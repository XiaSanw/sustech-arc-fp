nohup: ignoring input
/isaac-sim/extscache/omni.isaac.ml_archive-2.1.2+106.5.0.lx64.cp310/pip_prebundle/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: '/isaac-sim/extscache/omni.isaac.ml_archive-2.1.2+106.5.0.lx64.cp310/pip_prebundle/torchvision/image.so: ELF load command address/offset not page-aligned'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Loading user config located at: '/isaac-sim/kit/data/Kit/Isaac-Sim/4.5/user.config.json'
[Info] [carb] Logging to file: /isaac-sim/kit/logs/Kit/Isaac-Sim/4.5/kit_20260104_190056.log
2026-01-04 11:00:56 [0ms] [Warning] [omni.kit.app.plugin] No crash reporter present, dumps uploading isn't available.
2026-01-04 11:00:56 [4ms] [Warning] [omni.ext.plugin] [ext: rendering_modes] Extensions config 'extension.toml' doesn't exist '/workspace/isaaclab/apps/rendering_modes' or '/workspace/isaaclab/apps/rendering_modes/config'
2026-01-04 11:01:00 [3,754ms] [Warning] [omni.usd_config.extension] Enable omni.materialx.libs extension to use MaterialX
2026-01-04 11:01:03 [6,995ms] [Warning] [omni.datastore] OmniHub is inaccessible
2026-01-04 11:01:07 [11,514ms] [Warning] [omni.platforminfo.plugin] failed to open the default display.  Can't verify X Server version.
2026-01-04 11:01:09 [12,902ms] [Warning] [omni.isaac.dynamic_control] omni.isaac.dynamic_control is deprecated as of Isaac Sim 4.5. No action is needed from end-users.

|---------------------------------------------------------------------------------------------|
| Driver Version: 535.154.05    | Graphics API: Vulkan
|=============================================================================================|
| GPU | Name                             | Active | LDA | GPU Memory | Vendor-ID | LUID       |
|     |                                  |        |     |            | Device-ID | UUID       |
|     |                                  |        |     |            | Bus-ID    |            |
|---------------------------------------------------------------------------------------------|
| 0   | NVIDIA GeForce RTX 4090 D        | Yes: 0 |     | 24810   MB | 10de      | 0          |
|     |                                  |        |     |            | 2685      | 91c4a5c2.. |
|     |                                  |        |     |            | 65        |            |
|=============================================================================================|
| OS: 22.04.5 LTS (Jammy Jellyfish) ubuntu, Version: 22.04.5, Kernel: 5.4.250-9-velinux1u1-amd64
| Processor: Intel(R) Xeon(R) Platinum 8457C
| Cores: 22 | Logical Cores: 44
|---------------------------------------------------------------------------------------------|
| Total Memory (MB): 180751 | Free Memory: 79098
| Total Page/Swap (MB): 0 | Free Page/Swap: 0
|---------------------------------------------------------------------------------------------|
2026-01-04 11:01:39 [43,057ms] [Warning] [isaaclab.terrains.terrain_importer] Visual material specified for ground plane but no diffuse color found. Using default color: (0.0, 0.0, 0.0)
2026-01-04 11:01:41 [45,523ms] [Warning] [isaaclab.actuators.actuator_pd] The <ImplicitActuatorCfg> object has a value for 'effort_limit'. This parameter will be removed in the future. To set the effort limit, please use 'effort_limit_sim' instead.
2026-01-04 11:01:41 [45,523ms] [Warning] [isaaclab.actuators.actuator_pd] The <ImplicitActuatorCfg> object has a value for 'velocity_limit'. Previously, although this value was specified, it was not getting used by implicit actuators. Since this parameter affects the simulation behavior, we continue to not use it. This parameter will be removed in the future. To set the velocity limit, please use 'velocity_limit_sim' instead.
2026-01-04 11:01:44 [48,288ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPreviewSurface.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 11:01:44 [48,330ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdUVTexture.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 11:01:44 [48,371ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_float.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 11:01:44 [48,406ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_float2.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 11:01:44 [48,441ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_float3.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 11:01:44 [48,477ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_float4.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 11:01:44 [48,509ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_int.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 11:01:44 [48,545ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_string.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 11:01:44 [48,581ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_normal.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 11:01:44 [48,613ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_point.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 11:01:45 [48,648ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_vector.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 11:01:45 [48,691ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_matrix.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 11:01:45 [48,729ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdTransform2d.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

[INFO][AppLauncher]: Using device: cuda:0
[INFO][AppLauncher]: Loading experience file: /workspace/isaaclab/apps/isaaclab.python.headless.kit
[INFO]: Parsing configuration from: <class 'bipedal_locomotion.tasks.locomotion.robots.limx_pointfoot_env_cfg.PFBlindFlatEnvCfg'>
[INFO]: Parsing configuration from: PF_TRON1AFlatPPORunnerCfg(seed=42, device='cuda:0', num_steps_per_env=24, max_iterations=3000, empirical_normalization=False, policy=RslRlPpoActorCriticCfg(class_name='ActorCritic', init_noise_std=1.0, noise_std_type='scalar', actor_hidden_dims=[512, 256, 128], critic_hidden_dims=[512, 256, 128], activation='elu'), algorithm=RslRlPpoAlgorithmMlpCfg(class_name='PPO', num_learning_epochs=5, num_mini_batches=4, learning_rate=0.001, schedule='adaptive', gamma=0.99, lam=0.95, entropy_coef=0.01, desired_kl=0.01, max_grad_norm=1.0, value_loss_coef=1.0, use_clipped_value_loss=True, clip_param=0.2, normalize_advantage_per_mini_batch=False, symmetry_cfg=None, rnd_cfg=None, obs_history_len=10), clip_actions=None, save_interval=200, experiment_name='pf_tron_1a_flat', run_name='', logger='tensorboard', neptune_project='isaaclab', wandb_project='isaaclab', resume=False, load_run='.*', load_checkpoint='model_.*.pt', encoder=EncoderCfg(output_detach=True, num_input_dim=<dataclasses._MISSING_TYPE object at 0x7fd957be64d0>, num_output_dim=3, hidden_dims=[256, 128], activation='elu', orthogonal_init=False))
[INFO] Logging experiment in directory: /personal/limxtron1lab-main/logs/rsl_rl/pf_tron_1a_flat
Setting seed: 42
[INFO]: Base environment:
	Environment device    : cuda:0
	Environment seed      : 42
	Physics step-size     : 0.005
	Rendering step-size   : 0.04
	Environment step-size : 0.02
[INFO]: Time taken for scene creation : 1.681044 seconds
[INFO]: Scene manager:  <class InteractiveScene>
	Number of environments: 4096
	Environment spacing   : 2.5
	Source prim name      : /World/envs/env_0
	Global prim paths     : ['/World/ground']
	Replicate physics     : True
[INFO]: Starting the simulation. This may take a few seconds. Please wait...
[INFO]: Time taken for simulation start : 3.586805 seconds
[INFO] Command Manager:  <CommandManager> contains 2 active terms.
+------------------------------------------------+
|              Active Command Terms              |
+-------+---------------+------------------------+
| Index | Name          |          Type          |
+-------+---------------+------------------------+
|   0   | base_velocity | UniformVelocityCommand |
|   1   | gait_command  |      GaitCommand       |
+-------+---------------+------------------------+

[INFO] Event Manager:  <EventManager> contains 3 active terms.
+-------------------------------------------+
|   Active Event Terms in Mode: 'startup'   |
+-------+-----------------------------------+
| Index | Name                              |
+-------+-----------------------------------+
|   0   | add_base_mass                     |
|   1   | add_link_mass                     |
|   2   | radomize_rigid_body_mass_inertia  |
|   3   | robot_physics_material            |
|   4   | robot_joint_stiffness_and_damping |
|   5   | robot_center_of_mass              |
+-------+-----------------------------------+
+-------------------------------------+
| Active Event Terms in Mode: 'reset' |
+---------+---------------------------+
|  Index  | Name                      |
+---------+---------------------------+
|    0    | reset_robot_base          |
|    1    | reset_robot_joints        |
+---------+---------------------------+
+----------------------------------------------+
|    Active Event Terms in Mode: 'interval'    |
+-------+------------+-------------------------+
| Index | Name       | Interval time range (s) |
+-------+------------+-------------------------+
|   0   | push_robot |       (5.0, 10.0)       |
+-------+------------+-------------------------+

[INFO] Recorder Manager:  <RecorderManager> contains 0 active terms.
+---------------------+
| Active Recorder Terms |
+-----------+---------+
|   Index   | Name    |
+-----------+---------+
+-----------+---------+

[INFO] Action Manager:  <ActionManager> contains 1 active terms.
+----------------------------------+
|  Active Action Terms (shape: 6)  |
+--------+------------+------------+
| Index  | Name       |  Dimension |
+--------+------------+------------+
|   0    | joint_pos  |          6 |
+--------+------------+------------+

[INFO] Observation Manager: <ObservationManager> contains 4 groups.
+-------------------------------------------------------+
| Active Observation Terms in Group: 'policy' (shape: (30,)) |
+-------------+---------------------------+-------------+
|    Index    | Name                      |    Shape    |
+-------------+---------------------------+-------------+
|      0      | base_ang_vel              |     (3,)    |
|      1      | proj_gravity              |     (3,)    |
|      2      | joint_pos                 |     (6,)    |
|      3      | joint_vel                 |     (6,)    |
|      4      | last_action               |     (6,)    |
|      5      | gait_phase                |     (2,)    |
|      6      | gait_command              |     (4,)    |
+-------------+---------------------------+-------------+
+-------------------------------------------------------------+
| Active Observation Terms in Group: 'critic' (shape: (360,)) |
+----------+--------------------------------------+-----------+
|  Index   | Name                                 |   Shape   |
+----------+--------------------------------------+-----------+
|    0     | base_lin_vel                         |    (3,)   |
|    1     | base_ang_vel                         |    (3,)   |
|    2     | proj_gravity                         |    (3,)   |
|    3     | joint_pos                            |    (6,)   |
|    4     | joint_vel                            |    (6,)   |
|    5     | last_action                          |    (6,)   |
|    6     | gait_phase                           |    (2,)   |
|    7     | gait_command                         |    (4,)   |
|    8     | robot_joint_torque                   |    (6,)   |
|    9     | robot_joint_acc                      |    (6,)   |
|    10    | robot_feet_contact_force             |   (144,)  |
|    11    | robot_mass                           |   (12,)   |
|    12    | robot_inertia                        |   (108,)  |
|    13    | robot_joint_stiffness                |    (6,)   |
|    14    | robot_joint_damping                  |    (6,)   |
|    15    | robot_pos                            |    (3,)   |
|    16    | robot_vel                            |    (6,)   |
|    17    | robot_material_propertirs            |   (27,)   |
|    18    | robot_base_pose                      |    (3,)   |
+----------+--------------------------------------+-----------+
+---------------------------------------------------------+
| Active Observation Terms in Group: 'commands' (shape: (3,)) |
+-----------+---------------------------------+-----------+
|   Index   | Name                            |   Shape   |
+-----------+---------------------------------+-----------+
|     0     | velocity_commands               |    (3,)   |
+-----------+---------------------------------+-----------+
+-------------------------------------------------------------+
| Active Observation Terms in Group: 'obsHistory' (shape: (70, 30)) |
+-------------+----------------------------+------------------+
|    Index    | Name                       |      Shape       |
+-------------+----------------------------+------------------+
|      0      | base_ang_vel               |     (10, 3)      |
|      1      | proj_gravity               |     (10, 3)      |
|      2      | joint_pos                  |     (10, 6)      |
|      3      | joint_vel                  |     (10, 6)      |
|      4      | last_action                |     (10, 6)      |
|      5      | gait_phase                 |     (10, 2)      |
|      6      | gait_command               |     (10, 4)      |
+-------------+----------------------------+------------------+

[INFO] Termination Manager:  <TerminationManager> contains 2 active terms.
+---------------------------------+
|     Active Termination Terms    |
+-------+--------------+----------+
| Index | Name         | Time Out |
+-------+--------------+----------+
|   0   | time_out     |   True   |
|   1   | base_contact |  False   |
+-------+--------------+----------+

[INFO] Reward Manager:  <RewardManager> contains 19 active terms.
+-------------------------------------------+
|            Active Reward Terms            |
+-------+------------------------+----------+
| Index | Name                   |   Weight |
+-------+------------------------+----------+
|   0   | keep_balance           |      1.0 |
|   1   | rew_lin_vel_xy         |      8.0 |
|   2   | rew_ang_vel_z          |      4.0 |
|   3   | pen_base_height        |    -20.0 |
|   4   | pen_lin_vel_z          |     -0.5 |
|   5   | pen_ang_vel_xy         |    -0.05 |
|   6   | pen_joint_torque       |   -8e-05 |
|   7   | pen_joint_accel        | -2.5e-07 |
|   8   | pen_action_rate        |    -0.03 |
|   9   | pen_joint_pos_limits   |     -2.0 |
|   10  | pen_joint_vel_l2       |   -0.001 |
|   11  | pen_joint_powers       |  -0.0005 |
|   12  | pen_undesired_contacts |     -0.5 |
|   13  | pen_action_smoothness  |    -0.04 |
|   14  | pen_flat_orientation   |    -10.0 |
|   15  | pen_feet_distance      |     -100 |
|   16  | pen_feet_regulation    |     -0.1 |
|   17  | foot_landing_vel       |     -0.5 |
|   18  | test_gait_reward       |      1.0 |
+-------+------------------------+----------+

[INFO] Curriculum Manager:  <CurriculumManager> contains 0 active terms.
+----------------------+
| Active Curriculum Terms |
+-----------+----------+
|   Index   | Name     |
+-----------+----------+
+-----------+----------+

[INFO]: Completed setting up the environment...
encoder cfg: dict_keys(['seed', 'device', 'num_steps_per_env', 'max_iterations', 'empirical_normalization', 'policy', 'algorithm', 'clip_actions', 'save_interval', 'experiment_name', 'run_name', 'logger', 'neptune_project', 'wandb_project', 'resume', 'load_run', 'load_checkpoint', 'encoder'])
Encoder MLP: Sequential(
  (0): Linear(in_features=300, out_features=256, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=256, out_features=128, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=128, out_features=3, bias=True)
)
ActorCritic.__init__ got unexpected arguments, which will be ignored: ['class_name', 'noise_std_type']
Actor MLP: Sequential(
  (0): Linear(in_features=36, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=6, bias=True)
)
Critic MLP: Sequential(
  (0): Linear(in_features=363, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=1, bias=True)
)
Setting seed: 42
################################################################################
                      [1m Learning iteration 0/3000 [0m                       

                       Computation: 31876 steps/s (collection: 2.894s, learning 0.189s)
               Value function loss: 7.0667
                    Surrogate loss: 0.0125
             Mean action noise std: 1.0008
                     Learning rate: 0.0004
                       Mean reward: -4.86
               Mean episode length: 23.91
       Episode_Reward/keep_balance: 0.0125
     Episode_Reward/rew_lin_vel_xy: 0.0107
      Episode_Reward/rew_ang_vel_z: 0.0210
    Episode_Reward/pen_base_height: -0.0408
      Episode_Reward/pen_lin_vel_z: -0.0090
     Episode_Reward/pen_ang_vel_xy: -0.0075
   Episode_Reward/pen_joint_torque: -0.0013
    Episode_Reward/pen_joint_accel: -0.0020
    Episode_Reward/pen_action_rate: -0.0043
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0008
   Episode_Reward/pen_joint_powers: -0.0010
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.0154
Episode_Reward/pen_flat_orientation: -0.0164
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0021
   Episode_Reward/foot_landing_vel: -0.0048
   Episode_Reward/test_gait_reward: -0.0134
Metrics/base_velocity/error_vel_xy: 0.0539
Metrics/base_velocity/error_vel_yaw: 0.0274
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 3.08s
                        Total time: 3.08s
                               ETA: 9251.6s

################################################################################
                      [1m Learning iteration 1/3000 [0m                       

                       Computation: 87339 steps/s (collection: 0.998s, learning 0.127s)
               Value function loss: 5.3468
                    Surrogate loss: 0.0008
             Mean action noise std: 0.9976
                     Learning rate: 0.0015
                       Mean reward: -8.58
               Mean episode length: 42.82
       Episode_Reward/keep_balance: 0.0358
     Episode_Reward/rew_lin_vel_xy: 0.0296
      Episode_Reward/rew_ang_vel_z: 0.0457
    Episode_Reward/pen_base_height: -0.1795
      Episode_Reward/pen_lin_vel_z: -0.0195
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0128
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0491
Episode_Reward/pen_flat_orientation: -0.1288
  Episode_Reward/pen_feet_distance: -0.0058
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0401
Metrics/base_velocity/error_vel_xy: 0.1706
Metrics/base_velocity/error_vel_yaw: 0.1234
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 137.8333
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 1.13s
                        Total time: 4.21s
                               ETA: 6312.0s

################################################################################
                      [1m Learning iteration 2/3000 [0m                       

                       Computation: 89987 steps/s (collection: 0.973s, learning 0.119s)
               Value function loss: 2.4745
                    Surrogate loss: 0.0061
             Mean action noise std: 0.9966
                     Learning rate: 0.0022
                       Mean reward: -7.42
               Mean episode length: 35.10
       Episode_Reward/keep_balance: 0.0361
     Episode_Reward/rew_lin_vel_xy: 0.0326
      Episode_Reward/rew_ang_vel_z: 0.0463
    Episode_Reward/pen_base_height: -0.1779
      Episode_Reward/pen_lin_vel_z: -0.0193
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0129
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0494
Episode_Reward/pen_flat_orientation: -0.1292
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0405
Metrics/base_velocity/error_vel_xy: 0.1719
Metrics/base_velocity/error_vel_yaw: 0.1254
      Episode_Termination/time_out: 0.2083
  Episode_Termination/base_contact: 103.5000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 1.09s
                        Total time: 5.30s
                               ETA: 5298.3s

################################################################################
                      [1m Learning iteration 3/3000 [0m                       

                       Computation: 91307 steps/s (collection: 0.955s, learning 0.121s)
               Value function loss: 2.0284
                    Surrogate loss: 0.0087
             Mean action noise std: 0.9939
                     Learning rate: 0.0004
                       Mean reward: -7.87
               Mean episode length: 38.15
       Episode_Reward/keep_balance: 0.0369
     Episode_Reward/rew_lin_vel_xy: 0.0326
      Episode_Reward/rew_ang_vel_z: 0.0458
    Episode_Reward/pen_base_height: -0.1823
      Episode_Reward/pen_lin_vel_z: -0.0196
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0130
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0500
Episode_Reward/pen_flat_orientation: -0.1300
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0412
Metrics/base_velocity/error_vel_xy: 0.1791
Metrics/base_velocity/error_vel_yaw: 0.1324
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 118.8333
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 1.08s
                        Total time: 6.38s
                               ETA: 4779.1s

################################################################################
                      [1m Learning iteration 4/3000 [0m                       

                       Computation: 88546 steps/s (collection: 0.985s, learning 0.125s)
               Value function loss: 1.9366
                    Surrogate loss: 0.0157
             Mean action noise std: 0.9918
                     Learning rate: 0.0000
                       Mean reward: -7.98
               Mean episode length: 37.16
       Episode_Reward/keep_balance: 0.0368
     Episode_Reward/rew_lin_vel_xy: 0.0318
      Episode_Reward/rew_ang_vel_z: 0.0463
    Episode_Reward/pen_base_height: -0.1835
      Episode_Reward/pen_lin_vel_z: -0.0197
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0129
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0491
Episode_Reward/pen_flat_orientation: -0.1314
  Episode_Reward/pen_feet_distance: -0.0054
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0411
Metrics/base_velocity/error_vel_xy: 0.1769
Metrics/base_velocity/error_vel_yaw: 0.1314
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 106.4583
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 1.11s
                        Total time: 7.49s
                               ETA: 4487.2s

################################################################################
                      [1m Learning iteration 5/3000 [0m                       

                       Computation: 90467 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 1.8236
                    Surrogate loss: 0.0010
             Mean action noise std: 0.9909
                     Learning rate: 0.0009
                       Mean reward: -8.00
               Mean episode length: 38.22
       Episode_Reward/keep_balance: 0.0376
     Episode_Reward/rew_lin_vel_xy: 0.0316
      Episode_Reward/rew_ang_vel_z: 0.0464
    Episode_Reward/pen_base_height: -0.1863
      Episode_Reward/pen_lin_vel_z: -0.0199
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0058
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0131
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0500
Episode_Reward/pen_flat_orientation: -0.1327
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0419
Metrics/base_velocity/error_vel_xy: 0.1836
Metrics/base_velocity/error_vel_yaw: 0.1355
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 109.7083
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 1.09s
                        Total time: 8.58s
                               ETA: 4280.5s

################################################################################
                      [1m Learning iteration 6/3000 [0m                       

                       Computation: 86129 steps/s (collection: 1.017s, learning 0.124s)
               Value function loss: 1.6560
                    Surrogate loss: 0.0029
             Mean action noise std: 0.9889
                     Learning rate: 0.0044
                       Mean reward: -7.73
               Mean episode length: 37.68
       Episode_Reward/keep_balance: 0.0375
     Episode_Reward/rew_lin_vel_xy: 0.0313
      Episode_Reward/rew_ang_vel_z: 0.0473
    Episode_Reward/pen_base_height: -0.1861
      Episode_Reward/pen_lin_vel_z: -0.0200
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0058
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0130
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0496
Episode_Reward/pen_flat_orientation: -0.1322
  Episode_Reward/pen_feet_distance: -0.0057
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0420
Metrics/base_velocity/error_vel_xy: 0.1849
Metrics/base_velocity/error_vel_yaw: 0.1321
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 110.5833
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 1.14s
                        Total time: 9.72s
                               ETA: 4155.9s

################################################################################
                      [1m Learning iteration 7/3000 [0m                       

                       Computation: 83613 steps/s (collection: 1.043s, learning 0.132s)
               Value function loss: 1.5581
                    Surrogate loss: 0.0033
             Mean action noise std: 0.9834
                     Learning rate: 0.0099
                       Mean reward: -7.55
               Mean episode length: 36.94
       Episode_Reward/keep_balance: 0.0374
     Episode_Reward/rew_lin_vel_xy: 0.0345
      Episode_Reward/rew_ang_vel_z: 0.0469
    Episode_Reward/pen_base_height: -0.1863
      Episode_Reward/pen_lin_vel_z: -0.0200
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0058
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0128
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0489
Episode_Reward/pen_flat_orientation: -0.1326
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0418
Metrics/base_velocity/error_vel_xy: 0.1774
Metrics/base_velocity/error_vel_yaw: 0.1331
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 109.6250
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 1.18s
                        Total time: 10.89s
                               ETA: 4075.1s

################################################################################
                      [1m Learning iteration 8/3000 [0m                       

                       Computation: 89155 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 1.3167
                    Surrogate loss: 0.0035
             Mean action noise std: 0.9854
                     Learning rate: 0.0044
                       Mean reward: -7.63
               Mean episode length: 36.96
       Episode_Reward/keep_balance: 0.0371
     Episode_Reward/rew_lin_vel_xy: 0.0302
      Episode_Reward/rew_ang_vel_z: 0.0476
    Episode_Reward/pen_base_height: -0.1839
      Episode_Reward/pen_lin_vel_z: -0.0198
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0483
Episode_Reward/pen_flat_orientation: -0.1302
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0414
Metrics/base_velocity/error_vel_xy: 0.1822
Metrics/base_velocity/error_vel_yaw: 0.1275
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 109.9167
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 1.10s
                        Total time: 11.99s
                               ETA: 3987.7s

################################################################################
                      [1m Learning iteration 9/3000 [0m                       

                       Computation: 89221 steps/s (collection: 0.976s, learning 0.126s)
               Value function loss: 1.2523
                    Surrogate loss: 0.0073
             Mean action noise std: 0.9831
                     Learning rate: 0.0013
                       Mean reward: -7.40
               Mean episode length: 36.65
       Episode_Reward/keep_balance: 0.0372
     Episode_Reward/rew_lin_vel_xy: 0.0325
      Episode_Reward/rew_ang_vel_z: 0.0473
    Episode_Reward/pen_base_height: -0.1835
      Episode_Reward/pen_lin_vel_z: -0.0197
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0126
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0477
Episode_Reward/pen_flat_orientation: -0.1303
  Episode_Reward/pen_feet_distance: -0.0051
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0416
Metrics/base_velocity/error_vel_xy: 0.1800
Metrics/base_velocity/error_vel_yaw: 0.1298
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 112.7500
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.10s
                        Total time: 13.10s
                               ETA: 3917.2s

################################################################################
                      [1m Learning iteration 10/3000 [0m                      

                       Computation: 86821 steps/s (collection: 1.008s, learning 0.124s)
               Value function loss: 1.0649
                    Surrogate loss: 0.0064
             Mean action noise std: 0.9826
                     Learning rate: 0.0004
                       Mean reward: -7.55
               Mean episode length: 36.01
       Episode_Reward/keep_balance: 0.0368
     Episode_Reward/rew_lin_vel_xy: 0.0322
      Episode_Reward/rew_ang_vel_z: 0.0468
    Episode_Reward/pen_base_height: -0.1808
      Episode_Reward/pen_lin_vel_z: -0.0194
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0472
Episode_Reward/pen_flat_orientation: -0.1292
  Episode_Reward/pen_feet_distance: -0.0054
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0411
Metrics/base_velocity/error_vel_xy: 0.1767
Metrics/base_velocity/error_vel_yaw: 0.1291
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 107.8333
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.13s
                        Total time: 14.23s
                               ETA: 3867.7s

################################################################################
                      [1m Learning iteration 11/3000 [0m                      

                       Computation: 87466 steps/s (collection: 1.002s, learning 0.122s)
               Value function loss: 1.0105
                    Surrogate loss: 0.0007
             Mean action noise std: 0.9760
                     Learning rate: 0.0044
                       Mean reward: -7.70
               Mean episode length: 38.00
       Episode_Reward/keep_balance: 0.0373
     Episode_Reward/rew_lin_vel_xy: 0.0319
      Episode_Reward/rew_ang_vel_z: 0.0469
    Episode_Reward/pen_base_height: -0.1834
      Episode_Reward/pen_lin_vel_z: -0.0193
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0126
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0478
Episode_Reward/pen_flat_orientation: -0.1308
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0417
Metrics/base_velocity/error_vel_xy: 0.1816
Metrics/base_velocity/error_vel_yaw: 0.1311
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 110.0833
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.12s
                        Total time: 15.35s
                               ETA: 3824.2s

################################################################################
                      [1m Learning iteration 12/3000 [0m                      

                       Computation: 88728 steps/s (collection: 0.987s, learning 0.121s)
               Value function loss: 1.0170
                    Surrogate loss: 0.0025
             Mean action noise std: 0.9657
                     Learning rate: 0.0100
                       Mean reward: -7.11
               Mean episode length: 35.85
       Episode_Reward/keep_balance: 0.0368
     Episode_Reward/rew_lin_vel_xy: 0.0321
      Episode_Reward/rew_ang_vel_z: 0.0469
    Episode_Reward/pen_base_height: -0.1800
      Episode_Reward/pen_lin_vel_z: -0.0191
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0469
Episode_Reward/pen_flat_orientation: -0.1283
  Episode_Reward/pen_feet_distance: -0.0050
Episode_Reward/pen_feet_regulation: -0.0059
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0410
Metrics/base_velocity/error_vel_xy: 0.1781
Metrics/base_velocity/error_vel_yaw: 0.1290
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 112.9167
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.11s
                        Total time: 16.46s
                               ETA: 3783.5s

################################################################################
                      [1m Learning iteration 13/3000 [0m                      

                       Computation: 89046 steps/s (collection: 0.983s, learning 0.121s)
               Value function loss: 1.2095
                    Surrogate loss: -0.0008
             Mean action noise std: 0.9649
                     Learning rate: 0.0100
                       Mean reward: -7.07
               Mean episode length: 35.62
       Episode_Reward/keep_balance: 0.0366
     Episode_Reward/rew_lin_vel_xy: 0.0327
      Episode_Reward/rew_ang_vel_z: 0.0466
    Episode_Reward/pen_base_height: -0.1787
      Episode_Reward/pen_lin_vel_z: -0.0190
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0120
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0454
Episode_Reward/pen_flat_orientation: -0.1277
  Episode_Reward/pen_feet_distance: -0.0048
Episode_Reward/pen_feet_regulation: -0.0059
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0409
Metrics/base_velocity/error_vel_xy: 0.1765
Metrics/base_velocity/error_vel_yaw: 0.1261
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 113.6667
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.10s
                        Total time: 17.56s
                               ETA: 3747.6s

################################################################################
                      [1m Learning iteration 14/3000 [0m                      

                       Computation: 89615 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.9864
                    Surrogate loss: 0.0016
             Mean action noise std: 0.9610
                     Learning rate: 0.0067
                       Mean reward: -7.09
               Mean episode length: 34.70
       Episode_Reward/keep_balance: 0.0362
     Episode_Reward/rew_lin_vel_xy: 0.0298
      Episode_Reward/rew_ang_vel_z: 0.0468
    Episode_Reward/pen_base_height: -0.1769
      Episode_Reward/pen_lin_vel_z: -0.0188
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0116
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0438
Episode_Reward/pen_flat_orientation: -0.1269
  Episode_Reward/pen_feet_distance: -0.0043
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0403
Metrics/base_velocity/error_vel_xy: 0.1788
Metrics/base_velocity/error_vel_yaw: 0.1228
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 113.2500
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.10s
                        Total time: 18.66s
                               ETA: 3714.9s

################################################################################
                      [1m Learning iteration 15/3000 [0m                      

                       Computation: 89550 steps/s (collection: 0.979s, learning 0.119s)
               Value function loss: 0.9400
                    Surrogate loss: 0.0011
             Mean action noise std: 0.9619
                     Learning rate: 0.0100
                       Mean reward: -6.87
               Mean episode length: 35.36
       Episode_Reward/keep_balance: 0.0365
     Episode_Reward/rew_lin_vel_xy: 0.0305
      Episode_Reward/rew_ang_vel_z: 0.0472
    Episode_Reward/pen_base_height: -0.1774
      Episode_Reward/pen_lin_vel_z: -0.0187
     Episode_Reward/pen_ang_vel_xy: -0.0221
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0116
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0438
Episode_Reward/pen_flat_orientation: -0.1262
  Episode_Reward/pen_feet_distance: -0.0047
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0407
Metrics/base_velocity/error_vel_xy: 0.1793
Metrics/base_velocity/error_vel_yaw: 0.1245
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 112.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.10s
                        Total time: 19.76s
                               ETA: 3686.4s

################################################################################
                      [1m Learning iteration 16/3000 [0m                      

                       Computation: 88112 steps/s (collection: 0.993s, learning 0.123s)
               Value function loss: 0.7089
                    Surrogate loss: 0.0006
             Mean action noise std: 0.9636
                     Learning rate: 0.0100
                       Mean reward: -6.60
               Mean episode length: 35.06
       Episode_Reward/keep_balance: 0.0363
     Episode_Reward/rew_lin_vel_xy: 0.0311
      Episode_Reward/rew_ang_vel_z: 0.0477
    Episode_Reward/pen_base_height: -0.1765
      Episode_Reward/pen_lin_vel_z: -0.0186
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0116
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0437
Episode_Reward/pen_flat_orientation: -0.1261
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0404
Metrics/base_velocity/error_vel_xy: 0.1773
Metrics/base_velocity/error_vel_yaw: 0.1219
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 110.7500
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.12s
                        Total time: 20.88s
                               ETA: 3664.2s

################################################################################
                      [1m Learning iteration 17/3000 [0m                      

                       Computation: 86810 steps/s (collection: 1.006s, learning 0.127s)
               Value function loss: 0.8685
                    Surrogate loss: -0.0002
             Mean action noise std: 0.9596
                     Learning rate: 0.0100
                       Mean reward: -7.09
               Mean episode length: 36.17
       Episode_Reward/keep_balance: 0.0368
     Episode_Reward/rew_lin_vel_xy: 0.0327
      Episode_Reward/rew_ang_vel_z: 0.0484
    Episode_Reward/pen_base_height: -0.1785
      Episode_Reward/pen_lin_vel_z: -0.0188
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0118
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0445
Episode_Reward/pen_flat_orientation: -0.1276
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.0057
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0409
Metrics/base_velocity/error_vel_xy: 0.1780
Metrics/base_velocity/error_vel_yaw: 0.1214
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 112.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.13s
                        Total time: 22.01s
                               ETA: 3647.1s

################################################################################
                      [1m Learning iteration 18/3000 [0m                      

                       Computation: 80330 steps/s (collection: 1.100s, learning 0.124s)
               Value function loss: 1.1888
                    Surrogate loss: 0.0012
             Mean action noise std: 0.9594
                     Learning rate: 0.0100
                       Mean reward: -6.88
               Mean episode length: 35.64
       Episode_Reward/keep_balance: 0.0366
     Episode_Reward/rew_lin_vel_xy: 0.0330
      Episode_Reward/rew_ang_vel_z: 0.0485
    Episode_Reward/pen_base_height: -0.1773
      Episode_Reward/pen_lin_vel_z: -0.0186
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0116
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0439
Episode_Reward/pen_flat_orientation: -0.1265
  Episode_Reward/pen_feet_distance: -0.0038
Episode_Reward/pen_feet_regulation: -0.0057
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0408
Metrics/base_velocity/error_vel_xy: 0.1768
Metrics/base_velocity/error_vel_yaw: 0.1208
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 111.5000
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.22s
                        Total time: 23.23s
                               ETA: 3646.1s

################################################################################
                      [1m Learning iteration 19/3000 [0m                      

                       Computation: 81772 steps/s (collection: 1.077s, learning 0.125s)
               Value function loss: 1.1205
                    Surrogate loss: -0.0018
             Mean action noise std: 0.9563
                     Learning rate: 0.0100
                       Mean reward: -6.99
               Mean episode length: 37.01
       Episode_Reward/keep_balance: 0.0368
     Episode_Reward/rew_lin_vel_xy: 0.0324
      Episode_Reward/rew_ang_vel_z: 0.0486
    Episode_Reward/pen_base_height: -0.1766
      Episode_Reward/pen_lin_vel_z: -0.0184
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0116
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0436
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0410
Metrics/base_velocity/error_vel_xy: 0.1781
Metrics/base_velocity/error_vel_yaw: 0.1208
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.2500
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.20s
                        Total time: 24.43s
                               ETA: 3641.8s

################################################################################
                      [1m Learning iteration 20/3000 [0m                      

                       Computation: 89385 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 1.6355
                    Surrogate loss: 0.0010
             Mean action noise std: 0.9487
                     Learning rate: 0.0100
                       Mean reward: -7.13
               Mean episode length: 37.44
       Episode_Reward/keep_balance: 0.0356
     Episode_Reward/rew_lin_vel_xy: 0.0309
      Episode_Reward/rew_ang_vel_z: 0.0477
    Episode_Reward/pen_base_height: -0.1710
      Episode_Reward/pen_lin_vel_z: -0.0176
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0111
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0418
Episode_Reward/pen_flat_orientation: -0.1235
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0397
Metrics/base_velocity/error_vel_xy: 0.1741
Metrics/base_velocity/error_vel_yaw: 0.1156
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 113.9167
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.10s
                        Total time: 25.53s
                               ETA: 3623.3s

################################################################################
                      [1m Learning iteration 21/3000 [0m                      

                       Computation: 87688 steps/s (collection: 0.997s, learning 0.124s)
               Value function loss: 0.7362
                    Surrogate loss: -0.0001
             Mean action noise std: 0.9491
                     Learning rate: 0.0067
                       Mean reward: -6.60
               Mean episode length: 34.56
       Episode_Reward/keep_balance: 0.0358
     Episode_Reward/rew_lin_vel_xy: 0.0310
      Episode_Reward/rew_ang_vel_z: 0.0475
    Episode_Reward/pen_base_height: -0.1710
      Episode_Reward/pen_lin_vel_z: -0.0176
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0111
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0416
Episode_Reward/pen_flat_orientation: -0.1230
  Episode_Reward/pen_feet_distance: -0.0036
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0399
Metrics/base_velocity/error_vel_xy: 0.1759
Metrics/base_velocity/error_vel_yaw: 0.1176
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.2083
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.12s
                        Total time: 26.65s
                               ETA: 3609.2s

################################################################################
                      [1m Learning iteration 22/3000 [0m                      

                       Computation: 89834 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.8165
                    Surrogate loss: -0.0007
             Mean action noise std: 0.9462
                     Learning rate: 0.0100
                       Mean reward: -6.84
               Mean episode length: 37.14
       Episode_Reward/keep_balance: 0.0352
     Episode_Reward/rew_lin_vel_xy: 0.0299
      Episode_Reward/rew_ang_vel_z: 0.0487
    Episode_Reward/pen_base_height: -0.1679
      Episode_Reward/pen_lin_vel_z: -0.0171
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0107
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0402
Episode_Reward/pen_flat_orientation: -0.1217
  Episode_Reward/pen_feet_distance: -0.0027
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0393
Metrics/base_velocity/error_vel_xy: 0.1726
Metrics/base_velocity/error_vel_yaw: 0.1101
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 117.0833
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.09s
                        Total time: 27.75s
                               ETA: 3592.8s

################################################################################
                      [1m Learning iteration 23/3000 [0m                      

                       Computation: 89351 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 0.5224
                    Surrogate loss: 0.0083
             Mean action noise std: 0.9422
                     Learning rate: 0.0006
                       Mean reward: -6.39
               Mean episode length: 33.60
       Episode_Reward/keep_balance: 0.0349
     Episode_Reward/rew_lin_vel_xy: 0.0306
      Episode_Reward/rew_ang_vel_z: 0.0485
    Episode_Reward/pen_base_height: -0.1642
      Episode_Reward/pen_lin_vel_z: -0.0166
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0048
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0106
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0396
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0027
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0389
Metrics/base_velocity/error_vel_xy: 0.1710
Metrics/base_velocity/error_vel_yaw: 0.1066
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 119.3750
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 1.10s
                        Total time: 28.85s
                               ETA: 3578.5s

################################################################################
                      [1m Learning iteration 24/3000 [0m                      

                       Computation: 89735 steps/s (collection: 0.975s, learning 0.120s)
               Value function loss: 0.4188
                    Surrogate loss: 0.0184
             Mean action noise std: 0.9417
                     Learning rate: 0.0000
                       Mean reward: -6.55
               Mean episode length: 34.22
       Episode_Reward/keep_balance: 0.0346
     Episode_Reward/rew_lin_vel_xy: 0.0302
      Episode_Reward/rew_ang_vel_z: 0.0485
    Episode_Reward/pen_base_height: -0.1638
      Episode_Reward/pen_lin_vel_z: -0.0166
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0048
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0105
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0391
Episode_Reward/pen_flat_orientation: -0.1197
  Episode_Reward/pen_feet_distance: -0.0027
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0387
Metrics/base_velocity/error_vel_xy: 0.1705
Metrics/base_velocity/error_vel_yaw: 0.1056
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 119.0833
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 1.10s
                        Total time: 29.94s
                               ETA: 3564.6s

################################################################################
                      [1m Learning iteration 25/3000 [0m                      

                       Computation: 88883 steps/s (collection: 0.983s, learning 0.123s)
               Value function loss: 0.3866
                    Surrogate loss: 0.0000
             Mean action noise std: 0.9346
                     Learning rate: 0.0006
                       Mean reward: -6.29
               Mean episode length: 33.82
       Episode_Reward/keep_balance: 0.0349
     Episode_Reward/rew_lin_vel_xy: 0.0304
      Episode_Reward/rew_ang_vel_z: 0.0483
    Episode_Reward/pen_base_height: -0.1664
      Episode_Reward/pen_lin_vel_z: -0.0170
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0104
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0387
Episode_Reward/pen_flat_orientation: -0.1205
  Episode_Reward/pen_feet_distance: -0.0028
Episode_Reward/pen_feet_regulation: -0.0054
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0388
Metrics/base_velocity/error_vel_xy: 0.1682
Metrics/base_velocity/error_vel_yaw: 0.1072
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 118.6250
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 1.11s
                        Total time: 31.05s
                               ETA: 3552.9s

################################################################################
                      [1m Learning iteration 26/3000 [0m                      

                       Computation: 89504 steps/s (collection: 0.977s, learning 0.121s)
               Value function loss: 0.3724
                    Surrogate loss: 0.0012
             Mean action noise std: 0.9252
                     Learning rate: 0.0019
                       Mean reward: -6.06
               Mean episode length: 32.66
       Episode_Reward/keep_balance: 0.0344
     Episode_Reward/rew_lin_vel_xy: 0.0297
      Episode_Reward/rew_ang_vel_z: 0.0481
    Episode_Reward/pen_base_height: -0.1595
      Episode_Reward/pen_lin_vel_z: -0.0157
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0046
    Episode_Reward/pen_joint_accel: -0.0042
    Episode_Reward/pen_action_rate: -0.0101
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0374
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.0054
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0382
Metrics/base_velocity/error_vel_xy: 0.1677
Metrics/base_velocity/error_vel_yaw: 0.1029
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 117.3750
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 1.10s
                        Total time: 32.15s
                               ETA: 3541.1s

################################################################################
                      [1m Learning iteration 27/3000 [0m                      

                       Computation: 83866 steps/s (collection: 1.046s, learning 0.126s)
               Value function loss: 0.3772
                    Surrogate loss: 0.0057
             Mean action noise std: 0.9200
                     Learning rate: 0.0006
                       Mean reward: -5.85
               Mean episode length: 33.56
       Episode_Reward/keep_balance: 0.0342
     Episode_Reward/rew_lin_vel_xy: 0.0294
      Episode_Reward/rew_ang_vel_z: 0.0495
    Episode_Reward/pen_base_height: -0.1554
      Episode_Reward/pen_lin_vel_z: -0.0150
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0042
    Episode_Reward/pen_action_rate: -0.0098
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0362
Episode_Reward/pen_flat_orientation: -0.1131
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0379
Metrics/base_velocity/error_vel_xy: 0.1699
Metrics/base_velocity/error_vel_yaw: 0.0991
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 122.3333
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 1.17s
                        Total time: 33.32s
                               ETA: 3537.9s

################################################################################
                      [1m Learning iteration 28/3000 [0m                      

                       Computation: 86167 steps/s (collection: 1.015s, learning 0.126s)
               Value function loss: 0.2912
                    Surrogate loss: -0.0021
             Mean action noise std: 0.9118
                     Learning rate: 0.0013
                       Mean reward: -5.85
               Mean episode length: 32.93
       Episode_Reward/keep_balance: 0.0338
     Episode_Reward/rew_lin_vel_xy: 0.0282
      Episode_Reward/rew_ang_vel_z: 0.0487
    Episode_Reward/pen_base_height: -0.1531
      Episode_Reward/pen_lin_vel_z: -0.0149
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0042
    Episode_Reward/pen_action_rate: -0.0095
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0350
Episode_Reward/pen_flat_orientation: -0.1110
  Episode_Reward/pen_feet_distance: -0.0028
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0373
Metrics/base_velocity/error_vel_xy: 0.1700
Metrics/base_velocity/error_vel_yaw: 0.0969
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 119.4167
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 1.14s
                        Total time: 34.46s
                               ETA: 3531.7s

################################################################################
                      [1m Learning iteration 29/3000 [0m                      

                       Computation: 84847 steps/s (collection: 1.031s, learning 0.127s)
               Value function loss: 0.2811
                    Surrogate loss: -0.0022
             Mean action noise std: 0.9035
                     Learning rate: 0.0029
                       Mean reward: -6.26
               Mean episode length: 35.15
       Episode_Reward/keep_balance: 0.0340
     Episode_Reward/rew_lin_vel_xy: 0.0290
      Episode_Reward/rew_ang_vel_z: 0.0499
    Episode_Reward/pen_base_height: -0.1534
      Episode_Reward/pen_lin_vel_z: -0.0149
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0094
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0345
Episode_Reward/pen_flat_orientation: -0.1106
  Episode_Reward/pen_feet_distance: -0.0027
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0376
Metrics/base_velocity/error_vel_xy: 0.1693
Metrics/base_velocity/error_vel_yaw: 0.0961
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 121.5417
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 1.16s
                        Total time: 35.62s
                               ETA: 3527.6s

################################################################################
                      [1m Learning iteration 30/3000 [0m                      

                       Computation: 83632 steps/s (collection: 1.042s, learning 0.134s)
               Value function loss: 0.4162
                    Surrogate loss: 0.0044
             Mean action noise std: 0.8988
                     Learning rate: 0.0009
                       Mean reward: -5.93
               Mean episode length: 34.03
       Episode_Reward/keep_balance: 0.0336
     Episode_Reward/rew_lin_vel_xy: 0.0279
      Episode_Reward/rew_ang_vel_z: 0.0501
    Episode_Reward/pen_base_height: -0.1521
      Episode_Reward/pen_lin_vel_z: -0.0150
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0091
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0332
Episode_Reward/pen_flat_orientation: -0.1094
  Episode_Reward/pen_feet_distance: -0.0028
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0371
Metrics/base_velocity/error_vel_xy: 0.1678
Metrics/base_velocity/error_vel_yaw: 0.0919
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 124.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 1.18s
                        Total time: 36.80s
                               ETA: 3525.3s

################################################################################
                      [1m Learning iteration 31/3000 [0m                      

                       Computation: 88024 steps/s (collection: 0.993s, learning 0.124s)
               Value function loss: 0.3276
                    Surrogate loss: 0.0002
             Mean action noise std: 0.8908
                     Learning rate: 0.0019
                       Mean reward: -5.75
               Mean episode length: 33.20
       Episode_Reward/keep_balance: 0.0330
     Episode_Reward/rew_lin_vel_xy: 0.0282
      Episode_Reward/rew_ang_vel_z: 0.0502
    Episode_Reward/pen_base_height: -0.1484
      Episode_Reward/pen_lin_vel_z: -0.0146
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0041
    Episode_Reward/pen_joint_accel: -0.0042
    Episode_Reward/pen_action_rate: -0.0087
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0318
Episode_Reward/pen_flat_orientation: -0.1069
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0365
Metrics/base_velocity/error_vel_xy: 0.1641
Metrics/base_velocity/error_vel_yaw: 0.0888
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 125.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 1.12s
                        Total time: 37.91s
                               ETA: 3517.6s

################################################################################
                      [1m Learning iteration 32/3000 [0m                      

                       Computation: 90764 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.3731
                    Surrogate loss: 0.0003
             Mean action noise std: 0.8875
                     Learning rate: 0.0019
                       Mean reward: -5.60
               Mean episode length: 33.08
       Episode_Reward/keep_balance: 0.0331
     Episode_Reward/rew_lin_vel_xy: 0.0285
      Episode_Reward/rew_ang_vel_z: 0.0514
    Episode_Reward/pen_base_height: -0.1484
      Episode_Reward/pen_lin_vel_z: -0.0147
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0041
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0086
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0312
Episode_Reward/pen_flat_orientation: -0.1064
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0365
Metrics/base_velocity/error_vel_xy: 0.1643
Metrics/base_velocity/error_vel_yaw: 0.0870
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 125.2083
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 1.08s
                        Total time: 39.00s
                               ETA: 3507.2s

################################################################################
                      [1m Learning iteration 33/3000 [0m                      

                       Computation: 86236 steps/s (collection: 1.015s, learning 0.125s)
               Value function loss: 0.3026
                    Surrogate loss: 0.0009
             Mean action noise std: 0.8822
                     Learning rate: 0.0013
                       Mean reward: -5.37
               Mean episode length: 32.29
       Episode_Reward/keep_balance: 0.0325
     Episode_Reward/rew_lin_vel_xy: 0.0279
      Episode_Reward/rew_ang_vel_z: 0.0508
    Episode_Reward/pen_base_height: -0.1453
      Episode_Reward/pen_lin_vel_z: -0.0144
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0039
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0082
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0298
Episode_Reward/pen_flat_orientation: -0.1035
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.0049
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0359
Metrics/base_velocity/error_vel_xy: 0.1630
Metrics/base_velocity/error_vel_yaw: 0.0846
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 126.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 1.14s
                        Total time: 40.14s
                               ETA: 3502.4s

################################################################################
                      [1m Learning iteration 34/3000 [0m                      

                       Computation: 87572 steps/s (collection: 0.994s, learning 0.128s)
               Value function loss: 0.2874
                    Surrogate loss: 0.0017
             Mean action noise std: 0.8777
                     Learning rate: 0.0009
                       Mean reward: -5.34
               Mean episode length: 32.04
       Episode_Reward/keep_balance: 0.0321
     Episode_Reward/rew_lin_vel_xy: 0.0277
      Episode_Reward/rew_ang_vel_z: 0.0511
    Episode_Reward/pen_base_height: -0.1422
      Episode_Reward/pen_lin_vel_z: -0.0143
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0081
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0292
Episode_Reward/pen_flat_orientation: -0.1008
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.0049
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0354
Metrics/base_velocity/error_vel_xy: 0.1608
Metrics/base_velocity/error_vel_yaw: 0.0806
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 128.3750
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 1.12s
                        Total time: 41.26s
                               ETA: 3496.3s

################################################################################
                      [1m Learning iteration 35/3000 [0m                      

                       Computation: 87892 steps/s (collection: 0.991s, learning 0.128s)
               Value function loss: 0.2802
                    Surrogate loss: -0.0000
             Mean action noise std: 0.8698
                     Learning rate: 0.0013
                       Mean reward: -5.44
               Mean episode length: 32.51
       Episode_Reward/keep_balance: 0.0321
     Episode_Reward/rew_lin_vel_xy: 0.0276
      Episode_Reward/rew_ang_vel_z: 0.0499
    Episode_Reward/pen_base_height: -0.1430
      Episode_Reward/pen_lin_vel_z: -0.0147
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0080
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0289
Episode_Reward/pen_flat_orientation: -0.0995
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0352
Metrics/base_velocity/error_vel_xy: 0.1598
Metrics/base_velocity/error_vel_yaw: 0.0835
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 127.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 1.12s
                        Total time: 42.38s
                               ETA: 3490.2s

################################################################################
                      [1m Learning iteration 36/3000 [0m                      

                       Computation: 88422 steps/s (collection: 0.988s, learning 0.124s)
               Value function loss: 0.2857
                    Surrogate loss: 0.0015
             Mean action noise std: 0.8629
                     Learning rate: 0.0013
                       Mean reward: -5.25
               Mean episode length: 31.95
       Episode_Reward/keep_balance: 0.0317
     Episode_Reward/rew_lin_vel_xy: 0.0270
      Episode_Reward/rew_ang_vel_z: 0.0499
    Episode_Reward/pen_base_height: -0.1400
      Episode_Reward/pen_lin_vel_z: -0.0146
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0037
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0078
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0280
Episode_Reward/pen_flat_orientation: -0.0968
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0344
Metrics/base_velocity/error_vel_xy: 0.1593
Metrics/base_velocity/error_vel_yaw: 0.0795
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 128.4167
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 1.11s
                        Total time: 43.49s
                               ETA: 3483.8s

################################################################################
                      [1m Learning iteration 37/3000 [0m                      

                       Computation: 87647 steps/s (collection: 0.994s, learning 0.128s)
               Value function loss: 0.2484
                    Surrogate loss: 0.0027
             Mean action noise std: 0.8567
                     Learning rate: 0.0003
                       Mean reward: -5.30
               Mean episode length: 33.17
       Episode_Reward/keep_balance: 0.0318
     Episode_Reward/rew_lin_vel_xy: 0.0267
      Episode_Reward/rew_ang_vel_z: 0.0506
    Episode_Reward/pen_base_height: -0.1403
      Episode_Reward/pen_lin_vel_z: -0.0145
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0036
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0076
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0275
Episode_Reward/pen_flat_orientation: -0.0965
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0346
Metrics/base_velocity/error_vel_xy: 0.1611
Metrics/base_velocity/error_vel_yaw: 0.0787
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 132.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 1.12s
                        Total time: 44.61s
                               ETA: 3478.4s

################################################################################
                      [1m Learning iteration 38/3000 [0m                      

                       Computation: 87107 steps/s (collection: 1.002s, learning 0.127s)
               Value function loss: 0.2031
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8482
                     Learning rate: 0.0009
                       Mean reward: -4.92
               Mean episode length: 30.54
       Episode_Reward/keep_balance: 0.0310
     Episode_Reward/rew_lin_vel_xy: 0.0269
      Episode_Reward/rew_ang_vel_z: 0.0514
    Episode_Reward/pen_base_height: -0.1341
      Episode_Reward/pen_lin_vel_z: -0.0138
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0033
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0073
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0263
Episode_Reward/pen_flat_orientation: -0.0924
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0336
Metrics/base_velocity/error_vel_xy: 0.1571
Metrics/base_velocity/error_vel_yaw: 0.0717
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 134.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 1.13s
                        Total time: 45.74s
                               ETA: 3473.8s

################################################################################
                      [1m Learning iteration 39/3000 [0m                      

                       Computation: 89311 steps/s (collection: 0.982s, learning 0.119s)
               Value function loss: 0.1882
                    Surrogate loss: -0.0002
             Mean action noise std: 0.8440
                     Learning rate: 0.0013
                       Mean reward: -4.69
               Mean episode length: 29.97
       Episode_Reward/keep_balance: 0.0307
     Episode_Reward/rew_lin_vel_xy: 0.0270
      Episode_Reward/rew_ang_vel_z: 0.0522
    Episode_Reward/pen_base_height: -0.1317
      Episode_Reward/pen_lin_vel_z: -0.0136
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0032
    Episode_Reward/pen_joint_accel: -0.0042
    Episode_Reward/pen_action_rate: -0.0071
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0253
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0332
Metrics/base_velocity/error_vel_xy: 0.1552
Metrics/base_velocity/error_vel_yaw: 0.0694
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 132.9583
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 1.10s
                        Total time: 46.84s
                               ETA: 3467.3s

################################################################################
                      [1m Learning iteration 40/3000 [0m                      

                       Computation: 87795 steps/s (collection: 0.993s, learning 0.126s)
               Value function loss: 0.1765
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8359
                     Learning rate: 0.0009
                       Mean reward: -4.59
               Mean episode length: 31.32
       Episode_Reward/keep_balance: 0.0304
     Episode_Reward/rew_lin_vel_xy: 0.0263
      Episode_Reward/rew_ang_vel_z: 0.0532
    Episode_Reward/pen_base_height: -0.1292
      Episode_Reward/pen_lin_vel_z: -0.0135
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0031
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0069
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0247
Episode_Reward/pen_flat_orientation: -0.0883
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0328
Metrics/base_velocity/error_vel_xy: 0.1564
Metrics/base_velocity/error_vel_yaw: 0.0662
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 136.4583
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 1.12s
                        Total time: 47.96s
                               ETA: 3462.4s

################################################################################
                      [1m Learning iteration 41/3000 [0m                      

                       Computation: 88379 steps/s (collection: 0.988s, learning 0.124s)
               Value function loss: 0.1561
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8273
                     Learning rate: 0.0009
                       Mean reward: -4.18
               Mean episode length: 28.99
       Episode_Reward/keep_balance: 0.0300
     Episode_Reward/rew_lin_vel_xy: 0.0254
      Episode_Reward/rew_ang_vel_z: 0.0544
    Episode_Reward/pen_base_height: -0.1265
      Episode_Reward/pen_lin_vel_z: -0.0133
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0067
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0238
Episode_Reward/pen_flat_orientation: -0.0855
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0321
Metrics/base_velocity/error_vel_xy: 0.1548
Metrics/base_velocity/error_vel_yaw: 0.0621
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 138.8750
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 1.11s
                        Total time: 49.07s
                               ETA: 3457.2s

################################################################################
                      [1m Learning iteration 42/3000 [0m                      

                       Computation: 87013 steps/s (collection: 1.006s, learning 0.124s)
               Value function loss: 0.1705
                    Surrogate loss: -0.0016
             Mean action noise std: 0.8180
                     Learning rate: 0.0019
                       Mean reward: -4.29
               Mean episode length: 30.09
       Episode_Reward/keep_balance: 0.0297
     Episode_Reward/rew_lin_vel_xy: 0.0261
      Episode_Reward/rew_ang_vel_z: 0.0552
    Episode_Reward/pen_base_height: -0.1237
      Episode_Reward/pen_lin_vel_z: -0.0132
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0028
    Episode_Reward/pen_joint_accel: -0.0042
    Episode_Reward/pen_action_rate: -0.0065
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0231
Episode_Reward/pen_flat_orientation: -0.0819
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0318
Metrics/base_velocity/error_vel_xy: 0.1533
Metrics/base_velocity/error_vel_yaw: 0.0594
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 139.3750
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 1.13s
                        Total time: 50.20s
                               ETA: 3453.3s

################################################################################
                      [1m Learning iteration 43/3000 [0m                      

                       Computation: 87892 steps/s (collection: 0.994s, learning 0.125s)
               Value function loss: 0.1472
                    Surrogate loss: 0.0032
             Mean action noise std: 0.8157
                     Learning rate: 0.0003
                       Mean reward: -3.99
               Mean episode length: 29.28
       Episode_Reward/keep_balance: 0.0293
     Episode_Reward/rew_lin_vel_xy: 0.0249
      Episode_Reward/rew_ang_vel_z: 0.0565
    Episode_Reward/pen_base_height: -0.1215
      Episode_Reward/pen_lin_vel_z: -0.0131
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0027
    Episode_Reward/pen_joint_accel: -0.0042
    Episode_Reward/pen_action_rate: -0.0063
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0223
Episode_Reward/pen_flat_orientation: -0.0795
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0313
Metrics/base_velocity/error_vel_xy: 0.1524
Metrics/base_velocity/error_vel_yaw: 0.0552
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 139.4167
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 1.12s
                        Total time: 51.32s
                               ETA: 3448.9s

################################################################################
                      [1m Learning iteration 44/3000 [0m                      

                       Computation: 88972 steps/s (collection: 0.982s, learning 0.123s)
               Value function loss: 0.1353
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8053
                     Learning rate: 0.0006
                       Mean reward: -4.00
               Mean episode length: 29.01
       Episode_Reward/keep_balance: 0.0291
     Episode_Reward/rew_lin_vel_xy: 0.0248
      Episode_Reward/rew_ang_vel_z: 0.0581
    Episode_Reward/pen_base_height: -0.1201
      Episode_Reward/pen_lin_vel_z: -0.0131
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0026
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0062
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0215
Episode_Reward/pen_flat_orientation: -0.0775
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0311
Metrics/base_velocity/error_vel_xy: 0.1506
Metrics/base_velocity/error_vel_yaw: 0.0531
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 140.2917
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 1.10s
                        Total time: 52.42s
                               ETA: 3443.7s

################################################################################
                      [1m Learning iteration 45/3000 [0m                      

                       Computation: 87620 steps/s (collection: 0.995s, learning 0.127s)
               Value function loss: 0.1334
                    Surrogate loss: -0.0033
             Mean action noise std: 0.7938
                     Learning rate: 0.0013
                       Mean reward: -3.83
               Mean episode length: 29.06
       Episode_Reward/keep_balance: 0.0291
     Episode_Reward/rew_lin_vel_xy: 0.0248
      Episode_Reward/rew_ang_vel_z: 0.0592
    Episode_Reward/pen_base_height: -0.1190
      Episode_Reward/pen_lin_vel_z: -0.0131
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0026
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0061
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0213
Episode_Reward/pen_flat_orientation: -0.0760
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0308
Metrics/base_velocity/error_vel_xy: 0.1514
Metrics/base_velocity/error_vel_yaw: 0.0516
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 141.7500
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 1.12s
                        Total time: 53.55s
                               ETA: 3439.7s

################################################################################
                      [1m Learning iteration 46/3000 [0m                      

                       Computation: 87885 steps/s (collection: 0.993s, learning 0.126s)
               Value function loss: 0.1188
                    Surrogate loss: -0.0042
             Mean action noise std: 0.7790
                     Learning rate: 0.0019
                       Mean reward: -3.79
               Mean episode length: 29.61
       Episode_Reward/keep_balance: 0.0289
     Episode_Reward/rew_lin_vel_xy: 0.0241
      Episode_Reward/rew_ang_vel_z: 0.0600
    Episode_Reward/pen_base_height: -0.1171
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0024
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0059
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0204
Episode_Reward/pen_flat_orientation: -0.0745
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0304
Metrics/base_velocity/error_vel_xy: 0.1517
Metrics/base_velocity/error_vel_yaw: 0.0498
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 142.5000
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 1.12s
                        Total time: 54.66s
                               ETA: 3435.7s

################################################################################
                      [1m Learning iteration 47/3000 [0m                      

                       Computation: 90288 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.1131
                    Surrogate loss: -0.0053
             Mean action noise std: 0.7673
                     Learning rate: 0.0029
                       Mean reward: -3.72
               Mean episode length: 28.51
       Episode_Reward/keep_balance: 0.0288
     Episode_Reward/rew_lin_vel_xy: 0.0242
      Episode_Reward/rew_ang_vel_z: 0.0613
    Episode_Reward/pen_base_height: -0.1168
      Episode_Reward/pen_lin_vel_z: -0.0130
     Episode_Reward/pen_ang_vel_xy: -0.0221
   Episode_Reward/pen_joint_torque: -0.0024
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0057
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0197
Episode_Reward/pen_flat_orientation: -0.0732
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0304
Metrics/base_velocity/error_vel_xy: 0.1516
Metrics/base_velocity/error_vel_yaw: 0.0480
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 144.0833
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 1.09s
                        Total time: 55.75s
                               ETA: 3430.0s

################################################################################
                      [1m Learning iteration 48/3000 [0m                      

                       Computation: 88174 steps/s (collection: 0.989s, learning 0.126s)
               Value function loss: 0.1200
                    Surrogate loss: -0.0039
             Mean action noise std: 0.7548
                     Learning rate: 0.0044
                       Mean reward: -3.65
               Mean episode length: 28.90
       Episode_Reward/keep_balance: 0.0284
     Episode_Reward/rew_lin_vel_xy: 0.0238
      Episode_Reward/rew_ang_vel_z: 0.0622
    Episode_Reward/pen_base_height: -0.1141
      Episode_Reward/pen_lin_vel_z: -0.0130
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0023
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0054
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0188
Episode_Reward/pen_flat_orientation: -0.0708
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0298
Metrics/base_velocity/error_vel_xy: 0.1493
Metrics/base_velocity/error_vel_yaw: 0.0451
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 145.2083
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 1.11s
                        Total time: 56.87s
                               ETA: 3426.0s

################################################################################
                      [1m Learning iteration 49/3000 [0m                      

                       Computation: 87955 steps/s (collection: 0.993s, learning 0.124s)
               Value function loss: 0.1290
                    Surrogate loss: 0.0018
             Mean action noise std: 0.7495
                     Learning rate: 0.0003
                       Mean reward: -3.54
               Mean episode length: 28.38
       Episode_Reward/keep_balance: 0.0284
     Episode_Reward/rew_lin_vel_xy: 0.0239
      Episode_Reward/rew_ang_vel_z: 0.0633
    Episode_Reward/pen_base_height: -0.1132
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0023
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0053
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0182
Episode_Reward/pen_flat_orientation: -0.0693
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0298
Metrics/base_velocity/error_vel_xy: 0.1502
Metrics/base_velocity/error_vel_yaw: 0.0442
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 142.9167
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 1.12s
                        Total time: 57.99s
                               ETA: 3422.3s

################################################################################
                      [1m Learning iteration 50/3000 [0m                      

                       Computation: 85414 steps/s (collection: 1.027s, learning 0.124s)
               Value function loss: 0.1218
                    Surrogate loss: 0.0014
             Mean action noise std: 0.7457
                     Learning rate: 0.0002
                       Mean reward: -3.36
               Mean episode length: 27.99
       Episode_Reward/keep_balance: 0.0285
     Episode_Reward/rew_lin_vel_xy: 0.0235
      Episode_Reward/rew_ang_vel_z: 0.0648
    Episode_Reward/pen_base_height: -0.1128
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0022
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0052
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0177
Episode_Reward/pen_flat_orientation: -0.0684
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0299
Metrics/base_velocity/error_vel_xy: 0.1519
Metrics/base_velocity/error_vel_yaw: 0.0432
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 144.9583
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 1.15s
                        Total time: 59.14s
                               ETA: 3420.7s

################################################################################
                      [1m Learning iteration 51/3000 [0m                      

                       Computation: 90061 steps/s (collection: 0.971s, learning 0.121s)
               Value function loss: 0.1087
                    Surrogate loss: -0.0037
             Mean action noise std: 0.7372
                     Learning rate: 0.0006
                       Mean reward: -3.43
               Mean episode length: 28.51
       Episode_Reward/keep_balance: 0.0284
     Episode_Reward/rew_lin_vel_xy: 0.0232
      Episode_Reward/rew_ang_vel_z: 0.0656
    Episode_Reward/pen_base_height: -0.1119
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0022
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0051
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0175
Episode_Reward/pen_flat_orientation: -0.0676
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0299
Metrics/base_velocity/error_vel_xy: 0.1509
Metrics/base_velocity/error_vel_yaw: 0.0422
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 142.5833
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 1.09s
                        Total time: 60.23s
                               ETA: 3415.6s

################################################################################
                      [1m Learning iteration 52/3000 [0m                      

                       Computation: 90452 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.0974
                    Surrogate loss: -0.0030
             Mean action noise std: 0.7254
                     Learning rate: 0.0013
                       Mean reward: -3.18
               Mean episode length: 27.76
       Episode_Reward/keep_balance: 0.0285
     Episode_Reward/rew_lin_vel_xy: 0.0234
      Episode_Reward/rew_ang_vel_z: 0.0675
    Episode_Reward/pen_base_height: -0.1122
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0051
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0173
Episode_Reward/pen_flat_orientation: -0.0672
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0043
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0300
Metrics/base_velocity/error_vel_xy: 0.1503
Metrics/base_velocity/error_vel_yaw: 0.0408
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 142.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 1.09s
                        Total time: 61.32s
                               ETA: 3410.5s

################################################################################
                      [1m Learning iteration 53/3000 [0m                      

                       Computation: 90557 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 0.0955
                    Surrogate loss: 0.0007
             Mean action noise std: 0.7162
                     Learning rate: 0.0006
                       Mean reward: -3.16
               Mean episode length: 27.98
       Episode_Reward/keep_balance: 0.0285
     Episode_Reward/rew_lin_vel_xy: 0.0243
      Episode_Reward/rew_ang_vel_z: 0.0684
    Episode_Reward/pen_base_height: -0.1114
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0050
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0170
Episode_Reward/pen_flat_orientation: -0.0660
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0299
Metrics/base_velocity/error_vel_xy: 0.1504
Metrics/base_velocity/error_vel_yaw: 0.0399
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 145.9167
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 1.09s
                        Total time: 62.40s
                               ETA: 3405.5s

################################################################################
                      [1m Learning iteration 54/3000 [0m                      

                       Computation: 89539 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.0907
                    Surrogate loss: -0.0035
             Mean action noise std: 0.7031
                     Learning rate: 0.0009
                       Mean reward: -3.31
               Mean episode length: 28.28
       Episode_Reward/keep_balance: 0.0284
     Episode_Reward/rew_lin_vel_xy: 0.0246
      Episode_Reward/rew_ang_vel_z: 0.0692
    Episode_Reward/pen_base_height: -0.1106
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0048
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0164
Episode_Reward/pen_flat_orientation: -0.0648
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0298
Metrics/base_velocity/error_vel_xy: 0.1492
Metrics/base_velocity/error_vel_yaw: 0.0390
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 143.3333
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 1.10s
                        Total time: 63.50s
                               ETA: 3401.2s

################################################################################
                      [1m Learning iteration 55/3000 [0m                      

                       Computation: 90138 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.1064
                    Surrogate loss: -0.0006
             Mean action noise std: 0.6944
                     Learning rate: 0.0013
                       Mean reward: -3.06
               Mean episode length: 27.55
       Episode_Reward/keep_balance: 0.0285
     Episode_Reward/rew_lin_vel_xy: 0.0241
      Episode_Reward/rew_ang_vel_z: 0.0701
    Episode_Reward/pen_base_height: -0.1105
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0047
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0159
Episode_Reward/pen_flat_orientation: -0.0638
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0296
Metrics/base_velocity/error_vel_xy: 0.1503
Metrics/base_velocity/error_vel_yaw: 0.0385
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 144.0417
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 1.09s
                        Total time: 64.59s
                               ETA: 3396.7s

################################################################################
                      [1m Learning iteration 56/3000 [0m                      

                       Computation: 89108 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.0966
                    Surrogate loss: 0.0008
             Mean action noise std: 0.6848
                     Learning rate: 0.0013
                       Mean reward: -3.05
               Mean episode length: 28.48
       Episode_Reward/keep_balance: 0.0286
     Episode_Reward/rew_lin_vel_xy: 0.0252
      Episode_Reward/rew_ang_vel_z: 0.0718
    Episode_Reward/pen_base_height: -0.1109
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0046
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0155
Episode_Reward/pen_flat_orientation: -0.0637
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0298
Metrics/base_velocity/error_vel_xy: 0.1493
Metrics/base_velocity/error_vel_yaw: 0.0376
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 143.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 1.10s
                        Total time: 65.69s
                               ETA: 3392.9s

################################################################################
                      [1m Learning iteration 57/3000 [0m                      

                       Computation: 90153 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.0865
                    Surrogate loss: 0.0002
             Mean action noise std: 0.6777
                     Learning rate: 0.0004
                       Mean reward: -2.94
               Mean episode length: 28.69
       Episode_Reward/keep_balance: 0.0286
     Episode_Reward/rew_lin_vel_xy: 0.0252
      Episode_Reward/rew_ang_vel_z: 0.0728
    Episode_Reward/pen_base_height: -0.1107
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0045
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0152
Episode_Reward/pen_flat_orientation: -0.0631
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0299
Metrics/base_velocity/error_vel_xy: 0.1504
Metrics/base_velocity/error_vel_yaw: 0.0367
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 143.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 1.09s
                        Total time: 66.78s
                               ETA: 3388.6s

################################################################################
                      [1m Learning iteration 58/3000 [0m                      

                       Computation: 91766 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.0807
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6667
                     Learning rate: 0.0009
                       Mean reward: -3.02
               Mean episode length: 29.15
       Episode_Reward/keep_balance: 0.0287
     Episode_Reward/rew_lin_vel_xy: 0.0247
      Episode_Reward/rew_ang_vel_z: 0.0736
    Episode_Reward/pen_base_height: -0.1100
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0044
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0149
Episode_Reward/pen_flat_orientation: -0.0627
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0299
Metrics/base_velocity/error_vel_xy: 0.1508
Metrics/base_velocity/error_vel_yaw: 0.0365
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 139.7917
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 1.07s
                        Total time: 67.85s
                               ETA: 3383.5s

################################################################################
                      [1m Learning iteration 59/3000 [0m                      

                       Computation: 91529 steps/s (collection: 0.950s, learning 0.124s)
               Value function loss: 0.0834
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6574
                     Learning rate: 0.0019
                       Mean reward: -2.87
               Mean episode length: 28.92
       Episode_Reward/keep_balance: 0.0289
     Episode_Reward/rew_lin_vel_xy: 0.0252
      Episode_Reward/rew_ang_vel_z: 0.0751
    Episode_Reward/pen_base_height: -0.1096
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0043
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0145
Episode_Reward/pen_flat_orientation: -0.0618
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0299
Metrics/base_velocity/error_vel_xy: 0.1513
Metrics/base_velocity/error_vel_yaw: 0.0355
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 143.2083
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 1.07s
                        Total time: 68.93s
                               ETA: 3378.6s

################################################################################
                      [1m Learning iteration 60/3000 [0m                      

                       Computation: 91023 steps/s (collection: 0.960s, learning 0.120s)
               Value function loss: 0.0792
                    Surrogate loss: 0.0006
             Mean action noise std: 0.6487
                     Learning rate: 0.0009
                       Mean reward: -2.83
               Mean episode length: 29.34
       Episode_Reward/keep_balance: 0.0288
     Episode_Reward/rew_lin_vel_xy: 0.0250
      Episode_Reward/rew_ang_vel_z: 0.0751
    Episode_Reward/pen_base_height: -0.1088
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0042
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0141
Episode_Reward/pen_flat_orientation: -0.0619
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0037
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0297
Metrics/base_velocity/error_vel_xy: 0.1526
Metrics/base_velocity/error_vel_yaw: 0.0352
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 143.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 1.08s
                        Total time: 70.01s
                               ETA: 3374.2s

################################################################################
                      [1m Learning iteration 61/3000 [0m                      

                       Computation: 91716 steps/s (collection: 0.951s, learning 0.121s)
               Value function loss: 0.0804
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6365
                     Learning rate: 0.0009
                       Mean reward: -2.77
               Mean episode length: 29.58
       Episode_Reward/keep_balance: 0.0287
     Episode_Reward/rew_lin_vel_xy: 0.0243
      Episode_Reward/rew_ang_vel_z: 0.0753
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0041
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0138
Episode_Reward/pen_flat_orientation: -0.0611
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0036
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0297
Metrics/base_velocity/error_vel_xy: 0.1527
Metrics/base_velocity/error_vel_yaw: 0.0347
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 140.8750
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 1.07s
                        Total time: 71.08s
                               ETA: 3369.4s

################################################################################
                      [1m Learning iteration 62/3000 [0m                      

                       Computation: 91388 steps/s (collection: 0.954s, learning 0.121s)
               Value function loss: 0.0773
                    Surrogate loss: 0.0024
             Mean action noise std: 0.6326
                     Learning rate: 0.0004
                       Mean reward: -2.68
               Mean episode length: 29.98
       Episode_Reward/keep_balance: 0.0290
     Episode_Reward/rew_lin_vel_xy: 0.0243
      Episode_Reward/rew_ang_vel_z: 0.0769
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0134
Episode_Reward/pen_flat_orientation: -0.0607
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0035
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0299
Metrics/base_velocity/error_vel_xy: 0.1543
Metrics/base_velocity/error_vel_yaw: 0.0341
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 142.3333
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 1.08s
                        Total time: 72.16s
                               ETA: 3365.0s

################################################################################
                      [1m Learning iteration 63/3000 [0m                      

                       Computation: 90910 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.0723
                    Surrogate loss: -0.0040
             Mean action noise std: 0.6231
                     Learning rate: 0.0006
                       Mean reward: -2.69
               Mean episode length: 28.21
       Episode_Reward/keep_balance: 0.0289
     Episode_Reward/rew_lin_vel_xy: 0.0248
      Episode_Reward/rew_ang_vel_z: 0.0775
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0131
Episode_Reward/pen_flat_orientation: -0.0604
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0035
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0300
Metrics/base_velocity/error_vel_xy: 0.1522
Metrics/base_velocity/error_vel_yaw: 0.0333
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 139.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 1.08s
                        Total time: 73.24s
                               ETA: 3360.9s

################################################################################
                      [1m Learning iteration 64/3000 [0m                      

                       Computation: 90600 steps/s (collection: 0.960s, learning 0.125s)
               Value function loss: 0.0741
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6136
                     Learning rate: 0.0009
                       Mean reward: -2.70
               Mean episode length: 29.85
       Episode_Reward/keep_balance: 0.0291
     Episode_Reward/rew_lin_vel_xy: 0.0250
      Episode_Reward/rew_ang_vel_z: 0.0782
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0129
Episode_Reward/pen_flat_orientation: -0.0605
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0034
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0302
Metrics/base_velocity/error_vel_xy: 0.1534
Metrics/base_velocity/error_vel_yaw: 0.0337
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 141.7500
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 1.09s
                        Total time: 74.32s
                               ETA: 3357.1s

################################################################################
                      [1m Learning iteration 65/3000 [0m                      

                       Computation: 92130 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 0.0866
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6048
                     Learning rate: 0.0019
                       Mean reward: -2.63
               Mean episode length: 30.08
       Episode_Reward/keep_balance: 0.0292
     Episode_Reward/rew_lin_vel_xy: 0.0244
      Episode_Reward/rew_ang_vel_z: 0.0795
    Episode_Reward/pen_base_height: -0.1087
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0127
Episode_Reward/pen_flat_orientation: -0.0599
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0033
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0304
Metrics/base_velocity/error_vel_xy: 0.1544
Metrics/base_velocity/error_vel_yaw: 0.0331
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 139.8333
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 1.07s
                        Total time: 75.39s
                               ETA: 3352.5s

################################################################################
                      [1m Learning iteration 66/3000 [0m                      

                       Computation: 92016 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.0782
                    Surrogate loss: 0.0008
             Mean action noise std: 0.5990
                     Learning rate: 0.0009
                       Mean reward: -2.57
               Mean episode length: 29.57
       Episode_Reward/keep_balance: 0.0293
     Episode_Reward/rew_lin_vel_xy: 0.0245
      Episode_Reward/rew_ang_vel_z: 0.0805
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0124
Episode_Reward/pen_flat_orientation: -0.0591
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0033
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0304
Metrics/base_velocity/error_vel_xy: 0.1563
Metrics/base_velocity/error_vel_yaw: 0.0324
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 138.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 1.07s
                        Total time: 76.46s
                               ETA: 3348.1s

################################################################################
                      [1m Learning iteration 67/3000 [0m                      

                       Computation: 91887 steps/s (collection: 0.948s, learning 0.121s)
               Value function loss: 0.0819
                    Surrogate loss: -0.0016
             Mean action noise std: 0.5938
                     Learning rate: 0.0006
                       Mean reward: -2.55
               Mean episode length: 29.48
       Episode_Reward/keep_balance: 0.0296
     Episode_Reward/rew_lin_vel_xy: 0.0255
      Episode_Reward/rew_ang_vel_z: 0.0819
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0122
Episode_Reward/pen_flat_orientation: -0.0589
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0032
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0307
Metrics/base_velocity/error_vel_xy: 0.1557
Metrics/base_velocity/error_vel_yaw: 0.0323
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 137.1667
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 1.07s
                        Total time: 77.53s
                               ETA: 3343.9s

################################################################################
                      [1m Learning iteration 68/3000 [0m                      

                       Computation: 91210 steps/s (collection: 0.956s, learning 0.121s)
               Value function loss: 0.0824
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5850
                     Learning rate: 0.0013
                       Mean reward: -2.52
               Mean episode length: 29.94
       Episode_Reward/keep_balance: 0.0301
     Episode_Reward/rew_lin_vel_xy: 0.0258
      Episode_Reward/rew_ang_vel_z: 0.0836
    Episode_Reward/pen_base_height: -0.1089
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0123
Episode_Reward/pen_flat_orientation: -0.0590
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0032
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0311
Metrics/base_velocity/error_vel_xy: 0.1587
Metrics/base_velocity/error_vel_yaw: 0.0328
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 136.5833
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 1.08s
                        Total time: 78.60s
                               ETA: 3340.1s

################################################################################
                      [1m Learning iteration 69/3000 [0m                      

                       Computation: 92055 steps/s (collection: 0.947s, learning 0.121s)
               Value function loss: 0.0735
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5791
                     Learning rate: 0.0006
                       Mean reward: -2.44
               Mean episode length: 29.43
       Episode_Reward/keep_balance: 0.0300
     Episode_Reward/rew_lin_vel_xy: 0.0251
      Episode_Reward/rew_ang_vel_z: 0.0836
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0196
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0119
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0031
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0308
Metrics/base_velocity/error_vel_xy: 0.1590
Metrics/base_velocity/error_vel_yaw: 0.0324
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 136.2917
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 1.07s
                        Total time: 79.67s
                               ETA: 3336.0s

################################################################################
                      [1m Learning iteration 70/3000 [0m                      

                       Computation: 91721 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.0684
                    Surrogate loss: -0.0028
             Mean action noise std: 0.5722
                     Learning rate: 0.0006
                       Mean reward: -2.41
               Mean episode length: 30.02
       Episode_Reward/keep_balance: 0.0301
     Episode_Reward/rew_lin_vel_xy: 0.0259
      Episode_Reward/rew_ang_vel_z: 0.0846
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0117
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0031
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0310
Metrics/base_velocity/error_vel_xy: 0.1598
Metrics/base_velocity/error_vel_yaw: 0.0317
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 136.2083
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 1.07s
                        Total time: 80.74s
                               ETA: 3332.1s

################################################################################
                      [1m Learning iteration 71/3000 [0m                      

                       Computation: 91512 steps/s (collection: 0.953s, learning 0.121s)
               Value function loss: 0.0829
                    Surrogate loss: 0.0001
             Mean action noise std: 0.5666
                     Learning rate: 0.0009
                       Mean reward: -2.42
               Mean episode length: 30.33
       Episode_Reward/keep_balance: 0.0300
     Episode_Reward/rew_lin_vel_xy: 0.0246
      Episode_Reward/rew_ang_vel_z: 0.0851
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0113
Episode_Reward/pen_flat_orientation: -0.0575
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0031
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0310
Metrics/base_velocity/error_vel_xy: 0.1611
Metrics/base_velocity/error_vel_yaw: 0.0312
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 135.9583
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 1.07s
                        Total time: 81.82s
                               ETA: 3328.4s

################################################################################
                      [1m Learning iteration 72/3000 [0m                      

                       Computation: 91746 steps/s (collection: 0.952s, learning 0.120s)
               Value function loss: 0.0868
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5605
                     Learning rate: 0.0013
                       Mean reward: -2.26
               Mean episode length: 29.86
       Episode_Reward/keep_balance: 0.0302
     Episode_Reward/rew_lin_vel_xy: 0.0256
      Episode_Reward/rew_ang_vel_z: 0.0861
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0113
Episode_Reward/pen_flat_orientation: -0.0573
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0030
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0310
Metrics/base_velocity/error_vel_xy: 0.1596
Metrics/base_velocity/error_vel_yaw: 0.0314
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 134.6250
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 1.07s
                        Total time: 82.89s
                               ETA: 3324.7s

################################################################################
                      [1m Learning iteration 73/3000 [0m                      

                       Computation: 91572 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.0983
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5567
                     Learning rate: 0.0009
                       Mean reward: -2.41
               Mean episode length: 30.26
       Episode_Reward/keep_balance: 0.0306
     Episode_Reward/rew_lin_vel_xy: 0.0263
      Episode_Reward/rew_ang_vel_z: 0.0874
    Episode_Reward/pen_base_height: -0.1084
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0193
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0112
Episode_Reward/pen_flat_orientation: -0.0577
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0030
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0314
Metrics/base_velocity/error_vel_xy: 0.1611
Metrics/base_velocity/error_vel_yaw: 0.0317
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 131.9583
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 1.07s
                        Total time: 83.96s
                               ETA: 3321.1s

################################################################################
                      [1m Learning iteration 74/3000 [0m                      

                       Computation: 92258 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.0952
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5517
                     Learning rate: 0.0013
                       Mean reward: -2.37
               Mean episode length: 30.52
       Episode_Reward/keep_balance: 0.0307
     Episode_Reward/rew_lin_vel_xy: 0.0262
      Episode_Reward/rew_ang_vel_z: 0.0881
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0110
Episode_Reward/pen_flat_orientation: -0.0576
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0030
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0315
Metrics/base_velocity/error_vel_xy: 0.1610
Metrics/base_velocity/error_vel_yaw: 0.0312
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 136.1250
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 1.07s
                        Total time: 85.03s
                               ETA: 3317.3s

################################################################################
                      [1m Learning iteration 75/3000 [0m                      

                       Computation: 90037 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 0.0887
                    Surrogate loss: 0.0020
             Mean action noise std: 0.5480
                     Learning rate: 0.0006
                       Mean reward: -2.25
               Mean episode length: 31.47
       Episode_Reward/keep_balance: 0.0306
     Episode_Reward/rew_lin_vel_xy: 0.0268
      Episode_Reward/rew_ang_vel_z: 0.0884
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0108
Episode_Reward/pen_flat_orientation: -0.0569
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0029
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0315
Metrics/base_velocity/error_vel_xy: 0.1614
Metrics/base_velocity/error_vel_yaw: 0.0302
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 133.3333
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 1.09s
                        Total time: 86.12s
                               ETA: 3314.5s

################################################################################
                      [1m Learning iteration 76/3000 [0m                      

                       Computation: 91243 steps/s (collection: 0.956s, learning 0.121s)
               Value function loss: 0.0900
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5428
                     Learning rate: 0.0009
                       Mean reward: -2.23
               Mean episode length: 30.90
       Episode_Reward/keep_balance: 0.0306
     Episode_Reward/rew_lin_vel_xy: 0.0263
      Episode_Reward/rew_ang_vel_z: 0.0892
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0032
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0107
Episode_Reward/pen_flat_orientation: -0.0564
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0029
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0314
Metrics/base_velocity/error_vel_xy: 0.1612
Metrics/base_velocity/error_vel_yaw: 0.0298
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 133.4167
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 1.08s
                        Total time: 87.20s
                               ETA: 3311.3s

################################################################################
                      [1m Learning iteration 77/3000 [0m                      

                       Computation: 91094 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.0868
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5397
                     Learning rate: 0.0006
                       Mean reward: -2.25
               Mean episode length: 31.06
       Episode_Reward/keep_balance: 0.0307
     Episode_Reward/rew_lin_vel_xy: 0.0264
      Episode_Reward/rew_ang_vel_z: 0.0894
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0032
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0106
Episode_Reward/pen_flat_orientation: -0.0563
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0029
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0315
Metrics/base_velocity/error_vel_xy: 0.1627
Metrics/base_velocity/error_vel_yaw: 0.0301
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 131.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 1.08s
                        Total time: 88.28s
                               ETA: 3308.1s

################################################################################
                      [1m Learning iteration 78/3000 [0m                      

                       Computation: 91617 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.1002
                    Surrogate loss: -0.0016
             Mean action noise std: 0.5342
                     Learning rate: 0.0013
                       Mean reward: -2.21
               Mean episode length: 30.45
       Episode_Reward/keep_balance: 0.0310
     Episode_Reward/rew_lin_vel_xy: 0.0261
      Episode_Reward/rew_ang_vel_z: 0.0908
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0192
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0032
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0105
Episode_Reward/pen_flat_orientation: -0.0560
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0029
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0319
Metrics/base_velocity/error_vel_xy: 0.1640
Metrics/base_velocity/error_vel_yaw: 0.0302
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 130.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 1.07s
                        Total time: 89.35s
                               ETA: 3304.8s

################################################################################
                      [1m Learning iteration 79/3000 [0m                      

                       Computation: 90914 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.1004
                    Surrogate loss: 0.0019
             Mean action noise std: 0.5302
                     Learning rate: 0.0013
                       Mean reward: -2.22
               Mean episode length: 31.07
       Episode_Reward/keep_balance: 0.0314
     Episode_Reward/rew_lin_vel_xy: 0.0263
      Episode_Reward/rew_ang_vel_z: 0.0921
    Episode_Reward/pen_base_height: -0.1076
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0192
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0032
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0106
Episode_Reward/pen_flat_orientation: -0.0562
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0029
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0322
Metrics/base_velocity/error_vel_xy: 0.1662
Metrics/base_velocity/error_vel_yaw: 0.0303
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 129.7083
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 1.08s
                        Total time: 90.43s
                               ETA: 3301.9s

################################################################################
                      [1m Learning iteration 80/3000 [0m                      

                       Computation: 90169 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.0816
                    Surrogate loss: 0.0001
             Mean action noise std: 0.5249
                     Learning rate: 0.0013
                       Mean reward: -2.14
               Mean episode length: 31.23
       Episode_Reward/keep_balance: 0.0316
     Episode_Reward/rew_lin_vel_xy: 0.0279
      Episode_Reward/rew_ang_vel_z: 0.0931
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0192
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0032
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0105
Episode_Reward/pen_flat_orientation: -0.0558
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0028
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0325
Metrics/base_velocity/error_vel_xy: 0.1665
Metrics/base_velocity/error_vel_yaw: 0.0305
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 130.5000
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 1.09s
                        Total time: 91.52s
                               ETA: 3299.3s

################################################################################
                      [1m Learning iteration 81/3000 [0m                      

                       Computation: 90270 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.0893
                    Surrogate loss: -0.0002
             Mean action noise std: 0.5214
                     Learning rate: 0.0009
                       Mean reward: -2.16
               Mean episode length: 31.16
       Episode_Reward/keep_balance: 0.0315
     Episode_Reward/rew_lin_vel_xy: 0.0270
      Episode_Reward/rew_ang_vel_z: 0.0929
    Episode_Reward/pen_base_height: -0.1067
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0014
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0103
Episode_Reward/pen_flat_orientation: -0.0554
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0028
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0323
Metrics/base_velocity/error_vel_xy: 0.1653
Metrics/base_velocity/error_vel_yaw: 0.0300
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 129.7500
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 1.09s
                        Total time: 92.61s
                               ETA: 3296.7s

################################################################################
                      [1m Learning iteration 82/3000 [0m                      

                       Computation: 89541 steps/s (collection: 0.976s, learning 0.122s)
               Value function loss: 0.0858
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5170
                     Learning rate: 0.0009
                       Mean reward: -2.09
               Mean episode length: 31.66
       Episode_Reward/keep_balance: 0.0315
     Episode_Reward/rew_lin_vel_xy: 0.0275
      Episode_Reward/rew_ang_vel_z: 0.0937
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0193
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0014
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0101
Episode_Reward/pen_flat_orientation: -0.0552
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0028
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0323
Metrics/base_velocity/error_vel_xy: 0.1651
Metrics/base_velocity/error_vel_yaw: 0.0297
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 130.6667
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 1.10s
                        Total time: 93.71s
                               ETA: 3294.5s

################################################################################
                      [1m Learning iteration 83/3000 [0m                      

                       Computation: 90444 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.0846
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5121
                     Learning rate: 0.0009
                       Mean reward: -2.16
               Mean episode length: 32.50
       Episode_Reward/keep_balance: 0.0317
     Episode_Reward/rew_lin_vel_xy: 0.0287
      Episode_Reward/rew_ang_vel_z: 0.0937
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0101
Episode_Reward/pen_flat_orientation: -0.0555
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0028
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0326
Metrics/base_velocity/error_vel_xy: 0.1648
Metrics/base_velocity/error_vel_yaw: 0.0301
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 128.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 1.09s
                        Total time: 94.80s
                               ETA: 3291.9s

################################################################################
                      [1m Learning iteration 84/3000 [0m                      

                       Computation: 90885 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.0940
                    Surrogate loss: 0.0011
             Mean action noise std: 0.5089
                     Learning rate: 0.0006
                       Mean reward: -1.98
               Mean episode length: 32.55
       Episode_Reward/keep_balance: 0.0320
     Episode_Reward/rew_lin_vel_xy: 0.0277
      Episode_Reward/rew_ang_vel_z: 0.0955
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0192
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0014
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0100
Episode_Reward/pen_flat_orientation: -0.0552
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0028
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0329
Metrics/base_velocity/error_vel_xy: 0.1688
Metrics/base_velocity/error_vel_yaw: 0.0299
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 125.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 1.08s
                        Total time: 95.88s
                               ETA: 3289.2s

################################################################################
                      [1m Learning iteration 85/3000 [0m                      

                       Computation: 90674 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.0844
                    Surrogate loss: 0.0010
             Mean action noise std: 0.5054
                     Learning rate: 0.0006
                       Mean reward: -1.88
               Mean episode length: 33.38
       Episode_Reward/keep_balance: 0.0324
     Episode_Reward/rew_lin_vel_xy: 0.0287
      Episode_Reward/rew_ang_vel_z: 0.0962
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0192
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0014
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0100
Episode_Reward/pen_flat_orientation: -0.0550
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0028
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0333
Metrics/base_velocity/error_vel_xy: 0.1685
Metrics/base_velocity/error_vel_yaw: 0.0306
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 124.6250
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 1.08s
                        Total time: 96.96s
                               ETA: 3286.5s

################################################################################
                      [1m Learning iteration 86/3000 [0m                      

                       Computation: 89689 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.0886
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5022
                     Learning rate: 0.0009
                       Mean reward: -1.93
               Mean episode length: 33.00
       Episode_Reward/keep_balance: 0.0328
     Episode_Reward/rew_lin_vel_xy: 0.0290
      Episode_Reward/rew_ang_vel_z: 0.0985
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0110
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0014
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0100
Episode_Reward/pen_flat_orientation: -0.0550
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0029
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0338
Metrics/base_velocity/error_vel_xy: 0.1709
Metrics/base_velocity/error_vel_yaw: 0.0303
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 126.7917
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 1.10s
                        Total time: 98.06s
                               ETA: 3284.4s

################################################################################
                      [1m Learning iteration 87/3000 [0m                      

                       Computation: 91226 steps/s (collection: 0.957s, learning 0.121s)
               Value function loss: 0.0873
                    Surrogate loss: 0.0010
             Mean action noise std: 0.5007
                     Learning rate: 0.0004
                       Mean reward: -1.99
               Mean episode length: 33.99
       Episode_Reward/keep_balance: 0.0325
     Episode_Reward/rew_lin_vel_xy: 0.0277
      Episode_Reward/rew_ang_vel_z: 0.0976
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0110
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0014
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0098
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0028
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0333
Metrics/base_velocity/error_vel_xy: 0.1702
Metrics/base_velocity/error_vel_yaw: 0.0297
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 125.5417
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 1.08s
                        Total time: 99.14s
                               ETA: 3281.6s

################################################################################
                      [1m Learning iteration 88/3000 [0m                      

                       Computation: 91761 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.0882
                    Surrogate loss: -0.0024
             Mean action noise std: 0.4961
                     Learning rate: 0.0009
                       Mean reward: -1.87
               Mean episode length: 32.34
       Episode_Reward/keep_balance: 0.0327
     Episode_Reward/rew_lin_vel_xy: 0.0283
      Episode_Reward/rew_ang_vel_z: 0.0978
    Episode_Reward/pen_base_height: -0.1062
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0014
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0098
Episode_Reward/pen_flat_orientation: -0.0546
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0028
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0334
Metrics/base_velocity/error_vel_xy: 0.1715
Metrics/base_velocity/error_vel_yaw: 0.0302
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 124.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 1.07s
                        Total time: 100.21s
                               ETA: 3278.7s

################################################################################
                      [1m Learning iteration 89/3000 [0m                      

                       Computation: 91399 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.1028
                    Surrogate loss: 0.0009
             Mean action noise std: 0.4934
                     Learning rate: 0.0006
                       Mean reward: -1.72
               Mean episode length: 33.61
       Episode_Reward/keep_balance: 0.0326
     Episode_Reward/rew_lin_vel_xy: 0.0289
      Episode_Reward/rew_ang_vel_z: 0.0983
    Episode_Reward/pen_base_height: -0.1058
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0014
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0097
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0028
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0333
Metrics/base_velocity/error_vel_xy: 0.1712
Metrics/base_velocity/error_vel_yaw: 0.0296
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 124.8333
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 1.08s
                        Total time: 101.28s
                               ETA: 3275.9s

################################################################################
                      [1m Learning iteration 90/3000 [0m                      

                       Computation: 90842 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.0895
                    Surrogate loss: -0.0012
             Mean action noise std: 0.4906
                     Learning rate: 0.0009
                       Mean reward: -1.99
               Mean episode length: 32.88
       Episode_Reward/keep_balance: 0.0329
     Episode_Reward/rew_lin_vel_xy: 0.0287
      Episode_Reward/rew_ang_vel_z: 0.0996
    Episode_Reward/pen_base_height: -0.1067
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0014
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0097
Episode_Reward/pen_flat_orientation: -0.0541
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0029
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0338
Metrics/base_velocity/error_vel_xy: 0.1726
Metrics/base_velocity/error_vel_yaw: 0.0297
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 124.5000
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 1.08s
                        Total time: 102.36s
                               ETA: 3273.4s

################################################################################
                      [1m Learning iteration 91/3000 [0m                      

                       Computation: 91519 steps/s (collection: 0.954s, learning 0.121s)
               Value function loss: 0.0871
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4885
                     Learning rate: 0.0009
                       Mean reward: -1.81
               Mean episode length: 32.64
       Episode_Reward/keep_balance: 0.0333
     Episode_Reward/rew_lin_vel_xy: 0.0297
      Episode_Reward/rew_ang_vel_z: 0.1010
    Episode_Reward/pen_base_height: -0.1063
      Episode_Reward/pen_lin_vel_z: -0.0110
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0014
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0097
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0029
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0341
Metrics/base_velocity/error_vel_xy: 0.1727
Metrics/base_velocity/error_vel_yaw: 0.0297
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 122.0833
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 1.07s
                        Total time: 103.44s
                               ETA: 3270.7s

################################################################################
                      [1m Learning iteration 92/3000 [0m                      

                       Computation: 91170 steps/s (collection: 0.957s, learning 0.121s)
               Value function loss: 0.0881
                    Surrogate loss: -0.0009
             Mean action noise std: 0.4853
                     Learning rate: 0.0009
                       Mean reward: -1.93
               Mean episode length: 33.86
       Episode_Reward/keep_balance: 0.0334
     Episode_Reward/rew_lin_vel_xy: 0.0301
      Episode_Reward/rew_ang_vel_z: 0.1020
    Episode_Reward/pen_base_height: -0.1062
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0196
   Episode_Reward/pen_joint_torque: -0.0022
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0014
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0096
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0028
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0342
Metrics/base_velocity/error_vel_xy: 0.1735
Metrics/base_velocity/error_vel_yaw: 0.0290
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 122.2917
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 1.08s
                        Total time: 104.52s
                               ETA: 3268.1s

################################################################################
                      [1m Learning iteration 93/3000 [0m                      

                       Computation: 90937 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.0918
                    Surrogate loss: -0.0021
             Mean action noise std: 0.4813
                     Learning rate: 0.0013
                       Mean reward: -1.68
               Mean episode length: 33.65
       Episode_Reward/keep_balance: 0.0336
     Episode_Reward/rew_lin_vel_xy: 0.0297
      Episode_Reward/rew_ang_vel_z: 0.1023
    Episode_Reward/pen_base_height: -0.1063
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0022
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0014
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0096
Episode_Reward/pen_flat_orientation: -0.0539
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0028
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0344
Metrics/base_velocity/error_vel_xy: 0.1758
Metrics/base_velocity/error_vel_yaw: 0.0298
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 120.2083
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 1.08s
                        Total time: 105.60s
                               ETA: 3265.7s

################################################################################
                      [1m Learning iteration 94/3000 [0m                      

                       Computation: 91165 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.0930
                    Surrogate loss: 0.0027
             Mean action noise std: 0.4798
                     Learning rate: 0.0004
                       Mean reward: -1.63
               Mean episode length: 34.77
       Episode_Reward/keep_balance: 0.0341
     Episode_Reward/rew_lin_vel_xy: 0.0299
      Episode_Reward/rew_ang_vel_z: 0.1043
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0110
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0022
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0096
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0029
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0350
Metrics/base_velocity/error_vel_xy: 0.1788
Metrics/base_velocity/error_vel_yaw: 0.0301
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 119.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 1.08s
                        Total time: 106.68s
                               ETA: 3263.2s

################################################################################
                      [1m Learning iteration 95/3000 [0m                      

                       Computation: 91510 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 0.0935
                    Surrogate loss: -0.0009
             Mean action noise std: 0.4771
                     Learning rate: 0.0006
                       Mean reward: -1.62
               Mean episode length: 35.22
       Episode_Reward/keep_balance: 0.0341
     Episode_Reward/rew_lin_vel_xy: 0.0310
      Episode_Reward/rew_ang_vel_z: 0.1045
    Episode_Reward/pen_base_height: -0.1062
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0023
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0014
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0095
Episode_Reward/pen_flat_orientation: -0.0529
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0029
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0350
Metrics/base_velocity/error_vel_xy: 0.1774
Metrics/base_velocity/error_vel_yaw: 0.0297
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 120.1250
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 1.07s
                        Total time: 107.75s
                               ETA: 3260.6s

################################################################################
                      [1m Learning iteration 96/3000 [0m                      

                       Computation: 90221 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.0954
                    Surrogate loss: -0.0000
             Mean action noise std: 0.4746
                     Learning rate: 0.0006
                       Mean reward: -1.74
               Mean episode length: 34.86
       Episode_Reward/keep_balance: 0.0343
     Episode_Reward/rew_lin_vel_xy: 0.0299
      Episode_Reward/rew_ang_vel_z: 0.1051
    Episode_Reward/pen_base_height: -0.1065
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0023
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0014
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0095
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0029
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0350
Metrics/base_velocity/error_vel_xy: 0.1809
Metrics/base_velocity/error_vel_yaw: 0.0301
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 119.7500
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 1.09s
                        Total time: 108.84s
                               ETA: 3258.5s

################################################################################
                      [1m Learning iteration 97/3000 [0m                      

                       Computation: 90703 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.1060
                    Surrogate loss: -0.0002
             Mean action noise std: 0.4729
                     Learning rate: 0.0004
                       Mean reward: -1.75
               Mean episode length: 33.80
       Episode_Reward/keep_balance: 0.0345
     Episode_Reward/rew_lin_vel_xy: 0.0305
      Episode_Reward/rew_ang_vel_z: 0.1060
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0110
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0023
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0094
Episode_Reward/pen_flat_orientation: -0.0532
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0030
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0355
Metrics/base_velocity/error_vel_xy: 0.1825
Metrics/base_velocity/error_vel_yaw: 0.0303
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.0833
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 1.08s
                        Total time: 109.92s
                               ETA: 3256.2s

################################################################################
                      [1m Learning iteration 98/3000 [0m                      

                       Computation: 91212 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.1096
                    Surrogate loss: -0.0010
             Mean action noise std: 0.4704
                     Learning rate: 0.0009
                       Mean reward: -1.39
               Mean episode length: 36.95
       Episode_Reward/keep_balance: 0.0351
     Episode_Reward/rew_lin_vel_xy: 0.0319
      Episode_Reward/rew_ang_vel_z: 0.1077
    Episode_Reward/pen_base_height: -0.1069
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0024
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0096
Episode_Reward/pen_flat_orientation: -0.0541
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0030
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0362
Metrics/base_velocity/error_vel_xy: 0.1828
Metrics/base_velocity/error_vel_yaw: 0.0311
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 119.6667
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 1.08s
                        Total time: 111.00s
                               ETA: 3253.8s

################################################################################
                      [1m Learning iteration 99/3000 [0m                      

                       Computation: 92802 steps/s (collection: 0.936s, learning 0.123s)
               Value function loss: 0.1074
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4681
                     Learning rate: 0.0013
                       Mean reward: -1.53
               Mean episode length: 34.60
       Episode_Reward/keep_balance: 0.0348
     Episode_Reward/rew_lin_vel_xy: 0.0309
      Episode_Reward/rew_ang_vel_z: 0.1075
    Episode_Reward/pen_base_height: -0.1061
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0024
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0095
Episode_Reward/pen_flat_orientation: -0.0531
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0029
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0356
Metrics/base_velocity/error_vel_xy: 0.1821
Metrics/base_velocity/error_vel_yaw: 0.0296
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 116.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 1.06s
                        Total time: 112.06s
                               ETA: 3250.9s

################################################################################
                     [1m Learning iteration 100/3000 [0m                      

                       Computation: 91679 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.1125
                    Surrogate loss: 0.0017
             Mean action noise std: 0.4655
                     Learning rate: 0.0009
                       Mean reward: -1.38
               Mean episode length: 35.63
       Episode_Reward/keep_balance: 0.0351
     Episode_Reward/rew_lin_vel_xy: 0.0315
      Episode_Reward/rew_ang_vel_z: 0.1085
    Episode_Reward/pen_base_height: -0.1062
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0024
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0095
Episode_Reward/pen_flat_orientation: -0.0532
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0030
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0361
Metrics/base_velocity/error_vel_xy: 0.1833
Metrics/base_velocity/error_vel_yaw: 0.0301
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 116.1250
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 1.07s
                        Total time: 113.13s
                               ETA: 3248.4s

################################################################################
                     [1m Learning iteration 101/3000 [0m                      

                       Computation: 92762 steps/s (collection: 0.939s, learning 0.120s)
               Value function loss: 0.1013
                    Surrogate loss: -0.0015
             Mean action noise std: 0.4626
                     Learning rate: 0.0013
                       Mean reward: -1.61
               Mean episode length: 34.78
       Episode_Reward/keep_balance: 0.0349
     Episode_Reward/rew_lin_vel_xy: 0.0310
      Episode_Reward/rew_ang_vel_z: 0.1073
    Episode_Reward/pen_base_height: -0.1057
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0024
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0094
Episode_Reward/pen_flat_orientation: -0.0534
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0029
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0357
Metrics/base_velocity/error_vel_xy: 0.1829
Metrics/base_velocity/error_vel_yaw: 0.0298
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 116.7917
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 1.06s
                        Total time: 114.19s
                               ETA: 3245.5s

################################################################################
                     [1m Learning iteration 102/3000 [0m                      

                       Computation: 91542 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 0.1088
                    Surrogate loss: 0.0067
             Mean action noise std: 0.4612
                     Learning rate: 0.0004
                       Mean reward: -1.66
               Mean episode length: 35.55
       Episode_Reward/keep_balance: 0.0351
     Episode_Reward/rew_lin_vel_xy: 0.0320
      Episode_Reward/rew_ang_vel_z: 0.1083
    Episode_Reward/pen_base_height: -0.1057
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0024
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0534
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0029
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0360
Metrics/base_velocity/error_vel_xy: 0.1834
Metrics/base_velocity/error_vel_yaw: 0.0301
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.0833
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 1.07s
                        Total time: 115.27s
                               ETA: 3243.1s

################################################################################
                     [1m Learning iteration 103/3000 [0m                      

                       Computation: 93073 steps/s (collection: 0.935s, learning 0.121s)
               Value function loss: 0.0960
                    Surrogate loss: -0.0025
             Mean action noise std: 0.4592
                     Learning rate: 0.0006
                       Mean reward: -1.40
               Mean episode length: 36.81
       Episode_Reward/keep_balance: 0.0356
     Episode_Reward/rew_lin_vel_xy: 0.0326
      Episode_Reward/rew_ang_vel_z: 0.1098
    Episode_Reward/pen_base_height: -0.1056
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0024
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0094
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0030
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0364
Metrics/base_velocity/error_vel_xy: 0.1864
Metrics/base_velocity/error_vel_yaw: 0.0303
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.0417
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 1.06s
                        Total time: 116.32s
                               ETA: 3240.2s

################################################################################
                     [1m Learning iteration 104/3000 [0m                      

                       Computation: 91786 steps/s (collection: 0.946s, learning 0.125s)
               Value function loss: 0.1101
                    Surrogate loss: -0.0024
             Mean action noise std: 0.4569
                     Learning rate: 0.0009
                       Mean reward: -1.63
               Mean episode length: 35.14
       Episode_Reward/keep_balance: 0.0355
     Episode_Reward/rew_lin_vel_xy: 0.0317
      Episode_Reward/rew_ang_vel_z: 0.1097
    Episode_Reward/pen_base_height: -0.1055
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0024
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0030
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0364
Metrics/base_velocity/error_vel_xy: 0.1862
Metrics/base_velocity/error_vel_yaw: 0.0297
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 114.9583
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 1.07s
                        Total time: 117.39s
                               ETA: 3237.8s

################################################################################
                     [1m Learning iteration 105/3000 [0m                      

                       Computation: 92499 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 0.1129
                    Surrogate loss: 0.0004
             Mean action noise std: 0.4557
                     Learning rate: 0.0006
                       Mean reward: -1.54
               Mean episode length: 36.01
       Episode_Reward/keep_balance: 0.0360
     Episode_Reward/rew_lin_vel_xy: 0.0335
      Episode_Reward/rew_ang_vel_z: 0.1115
    Episode_Reward/pen_base_height: -0.1055
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0025
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0094
Episode_Reward/pen_flat_orientation: -0.0534
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0030
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0368
Metrics/base_velocity/error_vel_xy: 0.1850
Metrics/base_velocity/error_vel_yaw: 0.0304
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 112.4583
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 1.06s
                        Total time: 118.46s
                               ETA: 3235.2s

################################################################################
                     [1m Learning iteration 106/3000 [0m                      

                       Computation: 90754 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.1230
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4542
                     Learning rate: 0.0006
                       Mean reward: -1.59
               Mean episode length: 38.18
       Episode_Reward/keep_balance: 0.0364
     Episode_Reward/rew_lin_vel_xy: 0.0331
      Episode_Reward/rew_ang_vel_z: 0.1127
    Episode_Reward/pen_base_height: -0.1059
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0026
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0094
Episode_Reward/pen_flat_orientation: -0.0542
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0031
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0373
Metrics/base_velocity/error_vel_xy: 0.1894
Metrics/base_velocity/error_vel_yaw: 0.0308
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 112.7500
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 1.08s
                        Total time: 119.54s
                               ETA: 3233.1s

################################################################################
                     [1m Learning iteration 107/3000 [0m                      

                       Computation: 89681 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.1185
                    Surrogate loss: -0.0005
             Mean action noise std: 0.4524
                     Learning rate: 0.0009
                       Mean reward: -1.68
               Mean episode length: 34.67
       Episode_Reward/keep_balance: 0.0365
     Episode_Reward/rew_lin_vel_xy: 0.0337
      Episode_Reward/rew_ang_vel_z: 0.1127
    Episode_Reward/pen_base_height: -0.1056
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0026
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0539
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0031
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0377
Metrics/base_velocity/error_vel_xy: 0.1886
Metrics/base_velocity/error_vel_yaw: 0.0308
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 111.5000
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 1.10s
                        Total time: 120.64s
                               ETA: 3231.5s

################################################################################
                     [1m Learning iteration 108/3000 [0m                      

                       Computation: 89991 steps/s (collection: 0.967s, learning 0.126s)
               Value function loss: 0.1083
                    Surrogate loss: 0.0003
             Mean action noise std: 0.4499
                     Learning rate: 0.0006
                       Mean reward: -1.50
               Mean episode length: 38.13
       Episode_Reward/keep_balance: 0.0366
     Episode_Reward/rew_lin_vel_xy: 0.0331
      Episode_Reward/rew_ang_vel_z: 0.1136
    Episode_Reward/pen_base_height: -0.1052
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0026
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0534
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0030
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0376
Metrics/base_velocity/error_vel_xy: 0.1893
Metrics/base_velocity/error_vel_yaw: 0.0304
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 114.3333
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 1.09s
                        Total time: 121.73s
                               ETA: 3229.7s

################################################################################
                     [1m Learning iteration 109/3000 [0m                      

                       Computation: 91471 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.1073
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4476
                     Learning rate: 0.0009
                       Mean reward: -1.39
               Mean episode length: 37.53
       Episode_Reward/keep_balance: 0.0363
     Episode_Reward/rew_lin_vel_xy: 0.0330
      Episode_Reward/rew_ang_vel_z: 0.1128
    Episode_Reward/pen_base_height: -0.1059
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0026
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0091
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0030
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0372
Metrics/base_velocity/error_vel_xy: 0.1904
Metrics/base_velocity/error_vel_yaw: 0.0303
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 110.6667
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 1.07s
                        Total time: 122.80s
                               ETA: 3227.5s

################################################################################
                     [1m Learning iteration 110/3000 [0m                      

                       Computation: 92145 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 0.1175
                    Surrogate loss: 0.0004
             Mean action noise std: 0.4451
                     Learning rate: 0.0013
                       Mean reward: -1.59
               Mean episode length: 38.59
       Episode_Reward/keep_balance: 0.0368
     Episode_Reward/rew_lin_vel_xy: 0.0330
      Episode_Reward/rew_ang_vel_z: 0.1150
    Episode_Reward/pen_base_height: -0.1064
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0027
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0091
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0030
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0380
Metrics/base_velocity/error_vel_xy: 0.1913
Metrics/base_velocity/error_vel_yaw: 0.0304
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 109.5833
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 1.07s
                        Total time: 123.87s
                               ETA: 3225.1s

################################################################################
                     [1m Learning iteration 111/3000 [0m                      

                       Computation: 91011 steps/s (collection: 0.959s, learning 0.121s)
               Value function loss: 0.1131
                    Surrogate loss: 0.0079
             Mean action noise std: 0.4444
                     Learning rate: 0.0003
                       Mean reward: -1.37
               Mean episode length: 38.29
       Episode_Reward/keep_balance: 0.0371
     Episode_Reward/rew_lin_vel_xy: 0.0328
      Episode_Reward/rew_ang_vel_z: 0.1154
    Episode_Reward/pen_base_height: -0.1061
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0196
   Episode_Reward/pen_joint_torque: -0.0027
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0092
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0030
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0381
Metrics/base_velocity/error_vel_xy: 0.1934
Metrics/base_velocity/error_vel_yaw: 0.0306
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 111.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 1.08s
                        Total time: 124.95s
                               ETA: 3223.0s

################################################################################
                     [1m Learning iteration 112/3000 [0m                      

                       Computation: 92808 steps/s (collection: 0.936s, learning 0.123s)
               Value function loss: 0.1052
                    Surrogate loss: -0.0010
             Mean action noise std: 0.4430
                     Learning rate: 0.0006
                       Mean reward: -1.39
               Mean episode length: 36.80
       Episode_Reward/keep_balance: 0.0373
     Episode_Reward/rew_lin_vel_xy: 0.0340
      Episode_Reward/rew_ang_vel_z: 0.1168
    Episode_Reward/pen_base_height: -0.1060
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0196
   Episode_Reward/pen_joint_torque: -0.0027
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0091
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0030
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0385
Metrics/base_velocity/error_vel_xy: 0.1949
Metrics/base_velocity/error_vel_yaw: 0.0302
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 108.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 1.06s
                        Total time: 126.01s
                               ETA: 3220.5s

################################################################################
                     [1m Learning iteration 113/3000 [0m                      

                       Computation: 93164 steps/s (collection: 0.934s, learning 0.122s)
               Value function loss: 0.1162
                    Surrogate loss: -0.0000
             Mean action noise std: 0.4410
                     Learning rate: 0.0009
                       Mean reward: -1.52
               Mean episode length: 37.93
       Episode_Reward/keep_balance: 0.0378
     Episode_Reward/rew_lin_vel_xy: 0.0325
      Episode_Reward/rew_ang_vel_z: 0.1178
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0028
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0092
Episode_Reward/pen_flat_orientation: -0.0542
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0030
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0391
Metrics/base_velocity/error_vel_xy: 0.1995
Metrics/base_velocity/error_vel_yaw: 0.0312
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 105.8750
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 1.06s
                        Total time: 127.06s
                               ETA: 3217.8s

################################################################################
                     [1m Learning iteration 114/3000 [0m                      

                       Computation: 92558 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 0.1218
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4392
                     Learning rate: 0.0013
                       Mean reward: -1.57
               Mean episode length: 38.68
       Episode_Reward/keep_balance: 0.0384
     Episode_Reward/rew_lin_vel_xy: 0.0352
      Episode_Reward/rew_ang_vel_z: 0.1202
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0107
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0029
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0546
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0031
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0400
Metrics/base_velocity/error_vel_xy: 0.2016
Metrics/base_velocity/error_vel_yaw: 0.0318
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 106.8750
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 1.06s
                        Total time: 128.13s
                               ETA: 3215.4s

################################################################################
                     [1m Learning iteration 115/3000 [0m                      

                       Computation: 92094 steps/s (collection: 0.944s, learning 0.124s)
               Value function loss: 0.1568
                    Surrogate loss: 0.0033
             Mean action noise std: 0.4377
                     Learning rate: 0.0006
                       Mean reward: -1.27
               Mean episode length: 37.65
       Episode_Reward/keep_balance: 0.0381
     Episode_Reward/rew_lin_vel_xy: 0.0338
      Episode_Reward/rew_ang_vel_z: 0.1195
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0107
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0028
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0092
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0032
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0398
Metrics/base_velocity/error_vel_xy: 0.2020
Metrics/base_velocity/error_vel_yaw: 0.0309
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 106.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 1.07s
                        Total time: 129.19s
                               ETA: 3213.1s

################################################################################
                     [1m Learning iteration 116/3000 [0m                      

                       Computation: 92653 steps/s (collection: 0.940s, learning 0.121s)
               Value function loss: 0.1288
                    Surrogate loss: 0.0065
             Mean action noise std: 0.4376
                     Learning rate: 0.0002
                       Mean reward: -1.31
               Mean episode length: 38.22
       Episode_Reward/keep_balance: 0.0387
     Episode_Reward/rew_lin_vel_xy: 0.0370
      Episode_Reward/rew_ang_vel_z: 0.1214
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0107
     Episode_Reward/pen_ang_vel_xy: -0.0196
   Episode_Reward/pen_joint_torque: -0.0029
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0549
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0032
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0403
Metrics/base_velocity/error_vel_xy: 0.2001
Metrics/base_velocity/error_vel_yaw: 0.0318
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 105.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 1.06s
                        Total time: 130.25s
                               ETA: 3210.7s

################################################################################
                     [1m Learning iteration 117/3000 [0m                      

                       Computation: 93204 steps/s (collection: 0.932s, learning 0.123s)
               Value function loss: 0.1201
                    Surrogate loss: 0.0002
             Mean action noise std: 0.4366
                     Learning rate: 0.0004
                       Mean reward: -1.47
               Mean episode length: 39.62
       Episode_Reward/keep_balance: 0.0387
     Episode_Reward/rew_lin_vel_xy: 0.0373
      Episode_Reward/rew_ang_vel_z: 0.1212
    Episode_Reward/pen_base_height: -0.1069
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0029
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0092
Episode_Reward/pen_flat_orientation: -0.0546
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0032
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0402
Metrics/base_velocity/error_vel_xy: 0.1988
Metrics/base_velocity/error_vel_yaw: 0.0313
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 104.8750
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 1.05s
                        Total time: 131.31s
                               ETA: 3208.2s

################################################################################
                     [1m Learning iteration 118/3000 [0m                      

                       Computation: 92612 steps/s (collection: 0.942s, learning 0.119s)
               Value function loss: 0.1262
                    Surrogate loss: -0.0017
             Mean action noise std: 0.4338
                     Learning rate: 0.0009
                       Mean reward: -1.60
               Mean episode length: 38.54
       Episode_Reward/keep_balance: 0.0391
     Episode_Reward/rew_lin_vel_xy: 0.0353
      Episode_Reward/rew_ang_vel_z: 0.1228
    Episode_Reward/pen_base_height: -0.1067
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0011
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0549
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0033
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0407
Metrics/base_velocity/error_vel_xy: 0.2037
Metrics/base_velocity/error_vel_yaw: 0.0319
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 105.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 1.06s
                        Total time: 132.37s
                               ETA: 3205.8s

################################################################################
                     [1m Learning iteration 119/3000 [0m                      

                       Computation: 92725 steps/s (collection: 0.939s, learning 0.121s)
               Value function loss: 0.1303
                    Surrogate loss: 0.0006
             Mean action noise std: 0.4331
                     Learning rate: 0.0006
                       Mean reward: -1.26
               Mean episode length: 38.84
       Episode_Reward/keep_balance: 0.0387
     Episode_Reward/rew_lin_vel_xy: 0.0361
      Episode_Reward/rew_ang_vel_z: 0.1216
    Episode_Reward/pen_base_height: -0.1054
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0196
   Episode_Reward/pen_joint_torque: -0.0029
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0091
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0033
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0404
Metrics/base_velocity/error_vel_xy: 0.2008
Metrics/base_velocity/error_vel_yaw: 0.0310
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 104.5000
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 1.06s
                        Total time: 133.43s
                               ETA: 3203.4s

################################################################################
                     [1m Learning iteration 120/3000 [0m                      

                       Computation: 93941 steps/s (collection: 0.927s, learning 0.119s)
               Value function loss: 0.1213
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4320
                     Learning rate: 0.0009
                       Mean reward: -1.36
               Mean episode length: 39.33
       Episode_Reward/keep_balance: 0.0396
     Episode_Reward/rew_lin_vel_xy: 0.0360
      Episode_Reward/rew_ang_vel_z: 0.1241
    Episode_Reward/pen_base_height: -0.1067
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0196
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0551
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0034
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0415
Metrics/base_velocity/error_vel_xy: 0.2075
Metrics/base_velocity/error_vel_yaw: 0.0323
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 103.0417
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 1.05s
                        Total time: 134.48s
                               ETA: 3200.8s

################################################################################
                     [1m Learning iteration 121/3000 [0m                      

                       Computation: 93889 steps/s (collection: 0.926s, learning 0.121s)
               Value function loss: 0.1332
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4309
                     Learning rate: 0.0009
                       Mean reward: -1.44
               Mean episode length: 37.85
       Episode_Reward/keep_balance: 0.0395
     Episode_Reward/rew_lin_vel_xy: 0.0358
      Episode_Reward/rew_ang_vel_z: 0.1240
    Episode_Reward/pen_base_height: -0.1058
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0541
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0033
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0411
Metrics/base_velocity/error_vel_xy: 0.2069
Metrics/base_velocity/error_vel_yaw: 0.0319
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 103.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 1.05s
                        Total time: 135.52s
                               ETA: 3198.1s

################################################################################
                     [1m Learning iteration 122/3000 [0m                      

                       Computation: 93413 steps/s (collection: 0.932s, learning 0.120s)
               Value function loss: 0.1378
                    Surrogate loss: -0.0013
             Mean action noise std: 0.4296
                     Learning rate: 0.0013
                       Mean reward: -1.16
               Mean episode length: 42.21
       Episode_Reward/keep_balance: 0.0395
     Episode_Reward/rew_lin_vel_xy: 0.0363
      Episode_Reward/rew_ang_vel_z: 0.1242
    Episode_Reward/pen_base_height: -0.1061
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0092
Episode_Reward/pen_flat_orientation: -0.0542
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0033
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0409
Metrics/base_velocity/error_vel_xy: 0.2050
Metrics/base_velocity/error_vel_yaw: 0.0318
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 103.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 1.05s
                        Total time: 136.58s
                               ETA: 3195.7s

################################################################################
                     [1m Learning iteration 123/3000 [0m                      

                       Computation: 92464 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 0.1650
                    Surrogate loss: 0.0028
             Mean action noise std: 0.4293
                     Learning rate: 0.0003
                       Mean reward: -1.28
               Mean episode length: 40.57
       Episode_Reward/keep_balance: 0.0396
     Episode_Reward/rew_lin_vel_xy: 0.0376
      Episode_Reward/rew_ang_vel_z: 0.1250
    Episode_Reward/pen_base_height: -0.1059
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0542
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0033
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0412
Metrics/base_velocity/error_vel_xy: 0.2056
Metrics/base_velocity/error_vel_yaw: 0.0316
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 102.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 1.06s
                        Total time: 137.64s
                               ETA: 3193.5s

################################################################################
                     [1m Learning iteration 124/3000 [0m                      

                       Computation: 90924 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.1385
                    Surrogate loss: -0.0026
             Mean action noise std: 0.4283
                     Learning rate: 0.0006
                       Mean reward: -1.09
               Mean episode length: 41.62
       Episode_Reward/keep_balance: 0.0397
     Episode_Reward/rew_lin_vel_xy: 0.0367
      Episode_Reward/rew_ang_vel_z: 0.1246
    Episode_Reward/pen_base_height: -0.1063
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0092
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0033
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0410
Metrics/base_velocity/error_vel_xy: 0.2051
Metrics/base_velocity/error_vel_yaw: 0.0320
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 105.1667
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 1.08s
                        Total time: 138.72s
                               ETA: 3191.7s

################################################################################
                     [1m Learning iteration 125/3000 [0m                      

                       Computation: 91736 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.1340
                    Surrogate loss: -0.0001
             Mean action noise std: 0.4273
                     Learning rate: 0.0009
                       Mean reward: -1.30
               Mean episode length: 38.76
       Episode_Reward/keep_balance: 0.0395
     Episode_Reward/rew_lin_vel_xy: 0.0368
      Episode_Reward/rew_ang_vel_z: 0.1240
    Episode_Reward/pen_base_height: -0.1060
      Episode_Reward/pen_lin_vel_z: -0.0112
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0092
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0033
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0409
Metrics/base_velocity/error_vel_xy: 0.2058
Metrics/base_velocity/error_vel_yaw: 0.0319
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 102.5417
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 1.07s
                        Total time: 139.79s
                               ETA: 3189.7s

################################################################################
                     [1m Learning iteration 126/3000 [0m                      

                       Computation: 91998 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.1313
                    Surrogate loss: -0.0014
             Mean action noise std: 0.4269
                     Learning rate: 0.0009
                       Mean reward: -1.06
               Mean episode length: 40.86
       Episode_Reward/keep_balance: 0.0397
     Episode_Reward/rew_lin_vel_xy: 0.0364
      Episode_Reward/rew_ang_vel_z: 0.1246
    Episode_Reward/pen_base_height: -0.1061
      Episode_Reward/pen_lin_vel_z: -0.0112
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0031
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0092
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0034
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0413
Metrics/base_velocity/error_vel_xy: 0.2101
Metrics/base_velocity/error_vel_yaw: 0.0325
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 100.7083
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 1.07s
                        Total time: 140.86s
                               ETA: 3187.7s

################################################################################
                     [1m Learning iteration 127/3000 [0m                      

                       Computation: 91709 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 0.1571
                    Surrogate loss: -0.0014
             Mean action noise std: 0.4256
                     Learning rate: 0.0019
                       Mean reward: -0.83
               Mean episode length: 42.38
       Episode_Reward/keep_balance: 0.0404
     Episode_Reward/rew_lin_vel_xy: 0.0388
      Episode_Reward/rew_ang_vel_z: 0.1272
    Episode_Reward/pen_base_height: -0.1063
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0031
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0034
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0422
Metrics/base_velocity/error_vel_xy: 0.2090
Metrics/base_velocity/error_vel_yaw: 0.0326
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 101.9583
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 1.07s
                        Total time: 141.93s
                               ETA: 3185.7s

################################################################################
                     [1m Learning iteration 128/3000 [0m                      

                       Computation: 89799 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 0.1808
                    Surrogate loss: 0.0040
             Mean action noise std: 0.4249
                     Learning rate: 0.0004
                       Mean reward: -1.09
               Mean episode length: 41.04
       Episode_Reward/keep_balance: 0.0406
     Episode_Reward/rew_lin_vel_xy: 0.0371
      Episode_Reward/rew_ang_vel_z: 0.1279
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0032
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0543
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0034
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0424
Metrics/base_velocity/error_vel_xy: 0.2127
Metrics/base_velocity/error_vel_yaw: 0.0325
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 98.2917
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 1.09s
                        Total time: 143.03s
                               ETA: 3184.3s

################################################################################
                     [1m Learning iteration 129/3000 [0m                      

                       Computation: 89449 steps/s (collection: 0.973s, learning 0.126s)
               Value function loss: 0.1460
                    Surrogate loss: -0.0007
             Mean action noise std: 0.4250
                     Learning rate: 0.0006
                       Mean reward: -1.10
               Mean episode length: 41.60
       Episode_Reward/keep_balance: 0.0412
     Episode_Reward/rew_lin_vel_xy: 0.0402
      Episode_Reward/rew_ang_vel_z: 0.1299
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0112
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0032
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0094
Episode_Reward/pen_flat_orientation: -0.0543
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0034
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0427
Metrics/base_velocity/error_vel_xy: 0.2120
Metrics/base_velocity/error_vel_yaw: 0.0331
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 102.2917
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 1.10s
                        Total time: 144.13s
                               ETA: 3183.0s

################################################################################
                     [1m Learning iteration 130/3000 [0m                      

                       Computation: 89131 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 0.1493
                    Surrogate loss: 0.0029
             Mean action noise std: 0.4247
                     Learning rate: 0.0004
                       Mean reward: -1.21
               Mean episode length: 40.80
       Episode_Reward/keep_balance: 0.0405
     Episode_Reward/rew_lin_vel_xy: 0.0371
      Episode_Reward/rew_ang_vel_z: 0.1277
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0112
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0032
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0555
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0034
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0418
Metrics/base_velocity/error_vel_xy: 0.2123
Metrics/base_velocity/error_vel_yaw: 0.0327
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 100.9583
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 1.10s
                        Total time: 145.23s
                               ETA: 3181.7s

################################################################################
                     [1m Learning iteration 131/3000 [0m                      

                       Computation: 84320 steps/s (collection: 1.040s, learning 0.126s)
               Value function loss: 0.1206
                    Surrogate loss: 0.0014
             Mean action noise std: 0.4243
                     Learning rate: 0.0006
                       Mean reward: -1.26
               Mean episode length: 39.97
       Episode_Reward/keep_balance: 0.0403
     Episode_Reward/rew_lin_vel_xy: 0.0378
      Episode_Reward/rew_ang_vel_z: 0.1273
    Episode_Reward/pen_base_height: -0.1065
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0032
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0091
Episode_Reward/pen_flat_orientation: -0.0541
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0034
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0414
Metrics/base_velocity/error_vel_xy: 0.2087
Metrics/base_velocity/error_vel_yaw: 0.0321
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 101.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 1.17s
                        Total time: 146.40s
                               ETA: 3181.9s

################################################################################
                     [1m Learning iteration 132/3000 [0m                      

                       Computation: 85511 steps/s (collection: 1.016s, learning 0.134s)
               Value function loss: 0.1409
                    Surrogate loss: -0.0019
             Mean action noise std: 0.4231
                     Learning rate: 0.0009
                       Mean reward: -1.38
               Mean episode length: 39.26
       Episode_Reward/keep_balance: 0.0405
     Episode_Reward/rew_lin_vel_xy: 0.0378
      Episode_Reward/rew_ang_vel_z: 0.1278
    Episode_Reward/pen_base_height: -0.1067
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0201
   Episode_Reward/pen_joint_torque: -0.0032
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0092
Episode_Reward/pen_flat_orientation: -0.0542
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0034
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0414
Metrics/base_velocity/error_vel_xy: 0.2112
Metrics/base_velocity/error_vel_yaw: 0.0322
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 101.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 1.15s
                        Total time: 147.54s
                               ETA: 3181.6s

################################################################################
                     [1m Learning iteration 133/3000 [0m                      

                       Computation: 88550 steps/s (collection: 0.983s, learning 0.127s)
               Value function loss: 0.1361
                    Surrogate loss: -0.0002
             Mean action noise std: 0.4224
                     Learning rate: 0.0013
                       Mean reward: -1.10
               Mean episode length: 40.97
       Episode_Reward/keep_balance: 0.0403
     Episode_Reward/rew_lin_vel_xy: 0.0380
      Episode_Reward/rew_ang_vel_z: 0.1274
    Episode_Reward/pen_base_height: -0.1060
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0032
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0091
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0034
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0414
Metrics/base_velocity/error_vel_xy: 0.2075
Metrics/base_velocity/error_vel_yaw: 0.0318
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 100.7500
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 1.11s
                        Total time: 148.66s
                               ETA: 3180.6s

################################################################################
                     [1m Learning iteration 134/3000 [0m                      

                       Computation: 81304 steps/s (collection: 1.074s, learning 0.135s)
               Value function loss: 0.1571
                    Surrogate loss: -0.0009
             Mean action noise std: 0.4221
                     Learning rate: 0.0019
                       Mean reward: -1.05
               Mean episode length: 42.01
       Episode_Reward/keep_balance: 0.0407
     Episode_Reward/rew_lin_vel_xy: 0.0386
      Episode_Reward/rew_ang_vel_z: 0.1282
    Episode_Reward/pen_base_height: -0.1058
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0032
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0091
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0034
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0421
Metrics/base_velocity/error_vel_xy: 0.2115
Metrics/base_velocity/error_vel_yaw: 0.0324
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 101.1667
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 1.21s
                        Total time: 149.86s
                               ETA: 3181.6s

################################################################################
                     [1m Learning iteration 135/3000 [0m                      

                       Computation: 89460 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.1539
                    Surrogate loss: 0.0092
             Mean action noise std: 0.4217
                     Learning rate: 0.0002
                       Mean reward: -1.16
               Mean episode length: 42.39
       Episode_Reward/keep_balance: 0.0405
     Episode_Reward/rew_lin_vel_xy: 0.0385
      Episode_Reward/rew_ang_vel_z: 0.1276
    Episode_Reward/pen_base_height: -0.1056
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0032
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0091
Episode_Reward/pen_flat_orientation: -0.0539
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0035
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0419
Metrics/base_velocity/error_vel_xy: 0.2098
Metrics/base_velocity/error_vel_yaw: 0.0324
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 99.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 1.10s
                        Total time: 150.96s
                               ETA: 3180.2s

################################################################################
                     [1m Learning iteration 136/3000 [0m                      

                       Computation: 92122 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 0.1421
                    Surrogate loss: -0.0012
             Mean action noise std: 0.4211
                     Learning rate: 0.0004
                       Mean reward: -1.01
               Mean episode length: 43.00
       Episode_Reward/keep_balance: 0.0406
     Episode_Reward/rew_lin_vel_xy: 0.0383
      Episode_Reward/rew_ang_vel_z: 0.1284
    Episode_Reward/pen_base_height: -0.1048
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0032
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0012
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0091
Episode_Reward/pen_flat_orientation: -0.0534
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0035
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0418
Metrics/base_velocity/error_vel_xy: 0.2100
Metrics/base_velocity/error_vel_yaw: 0.0319
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 100.3333
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 1.07s
                        Total time: 152.03s
                               ETA: 3178.2s

################################################################################
                     [1m Learning iteration 137/3000 [0m                      

                       Computation: 91019 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.1363
                    Surrogate loss: -0.0013
             Mean action noise std: 0.4204
                     Learning rate: 0.0006
                       Mean reward: -1.30
               Mean episode length: 38.83
       Episode_Reward/keep_balance: 0.0410
     Episode_Reward/rew_lin_vel_xy: 0.0387
      Episode_Reward/rew_ang_vel_z: 0.1297
    Episode_Reward/pen_base_height: -0.1049
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0033
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0091
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0036
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0425
Metrics/base_velocity/error_vel_xy: 0.2151
Metrics/base_velocity/error_vel_yaw: 0.0323
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 99.4583
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 1.08s
                        Total time: 153.11s
                               ETA: 3176.5s

################################################################################
                     [1m Learning iteration 138/3000 [0m                      

                       Computation: 91220 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.1416
                    Surrogate loss: -0.0015
             Mean action noise std: 0.4194
                     Learning rate: 0.0006
                       Mean reward: -1.04
               Mean episode length: 42.79
       Episode_Reward/keep_balance: 0.0413
     Episode_Reward/rew_lin_vel_xy: 0.0396
      Episode_Reward/rew_ang_vel_z: 0.1302
    Episode_Reward/pen_base_height: -0.1059
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0033
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0092
Episode_Reward/pen_flat_orientation: -0.0546
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0036
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0427
Metrics/base_velocity/error_vel_xy: 0.2139
Metrics/base_velocity/error_vel_yaw: 0.0329
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 98.2917
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 1.08s
                        Total time: 154.19s
                               ETA: 3174.7s

################################################################################
                     [1m Learning iteration 139/3000 [0m                      

                       Computation: 86988 steps/s (collection: 1.005s, learning 0.125s)
               Value function loss: 0.1405
                    Surrogate loss: -0.0004
             Mean action noise std: 0.4188
                     Learning rate: 0.0004
                       Mean reward: -1.02
               Mean episode length: 43.05
       Episode_Reward/keep_balance: 0.0418
     Episode_Reward/rew_lin_vel_xy: 0.0399
      Episode_Reward/rew_ang_vel_z: 0.1324
    Episode_Reward/pen_base_height: -0.1049
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0034
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0539
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0036
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0436
Metrics/base_velocity/error_vel_xy: 0.2194
Metrics/base_velocity/error_vel_yaw: 0.0327
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 99.5417
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 1.13s
                        Total time: 155.32s
                               ETA: 3174.0s

################################################################################
                     [1m Learning iteration 140/3000 [0m                      

                       Computation: 91909 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.1476
                    Surrogate loss: -0.0000
             Mean action noise std: 0.4179
                     Learning rate: 0.0009
                       Mean reward: -1.07
               Mean episode length: 41.47
       Episode_Reward/keep_balance: 0.0412
     Episode_Reward/rew_lin_vel_xy: 0.0390
      Episode_Reward/rew_ang_vel_z: 0.1303
    Episode_Reward/pen_base_height: -0.1044
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0033
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0091
Episode_Reward/pen_flat_orientation: -0.0541
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0036
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0429
Metrics/base_velocity/error_vel_xy: 0.2153
Metrics/base_velocity/error_vel_yaw: 0.0324
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 97.0417
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 1.07s
                        Total time: 156.39s
                               ETA: 3172.1s

################################################################################
                     [1m Learning iteration 141/3000 [0m                      

                       Computation: 91797 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 0.1662
                    Surrogate loss: -0.0009
             Mean action noise std: 0.4171
                     Learning rate: 0.0013
                       Mean reward: -1.15
               Mean episode length: 40.41
       Episode_Reward/keep_balance: 0.0423
     Episode_Reward/rew_lin_vel_xy: 0.0404
      Episode_Reward/rew_ang_vel_z: 0.1336
    Episode_Reward/pen_base_height: -0.1052
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0034
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0094
Episode_Reward/pen_flat_orientation: -0.0544
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0037
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0441
Metrics/base_velocity/error_vel_xy: 0.2189
Metrics/base_velocity/error_vel_yaw: 0.0335
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 97.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 1.07s
                        Total time: 157.46s
                               ETA: 3170.2s

################################################################################
                     [1m Learning iteration 142/3000 [0m                      

                       Computation: 92627 steps/s (collection: 0.940s, learning 0.121s)
               Value function loss: 0.1709
                    Surrogate loss: 0.0060
             Mean action noise std: 0.4171
                     Learning rate: 0.0003
                       Mean reward: -0.91
               Mean episode length: 43.55
       Episode_Reward/keep_balance: 0.0419
     Episode_Reward/rew_lin_vel_xy: 0.0389
      Episode_Reward/rew_ang_vel_z: 0.1324
    Episode_Reward/pen_base_height: -0.1048
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0201
   Episode_Reward/pen_joint_torque: -0.0034
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0092
Episode_Reward/pen_flat_orientation: -0.0541
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0037
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0437
Metrics/base_velocity/error_vel_xy: 0.2188
Metrics/base_velocity/error_vel_yaw: 0.0329
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 96.5000
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 1.06s
                        Total time: 158.52s
                               ETA: 3168.2s

################################################################################
                     [1m Learning iteration 143/3000 [0m                      

                       Computation: 90994 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.1732
                    Surrogate loss: 0.0015
             Mean action noise std: 0.4170
                     Learning rate: 0.0004
                       Mean reward: -0.90
               Mean episode length: 42.54
       Episode_Reward/keep_balance: 0.0423
     Episode_Reward/rew_lin_vel_xy: 0.0423
      Episode_Reward/rew_ang_vel_z: 0.1338
    Episode_Reward/pen_base_height: -0.1052
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0035
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0543
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0439
Metrics/base_velocity/error_vel_xy: 0.2187
Metrics/base_velocity/error_vel_yaw: 0.0335
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 97.2083
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 1.08s
                        Total time: 159.60s
                               ETA: 3166.5s

################################################################################
                     [1m Learning iteration 144/3000 [0m                      

                       Computation: 92323 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.1602
                    Surrogate loss: 0.0043
             Mean action noise std: 0.4168
                     Learning rate: 0.0003
                       Mean reward: -0.84
               Mean episode length: 43.69
       Episode_Reward/keep_balance: 0.0422
     Episode_Reward/rew_lin_vel_xy: 0.0415
      Episode_Reward/rew_ang_vel_z: 0.1338
    Episode_Reward/pen_base_height: -0.1050
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0035
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0037
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0437
Metrics/base_velocity/error_vel_xy: 0.2187
Metrics/base_velocity/error_vel_yaw: 0.0330
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 97.3750
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 1.06s
                        Total time: 160.66s
                               ETA: 3164.5s

################################################################################
                     [1m Learning iteration 145/3000 [0m                      

                       Computation: 90149 steps/s (collection: 0.951s, learning 0.140s)
               Value function loss: 0.1633
                    Surrogate loss: -0.0000
             Mean action noise std: 0.4162
                     Learning rate: 0.0006
                       Mean reward: -0.55
               Mean episode length: 43.16
       Episode_Reward/keep_balance: 0.0423
     Episode_Reward/rew_lin_vel_xy: 0.0412
      Episode_Reward/rew_ang_vel_z: 0.1340
    Episode_Reward/pen_base_height: -0.1050
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0035
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0037
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0438
Metrics/base_velocity/error_vel_xy: 0.2175
Metrics/base_velocity/error_vel_yaw: 0.0331
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 96.1667
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 1.09s
                        Total time: 161.76s
                               ETA: 3163.1s

################################################################################
                     [1m Learning iteration 146/3000 [0m                      

                       Computation: 90494 steps/s (collection: 0.961s, learning 0.125s)
               Value function loss: 0.1585
                    Surrogate loss: -0.0006
             Mean action noise std: 0.4157
                     Learning rate: 0.0006
                       Mean reward: -0.88
               Mean episode length: 41.80
       Episode_Reward/keep_balance: 0.0425
     Episode_Reward/rew_lin_vel_xy: 0.0418
      Episode_Reward/rew_ang_vel_z: 0.1348
    Episode_Reward/pen_base_height: -0.1057
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0035
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0094
Episode_Reward/pen_flat_orientation: -0.0539
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0037
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0441
Metrics/base_velocity/error_vel_xy: 0.2200
Metrics/base_velocity/error_vel_yaw: 0.0332
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 95.6667
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 1.09s
                        Total time: 162.84s
                               ETA: 3161.6s

################################################################################
                     [1m Learning iteration 147/3000 [0m                      

                       Computation: 89502 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.1648
                    Surrogate loss: 0.0005
             Mean action noise std: 0.4155
                     Learning rate: 0.0006
                       Mean reward: -1.00
               Mean episode length: 42.63
       Episode_Reward/keep_balance: 0.0425
     Episode_Reward/rew_lin_vel_xy: 0.0416
      Episode_Reward/rew_ang_vel_z: 0.1347
    Episode_Reward/pen_base_height: -0.1056
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0035
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0442
Metrics/base_velocity/error_vel_xy: 0.2211
Metrics/base_velocity/error_vel_yaw: 0.0335
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 97.1667
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 1.10s
                        Total time: 163.94s
                               ETA: 3160.3s

################################################################################
                     [1m Learning iteration 148/3000 [0m                      

                       Computation: 89461 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.1729
                    Surrogate loss: -0.0012
             Mean action noise std: 0.4159
                     Learning rate: 0.0013
                       Mean reward: -1.04
               Mean episode length: 42.80
       Episode_Reward/keep_balance: 0.0423
     Episode_Reward/rew_lin_vel_xy: 0.0398
      Episode_Reward/rew_ang_vel_z: 0.1338
    Episode_Reward/pen_base_height: -0.1046
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0035
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0440
Metrics/base_velocity/error_vel_xy: 0.2206
Metrics/base_velocity/error_vel_yaw: 0.0334
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 95.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 1.10s
                        Total time: 165.04s
                               ETA: 3159.0s

################################################################################
                     [1m Learning iteration 149/3000 [0m                      

                       Computation: 88184 steps/s (collection: 0.988s, learning 0.126s)
               Value function loss: 0.1662
                    Surrogate loss: 0.0005
             Mean action noise std: 0.4154
                     Learning rate: 0.0009
                       Mean reward: -0.95
               Mean episode length: 43.21
       Episode_Reward/keep_balance: 0.0428
     Episode_Reward/rew_lin_vel_xy: 0.0426
      Episode_Reward/rew_ang_vel_z: 0.1357
    Episode_Reward/pen_base_height: -0.1045
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0035
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0094
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0442
Metrics/base_velocity/error_vel_xy: 0.2213
Metrics/base_velocity/error_vel_yaw: 0.0333
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 95.6250
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 1.11s
                        Total time: 166.15s
                               ETA: 3158.0s

################################################################################
                     [1m Learning iteration 150/3000 [0m                      

                       Computation: 91041 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.1420
                    Surrogate loss: 0.0010
             Mean action noise std: 0.4148
                     Learning rate: 0.0004
                       Mean reward: -0.87
               Mean episode length: 45.76
       Episode_Reward/keep_balance: 0.0427
     Episode_Reward/rew_lin_vel_xy: 0.0424
      Episode_Reward/rew_ang_vel_z: 0.1352
    Episode_Reward/pen_base_height: -0.1044
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0036
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0442
Metrics/base_velocity/error_vel_xy: 0.2194
Metrics/base_velocity/error_vel_yaw: 0.0334
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 98.0833
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 1.08s
                        Total time: 167.23s
                               ETA: 3156.4s

################################################################################
                     [1m Learning iteration 151/3000 [0m                      

                       Computation: 91571 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.1477
                    Surrogate loss: -0.0010
             Mean action noise std: 0.4142
                     Learning rate: 0.0006
                       Mean reward: -0.90
               Mean episode length: 42.82
       Episode_Reward/keep_balance: 0.0425
     Episode_Reward/rew_lin_vel_xy: 0.0405
      Episode_Reward/rew_ang_vel_z: 0.1343
    Episode_Reward/pen_base_height: -0.1035
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0035
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0532
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0037
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0437
Metrics/base_velocity/error_vel_xy: 0.2207
Metrics/base_velocity/error_vel_yaw: 0.0331
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 94.7500
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 1.07s
                        Total time: 168.31s
                               ETA: 3154.6s

################################################################################
                     [1m Learning iteration 152/3000 [0m                      

                       Computation: 92346 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.1422
                    Surrogate loss: -0.0004
             Mean action noise std: 0.4141
                     Learning rate: 0.0009
                       Mean reward: -1.03
               Mean episode length: 43.98
       Episode_Reward/keep_balance: 0.0426
     Episode_Reward/rew_lin_vel_xy: 0.0402
      Episode_Reward/rew_ang_vel_z: 0.1350
    Episode_Reward/pen_base_height: -0.1040
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0035
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0092
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0439
Metrics/base_velocity/error_vel_xy: 0.2221
Metrics/base_velocity/error_vel_yaw: 0.0334
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 95.0833
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 1.06s
                        Total time: 169.37s
                               ETA: 3152.7s

################################################################################
                     [1m Learning iteration 153/3000 [0m                      

                       Computation: 92171 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 0.1578
                    Surrogate loss: -0.0020
             Mean action noise std: 0.4142
                     Learning rate: 0.0013
                       Mean reward: -0.99
               Mean episode length: 42.07
       Episode_Reward/keep_balance: 0.0429
     Episode_Reward/rew_lin_vel_xy: 0.0410
      Episode_Reward/rew_ang_vel_z: 0.1364
    Episode_Reward/pen_base_height: -0.1035
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0036
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0093
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0444
Metrics/base_velocity/error_vel_xy: 0.2237
Metrics/base_velocity/error_vel_yaw: 0.0335
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 96.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 1.07s
                        Total time: 170.44s
                               ETA: 3150.9s

################################################################################
                     [1m Learning iteration 154/3000 [0m                      

                       Computation: 91739 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.1803
                    Surrogate loss: -0.0007
             Mean action noise std: 0.4139
                     Learning rate: 0.0019
                       Mean reward: -1.09
               Mean episode length: 43.68
       Episode_Reward/keep_balance: 0.0433
     Episode_Reward/rew_lin_vel_xy: 0.0424
      Episode_Reward/rew_ang_vel_z: 0.1366
    Episode_Reward/pen_base_height: -0.1042
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0036
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0032
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0094
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0444
Metrics/base_velocity/error_vel_xy: 0.2240
Metrics/base_velocity/error_vel_yaw: 0.0345
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 94.7500
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 1.07s
                        Total time: 171.51s
                               ETA: 3149.1s

################################################################################
                     [1m Learning iteration 155/3000 [0m                      

                       Computation: 91794 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.1869
                    Surrogate loss: 0.0013
             Mean action noise std: 0.4138
                     Learning rate: 0.0019
                       Mean reward: -0.76
               Mean episode length: 44.95
       Episode_Reward/keep_balance: 0.0434
     Episode_Reward/rew_lin_vel_xy: 0.0433
      Episode_Reward/rew_ang_vel_z: 0.1372
    Episode_Reward/pen_base_height: -0.1042
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0037
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0032
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0095
Episode_Reward/pen_flat_orientation: -0.0532
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0447
Metrics/base_velocity/error_vel_xy: 0.2244
Metrics/base_velocity/error_vel_yaw: 0.0347
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 94.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 1.07s
                        Total time: 172.58s
                               ETA: 3147.4s

################################################################################
                     [1m Learning iteration 156/3000 [0m                      

                       Computation: 92621 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 0.1860
                    Surrogate loss: 0.0021
             Mean action noise std: 0.4139
                     Learning rate: 0.0006
                       Mean reward: -1.10
               Mean episode length: 43.92
       Episode_Reward/keep_balance: 0.0433
     Episode_Reward/rew_lin_vel_xy: 0.0408
      Episode_Reward/rew_ang_vel_z: 0.1370
    Episode_Reward/pen_base_height: -0.1044
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0037
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0032
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0094
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0444
Metrics/base_velocity/error_vel_xy: 0.2245
Metrics/base_velocity/error_vel_yaw: 0.0340
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 93.1250
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 1.06s
                        Total time: 173.64s
                               ETA: 3145.5s

################################################################################
                     [1m Learning iteration 157/3000 [0m                      

                       Computation: 93426 steps/s (collection: 0.933s, learning 0.120s)
               Value function loss: 0.1660
                    Surrogate loss: 0.0001
             Mean action noise std: 0.4141
                     Learning rate: 0.0009
                       Mean reward: -1.15
               Mean episode length: 40.43
       Episode_Reward/keep_balance: 0.0433
     Episode_Reward/rew_lin_vel_xy: 0.0424
      Episode_Reward/rew_ang_vel_z: 0.1371
    Episode_Reward/pen_base_height: -0.1055
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0037
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0032
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0095
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0446
Metrics/base_velocity/error_vel_xy: 0.2244
Metrics/base_velocity/error_vel_yaw: 0.0345
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 93.8750
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 1.05s
                        Total time: 174.69s
                               ETA: 3143.4s

################################################################################
                     [1m Learning iteration 158/3000 [0m                      

                       Computation: 92102 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 0.1852
                    Surrogate loss: -0.0005
             Mean action noise std: 0.4144
                     Learning rate: 0.0009
                       Mean reward: -0.91
               Mean episode length: 44.03
       Episode_Reward/keep_balance: 0.0437
     Episode_Reward/rew_lin_vel_xy: 0.0429
      Episode_Reward/rew_ang_vel_z: 0.1387
    Episode_Reward/pen_base_height: -0.1046
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0037
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0032
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0095
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0446
Metrics/base_velocity/error_vel_xy: 0.2239
Metrics/base_velocity/error_vel_yaw: 0.0338
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 93.3333
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 1.07s
                        Total time: 175.76s
                               ETA: 3141.6s

################################################################################
                     [1m Learning iteration 159/3000 [0m                      

                       Computation: 92506 steps/s (collection: 0.941s, learning 0.121s)
               Value function loss: 0.2109
                    Surrogate loss: 0.0019
             Mean action noise std: 0.4143
                     Learning rate: 0.0009
                       Mean reward: -0.65
               Mean episode length: 46.00
       Episode_Reward/keep_balance: 0.0446
     Episode_Reward/rew_lin_vel_xy: 0.0452
      Episode_Reward/rew_ang_vel_z: 0.1415
    Episode_Reward/pen_base_height: -0.1053
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0097
Episode_Reward/pen_flat_orientation: -0.0551
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0456
Metrics/base_velocity/error_vel_xy: 0.2287
Metrics/base_velocity/error_vel_yaw: 0.0348
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 91.1250
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 1.06s
                        Total time: 176.82s
                               ETA: 3139.7s

################################################################################
                     [1m Learning iteration 160/3000 [0m                      

                       Computation: 91664 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 0.1655
                    Surrogate loss: 0.0007
             Mean action noise std: 0.4145
                     Learning rate: 0.0006
                       Mean reward: -0.92
               Mean episode length: 43.91
       Episode_Reward/keep_balance: 0.0446
     Episode_Reward/rew_lin_vel_xy: 0.0436
      Episode_Reward/rew_ang_vel_z: 0.1415
    Episode_Reward/pen_base_height: -0.1056
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0098
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0455
Metrics/base_velocity/error_vel_xy: 0.2319
Metrics/base_velocity/error_vel_yaw: 0.0348
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.9583
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 1.07s
                        Total time: 177.90s
                               ETA: 3138.0s

################################################################################
                     [1m Learning iteration 161/3000 [0m                      

                       Computation: 92613 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 0.1724
                    Surrogate loss: 0.0010
             Mean action noise std: 0.4145
                     Learning rate: 0.0006
                       Mean reward: -0.75
               Mean episode length: 45.30
       Episode_Reward/keep_balance: 0.0446
     Episode_Reward/rew_lin_vel_xy: 0.0433
      Episode_Reward/rew_ang_vel_z: 0.1411
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0039
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0098
Episode_Reward/pen_flat_orientation: -0.0556
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0460
Metrics/base_velocity/error_vel_xy: 0.2308
Metrics/base_velocity/error_vel_yaw: 0.0356
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 92.7500
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 1.06s
                        Total time: 178.96s
                               ETA: 3136.2s

################################################################################
                     [1m Learning iteration 162/3000 [0m                      

                       Computation: 92386 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 0.1612
                    Surrogate loss: 0.0002
             Mean action noise std: 0.4141
                     Learning rate: 0.0006
                       Mean reward: -0.79
               Mean episode length: 45.59
       Episode_Reward/keep_balance: 0.0447
     Episode_Reward/rew_lin_vel_xy: 0.0457
      Episode_Reward/rew_ang_vel_z: 0.1417
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0039
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0098
Episode_Reward/pen_flat_orientation: -0.0556
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0458
Metrics/base_velocity/error_vel_xy: 0.2272
Metrics/base_velocity/error_vel_yaw: 0.0356
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 91.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 1.06s
                        Total time: 180.02s
                               ETA: 3134.4s

################################################################################
                     [1m Learning iteration 163/3000 [0m                      

                       Computation: 92066 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.1609
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4136
                     Learning rate: 0.0009
                       Mean reward: -0.31
               Mean episode length: 46.86
       Episode_Reward/keep_balance: 0.0445
     Episode_Reward/rew_lin_vel_xy: 0.0442
      Episode_Reward/rew_ang_vel_z: 0.1411
    Episode_Reward/pen_base_height: -0.1054
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0098
Episode_Reward/pen_flat_orientation: -0.0542
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0455
Metrics/base_velocity/error_vel_xy: 0.2287
Metrics/base_velocity/error_vel_yaw: 0.0352
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 92.2917
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 1.07s
                        Total time: 181.09s
                               ETA: 3132.6s

################################################################################
                     [1m Learning iteration 164/3000 [0m                      

                       Computation: 93427 steps/s (collection: 0.930s, learning 0.122s)
               Value function loss: 0.1744
                    Surrogate loss: 0.0005
             Mean action noise std: 0.4133
                     Learning rate: 0.0009
                       Mean reward: -0.95
               Mean episode length: 46.21
       Episode_Reward/keep_balance: 0.0445
     Episode_Reward/rew_lin_vel_xy: 0.0417
      Episode_Reward/rew_ang_vel_z: 0.1410
    Episode_Reward/pen_base_height: -0.1055
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0039
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0098
Episode_Reward/pen_flat_orientation: -0.0539
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0459
Metrics/base_velocity/error_vel_xy: 0.2335
Metrics/base_velocity/error_vel_yaw: 0.0352
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 91.8333
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 1.05s
                        Total time: 182.14s
                               ETA: 3130.6s

################################################################################
                     [1m Learning iteration 165/3000 [0m                      

                       Computation: 92799 steps/s (collection: 0.937s, learning 0.123s)
               Value function loss: 0.1688
                    Surrogate loss: 0.0034
             Mean action noise std: 0.4131
                     Learning rate: 0.0006
                       Mean reward: -1.03
               Mean episode length: 43.86
       Episode_Reward/keep_balance: 0.0446
     Episode_Reward/rew_lin_vel_xy: 0.0427
      Episode_Reward/rew_ang_vel_z: 0.1414
    Episode_Reward/pen_base_height: -0.1051
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0098
Episode_Reward/pen_flat_orientation: -0.0544
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0460
Metrics/base_velocity/error_vel_xy: 0.2310
Metrics/base_velocity/error_vel_yaw: 0.0348
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 91.0833
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 1.06s
                        Total time: 183.20s
                               ETA: 3128.8s

################################################################################
                     [1m Learning iteration 166/3000 [0m                      

                       Computation: 92212 steps/s (collection: 0.943s, learning 0.123s)
               Value function loss: 0.1607
                    Surrogate loss: -0.0003
             Mean action noise std: 0.4126
                     Learning rate: 0.0013
                       Mean reward: -0.96
               Mean episode length: 44.81
       Episode_Reward/keep_balance: 0.0448
     Episode_Reward/rew_lin_vel_xy: 0.0446
      Episode_Reward/rew_ang_vel_z: 0.1420
    Episode_Reward/pen_base_height: -0.1061
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0039
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0099
Episode_Reward/pen_flat_orientation: -0.0553
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0461
Metrics/base_velocity/error_vel_xy: 0.2325
Metrics/base_velocity/error_vel_yaw: 0.0355
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 93.0833
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 1.07s
                        Total time: 184.27s
                               ETA: 3127.0s

################################################################################
                     [1m Learning iteration 167/3000 [0m                      

                       Computation: 92160 steps/s (collection: 0.943s, learning 0.123s)
               Value function loss: 0.1611
                    Surrogate loss: 0.0019
             Mean action noise std: 0.4122
                     Learning rate: 0.0009
                       Mean reward: -0.56
               Mean episode length: 45.29
       Episode_Reward/keep_balance: 0.0445
     Episode_Reward/rew_lin_vel_xy: 0.0420
      Episode_Reward/rew_ang_vel_z: 0.1409
    Episode_Reward/pen_base_height: -0.1061
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0039
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0098
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0459
Metrics/base_velocity/error_vel_xy: 0.2334
Metrics/base_velocity/error_vel_yaw: 0.0352
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 89.6667
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 1.07s
                        Total time: 185.33s
                               ETA: 3125.3s

################################################################################
                     [1m Learning iteration 168/3000 [0m                      

                       Computation: 92401 steps/s (collection: 0.940s, learning 0.124s)
               Value function loss: 0.1484
                    Surrogate loss: -0.0007
             Mean action noise std: 0.4115
                     Learning rate: 0.0009
                       Mean reward: -0.94
               Mean episode length: 44.10
       Episode_Reward/keep_balance: 0.0449
     Episode_Reward/rew_lin_vel_xy: 0.0435
      Episode_Reward/rew_ang_vel_z: 0.1422
    Episode_Reward/pen_base_height: -0.1067
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0039
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0099
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0461
Metrics/base_velocity/error_vel_xy: 0.2322
Metrics/base_velocity/error_vel_yaw: 0.0358
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.6667
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 1.06s
                        Total time: 186.40s
                               ETA: 3123.5s

################################################################################
                     [1m Learning iteration 169/3000 [0m                      

                       Computation: 92784 steps/s (collection: 0.936s, learning 0.124s)
               Value function loss: 0.1712
                    Surrogate loss: 0.0022
             Mean action noise std: 0.4114
                     Learning rate: 0.0003
                       Mean reward: -0.73
               Mean episode length: 46.92
       Episode_Reward/keep_balance: 0.0452
     Episode_Reward/rew_lin_vel_xy: 0.0449
      Episode_Reward/rew_ang_vel_z: 0.1434
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0099
Episode_Reward/pen_flat_orientation: -0.0552
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0463
Metrics/base_velocity/error_vel_xy: 0.2336
Metrics/base_velocity/error_vel_yaw: 0.0354
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 89.7083
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 1.06s
                        Total time: 187.46s
                               ETA: 3121.7s

################################################################################
                     [1m Learning iteration 170/3000 [0m                      

                       Computation: 92622 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 0.1688
                    Surrogate loss: -0.0011
             Mean action noise std: 0.4109
                     Learning rate: 0.0006
                       Mean reward: -0.96
               Mean episode length: 45.86
       Episode_Reward/keep_balance: 0.0454
     Episode_Reward/rew_lin_vel_xy: 0.0452
      Episode_Reward/rew_ang_vel_z: 0.1446
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0100
Episode_Reward/pen_flat_orientation: -0.0549
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0467
Metrics/base_velocity/error_vel_xy: 0.2347
Metrics/base_velocity/error_vel_yaw: 0.0352
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 92.2083
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 1.06s
                        Total time: 188.52s
                               ETA: 3119.9s

################################################################################
                     [1m Learning iteration 171/3000 [0m                      

                       Computation: 92231 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.1778
                    Surrogate loss: 0.0012
             Mean action noise std: 0.4107
                     Learning rate: 0.0003
                       Mean reward: -0.92
               Mean episode length: 45.22
       Episode_Reward/keep_balance: 0.0452
     Episode_Reward/rew_lin_vel_xy: 0.0442
      Episode_Reward/rew_ang_vel_z: 0.1431
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0099
Episode_Reward/pen_flat_orientation: -0.0546
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0466
Metrics/base_velocity/error_vel_xy: 0.2337
Metrics/base_velocity/error_vel_yaw: 0.0357
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.9583
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 1.07s
                        Total time: 189.58s
                               ETA: 3118.2s

################################################################################
                     [1m Learning iteration 172/3000 [0m                      

                       Computation: 91845 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 0.1679
                    Surrogate loss: -0.0017
             Mean action noise std: 0.4097
                     Learning rate: 0.0006
                       Mean reward: -1.01
               Mean episode length: 44.16
       Episode_Reward/keep_balance: 0.0458
     Episode_Reward/rew_lin_vel_xy: 0.0465
      Episode_Reward/rew_ang_vel_z: 0.1453
    Episode_Reward/pen_base_height: -0.1065
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0101
Episode_Reward/pen_flat_orientation: -0.0550
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0472
Metrics/base_velocity/error_vel_xy: 0.2325
Metrics/base_velocity/error_vel_yaw: 0.0362
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 91.4583
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 1.07s
                        Total time: 190.65s
                               ETA: 3116.6s

################################################################################
                     [1m Learning iteration 173/3000 [0m                      

                       Computation: 92702 steps/s (collection: 0.938s, learning 0.122s)
               Value function loss: 0.1832
                    Surrogate loss: 0.0011
             Mean action noise std: 0.4088
                     Learning rate: 0.0009
                       Mean reward: -0.67
               Mean episode length: 46.71
       Episode_Reward/keep_balance: 0.0458
     Episode_Reward/rew_lin_vel_xy: 0.0470
      Episode_Reward/rew_ang_vel_z: 0.1451
    Episode_Reward/pen_base_height: -0.1057
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0100
Episode_Reward/pen_flat_orientation: -0.0542
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2347
Metrics/base_velocity/error_vel_yaw: 0.0359
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 91.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 1.06s
                        Total time: 191.71s
                               ETA: 3114.8s

################################################################################
                     [1m Learning iteration 174/3000 [0m                      

                       Computation: 92599 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 0.1722
                    Surrogate loss: 0.0038
             Mean action noise std: 0.4087
                     Learning rate: 0.0003
                       Mean reward: -1.01
               Mean episode length: 44.19
       Episode_Reward/keep_balance: 0.0452
     Episode_Reward/rew_lin_vel_xy: 0.0449
      Episode_Reward/rew_ang_vel_z: 0.1433
    Episode_Reward/pen_base_height: -0.1053
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0099
Episode_Reward/pen_flat_orientation: -0.0532
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0463
Metrics/base_velocity/error_vel_xy: 0.2336
Metrics/base_velocity/error_vel_yaw: 0.0352
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.0833
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 1.06s
                        Total time: 192.78s
                               ETA: 3113.1s

################################################################################
                     [1m Learning iteration 175/3000 [0m                      

                       Computation: 91057 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.1622
                    Surrogate loss: -0.0006
             Mean action noise std: 0.4086
                     Learning rate: 0.0004
                       Mean reward: -0.94
               Mean episode length: 44.27
       Episode_Reward/keep_balance: 0.0456
     Episode_Reward/rew_lin_vel_xy: 0.0446
      Episode_Reward/rew_ang_vel_z: 0.1445
    Episode_Reward/pen_base_height: -0.1053
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0099
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0467
Metrics/base_velocity/error_vel_xy: 0.2377
Metrics/base_velocity/error_vel_yaw: 0.0359
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.2917
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 1.08s
                        Total time: 193.86s
                               ETA: 3111.6s

################################################################################
                     [1m Learning iteration 176/3000 [0m                      

                       Computation: 89642 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 0.1645
                    Surrogate loss: -0.0002
             Mean action noise std: 0.4078
                     Learning rate: 0.0006
                       Mean reward: -0.85
               Mean episode length: 45.52
       Episode_Reward/keep_balance: 0.0460
     Episode_Reward/rew_lin_vel_xy: 0.0462
      Episode_Reward/rew_ang_vel_z: 0.1464
    Episode_Reward/pen_base_height: -0.1056
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0041
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0100
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0470
Metrics/base_velocity/error_vel_xy: 0.2361
Metrics/base_velocity/error_vel_yaw: 0.0360
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 91.3333
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 1.10s
                        Total time: 194.95s
                               ETA: 3110.4s

################################################################################
                     [1m Learning iteration 177/3000 [0m                      

                       Computation: 91319 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.1479
                    Surrogate loss: 0.0022
             Mean action noise std: 0.4073
                     Learning rate: 0.0004
                       Mean reward: -0.95
               Mean episode length: 45.41
       Episode_Reward/keep_balance: 0.0457
     Episode_Reward/rew_lin_vel_xy: 0.0444
      Episode_Reward/rew_ang_vel_z: 0.1459
    Episode_Reward/pen_base_height: -0.1055
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0041
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0099
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0467
Metrics/base_velocity/error_vel_xy: 0.2385
Metrics/base_velocity/error_vel_yaw: 0.0349
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.1250
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 1.08s
                        Total time: 196.03s
                               ETA: 3108.9s

################################################################################
                     [1m Learning iteration 178/3000 [0m                      

                       Computation: 92486 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 0.1616
                    Surrogate loss: 0.0030
             Mean action noise std: 0.4072
                     Learning rate: 0.0003
                       Mean reward: -0.85
               Mean episode length: 44.70
       Episode_Reward/keep_balance: 0.0457
     Episode_Reward/rew_lin_vel_xy: 0.0460
      Episode_Reward/rew_ang_vel_z: 0.1454
    Episode_Reward/pen_base_height: -0.1056
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0041
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0099
Episode_Reward/pen_flat_orientation: -0.0539
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0466
Metrics/base_velocity/error_vel_xy: 0.2322
Metrics/base_velocity/error_vel_yaw: 0.0356
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.2083
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 1.06s
                        Total time: 197.09s
                               ETA: 3107.2s

################################################################################
                     [1m Learning iteration 179/3000 [0m                      

                       Computation: 92684 steps/s (collection: 0.938s, learning 0.122s)
               Value function loss: 0.1594
                    Surrogate loss: -0.0017
             Mean action noise std: 0.4067
                     Learning rate: 0.0004
                       Mean reward: -0.87
               Mean episode length: 45.75
       Episode_Reward/keep_balance: 0.0462
     Episode_Reward/rew_lin_vel_xy: 0.0461
      Episode_Reward/rew_ang_vel_z: 0.1465
    Episode_Reward/pen_base_height: -0.1063
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0041
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0099
Episode_Reward/pen_flat_orientation: -0.0549
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2378
Metrics/base_velocity/error_vel_yaw: 0.0360
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.9583
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 1.06s
                        Total time: 198.15s
                               ETA: 3105.5s

################################################################################
                     [1m Learning iteration 180/3000 [0m                      

                       Computation: 91900 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.1871
                    Surrogate loss: -0.0003
             Mean action noise std: 0.4064
                     Learning rate: 0.0009
                       Mean reward: -0.99
               Mean episode length: 44.96
       Episode_Reward/keep_balance: 0.0462
     Episode_Reward/rew_lin_vel_xy: 0.0462
      Episode_Reward/rew_ang_vel_z: 0.1464
    Episode_Reward/pen_base_height: -0.1064
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0041
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0100
Episode_Reward/pen_flat_orientation: -0.0547
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0468
Metrics/base_velocity/error_vel_xy: 0.2389
Metrics/base_velocity/error_vel_yaw: 0.0362
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.6667
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 1.07s
                        Total time: 199.22s
                               ETA: 3103.9s

################################################################################
                     [1m Learning iteration 181/3000 [0m                      

                       Computation: 93052 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 0.1944
                    Surrogate loss: 0.0005
             Mean action noise std: 0.4064
                     Learning rate: 0.0006
                       Mean reward: -0.68
               Mean episode length: 47.03
       Episode_Reward/keep_balance: 0.0462
     Episode_Reward/rew_lin_vel_xy: 0.0465
      Episode_Reward/rew_ang_vel_z: 0.1462
    Episode_Reward/pen_base_height: -0.1065
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0099
Episode_Reward/pen_flat_orientation: -0.0543
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0468
Metrics/base_velocity/error_vel_xy: 0.2361
Metrics/base_velocity/error_vel_yaw: 0.0370
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 1.06s
                        Total time: 200.28s
                               ETA: 3102.1s

################################################################################
                     [1m Learning iteration 182/3000 [0m                      

                       Computation: 93131 steps/s (collection: 0.934s, learning 0.122s)
               Value function loss: 0.1810
                    Surrogate loss: -0.0005
             Mean action noise std: 0.4065
                     Learning rate: 0.0013
                       Mean reward: -0.82
               Mean episode length: 46.83
       Episode_Reward/keep_balance: 0.0465
     Episode_Reward/rew_lin_vel_xy: 0.0464
      Episode_Reward/rew_ang_vel_z: 0.1470
    Episode_Reward/pen_base_height: -0.1057
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0041
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0100
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0470
Metrics/base_velocity/error_vel_xy: 0.2366
Metrics/base_velocity/error_vel_yaw: 0.0367
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.7500
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 1.06s
                        Total time: 201.33s
                               ETA: 3100.3s

################################################################################
                     [1m Learning iteration 183/3000 [0m                      

                       Computation: 92308 steps/s (collection: 0.939s, learning 0.126s)
               Value function loss: 0.1928
                    Surrogate loss: -0.0021
             Mean action noise std: 0.4052
                     Learning rate: 0.0019
                       Mean reward: -0.64
               Mean episode length: 48.68
       Episode_Reward/keep_balance: 0.0463
     Episode_Reward/rew_lin_vel_xy: 0.0468
      Episode_Reward/rew_ang_vel_z: 0.1471
    Episode_Reward/pen_base_height: -0.1048
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0100
Episode_Reward/pen_flat_orientation: -0.0531
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0468
Metrics/base_velocity/error_vel_xy: 0.2403
Metrics/base_velocity/error_vel_yaw: 0.0358
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.9583
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 1.06s
                        Total time: 202.40s
                               ETA: 3098.7s

################################################################################
                     [1m Learning iteration 184/3000 [0m                      

                       Computation: 92997 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 0.2427
                    Surrogate loss: 0.0027
             Mean action noise std: 0.4044
                     Learning rate: 0.0009
                       Mean reward: -0.16
               Mean episode length: 48.05
       Episode_Reward/keep_balance: 0.0465
     Episode_Reward/rew_lin_vel_xy: 0.0476
      Episode_Reward/rew_ang_vel_z: 0.1478
    Episode_Reward/pen_base_height: -0.1052
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0100
Episode_Reward/pen_flat_orientation: -0.0534
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0466
Metrics/base_velocity/error_vel_xy: 0.2390
Metrics/base_velocity/error_vel_yaw: 0.0361
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.2917
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 1.06s
                        Total time: 203.46s
                               ETA: 3096.9s

################################################################################
                     [1m Learning iteration 185/3000 [0m                      

                       Computation: 91824 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 0.1664
                    Surrogate loss: 0.0046
             Mean action noise std: 0.4043
                     Learning rate: 0.0002
                       Mean reward: -1.06
               Mean episode length: 45.39
       Episode_Reward/keep_balance: 0.0468
     Episode_Reward/rew_lin_vel_xy: 0.0461
      Episode_Reward/rew_ang_vel_z: 0.1488
    Episode_Reward/pen_base_height: -0.1060
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0101
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2408
Metrics/base_velocity/error_vel_yaw: 0.0366
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.0417
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 1.07s
                        Total time: 204.53s
                               ETA: 3095.4s

################################################################################
                     [1m Learning iteration 186/3000 [0m                      

                       Computation: 91898 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 0.1549
                    Surrogate loss: -0.0016
             Mean action noise std: 0.4035
                     Learning rate: 0.0006
                       Mean reward: -0.52
               Mean episode length: 48.83
       Episode_Reward/keep_balance: 0.0471
     Episode_Reward/rew_lin_vel_xy: 0.0467
      Episode_Reward/rew_ang_vel_z: 0.1497
    Episode_Reward/pen_base_height: -0.1065
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0101
Episode_Reward/pen_flat_orientation: -0.0546
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2430
Metrics/base_velocity/error_vel_yaw: 0.0370
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 89.0833
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 1.07s
                        Total time: 205.60s
                               ETA: 3093.8s

################################################################################
                     [1m Learning iteration 187/3000 [0m                      

                       Computation: 92802 steps/s (collection: 0.936s, learning 0.123s)
               Value function loss: 0.1612
                    Surrogate loss: -0.0006
             Mean action noise std: 0.4033
                     Learning rate: 0.0004
                       Mean reward: -0.72
               Mean episode length: 45.80
       Episode_Reward/keep_balance: 0.0465
     Episode_Reward/rew_lin_vel_xy: 0.0481
      Episode_Reward/rew_ang_vel_z: 0.1481
    Episode_Reward/pen_base_height: -0.1060
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0100
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0470
Metrics/base_velocity/error_vel_xy: 0.2361
Metrics/base_velocity/error_vel_yaw: 0.0366
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.8333
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 1.06s
                        Total time: 206.66s
                               ETA: 3092.1s

################################################################################
                     [1m Learning iteration 188/3000 [0m                      

                       Computation: 91665 steps/s (collection: 0.946s, learning 0.126s)
               Value function loss: 0.1762
                    Surrogate loss: -0.0014
             Mean action noise std: 0.4034
                     Learning rate: 0.0009
                       Mean reward: -0.58
               Mean episode length: 46.77
       Episode_Reward/keep_balance: 0.0471
     Episode_Reward/rew_lin_vel_xy: 0.0468
      Episode_Reward/rew_ang_vel_z: 0.1500
    Episode_Reward/pen_base_height: -0.1061
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0102
Episode_Reward/pen_flat_orientation: -0.0539
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0043
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2441
Metrics/base_velocity/error_vel_yaw: 0.0372
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.3333
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 1.07s
                        Total time: 207.73s
                               ETA: 3090.6s

################################################################################
                     [1m Learning iteration 189/3000 [0m                      

                       Computation: 91591 steps/s (collection: 0.949s, learning 0.124s)
               Value function loss: 0.1891
                    Surrogate loss: 0.0001
             Mean action noise std: 0.4036
                     Learning rate: 0.0009
                       Mean reward: -0.93
               Mean episode length: 45.08
       Episode_Reward/keep_balance: 0.0466
     Episode_Reward/rew_lin_vel_xy: 0.0476
      Episode_Reward/rew_ang_vel_z: 0.1487
    Episode_Reward/pen_base_height: -0.1064
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0100
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0470
Metrics/base_velocity/error_vel_xy: 0.2394
Metrics/base_velocity/error_vel_yaw: 0.0364
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 89.0417
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 1.07s
                        Total time: 208.80s
                               ETA: 3089.2s

################################################################################
                     [1m Learning iteration 190/3000 [0m                      

                       Computation: 93544 steps/s (collection: 0.929s, learning 0.121s)
               Value function loss: 0.1963
                    Surrogate loss: 0.0014
             Mean action noise std: 0.4037
                     Learning rate: 0.0003
                       Mean reward: -0.55
               Mean episode length: 46.75
       Episode_Reward/keep_balance: 0.0465
     Episode_Reward/rew_lin_vel_xy: 0.0475
      Episode_Reward/rew_ang_vel_z: 0.1477
    Episode_Reward/pen_base_height: -0.1058
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0100
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0043
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0466
Metrics/base_velocity/error_vel_xy: 0.2397
Metrics/base_velocity/error_vel_yaw: 0.0368
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.2917
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 1.05s
                        Total time: 209.85s
                               ETA: 3087.4s

################################################################################
                     [1m Learning iteration 191/3000 [0m                      

                       Computation: 92112 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.1879
                    Surrogate loss: -0.0021
             Mean action noise std: 0.4033
                     Learning rate: 0.0006
                       Mean reward: -0.65
               Mean episode length: 48.30
       Episode_Reward/keep_balance: 0.0465
     Episode_Reward/rew_lin_vel_xy: 0.0465
      Episode_Reward/rew_ang_vel_z: 0.1485
    Episode_Reward/pen_base_height: -0.1051
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0099
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0043
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2416
Metrics/base_velocity/error_vel_yaw: 0.0356
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.7083
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 1.07s
                        Total time: 210.92s
                               ETA: 3085.8s

################################################################################
                     [1m Learning iteration 192/3000 [0m                      

                       Computation: 93323 steps/s (collection: 0.932s, learning 0.121s)
               Value function loss: 0.2160
                    Surrogate loss: -0.0015
             Mean action noise std: 0.4032
                     Learning rate: 0.0013
                       Mean reward: -0.87
               Mean episode length: 45.52
       Episode_Reward/keep_balance: 0.0470
     Episode_Reward/rew_lin_vel_xy: 0.0471
      Episode_Reward/rew_ang_vel_z: 0.1500
    Episode_Reward/pen_base_height: -0.1063
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0101
Episode_Reward/pen_flat_orientation: -0.0541
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0043
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2403
Metrics/base_velocity/error_vel_yaw: 0.0360
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.5417
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 1.05s
                        Total time: 211.97s
                               ETA: 3084.0s

################################################################################
                     [1m Learning iteration 193/3000 [0m                      

                       Computation: 93186 steps/s (collection: 0.934s, learning 0.121s)
               Value function loss: 0.2714
                    Surrogate loss: 0.0001
             Mean action noise std: 0.4028
                     Learning rate: 0.0029
                       Mean reward: -0.68
               Mean episode length: 47.14
       Episode_Reward/keep_balance: 0.0474
     Episode_Reward/rew_lin_vel_xy: 0.0471
      Episode_Reward/rew_ang_vel_z: 0.1515
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0102
Episode_Reward/pen_flat_orientation: -0.0543
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0043
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0472
Metrics/base_velocity/error_vel_xy: 0.2418
Metrics/base_velocity/error_vel_yaw: 0.0365
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.1667
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 1.05s
                        Total time: 213.03s
                               ETA: 3082.3s

################################################################################
                     [1m Learning iteration 194/3000 [0m                      

                       Computation: 93462 steps/s (collection: 0.930s, learning 0.122s)
               Value function loss: 0.2934
                    Surrogate loss: -0.0000
             Mean action noise std: 0.4032
                     Learning rate: 0.0029
                       Mean reward: -0.42
               Mean episode length: 48.60
       Episode_Reward/keep_balance: 0.0477
     Episode_Reward/rew_lin_vel_xy: 0.0485
      Episode_Reward/rew_ang_vel_z: 0.1524
    Episode_Reward/pen_base_height: -0.1065
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0102
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0472
Metrics/base_velocity/error_vel_xy: 0.2435
Metrics/base_velocity/error_vel_yaw: 0.0368
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 1.05s
                        Total time: 214.08s
                               ETA: 3080.6s

################################################################################
                     [1m Learning iteration 195/3000 [0m                      

                       Computation: 92697 steps/s (collection: 0.939s, learning 0.121s)
               Value function loss: 0.2868
                    Surrogate loss: 0.0025
             Mean action noise std: 0.4031
                     Learning rate: 0.0004
                       Mean reward: -0.86
               Mean episode length: 46.04
       Episode_Reward/keep_balance: 0.0474
     Episode_Reward/rew_lin_vel_xy: 0.0483
      Episode_Reward/rew_ang_vel_z: 0.1516
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0102
Episode_Reward/pen_flat_orientation: -0.0543
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0472
Metrics/base_velocity/error_vel_xy: 0.2416
Metrics/base_velocity/error_vel_yaw: 0.0366
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.1667
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 1.06s
                        Total time: 215.14s
                               ETA: 3078.9s

################################################################################
                     [1m Learning iteration 196/3000 [0m                      

                       Computation: 93495 steps/s (collection: 0.930s, learning 0.122s)
               Value function loss: 0.2280
                    Surrogate loss: -0.0010
             Mean action noise std: 0.4030
                     Learning rate: 0.0009
                       Mean reward: -0.47
               Mean episode length: 47.31
       Episode_Reward/keep_balance: 0.0467
     Episode_Reward/rew_lin_vel_xy: 0.0459
      Episode_Reward/rew_ang_vel_z: 0.1492
    Episode_Reward/pen_base_height: -0.1064
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0101
Episode_Reward/pen_flat_orientation: -0.0534
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0465
Metrics/base_velocity/error_vel_xy: 0.2417
Metrics/base_velocity/error_vel_yaw: 0.0358
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.1250
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 1.05s
                        Total time: 216.19s
                               ETA: 3077.2s

################################################################################
                     [1m Learning iteration 197/3000 [0m                      

                       Computation: 92969 steps/s (collection: 0.936s, learning 0.122s)
               Value function loss: 0.2585
                    Surrogate loss: 0.0023
             Mean action noise std: 0.4031
                     Learning rate: 0.0006
                       Mean reward: -0.91
               Mean episode length: 45.30
       Episode_Reward/keep_balance: 0.0472
     Episode_Reward/rew_lin_vel_xy: 0.0489
      Episode_Reward/rew_ang_vel_z: 0.1509
    Episode_Reward/pen_base_height: -0.1067
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0102
Episode_Reward/pen_flat_orientation: -0.0532
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2412
Metrics/base_velocity/error_vel_yaw: 0.0364
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.4583
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 1.06s
                        Total time: 217.25s
                               ETA: 3075.5s

################################################################################
                     [1m Learning iteration 198/3000 [0m                      

                       Computation: 92557 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 0.1953
                    Surrogate loss: 0.0007
             Mean action noise std: 0.4030
                     Learning rate: 0.0003
                       Mean reward: -0.67
               Mean episode length: 46.53
       Episode_Reward/keep_balance: 0.0470
     Episode_Reward/rew_lin_vel_xy: 0.0452
      Episode_Reward/rew_ang_vel_z: 0.1501
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0102
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2459
Metrics/base_velocity/error_vel_yaw: 0.0364
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.7917
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 1.06s
                        Total time: 218.31s
                               ETA: 3073.9s

################################################################################
                     [1m Learning iteration 199/3000 [0m                      

                       Computation: 92784 steps/s (collection: 0.937s, learning 0.123s)
               Value function loss: 0.1644
                    Surrogate loss: -0.0009
             Mean action noise std: 0.4028
                     Learning rate: 0.0006
                       Mean reward: -0.73
               Mean episode length: 46.68
       Episode_Reward/keep_balance: 0.0476
     Episode_Reward/rew_lin_vel_xy: 0.0508
      Episode_Reward/rew_ang_vel_z: 0.1523
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0103
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2416
Metrics/base_velocity/error_vel_yaw: 0.0367
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.1250
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 1.06s
                        Total time: 219.37s
                               ETA: 3072.3s

################################################################################
                     [1m Learning iteration 200/3000 [0m                      

                       Computation: 92826 steps/s (collection: 0.937s, learning 0.122s)
               Value function loss: 0.1679
                    Surrogate loss: 0.0014
             Mean action noise std: 0.4025
                     Learning rate: 0.0004
                       Mean reward: -0.66
               Mean episode length: 47.47
       Episode_Reward/keep_balance: 0.0472
     Episode_Reward/rew_lin_vel_xy: 0.0449
      Episode_Reward/rew_ang_vel_z: 0.1505
    Episode_Reward/pen_base_height: -0.1060
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0102
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0467
Metrics/base_velocity/error_vel_xy: 0.2454
Metrics/base_velocity/error_vel_yaw: 0.0363
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.6667
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 1.06s
                        Total time: 220.43s
                               ETA: 3070.7s

################################################################################
                     [1m Learning iteration 201/3000 [0m                      

                       Computation: 92506 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 0.1569
                    Surrogate loss: -0.0004
             Mean action noise std: 0.4023
                     Learning rate: 0.0003
                       Mean reward: -0.70
               Mean episode length: 48.54
       Episode_Reward/keep_balance: 0.0474
     Episode_Reward/rew_lin_vel_xy: 0.0486
      Episode_Reward/rew_ang_vel_z: 0.1521
    Episode_Reward/pen_base_height: -0.1061
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0102
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0470
Metrics/base_velocity/error_vel_xy: 0.2428
Metrics/base_velocity/error_vel_yaw: 0.0357
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.5833
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 1.06s
                        Total time: 221.49s
                               ETA: 3069.1s

################################################################################
                     [1m Learning iteration 202/3000 [0m                      

                       Computation: 91065 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.1576
                    Surrogate loss: -0.0016
             Mean action noise std: 0.4022
                     Learning rate: 0.0004
                       Mean reward: -0.80
               Mean episode length: 46.41
       Episode_Reward/keep_balance: 0.0471
     Episode_Reward/rew_lin_vel_xy: 0.0473
      Episode_Reward/rew_ang_vel_z: 0.1506
    Episode_Reward/pen_base_height: -0.1054
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0102
Episode_Reward/pen_flat_orientation: -0.0523
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0466
Metrics/base_velocity/error_vel_xy: 0.2411
Metrics/base_velocity/error_vel_yaw: 0.0360
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.7500
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 1.08s
                        Total time: 222.57s
                               ETA: 3067.8s

################################################################################
                     [1m Learning iteration 203/3000 [0m                      

                       Computation: 90262 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.1692
                    Surrogate loss: -0.0017
             Mean action noise std: 0.4025
                     Learning rate: 0.0006
                       Mean reward: -0.64
               Mean episode length: 45.68
       Episode_Reward/keep_balance: 0.0474
     Episode_Reward/rew_lin_vel_xy: 0.0467
      Episode_Reward/rew_ang_vel_z: 0.1512
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0103
Episode_Reward/pen_flat_orientation: -0.0534
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0466
Metrics/base_velocity/error_vel_xy: 0.2469
Metrics/base_velocity/error_vel_yaw: 0.0365
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 1.09s
                        Total time: 223.66s
                               ETA: 3066.6s

################################################################################
                     [1m Learning iteration 204/3000 [0m                      

                       Computation: 76126 steps/s (collection: 1.169s, learning 0.122s)
               Value function loss: 0.1743
                    Surrogate loss: 0.0026
             Mean action noise std: 0.4025
                     Learning rate: 0.0003
                       Mean reward: -0.90
               Mean episode length: 45.49
       Episode_Reward/keep_balance: 0.0467
     Episode_Reward/rew_lin_vel_xy: 0.0471
      Episode_Reward/rew_ang_vel_z: 0.1489
    Episode_Reward/pen_base_height: -0.1067
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0102
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2404
Metrics/base_velocity/error_vel_yaw: 0.0360
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.1250
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 1.29s
                        Total time: 224.95s
                               ETA: 3068.1s

################################################################################
                     [1m Learning iteration 205/3000 [0m                      

                       Computation: 90596 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 0.1709
                    Surrogate loss: -0.0012
             Mean action noise std: 0.4024
                     Learning rate: 0.0004
                       Mean reward: -0.51
               Mean episode length: 47.84
       Episode_Reward/keep_balance: 0.0478
     Episode_Reward/rew_lin_vel_xy: 0.0492
      Episode_Reward/rew_ang_vel_z: 0.1530
    Episode_Reward/pen_base_height: -0.1063
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0104
Episode_Reward/pen_flat_orientation: -0.0531
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0470
Metrics/base_velocity/error_vel_xy: 0.2430
Metrics/base_velocity/error_vel_yaw: 0.0362
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 1.09s
                        Total time: 226.04s
                               ETA: 3066.9s

################################################################################
                     [1m Learning iteration 206/3000 [0m                      

                       Computation: 91435 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.1851
                    Surrogate loss: -0.0016
             Mean action noise std: 0.4021
                     Learning rate: 0.0009
                       Mean reward: -0.75
               Mean episode length: 48.85
       Episode_Reward/keep_balance: 0.0473
     Episode_Reward/rew_lin_vel_xy: 0.0444
      Episode_Reward/rew_ang_vel_z: 0.1511
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0103
Episode_Reward/pen_flat_orientation: -0.0544
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0463
Metrics/base_velocity/error_vel_xy: 0.2473
Metrics/base_velocity/error_vel_yaw: 0.0363
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.7500
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 1.08s
                        Total time: 227.11s
                               ETA: 3065.5s

################################################################################
                     [1m Learning iteration 207/3000 [0m                      

                       Computation: 91565 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.1790
                    Surrogate loss: 0.0011
             Mean action noise std: 0.4017
                     Learning rate: 0.0004
                       Mean reward: -0.56
               Mean episode length: 49.67
       Episode_Reward/keep_balance: 0.0477
     Episode_Reward/rew_lin_vel_xy: 0.0489
      Episode_Reward/rew_ang_vel_z: 0.1532
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0103
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0470
Metrics/base_velocity/error_vel_xy: 0.2437
Metrics/base_velocity/error_vel_yaw: 0.0360
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.0417
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 1.07s
                        Total time: 228.19s
                               ETA: 3064.1s

################################################################################
                     [1m Learning iteration 208/3000 [0m                      

                       Computation: 91661 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.1734
                    Surrogate loss: 0.0003
             Mean action noise std: 0.4015
                     Learning rate: 0.0006
                       Mean reward: -0.43
               Mean episode length: 49.54
       Episode_Reward/keep_balance: 0.0476
     Episode_Reward/rew_lin_vel_xy: 0.0497
      Episode_Reward/rew_ang_vel_z: 0.1525
    Episode_Reward/pen_base_height: -0.1061
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0103
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0467
Metrics/base_velocity/error_vel_xy: 0.2440
Metrics/base_velocity/error_vel_yaw: 0.0363
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.9583
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 1.07s
                        Total time: 229.26s
                               ETA: 3062.6s

################################################################################
                     [1m Learning iteration 209/3000 [0m                      

                       Computation: 90409 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.1985
                    Surrogate loss: 0.0005
             Mean action noise std: 0.4019
                     Learning rate: 0.0004
                       Mean reward: -0.39
               Mean episode length: 49.47
       Episode_Reward/keep_balance: 0.0477
     Episode_Reward/rew_lin_vel_xy: 0.0468
      Episode_Reward/rew_ang_vel_z: 0.1525
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0103
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0465
Metrics/base_velocity/error_vel_xy: 0.2470
Metrics/base_velocity/error_vel_yaw: 0.0367
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.7083
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 1.09s
                        Total time: 230.35s
                               ETA: 3061.4s

################################################################################
                     [1m Learning iteration 210/3000 [0m                      

                       Computation: 90382 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.2024
                    Surrogate loss: 0.0003
             Mean action noise std: 0.4020
                     Learning rate: 0.0002
                       Mean reward: -0.53
               Mean episode length: 48.04
       Episode_Reward/keep_balance: 0.0480
     Episode_Reward/rew_lin_vel_xy: 0.0479
      Episode_Reward/rew_ang_vel_z: 0.1536
    Episode_Reward/pen_base_height: -0.1065
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0046
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0104
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0468
Metrics/base_velocity/error_vel_xy: 0.2480
Metrics/base_velocity/error_vel_yaw: 0.0366
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 1.09s
                        Total time: 231.43s
                               ETA: 3060.2s

################################################################################
                     [1m Learning iteration 211/3000 [0m                      

                       Computation: 90976 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.1930
                    Surrogate loss: -0.0020
             Mean action noise std: 0.4018
                     Learning rate: 0.0004
                       Mean reward: -0.61
               Mean episode length: 45.92
       Episode_Reward/keep_balance: 0.0480
     Episode_Reward/rew_lin_vel_xy: 0.0466
      Episode_Reward/rew_ang_vel_z: 0.1536
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0046
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0103
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2487
Metrics/base_velocity/error_vel_yaw: 0.0365
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 89.1667
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 1.08s
                        Total time: 232.51s
                               ETA: 3058.9s

################################################################################
                     [1m Learning iteration 212/3000 [0m                      

                       Computation: 91718 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.2037
                    Surrogate loss: -0.0010
             Mean action noise std: 0.4021
                     Learning rate: 0.0009
                       Mean reward: -0.52
               Mean episode length: 47.93
       Episode_Reward/keep_balance: 0.0479
     Episode_Reward/rew_lin_vel_xy: 0.0496
      Episode_Reward/rew_ang_vel_z: 0.1529
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0046
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0103
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0468
Metrics/base_velocity/error_vel_xy: 0.2445
Metrics/base_velocity/error_vel_yaw: 0.0372
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 1.07s
                        Total time: 233.59s
                               ETA: 3057.5s

################################################################################
                     [1m Learning iteration 213/3000 [0m                      

                       Computation: 90849 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.2344
                    Surrogate loss: -0.0016
             Mean action noise std: 0.4031
                     Learning rate: 0.0019
                       Mean reward: -0.19
               Mean episode length: 49.25
       Episode_Reward/keep_balance: 0.0484
     Episode_Reward/rew_lin_vel_xy: 0.0506
      Episode_Reward/rew_ang_vel_z: 0.1553
    Episode_Reward/pen_base_height: -0.1064
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0047
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0105
Episode_Reward/pen_flat_orientation: -0.0527
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2458
Metrics/base_velocity/error_vel_yaw: 0.0365
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 1.08s
                        Total time: 234.67s
                               ETA: 3056.2s

################################################################################
                     [1m Learning iteration 214/3000 [0m                      

                       Computation: 90834 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.2714
                    Surrogate loss: 0.0037
             Mean action noise std: 0.4036
                     Learning rate: 0.0006
                       Mean reward: -0.44
               Mean episode length: 48.35
       Episode_Reward/keep_balance: 0.0485
     Episode_Reward/rew_lin_vel_xy: 0.0505
      Episode_Reward/rew_ang_vel_z: 0.1555
    Episode_Reward/pen_base_height: -0.1058
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0047
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0106
Episode_Reward/pen_flat_orientation: -0.0527
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2471
Metrics/base_velocity/error_vel_yaw: 0.0370
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.9167
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 1.08s
                        Total time: 235.75s
                               ETA: 3054.9s

################################################################################
                     [1m Learning iteration 215/3000 [0m                      

                       Computation: 91138 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.1922
                    Surrogate loss: -0.0013
             Mean action noise std: 0.4034
                     Learning rate: 0.0009
                       Mean reward: -0.72
               Mean episode length: 48.48
       Episode_Reward/keep_balance: 0.0486
     Episode_Reward/rew_lin_vel_xy: 0.0496
      Episode_Reward/rew_ang_vel_z: 0.1556
    Episode_Reward/pen_base_height: -0.1063
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0047
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0105
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2474
Metrics/base_velocity/error_vel_yaw: 0.0367
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.3750
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 1.08s
                        Total time: 236.83s
                               ETA: 3053.6s

################################################################################
                     [1m Learning iteration 216/3000 [0m                      

                       Computation: 91714 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 0.1702
                    Surrogate loss: -0.0002
             Mean action noise std: 0.4029
                     Learning rate: 0.0009
                       Mean reward: -0.24
               Mean episode length: 49.07
       Episode_Reward/keep_balance: 0.0487
     Episode_Reward/rew_lin_vel_xy: 0.0539
      Episode_Reward/rew_ang_vel_z: 0.1557
    Episode_Reward/pen_base_height: -0.1067
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0047
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0106
Episode_Reward/pen_flat_orientation: -0.0527
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2481
Metrics/base_velocity/error_vel_yaw: 0.0371
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.3750
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 1.07s
                        Total time: 237.90s
                               ETA: 3052.1s

################################################################################
                     [1m Learning iteration 217/3000 [0m                      

                       Computation: 88933 steps/s (collection: 0.979s, learning 0.127s)
               Value function loss: 0.1732
                    Surrogate loss: 0.0053
             Mean action noise std: 0.4029
                     Learning rate: 0.0001
                       Mean reward: -0.56
               Mean episode length: 47.93
       Episode_Reward/keep_balance: 0.0485
     Episode_Reward/rew_lin_vel_xy: 0.0514
      Episode_Reward/rew_ang_vel_z: 0.1549
    Episode_Reward/pen_base_height: -0.1067
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0047
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0105
Episode_Reward/pen_flat_orientation: -0.0532
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0472
Metrics/base_velocity/error_vel_xy: 0.2463
Metrics/base_velocity/error_vel_yaw: 0.0372
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.2917
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 1.11s
                        Total time: 239.01s
                               ETA: 3051.2s

################################################################################
                     [1m Learning iteration 218/3000 [0m                      

                       Computation: 90880 steps/s (collection: 0.956s, learning 0.126s)
               Value function loss: 0.1732
                    Surrogate loss: -0.0010
             Mean action noise std: 0.4029
                     Learning rate: 0.0003
                       Mean reward: -0.49
               Mean episode length: 47.99
       Episode_Reward/keep_balance: 0.0487
     Episode_Reward/rew_lin_vel_xy: 0.0485
      Episode_Reward/rew_ang_vel_z: 0.1551
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0048
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0106
Episode_Reward/pen_flat_orientation: -0.0527
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2539
Metrics/base_velocity/error_vel_yaw: 0.0374
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.7917
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 1.08s
                        Total time: 240.09s
                               ETA: 3049.9s

################################################################################
                     [1m Learning iteration 219/3000 [0m                      

                       Computation: 91893 steps/s (collection: 0.943s, learning 0.127s)
               Value function loss: 0.1598
                    Surrogate loss: -0.0014
             Mean action noise std: 0.4032
                     Learning rate: 0.0006
                       Mean reward: -0.43
               Mean episode length: 48.05
       Episode_Reward/keep_balance: 0.0489
     Episode_Reward/rew_lin_vel_xy: 0.0506
      Episode_Reward/rew_ang_vel_z: 0.1568
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0048
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0106
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2511
Metrics/base_velocity/error_vel_yaw: 0.0369
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.9167
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 1.07s
                        Total time: 241.16s
                               ETA: 3048.5s

################################################################################
                     [1m Learning iteration 220/3000 [0m                      

                       Computation: 90932 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 0.1883
                    Surrogate loss: 0.0003
             Mean action noise std: 0.4035
                     Learning rate: 0.0003
                       Mean reward: -0.44
               Mean episode length: 50.18
       Episode_Reward/keep_balance: 0.0491
     Episode_Reward/rew_lin_vel_xy: 0.0519
      Episode_Reward/rew_ang_vel_z: 0.1567
    Episode_Reward/pen_base_height: -0.1088
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0048
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0108
Episode_Reward/pen_flat_orientation: -0.0542
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2484
Metrics/base_velocity/error_vel_yaw: 0.0377
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.7917
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 1.08s
                        Total time: 242.24s
                               ETA: 3047.2s

################################################################################
                     [1m Learning iteration 221/3000 [0m                      

                       Computation: 91440 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.1743
                    Surrogate loss: -0.0010
             Mean action noise std: 0.4034
                     Learning rate: 0.0004
                       Mean reward: -0.12
               Mean episode length: 49.93
       Episode_Reward/keep_balance: 0.0489
     Episode_Reward/rew_lin_vel_xy: 0.0502
      Episode_Reward/rew_ang_vel_z: 0.1563
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0048
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0107
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2507
Metrics/base_velocity/error_vel_yaw: 0.0373
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.7917
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 1.08s
                        Total time: 243.31s
                               ETA: 3045.8s

################################################################################
                     [1m Learning iteration 222/3000 [0m                      

                       Computation: 91034 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.1758
                    Surrogate loss: 0.0008
             Mean action noise std: 0.4033
                     Learning rate: 0.0004
                       Mean reward: -0.71
               Mean episode length: 48.04
       Episode_Reward/keep_balance: 0.0493
     Episode_Reward/rew_lin_vel_xy: 0.0496
      Episode_Reward/rew_ang_vel_z: 0.1578
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0108
Episode_Reward/pen_flat_orientation: -0.0532
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2543
Metrics/base_velocity/error_vel_yaw: 0.0373
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.9583
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 1.08s
                        Total time: 244.39s
                               ETA: 3044.5s

################################################################################
                     [1m Learning iteration 223/3000 [0m                      

                       Computation: 92209 steps/s (collection: 0.943s, learning 0.123s)
               Value function loss: 0.1960
                    Surrogate loss: -0.0002
             Mean action noise std: 0.4034
                     Learning rate: 0.0004
                       Mean reward: -0.24
               Mean episode length: 50.44
       Episode_Reward/keep_balance: 0.0491
     Episode_Reward/rew_lin_vel_xy: 0.0506
      Episode_Reward/rew_ang_vel_z: 0.1569
    Episode_Reward/pen_base_height: -0.1081
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0107
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0049
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2540
Metrics/base_velocity/error_vel_yaw: 0.0375
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.7500
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 1.07s
                        Total time: 245.46s
                               ETA: 3043.0s

################################################################################
                     [1m Learning iteration 224/3000 [0m                      

                       Computation: 90665 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.1971
                    Surrogate loss: 0.0005
             Mean action noise std: 0.4033
                     Learning rate: 0.0004
                       Mean reward: -0.51
               Mean episode length: 48.45
       Episode_Reward/keep_balance: 0.0488
     Episode_Reward/rew_lin_vel_xy: 0.0523
      Episode_Reward/rew_ang_vel_z: 0.1556
    Episode_Reward/pen_base_height: -0.1076
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0107
Episode_Reward/pen_flat_orientation: -0.0532
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0049
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0472
Metrics/base_velocity/error_vel_xy: 0.2464
Metrics/base_velocity/error_vel_yaw: 0.0374
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.3333
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 1.08s
                        Total time: 246.54s
                               ETA: 3041.8s

################################################################################
                     [1m Learning iteration 225/3000 [0m                      

                       Computation: 90531 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.1933
                    Surrogate loss: 0.0014
             Mean action noise std: 0.4034
                     Learning rate: 0.0002
                       Mean reward: -0.49
               Mean episode length: 50.34
       Episode_Reward/keep_balance: 0.0497
     Episode_Reward/rew_lin_vel_xy: 0.0524
      Episode_Reward/rew_ang_vel_z: 0.1588
    Episode_Reward/pen_base_height: -0.1081
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0109
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2512
Metrics/base_velocity/error_vel_yaw: 0.0378
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.5417
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 1.09s
                        Total time: 247.63s
                               ETA: 3040.6s

################################################################################
                     [1m Learning iteration 226/3000 [0m                      

                       Computation: 91137 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.1961
                    Surrogate loss: -0.0015
             Mean action noise std: 0.4036
                     Learning rate: 0.0004
                       Mean reward: -0.37
               Mean episode length: 47.68
       Episode_Reward/keep_balance: 0.0491
     Episode_Reward/rew_lin_vel_xy: 0.0504
      Episode_Reward/rew_ang_vel_z: 0.1564
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0107
Episode_Reward/pen_flat_orientation: -0.0531
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2514
Metrics/base_velocity/error_vel_yaw: 0.0376
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.1250
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 1.08s
                        Total time: 248.71s
                               ETA: 3039.3s

################################################################################
                     [1m Learning iteration 227/3000 [0m                      

                       Computation: 92135 steps/s (collection: 0.943s, learning 0.124s)
               Value function loss: 0.1893
                    Surrogate loss: -0.0005
             Mean action noise std: 0.4038
                     Learning rate: 0.0009
                       Mean reward: -0.13
               Mean episode length: 51.03
       Episode_Reward/keep_balance: 0.0499
     Episode_Reward/rew_lin_vel_xy: 0.0555
      Episode_Reward/rew_ang_vel_z: 0.1593
    Episode_Reward/pen_base_height: -0.1094
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0110
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0480
Metrics/base_velocity/error_vel_xy: 0.2525
Metrics/base_velocity/error_vel_yaw: 0.0383
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.2917
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 1.07s
                        Total time: 249.78s
                               ETA: 3037.8s

################################################################################
                     [1m Learning iteration 228/3000 [0m                      

                       Computation: 91064 steps/s (collection: 0.955s, learning 0.125s)
               Value function loss: 0.2034
                    Surrogate loss: 0.0011
             Mean action noise std: 0.4041
                     Learning rate: 0.0002
                       Mean reward: -0.41
               Mean episode length: 51.30
       Episode_Reward/keep_balance: 0.0498
     Episode_Reward/rew_lin_vel_xy: 0.0504
      Episode_Reward/rew_ang_vel_z: 0.1588
    Episode_Reward/pen_base_height: -0.1082
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0110
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0480
Metrics/base_velocity/error_vel_xy: 0.2587
Metrics/base_velocity/error_vel_yaw: 0.0384
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.3750
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 1.08s
                        Total time: 250.85s
                               ETA: 3036.5s

################################################################################
                     [1m Learning iteration 229/3000 [0m                      

                       Computation: 92308 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.1944
                    Surrogate loss: -0.0018
             Mean action noise std: 0.4040
                     Learning rate: 0.0004
                       Mean reward: -0.61
               Mean episode length: 48.11
       Episode_Reward/keep_balance: 0.0496
     Episode_Reward/rew_lin_vel_xy: 0.0493
      Episode_Reward/rew_ang_vel_z: 0.1580
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0109
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2578
Metrics/base_velocity/error_vel_yaw: 0.0383
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.9583
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 1.06s
                        Total time: 251.92s
                               ETA: 3035.1s

################################################################################
                     [1m Learning iteration 230/3000 [0m                      

                       Computation: 91626 steps/s (collection: 0.949s, learning 0.124s)
               Value function loss: 0.1856
                    Surrogate loss: -0.0020
             Mean action noise std: 0.4035
                     Learning rate: 0.0006
                       Mean reward: -0.53
               Mean episode length: 50.10
       Episode_Reward/keep_balance: 0.0497
     Episode_Reward/rew_lin_vel_xy: 0.0520
      Episode_Reward/rew_ang_vel_z: 0.1585
    Episode_Reward/pen_base_height: -0.1082
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0109
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2566
Metrics/base_velocity/error_vel_yaw: 0.0381
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.1250
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 1.07s
                        Total time: 252.99s
                               ETA: 3033.7s

################################################################################
                     [1m Learning iteration 231/3000 [0m                      

                       Computation: 91813 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.1813
                    Surrogate loss: 0.0017
             Mean action noise std: 0.4033
                     Learning rate: 0.0002
                       Mean reward: -0.75
               Mean episode length: 46.94
       Episode_Reward/keep_balance: 0.0497
     Episode_Reward/rew_lin_vel_xy: 0.0536
      Episode_Reward/rew_ang_vel_z: 0.1589
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0110
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2519
Metrics/base_velocity/error_vel_yaw: 0.0376
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.5417
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 1.07s
                        Total time: 254.06s
                               ETA: 3032.3s

################################################################################
                     [1m Learning iteration 232/3000 [0m                      

                       Computation: 91949 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.1737
                    Surrogate loss: -0.0021
             Mean action noise std: 0.4030
                     Learning rate: 0.0004
                       Mean reward: -0.26
               Mean episode length: 50.34
       Episode_Reward/keep_balance: 0.0493
     Episode_Reward/rew_lin_vel_xy: 0.0507
      Episode_Reward/rew_ang_vel_z: 0.1580
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0108
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0470
Metrics/base_velocity/error_vel_xy: 0.2549
Metrics/base_velocity/error_vel_yaw: 0.0371
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.0833
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 1.07s
                        Total time: 255.13s
                               ETA: 3030.9s

################################################################################
                     [1m Learning iteration 233/3000 [0m                      

                       Computation: 92467 steps/s (collection: 0.939s, learning 0.124s)
               Value function loss: 0.1641
                    Surrogate loss: 0.0000
             Mean action noise std: 0.4026
                     Learning rate: 0.0004
                       Mean reward: -0.45
               Mean episode length: 49.74
       Episode_Reward/keep_balance: 0.0489
     Episode_Reward/rew_lin_vel_xy: 0.0486
      Episode_Reward/rew_ang_vel_z: 0.1565
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0107
Episode_Reward/pen_flat_orientation: -0.0529
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2549
Metrics/base_velocity/error_vel_yaw: 0.0374
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 1.06s
                        Total time: 256.20s
                               ETA: 3029.5s

################################################################################
                     [1m Learning iteration 234/3000 [0m                      

                       Computation: 91737 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.1746
                    Surrogate loss: -0.0018
             Mean action noise std: 0.4017
                     Learning rate: 0.0006
                       Mean reward: -0.36
               Mean episode length: 52.03
       Episode_Reward/keep_balance: 0.0498
     Episode_Reward/rew_lin_vel_xy: 0.0524
      Episode_Reward/rew_ang_vel_z: 0.1598
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0109
Episode_Reward/pen_flat_orientation: -0.0532
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2569
Metrics/base_velocity/error_vel_yaw: 0.0377
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.2917
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 1.07s
                        Total time: 257.27s
                               ETA: 3028.1s

################################################################################
                     [1m Learning iteration 235/3000 [0m                      

                       Computation: 91412 steps/s (collection: 0.950s, learning 0.125s)
               Value function loss: 0.1755
                    Surrogate loss: -0.0003
             Mean action noise std: 0.4020
                     Learning rate: 0.0004
                       Mean reward: -0.67
               Mean episode length: 48.63
       Episode_Reward/keep_balance: 0.0493
     Episode_Reward/rew_lin_vel_xy: 0.0514
      Episode_Reward/rew_ang_vel_z: 0.1578
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0108
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2509
Metrics/base_velocity/error_vel_yaw: 0.0373
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.4583
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 1.08s
                        Total time: 258.34s
                               ETA: 3026.8s

################################################################################
                     [1m Learning iteration 236/3000 [0m                      

                       Computation: 92027 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.1801
                    Surrogate loss: 0.0001
             Mean action noise std: 0.4021
                     Learning rate: 0.0006
                       Mean reward: -0.62
               Mean episode length: 47.36
       Episode_Reward/keep_balance: 0.0494
     Episode_Reward/rew_lin_vel_xy: 0.0499
      Episode_Reward/rew_ang_vel_z: 0.1585
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0107
Episode_Reward/pen_flat_orientation: -0.0527
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2553
Metrics/base_velocity/error_vel_yaw: 0.0374
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.0417
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 1.07s
                        Total time: 259.41s
                               ETA: 3025.4s

################################################################################
                     [1m Learning iteration 237/3000 [0m                      

                       Computation: 93050 steps/s (collection: 0.934s, learning 0.123s)
               Value function loss: 0.1754
                    Surrogate loss: 0.0021
             Mean action noise std: 0.4022
                     Learning rate: 0.0003
                       Mean reward: -0.59
               Mean episode length: 48.21
       Episode_Reward/keep_balance: 0.0492
     Episode_Reward/rew_lin_vel_xy: 0.0495
      Episode_Reward/rew_ang_vel_z: 0.1580
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0108
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2532
Metrics/base_velocity/error_vel_yaw: 0.0371
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.0000
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 1.06s
                        Total time: 260.47s
                               ETA: 3023.8s

################################################################################
                     [1m Learning iteration 238/3000 [0m                      

                       Computation: 92472 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 0.1931
                    Surrogate loss: -0.0025
             Mean action noise std: 0.4024
                     Learning rate: 0.0006
                       Mean reward: -0.24
               Mean episode length: 50.25
       Episode_Reward/keep_balance: 0.0495
     Episode_Reward/rew_lin_vel_xy: 0.0521
      Episode_Reward/rew_ang_vel_z: 0.1594
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0108
Episode_Reward/pen_flat_orientation: -0.0521
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0472
Metrics/base_velocity/error_vel_xy: 0.2539
Metrics/base_velocity/error_vel_yaw: 0.0370
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.3333
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 1.06s
                        Total time: 261.53s
                               ETA: 3022.4s

################################################################################
                     [1m Learning iteration 239/3000 [0m                      

                       Computation: 92585 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 0.1844
                    Surrogate loss: -0.0020
             Mean action noise std: 0.4032
                     Learning rate: 0.0013
                       Mean reward: -0.47
               Mean episode length: 49.32
       Episode_Reward/keep_balance: 0.0495
     Episode_Reward/rew_lin_vel_xy: 0.0494
      Episode_Reward/rew_ang_vel_z: 0.1588
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0125
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0109
Episode_Reward/pen_flat_orientation: -0.0527
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2555
Metrics/base_velocity/error_vel_yaw: 0.0375
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.5833
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 1.06s
                        Total time: 262.59s
                               ETA: 3020.9s

################################################################################
                     [1m Learning iteration 240/3000 [0m                      

                       Computation: 92598 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 0.2373
                    Surrogate loss: -0.0015
             Mean action noise std: 0.4035
                     Learning rate: 0.0019
                       Mean reward: -0.24
               Mean episode length: 50.99
       Episode_Reward/keep_balance: 0.0495
     Episode_Reward/rew_lin_vel_xy: 0.0507
      Episode_Reward/rew_ang_vel_z: 0.1588
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0109
Episode_Reward/pen_flat_orientation: -0.0520
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2567
Metrics/base_velocity/error_vel_yaw: 0.0374
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.9167
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 1.06s
                        Total time: 263.65s
                               ETA: 3019.4s

################################################################################
                     [1m Learning iteration 241/3000 [0m                      

                       Computation: 91630 steps/s (collection: 0.947s, learning 0.126s)
               Value function loss: 0.2494
                    Surrogate loss: 0.0079
             Mean action noise std: 0.4040
                     Learning rate: 0.0001
                       Mean reward: -0.85
               Mean episode length: 47.03
       Episode_Reward/keep_balance: 0.0498
     Episode_Reward/rew_lin_vel_xy: 0.0509
      Episode_Reward/rew_ang_vel_z: 0.1595
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0110
Episode_Reward/pen_flat_orientation: -0.0527
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2592
Metrics/base_velocity/error_vel_yaw: 0.0376
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.1667
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 1.07s
                        Total time: 264.73s
                               ETA: 3018.1s

################################################################################
                     [1m Learning iteration 242/3000 [0m                      

                       Computation: 92301 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.1780
                    Surrogate loss: -0.0013
             Mean action noise std: 0.4044
                     Learning rate: 0.0004
                       Mean reward: -0.35
               Mean episode length: 51.77
       Episode_Reward/keep_balance: 0.0490
     Episode_Reward/rew_lin_vel_xy: 0.0514
      Episode_Reward/rew_ang_vel_z: 0.1572
    Episode_Reward/pen_base_height: -0.1062
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0108
Episode_Reward/pen_flat_orientation: -0.0517
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0467
Metrics/base_velocity/error_vel_xy: 0.2528
Metrics/base_velocity/error_vel_yaw: 0.0367
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.8333
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 1.07s
                        Total time: 265.79s
                               ETA: 3016.7s

################################################################################
                     [1m Learning iteration 243/3000 [0m                      

                       Computation: 91532 steps/s (collection: 0.950s, learning 0.124s)
               Value function loss: 0.1987
                    Surrogate loss: -0.0015
             Mean action noise std: 0.4047
                     Learning rate: 0.0009
                       Mean reward: -0.29
               Mean episode length: 51.38
       Episode_Reward/keep_balance: 0.0497
     Episode_Reward/rew_lin_vel_xy: 0.0537
      Episode_Reward/rew_ang_vel_z: 0.1591
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0109
Episode_Reward/pen_flat_orientation: -0.0525
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2510
Metrics/base_velocity/error_vel_yaw: 0.0377
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.4167
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 1.07s
                        Total time: 266.87s
                               ETA: 3015.4s

################################################################################
                     [1m Learning iteration 244/3000 [0m                      

                       Computation: 93016 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 0.2030
                    Surrogate loss: -0.0021
             Mean action noise std: 0.4045
                     Learning rate: 0.0013
                       Mean reward: -0.61
               Mean episode length: 50.56
       Episode_Reward/keep_balance: 0.0493
     Episode_Reward/rew_lin_vel_xy: 0.0492
      Episode_Reward/rew_ang_vel_z: 0.1577
    Episode_Reward/pen_base_height: -0.1065
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0109
Episode_Reward/pen_flat_orientation: -0.0520
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2559
Metrics/base_velocity/error_vel_yaw: 0.0376
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.9167
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 1.06s
                        Total time: 267.92s
                               ETA: 3013.9s

################################################################################
                     [1m Learning iteration 245/3000 [0m                      

                       Computation: 93130 steps/s (collection: 0.934s, learning 0.122s)
               Value function loss: 0.2327
                    Surrogate loss: -0.0022
             Mean action noise std: 0.4041
                     Learning rate: 0.0019
                       Mean reward: -0.37
               Mean episode length: 49.75
       Episode_Reward/keep_balance: 0.0502
     Episode_Reward/rew_lin_vel_xy: 0.0539
      Episode_Reward/rew_ang_vel_z: 0.1600
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0041
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0111
Episode_Reward/pen_flat_orientation: -0.0531
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2577
Metrics/base_velocity/error_vel_yaw: 0.0385
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.1250
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 1.06s
                        Total time: 268.98s
                               ETA: 3012.3s

################################################################################
                     [1m Learning iteration 246/3000 [0m                      

                       Computation: 93210 steps/s (collection: 0.932s, learning 0.123s)
               Value function loss: 0.2891
                    Surrogate loss: 0.0039
             Mean action noise std: 0.4040
                     Learning rate: 0.0006
                       Mean reward: -0.46
               Mean episode length: 51.68
       Episode_Reward/keep_balance: 0.0501
     Episode_Reward/rew_lin_vel_xy: 0.0526
      Episode_Reward/rew_ang_vel_z: 0.1599
    Episode_Reward/pen_base_height: -0.1081
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0041
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0111
Episode_Reward/pen_flat_orientation: -0.0529
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2582
Metrics/base_velocity/error_vel_yaw: 0.0384
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.7083
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 1.05s
                        Total time: 270.03s
                               ETA: 3010.8s

################################################################################
                     [1m Learning iteration 247/3000 [0m                      

                       Computation: 91320 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.1839
                    Surrogate loss: -0.0007
             Mean action noise std: 0.4039
                     Learning rate: 0.0009
                       Mean reward: -0.05
               Mean episode length: 51.95
       Episode_Reward/keep_balance: 0.0499
     Episode_Reward/rew_lin_vel_xy: 0.0509
      Episode_Reward/rew_ang_vel_z: 0.1593
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0041
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0111
Episode_Reward/pen_flat_orientation: -0.0526
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2557
Metrics/base_velocity/error_vel_yaw: 0.0380
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 1.08s
                        Total time: 271.11s
                               ETA: 3009.5s

################################################################################
                     [1m Learning iteration 248/3000 [0m                      

                       Computation: 90463 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.1625
                    Surrogate loss: -0.0001
             Mean action noise std: 0.4038
                     Learning rate: 0.0004
                       Mean reward: -0.42
               Mean episode length: 49.51
       Episode_Reward/keep_balance: 0.0499
     Episode_Reward/rew_lin_vel_xy: 0.0505
      Episode_Reward/rew_ang_vel_z: 0.1594
    Episode_Reward/pen_base_height: -0.1069
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0110
Episode_Reward/pen_flat_orientation: -0.0524
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2551
Metrics/base_velocity/error_vel_yaw: 0.0378
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.0833
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 1.09s
                        Total time: 272.20s
                               ETA: 3008.4s

################################################################################
                     [1m Learning iteration 249/3000 [0m                      

                       Computation: 91509 steps/s (collection: 0.949s, learning 0.125s)
               Value function loss: 0.1549
                    Surrogate loss: 0.0013
             Mean action noise std: 0.4037
                     Learning rate: 0.0004
                       Mean reward: -0.44
               Mean episode length: 49.93
       Episode_Reward/keep_balance: 0.0500
     Episode_Reward/rew_lin_vel_xy: 0.0525
      Episode_Reward/rew_ang_vel_z: 0.1596
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0110
Episode_Reward/pen_flat_orientation: -0.0526
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2541
Metrics/base_velocity/error_vel_yaw: 0.0382
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.9583
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 1.07s
                        Total time: 273.27s
                               ETA: 3007.1s

################################################################################
                     [1m Learning iteration 250/3000 [0m                      

                       Computation: 92445 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 0.1577
                    Surrogate loss: -0.0027
             Mean action noise std: 0.4036
                     Learning rate: 0.0006
                       Mean reward: -0.54
               Mean episode length: 50.69
       Episode_Reward/keep_balance: 0.0500
     Episode_Reward/rew_lin_vel_xy: 0.0520
      Episode_Reward/rew_ang_vel_z: 0.1595
    Episode_Reward/pen_base_height: -0.1069
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0109
Episode_Reward/pen_flat_orientation: -0.0528
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2584
Metrics/base_velocity/error_vel_yaw: 0.0381
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.0417
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 1.06s
                        Total time: 274.33s
                               ETA: 3005.6s

################################################################################
                     [1m Learning iteration 251/3000 [0m                      

                       Computation: 91280 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.1794
                    Surrogate loss: -0.0014
             Mean action noise std: 0.4036
                     Learning rate: 0.0013
                       Mean reward: -0.20
               Mean episode length: 49.36
       Episode_Reward/keep_balance: 0.0497
     Episode_Reward/rew_lin_vel_xy: 0.0515
      Episode_Reward/rew_ang_vel_z: 0.1592
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0109
Episode_Reward/pen_flat_orientation: -0.0534
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2553
Metrics/base_velocity/error_vel_yaw: 0.0374
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.6667
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 1.08s
                        Total time: 275.41s
                               ETA: 3004.4s

################################################################################
                     [1m Learning iteration 252/3000 [0m                      

                       Computation: 91667 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.1936
                    Surrogate loss: 0.0006
             Mean action noise std: 0.4036
                     Learning rate: 0.0004
                       Mean reward: -0.36
               Mean episode length: 50.35
       Episode_Reward/keep_balance: 0.0504
     Episode_Reward/rew_lin_vel_xy: 0.0531
      Episode_Reward/rew_ang_vel_z: 0.1621
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0041
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0110
Episode_Reward/pen_flat_orientation: -0.0528
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2565
Metrics/base_velocity/error_vel_yaw: 0.0376
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.7500
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 1.07s
                        Total time: 276.48s
                               ETA: 3003.1s

################################################################################
                     [1m Learning iteration 253/3000 [0m                      

                       Computation: 92291 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.1806
                    Surrogate loss: 0.0032
             Mean action noise std: 0.4035
                     Learning rate: 0.0000
                       Mean reward: -0.44
               Mean episode length: 49.75
       Episode_Reward/keep_balance: 0.0501
     Episode_Reward/rew_lin_vel_xy: 0.0508
      Episode_Reward/rew_ang_vel_z: 0.1601
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0041
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0110
Episode_Reward/pen_flat_orientation: -0.0528
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0054
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2579
Metrics/base_velocity/error_vel_yaw: 0.0380
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.3333
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 1.07s
                        Total time: 277.55s
                               ETA: 3001.7s

################################################################################
                     [1m Learning iteration 254/3000 [0m                      

                       Computation: 91749 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 0.1719
                    Surrogate loss: -0.0012
             Mean action noise std: 0.4032
                     Learning rate: 0.0001
                       Mean reward: -0.31
               Mean episode length: 50.27
       Episode_Reward/keep_balance: 0.0503
     Episode_Reward/rew_lin_vel_xy: 0.0534
      Episode_Reward/rew_ang_vel_z: 0.1617
    Episode_Reward/pen_base_height: -0.1067
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0041
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0109
Episode_Reward/pen_flat_orientation: -0.0524
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2571
Metrics/base_velocity/error_vel_yaw: 0.0374
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.2500
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 1.07s
                        Total time: 278.62s
                               ETA: 3000.3s

################################################################################
                     [1m Learning iteration 255/3000 [0m                      

                       Computation: 92336 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 0.1648
                    Surrogate loss: -0.0024
             Mean action noise std: 0.4021
                     Learning rate: 0.0003
                       Mean reward: -0.38
               Mean episode length: 50.88
       Episode_Reward/keep_balance: 0.0508
     Episode_Reward/rew_lin_vel_xy: 0.0518
      Episode_Reward/rew_ang_vel_z: 0.1628
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0041
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0111
Episode_Reward/pen_flat_orientation: -0.0531
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2641
Metrics/base_velocity/error_vel_yaw: 0.0386
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 1.06s
                        Total time: 279.68s
                               ETA: 2999.0s

################################################################################
                     [1m Learning iteration 256/3000 [0m                      

                       Computation: 92175 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 0.1605
                    Surrogate loss: -0.0017
             Mean action noise std: 0.4017
                     Learning rate: 0.0004
                       Mean reward: -0.43
               Mean episode length: 48.15
       Episode_Reward/keep_balance: 0.0503
     Episode_Reward/rew_lin_vel_xy: 0.0529
      Episode_Reward/rew_ang_vel_z: 0.1615
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0041
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0110
Episode_Reward/pen_flat_orientation: -0.0524
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2563
Metrics/base_velocity/error_vel_yaw: 0.0374
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.2500
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 1.07s
                        Total time: 280.75s
                               ETA: 2997.6s

################################################################################
                     [1m Learning iteration 257/3000 [0m                      

                       Computation: 92055 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.1672
                    Surrogate loss: -0.0006
             Mean action noise std: 0.4011
                     Learning rate: 0.0006
                       Mean reward: -0.25
               Mean episode length: 50.06
       Episode_Reward/keep_balance: 0.0506
     Episode_Reward/rew_lin_vel_xy: 0.0530
      Episode_Reward/rew_ang_vel_z: 0.1624
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0041
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0111
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0054
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0480
Metrics/base_velocity/error_vel_xy: 0.2588
Metrics/base_velocity/error_vel_yaw: 0.0378
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 1.07s
                        Total time: 281.82s
                               ETA: 2996.2s

################################################################################
                     [1m Learning iteration 258/3000 [0m                      

                       Computation: 89382 steps/s (collection: 0.942s, learning 0.158s)
               Value function loss: 0.1919
                    Surrogate loss: -0.0006
             Mean action noise std: 0.4009
                     Learning rate: 0.0006
                       Mean reward: -0.21
               Mean episode length: 50.18
       Episode_Reward/keep_balance: 0.0504
     Episode_Reward/rew_lin_vel_xy: 0.0524
      Episode_Reward/rew_ang_vel_z: 0.1618
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0041
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0109
Episode_Reward/pen_flat_orientation: -0.0526
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0054
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2590
Metrics/base_velocity/error_vel_yaw: 0.0377
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.8333
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 1.10s
                        Total time: 282.92s
                               ETA: 2995.2s

################################################################################
                     [1m Learning iteration 259/3000 [0m                      

                       Computation: 90599 steps/s (collection: 0.960s, learning 0.125s)
               Value function loss: 0.1897
                    Surrogate loss: -0.0002
             Mean action noise std: 0.4008
                     Learning rate: 0.0006
                       Mean reward: -0.24
               Mean episode length: 49.79
       Episode_Reward/keep_balance: 0.0506
     Episode_Reward/rew_lin_vel_xy: 0.0525
      Episode_Reward/rew_ang_vel_z: 0.1630
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0041
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0110
Episode_Reward/pen_flat_orientation: -0.0525
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2608
Metrics/base_velocity/error_vel_yaw: 0.0375
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.8750
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 1.09s
                        Total time: 284.00s
                               ETA: 2994.0s

################################################################################
                     [1m Learning iteration 260/3000 [0m                      

                       Computation: 92147 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 0.1994
                    Surrogate loss: -0.0001
             Mean action noise std: 0.4009
                     Learning rate: 0.0006
                       Mean reward: -0.14
               Mean episode length: 51.34
       Episode_Reward/keep_balance: 0.0514
     Episode_Reward/rew_lin_vel_xy: 0.0568
      Episode_Reward/rew_ang_vel_z: 0.1656
    Episode_Reward/pen_base_height: -0.1084
      Episode_Reward/pen_lin_vel_z: -0.0125
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0042
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0112
Episode_Reward/pen_flat_orientation: -0.0529
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0057
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0486
Metrics/base_velocity/error_vel_xy: 0.2606
Metrics/base_velocity/error_vel_yaw: 0.0380
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.0417
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 1.07s
                        Total time: 285.07s
                               ETA: 2992.7s

################################################################################
                     [1m Learning iteration 261/3000 [0m                      

                       Computation: 91808 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.1838
                    Surrogate loss: 0.0007
             Mean action noise std: 0.4015
                     Learning rate: 0.0006
                       Mean reward: -0.31
               Mean episode length: 49.66
       Episode_Reward/keep_balance: 0.0511
     Episode_Reward/rew_lin_vel_xy: 0.0560
      Episode_Reward/rew_ang_vel_z: 0.1645
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0042
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0111
Episode_Reward/pen_flat_orientation: -0.0525
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0483
Metrics/base_velocity/error_vel_xy: 0.2578
Metrics/base_velocity/error_vel_yaw: 0.0377
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.6667
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 1.07s
                        Total time: 286.14s
                               ETA: 2991.4s

################################################################################
                     [1m Learning iteration 262/3000 [0m                      

                       Computation: 91228 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.1910
                    Surrogate loss: 0.0027
             Mean action noise std: 0.4014
                     Learning rate: 0.0003
                       Mean reward: -0.21
               Mean episode length: 53.30
       Episode_Reward/keep_balance: 0.0513
     Episode_Reward/rew_lin_vel_xy: 0.0526
      Episode_Reward/rew_ang_vel_z: 0.1654
    Episode_Reward/pen_base_height: -0.1079
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0042
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0111
Episode_Reward/pen_flat_orientation: -0.0531
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0057
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0483
Metrics/base_velocity/error_vel_xy: 0.2650
Metrics/base_velocity/error_vel_yaw: 0.0379
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.1250
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 1.08s
                        Total time: 287.22s
                               ETA: 2990.1s

################################################################################
                     [1m Learning iteration 263/3000 [0m                      

                       Computation: 91387 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.1930
                    Surrogate loss: -0.0001
             Mean action noise std: 0.4011
                     Learning rate: 0.0003
                       Mean reward: -0.47
               Mean episode length: 51.01
       Episode_Reward/keep_balance: 0.0510
     Episode_Reward/rew_lin_vel_xy: 0.0549
      Episode_Reward/rew_ang_vel_z: 0.1634
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0042
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0111
Episode_Reward/pen_flat_orientation: -0.0529
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0057
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0482
Metrics/base_velocity/error_vel_xy: 0.2601
Metrics/base_velocity/error_vel_yaw: 0.0384
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.0833
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 1.08s
                        Total time: 288.29s
                               ETA: 2988.9s

################################################################################
                     [1m Learning iteration 264/3000 [0m                      

                       Computation: 92159 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 0.1956
                    Surrogate loss: -0.0014
             Mean action noise std: 0.4005
                     Learning rate: 0.0006
                       Mean reward: -0.42
               Mean episode length: 52.15
       Episode_Reward/keep_balance: 0.0510
     Episode_Reward/rew_lin_vel_xy: 0.0550
      Episode_Reward/rew_ang_vel_z: 0.1636
    Episode_Reward/pen_base_height: -0.1087
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0042
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0111
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0481
Metrics/base_velocity/error_vel_xy: 0.2608
Metrics/base_velocity/error_vel_yaw: 0.0380
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 1.07s
                        Total time: 289.36s
                               ETA: 2987.5s

################################################################################
                     [1m Learning iteration 265/3000 [0m                      

                       Computation: 91058 steps/s (collection: 0.951s, learning 0.128s)
               Value function loss: 0.1950
                    Surrogate loss: -0.0004
             Mean action noise std: 0.4001
                     Learning rate: 0.0006
                       Mean reward: -0.21
               Mean episode length: 51.78
       Episode_Reward/keep_balance: 0.0519
     Episode_Reward/rew_lin_vel_xy: 0.0564
      Episode_Reward/rew_ang_vel_z: 0.1664
    Episode_Reward/pen_base_height: -0.1088
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0043
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0114
Episode_Reward/pen_flat_orientation: -0.0529
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0489
Metrics/base_velocity/error_vel_xy: 0.2609
Metrics/base_velocity/error_vel_yaw: 0.0391
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.7917
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 1.08s
                        Total time: 290.44s
                               ETA: 2986.3s

################################################################################
                     [1m Learning iteration 266/3000 [0m                      

                       Computation: 92097 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 0.2085
                    Surrogate loss: -0.0009
             Mean action noise std: 0.3999
                     Learning rate: 0.0004
                       Mean reward: -0.37
               Mean episode length: 51.70
       Episode_Reward/keep_balance: 0.0515
     Episode_Reward/rew_lin_vel_xy: 0.0544
      Episode_Reward/rew_ang_vel_z: 0.1649
    Episode_Reward/pen_base_height: -0.1081
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0043
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0112
Episode_Reward/pen_flat_orientation: -0.0522
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0484
Metrics/base_velocity/error_vel_xy: 0.2636
Metrics/base_velocity/error_vel_yaw: 0.0388
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.9583
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 1.07s
                        Total time: 291.51s
                               ETA: 2984.9s

################################################################################
                     [1m Learning iteration 267/3000 [0m                      

                       Computation: 91329 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.2246
                    Surrogate loss: 0.0006
             Mean action noise std: 0.4002
                     Learning rate: 0.0009
                       Mean reward: -0.39
               Mean episode length: 52.61
       Episode_Reward/keep_balance: 0.0519
     Episode_Reward/rew_lin_vel_xy: 0.0562
      Episode_Reward/rew_ang_vel_z: 0.1664
    Episode_Reward/pen_base_height: -0.1092
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0221
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0043
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0114
Episode_Reward/pen_flat_orientation: -0.0529
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0074
   Episode_Reward/test_gait_reward: -0.0488
Metrics/base_velocity/error_vel_xy: 0.2624
Metrics/base_velocity/error_vel_yaw: 0.0393
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.8333
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 1.08s
                        Total time: 292.58s
                               ETA: 2983.7s

################################################################################
                     [1m Learning iteration 268/3000 [0m                      

                       Computation: 92053 steps/s (collection: 0.944s, learning 0.124s)
               Value function loss: 0.2290
                    Surrogate loss: -0.0016
             Mean action noise std: 0.3997
                     Learning rate: 0.0013
                       Mean reward: -0.28
               Mean episode length: 51.11
       Episode_Reward/keep_balance: 0.0524
     Episode_Reward/rew_lin_vel_xy: 0.0576
      Episode_Reward/rew_ang_vel_z: 0.1685
    Episode_Reward/pen_base_height: -0.1094
      Episode_Reward/pen_lin_vel_z: -0.0125
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0044
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0115
Episode_Reward/pen_flat_orientation: -0.0534
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0074
   Episode_Reward/test_gait_reward: -0.0489
Metrics/base_velocity/error_vel_xy: 0.2686
Metrics/base_velocity/error_vel_yaw: 0.0388
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.4583
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 1.07s
                        Total time: 293.65s
                               ETA: 2982.4s

################################################################################
                     [1m Learning iteration 269/3000 [0m                      

                       Computation: 92322 steps/s (collection: 0.941s, learning 0.124s)
               Value function loss: 0.2349
                    Surrogate loss: 0.0017
             Mean action noise std: 0.3998
                     Learning rate: 0.0004
                       Mean reward: -0.44
               Mean episode length: 51.22
       Episode_Reward/keep_balance: 0.0519
     Episode_Reward/rew_lin_vel_xy: 0.0550
      Episode_Reward/rew_ang_vel_z: 0.1667
    Episode_Reward/pen_base_height: -0.1089
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0044
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0114
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0486
Metrics/base_velocity/error_vel_xy: 0.2669
Metrics/base_velocity/error_vel_yaw: 0.0388
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 1.06s
                        Total time: 294.72s
                               ETA: 2981.0s

################################################################################
                     [1m Learning iteration 270/3000 [0m                      

                       Computation: 91365 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.2264
                    Surrogate loss: -0.0003
             Mean action noise std: 0.4003
                     Learning rate: 0.0006
                       Mean reward: -0.37
               Mean episode length: 51.05
       Episode_Reward/keep_balance: 0.0520
     Episode_Reward/rew_lin_vel_xy: 0.0572
      Episode_Reward/rew_ang_vel_z: 0.1667
    Episode_Reward/pen_base_height: -0.1095
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0058
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0044
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0114
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0063
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0484
Metrics/base_velocity/error_vel_xy: 0.2620
Metrics/base_velocity/error_vel_yaw: 0.0391
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.6250
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 1.08s
                        Total time: 295.79s
                               ETA: 2979.8s

################################################################################
                     [1m Learning iteration 271/3000 [0m                      

                       Computation: 91097 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.2095
                    Surrogate loss: -0.0010
             Mean action noise std: 0.3997
                     Learning rate: 0.0004
                       Mean reward: -0.51
               Mean episode length: 50.81
       Episode_Reward/keep_balance: 0.0519
     Episode_Reward/rew_lin_vel_xy: 0.0566
      Episode_Reward/rew_ang_vel_z: 0.1660
    Episode_Reward/pen_base_height: -0.1089
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0044
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0114
Episode_Reward/pen_flat_orientation: -0.0532
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0074
   Episode_Reward/test_gait_reward: -0.0483
Metrics/base_velocity/error_vel_xy: 0.2639
Metrics/base_velocity/error_vel_yaw: 0.0394
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 1.08s
                        Total time: 296.87s
                               ETA: 2978.5s

################################################################################
                     [1m Learning iteration 272/3000 [0m                      

                       Computation: 91155 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.2026
                    Surrogate loss: -0.0007
             Mean action noise std: 0.4001
                     Learning rate: 0.0004
                       Mean reward: 0.02
               Mean episode length: 56.57
       Episode_Reward/keep_balance: 0.0528
     Episode_Reward/rew_lin_vel_xy: 0.0544
      Episode_Reward/rew_ang_vel_z: 0.1697
    Episode_Reward/pen_base_height: -0.1093
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0059
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0044
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0116
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0074
   Episode_Reward/test_gait_reward: -0.0497
Metrics/base_velocity/error_vel_xy: 0.2734
Metrics/base_velocity/error_vel_yaw: 0.0395
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 77.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 1.08s
                        Total time: 297.95s
                               ETA: 2977.3s

################################################################################
                     [1m Learning iteration 273/3000 [0m                      

                       Computation: 90978 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 0.2095
                    Surrogate loss: -0.0002
             Mean action noise std: 0.4009
                     Learning rate: 0.0004
                       Mean reward: -0.45
               Mean episode length: 52.10
       Episode_Reward/keep_balance: 0.0523
     Episode_Reward/rew_lin_vel_xy: 0.0526
      Episode_Reward/rew_ang_vel_z: 0.1678
    Episode_Reward/pen_base_height: -0.1096
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0221
   Episode_Reward/pen_joint_torque: -0.0058
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0044
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0116
Episode_Reward/pen_flat_orientation: -0.0532
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0074
   Episode_Reward/test_gait_reward: -0.0490
Metrics/base_velocity/error_vel_xy: 0.2683
Metrics/base_velocity/error_vel_yaw: 0.0394
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 1.08s
                        Total time: 299.03s
                               ETA: 2976.1s

################################################################################
                     [1m Learning iteration 274/3000 [0m                      

                       Computation: 92142 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 0.2007
                    Surrogate loss: -0.0006
             Mean action noise std: 0.4010
                     Learning rate: 0.0004
                       Mean reward: -0.20
               Mean episode length: 54.62
       Episode_Reward/keep_balance: 0.0528
     Episode_Reward/rew_lin_vel_xy: 0.0572
      Episode_Reward/rew_ang_vel_z: 0.1692
    Episode_Reward/pen_base_height: -0.1098
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0059
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0045
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0117
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0064
   Episode_Reward/foot_landing_vel: -0.0076
   Episode_Reward/test_gait_reward: -0.0492
Metrics/base_velocity/error_vel_xy: 0.2669
Metrics/base_velocity/error_vel_yaw: 0.0401
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 75.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 1.07s
                        Total time: 300.10s
                               ETA: 2974.8s

################################################################################
                     [1m Learning iteration 275/3000 [0m                      

                       Computation: 91268 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.2068
                    Surrogate loss: -0.0012
             Mean action noise std: 0.4010
                     Learning rate: 0.0006
                       Mean reward: -0.16
               Mean episode length: 53.94
       Episode_Reward/keep_balance: 0.0531
     Episode_Reward/rew_lin_vel_xy: 0.0572
      Episode_Reward/rew_ang_vel_z: 0.1701
    Episode_Reward/pen_base_height: -0.1100
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0221
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0046
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0118
Episode_Reward/pen_flat_orientation: -0.0531
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0064
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0493
Metrics/base_velocity/error_vel_xy: 0.2688
Metrics/base_velocity/error_vel_yaw: 0.0404
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 1.08s
                        Total time: 301.17s
                               ETA: 2973.6s

################################################################################
                     [1m Learning iteration 276/3000 [0m                      

                       Computation: 92285 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.2232
                    Surrogate loss: -0.0012
             Mean action noise std: 0.4006
                     Learning rate: 0.0009
                       Mean reward: -0.37
               Mean episode length: 52.16
       Episode_Reward/keep_balance: 0.0534
     Episode_Reward/rew_lin_vel_xy: 0.0613
      Episode_Reward/rew_ang_vel_z: 0.1711
    Episode_Reward/pen_base_height: -0.1101
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0059
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0045
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0119
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0065
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0496
Metrics/base_velocity/error_vel_xy: 0.2655
Metrics/base_velocity/error_vel_yaw: 0.0406
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.3333
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 1.07s
                        Total time: 302.24s
                               ETA: 2972.2s

################################################################################
                     [1m Learning iteration 277/3000 [0m                      

                       Computation: 92405 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 0.2564
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4001
                     Learning rate: 0.0019
                       Mean reward: 0.00
               Mean episode length: 53.93
       Episode_Reward/keep_balance: 0.0528
     Episode_Reward/rew_lin_vel_xy: 0.0566
      Episode_Reward/rew_ang_vel_z: 0.1687
    Episode_Reward/pen_base_height: -0.1097
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0045
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0118
Episode_Reward/pen_flat_orientation: -0.0525
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0064
   Episode_Reward/foot_landing_vel: -0.0076
   Episode_Reward/test_gait_reward: -0.0488
Metrics/base_velocity/error_vel_xy: 0.2685
Metrics/base_velocity/error_vel_yaw: 0.0403
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 1.06s
                        Total time: 303.30s
                               ETA: 2970.8s

################################################################################
                     [1m Learning iteration 278/3000 [0m                      

                       Computation: 91708 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.2934
                    Surrogate loss: 0.0032
             Mean action noise std: 0.4002
                     Learning rate: 0.0004
                       Mean reward: -0.18
               Mean episode length: 53.45
       Episode_Reward/keep_balance: 0.0532
     Episode_Reward/rew_lin_vel_xy: 0.0578
      Episode_Reward/rew_ang_vel_z: 0.1704
    Episode_Reward/pen_base_height: -0.1098
      Episode_Reward/pen_lin_vel_z: -0.0125
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0046
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0118
Episode_Reward/pen_flat_orientation: -0.0527
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0064
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0492
Metrics/base_velocity/error_vel_xy: 0.2685
Metrics/base_velocity/error_vel_yaw: 0.0406
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.6667
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 1.07s
                        Total time: 304.38s
                               ETA: 2969.6s

################################################################################
                     [1m Learning iteration 279/3000 [0m                      

                       Computation: 91561 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.2391
                    Surrogate loss: 0.0089
             Mean action noise std: 0.4003
                     Learning rate: 0.0000
                       Mean reward: -0.75
               Mean episode length: 51.64
       Episode_Reward/keep_balance: 0.0529
     Episode_Reward/rew_lin_vel_xy: 0.0575
      Episode_Reward/rew_ang_vel_z: 0.1695
    Episode_Reward/pen_base_height: -0.1092
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0046
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0117
Episode_Reward/pen_flat_orientation: -0.0522
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0065
   Episode_Reward/foot_landing_vel: -0.0076
   Episode_Reward/test_gait_reward: -0.0489
Metrics/base_velocity/error_vel_xy: 0.2676
Metrics/base_velocity/error_vel_yaw: 0.0400
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.3333
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 1.07s
                        Total time: 305.45s
                               ETA: 2968.3s

################################################################################
                     [1m Learning iteration 280/3000 [0m                      

                       Computation: 91198 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.2461
                    Surrogate loss: 0.0040
             Mean action noise std: 0.4005
                     Learning rate: 0.0000
                       Mean reward: -0.34
               Mean episode length: 53.75
       Episode_Reward/keep_balance: 0.0531
     Episode_Reward/rew_lin_vel_xy: 0.0571
      Episode_Reward/rew_ang_vel_z: 0.1700
    Episode_Reward/pen_base_height: -0.1091
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0059
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0046
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0117
Episode_Reward/pen_flat_orientation: -0.0524
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0065
   Episode_Reward/foot_landing_vel: -0.0076
   Episode_Reward/test_gait_reward: -0.0488
Metrics/base_velocity/error_vel_xy: 0.2711
Metrics/base_velocity/error_vel_yaw: 0.0404
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 1.08s
                        Total time: 306.53s
                               ETA: 2967.1s

################################################################################
                     [1m Learning iteration 281/3000 [0m                      

                       Computation: 90930 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.2360
                    Surrogate loss: 0.0014
             Mean action noise std: 0.4007
                     Learning rate: 0.0001
                       Mean reward: -0.16
               Mean episode length: 55.96
       Episode_Reward/keep_balance: 0.0531
     Episode_Reward/rew_lin_vel_xy: 0.0550
      Episode_Reward/rew_ang_vel_z: 0.1705
    Episode_Reward/pen_base_height: -0.1090
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0045
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0117
Episode_Reward/pen_flat_orientation: -0.0531
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0066
   Episode_Reward/foot_landing_vel: -0.0076
   Episode_Reward/test_gait_reward: -0.0489
Metrics/base_velocity/error_vel_xy: 0.2715
Metrics/base_velocity/error_vel_yaw: 0.0400
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 75.8750
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 1.08s
                        Total time: 307.61s
                               ETA: 2965.9s

################################################################################
                     [1m Learning iteration 282/3000 [0m                      

                       Computation: 91869 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.2298
                    Surrogate loss: -0.0009
             Mean action noise std: 0.4010
                     Learning rate: 0.0003
                       Mean reward: -0.03
               Mean episode length: 54.55
       Episode_Reward/keep_balance: 0.0540
     Episode_Reward/rew_lin_vel_xy: 0.0613
      Episode_Reward/rew_ang_vel_z: 0.1732
    Episode_Reward/pen_base_height: -0.1105
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0061
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0046
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0119
Episode_Reward/pen_flat_orientation: -0.0539
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0067
   Episode_Reward/foot_landing_vel: -0.0076
   Episode_Reward/test_gait_reward: -0.0493
Metrics/base_velocity/error_vel_xy: 0.2705
Metrics/base_velocity/error_vel_yaw: 0.0411
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 1.07s
                        Total time: 308.68s
                               ETA: 2964.6s

################################################################################
                     [1m Learning iteration 283/3000 [0m                      

                       Computation: 91242 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 0.2213
                    Surrogate loss: -0.0006
             Mean action noise std: 0.4010
                     Learning rate: 0.0003
                       Mean reward: -0.11
               Mean episode length: 54.41
       Episode_Reward/keep_balance: 0.0538
     Episode_Reward/rew_lin_vel_xy: 0.0606
      Episode_Reward/rew_ang_vel_z: 0.1726
    Episode_Reward/pen_base_height: -0.1098
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0046
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0118
Episode_Reward/pen_flat_orientation: -0.0527
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0067
   Episode_Reward/foot_landing_vel: -0.0076
   Episode_Reward/test_gait_reward: -0.0496
Metrics/base_velocity/error_vel_xy: 0.2687
Metrics/base_velocity/error_vel_yaw: 0.0405
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 75.7083
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 1.08s
                        Total time: 309.76s
                               ETA: 2963.4s

################################################################################
                     [1m Learning iteration 284/3000 [0m                      

                       Computation: 92161 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 0.2189
                    Surrogate loss: -0.0003
             Mean action noise std: 0.4013
                     Learning rate: 0.0006
                       Mean reward: -0.34
               Mean episode length: 52.49
       Episode_Reward/keep_balance: 0.0538
     Episode_Reward/rew_lin_vel_xy: 0.0594
      Episode_Reward/rew_ang_vel_z: 0.1722
    Episode_Reward/pen_base_height: -0.1093
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0061
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0047
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0119
Episode_Reward/pen_flat_orientation: -0.0527
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0070
   Episode_Reward/foot_landing_vel: -0.0077
   Episode_Reward/test_gait_reward: -0.0493
Metrics/base_velocity/error_vel_xy: 0.2732
Metrics/base_velocity/error_vel_yaw: 0.0410
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.4583
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 1.07s
                        Total time: 310.82s
                               ETA: 2962.1s

################################################################################
                     [1m Learning iteration 285/3000 [0m                      

                       Computation: 91202 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.2201
                    Surrogate loss: -0.0005
             Mean action noise std: 0.4017
                     Learning rate: 0.0006
                       Mean reward: 0.06
               Mean episode length: 55.80
       Episode_Reward/keep_balance: 0.0543
     Episode_Reward/rew_lin_vel_xy: 0.0591
      Episode_Reward/rew_ang_vel_z: 0.1737
    Episode_Reward/pen_base_height: -0.1101
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0062
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0047
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0121
Episode_Reward/pen_flat_orientation: -0.0534
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0069
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0495
Metrics/base_velocity/error_vel_xy: 0.2745
Metrics/base_velocity/error_vel_yaw: 0.0416
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 73.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 1.08s
                        Total time: 311.90s
                               ETA: 2960.9s

################################################################################
                     [1m Learning iteration 286/3000 [0m                      

                       Computation: 90791 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.2288
                    Surrogate loss: -0.0011
             Mean action noise std: 0.4017
                     Learning rate: 0.0006
                       Mean reward: -0.11
               Mean episode length: 55.42
       Episode_Reward/keep_balance: 0.0544
     Episode_Reward/rew_lin_vel_xy: 0.0584
      Episode_Reward/rew_ang_vel_z: 0.1737
    Episode_Reward/pen_base_height: -0.1102
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0221
   Episode_Reward/pen_joint_torque: -0.0063
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0047
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0120
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0070
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0496
Metrics/base_velocity/error_vel_xy: 0.2730
Metrics/base_velocity/error_vel_yaw: 0.0420
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.8750
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 1.08s
                        Total time: 312.98s
                               ETA: 2959.7s

################################################################################
                     [1m Learning iteration 287/3000 [0m                      

                       Computation: 90408 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.2189
                    Surrogate loss: -0.0005
             Mean action noise std: 0.4012
                     Learning rate: 0.0009
                       Mean reward: -0.14
               Mean episode length: 54.74
       Episode_Reward/keep_balance: 0.0542
     Episode_Reward/rew_lin_vel_xy: 0.0565
      Episode_Reward/rew_ang_vel_z: 0.1730
    Episode_Reward/pen_base_height: -0.1096
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0062
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0047
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0120
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0069
   Episode_Reward/foot_landing_vel: -0.0077
   Episode_Reward/test_gait_reward: -0.0496
Metrics/base_velocity/error_vel_xy: 0.2773
Metrics/base_velocity/error_vel_yaw: 0.0415
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 75.7083
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 1.09s
                        Total time: 314.07s
                               ETA: 2958.6s

################################################################################
                     [1m Learning iteration 288/3000 [0m                      

                       Computation: 90871 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.2356
                    Surrogate loss: 0.0004
             Mean action noise std: 0.4008
                     Learning rate: 0.0004
                       Mean reward: 0.11
               Mean episode length: 56.80
       Episode_Reward/keep_balance: 0.0538
     Episode_Reward/rew_lin_vel_xy: 0.0575
      Episode_Reward/rew_ang_vel_z: 0.1718
    Episode_Reward/pen_base_height: -0.1100
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0062
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0047
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0120
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0069
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0493
Metrics/base_velocity/error_vel_xy: 0.2712
Metrics/base_velocity/error_vel_yaw: 0.0411
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 75.5000
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 1.08s
                        Total time: 315.15s
                               ETA: 2957.4s

################################################################################
                     [1m Learning iteration 289/3000 [0m                      

                       Computation: 92452 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 0.2488
                    Surrogate loss: 0.0008
             Mean action noise std: 0.4010
                     Learning rate: 0.0006
                       Mean reward: -0.45
               Mean episode length: 52.97
       Episode_Reward/keep_balance: 0.0540
     Episode_Reward/rew_lin_vel_xy: 0.0600
      Episode_Reward/rew_ang_vel_z: 0.1726
    Episode_Reward/pen_base_height: -0.1104
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0063
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0047
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0120
Episode_Reward/pen_flat_orientation: -0.0539
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0071
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0494
Metrics/base_velocity/error_vel_xy: 0.2717
Metrics/base_velocity/error_vel_yaw: 0.0413
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.4583
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 1.06s
                        Total time: 316.22s
                               ETA: 2956.1s

################################################################################
                     [1m Learning iteration 290/3000 [0m                      

                       Computation: 92625 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 0.2282
                    Surrogate loss: 0.0010
             Mean action noise std: 0.4010
                     Learning rate: 0.0004
                       Mean reward: -0.08
               Mean episode length: 55.41
       Episode_Reward/keep_balance: 0.0549
     Episode_Reward/rew_lin_vel_xy: 0.0609
      Episode_Reward/rew_ang_vel_z: 0.1756
    Episode_Reward/pen_base_height: -0.1111
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0065
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0048
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0122
Episode_Reward/pen_flat_orientation: -0.0539
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0072
   Episode_Reward/foot_landing_vel: -0.0080
   Episode_Reward/test_gait_reward: -0.0498
Metrics/base_velocity/error_vel_xy: 0.2717
Metrics/base_velocity/error_vel_yaw: 0.0416
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.0000
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 1.06s
                        Total time: 317.28s
                               ETA: 2954.7s

################################################################################
                     [1m Learning iteration 291/3000 [0m                      

                       Computation: 91702 steps/s (collection: 0.946s, learning 0.126s)
               Value function loss: 0.1940
                    Surrogate loss: -0.0006
             Mean action noise std: 0.4004
                     Learning rate: 0.0003
                       Mean reward: -0.32
               Mean episode length: 51.82
       Episode_Reward/keep_balance: 0.0553
     Episode_Reward/rew_lin_vel_xy: 0.0592
      Episode_Reward/rew_ang_vel_z: 0.1767
    Episode_Reward/pen_base_height: -0.1111
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0065
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0049
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0124
Episode_Reward/pen_flat_orientation: -0.0547
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0074
   Episode_Reward/foot_landing_vel: -0.0081
   Episode_Reward/test_gait_reward: -0.0502
Metrics/base_velocity/error_vel_xy: 0.2777
Metrics/base_velocity/error_vel_yaw: 0.0424
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 73.1667
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 1.07s
                        Total time: 318.35s
                               ETA: 2953.4s

################################################################################
                     [1m Learning iteration 292/3000 [0m                      

                       Computation: 90809 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.1981
                    Surrogate loss: -0.0002
             Mean action noise std: 0.3998
                     Learning rate: 0.0003
                       Mean reward: -0.06
               Mean episode length: 54.45
       Episode_Reward/keep_balance: 0.0552
     Episode_Reward/rew_lin_vel_xy: 0.0604
      Episode_Reward/rew_ang_vel_z: 0.1767
    Episode_Reward/pen_base_height: -0.1106
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0066
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0049
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0123
Episode_Reward/pen_flat_orientation: -0.0542
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0073
   Episode_Reward/foot_landing_vel: -0.0081
   Episode_Reward/test_gait_reward: -0.0499
Metrics/base_velocity/error_vel_xy: 0.2809
Metrics/base_velocity/error_vel_yaw: 0.0418
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 75.0000
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 1.08s
                        Total time: 319.43s
                               ETA: 2952.3s

################################################################################
                     [1m Learning iteration 293/3000 [0m                      

                       Computation: 91732 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 0.2064
                    Surrogate loss: -0.0014
             Mean action noise std: 0.3997
                     Learning rate: 0.0004
                       Mean reward: 0.03
               Mean episode length: 56.70
       Episode_Reward/keep_balance: 0.0550
     Episode_Reward/rew_lin_vel_xy: 0.0603
      Episode_Reward/rew_ang_vel_z: 0.1761
    Episode_Reward/pen_base_height: -0.1113
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0065
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0049
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0123
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0072
   Episode_Reward/foot_landing_vel: -0.0080
   Episode_Reward/test_gait_reward: -0.0498
Metrics/base_velocity/error_vel_xy: 0.2727
Metrics/base_velocity/error_vel_yaw: 0.0415
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 73.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 1.07s
                        Total time: 320.50s
                               ETA: 2951.0s

################################################################################
                     [1m Learning iteration 294/3000 [0m                      

                       Computation: 92241 steps/s (collection: 0.940s, learning 0.125s)
               Value function loss: 0.2134
                    Surrogate loss: -0.0023
             Mean action noise std: 0.3991
                     Learning rate: 0.0006
                       Mean reward: -0.43
               Mean episode length: 54.66
       Episode_Reward/keep_balance: 0.0554
     Episode_Reward/rew_lin_vel_xy: 0.0606
      Episode_Reward/rew_ang_vel_z: 0.1772
    Episode_Reward/pen_base_height: -0.1115
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0065
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0049
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0123
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0074
   Episode_Reward/foot_landing_vel: -0.0081
   Episode_Reward/test_gait_reward: -0.0497
Metrics/base_velocity/error_vel_xy: 0.2775
Metrics/base_velocity/error_vel_yaw: 0.0420
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 1.07s
                        Total time: 321.57s
                               ETA: 2949.7s

################################################################################
                     [1m Learning iteration 295/3000 [0m                      

                       Computation: 91977 steps/s (collection: 0.944s, learning 0.125s)
               Value function loss: 0.2470
                    Surrogate loss: 0.0008
             Mean action noise std: 0.3983
                     Learning rate: 0.0006
                       Mean reward: -0.37
               Mean episode length: 55.27
       Episode_Reward/keep_balance: 0.0555
     Episode_Reward/rew_lin_vel_xy: 0.0634
      Episode_Reward/rew_ang_vel_z: 0.1770
    Episode_Reward/pen_base_height: -0.1105
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0066
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0049
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0124
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0074
   Episode_Reward/foot_landing_vel: -0.0081
   Episode_Reward/test_gait_reward: -0.0502
Metrics/base_velocity/error_vel_xy: 0.2736
Metrics/base_velocity/error_vel_yaw: 0.0426
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.2500
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 1.07s
                        Total time: 322.64s
                               ETA: 2948.4s

################################################################################
                     [1m Learning iteration 296/3000 [0m                      

                       Computation: 91379 steps/s (collection: 0.950s, learning 0.126s)
               Value function loss: 0.2643
                    Surrogate loss: 0.0016
             Mean action noise std: 0.3983
                     Learning rate: 0.0002
                       Mean reward: -0.26
               Mean episode length: 55.38
       Episode_Reward/keep_balance: 0.0550
     Episode_Reward/rew_lin_vel_xy: 0.0605
      Episode_Reward/rew_ang_vel_z: 0.1759
    Episode_Reward/pen_base_height: -0.1106
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0065
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0049
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0124
Episode_Reward/pen_flat_orientation: -0.0542
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0073
   Episode_Reward/foot_landing_vel: -0.0082
   Episode_Reward/test_gait_reward: -0.0498
Metrics/base_velocity/error_vel_xy: 0.2802
Metrics/base_velocity/error_vel_yaw: 0.0418
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 1.08s
                        Total time: 323.71s
                               ETA: 2947.2s

################################################################################
                     [1m Learning iteration 297/3000 [0m                      

                       Computation: 91800 steps/s (collection: 0.947s, learning 0.124s)
               Value function loss: 0.2307
                    Surrogate loss: -0.0022
             Mean action noise std: 0.3987
                     Learning rate: 0.0004
                       Mean reward: -0.15
               Mean episode length: 56.54
       Episode_Reward/keep_balance: 0.0556
     Episode_Reward/rew_lin_vel_xy: 0.0613
      Episode_Reward/rew_ang_vel_z: 0.1769
    Episode_Reward/pen_base_height: -0.1133
      Episode_Reward/pen_lin_vel_z: -0.0130
     Episode_Reward/pen_ang_vel_xy: -0.0231
   Episode_Reward/pen_joint_torque: -0.0067
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0050
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0125
Episode_Reward/pen_flat_orientation: -0.0557
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0075
   Episode_Reward/foot_landing_vel: -0.0082
   Episode_Reward/test_gait_reward: -0.0505
Metrics/base_velocity/error_vel_xy: 0.2780
Metrics/base_velocity/error_vel_yaw: 0.0432
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 68.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 1.07s
                        Total time: 324.78s
                               ETA: 2945.9s

################################################################################
                     [1m Learning iteration 298/3000 [0m                      

                       Computation: 91035 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.2475
                    Surrogate loss: 0.0004
             Mean action noise std: 0.3988
                     Learning rate: 0.0004
                       Mean reward: 0.23
               Mean episode length: 58.76
       Episode_Reward/keep_balance: 0.0570
     Episode_Reward/rew_lin_vel_xy: 0.0672
      Episode_Reward/rew_ang_vel_z: 0.1822
    Episode_Reward/pen_base_height: -0.1131
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0069
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0051
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0128
Episode_Reward/pen_flat_orientation: -0.0556
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0076
   Episode_Reward/foot_landing_vel: -0.0084
   Episode_Reward/test_gait_reward: -0.0511
Metrics/base_velocity/error_vel_xy: 0.2831
Metrics/base_velocity/error_vel_yaw: 0.0434
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 1.08s
                        Total time: 325.86s
                               ETA: 2944.8s

################################################################################
                     [1m Learning iteration 299/3000 [0m                      

                       Computation: 91176 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.2262
                    Surrogate loss: -0.0018
             Mean action noise std: 0.3983
                     Learning rate: 0.0006
                       Mean reward: -0.42
               Mean episode length: 54.76
       Episode_Reward/keep_balance: 0.0569
     Episode_Reward/rew_lin_vel_xy: 0.0621
      Episode_Reward/rew_ang_vel_z: 0.1817
    Episode_Reward/pen_base_height: -0.1129
      Episode_Reward/pen_lin_vel_z: -0.0130
     Episode_Reward/pen_ang_vel_xy: -0.0231
   Episode_Reward/pen_joint_torque: -0.0070
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0051
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0127
Episode_Reward/pen_flat_orientation: -0.0557
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0077
   Episode_Reward/foot_landing_vel: -0.0085
   Episode_Reward/test_gait_reward: -0.0509
Metrics/base_velocity/error_vel_xy: 0.2802
Metrics/base_velocity/error_vel_yaw: 0.0435
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 70.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 1.08s
                        Total time: 326.94s
                               ETA: 2943.6s

################################################################################
                     [1m Learning iteration 300/3000 [0m                      

                       Computation: 91486 steps/s (collection: 0.950s, learning 0.124s)
               Value function loss: 0.2579
                    Surrogate loss: -0.0007
             Mean action noise std: 0.3988
                     Learning rate: 0.0009
                       Mean reward: -0.10
               Mean episode length: 55.05
       Episode_Reward/keep_balance: 0.0563
     Episode_Reward/rew_lin_vel_xy: 0.0633
      Episode_Reward/rew_ang_vel_z: 0.1800
    Episode_Reward/pen_base_height: -0.1132
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0069
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0051
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0126
Episode_Reward/pen_flat_orientation: -0.0556
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0077
   Episode_Reward/foot_landing_vel: -0.0086
   Episode_Reward/test_gait_reward: -0.0506
Metrics/base_velocity/error_vel_xy: 0.2769
Metrics/base_velocity/error_vel_yaw: 0.0428
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 72.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 1.07s
                        Total time: 328.02s
                               ETA: 2942.3s

################################################################################
                     [1m Learning iteration 301/3000 [0m                      

                       Computation: 91480 steps/s (collection: 0.947s, learning 0.127s)
               Value function loss: 0.3173
                    Surrogate loss: 0.0060
             Mean action noise std: 0.3989
                     Learning rate: 0.0001
                       Mean reward: -0.15
               Mean episode length: 57.08
       Episode_Reward/keep_balance: 0.0576
     Episode_Reward/rew_lin_vel_xy: 0.0648
      Episode_Reward/rew_ang_vel_z: 0.1844
    Episode_Reward/pen_base_height: -0.1141
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0071
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0052
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0129
Episode_Reward/pen_flat_orientation: -0.0569
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0076
   Episode_Reward/foot_landing_vel: -0.0087
   Episode_Reward/test_gait_reward: -0.0514
Metrics/base_velocity/error_vel_xy: 0.2850
Metrics/base_velocity/error_vel_yaw: 0.0436
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 72.0000
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 1.07s
                        Total time: 329.09s
                               ETA: 2941.1s

################################################################################
                     [1m Learning iteration 302/3000 [0m                      

                       Computation: 91619 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.2349
                    Surrogate loss: -0.0020
             Mean action noise std: 0.3988
                     Learning rate: 0.0003
                       Mean reward: -0.48
               Mean episode length: 53.56
       Episode_Reward/keep_balance: 0.0566
     Episode_Reward/rew_lin_vel_xy: 0.0624
      Episode_Reward/rew_ang_vel_z: 0.1806
    Episode_Reward/pen_base_height: -0.1131
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0070
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0052
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0126
Episode_Reward/pen_flat_orientation: -0.0558
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0078
   Episode_Reward/foot_landing_vel: -0.0087
   Episode_Reward/test_gait_reward: -0.0503
Metrics/base_velocity/error_vel_xy: 0.2816
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 69.9167
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 1.07s
                        Total time: 330.16s
                               ETA: 2939.9s

################################################################################
                     [1m Learning iteration 303/3000 [0m                      

                       Computation: 91609 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.2647
                    Surrogate loss: 0.0000
             Mean action noise std: 0.3986
                     Learning rate: 0.0004
                       Mean reward: 0.16
               Mean episode length: 61.23
       Episode_Reward/keep_balance: 0.0577
     Episode_Reward/rew_lin_vel_xy: 0.0686
      Episode_Reward/rew_ang_vel_z: 0.1842
    Episode_Reward/pen_base_height: -0.1137
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0072
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0053
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0129
Episode_Reward/pen_flat_orientation: -0.0563
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0079
   Episode_Reward/foot_landing_vel: -0.0088
   Episode_Reward/test_gait_reward: -0.0516
Metrics/base_velocity/error_vel_xy: 0.2794
Metrics/base_velocity/error_vel_yaw: 0.0442
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 71.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 1.07s
                        Total time: 331.24s
                               ETA: 2938.6s

################################################################################
                     [1m Learning iteration 304/3000 [0m                      

                       Computation: 90720 steps/s (collection: 0.956s, learning 0.127s)
               Value function loss: 0.2637
                    Surrogate loss: -0.0005
             Mean action noise std: 0.3985
                     Learning rate: 0.0003
                       Mean reward: -0.24
               Mean episode length: 58.33
       Episode_Reward/keep_balance: 0.0579
     Episode_Reward/rew_lin_vel_xy: 0.0639
      Episode_Reward/rew_ang_vel_z: 0.1851
    Episode_Reward/pen_base_height: -0.1148
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0073
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0053
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0130
Episode_Reward/pen_flat_orientation: -0.0567
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0080
   Episode_Reward/foot_landing_vel: -0.0088
   Episode_Reward/test_gait_reward: -0.0514
Metrics/base_velocity/error_vel_xy: 0.2885
Metrics/base_velocity/error_vel_yaw: 0.0442
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 69.1667
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 1.08s
                        Total time: 332.32s
                               ETA: 2937.5s

################################################################################
                     [1m Learning iteration 305/3000 [0m                      

                       Computation: 91730 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.2682
                    Surrogate loss: -0.0017
             Mean action noise std: 0.3982
                     Learning rate: 0.0006
                       Mean reward: 0.65
               Mean episode length: 61.24
       Episode_Reward/keep_balance: 0.0579
     Episode_Reward/rew_lin_vel_xy: 0.0651
      Episode_Reward/rew_ang_vel_z: 0.1849
    Episode_Reward/pen_base_height: -0.1148
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0074
    Episode_Reward/pen_joint_accel: -0.0057
    Episode_Reward/pen_action_rate: -0.0053
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0131
Episode_Reward/pen_flat_orientation: -0.0569
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0079
   Episode_Reward/foot_landing_vel: -0.0087
   Episode_Reward/test_gait_reward: -0.0517
Metrics/base_velocity/error_vel_xy: 0.2835
Metrics/base_velocity/error_vel_yaw: 0.0442
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 71.7500
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 1.07s
                        Total time: 333.39s
                               ETA: 2936.2s

################################################################################
                     [1m Learning iteration 306/3000 [0m                      

                       Computation: 92624 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 0.2535
                    Surrogate loss: -0.0006
             Mean action noise std: 0.3984
                     Learning rate: 0.0006
                       Mean reward: 0.04
               Mean episode length: 58.90
       Episode_Reward/keep_balance: 0.0582
     Episode_Reward/rew_lin_vel_xy: 0.0675
      Episode_Reward/rew_ang_vel_z: 0.1851
    Episode_Reward/pen_base_height: -0.1148
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0074
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0054
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0132
Episode_Reward/pen_flat_orientation: -0.0562
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0079
   Episode_Reward/foot_landing_vel: -0.0089
   Episode_Reward/test_gait_reward: -0.0522
Metrics/base_velocity/error_vel_xy: 0.2842
Metrics/base_velocity/error_vel_yaw: 0.0451
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 69.4167
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 1.06s
                        Total time: 334.45s
                               ETA: 2934.9s

################################################################################
                     [1m Learning iteration 307/3000 [0m                      

                       Computation: 91920 steps/s (collection: 0.948s, learning 0.121s)
               Value function loss: 0.2506
                    Surrogate loss: -0.0004
             Mean action noise std: 0.3990
                     Learning rate: 0.0006
                       Mean reward: 0.22
               Mean episode length: 58.13
       Episode_Reward/keep_balance: 0.0570
     Episode_Reward/rew_lin_vel_xy: 0.0670
      Episode_Reward/rew_ang_vel_z: 0.1820
    Episode_Reward/pen_base_height: -0.1136
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0072
    Episode_Reward/pen_joint_accel: -0.0056
    Episode_Reward/pen_action_rate: -0.0053
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0129
Episode_Reward/pen_flat_orientation: -0.0556
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0081
   Episode_Reward/foot_landing_vel: -0.0088
   Episode_Reward/test_gait_reward: -0.0511
Metrics/base_velocity/error_vel_xy: 0.2775
Metrics/base_velocity/error_vel_yaw: 0.0437
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 72.4167
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 1.07s
                        Total time: 335.52s
                               ETA: 2933.6s

################################################################################
                     [1m Learning iteration 308/3000 [0m                      

                       Computation: 92791 steps/s (collection: 0.938s, learning 0.122s)
               Value function loss: 0.2742
                    Surrogate loss: -0.0015
             Mean action noise std: 0.3998
                     Learning rate: 0.0009
                       Mean reward: -0.08
               Mean episode length: 55.81
       Episode_Reward/keep_balance: 0.0586
     Episode_Reward/rew_lin_vel_xy: 0.0686
      Episode_Reward/rew_ang_vel_z: 0.1873
    Episode_Reward/pen_base_height: -0.1149
      Episode_Reward/pen_lin_vel_z: -0.0130
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0074
    Episode_Reward/pen_joint_accel: -0.0056
    Episode_Reward/pen_action_rate: -0.0054
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0134
Episode_Reward/pen_flat_orientation: -0.0560
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0080
   Episode_Reward/foot_landing_vel: -0.0087
   Episode_Reward/test_gait_reward: -0.0527
Metrics/base_velocity/error_vel_xy: 0.2862
Metrics/base_velocity/error_vel_yaw: 0.0448
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 65.4167
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 1.06s
                        Total time: 336.58s
                               ETA: 2932.3s

################################################################################
                     [1m Learning iteration 309/3000 [0m                      

                       Computation: 93018 steps/s (collection: 0.933s, learning 0.124s)
               Value function loss: 0.2831
                    Surrogate loss: 0.0021
             Mean action noise std: 0.3999
                     Learning rate: 0.0004
                       Mean reward: 0.06
               Mean episode length: 61.63
       Episode_Reward/keep_balance: 0.0591
     Episode_Reward/rew_lin_vel_xy: 0.0730
      Episode_Reward/rew_ang_vel_z: 0.1896
    Episode_Reward/pen_base_height: -0.1146
      Episode_Reward/pen_lin_vel_z: -0.0131
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0075
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0055
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0134
Episode_Reward/pen_flat_orientation: -0.0560
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0082
   Episode_Reward/foot_landing_vel: -0.0088
   Episode_Reward/test_gait_reward: -0.0527
Metrics/base_velocity/error_vel_xy: 0.2801
Metrics/base_velocity/error_vel_yaw: 0.0445
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 71.2500
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 1.06s
                        Total time: 337.64s
                               ETA: 2930.9s

################################################################################
                     [1m Learning iteration 310/3000 [0m                      

                       Computation: 91794 steps/s (collection: 0.947s, learning 0.124s)
               Value function loss: 0.2870
                    Surrogate loss: 0.0002
             Mean action noise std: 0.4001
                     Learning rate: 0.0002
                       Mean reward: 0.26
               Mean episode length: 65.06
       Episode_Reward/keep_balance: 0.0598
     Episode_Reward/rew_lin_vel_xy: 0.0674
      Episode_Reward/rew_ang_vel_z: 0.1912
    Episode_Reward/pen_base_height: -0.1139
      Episode_Reward/pen_lin_vel_z: -0.0131
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0077
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0056
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0136
Episode_Reward/pen_flat_orientation: -0.0565
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0084
   Episode_Reward/foot_landing_vel: -0.0091
   Episode_Reward/test_gait_reward: -0.0529
Metrics/base_velocity/error_vel_xy: 0.2901
Metrics/base_velocity/error_vel_yaw: 0.0451
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 65.8750
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 1.07s
                        Total time: 338.71s
                               ETA: 2929.7s

################################################################################
                     [1m Learning iteration 311/3000 [0m                      

                       Computation: 91989 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.2815
                    Surrogate loss: -0.0020
             Mean action noise std: 0.4003
                     Learning rate: 0.0003
                       Mean reward: 0.19
               Mean episode length: 63.50
       Episode_Reward/keep_balance: 0.0597
     Episode_Reward/rew_lin_vel_xy: 0.0693
      Episode_Reward/rew_ang_vel_z: 0.1905
    Episode_Reward/pen_base_height: -0.1147
      Episode_Reward/pen_lin_vel_z: -0.0131
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0077
    Episode_Reward/pen_joint_accel: -0.0056
    Episode_Reward/pen_action_rate: -0.0056
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0137
Episode_Reward/pen_flat_orientation: -0.0569
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0085
   Episode_Reward/foot_landing_vel: -0.0090
   Episode_Reward/test_gait_reward: -0.0530
Metrics/base_velocity/error_vel_xy: 0.2887
Metrics/base_velocity/error_vel_yaw: 0.0459
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 68.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 1.07s
                        Total time: 339.78s
                               ETA: 2928.4s

################################################################################
                     [1m Learning iteration 312/3000 [0m                      

                       Computation: 85295 steps/s (collection: 1.029s, learning 0.124s)
               Value function loss: 0.2918
                    Surrogate loss: -0.0020
             Mean action noise std: 0.4007
                     Learning rate: 0.0006
                       Mean reward: -0.10
               Mean episode length: 61.15
       Episode_Reward/keep_balance: 0.0612
     Episode_Reward/rew_lin_vel_xy: 0.0723
      Episode_Reward/rew_ang_vel_z: 0.1944
    Episode_Reward/pen_base_height: -0.1162
      Episode_Reward/pen_lin_vel_z: -0.0133
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0079
    Episode_Reward/pen_joint_accel: -0.0058
    Episode_Reward/pen_action_rate: -0.0058
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0141
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0089
   Episode_Reward/foot_landing_vel: -0.0092
   Episode_Reward/test_gait_reward: -0.0540
Metrics/base_velocity/error_vel_xy: 0.2945
Metrics/base_velocity/error_vel_yaw: 0.0477
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 64.8750
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 1.15s
                        Total time: 340.93s
                               ETA: 2927.9s

################################################################################
                     [1m Learning iteration 313/3000 [0m                      

                       Computation: 89871 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.2812
                    Surrogate loss: -0.0007
             Mean action noise std: 0.4010
                     Learning rate: 0.0009
                       Mean reward: -0.08
               Mean episode length: 60.06
       Episode_Reward/keep_balance: 0.0606
     Episode_Reward/rew_lin_vel_xy: 0.0735
      Episode_Reward/rew_ang_vel_z: 0.1927
    Episode_Reward/pen_base_height: -0.1163
      Episode_Reward/pen_lin_vel_z: -0.0132
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0078
    Episode_Reward/pen_joint_accel: -0.0059
    Episode_Reward/pen_action_rate: -0.0058
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0140
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0088
   Episode_Reward/foot_landing_vel: -0.0093
   Episode_Reward/test_gait_reward: -0.0540
Metrics/base_velocity/error_vel_xy: 0.2876
Metrics/base_velocity/error_vel_yaw: 0.0472
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 70.7917
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 1.09s
                        Total time: 342.03s
                               ETA: 2926.8s

################################################################################
                     [1m Learning iteration 314/3000 [0m                      

                       Computation: 90790 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.3233
                    Surrogate loss: 0.0039
             Mean action noise std: 0.4012
                     Learning rate: 0.0004
                       Mean reward: 0.41
               Mean episode length: 60.92
       Episode_Reward/keep_balance: 0.0610
     Episode_Reward/rew_lin_vel_xy: 0.0750
      Episode_Reward/rew_ang_vel_z: 0.1945
    Episode_Reward/pen_base_height: -0.1159
      Episode_Reward/pen_lin_vel_z: -0.0131
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0078
    Episode_Reward/pen_joint_accel: -0.0061
    Episode_Reward/pen_action_rate: -0.0059
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0143
Episode_Reward/pen_flat_orientation: -0.0570
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0091
   Episode_Reward/foot_landing_vel: -0.0092
   Episode_Reward/test_gait_reward: -0.0543
Metrics/base_velocity/error_vel_xy: 0.2877
Metrics/base_velocity/error_vel_yaw: 0.0468
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 67.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 1.08s
                        Total time: 343.11s
                               ETA: 2925.7s

################################################################################
                     [1m Learning iteration 315/3000 [0m                      

                       Computation: 90866 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.3047
                    Surrogate loss: -0.0002
             Mean action noise std: 0.4010
                     Learning rate: 0.0006
                       Mean reward: 0.10
               Mean episode length: 59.87
       Episode_Reward/keep_balance: 0.0600
     Episode_Reward/rew_lin_vel_xy: 0.0725
      Episode_Reward/rew_ang_vel_z: 0.1910
    Episode_Reward/pen_base_height: -0.1143
      Episode_Reward/pen_lin_vel_z: -0.0132
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0076
    Episode_Reward/pen_joint_accel: -0.0058
    Episode_Reward/pen_action_rate: -0.0057
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0139
Episode_Reward/pen_flat_orientation: -0.0557
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0090
   Episode_Reward/foot_landing_vel: -0.0090
   Episode_Reward/test_gait_reward: -0.0534
Metrics/base_velocity/error_vel_xy: 0.2875
Metrics/base_velocity/error_vel_yaw: 0.0464
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 65.2917
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 1.08s
                        Total time: 344.19s
                               ETA: 2924.5s

################################################################################
                     [1m Learning iteration 316/3000 [0m                      

                       Computation: 91434 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.3078
                    Surrogate loss: -0.0016
             Mean action noise std: 0.4009
                     Learning rate: 0.0013
                       Mean reward: 0.32
               Mean episode length: 62.95
       Episode_Reward/keep_balance: 0.0608
     Episode_Reward/rew_lin_vel_xy: 0.0680
      Episode_Reward/rew_ang_vel_z: 0.1939
    Episode_Reward/pen_base_height: -0.1156
      Episode_Reward/pen_lin_vel_z: -0.0131
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0079
    Episode_Reward/pen_joint_accel: -0.0057
    Episode_Reward/pen_action_rate: -0.0058
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0142
Episode_Reward/pen_flat_orientation: -0.0570
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0090
   Episode_Reward/foot_landing_vel: -0.0093
   Episode_Reward/test_gait_reward: -0.0544
Metrics/base_velocity/error_vel_xy: 0.3000
Metrics/base_velocity/error_vel_yaw: 0.0471
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 68.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 1.08s
                        Total time: 345.26s
                               ETA: 2923.3s

################################################################################
                     [1m Learning iteration 317/3000 [0m                      

                       Computation: 91259 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.4479
                    Surrogate loss: -0.0014
             Mean action noise std: 0.4008
                     Learning rate: 0.0029
                       Mean reward: 0.03
               Mean episode length: 59.86
       Episode_Reward/keep_balance: 0.0615
     Episode_Reward/rew_lin_vel_xy: 0.0705
      Episode_Reward/rew_ang_vel_z: 0.1957
    Episode_Reward/pen_base_height: -0.1165
      Episode_Reward/pen_lin_vel_z: -0.0135
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0081
    Episode_Reward/pen_joint_accel: -0.0058
    Episode_Reward/pen_action_rate: -0.0059
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0144
Episode_Reward/pen_flat_orientation: -0.0574
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0093
   Episode_Reward/foot_landing_vel: -0.0094
   Episode_Reward/test_gait_reward: -0.0546
Metrics/base_velocity/error_vel_xy: 0.2978
Metrics/base_velocity/error_vel_yaw: 0.0478
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 64.0833
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 1.08s
                        Total time: 346.34s
                               ETA: 2922.1s

################################################################################
                     [1m Learning iteration 318/3000 [0m                      

                       Computation: 90886 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.3387
                    Surrogate loss: 0.0098
             Mean action noise std: 0.4010
                     Learning rate: 0.0002
                       Mean reward: 0.27
               Mean episode length: 64.46
       Episode_Reward/keep_balance: 0.0619
     Episode_Reward/rew_lin_vel_xy: 0.0723
      Episode_Reward/rew_ang_vel_z: 0.1962
    Episode_Reward/pen_base_height: -0.1163
      Episode_Reward/pen_lin_vel_z: -0.0134
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0081
    Episode_Reward/pen_joint_accel: -0.0061
    Episode_Reward/pen_action_rate: -0.0060
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0146
Episode_Reward/pen_flat_orientation: -0.0575
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0094
   Episode_Reward/foot_landing_vel: -0.0095
   Episode_Reward/test_gait_reward: -0.0553
Metrics/base_velocity/error_vel_xy: 0.2951
Metrics/base_velocity/error_vel_yaw: 0.0484
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 66.0000
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 1.08s
                        Total time: 347.42s
                               ETA: 2921.0s

################################################################################
                     [1m Learning iteration 319/3000 [0m                      

                       Computation: 92276 steps/s (collection: 0.942s, learning 0.124s)
               Value function loss: 0.2614
                    Surrogate loss: 0.0070
             Mean action noise std: 0.4011
                     Learning rate: 0.0000
                       Mean reward: 0.20
               Mean episode length: 62.64
       Episode_Reward/keep_balance: 0.0626
     Episode_Reward/rew_lin_vel_xy: 0.0747
      Episode_Reward/rew_ang_vel_z: 0.1990
    Episode_Reward/pen_base_height: -0.1182
      Episode_Reward/pen_lin_vel_z: -0.0134
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0083
    Episode_Reward/pen_joint_accel: -0.0060
    Episode_Reward/pen_action_rate: -0.0061
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0149
Episode_Reward/pen_flat_orientation: -0.0584
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0094
   Episode_Reward/foot_landing_vel: -0.0095
   Episode_Reward/test_gait_reward: -0.0564
Metrics/base_velocity/error_vel_xy: 0.2969
Metrics/base_velocity/error_vel_yaw: 0.0490
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 61.5000
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 1.07s
                        Total time: 348.49s
                               ETA: 2919.7s

################################################################################
                     [1m Learning iteration 320/3000 [0m                      

                       Computation: 91509 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.2746
                    Surrogate loss: 0.0053
             Mean action noise std: 0.4012
                     Learning rate: 0.0000
                       Mean reward: 0.44
               Mean episode length: 65.20
       Episode_Reward/keep_balance: 0.0635
     Episode_Reward/rew_lin_vel_xy: 0.0772
      Episode_Reward/rew_ang_vel_z: 0.2014
    Episode_Reward/pen_base_height: -0.1169
      Episode_Reward/pen_lin_vel_z: -0.0136
     Episode_Reward/pen_ang_vel_xy: -0.0232
   Episode_Reward/pen_joint_torque: -0.0084
    Episode_Reward/pen_joint_accel: -0.0062
    Episode_Reward/pen_action_rate: -0.0062
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0151
Episode_Reward/pen_flat_orientation: -0.0575
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0096
   Episode_Reward/foot_landing_vel: -0.0095
   Episode_Reward/test_gait_reward: -0.0566
Metrics/base_velocity/error_vel_xy: 0.3027
Metrics/base_velocity/error_vel_yaw: 0.0497
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 65.4583
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 1.07s
                        Total time: 349.56s
                               ETA: 2918.5s

################################################################################
                     [1m Learning iteration 321/3000 [0m                      

                       Computation: 91060 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.3057
                    Surrogate loss: 0.0142
             Mean action noise std: 0.4012
                     Learning rate: 0.0000
                       Mean reward: 0.24
               Mean episode length: 68.26
       Episode_Reward/keep_balance: 0.0634
     Episode_Reward/rew_lin_vel_xy: 0.0739
      Episode_Reward/rew_ang_vel_z: 0.2006
    Episode_Reward/pen_base_height: -0.1194
      Episode_Reward/pen_lin_vel_z: -0.0135
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0085
    Episode_Reward/pen_joint_accel: -0.0059
    Episode_Reward/pen_action_rate: -0.0062
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0149
Episode_Reward/pen_flat_orientation: -0.0599
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0097
   Episode_Reward/foot_landing_vel: -0.0096
   Episode_Reward/test_gait_reward: -0.0568
Metrics/base_velocity/error_vel_xy: 0.3057
Metrics/base_velocity/error_vel_yaw: 0.0504
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 63.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 1.08s
                        Total time: 350.64s
                               ETA: 2917.3s

################################################################################
                     [1m Learning iteration 322/3000 [0m                      

                       Computation: 91586 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.2770
                    Surrogate loss: 0.0042
             Mean action noise std: 0.4012
                     Learning rate: 0.0000
                       Mean reward: 0.17
               Mean episode length: 67.02
       Episode_Reward/keep_balance: 0.0639
     Episode_Reward/rew_lin_vel_xy: 0.0769
      Episode_Reward/rew_ang_vel_z: 0.2014
    Episode_Reward/pen_base_height: -0.1201
      Episode_Reward/pen_lin_vel_z: -0.0136
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0086
    Episode_Reward/pen_joint_accel: -0.0062
    Episode_Reward/pen_action_rate: -0.0063
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0153
Episode_Reward/pen_flat_orientation: -0.0605
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0097
   Episode_Reward/foot_landing_vel: -0.0097
   Episode_Reward/test_gait_reward: -0.0574
Metrics/base_velocity/error_vel_xy: 0.3024
Metrics/base_velocity/error_vel_yaw: 0.0514
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 63.1250
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 1.07s
                        Total time: 351.72s
                               ETA: 2916.1s

################################################################################
                     [1m Learning iteration 323/3000 [0m                      

                       Computation: 92442 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 0.2813
                    Surrogate loss: 0.0063
             Mean action noise std: 0.4013
                     Learning rate: 0.0000
                       Mean reward: 0.45
               Mean episode length: 64.73
       Episode_Reward/keep_balance: 0.0653
     Episode_Reward/rew_lin_vel_xy: 0.0795
      Episode_Reward/rew_ang_vel_z: 0.2058
    Episode_Reward/pen_base_height: -0.1205
      Episode_Reward/pen_lin_vel_z: -0.0136
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0088
    Episode_Reward/pen_joint_accel: -0.0062
    Episode_Reward/pen_action_rate: -0.0064
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0156
Episode_Reward/pen_flat_orientation: -0.0606
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0100
   Episode_Reward/foot_landing_vel: -0.0099
   Episode_Reward/test_gait_reward: -0.0586
Metrics/base_velocity/error_vel_xy: 0.3071
Metrics/base_velocity/error_vel_yaw: 0.0523
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 62.5417
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 1.06s
                        Total time: 352.78s
                               ETA: 2914.8s

################################################################################
                     [1m Learning iteration 324/3000 [0m                      

                       Computation: 91704 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.3106
                    Surrogate loss: 0.0101
             Mean action noise std: 0.4014
                     Learning rate: 0.0000
                       Mean reward: 0.16
               Mean episode length: 64.58
       Episode_Reward/keep_balance: 0.0649
     Episode_Reward/rew_lin_vel_xy: 0.0785
      Episode_Reward/rew_ang_vel_z: 0.2052
    Episode_Reward/pen_base_height: -0.1202
      Episode_Reward/pen_lin_vel_z: -0.0137
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0087
    Episode_Reward/pen_joint_accel: -0.0062
    Episode_Reward/pen_action_rate: -0.0064
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0155
Episode_Reward/pen_flat_orientation: -0.0600
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0097
   Episode_Reward/foot_landing_vel: -0.0097
   Episode_Reward/test_gait_reward: -0.0583
Metrics/base_velocity/error_vel_xy: 0.3075
Metrics/base_velocity/error_vel_yaw: 0.0513
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 64.8750
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 1.07s
                        Total time: 353.85s
                               ETA: 2913.6s

################################################################################
                     [1m Learning iteration 325/3000 [0m                      

                       Computation: 91923 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 0.2968
                    Surrogate loss: 0.0015
             Mean action noise std: 0.4015
                     Learning rate: 0.0001
                       Mean reward: 0.03
               Mean episode length: 63.82
       Episode_Reward/keep_balance: 0.0645
     Episode_Reward/rew_lin_vel_xy: 0.0794
      Episode_Reward/rew_ang_vel_z: 0.2034
    Episode_Reward/pen_base_height: -0.1203
      Episode_Reward/pen_lin_vel_z: -0.0138
     Episode_Reward/pen_ang_vel_xy: -0.0234
   Episode_Reward/pen_joint_torque: -0.0087
    Episode_Reward/pen_joint_accel: -0.0063
    Episode_Reward/pen_action_rate: -0.0064
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0154
Episode_Reward/pen_flat_orientation: -0.0600
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0099
   Episode_Reward/foot_landing_vel: -0.0097
   Episode_Reward/test_gait_reward: -0.0581
Metrics/base_velocity/error_vel_xy: 0.3064
Metrics/base_velocity/error_vel_yaw: 0.0519
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 61.8333
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 1.07s
                        Total time: 354.92s
                               ETA: 2912.3s

################################################################################
                     [1m Learning iteration 326/3000 [0m                      

                       Computation: 91352 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.2949
                    Surrogate loss: -0.0021
             Mean action noise std: 0.4014
                     Learning rate: 0.0003
                       Mean reward: 0.48
               Mean episode length: 66.45
       Episode_Reward/keep_balance: 0.0654
     Episode_Reward/rew_lin_vel_xy: 0.0791
      Episode_Reward/rew_ang_vel_z: 0.2063
    Episode_Reward/pen_base_height: -0.1215
      Episode_Reward/pen_lin_vel_z: -0.0136
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0088
    Episode_Reward/pen_joint_accel: -0.0062
    Episode_Reward/pen_action_rate: -0.0065
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0157
Episode_Reward/pen_flat_orientation: -0.0601
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0097
   Episode_Reward/foot_landing_vel: -0.0099
   Episode_Reward/test_gait_reward: -0.0590
Metrics/base_velocity/error_vel_xy: 0.3087
Metrics/base_velocity/error_vel_yaw: 0.0522
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 63.2917
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 1.08s
                        Total time: 356.00s
                               ETA: 2911.1s

################################################################################
                     [1m Learning iteration 327/3000 [0m                      

                       Computation: 90757 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.3316
                    Surrogate loss: -0.0023
             Mean action noise std: 0.4010
                     Learning rate: 0.0009
                       Mean reward: 0.48
               Mean episode length: 67.88
       Episode_Reward/keep_balance: 0.0649
     Episode_Reward/rew_lin_vel_xy: 0.0791
      Episode_Reward/rew_ang_vel_z: 0.2053
    Episode_Reward/pen_base_height: -0.1198
      Episode_Reward/pen_lin_vel_z: -0.0137
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0087
    Episode_Reward/pen_joint_accel: -0.0061
    Episode_Reward/pen_action_rate: -0.0065
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0155
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0100
   Episode_Reward/foot_landing_vel: -0.0098
   Episode_Reward/test_gait_reward: -0.0583
Metrics/base_velocity/error_vel_xy: 0.3051
Metrics/base_velocity/error_vel_yaw: 0.0511
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 61.7500
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 1.08s
                        Total time: 357.08s
                               ETA: 2910.0s

################################################################################
                     [1m Learning iteration 328/3000 [0m                      

                       Computation: 91997 steps/s (collection: 0.944s, learning 0.124s)
               Value function loss: 0.3655
                    Surrogate loss: -0.0017
             Mean action noise std: 0.4012
                     Learning rate: 0.0019
                       Mean reward: -0.30
               Mean episode length: 62.94
       Episode_Reward/keep_balance: 0.0654
     Episode_Reward/rew_lin_vel_xy: 0.0765
      Episode_Reward/rew_ang_vel_z: 0.2063
    Episode_Reward/pen_base_height: -0.1201
      Episode_Reward/pen_lin_vel_z: -0.0137
     Episode_Reward/pen_ang_vel_xy: -0.0232
   Episode_Reward/pen_joint_torque: -0.0088
    Episode_Reward/pen_joint_accel: -0.0062
    Episode_Reward/pen_action_rate: -0.0065
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0157
Episode_Reward/pen_flat_orientation: -0.0590
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0101
   Episode_Reward/foot_landing_vel: -0.0099
   Episode_Reward/test_gait_reward: -0.0586
Metrics/base_velocity/error_vel_xy: 0.3065
Metrics/base_velocity/error_vel_yaw: 0.0521
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 62.1250
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 1.07s
                        Total time: 358.15s
                               ETA: 2908.7s

################################################################################
                     [1m Learning iteration 329/3000 [0m                      

                       Computation: 92235 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.4327
                    Surrogate loss: 0.0037
             Mean action noise std: 0.4019
                     Learning rate: 0.0006
                       Mean reward: 0.08
               Mean episode length: 66.87
       Episode_Reward/keep_balance: 0.0654
     Episode_Reward/rew_lin_vel_xy: 0.0828
      Episode_Reward/rew_ang_vel_z: 0.2065
    Episode_Reward/pen_base_height: -0.1210
      Episode_Reward/pen_lin_vel_z: -0.0139
     Episode_Reward/pen_ang_vel_xy: -0.0233
   Episode_Reward/pen_joint_torque: -0.0086
    Episode_Reward/pen_joint_accel: -0.0064
    Episode_Reward/pen_action_rate: -0.0065
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0158
Episode_Reward/pen_flat_orientation: -0.0612
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0101
   Episode_Reward/foot_landing_vel: -0.0099
   Episode_Reward/test_gait_reward: -0.0592
Metrics/base_velocity/error_vel_xy: 0.3062
Metrics/base_velocity/error_vel_yaw: 0.0524
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 62.2500
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 1.07s
                        Total time: 359.21s
                               ETA: 2907.5s

################################################################################
                     [1m Learning iteration 330/3000 [0m                      

                       Computation: 90924 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.2793
                    Surrogate loss: 0.0024
             Mean action noise std: 0.4022
                     Learning rate: 0.0003
                       Mean reward: -0.02
               Mean episode length: 65.65
       Episode_Reward/keep_balance: 0.0664
     Episode_Reward/rew_lin_vel_xy: 0.0810
      Episode_Reward/rew_ang_vel_z: 0.2090
    Episode_Reward/pen_base_height: -0.1228
      Episode_Reward/pen_lin_vel_z: -0.0136
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0090
    Episode_Reward/pen_joint_accel: -0.0064
    Episode_Reward/pen_action_rate: -0.0066
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0159
Episode_Reward/pen_flat_orientation: -0.0625
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0103
   Episode_Reward/foot_landing_vel: -0.0100
   Episode_Reward/test_gait_reward: -0.0594
Metrics/base_velocity/error_vel_xy: 0.3058
Metrics/base_velocity/error_vel_yaw: 0.0535
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 61.2083
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 1.08s
                        Total time: 360.30s
                               ETA: 2906.3s

################################################################################
                     [1m Learning iteration 331/3000 [0m                      

                       Computation: 91978 steps/s (collection: 0.943s, learning 0.126s)
               Value function loss: 0.2646
                    Surrogate loss: 0.0050
             Mean action noise std: 0.4023
                     Learning rate: 0.0001
                       Mean reward: 0.41
               Mean episode length: 69.28
       Episode_Reward/keep_balance: 0.0665
     Episode_Reward/rew_lin_vel_xy: 0.0822
      Episode_Reward/rew_ang_vel_z: 0.2100
    Episode_Reward/pen_base_height: -0.1215
      Episode_Reward/pen_lin_vel_z: -0.0134
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0090
    Episode_Reward/pen_joint_accel: -0.0065
    Episode_Reward/pen_action_rate: -0.0067
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0161
Episode_Reward/pen_flat_orientation: -0.0609
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0100
   Episode_Reward/foot_landing_vel: -0.0099
   Episode_Reward/test_gait_reward: -0.0601
Metrics/base_velocity/error_vel_xy: 0.3132
Metrics/base_velocity/error_vel_yaw: 0.0528
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 61.7500
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 1.07s
                        Total time: 361.36s
                               ETA: 2905.1s

################################################################################
                     [1m Learning iteration 332/3000 [0m                      

                       Computation: 91044 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.2621
                    Surrogate loss: -0.0011
             Mean action noise std: 0.4023
                     Learning rate: 0.0003
                       Mean reward: 0.06
               Mean episode length: 64.92
       Episode_Reward/keep_balance: 0.0665
     Episode_Reward/rew_lin_vel_xy: 0.0820
      Episode_Reward/rew_ang_vel_z: 0.2103
    Episode_Reward/pen_base_height: -0.1212
      Episode_Reward/pen_lin_vel_z: -0.0136
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0090
    Episode_Reward/pen_joint_accel: -0.0065
    Episode_Reward/pen_action_rate: -0.0067
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0160
Episode_Reward/pen_flat_orientation: -0.0600
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0104
   Episode_Reward/foot_landing_vel: -0.0100
   Episode_Reward/test_gait_reward: -0.0601
Metrics/base_velocity/error_vel_xy: 0.3081
Metrics/base_velocity/error_vel_yaw: 0.0524
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 61.1250
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 1.08s
                        Total time: 362.44s
                               ETA: 2903.9s

################################################################################
                     [1m Learning iteration 333/3000 [0m                      

                       Computation: 91575 steps/s (collection: 0.943s, learning 0.130s)
               Value function loss: 0.2774
                    Surrogate loss: -0.0009
             Mean action noise std: 0.4025
                     Learning rate: 0.0006
                       Mean reward: 0.35
               Mean episode length: 66.44
       Episode_Reward/keep_balance: 0.0663
     Episode_Reward/rew_lin_vel_xy: 0.0787
      Episode_Reward/rew_ang_vel_z: 0.2090
    Episode_Reward/pen_base_height: -0.1202
      Episode_Reward/pen_lin_vel_z: -0.0139
     Episode_Reward/pen_ang_vel_xy: -0.0232
   Episode_Reward/pen_joint_torque: -0.0091
    Episode_Reward/pen_joint_accel: -0.0065
    Episode_Reward/pen_action_rate: -0.0068
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0035
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0161
Episode_Reward/pen_flat_orientation: -0.0587
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0105
   Episode_Reward/foot_landing_vel: -0.0102
   Episode_Reward/test_gait_reward: -0.0595
Metrics/base_velocity/error_vel_xy: 0.3133
Metrics/base_velocity/error_vel_yaw: 0.0526
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 59.7917
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 1.07s
                        Total time: 363.52s
                               ETA: 2902.7s

################################################################################
                     [1m Learning iteration 334/3000 [0m                      

                       Computation: 91504 steps/s (collection: 0.945s, learning 0.129s)
               Value function loss: 0.2950
                    Surrogate loss: 0.0012
             Mean action noise std: 0.4023
                     Learning rate: 0.0003
                       Mean reward: 0.52
               Mean episode length: 68.69
       Episode_Reward/keep_balance: 0.0666
     Episode_Reward/rew_lin_vel_xy: 0.0811
      Episode_Reward/rew_ang_vel_z: 0.2099
    Episode_Reward/pen_base_height: -0.1212
      Episode_Reward/pen_lin_vel_z: -0.0140
     Episode_Reward/pen_ang_vel_xy: -0.0232
   Episode_Reward/pen_joint_torque: -0.0092
    Episode_Reward/pen_joint_accel: -0.0065
    Episode_Reward/pen_action_rate: -0.0069
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0035
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0162
Episode_Reward/pen_flat_orientation: -0.0588
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0106
   Episode_Reward/foot_landing_vel: -0.0102
   Episode_Reward/test_gait_reward: -0.0601
Metrics/base_velocity/error_vel_xy: 0.3129
Metrics/base_velocity/error_vel_yaw: 0.0530
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 60.1250
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 1.07s
                        Total time: 364.59s
                               ETA: 2901.5s

################################################################################
                     [1m Learning iteration 335/3000 [0m                      

                       Computation: 92196 steps/s (collection: 0.943s, learning 0.123s)
               Value function loss: 0.2764
                    Surrogate loss: -0.0022
             Mean action noise std: 0.4029
                     Learning rate: 0.0004
                       Mean reward: 0.16
               Mean episode length: 68.49
       Episode_Reward/keep_balance: 0.0678
     Episode_Reward/rew_lin_vel_xy: 0.0871
      Episode_Reward/rew_ang_vel_z: 0.2133
    Episode_Reward/pen_base_height: -0.1223
      Episode_Reward/pen_lin_vel_z: -0.0139
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0091
    Episode_Reward/pen_joint_accel: -0.0065
    Episode_Reward/pen_action_rate: -0.0069
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0035
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0166
Episode_Reward/pen_flat_orientation: -0.0601
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0105
   Episode_Reward/foot_landing_vel: -0.0101
   Episode_Reward/test_gait_reward: -0.0612
Metrics/base_velocity/error_vel_xy: 0.3090
Metrics/base_velocity/error_vel_yaw: 0.0545
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 59.5000
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 1.07s
                        Total time: 365.66s
                               ETA: 2900.2s

################################################################################
                     [1m Learning iteration 336/3000 [0m                      

                       Computation: 92239 steps/s (collection: 0.937s, learning 0.129s)
               Value function loss: 0.2884
                    Surrogate loss: -0.0021
             Mean action noise std: 0.4034
                     Learning rate: 0.0009
                       Mean reward: 0.36
               Mean episode length: 70.48
       Episode_Reward/keep_balance: 0.0679
     Episode_Reward/rew_lin_vel_xy: 0.0861
      Episode_Reward/rew_ang_vel_z: 0.2141
    Episode_Reward/pen_base_height: -0.1217
      Episode_Reward/pen_lin_vel_z: -0.0139
     Episode_Reward/pen_ang_vel_xy: -0.0232
   Episode_Reward/pen_joint_torque: -0.0093
    Episode_Reward/pen_joint_accel: -0.0067
    Episode_Reward/pen_action_rate: -0.0070
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0035
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0166
Episode_Reward/pen_flat_orientation: -0.0602
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0106
   Episode_Reward/foot_landing_vel: -0.0102
   Episode_Reward/test_gait_reward: -0.0613
Metrics/base_velocity/error_vel_xy: 0.3115
Metrics/base_velocity/error_vel_yaw: 0.0545
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 62.0833
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 1.07s
                        Total time: 366.72s
                               ETA: 2899.0s

################################################################################
                     [1m Learning iteration 337/3000 [0m                      

                       Computation: 90823 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.3404
                    Surrogate loss: -0.0019
             Mean action noise std: 0.4035
                     Learning rate: 0.0013
                       Mean reward: 0.59
               Mean episode length: 70.85
       Episode_Reward/keep_balance: 0.0676
     Episode_Reward/rew_lin_vel_xy: 0.0829
      Episode_Reward/rew_ang_vel_z: 0.2133
    Episode_Reward/pen_base_height: -0.1218
      Episode_Reward/pen_lin_vel_z: -0.0139
     Episode_Reward/pen_ang_vel_xy: -0.0231
   Episode_Reward/pen_joint_torque: -0.0091
    Episode_Reward/pen_joint_accel: -0.0066
    Episode_Reward/pen_action_rate: -0.0069
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0035
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0165
Episode_Reward/pen_flat_orientation: -0.0596
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0105
   Episode_Reward/foot_landing_vel: -0.0100
   Episode_Reward/test_gait_reward: -0.0614
Metrics/base_velocity/error_vel_xy: 0.3143
Metrics/base_velocity/error_vel_yaw: 0.0538
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 60.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 1.08s
                        Total time: 367.81s
                               ETA: 2897.8s

################################################################################
                     [1m Learning iteration 338/3000 [0m                      

                       Computation: 92526 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 0.3460
                    Surrogate loss: -0.0002
             Mean action noise std: 0.4045
                     Learning rate: 0.0019
                       Mean reward: 0.63
               Mean episode length: 67.21
       Episode_Reward/keep_balance: 0.0663
     Episode_Reward/rew_lin_vel_xy: 0.0798
      Episode_Reward/rew_ang_vel_z: 0.2091
    Episode_Reward/pen_base_height: -0.1207
      Episode_Reward/pen_lin_vel_z: -0.0138
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0091
    Episode_Reward/pen_joint_accel: -0.0065
    Episode_Reward/pen_action_rate: -0.0068
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0035
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0162
Episode_Reward/pen_flat_orientation: -0.0595
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0107
   Episode_Reward/foot_landing_vel: -0.0101
   Episode_Reward/test_gait_reward: -0.0602
Metrics/base_velocity/error_vel_xy: 0.3118
Metrics/base_velocity/error_vel_yaw: 0.0527
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 57.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 1.06s
                        Total time: 368.87s
                               ETA: 2896.5s

################################################################################
                     [1m Learning iteration 339/3000 [0m                      

                       Computation: 92346 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.3851
                    Surrogate loss: 0.0026
             Mean action noise std: 0.4052
                     Learning rate: 0.0009
                       Mean reward: 1.10
               Mean episode length: 74.76
       Episode_Reward/keep_balance: 0.0697
     Episode_Reward/rew_lin_vel_xy: 0.0910
      Episode_Reward/rew_ang_vel_z: 0.2193
    Episode_Reward/pen_base_height: -0.1229
      Episode_Reward/pen_lin_vel_z: -0.0142
     Episode_Reward/pen_ang_vel_xy: -0.0235
   Episode_Reward/pen_joint_torque: -0.0097
    Episode_Reward/pen_joint_accel: -0.0069
    Episode_Reward/pen_action_rate: -0.0073
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0024
   Episode_Reward/pen_joint_powers: -0.0037
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0171
Episode_Reward/pen_flat_orientation: -0.0603
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0115
   Episode_Reward/foot_landing_vel: -0.0104
   Episode_Reward/test_gait_reward: -0.0631
Metrics/base_velocity/error_vel_xy: 0.3194
Metrics/base_velocity/error_vel_yaw: 0.0557
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 58.5000
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 1.06s
                        Total time: 369.93s
                               ETA: 2895.3s

################################################################################
                     [1m Learning iteration 340/3000 [0m                      

                       Computation: 91130 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.3341
                    Surrogate loss: 0.0042
             Mean action noise std: 0.4051
                     Learning rate: 0.0003
                       Mean reward: 0.36
               Mean episode length: 69.29
       Episode_Reward/keep_balance: 0.0700
     Episode_Reward/rew_lin_vel_xy: 0.0848
      Episode_Reward/rew_ang_vel_z: 0.2203
    Episode_Reward/pen_base_height: -0.1229
      Episode_Reward/pen_lin_vel_z: -0.0142
     Episode_Reward/pen_ang_vel_xy: -0.0234
   Episode_Reward/pen_joint_torque: -0.0098
    Episode_Reward/pen_joint_accel: -0.0069
    Episode_Reward/pen_action_rate: -0.0073
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0024
   Episode_Reward/pen_joint_powers: -0.0037
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0173
Episode_Reward/pen_flat_orientation: -0.0602
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0114
   Episode_Reward/foot_landing_vel: -0.0105
   Episode_Reward/test_gait_reward: -0.0635
Metrics/base_velocity/error_vel_xy: 0.3283
Metrics/base_velocity/error_vel_yaw: 0.0562
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 59.1667
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 1.08s
                        Total time: 371.01s
                               ETA: 2894.1s

################################################################################
                     [1m Learning iteration 341/3000 [0m                      

                       Computation: 91731 steps/s (collection: 0.946s, learning 0.126s)
               Value function loss: 0.3735
                    Surrogate loss: 0.0002
             Mean action noise std: 0.4054
                     Learning rate: 0.0006
                       Mean reward: 0.22
               Mean episode length: 69.01
       Episode_Reward/keep_balance: 0.0706
     Episode_Reward/rew_lin_vel_xy: 0.0880
      Episode_Reward/rew_ang_vel_z: 0.2212
    Episode_Reward/pen_base_height: -0.1231
      Episode_Reward/pen_lin_vel_z: -0.0147
     Episode_Reward/pen_ang_vel_xy: -0.0236
   Episode_Reward/pen_joint_torque: -0.0098
    Episode_Reward/pen_joint_accel: -0.0067
    Episode_Reward/pen_action_rate: -0.0075
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0024
   Episode_Reward/pen_joint_powers: -0.0037
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0176
Episode_Reward/pen_flat_orientation: -0.0605
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0117
   Episode_Reward/foot_landing_vel: -0.0107
   Episode_Reward/test_gait_reward: -0.0640
Metrics/base_velocity/error_vel_xy: 0.3286
Metrics/base_velocity/error_vel_yaw: 0.0574
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 56.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 1.07s
                        Total time: 372.08s
                               ETA: 2892.9s

################################################################################
                     [1m Learning iteration 342/3000 [0m                      

                       Computation: 90507 steps/s (collection: 0.957s, learning 0.129s)
               Value function loss: 0.4194
                    Surrogate loss: 0.0023
             Mean action noise std: 0.4058
                     Learning rate: 0.0006
                       Mean reward: 0.36
               Mean episode length: 73.36
       Episode_Reward/keep_balance: 0.0691
     Episode_Reward/rew_lin_vel_xy: 0.0892
      Episode_Reward/rew_ang_vel_z: 0.2160
    Episode_Reward/pen_base_height: -0.1258
      Episode_Reward/pen_lin_vel_z: -0.0142
     Episode_Reward/pen_ang_vel_xy: -0.0233
   Episode_Reward/pen_joint_torque: -0.0095
    Episode_Reward/pen_joint_accel: -0.0070
    Episode_Reward/pen_action_rate: -0.0073
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0024
   Episode_Reward/pen_joint_powers: -0.0037
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0173
Episode_Reward/pen_flat_orientation: -0.0622
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0114
   Episode_Reward/foot_landing_vel: -0.0104
   Episode_Reward/test_gait_reward: -0.0634
Metrics/base_velocity/error_vel_xy: 0.3186
Metrics/base_velocity/error_vel_yaw: 0.0569
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 55.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 1.09s
                        Total time: 373.17s
                               ETA: 2891.8s

################################################################################
                     [1m Learning iteration 343/3000 [0m                      

                       Computation: 90610 steps/s (collection: 0.956s, learning 0.129s)
               Value function loss: 0.3954
                    Surrogate loss: 0.0072
             Mean action noise std: 0.4060
                     Learning rate: 0.0002
                       Mean reward: 0.10
               Mean episode length: 73.65
       Episode_Reward/keep_balance: 0.0729
     Episode_Reward/rew_lin_vel_xy: 0.0980
      Episode_Reward/rew_ang_vel_z: 0.2272
    Episode_Reward/pen_base_height: -0.1297
      Episode_Reward/pen_lin_vel_z: -0.0145
     Episode_Reward/pen_ang_vel_xy: -0.0234
   Episode_Reward/pen_joint_torque: -0.0101
    Episode_Reward/pen_joint_accel: -0.0072
    Episode_Reward/pen_action_rate: -0.0079
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0025
   Episode_Reward/pen_joint_powers: -0.0039
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0184
Episode_Reward/pen_flat_orientation: -0.0662
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0120
   Episode_Reward/foot_landing_vel: -0.0112
   Episode_Reward/test_gait_reward: -0.0666
Metrics/base_velocity/error_vel_xy: 0.3276
Metrics/base_velocity/error_vel_yaw: 0.0607
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 53.6667
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 1.08s
                        Total time: 374.25s
                               ETA: 2890.7s

################################################################################
                     [1m Learning iteration 344/3000 [0m                      

                       Computation: 90639 steps/s (collection: 0.955s, learning 0.130s)
               Value function loss: 0.3755
                    Surrogate loss: 0.0037
             Mean action noise std: 0.4062
                     Learning rate: 0.0002
                       Mean reward: 0.35
               Mean episode length: 74.84
       Episode_Reward/keep_balance: 0.0734
     Episode_Reward/rew_lin_vel_xy: 0.0985
      Episode_Reward/rew_ang_vel_z: 0.2281
    Episode_Reward/pen_base_height: -0.1308
      Episode_Reward/pen_lin_vel_z: -0.0144
     Episode_Reward/pen_ang_vel_xy: -0.0233
   Episode_Reward/pen_joint_torque: -0.0101
    Episode_Reward/pen_joint_accel: -0.0076
    Episode_Reward/pen_action_rate: -0.0078
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0025
   Episode_Reward/pen_joint_powers: -0.0039
Episode_Reward/pen_undesired_contacts: -0.0022
Episode_Reward/pen_action_smoothness: -0.0187
Episode_Reward/pen_flat_orientation: -0.0676
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0116
   Episode_Reward/foot_landing_vel: -0.0110
   Episode_Reward/test_gait_reward: -0.0673
Metrics/base_velocity/error_vel_xy: 0.3255
Metrics/base_velocity/error_vel_yaw: 0.0611
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 57.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 1.08s
                        Total time: 375.34s
                               ETA: 2889.6s

################################################################################
                     [1m Learning iteration 345/3000 [0m                      

                       Computation: 92345 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.3860
                    Surrogate loss: -0.0011
             Mean action noise std: 0.4063
                     Learning rate: 0.0004
                       Mean reward: 0.55
               Mean episode length: 75.88
       Episode_Reward/keep_balance: 0.0734
     Episode_Reward/rew_lin_vel_xy: 0.0925
      Episode_Reward/rew_ang_vel_z: 0.2284
    Episode_Reward/pen_base_height: -0.1302
      Episode_Reward/pen_lin_vel_z: -0.0144
     Episode_Reward/pen_ang_vel_xy: -0.0233
   Episode_Reward/pen_joint_torque: -0.0101
    Episode_Reward/pen_joint_accel: -0.0074
    Episode_Reward/pen_action_rate: -0.0078
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0025
   Episode_Reward/pen_joint_powers: -0.0038
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0186
Episode_Reward/pen_flat_orientation: -0.0674
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0114
   Episode_Reward/foot_landing_vel: -0.0109
   Episode_Reward/test_gait_reward: -0.0675
Metrics/base_velocity/error_vel_xy: 0.3324
Metrics/base_velocity/error_vel_yaw: 0.0612
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 57.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 1.06s
                        Total time: 376.40s
                               ETA: 2888.3s

################################################################################
                     [1m Learning iteration 346/3000 [0m                      

                       Computation: 92600 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 0.3932
                    Surrogate loss: -0.0019
             Mean action noise std: 0.4063
                     Learning rate: 0.0006
                       Mean reward: 0.09
               Mean episode length: 69.74
       Episode_Reward/keep_balance: 0.0723
     Episode_Reward/rew_lin_vel_xy: 0.0995
      Episode_Reward/rew_ang_vel_z: 0.2242
    Episode_Reward/pen_base_height: -0.1288
      Episode_Reward/pen_lin_vel_z: -0.0143
     Episode_Reward/pen_ang_vel_xy: -0.0235
   Episode_Reward/pen_joint_torque: -0.0100
    Episode_Reward/pen_joint_accel: -0.0073
    Episode_Reward/pen_action_rate: -0.0077
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0025
   Episode_Reward/pen_joint_powers: -0.0038
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0183
Episode_Reward/pen_flat_orientation: -0.0650
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0115
   Episode_Reward/foot_landing_vel: -0.0109
   Episode_Reward/test_gait_reward: -0.0666
Metrics/base_velocity/error_vel_xy: 0.3182
Metrics/base_velocity/error_vel_yaw: 0.0606
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 51.6667
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 1.06s
                        Total time: 377.47s
                               ETA: 2887.0s

################################################################################
                     [1m Learning iteration 347/3000 [0m                      

                       Computation: 90716 steps/s (collection: 0.955s, learning 0.129s)
               Value function loss: 0.3869
                    Surrogate loss: -0.0004
             Mean action noise std: 0.4064
                     Learning rate: 0.0004
                       Mean reward: 0.53
               Mean episode length: 77.74
       Episode_Reward/keep_balance: 0.0733
     Episode_Reward/rew_lin_vel_xy: 0.0988
      Episode_Reward/rew_ang_vel_z: 0.2264
    Episode_Reward/pen_base_height: -0.1315
      Episode_Reward/pen_lin_vel_z: -0.0145
     Episode_Reward/pen_ang_vel_xy: -0.0233
   Episode_Reward/pen_joint_torque: -0.0101
    Episode_Reward/pen_joint_accel: -0.0075
    Episode_Reward/pen_action_rate: -0.0079
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0025
   Episode_Reward/pen_joint_powers: -0.0039
Episode_Reward/pen_undesired_contacts: -0.0022
Episode_Reward/pen_action_smoothness: -0.0187
Episode_Reward/pen_flat_orientation: -0.0666
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0116
   Episode_Reward/foot_landing_vel: -0.0111
   Episode_Reward/test_gait_reward: -0.0675
Metrics/base_velocity/error_vel_xy: 0.3238
Metrics/base_velocity/error_vel_yaw: 0.0623
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 58.0417
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 1.08s
                        Total time: 378.55s
                               ETA: 2885.9s

################################################################################
                     [1m Learning iteration 348/3000 [0m                      

                       Computation: 91501 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.4079
                    Surrogate loss: 0.0024
             Mean action noise std: 0.4064
                     Learning rate: 0.0004
                       Mean reward: 0.46
               Mean episode length: 74.71
       Episode_Reward/keep_balance: 0.0736
     Episode_Reward/rew_lin_vel_xy: 0.0989
      Episode_Reward/rew_ang_vel_z: 0.2282
    Episode_Reward/pen_base_height: -0.1292
      Episode_Reward/pen_lin_vel_z: -0.0144
     Episode_Reward/pen_ang_vel_xy: -0.0235
   Episode_Reward/pen_joint_torque: -0.0103
    Episode_Reward/pen_joint_accel: -0.0073
    Episode_Reward/pen_action_rate: -0.0079
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0025
   Episode_Reward/pen_joint_powers: -0.0039
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0187
Episode_Reward/pen_flat_orientation: -0.0649
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0119
   Episode_Reward/foot_landing_vel: -0.0111
   Episode_Reward/test_gait_reward: -0.0680
Metrics/base_velocity/error_vel_xy: 0.3252
Metrics/base_velocity/error_vel_yaw: 0.0620
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 53.9167
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 1.07s
                        Total time: 379.62s
                               ETA: 2884.7s

################################################################################
                     [1m Learning iteration 349/3000 [0m                      

                       Computation: 91557 steps/s (collection: 0.949s, learning 0.124s)
               Value function loss: 0.3864
                    Surrogate loss: -0.0000
             Mean action noise std: 0.4068
                     Learning rate: 0.0006
                       Mean reward: 0.32
               Mean episode length: 71.67
       Episode_Reward/keep_balance: 0.0743
     Episode_Reward/rew_lin_vel_xy: 0.0968
      Episode_Reward/rew_ang_vel_z: 0.2305
    Episode_Reward/pen_base_height: -0.1291
      Episode_Reward/pen_lin_vel_z: -0.0146
     Episode_Reward/pen_ang_vel_xy: -0.0237
   Episode_Reward/pen_joint_torque: -0.0105
    Episode_Reward/pen_joint_accel: -0.0072
    Episode_Reward/pen_action_rate: -0.0080
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0025
   Episode_Reward/pen_joint_powers: -0.0040
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0188
Episode_Reward/pen_flat_orientation: -0.0656
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0122
   Episode_Reward/foot_landing_vel: -0.0113
   Episode_Reward/test_gait_reward: -0.0683
Metrics/base_velocity/error_vel_xy: 0.3334
Metrics/base_velocity/error_vel_yaw: 0.0626
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 52.1250
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 1.07s
                        Total time: 380.70s
                               ETA: 2883.5s

################################################################################
                     [1m Learning iteration 350/3000 [0m                      

                       Computation: 92226 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 0.3992
                    Surrogate loss: -0.0019
             Mean action noise std: 0.4074
                     Learning rate: 0.0013
                       Mean reward: 0.92
               Mean episode length: 73.30
       Episode_Reward/keep_balance: 0.0745
     Episode_Reward/rew_lin_vel_xy: 0.1046
      Episode_Reward/rew_ang_vel_z: 0.2301
    Episode_Reward/pen_base_height: -0.1303
      Episode_Reward/pen_lin_vel_z: -0.0144
     Episode_Reward/pen_ang_vel_xy: -0.0235
   Episode_Reward/pen_joint_torque: -0.0105
    Episode_Reward/pen_joint_accel: -0.0073
    Episode_Reward/pen_action_rate: -0.0081
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0025
   Episode_Reward/pen_joint_powers: -0.0040
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0189
Episode_Reward/pen_flat_orientation: -0.0674
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0122
   Episode_Reward/foot_landing_vel: -0.0113
   Episode_Reward/test_gait_reward: -0.0686
Metrics/base_velocity/error_vel_xy: 0.3256
Metrics/base_velocity/error_vel_yaw: 0.0638
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 54.1250
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 1.07s
                        Total time: 381.76s
                               ETA: 2882.3s

################################################################################
                     [1m Learning iteration 351/3000 [0m                      

                       Computation: 92408 steps/s (collection: 0.940s, learning 0.124s)
               Value function loss: 0.5399
                    Surrogate loss: -0.0013
             Mean action noise std: 0.4078
                     Learning rate: 0.0029
                       Mean reward: 0.75
               Mean episode length: 79.30
       Episode_Reward/keep_balance: 0.0747
     Episode_Reward/rew_lin_vel_xy: 0.0963
      Episode_Reward/rew_ang_vel_z: 0.2328
    Episode_Reward/pen_base_height: -0.1286
      Episode_Reward/pen_lin_vel_z: -0.0142
     Episode_Reward/pen_ang_vel_xy: -0.0237
   Episode_Reward/pen_joint_torque: -0.0104
    Episode_Reward/pen_joint_accel: -0.0075
    Episode_Reward/pen_action_rate: -0.0081
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0025
   Episode_Reward/pen_joint_powers: -0.0039
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0189
Episode_Reward/pen_flat_orientation: -0.0657
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0123
   Episode_Reward/foot_landing_vel: -0.0112
   Episode_Reward/test_gait_reward: -0.0686
Metrics/base_velocity/error_vel_xy: 0.3354
Metrics/base_velocity/error_vel_yaw: 0.0618
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 53.1250
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 1.06s
                        Total time: 382.83s
                               ETA: 2881.0s

################################################################################
                     [1m Learning iteration 352/3000 [0m                      

                       Computation: 93428 steps/s (collection: 0.930s, learning 0.122s)
               Value function loss: 0.5564
                    Surrogate loss: 0.0023
             Mean action noise std: 0.4082
                     Learning rate: 0.0006
                       Mean reward: 0.73
               Mean episode length: 77.62
       Episode_Reward/keep_balance: 0.0760
     Episode_Reward/rew_lin_vel_xy: 0.0952
      Episode_Reward/rew_ang_vel_z: 0.2367
    Episode_Reward/pen_base_height: -0.1305
      Episode_Reward/pen_lin_vel_z: -0.0145
     Episode_Reward/pen_ang_vel_xy: -0.0237
   Episode_Reward/pen_joint_torque: -0.0109
    Episode_Reward/pen_joint_accel: -0.0076
    Episode_Reward/pen_action_rate: -0.0083
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0026
   Episode_Reward/pen_joint_powers: -0.0041
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0193
Episode_Reward/pen_flat_orientation: -0.0679
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0128
   Episode_Reward/foot_landing_vel: -0.0119
   Episode_Reward/test_gait_reward: -0.0695
Metrics/base_velocity/error_vel_xy: 0.3437
Metrics/base_velocity/error_vel_yaw: 0.0630
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 52.6667
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 1.05s
                        Total time: 383.88s
                               ETA: 2879.6s

################################################################################
                     [1m Learning iteration 353/3000 [0m                      

                       Computation: 91343 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.4253
                    Surrogate loss: 0.0005
             Mean action noise std: 0.4081
                     Learning rate: 0.0006
                       Mean reward: 0.55
               Mean episode length: 76.97
       Episode_Reward/keep_balance: 0.0776
     Episode_Reward/rew_lin_vel_xy: 0.1077
      Episode_Reward/rew_ang_vel_z: 0.2406
    Episode_Reward/pen_base_height: -0.1297
      Episode_Reward/pen_lin_vel_z: -0.0147
     Episode_Reward/pen_ang_vel_xy: -0.0239
   Episode_Reward/pen_joint_torque: -0.0110
    Episode_Reward/pen_joint_accel: -0.0079
    Episode_Reward/pen_action_rate: -0.0086
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0027
   Episode_Reward/pen_joint_powers: -0.0041
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0200
Episode_Reward/pen_flat_orientation: -0.0670
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0131
   Episode_Reward/foot_landing_vel: -0.0119
   Episode_Reward/test_gait_reward: -0.0708
Metrics/base_velocity/error_vel_xy: 0.3404
Metrics/base_velocity/error_vel_yaw: 0.0653
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 50.9583
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 1.08s
                        Total time: 384.96s
                               ETA: 2878.5s

################################################################################
                     [1m Learning iteration 354/3000 [0m                      

                       Computation: 92197 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 0.3966
                    Surrogate loss: 0.0028
             Mean action noise std: 0.4082
                     Learning rate: 0.0003
                       Mean reward: 0.19
               Mean episode length: 73.42
       Episode_Reward/keep_balance: 0.0771
     Episode_Reward/rew_lin_vel_xy: 0.1012
      Episode_Reward/rew_ang_vel_z: 0.2392
    Episode_Reward/pen_base_height: -0.1297
      Episode_Reward/pen_lin_vel_z: -0.0146
     Episode_Reward/pen_ang_vel_xy: -0.0241
   Episode_Reward/pen_joint_torque: -0.0109
    Episode_Reward/pen_joint_accel: -0.0079
    Episode_Reward/pen_action_rate: -0.0085
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0027
   Episode_Reward/pen_joint_powers: -0.0041
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0198
Episode_Reward/pen_flat_orientation: -0.0666
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0129
   Episode_Reward/foot_landing_vel: -0.0118
   Episode_Reward/test_gait_reward: -0.0708
Metrics/base_velocity/error_vel_xy: 0.3368
Metrics/base_velocity/error_vel_yaw: 0.0644
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 50.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 1.07s
                        Total time: 386.02s
                               ETA: 2877.2s

################################################################################
                     [1m Learning iteration 355/3000 [0m                      

                       Computation: 91970 steps/s (collection: 0.945s, learning 0.124s)
               Value function loss: 0.3940
                    Surrogate loss: -0.0021
             Mean action noise std: 0.4087
                     Learning rate: 0.0006
                       Mean reward: 0.99
               Mean episode length: 81.83
       Episode_Reward/keep_balance: 0.0793
     Episode_Reward/rew_lin_vel_xy: 0.1145
      Episode_Reward/rew_ang_vel_z: 0.2460
    Episode_Reward/pen_base_height: -0.1291
      Episode_Reward/pen_lin_vel_z: -0.0150
     Episode_Reward/pen_ang_vel_xy: -0.0243
   Episode_Reward/pen_joint_torque: -0.0114
    Episode_Reward/pen_joint_accel: -0.0078
    Episode_Reward/pen_action_rate: -0.0088
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0027
   Episode_Reward/pen_joint_powers: -0.0042
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0203
Episode_Reward/pen_flat_orientation: -0.0667
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0137
   Episode_Reward/foot_landing_vel: -0.0120
   Episode_Reward/test_gait_reward: -0.0722
Metrics/base_velocity/error_vel_xy: 0.3465
Metrics/base_velocity/error_vel_yaw: 0.0663
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 50.2500
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 1.07s
                        Total time: 387.09s
                               ETA: 2876.0s

################################################################################
                     [1m Learning iteration 356/3000 [0m                      

                       Computation: 91582 steps/s (collection: 0.948s, learning 0.126s)
               Value function loss: 0.4060
                    Surrogate loss: -0.0007
             Mean action noise std: 0.4093
                     Learning rate: 0.0009
                       Mean reward: 0.58
               Mean episode length: 79.56
       Episode_Reward/keep_balance: 0.0788
     Episode_Reward/rew_lin_vel_xy: 0.1057
      Episode_Reward/rew_ang_vel_z: 0.2461
    Episode_Reward/pen_base_height: -0.1287
      Episode_Reward/pen_lin_vel_z: -0.0149
     Episode_Reward/pen_ang_vel_xy: -0.0246
   Episode_Reward/pen_joint_torque: -0.0112
    Episode_Reward/pen_joint_accel: -0.0077
    Episode_Reward/pen_action_rate: -0.0088
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0028
   Episode_Reward/pen_joint_powers: -0.0042
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0202
Episode_Reward/pen_flat_orientation: -0.0679
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0141
   Episode_Reward/foot_landing_vel: -0.0121
   Episode_Reward/test_gait_reward: -0.0718
Metrics/base_velocity/error_vel_xy: 0.3539
Metrics/base_velocity/error_vel_yaw: 0.0646
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 50.5000
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 1.07s
                        Total time: 388.16s
                               ETA: 2874.8s

################################################################################
                     [1m Learning iteration 357/3000 [0m                      

                       Computation: 90522 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.3976
                    Surrogate loss: 0.0009
             Mean action noise std: 0.4093
                     Learning rate: 0.0006
                       Mean reward: 1.41
               Mean episode length: 84.55
       Episode_Reward/keep_balance: 0.0805
     Episode_Reward/rew_lin_vel_xy: 0.1108
      Episode_Reward/rew_ang_vel_z: 0.2493
    Episode_Reward/pen_base_height: -0.1328
      Episode_Reward/pen_lin_vel_z: -0.0151
     Episode_Reward/pen_ang_vel_xy: -0.0243
   Episode_Reward/pen_joint_torque: -0.0113
    Episode_Reward/pen_joint_accel: -0.0081
    Episode_Reward/pen_action_rate: -0.0090
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0028
   Episode_Reward/pen_joint_powers: -0.0043
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0208
Episode_Reward/pen_flat_orientation: -0.0712
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0141
   Episode_Reward/foot_landing_vel: -0.0124
   Episode_Reward/test_gait_reward: -0.0733
Metrics/base_velocity/error_vel_xy: 0.3520
Metrics/base_velocity/error_vel_yaw: 0.0674
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 51.0417
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 1.09s
                        Total time: 389.25s
                               ETA: 2873.7s

################################################################################
                     [1m Learning iteration 358/3000 [0m                      

                       Computation: 92245 steps/s (collection: 0.940s, learning 0.126s)
               Value function loss: 0.3948
                    Surrogate loss: 0.0008
             Mean action noise std: 0.4092
                     Learning rate: 0.0009
                       Mean reward: 0.90
               Mean episode length: 80.67
       Episode_Reward/keep_balance: 0.0806
     Episode_Reward/rew_lin_vel_xy: 0.1095
      Episode_Reward/rew_ang_vel_z: 0.2497
    Episode_Reward/pen_base_height: -0.1315
      Episode_Reward/pen_lin_vel_z: -0.0150
     Episode_Reward/pen_ang_vel_xy: -0.0244
   Episode_Reward/pen_joint_torque: -0.0115
    Episode_Reward/pen_joint_accel: -0.0081
    Episode_Reward/pen_action_rate: -0.0090
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0028
   Episode_Reward/pen_joint_powers: -0.0043
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0207
Episode_Reward/pen_flat_orientation: -0.0707
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0146
   Episode_Reward/foot_landing_vel: -0.0124
   Episode_Reward/test_gait_reward: -0.0730
Metrics/base_velocity/error_vel_xy: 0.3569
Metrics/base_velocity/error_vel_yaw: 0.0676
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 48.6667
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 1.07s
                        Total time: 390.32s
                               ETA: 2872.5s

################################################################################
                     [1m Learning iteration 359/3000 [0m                      

                       Computation: 93066 steps/s (collection: 0.934s, learning 0.123s)
               Value function loss: 0.4781
                    Surrogate loss: -0.0019
             Mean action noise std: 0.4096
                     Learning rate: 0.0013
                       Mean reward: 0.69
               Mean episode length: 76.99
       Episode_Reward/keep_balance: 0.0816
     Episode_Reward/rew_lin_vel_xy: 0.1135
      Episode_Reward/rew_ang_vel_z: 0.2542
    Episode_Reward/pen_base_height: -0.1311
      Episode_Reward/pen_lin_vel_z: -0.0149
     Episode_Reward/pen_ang_vel_xy: -0.0246
   Episode_Reward/pen_joint_torque: -0.0116
    Episode_Reward/pen_joint_accel: -0.0081
    Episode_Reward/pen_action_rate: -0.0090
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0028
   Episode_Reward/pen_joint_powers: -0.0043
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0210
Episode_Reward/pen_flat_orientation: -0.0688
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0142
   Episode_Reward/foot_landing_vel: -0.0121
   Episode_Reward/test_gait_reward: -0.0748
Metrics/base_velocity/error_vel_xy: 0.3586
Metrics/base_velocity/error_vel_yaw: 0.0677
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 50.2500
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 1.06s
                        Total time: 391.37s
                               ETA: 2871.1s

################################################################################
                     [1m Learning iteration 360/3000 [0m                      

                       Computation: 93175 steps/s (collection: 0.931s, learning 0.124s)
               Value function loss: 0.4589
                    Surrogate loss: 0.0009
             Mean action noise std: 0.4102
                     Learning rate: 0.0006
                       Mean reward: 0.85
               Mean episode length: 84.11
       Episode_Reward/keep_balance: 0.0802
     Episode_Reward/rew_lin_vel_xy: 0.1066
      Episode_Reward/rew_ang_vel_z: 0.2492
    Episode_Reward/pen_base_height: -0.1311
      Episode_Reward/pen_lin_vel_z: -0.0152
     Episode_Reward/pen_ang_vel_xy: -0.0245
   Episode_Reward/pen_joint_torque: -0.0115
    Episode_Reward/pen_joint_accel: -0.0079
    Episode_Reward/pen_action_rate: -0.0090
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0028
   Episode_Reward/pen_joint_powers: -0.0044
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0207
Episode_Reward/pen_flat_orientation: -0.0695
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0149
   Episode_Reward/foot_landing_vel: -0.0123
   Episode_Reward/test_gait_reward: -0.0733
Metrics/base_velocity/error_vel_xy: 0.3582
Metrics/base_velocity/error_vel_yaw: 0.0666
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 46.3333
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 1.06s
                        Total time: 392.43s
                               ETA: 2869.8s

################################################################################
                     [1m Learning iteration 361/3000 [0m                      

                       Computation: 93471 steps/s (collection: 0.930s, learning 0.122s)
               Value function loss: 0.4297
                    Surrogate loss: 0.0033
             Mean action noise std: 0.4104
                     Learning rate: 0.0003
                       Mean reward: 1.23
               Mean episode length: 81.11
       Episode_Reward/keep_balance: 0.0836
     Episode_Reward/rew_lin_vel_xy: 0.1147
      Episode_Reward/rew_ang_vel_z: 0.2591
    Episode_Reward/pen_base_height: -0.1334
      Episode_Reward/pen_lin_vel_z: -0.0155
     Episode_Reward/pen_ang_vel_xy: -0.0248
   Episode_Reward/pen_joint_torque: -0.0121
    Episode_Reward/pen_joint_accel: -0.0083
    Episode_Reward/pen_action_rate: -0.0095
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0030
   Episode_Reward/pen_joint_powers: -0.0046
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0216
Episode_Reward/pen_flat_orientation: -0.0706
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0157
   Episode_Reward/foot_landing_vel: -0.0128
   Episode_Reward/test_gait_reward: -0.0767
Metrics/base_velocity/error_vel_xy: 0.3636
Metrics/base_velocity/error_vel_yaw: 0.0707
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 48.6667
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 1.05s
                        Total time: 393.48s
                               ETA: 2868.5s

################################################################################
                     [1m Learning iteration 362/3000 [0m                      

                       Computation: 92348 steps/s (collection: 0.941s, learning 0.124s)
               Value function loss: 0.4377
                    Surrogate loss: 0.0009
             Mean action noise std: 0.4108
                     Learning rate: 0.0003
                       Mean reward: 1.26
               Mean episode length: 88.52
       Episode_Reward/keep_balance: 0.0846
     Episode_Reward/rew_lin_vel_xy: 0.1136
      Episode_Reward/rew_ang_vel_z: 0.2627
    Episode_Reward/pen_base_height: -0.1307
      Episode_Reward/pen_lin_vel_z: -0.0158
     Episode_Reward/pen_ang_vel_xy: -0.0252
   Episode_Reward/pen_joint_torque: -0.0125
    Episode_Reward/pen_joint_accel: -0.0081
    Episode_Reward/pen_action_rate: -0.0097
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0030
   Episode_Reward/pen_joint_powers: -0.0046
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0221
Episode_Reward/pen_flat_orientation: -0.0687
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0162
   Episode_Reward/foot_landing_vel: -0.0130
   Episode_Reward/test_gait_reward: -0.0772
Metrics/base_velocity/error_vel_xy: 0.3784
Metrics/base_velocity/error_vel_yaw: 0.0705
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 46.7083
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 1.06s
                        Total time: 394.54s
                               ETA: 2867.2s

################################################################################
                     [1m Learning iteration 363/3000 [0m                      

                       Computation: 92055 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.4364
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4110
                     Learning rate: 0.0006
                       Mean reward: 1.68
               Mean episode length: 89.74
       Episode_Reward/keep_balance: 0.0843
     Episode_Reward/rew_lin_vel_xy: 0.1167
      Episode_Reward/rew_ang_vel_z: 0.2614
    Episode_Reward/pen_base_height: -0.1317
      Episode_Reward/pen_lin_vel_z: -0.0160
     Episode_Reward/pen_ang_vel_xy: -0.0253
   Episode_Reward/pen_joint_torque: -0.0126
    Episode_Reward/pen_joint_accel: -0.0085
    Episode_Reward/pen_action_rate: -0.0097
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0031
   Episode_Reward/pen_joint_powers: -0.0047
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0219
Episode_Reward/pen_flat_orientation: -0.0691
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0165
   Episode_Reward/foot_landing_vel: -0.0129
   Episode_Reward/test_gait_reward: -0.0773
Metrics/base_velocity/error_vel_xy: 0.3726
Metrics/base_velocity/error_vel_yaw: 0.0706
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 44.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 1.07s
                        Total time: 395.61s
                               ETA: 2866.0s

################################################################################
                     [1m Learning iteration 364/3000 [0m                      

                       Computation: 92098 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 0.4999
                    Surrogate loss: 0.0002
             Mean action noise std: 0.4111
                     Learning rate: 0.0006
                       Mean reward: 2.12
               Mean episode length: 95.33
       Episode_Reward/keep_balance: 0.0850
     Episode_Reward/rew_lin_vel_xy: 0.1185
      Episode_Reward/rew_ang_vel_z: 0.2642
    Episode_Reward/pen_base_height: -0.1329
      Episode_Reward/pen_lin_vel_z: -0.0157
     Episode_Reward/pen_ang_vel_xy: -0.0248
   Episode_Reward/pen_joint_torque: -0.0124
    Episode_Reward/pen_joint_accel: -0.0082
    Episode_Reward/pen_action_rate: -0.0098
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0030
   Episode_Reward/pen_joint_powers: -0.0047
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0221
Episode_Reward/pen_flat_orientation: -0.0700
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0164
   Episode_Reward/foot_landing_vel: -0.0131
   Episode_Reward/test_gait_reward: -0.0787
Metrics/base_velocity/error_vel_xy: 0.3692
Metrics/base_velocity/error_vel_yaw: 0.0704
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 46.4167
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 1.07s
                        Total time: 396.68s
                               ETA: 2864.8s

################################################################################
                     [1m Learning iteration 365/3000 [0m                      

                       Computation: 93024 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 0.4573
                    Surrogate loss: 0.0115
             Mean action noise std: 0.4113
                     Learning rate: 0.0001
                       Mean reward: 0.82
               Mean episode length: 86.09
       Episode_Reward/keep_balance: 0.0856
     Episode_Reward/rew_lin_vel_xy: 0.1177
      Episode_Reward/rew_ang_vel_z: 0.2664
    Episode_Reward/pen_base_height: -0.1342
      Episode_Reward/pen_lin_vel_z: -0.0159
     Episode_Reward/pen_ang_vel_xy: -0.0249
   Episode_Reward/pen_joint_torque: -0.0125
    Episode_Reward/pen_joint_accel: -0.0084
    Episode_Reward/pen_action_rate: -0.0098
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0030
   Episode_Reward/pen_joint_powers: -0.0047
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0223
Episode_Reward/pen_flat_orientation: -0.0715
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0160
   Episode_Reward/foot_landing_vel: -0.0130
   Episode_Reward/test_gait_reward: -0.0792
Metrics/base_velocity/error_vel_xy: 0.3777
Metrics/base_velocity/error_vel_yaw: 0.0715
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 45.7083
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 1.06s
                        Total time: 397.73s
                               ETA: 2863.5s

################################################################################
                     [1m Learning iteration 366/3000 [0m                      

                       Computation: 92136 steps/s (collection: 0.943s, learning 0.123s)
               Value function loss: 0.4381
                    Surrogate loss: 0.0011
             Mean action noise std: 0.4117
                     Learning rate: 0.0004
                       Mean reward: 1.35
               Mean episode length: 94.41
       Episode_Reward/keep_balance: 0.0903
     Episode_Reward/rew_lin_vel_xy: 0.1282
      Episode_Reward/rew_ang_vel_z: 0.2800
    Episode_Reward/pen_base_height: -0.1379
      Episode_Reward/pen_lin_vel_z: -0.0165
     Episode_Reward/pen_ang_vel_xy: -0.0252
   Episode_Reward/pen_joint_torque: -0.0132
    Episode_Reward/pen_joint_accel: -0.0092
    Episode_Reward/pen_action_rate: -0.0105
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0032
   Episode_Reward/pen_joint_powers: -0.0050
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0239
Episode_Reward/pen_flat_orientation: -0.0742
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0175
   Episode_Reward/foot_landing_vel: -0.0138
   Episode_Reward/test_gait_reward: -0.0836
Metrics/base_velocity/error_vel_xy: 0.3893
Metrics/base_velocity/error_vel_yaw: 0.0764
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 43.3750
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 1.07s
                        Total time: 398.80s
                               ETA: 2862.2s

################################################################################
                     [1m Learning iteration 367/3000 [0m                      

                       Computation: 91575 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.4379
                    Surrogate loss: -0.0015
             Mean action noise std: 0.4119
                     Learning rate: 0.0006
                       Mean reward: 1.81
               Mean episode length: 95.08
       Episode_Reward/keep_balance: 0.0914
     Episode_Reward/rew_lin_vel_xy: 0.1327
      Episode_Reward/rew_ang_vel_z: 0.2833
    Episode_Reward/pen_base_height: -0.1398
      Episode_Reward/pen_lin_vel_z: -0.0164
     Episode_Reward/pen_ang_vel_xy: -0.0253
   Episode_Reward/pen_joint_torque: -0.0134
    Episode_Reward/pen_joint_accel: -0.0091
    Episode_Reward/pen_action_rate: -0.0106
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0032
   Episode_Reward/pen_joint_powers: -0.0050
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0244
Episode_Reward/pen_flat_orientation: -0.0743
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0168
   Episode_Reward/foot_landing_vel: -0.0140
   Episode_Reward/test_gait_reward: -0.0846
Metrics/base_velocity/error_vel_xy: 0.3837
Metrics/base_velocity/error_vel_yaw: 0.0773
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 46.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 1.07s
                        Total time: 399.88s
                               ETA: 2861.1s

################################################################################
                     [1m Learning iteration 368/3000 [0m                      

                       Computation: 89842 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.5321
                    Surrogate loss: -0.0007
             Mean action noise std: 0.4120
                     Learning rate: 0.0013
                       Mean reward: 0.67
               Mean episode length: 87.62
       Episode_Reward/keep_balance: 0.0900
     Episode_Reward/rew_lin_vel_xy: 0.1204
      Episode_Reward/rew_ang_vel_z: 0.2777
    Episode_Reward/pen_base_height: -0.1408
      Episode_Reward/pen_lin_vel_z: -0.0166
     Episode_Reward/pen_ang_vel_xy: -0.0252
   Episode_Reward/pen_joint_torque: -0.0137
    Episode_Reward/pen_joint_accel: -0.0088
    Episode_Reward/pen_action_rate: -0.0106
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0032
   Episode_Reward/pen_joint_powers: -0.0050
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0241
Episode_Reward/pen_flat_orientation: -0.0735
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0169
   Episode_Reward/foot_landing_vel: -0.0139
   Episode_Reward/test_gait_reward: -0.0834
Metrics/base_velocity/error_vel_xy: 0.3844
Metrics/base_velocity/error_vel_yaw: 0.0772
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 45.4583
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 1.09s
                        Total time: 400.97s
                               ETA: 2860.0s

################################################################################
                     [1m Learning iteration 369/3000 [0m                      

                       Computation: 93671 steps/s (collection: 0.928s, learning 0.122s)
               Value function loss: 0.6120
                    Surrogate loss: 0.0018
             Mean action noise std: 0.4120
                     Learning rate: 0.0013
                       Mean reward: 1.26
               Mean episode length: 86.83
       Episode_Reward/keep_balance: 0.0891
     Episode_Reward/rew_lin_vel_xy: 0.1283
      Episode_Reward/rew_ang_vel_z: 0.2760
    Episode_Reward/pen_base_height: -0.1395
      Episode_Reward/pen_lin_vel_z: -0.0163
     Episode_Reward/pen_ang_vel_xy: -0.0252
   Episode_Reward/pen_joint_torque: -0.0132
    Episode_Reward/pen_joint_accel: -0.0090
    Episode_Reward/pen_action_rate: -0.0104
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0032
   Episode_Reward/pen_joint_powers: -0.0049
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0237
Episode_Reward/pen_flat_orientation: -0.0721
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0166
   Episode_Reward/foot_landing_vel: -0.0136
   Episode_Reward/test_gait_reward: -0.0827
Metrics/base_velocity/error_vel_xy: 0.3751
Metrics/base_velocity/error_vel_yaw: 0.0755
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 41.8333
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 1.05s
                        Total time: 402.02s
                               ETA: 2858.7s

################################################################################
                     [1m Learning iteration 370/3000 [0m                      

                       Computation: 92857 steps/s (collection: 0.937s, learning 0.122s)
               Value function loss: 0.4915
                    Surrogate loss: 0.0029
             Mean action noise std: 0.4118
                     Learning rate: 0.0004
                       Mean reward: 0.55
               Mean episode length: 91.16
       Episode_Reward/keep_balance: 0.0902
     Episode_Reward/rew_lin_vel_xy: 0.1255
      Episode_Reward/rew_ang_vel_z: 0.2779
    Episode_Reward/pen_base_height: -0.1422
      Episode_Reward/pen_lin_vel_z: -0.0161
     Episode_Reward/pen_ang_vel_xy: -0.0248
   Episode_Reward/pen_joint_torque: -0.0133
    Episode_Reward/pen_joint_accel: -0.0091
    Episode_Reward/pen_action_rate: -0.0105
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0031
   Episode_Reward/pen_joint_powers: -0.0049
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0243
Episode_Reward/pen_flat_orientation: -0.0729
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0164
   Episode_Reward/foot_landing_vel: -0.0140
   Episode_Reward/test_gait_reward: -0.0842
Metrics/base_velocity/error_vel_xy: 0.3880
Metrics/base_velocity/error_vel_yaw: 0.0778
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 43.4583
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 1.06s
                        Total time: 403.08s
                               ETA: 2857.4s

################################################################################
                     [1m Learning iteration 371/3000 [0m                      

                       Computation: 91217 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.5438
                    Surrogate loss: 0.0126
             Mean action noise std: 0.4118
                     Learning rate: 0.0000
                       Mean reward: 1.30
               Mean episode length: 93.39
       Episode_Reward/keep_balance: 0.0910
     Episode_Reward/rew_lin_vel_xy: 0.1352
      Episode_Reward/rew_ang_vel_z: 0.2812
    Episode_Reward/pen_base_height: -0.1413
      Episode_Reward/pen_lin_vel_z: -0.0164
     Episode_Reward/pen_ang_vel_xy: -0.0251
   Episode_Reward/pen_joint_torque: -0.0135
    Episode_Reward/pen_joint_accel: -0.0093
    Episode_Reward/pen_action_rate: -0.0106
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0032
   Episode_Reward/pen_joint_powers: -0.0050
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0247
Episode_Reward/pen_flat_orientation: -0.0717
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0165
   Episode_Reward/foot_landing_vel: -0.0137
   Episode_Reward/test_gait_reward: -0.0849
Metrics/base_velocity/error_vel_xy: 0.3733
Metrics/base_velocity/error_vel_yaw: 0.0775
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 42.6250
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 1.08s
                        Total time: 404.16s
                               ETA: 2856.2s

################################################################################
                     [1m Learning iteration 372/3000 [0m                      

                       Computation: 92470 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 0.5120
                    Surrogate loss: -0.0002
             Mean action noise std: 0.4119
                     Learning rate: 0.0004
                       Mean reward: 1.33
               Mean episode length: 96.86
       Episode_Reward/keep_balance: 0.0906
     Episode_Reward/rew_lin_vel_xy: 0.1296
      Episode_Reward/rew_ang_vel_z: 0.2807
    Episode_Reward/pen_base_height: -0.1402
      Episode_Reward/pen_lin_vel_z: -0.0164
     Episode_Reward/pen_ang_vel_xy: -0.0251
   Episode_Reward/pen_joint_torque: -0.0138
    Episode_Reward/pen_joint_accel: -0.0087
    Episode_Reward/pen_action_rate: -0.0106
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0031
   Episode_Reward/pen_joint_powers: -0.0050
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0244
Episode_Reward/pen_flat_orientation: -0.0697
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0165
   Episode_Reward/foot_landing_vel: -0.0138
   Episode_Reward/test_gait_reward: -0.0842
Metrics/base_velocity/error_vel_xy: 0.3775
Metrics/base_velocity/error_vel_yaw: 0.0764
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 42.9167
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 1.06s
                        Total time: 405.22s
                               ETA: 2855.0s

################################################################################
                     [1m Learning iteration 373/3000 [0m                      

                       Computation: 92556 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 0.5308
                    Surrogate loss: 0.0003
             Mean action noise std: 0.4120
                     Learning rate: 0.0006
                       Mean reward: 1.65
               Mean episode length: 96.35
       Episode_Reward/keep_balance: 0.0932
     Episode_Reward/rew_lin_vel_xy: 0.1366
      Episode_Reward/rew_ang_vel_z: 0.2877
    Episode_Reward/pen_base_height: -0.1403
      Episode_Reward/pen_lin_vel_z: -0.0169
     Episode_Reward/pen_ang_vel_xy: -0.0257
   Episode_Reward/pen_joint_torque: -0.0140
    Episode_Reward/pen_joint_accel: -0.0094
    Episode_Reward/pen_action_rate: -0.0110
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0033
   Episode_Reward/pen_joint_powers: -0.0051
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0252
Episode_Reward/pen_flat_orientation: -0.0720
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0169
   Episode_Reward/foot_landing_vel: -0.0143
   Episode_Reward/test_gait_reward: -0.0866
Metrics/base_velocity/error_vel_xy: 0.3954
Metrics/base_velocity/error_vel_yaw: 0.0795
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 39.4583
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 1.06s
                        Total time: 406.28s
                               ETA: 2853.7s

################################################################################
                     [1m Learning iteration 374/3000 [0m                      

                       Computation: 91530 steps/s (collection: 0.949s, learning 0.125s)
               Value function loss: 0.6275
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4122
                     Learning rate: 0.0013
                       Mean reward: 1.27
               Mean episode length: 94.34
       Episode_Reward/keep_balance: 0.0959
     Episode_Reward/rew_lin_vel_xy: 0.1396
      Episode_Reward/rew_ang_vel_z: 0.2961
    Episode_Reward/pen_base_height: -0.1432
      Episode_Reward/pen_lin_vel_z: -0.0169
     Episode_Reward/pen_ang_vel_xy: -0.0256
   Episode_Reward/pen_joint_torque: -0.0142
    Episode_Reward/pen_joint_accel: -0.0095
    Episode_Reward/pen_action_rate: -0.0114
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0034
   Episode_Reward/pen_joint_powers: -0.0053
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0260
Episode_Reward/pen_flat_orientation: -0.0760
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0179
   Episode_Reward/foot_landing_vel: -0.0147
   Episode_Reward/test_gait_reward: -0.0893
Metrics/base_velocity/error_vel_xy: 0.3989
Metrics/base_velocity/error_vel_yaw: 0.0819
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 42.0000
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 1.07s
                        Total time: 407.35s
                               ETA: 2852.6s

################################################################################
                     [1m Learning iteration 375/3000 [0m                      

                       Computation: 91871 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 0.6936
                    Surrogate loss: -0.0010
             Mean action noise std: 0.4125
                     Learning rate: 0.0019
                       Mean reward: 1.93
               Mean episode length: 103.42
       Episode_Reward/keep_balance: 0.1005
     Episode_Reward/rew_lin_vel_xy: 0.1549
      Episode_Reward/rew_ang_vel_z: 0.3105
    Episode_Reward/pen_base_height: -0.1467
      Episode_Reward/pen_lin_vel_z: -0.0176
     Episode_Reward/pen_ang_vel_xy: -0.0263
   Episode_Reward/pen_joint_torque: -0.0152
    Episode_Reward/pen_joint_accel: -0.0097
    Episode_Reward/pen_action_rate: -0.0120
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0036
   Episode_Reward/pen_joint_powers: -0.0056
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0272
Episode_Reward/pen_flat_orientation: -0.0786
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0191
   Episode_Reward/foot_landing_vel: -0.0153
   Episode_Reward/test_gait_reward: -0.0934
Metrics/base_velocity/error_vel_xy: 0.4085
Metrics/base_velocity/error_vel_yaw: 0.0854
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 38.7500
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 1.07s
                        Total time: 408.42s
                               ETA: 2851.4s

################################################################################
                     [1m Learning iteration 376/3000 [0m                      

                       Computation: 91651 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.9013
                    Surrogate loss: 0.0223
             Mean action noise std: 0.4137
                     Learning rate: 0.0003
                       Mean reward: 1.71
               Mean episode length: 96.61
       Episode_Reward/keep_balance: 0.0999
     Episode_Reward/rew_lin_vel_xy: 0.1530
      Episode_Reward/rew_ang_vel_z: 0.3078
    Episode_Reward/pen_base_height: -0.1476
      Episode_Reward/pen_lin_vel_z: -0.0171
     Episode_Reward/pen_ang_vel_xy: -0.0257
   Episode_Reward/pen_joint_torque: -0.0148
    Episode_Reward/pen_joint_accel: -0.0100
    Episode_Reward/pen_action_rate: -0.0118
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0035
   Episode_Reward/pen_joint_powers: -0.0055
Episode_Reward/pen_undesired_contacts: -0.0023
Episode_Reward/pen_action_smoothness: -0.0273
Episode_Reward/pen_flat_orientation: -0.0806
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0179
   Episode_Reward/foot_landing_vel: -0.0150
   Episode_Reward/test_gait_reward: -0.0930
Metrics/base_velocity/error_vel_xy: 0.4047
Metrics/base_velocity/error_vel_yaw: 0.0859
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 42.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 1.07s
                        Total time: 409.50s
                               ETA: 2850.2s

################################################################################
                     [1m Learning iteration 377/3000 [0m                      

                       Computation: 91412 steps/s (collection: 0.951s, learning 0.124s)
               Value function loss: 0.5888
                    Surrogate loss: 0.0014
             Mean action noise std: 0.4139
                     Learning rate: 0.0003
                       Mean reward: 1.70
               Mean episode length: 101.30
       Episode_Reward/keep_balance: 0.1019
     Episode_Reward/rew_lin_vel_xy: 0.1609
      Episode_Reward/rew_ang_vel_z: 0.3142
    Episode_Reward/pen_base_height: -0.1469
      Episode_Reward/pen_lin_vel_z: -0.0173
     Episode_Reward/pen_ang_vel_xy: -0.0263
   Episode_Reward/pen_joint_torque: -0.0147
    Episode_Reward/pen_joint_accel: -0.0104
    Episode_Reward/pen_action_rate: -0.0121
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0035
   Episode_Reward/pen_joint_powers: -0.0055
Episode_Reward/pen_undesired_contacts: -0.0022
Episode_Reward/pen_action_smoothness: -0.0279
Episode_Reward/pen_flat_orientation: -0.0811
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0182
   Episode_Reward/foot_landing_vel: -0.0153
   Episode_Reward/test_gait_reward: -0.0955
Metrics/base_velocity/error_vel_xy: 0.4081
Metrics/base_velocity/error_vel_yaw: 0.0877
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 42.8333
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 1.08s
                        Total time: 410.57s
                               ETA: 2849.0s

################################################################################
                     [1m Learning iteration 378/3000 [0m                      

                       Computation: 92550 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 0.5433
                    Surrogate loss: -0.0016
             Mean action noise std: 0.4138
                     Learning rate: 0.0006
                       Mean reward: 1.77
               Mean episode length: 95.70
       Episode_Reward/keep_balance: 0.0981
     Episode_Reward/rew_lin_vel_xy: 0.1434
      Episode_Reward/rew_ang_vel_z: 0.3017
    Episode_Reward/pen_base_height: -0.1447
      Episode_Reward/pen_lin_vel_z: -0.0171
     Episode_Reward/pen_ang_vel_xy: -0.0261
   Episode_Reward/pen_joint_torque: -0.0145
    Episode_Reward/pen_joint_accel: -0.0098
    Episode_Reward/pen_action_rate: -0.0116
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0034
   Episode_Reward/pen_joint_powers: -0.0054
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0266
Episode_Reward/pen_flat_orientation: -0.0791
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0187
   Episode_Reward/foot_landing_vel: -0.0149
   Episode_Reward/test_gait_reward: -0.0912
Metrics/base_velocity/error_vel_xy: 0.4099
Metrics/base_velocity/error_vel_yaw: 0.0848
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 37.1250
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 1.06s
                        Total time: 411.63s
                               ETA: 2847.8s

################################################################################
                     [1m Learning iteration 379/3000 [0m                      

                       Computation: 92339 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.5021
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4134
                     Learning rate: 0.0009
                       Mean reward: 1.23
               Mean episode length: 105.16
       Episode_Reward/keep_balance: 0.0996
     Episode_Reward/rew_lin_vel_xy: 0.1532
      Episode_Reward/rew_ang_vel_z: 0.3069
    Episode_Reward/pen_base_height: -0.1478
      Episode_Reward/pen_lin_vel_z: -0.0170
     Episode_Reward/pen_ang_vel_xy: -0.0258
   Episode_Reward/pen_joint_torque: -0.0149
    Episode_Reward/pen_joint_accel: -0.0099
    Episode_Reward/pen_action_rate: -0.0119
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0034
   Episode_Reward/pen_joint_powers: -0.0054
Episode_Reward/pen_undesired_contacts: -0.0022
Episode_Reward/pen_action_smoothness: -0.0274
Episode_Reward/pen_flat_orientation: -0.0817
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0180
   Episode_Reward/foot_landing_vel: -0.0151
   Episode_Reward/test_gait_reward: -0.0931
Metrics/base_velocity/error_vel_xy: 0.4090
Metrics/base_velocity/error_vel_yaw: 0.0866
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 46.7500
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 1.06s
                        Total time: 412.70s
                               ETA: 2846.5s

################################################################################
                     [1m Learning iteration 380/3000 [0m                      

                       Computation: 92502 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 0.6403
                    Surrogate loss: -0.0001
             Mean action noise std: 0.4131
                     Learning rate: 0.0019
                       Mean reward: 2.38
               Mean episode length: 101.73
       Episode_Reward/keep_balance: 0.1006
     Episode_Reward/rew_lin_vel_xy: 0.1578
      Episode_Reward/rew_ang_vel_z: 0.3104
    Episode_Reward/pen_base_height: -0.1467
      Episode_Reward/pen_lin_vel_z: -0.0168
     Episode_Reward/pen_ang_vel_xy: -0.0260
   Episode_Reward/pen_joint_torque: -0.0147
    Episode_Reward/pen_joint_accel: -0.0098
    Episode_Reward/pen_action_rate: -0.0118
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0034
   Episode_Reward/pen_joint_powers: -0.0054
Episode_Reward/pen_undesired_contacts: -0.0022
Episode_Reward/pen_action_smoothness: -0.0273
Episode_Reward/pen_flat_orientation: -0.0805
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0178
   Episode_Reward/foot_landing_vel: -0.0148
   Episode_Reward/test_gait_reward: -0.0938
Metrics/base_velocity/error_vel_xy: 0.4062
Metrics/base_velocity/error_vel_yaw: 0.0874
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 38.0833
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 1.06s
                        Total time: 413.76s
                               ETA: 2845.3s

################################################################################
                     [1m Learning iteration 381/3000 [0m                      

                       Computation: 92807 steps/s (collection: 0.935s, learning 0.124s)
               Value function loss: 0.7860
                    Surrogate loss: 0.0012
             Mean action noise std: 0.4130
                     Learning rate: 0.0013
                       Mean reward: 1.58
               Mean episode length: 96.69
       Episode_Reward/keep_balance: 0.0940
     Episode_Reward/rew_lin_vel_xy: 0.1346
      Episode_Reward/rew_ang_vel_z: 0.2883
    Episode_Reward/pen_base_height: -0.1434
      Episode_Reward/pen_lin_vel_z: -0.0162
     Episode_Reward/pen_ang_vel_xy: -0.0254
   Episode_Reward/pen_joint_torque: -0.0139
    Episode_Reward/pen_joint_accel: -0.0093
    Episode_Reward/pen_action_rate: -0.0109
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0032
   Episode_Reward/pen_joint_powers: -0.0051
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0255
Episode_Reward/pen_flat_orientation: -0.0779
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0165
   Episode_Reward/foot_landing_vel: -0.0138
   Episode_Reward/test_gait_reward: -0.0885
Metrics/base_velocity/error_vel_xy: 0.3889
Metrics/base_velocity/error_vel_yaw: 0.0822
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 34.9167
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 1.06s
                        Total time: 414.82s
                               ETA: 2844.0s

################################################################################
                     [1m Learning iteration 382/3000 [0m                      

                       Computation: 93039 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 0.6631
                    Surrogate loss: 0.0034
             Mean action noise std: 0.4134
                     Learning rate: 0.0004
                       Mean reward: 1.30
               Mean episode length: 90.91
       Episode_Reward/keep_balance: 0.0964
     Episode_Reward/rew_lin_vel_xy: 0.1523
      Episode_Reward/rew_ang_vel_z: 0.2959
    Episode_Reward/pen_base_height: -0.1444
      Episode_Reward/pen_lin_vel_z: -0.0165
     Episode_Reward/pen_ang_vel_xy: -0.0259
   Episode_Reward/pen_joint_torque: -0.0140
    Episode_Reward/pen_joint_accel: -0.0096
    Episode_Reward/pen_action_rate: -0.0113
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0033
   Episode_Reward/pen_joint_powers: -0.0052
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0264
Episode_Reward/pen_flat_orientation: -0.0781
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0170
   Episode_Reward/foot_landing_vel: -0.0142
   Episode_Reward/test_gait_reward: -0.0900
Metrics/base_velocity/error_vel_xy: 0.3868
Metrics/base_velocity/error_vel_yaw: 0.0844
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 38.7917
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 1.06s
                        Total time: 415.88s
                               ETA: 2842.7s

################################################################################
                     [1m Learning iteration 383/3000 [0m                      

                       Computation: 92107 steps/s (collection: 0.944s, learning 0.124s)
               Value function loss: 0.6056
                    Surrogate loss: 0.0051
             Mean action noise std: 0.4137
                     Learning rate: 0.0001
                       Mean reward: 1.34
               Mean episode length: 97.83
       Episode_Reward/keep_balance: 0.0999
     Episode_Reward/rew_lin_vel_xy: 0.1483
      Episode_Reward/rew_ang_vel_z: 0.3068
    Episode_Reward/pen_base_height: -0.1457
      Episode_Reward/pen_lin_vel_z: -0.0170
     Episode_Reward/pen_ang_vel_xy: -0.0264
   Episode_Reward/pen_joint_torque: -0.0148
    Episode_Reward/pen_joint_accel: -0.0100
    Episode_Reward/pen_action_rate: -0.0118
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0035
   Episode_Reward/pen_joint_powers: -0.0054
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0270
Episode_Reward/pen_flat_orientation: -0.0795
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0179
   Episode_Reward/foot_landing_vel: -0.0148
   Episode_Reward/test_gait_reward: -0.0939
Metrics/base_velocity/error_vel_xy: 0.4106
Metrics/base_velocity/error_vel_yaw: 0.0877
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 36.4167
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 1.07s
                        Total time: 416.94s
                               ETA: 2841.5s

################################################################################
                     [1m Learning iteration 384/3000 [0m                      

                       Computation: 91920 steps/s (collection: 0.942s, learning 0.127s)
               Value function loss: 0.6021
                    Surrogate loss: 0.0041
             Mean action noise std: 0.4139
                     Learning rate: 0.0001
                       Mean reward: 2.82
               Mean episode length: 106.87
       Episode_Reward/keep_balance: 0.1034
     Episode_Reward/rew_lin_vel_xy: 0.1570
      Episode_Reward/rew_ang_vel_z: 0.3173
    Episode_Reward/pen_base_height: -0.1463
      Episode_Reward/pen_lin_vel_z: -0.0174
     Episode_Reward/pen_ang_vel_xy: -0.0270
   Episode_Reward/pen_joint_torque: -0.0151
    Episode_Reward/pen_joint_accel: -0.0105
    Episode_Reward/pen_action_rate: -0.0124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0037
   Episode_Reward/pen_joint_powers: -0.0057
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0283
Episode_Reward/pen_flat_orientation: -0.0822
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0193
   Episode_Reward/foot_landing_vel: -0.0153
   Episode_Reward/test_gait_reward: -0.0966
Metrics/base_velocity/error_vel_xy: 0.4134
Metrics/base_velocity/error_vel_yaw: 0.0905
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 35.6250
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 1.07s
                        Total time: 418.01s
                               ETA: 2840.3s

################################################################################
                     [1m Learning iteration 385/3000 [0m                      

                       Computation: 92279 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.6087
                    Surrogate loss: 0.0079
             Mean action noise std: 0.4140
                     Learning rate: 0.0000
                       Mean reward: 1.92
               Mean episode length: 99.36
       Episode_Reward/keep_balance: 0.1039
     Episode_Reward/rew_lin_vel_xy: 0.1618
      Episode_Reward/rew_ang_vel_z: 0.3201
    Episode_Reward/pen_base_height: -0.1454
      Episode_Reward/pen_lin_vel_z: -0.0174
     Episode_Reward/pen_ang_vel_xy: -0.0269
   Episode_Reward/pen_joint_torque: -0.0156
    Episode_Reward/pen_joint_accel: -0.0100
    Episode_Reward/pen_action_rate: -0.0123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0036
   Episode_Reward/pen_joint_powers: -0.0057
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0280
Episode_Reward/pen_flat_orientation: -0.0802
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0186
   Episode_Reward/foot_landing_vel: -0.0152
   Episode_Reward/test_gait_reward: -0.0963
Metrics/base_velocity/error_vel_xy: 0.4138
Metrics/base_velocity/error_vel_yaw: 0.0898
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 34.8750
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 1.07s
                        Total time: 419.08s
                               ETA: 2839.1s

################################################################################
                     [1m Learning iteration 386/3000 [0m                      

                       Computation: 93496 steps/s (collection: 0.928s, learning 0.124s)
               Value function loss: 0.6557
                    Surrogate loss: 0.0071
             Mean action noise std: 0.4140
                     Learning rate: 0.0000
                       Mean reward: 2.73
               Mean episode length: 113.89
       Episode_Reward/keep_balance: 0.1073
     Episode_Reward/rew_lin_vel_xy: 0.1715
      Episode_Reward/rew_ang_vel_z: 0.3303
    Episode_Reward/pen_base_height: -0.1480
      Episode_Reward/pen_lin_vel_z: -0.0176
     Episode_Reward/pen_ang_vel_xy: -0.0268
   Episode_Reward/pen_joint_torque: -0.0159
    Episode_Reward/pen_joint_accel: -0.0107
    Episode_Reward/pen_action_rate: -0.0129
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0037
   Episode_Reward/pen_joint_powers: -0.0058
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0293
Episode_Reward/pen_flat_orientation: -0.0819
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0197
   Episode_Reward/foot_landing_vel: -0.0159
   Episode_Reward/test_gait_reward: -0.0996
Metrics/base_velocity/error_vel_xy: 0.4198
Metrics/base_velocity/error_vel_yaw: 0.0932
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 34.1667
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 1.05s
                        Total time: 420.13s
                               ETA: 2837.8s

################################################################################
                     [1m Learning iteration 387/3000 [0m                      

                       Computation: 92903 steps/s (collection: 0.934s, learning 0.124s)
               Value function loss: 0.6458
                    Surrogate loss: -0.0007
             Mean action noise std: 0.4139
                     Learning rate: 0.0003
                       Mean reward: 2.47
               Mean episode length: 109.83
       Episode_Reward/keep_balance: 0.1092
     Episode_Reward/rew_lin_vel_xy: 0.1646
      Episode_Reward/rew_ang_vel_z: 0.3374
    Episode_Reward/pen_base_height: -0.1479
      Episode_Reward/pen_lin_vel_z: -0.0178
     Episode_Reward/pen_ang_vel_xy: -0.0270
   Episode_Reward/pen_joint_torque: -0.0160
    Episode_Reward/pen_joint_accel: -0.0101
    Episode_Reward/pen_action_rate: -0.0131
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0038
   Episode_Reward/pen_joint_powers: -0.0059
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0298
Episode_Reward/pen_flat_orientation: -0.0829
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0198
   Episode_Reward/foot_landing_vel: -0.0159
   Episode_Reward/test_gait_reward: -0.1020
Metrics/base_velocity/error_vel_xy: 0.4386
Metrics/base_velocity/error_vel_yaw: 0.0933
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 34.2917
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 1.06s
                        Total time: 421.19s
                               ETA: 2836.5s

################################################################################
                     [1m Learning iteration 388/3000 [0m                      

                       Computation: 92895 steps/s (collection: 0.935s, learning 0.124s)
               Value function loss: 0.7110
                    Surrogate loss: -0.0010
             Mean action noise std: 0.4140
                     Learning rate: 0.0006
                       Mean reward: 3.06
               Mean episode length: 117.49
       Episode_Reward/keep_balance: 0.1115
     Episode_Reward/rew_lin_vel_xy: 0.1806
      Episode_Reward/rew_ang_vel_z: 0.3442
    Episode_Reward/pen_base_height: -0.1487
      Episode_Reward/pen_lin_vel_z: -0.0181
     Episode_Reward/pen_ang_vel_xy: -0.0276
   Episode_Reward/pen_joint_torque: -0.0166
    Episode_Reward/pen_joint_accel: -0.0113
    Episode_Reward/pen_action_rate: -0.0135
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0038
   Episode_Reward/pen_joint_powers: -0.0061
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0305
Episode_Reward/pen_flat_orientation: -0.0834
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0201
   Episode_Reward/foot_landing_vel: -0.0163
   Episode_Reward/test_gait_reward: -0.1043
Metrics/base_velocity/error_vel_xy: 0.4379
Metrics/base_velocity/error_vel_yaw: 0.0956
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 33.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 1.06s
                        Total time: 422.25s
                               ETA: 2835.2s

################################################################################
                     [1m Learning iteration 389/3000 [0m                      

                       Computation: 92251 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.7779
                    Surrogate loss: -0.0012
             Mean action noise std: 0.4141
                     Learning rate: 0.0013
                       Mean reward: 2.73
               Mean episode length: 109.49
       Episode_Reward/keep_balance: 0.1110
     Episode_Reward/rew_lin_vel_xy: 0.1719
      Episode_Reward/rew_ang_vel_z: 0.3439
    Episode_Reward/pen_base_height: -0.1474
      Episode_Reward/pen_lin_vel_z: -0.0179
     Episode_Reward/pen_ang_vel_xy: -0.0274
   Episode_Reward/pen_joint_torque: -0.0164
    Episode_Reward/pen_joint_accel: -0.0106
    Episode_Reward/pen_action_rate: -0.0133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0038
   Episode_Reward/pen_joint_powers: -0.0060
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0301
Episode_Reward/pen_flat_orientation: -0.0819
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0204
   Episode_Reward/foot_landing_vel: -0.0163
   Episode_Reward/test_gait_reward: -0.1037
Metrics/base_velocity/error_vel_xy: 0.4373
Metrics/base_velocity/error_vel_yaw: 0.0944
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 31.2500
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 1.07s
                        Total time: 423.31s
                               ETA: 2834.0s

################################################################################
                     [1m Learning iteration 390/3000 [0m                      

                       Computation: 92279 steps/s (collection: 0.941s, learning 0.125s)
               Value function loss: 0.9269
                    Surrogate loss: -0.0025
             Mean action noise std: 0.4132
                     Learning rate: 0.0029
                       Mean reward: 2.33
               Mean episode length: 111.35
       Episode_Reward/keep_balance: 0.1097
     Episode_Reward/rew_lin_vel_xy: 0.1622
      Episode_Reward/rew_ang_vel_z: 0.3383
    Episode_Reward/pen_base_height: -0.1486
      Episode_Reward/pen_lin_vel_z: -0.0185
     Episode_Reward/pen_ang_vel_xy: -0.0280
   Episode_Reward/pen_joint_torque: -0.0161
    Episode_Reward/pen_joint_accel: -0.0107
    Episode_Reward/pen_action_rate: -0.0135
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0039
   Episode_Reward/pen_joint_powers: -0.0061
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0301
Episode_Reward/pen_flat_orientation: -0.0826
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0214
   Episode_Reward/foot_landing_vel: -0.0164
   Episode_Reward/test_gait_reward: -0.1027
Metrics/base_velocity/error_vel_xy: 0.4510
Metrics/base_velocity/error_vel_yaw: 0.0946
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 29.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 1.07s
                        Total time: 424.38s
                               ETA: 2832.8s

################################################################################
                     [1m Learning iteration 391/3000 [0m                      

                       Computation: 92777 steps/s (collection: 0.936s, learning 0.124s)
               Value function loss: 0.8905
                    Surrogate loss: 0.0039
             Mean action noise std: 0.4136
                     Learning rate: 0.0009
                       Mean reward: 3.57
               Mean episode length: 118.81
       Episode_Reward/keep_balance: 0.1209
     Episode_Reward/rew_lin_vel_xy: 0.2010
      Episode_Reward/rew_ang_vel_z: 0.3738
    Episode_Reward/pen_base_height: -0.1530
      Episode_Reward/pen_lin_vel_z: -0.0189
     Episode_Reward/pen_ang_vel_xy: -0.0285
   Episode_Reward/pen_joint_torque: -0.0175
    Episode_Reward/pen_joint_accel: -0.0120
    Episode_Reward/pen_action_rate: -0.0148
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0042
   Episode_Reward/pen_joint_powers: -0.0065
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0330
Episode_Reward/pen_flat_orientation: -0.0888
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0227
   Episode_Reward/foot_landing_vel: -0.0176
   Episode_Reward/test_gait_reward: -0.1123
Metrics/base_velocity/error_vel_xy: 0.4627
Metrics/base_velocity/error_vel_yaw: 0.1036
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 34.5417
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 1.06s
                        Total time: 425.44s
                               ETA: 2831.5s

################################################################################
                     [1m Learning iteration 392/3000 [0m                      

                       Computation: 92303 steps/s (collection: 0.941s, learning 0.124s)
               Value function loss: 0.6885
                    Surrogate loss: 0.0033
             Mean action noise std: 0.4140
                     Learning rate: 0.0004
                       Mean reward: 3.11
               Mean episode length: 130.88
       Episode_Reward/keep_balance: 0.1256
     Episode_Reward/rew_lin_vel_xy: 0.2016
      Episode_Reward/rew_ang_vel_z: 0.3882
    Episode_Reward/pen_base_height: -0.1538
      Episode_Reward/pen_lin_vel_z: -0.0194
     Episode_Reward/pen_ang_vel_xy: -0.0289
   Episode_Reward/pen_joint_torque: -0.0186
    Episode_Reward/pen_joint_accel: -0.0121
    Episode_Reward/pen_action_rate: -0.0154
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0044
   Episode_Reward/pen_joint_powers: -0.0068
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0343
Episode_Reward/pen_flat_orientation: -0.0882
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0237
   Episode_Reward/foot_landing_vel: -0.0184
   Episode_Reward/test_gait_reward: -0.1164
Metrics/base_velocity/error_vel_xy: 0.4874
Metrics/base_velocity/error_vel_yaw: 0.1074
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 31.5833
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 1.07s
                        Total time: 426.50s
                               ETA: 2830.3s

################################################################################
                     [1m Learning iteration 393/3000 [0m                      

                       Computation: 92653 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 0.6738
                    Surrogate loss: 0.0023
             Mean action noise std: 0.4142
                     Learning rate: 0.0003
                       Mean reward: 1.29
               Mean episode length: 104.40
       Episode_Reward/keep_balance: 0.1129
     Episode_Reward/rew_lin_vel_xy: 0.1697
      Episode_Reward/rew_ang_vel_z: 0.3483
    Episode_Reward/pen_base_height: -0.1479
      Episode_Reward/pen_lin_vel_z: -0.0183
     Episode_Reward/pen_ang_vel_xy: -0.0278
   Episode_Reward/pen_joint_torque: -0.0166
    Episode_Reward/pen_joint_accel: -0.0110
    Episode_Reward/pen_action_rate: -0.0137
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0039
   Episode_Reward/pen_joint_powers: -0.0061
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0307
Episode_Reward/pen_flat_orientation: -0.0824
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0208
   Episode_Reward/foot_landing_vel: -0.0166
   Episode_Reward/test_gait_reward: -0.1056
Metrics/base_velocity/error_vel_xy: 0.4576
Metrics/base_velocity/error_vel_yaw: 0.0977
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 26.8333
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 1.06s
                        Total time: 427.56s
                               ETA: 2829.1s

################################################################################
                     [1m Learning iteration 394/3000 [0m                      

                       Computation: 93106 steps/s (collection: 0.933s, learning 0.123s)
               Value function loss: 0.5468
                    Surrogate loss: 0.0055
             Mean action noise std: 0.4143
                     Learning rate: 0.0003
                       Mean reward: 2.89
               Mean episode length: 123.32
       Episode_Reward/keep_balance: 0.1189
     Episode_Reward/rew_lin_vel_xy: 0.1880
      Episode_Reward/rew_ang_vel_z: 0.3671
    Episode_Reward/pen_base_height: -0.1540
      Episode_Reward/pen_lin_vel_z: -0.0189
     Episode_Reward/pen_ang_vel_xy: -0.0282
   Episode_Reward/pen_joint_torque: -0.0175
    Episode_Reward/pen_joint_accel: -0.0118
    Episode_Reward/pen_action_rate: -0.0146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0042
   Episode_Reward/pen_joint_powers: -0.0065
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0324
Episode_Reward/pen_flat_orientation: -0.0902
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0229
   Episode_Reward/foot_landing_vel: -0.0176
   Episode_Reward/test_gait_reward: -0.1106
Metrics/base_velocity/error_vel_xy: 0.4601
Metrics/base_velocity/error_vel_yaw: 0.1027
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 29.5000
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 1.06s
                        Total time: 428.62s
                               ETA: 2827.8s

################################################################################
                     [1m Learning iteration 395/3000 [0m                      

                       Computation: 90398 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.4862
                    Surrogate loss: -0.0020
             Mean action noise std: 0.4145
                     Learning rate: 0.0006
                       Mean reward: 4.51
               Mean episode length: 136.81
       Episode_Reward/keep_balance: 0.1337
     Episode_Reward/rew_lin_vel_xy: 0.2157
      Episode_Reward/rew_ang_vel_z: 0.4127
    Episode_Reward/pen_base_height: -0.1618
      Episode_Reward/pen_lin_vel_z: -0.0201
     Episode_Reward/pen_ang_vel_xy: -0.0297
   Episode_Reward/pen_joint_torque: -0.0200
    Episode_Reward/pen_joint_accel: -0.0133
    Episode_Reward/pen_action_rate: -0.0167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0046
   Episode_Reward/pen_joint_powers: -0.0073
Episode_Reward/pen_undesired_contacts: -0.0023
Episode_Reward/pen_action_smoothness: -0.0368
Episode_Reward/pen_flat_orientation: -0.0951
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0238
   Episode_Reward/foot_landing_vel: -0.0199
   Episode_Reward/test_gait_reward: -0.1233
Metrics/base_velocity/error_vel_xy: 0.5133
Metrics/base_velocity/error_vel_yaw: 0.1155
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 40.9167
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 1.09s
                        Total time: 429.71s
                               ETA: 2826.7s

################################################################################
                     [1m Learning iteration 396/3000 [0m                      

                       Computation: 92300 steps/s (collection: 0.941s, learning 0.124s)
               Value function loss: 0.5975
                    Surrogate loss: -0.0015
             Mean action noise std: 0.4142
                     Learning rate: 0.0013
                       Mean reward: 3.33
               Mean episode length: 123.32
       Episode_Reward/keep_balance: 0.1411
     Episode_Reward/rew_lin_vel_xy: 0.2521
      Episode_Reward/rew_ang_vel_z: 0.4379
    Episode_Reward/pen_base_height: -0.1619
      Episode_Reward/pen_lin_vel_z: -0.0206
     Episode_Reward/pen_ang_vel_xy: -0.0300
   Episode_Reward/pen_joint_torque: -0.0213
    Episode_Reward/pen_joint_accel: -0.0133
    Episode_Reward/pen_action_rate: -0.0175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0048
   Episode_Reward/pen_joint_powers: -0.0076
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0386
Episode_Reward/pen_flat_orientation: -0.0952
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0249
   Episode_Reward/foot_landing_vel: -0.0201
   Episode_Reward/test_gait_reward: -0.1306
Metrics/base_velocity/error_vel_xy: 0.5240
Metrics/base_velocity/error_vel_yaw: 0.1197
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 32.3750
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 1.07s
                        Total time: 430.77s
                               ETA: 2825.5s

################################################################################
                     [1m Learning iteration 397/3000 [0m                      

                       Computation: 92674 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 0.8041
                    Surrogate loss: -0.0026
             Mean action noise std: 0.4144
                     Learning rate: 0.0019
                       Mean reward: 2.57
               Mean episode length: 114.44
       Episode_Reward/keep_balance: 0.1187
     Episode_Reward/rew_lin_vel_xy: 0.1857
      Episode_Reward/rew_ang_vel_z: 0.3653
    Episode_Reward/pen_base_height: -0.1513
      Episode_Reward/pen_lin_vel_z: -0.0192
     Episode_Reward/pen_ang_vel_xy: -0.0289
   Episode_Reward/pen_joint_torque: -0.0177
    Episode_Reward/pen_joint_accel: -0.0117
    Episode_Reward/pen_action_rate: -0.0146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0043
   Episode_Reward/pen_joint_powers: -0.0066
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0323
Episode_Reward/pen_flat_orientation: -0.0883
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0236
   Episode_Reward/foot_landing_vel: -0.0180
   Episode_Reward/test_gait_reward: -0.1113
Metrics/base_velocity/error_vel_xy: 0.4784
Metrics/base_velocity/error_vel_yaw: 0.1030
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 24.3333
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 1.06s
                        Total time: 431.83s
                               ETA: 2824.3s

################################################################################
                     [1m Learning iteration 398/3000 [0m                      

                       Computation: 92829 steps/s (collection: 0.935s, learning 0.124s)
               Value function loss: 0.6638
                    Surrogate loss: 0.0037
             Mean action noise std: 0.4143
                     Learning rate: 0.0004
                       Mean reward: 2.68
               Mean episode length: 123.41
       Episode_Reward/keep_balance: 0.1133
     Episode_Reward/rew_lin_vel_xy: 0.1689
      Episode_Reward/rew_ang_vel_z: 0.3468
    Episode_Reward/pen_base_height: -0.1502
      Episode_Reward/pen_lin_vel_z: -0.0187
     Episode_Reward/pen_ang_vel_xy: -0.0283
   Episode_Reward/pen_joint_torque: -0.0169
    Episode_Reward/pen_joint_accel: -0.0114
    Episode_Reward/pen_action_rate: -0.0141
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0041
   Episode_Reward/pen_joint_powers: -0.0063
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0311
Episode_Reward/pen_flat_orientation: -0.0875
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0225
   Episode_Reward/foot_landing_vel: -0.0174
   Episode_Reward/test_gait_reward: -0.1072
Metrics/base_velocity/error_vel_xy: 0.4613
Metrics/base_velocity/error_vel_yaw: 0.0998
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 24.6250
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 1.06s
                        Total time: 432.89s
                               ETA: 2823.0s

################################################################################
                     [1m Learning iteration 399/3000 [0m                      

                       Computation: 92641 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 0.5806
                    Surrogate loss: -0.0011
             Mean action noise std: 0.4141
                     Learning rate: 0.0009
                       Mean reward: 3.62
               Mean episode length: 133.50
       Episode_Reward/keep_balance: 0.1282
     Episode_Reward/rew_lin_vel_xy: 0.2008
      Episode_Reward/rew_ang_vel_z: 0.3949
    Episode_Reward/pen_base_height: -0.1559
      Episode_Reward/pen_lin_vel_z: -0.0196
     Episode_Reward/pen_ang_vel_xy: -0.0294
   Episode_Reward/pen_joint_torque: -0.0187
    Episode_Reward/pen_joint_accel: -0.0127
    Episode_Reward/pen_action_rate: -0.0160
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0046
   Episode_Reward/pen_joint_powers: -0.0070
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0351
Episode_Reward/pen_flat_orientation: -0.0948
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0246
   Episode_Reward/foot_landing_vel: -0.0191
   Episode_Reward/test_gait_reward: -0.1192
Metrics/base_velocity/error_vel_xy: 0.5046
Metrics/base_velocity/error_vel_yaw: 0.1105
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 28.2083
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 1.06s
                        Total time: 433.95s
                               ETA: 2821.8s

################################################################################
                     [1m Learning iteration 400/3000 [0m                      

                       Computation: 92447 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 0.7017
                    Surrogate loss: -0.0023
             Mean action noise std: 0.4142
                     Learning rate: 0.0019
                       Mean reward: 4.14
               Mean episode length: 139.24
       Episode_Reward/keep_balance: 0.1301
     Episode_Reward/rew_lin_vel_xy: 0.2030
      Episode_Reward/rew_ang_vel_z: 0.4011
    Episode_Reward/pen_base_height: -0.1577
      Episode_Reward/pen_lin_vel_z: -0.0199
     Episode_Reward/pen_ang_vel_xy: -0.0292
   Episode_Reward/pen_joint_torque: -0.0190
    Episode_Reward/pen_joint_accel: -0.0127
    Episode_Reward/pen_action_rate: -0.0162
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0046
   Episode_Reward/pen_joint_powers: -0.0071
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0356
Episode_Reward/pen_flat_orientation: -0.0967
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0251
   Episode_Reward/foot_landing_vel: -0.0192
   Episode_Reward/test_gait_reward: -0.1216
Metrics/base_velocity/error_vel_xy: 0.5027
Metrics/base_velocity/error_vel_yaw: 0.1120
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 26.9583
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 1.06s
                        Total time: 435.02s
                               ETA: 2820.6s

################################################################################
                     [1m Learning iteration 401/3000 [0m                      

                       Computation: 88619 steps/s (collection: 0.987s, learning 0.122s)
               Value function loss: 0.7119
                    Surrogate loss: 0.0101
             Mean action noise std: 0.4141
                     Learning rate: 0.0001
                       Mean reward: 4.11
               Mean episode length: 136.69
       Episode_Reward/keep_balance: 0.1318
     Episode_Reward/rew_lin_vel_xy: 0.2117
      Episode_Reward/rew_ang_vel_z: 0.4079
    Episode_Reward/pen_base_height: -0.1582
      Episode_Reward/pen_lin_vel_z: -0.0199
     Episode_Reward/pen_ang_vel_xy: -0.0289
   Episode_Reward/pen_joint_torque: -0.0190
    Episode_Reward/pen_joint_accel: -0.0129
    Episode_Reward/pen_action_rate: -0.0163
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0046
   Episode_Reward/pen_joint_powers: -0.0071
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0361
Episode_Reward/pen_flat_orientation: -0.0960
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0243
   Episode_Reward/foot_landing_vel: -0.0195
   Episode_Reward/test_gait_reward: -0.1237
Metrics/base_velocity/error_vel_xy: 0.5112
Metrics/base_velocity/error_vel_yaw: 0.1123
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 24.5833
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 1.11s
                        Total time: 436.13s
                               ETA: 2819.6s

################################################################################
                     [1m Learning iteration 402/3000 [0m                      

                       Computation: 91623 steps/s (collection: 0.949s, learning 0.124s)
               Value function loss: 0.5815
                    Surrogate loss: 0.0063
             Mean action noise std: 0.4142
                     Learning rate: 0.0002
                       Mean reward: 3.94
               Mean episode length: 134.50
       Episode_Reward/keep_balance: 0.1361
     Episode_Reward/rew_lin_vel_xy: 0.2213
      Episode_Reward/rew_ang_vel_z: 0.4228
    Episode_Reward/pen_base_height: -0.1578
      Episode_Reward/pen_lin_vel_z: -0.0198
     Episode_Reward/pen_ang_vel_xy: -0.0297
   Episode_Reward/pen_joint_torque: -0.0194
    Episode_Reward/pen_joint_accel: -0.0133
    Episode_Reward/pen_action_rate: -0.0168
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0047
   Episode_Reward/pen_joint_powers: -0.0073
Episode_Reward/pen_undesired_contacts: -0.0022
Episode_Reward/pen_action_smoothness: -0.0375
Episode_Reward/pen_flat_orientation: -0.0981
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0244
   Episode_Reward/foot_landing_vel: -0.0192
   Episode_Reward/test_gait_reward: -0.1269
Metrics/base_velocity/error_vel_xy: 0.5257
Metrics/base_velocity/error_vel_yaw: 0.1146
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 25.5833
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 1.07s
                        Total time: 437.20s
                               ETA: 2818.5s

################################################################################
                     [1m Learning iteration 403/3000 [0m                      

                       Computation: 92700 steps/s (collection: 0.936s, learning 0.124s)
               Value function loss: 0.5993
                    Surrogate loss: 0.0033
             Mean action noise std: 0.4143
                     Learning rate: 0.0004
                       Mean reward: 4.36
               Mean episode length: 139.70
       Episode_Reward/keep_balance: 0.1450
     Episode_Reward/rew_lin_vel_xy: 0.2367
      Episode_Reward/rew_ang_vel_z: 0.4482
    Episode_Reward/pen_base_height: -0.1641
      Episode_Reward/pen_lin_vel_z: -0.0214
     Episode_Reward/pen_ang_vel_xy: -0.0305
   Episode_Reward/pen_joint_torque: -0.0215
    Episode_Reward/pen_joint_accel: -0.0140
    Episode_Reward/pen_action_rate: -0.0183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0051
   Episode_Reward/pen_joint_powers: -0.0080
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0397
Episode_Reward/pen_flat_orientation: -0.1028
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0276
   Episode_Reward/foot_landing_vel: -0.0207
   Episode_Reward/test_gait_reward: -0.1347
Metrics/base_velocity/error_vel_xy: 0.5539
Metrics/base_velocity/error_vel_yaw: 0.1239
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 24.4167
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 1.06s
                        Total time: 438.26s
                               ETA: 2817.2s

################################################################################
                     [1m Learning iteration 404/3000 [0m                      

                       Computation: 89998 steps/s (collection: 0.965s, learning 0.127s)
               Value function loss: 0.5961
                    Surrogate loss: 0.0026
             Mean action noise std: 0.4144
                     Learning rate: 0.0006
                       Mean reward: 5.93
               Mean episode length: 145.96
       Episode_Reward/keep_balance: 0.1356
     Episode_Reward/rew_lin_vel_xy: 0.2331
      Episode_Reward/rew_ang_vel_z: 0.4198
    Episode_Reward/pen_base_height: -0.1594
      Episode_Reward/pen_lin_vel_z: -0.0198
     Episode_Reward/pen_ang_vel_xy: -0.0293
   Episode_Reward/pen_joint_torque: -0.0190
    Episode_Reward/pen_joint_accel: -0.0126
    Episode_Reward/pen_action_rate: -0.0168
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0047
   Episode_Reward/pen_joint_powers: -0.0072
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0373
Episode_Reward/pen_flat_orientation: -0.0990
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0244
   Episode_Reward/foot_landing_vel: -0.0196
   Episode_Reward/test_gait_reward: -0.1264
Metrics/base_velocity/error_vel_xy: 0.5091
Metrics/base_velocity/error_vel_yaw: 0.1162
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 26.5000
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 1.09s
                        Total time: 439.35s
                               ETA: 2816.2s

################################################################################
                     [1m Learning iteration 405/3000 [0m                      

                       Computation: 91879 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.6228
                    Surrogate loss: 0.0012
             Mean action noise std: 0.4144
                     Learning rate: 0.0004
                       Mean reward: 4.82
               Mean episode length: 141.21
       Episode_Reward/keep_balance: 0.1467
     Episode_Reward/rew_lin_vel_xy: 0.2682
      Episode_Reward/rew_ang_vel_z: 0.4549
    Episode_Reward/pen_base_height: -0.1647
      Episode_Reward/pen_lin_vel_z: -0.0211
     Episode_Reward/pen_ang_vel_xy: -0.0303
   Episode_Reward/pen_joint_torque: -0.0211
    Episode_Reward/pen_joint_accel: -0.0139
    Episode_Reward/pen_action_rate: -0.0184
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0050
   Episode_Reward/pen_joint_powers: -0.0079
Episode_Reward/pen_undesired_contacts: -0.0022
Episode_Reward/pen_action_smoothness: -0.0405
Episode_Reward/pen_flat_orientation: -0.1031
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0256
   Episode_Reward/foot_landing_vel: -0.0207
   Episode_Reward/test_gait_reward: -0.1366
Metrics/base_velocity/error_vel_xy: 0.5208
Metrics/base_velocity/error_vel_yaw: 0.1242
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 28.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 1.07s
                        Total time: 440.42s
                               ETA: 2815.0s

################################################################################
                     [1m Learning iteration 406/3000 [0m                      

                       Computation: 91995 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.6691
                    Surrogate loss: -0.0026
             Mean action noise std: 0.4150
                     Learning rate: 0.0013
                       Mean reward: 4.38
               Mean episode length: 143.26
       Episode_Reward/keep_balance: 0.1410
     Episode_Reward/rew_lin_vel_xy: 0.2261
      Episode_Reward/rew_ang_vel_z: 0.4379
    Episode_Reward/pen_base_height: -0.1612
      Episode_Reward/pen_lin_vel_z: -0.0204
     Episode_Reward/pen_ang_vel_xy: -0.0299
   Episode_Reward/pen_joint_torque: -0.0203
    Episode_Reward/pen_joint_accel: -0.0133
    Episode_Reward/pen_action_rate: -0.0175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0048
   Episode_Reward/pen_joint_powers: -0.0076
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0387
Episode_Reward/pen_flat_orientation: -0.0998
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0252
   Episode_Reward/foot_landing_vel: -0.0195
   Episode_Reward/test_gait_reward: -0.1320
Metrics/base_velocity/error_vel_xy: 0.5372
Metrics/base_velocity/error_vel_yaw: 0.1192
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 26.2083
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 1.07s
                        Total time: 441.49s
                               ETA: 2813.8s

################################################################################
                     [1m Learning iteration 407/3000 [0m                      

                       Computation: 92544 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 0.7635
                    Surrogate loss: -0.0003
             Mean action noise std: 0.4151
                     Learning rate: 0.0013
                       Mean reward: 4.11
               Mean episode length: 134.28
       Episode_Reward/keep_balance: 0.1429
     Episode_Reward/rew_lin_vel_xy: 0.2478
      Episode_Reward/rew_ang_vel_z: 0.4441
    Episode_Reward/pen_base_height: -0.1619
      Episode_Reward/pen_lin_vel_z: -0.0207
     Episode_Reward/pen_ang_vel_xy: -0.0299
   Episode_Reward/pen_joint_torque: -0.0209
    Episode_Reward/pen_joint_accel: -0.0130
    Episode_Reward/pen_action_rate: -0.0179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0049
   Episode_Reward/pen_joint_powers: -0.0077
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0391
Episode_Reward/pen_flat_orientation: -0.0980
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0255
   Episode_Reward/foot_landing_vel: -0.0200
   Episode_Reward/test_gait_reward: -0.1331
Metrics/base_velocity/error_vel_xy: 0.5200
Metrics/base_velocity/error_vel_yaw: 0.1202
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 23.6250
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 1.06s
                        Total time: 442.55s
                               ETA: 2812.6s

################################################################################
                     [1m Learning iteration 408/3000 [0m                      

                       Computation: 92986 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 0.6866
                    Surrogate loss: 0.0033
             Mean action noise std: 0.4154
                     Learning rate: 0.0006
                       Mean reward: 5.07
               Mean episode length: 156.71
       Episode_Reward/keep_balance: 0.1455
     Episode_Reward/rew_lin_vel_xy: 0.2443
      Episode_Reward/rew_ang_vel_z: 0.4509
    Episode_Reward/pen_base_height: -0.1648
      Episode_Reward/pen_lin_vel_z: -0.0208
     Episode_Reward/pen_ang_vel_xy: -0.0300
   Episode_Reward/pen_joint_torque: -0.0215
    Episode_Reward/pen_joint_accel: -0.0138
    Episode_Reward/pen_action_rate: -0.0183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0050
   Episode_Reward/pen_joint_powers: -0.0079
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0403
Episode_Reward/pen_flat_orientation: -0.1022
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0262
   Episode_Reward/foot_landing_vel: -0.0204
   Episode_Reward/test_gait_reward: -0.1354
Metrics/base_velocity/error_vel_xy: 0.5391
Metrics/base_velocity/error_vel_yaw: 0.1238
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 26.0417
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 1.06s
                        Total time: 443.61s
                               ETA: 2811.3s

################################################################################
                     [1m Learning iteration 409/3000 [0m                      

                       Computation: 91671 steps/s (collection: 0.949s, learning 0.124s)
               Value function loss: 0.6581
                    Surrogate loss: -0.0018
             Mean action noise std: 0.4160
                     Learning rate: 0.0009
                       Mean reward: 5.51
               Mean episode length: 152.92
       Episode_Reward/keep_balance: 0.1501
     Episode_Reward/rew_lin_vel_xy: 0.2712
      Episode_Reward/rew_ang_vel_z: 0.4671
    Episode_Reward/pen_base_height: -0.1654
      Episode_Reward/pen_lin_vel_z: -0.0211
     Episode_Reward/pen_ang_vel_xy: -0.0304
   Episode_Reward/pen_joint_torque: -0.0218
    Episode_Reward/pen_joint_accel: -0.0135
    Episode_Reward/pen_action_rate: -0.0190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0051
   Episode_Reward/pen_joint_powers: -0.0081
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0419
Episode_Reward/pen_flat_orientation: -0.1013
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0260
   Episode_Reward/foot_landing_vel: -0.0210
   Episode_Reward/test_gait_reward: -0.1400
Metrics/base_velocity/error_vel_xy: 0.5533
Metrics/base_velocity/error_vel_yaw: 0.1271
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 25.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 1.07s
                        Total time: 444.68s
                               ETA: 2810.2s

################################################################################
                     [1m Learning iteration 410/3000 [0m                      

                       Computation: 92348 steps/s (collection: 0.941s, learning 0.124s)
               Value function loss: 0.6070
                    Surrogate loss: 0.0025
             Mean action noise std: 0.4162
                     Learning rate: 0.0006
                       Mean reward: 4.14
               Mean episode length: 129.64
       Episode_Reward/keep_balance: 0.1570
     Episode_Reward/rew_lin_vel_xy: 0.2900
      Episode_Reward/rew_ang_vel_z: 0.4870
    Episode_Reward/pen_base_height: -0.1670
      Episode_Reward/pen_lin_vel_z: -0.0214
     Episode_Reward/pen_ang_vel_xy: -0.0314
   Episode_Reward/pen_joint_torque: -0.0229
    Episode_Reward/pen_joint_accel: -0.0143
    Episode_Reward/pen_action_rate: -0.0197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0052
   Episode_Reward/pen_joint_powers: -0.0084
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0434
Episode_Reward/pen_flat_orientation: -0.1033
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0265
   Episode_Reward/foot_landing_vel: -0.0215
   Episode_Reward/test_gait_reward: -0.1453
Metrics/base_velocity/error_vel_xy: 0.5717
Metrics/base_velocity/error_vel_yaw: 0.1343
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 21.7500
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 1.06s
                        Total time: 445.75s
                               ETA: 2809.0s

################################################################################
                     [1m Learning iteration 411/3000 [0m                      

                       Computation: 92248 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.7101
                    Surrogate loss: -0.0004
             Mean action noise std: 0.4163
                     Learning rate: 0.0006
                       Mean reward: 4.27
               Mean episode length: 134.95
       Episode_Reward/keep_balance: 0.1443
     Episode_Reward/rew_lin_vel_xy: 0.2396
      Episode_Reward/rew_ang_vel_z: 0.4466
    Episode_Reward/pen_base_height: -0.1631
      Episode_Reward/pen_lin_vel_z: -0.0209
     Episode_Reward/pen_ang_vel_xy: -0.0307
   Episode_Reward/pen_joint_torque: -0.0206
    Episode_Reward/pen_joint_accel: -0.0138
    Episode_Reward/pen_action_rate: -0.0183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0050
   Episode_Reward/pen_joint_powers: -0.0079
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0401
Episode_Reward/pen_flat_orientation: -0.1010
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0262
   Episode_Reward/foot_landing_vel: -0.0207
   Episode_Reward/test_gait_reward: -0.1355
Metrics/base_velocity/error_vel_xy: 0.5315
Metrics/base_velocity/error_vel_yaw: 0.1229
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 21.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 1.07s
                        Total time: 446.81s
                               ETA: 2807.8s

################################################################################
                     [1m Learning iteration 412/3000 [0m                      

                       Computation: 90711 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.6618
                    Surrogate loss: 0.0011
             Mean action noise std: 0.4169
                     Learning rate: 0.0009
                       Mean reward: 5.07
               Mean episode length: 147.37
       Episode_Reward/keep_balance: 0.1445
     Episode_Reward/rew_lin_vel_xy: 0.2468
      Episode_Reward/rew_ang_vel_z: 0.4500
    Episode_Reward/pen_base_height: -0.1616
      Episode_Reward/pen_lin_vel_z: -0.0206
     Episode_Reward/pen_ang_vel_xy: -0.0301
   Episode_Reward/pen_joint_torque: -0.0206
    Episode_Reward/pen_joint_accel: -0.0127
    Episode_Reward/pen_action_rate: -0.0181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0048
   Episode_Reward/pen_joint_powers: -0.0077
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0401
Episode_Reward/pen_flat_orientation: -0.0993
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0249
   Episode_Reward/foot_landing_vel: -0.0201
   Episode_Reward/test_gait_reward: -0.1350
Metrics/base_velocity/error_vel_xy: 0.5367
Metrics/base_velocity/error_vel_yaw: 0.1211
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 22.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 1.08s
                        Total time: 447.90s
                               ETA: 2806.7s

################################################################################
                     [1m Learning iteration 413/3000 [0m                      

                       Computation: 91681 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.5328
                    Surrogate loss: 0.0014
             Mean action noise std: 0.4170
                     Learning rate: 0.0004
                       Mean reward: 7.23
               Mean episode length: 193.20
       Episode_Reward/keep_balance: 0.1610
     Episode_Reward/rew_lin_vel_xy: 0.2767
      Episode_Reward/rew_ang_vel_z: 0.5020
    Episode_Reward/pen_base_height: -0.1697
      Episode_Reward/pen_lin_vel_z: -0.0220
     Episode_Reward/pen_ang_vel_xy: -0.0320
   Episode_Reward/pen_joint_torque: -0.0232
    Episode_Reward/pen_joint_accel: -0.0150
    Episode_Reward/pen_action_rate: -0.0207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0055
   Episode_Reward/pen_joint_powers: -0.0088
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0449
Episode_Reward/pen_flat_orientation: -0.1095
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0270
   Episode_Reward/foot_landing_vel: -0.0235
   Episode_Reward/test_gait_reward: -0.1493
Metrics/base_velocity/error_vel_xy: 0.5881
Metrics/base_velocity/error_vel_yaw: 0.1336
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 30.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 1.07s
                        Total time: 448.97s
                               ETA: 2805.5s

################################################################################
                     [1m Learning iteration 414/3000 [0m                      

                       Computation: 91905 steps/s (collection: 0.946s, learning 0.124s)
               Value function loss: 0.6085
                    Surrogate loss: 0.0009
             Mean action noise std: 0.4170
                     Learning rate: 0.0004
                       Mean reward: 8.95
               Mean episode length: 192.83
       Episode_Reward/keep_balance: 0.1862
     Episode_Reward/rew_lin_vel_xy: 0.3430
      Episode_Reward/rew_ang_vel_z: 0.5837
    Episode_Reward/pen_base_height: -0.1784
      Episode_Reward/pen_lin_vel_z: -0.0240
     Episode_Reward/pen_ang_vel_xy: -0.0339
   Episode_Reward/pen_joint_torque: -0.0273
    Episode_Reward/pen_joint_accel: -0.0162
    Episode_Reward/pen_action_rate: -0.0239
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0060
   Episode_Reward/pen_joint_powers: -0.0100
Episode_Reward/pen_undesired_contacts: -0.0021
Episode_Reward/pen_action_smoothness: -0.0520
Episode_Reward/pen_flat_orientation: -0.1152
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0297
   Episode_Reward/foot_landing_vel: -0.0248
   Episode_Reward/test_gait_reward: -0.1712
Metrics/base_velocity/error_vel_xy: 0.6597
Metrics/base_velocity/error_vel_yaw: 0.1521
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 30.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 1.07s
                        Total time: 450.04s
                               ETA: 2804.3s

################################################################################
                     [1m Learning iteration 415/3000 [0m                      

                       Computation: 92662 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 0.6491
                    Surrogate loss: -0.0020
             Mean action noise std: 0.4170
                     Learning rate: 0.0009
                       Mean reward: 3.25
               Mean episode length: 122.22
       Episode_Reward/keep_balance: 0.1475
     Episode_Reward/rew_lin_vel_xy: 0.2355
      Episode_Reward/rew_ang_vel_z: 0.4589
    Episode_Reward/pen_base_height: -0.1603
      Episode_Reward/pen_lin_vel_z: -0.0202
     Episode_Reward/pen_ang_vel_xy: -0.0300
   Episode_Reward/pen_joint_torque: -0.0213
    Episode_Reward/pen_joint_accel: -0.0135
    Episode_Reward/pen_action_rate: -0.0186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0048
   Episode_Reward/pen_joint_powers: -0.0078
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0409
Episode_Reward/pen_flat_orientation: -0.0962
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0240
   Episode_Reward/foot_landing_vel: -0.0195
   Episode_Reward/test_gait_reward: -0.1379
Metrics/base_velocity/error_vel_xy: 0.5539
Metrics/base_velocity/error_vel_yaw: 0.1232
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 18.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 1.06s
                        Total time: 451.10s
                               ETA: 2803.1s

################################################################################
                     [1m Learning iteration 416/3000 [0m                      

                       Computation: 92811 steps/s (collection: 0.936s, learning 0.124s)
               Value function loss: 0.7697
                    Surrogate loss: -0.0004
             Mean action noise std: 0.4168
                     Learning rate: 0.0019
                       Mean reward: 5.41
               Mean episode length: 175.62
       Episode_Reward/keep_balance: 0.1358
     Episode_Reward/rew_lin_vel_xy: 0.2147
      Episode_Reward/rew_ang_vel_z: 0.4164
    Episode_Reward/pen_base_height: -0.1598
      Episode_Reward/pen_lin_vel_z: -0.0199
     Episode_Reward/pen_ang_vel_xy: -0.0297
   Episode_Reward/pen_joint_torque: -0.0200
    Episode_Reward/pen_joint_accel: -0.0130
    Episode_Reward/pen_action_rate: -0.0173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0047
   Episode_Reward/pen_joint_powers: -0.0075
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0382
Episode_Reward/pen_flat_orientation: -0.0950
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0236
   Episode_Reward/foot_landing_vel: -0.0192
   Episode_Reward/test_gait_reward: -0.1270
Metrics/base_velocity/error_vel_xy: 0.5251
Metrics/base_velocity/error_vel_yaw: 0.1185
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 20.0833
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 1.06s
                        Total time: 452.16s
                               ETA: 2801.9s

################################################################################
                     [1m Learning iteration 417/3000 [0m                      

                       Computation: 89991 steps/s (collection: 0.966s, learning 0.127s)
               Value function loss: 0.8450
                    Surrogate loss: 0.0005
             Mean action noise std: 0.4163
                     Learning rate: 0.0019
                       Mean reward: 4.64
               Mean episode length: 139.32
       Episode_Reward/keep_balance: 0.1524
     Episode_Reward/rew_lin_vel_xy: 0.2497
      Episode_Reward/rew_ang_vel_z: 0.4716
    Episode_Reward/pen_base_height: -0.1679
      Episode_Reward/pen_lin_vel_z: -0.0219
     Episode_Reward/pen_ang_vel_xy: -0.0311
   Episode_Reward/pen_joint_torque: -0.0231
    Episode_Reward/pen_joint_accel: -0.0143
    Episode_Reward/pen_action_rate: -0.0197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0053
   Episode_Reward/pen_joint_powers: -0.0085
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0430
Episode_Reward/pen_flat_orientation: -0.1023
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0278
   Episode_Reward/foot_landing_vel: -0.0219
   Episode_Reward/test_gait_reward: -0.1426
Metrics/base_velocity/error_vel_xy: 0.5734
Metrics/base_velocity/error_vel_yaw: 0.1299
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 23.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 1.09s
                        Total time: 453.25s
                               ETA: 2800.8s

################################################################################
                     [1m Learning iteration 418/3000 [0m                      

                       Computation: 91101 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.8206
                    Surrogate loss: 0.0152
             Mean action noise std: 0.4166
                     Learning rate: 0.0000
                       Mean reward: 5.78
               Mean episode length: 146.71
       Episode_Reward/keep_balance: 0.1590
     Episode_Reward/rew_lin_vel_xy: 0.2838
      Episode_Reward/rew_ang_vel_z: 0.4933
    Episode_Reward/pen_base_height: -0.1692
      Episode_Reward/pen_lin_vel_z: -0.0220
     Episode_Reward/pen_ang_vel_xy: -0.0316
   Episode_Reward/pen_joint_torque: -0.0234
    Episode_Reward/pen_joint_accel: -0.0153
    Episode_Reward/pen_action_rate: -0.0206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0055
   Episode_Reward/pen_joint_powers: -0.0087
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0449
Episode_Reward/pen_flat_orientation: -0.1052
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0280
   Episode_Reward/foot_landing_vel: -0.0228
   Episode_Reward/test_gait_reward: -0.1476
Metrics/base_velocity/error_vel_xy: 0.5777
Metrics/base_velocity/error_vel_yaw: 0.1343
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 22.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 1.08s
                        Total time: 454.33s
                               ETA: 2799.7s

################################################################################
                     [1m Learning iteration 419/3000 [0m                      

                       Computation: 89358 steps/s (collection: 0.975s, learning 0.125s)
               Value function loss: 0.8008
                    Surrogate loss: 0.0073
             Mean action noise std: 0.4166
                     Learning rate: 0.0000
                       Mean reward: 3.83
               Mean episode length: 138.04
       Episode_Reward/keep_balance: 0.1617
     Episode_Reward/rew_lin_vel_xy: 0.2802
      Episode_Reward/rew_ang_vel_z: 0.5038
    Episode_Reward/pen_base_height: -0.1683
      Episode_Reward/pen_lin_vel_z: -0.0226
     Episode_Reward/pen_ang_vel_xy: -0.0322
   Episode_Reward/pen_joint_torque: -0.0240
    Episode_Reward/pen_joint_accel: -0.0154
    Episode_Reward/pen_action_rate: -0.0210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0056
   Episode_Reward/pen_joint_powers: -0.0088
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0453
Episode_Reward/pen_flat_orientation: -0.1052
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0282
   Episode_Reward/foot_landing_vel: -0.0235
   Episode_Reward/test_gait_reward: -0.1504
Metrics/base_velocity/error_vel_xy: 0.5853
Metrics/base_velocity/error_vel_yaw: 0.1355
      Episode_Termination/time_out: 0.1250
  Episode_Termination/base_contact: 20.5000
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 1.10s
                        Total time: 455.43s
                               ETA: 2798.7s

################################################################################
                     [1m Learning iteration 420/3000 [0m                      

                       Computation: 90993 steps/s (collection: 0.956s, learning 0.125s)
               Value function loss: 0.7284
                    Surrogate loss: 0.0178
             Mean action noise std: 0.4166
                     Learning rate: 0.0000
                       Mean reward: 5.52
               Mean episode length: 155.35
       Episode_Reward/keep_balance: 0.1527
     Episode_Reward/rew_lin_vel_xy: 0.2652
      Episode_Reward/rew_ang_vel_z: 0.4746
    Episode_Reward/pen_base_height: -0.1635
      Episode_Reward/pen_lin_vel_z: -0.0213
     Episode_Reward/pen_ang_vel_xy: -0.0313
   Episode_Reward/pen_joint_torque: -0.0222
    Episode_Reward/pen_joint_accel: -0.0136
    Episode_Reward/pen_action_rate: -0.0196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0052
   Episode_Reward/pen_joint_powers: -0.0083
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0428
Episode_Reward/pen_flat_orientation: -0.1011
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0267
   Episode_Reward/foot_landing_vel: -0.0213
   Episode_Reward/test_gait_reward: -0.1419
Metrics/base_velocity/error_vel_xy: 0.5511
Metrics/base_velocity/error_vel_yaw: 0.1281
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 18.6667
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 1.08s
                        Total time: 456.51s
                               ETA: 2797.6s

################################################################################
                     [1m Learning iteration 421/3000 [0m                      

                       Computation: 90449 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.7139
                    Surrogate loss: 0.0083
             Mean action noise std: 0.4167
                     Learning rate: 0.0000
                       Mean reward: 6.41
               Mean episode length: 155.54
       Episode_Reward/keep_balance: 0.1578
     Episode_Reward/rew_lin_vel_xy: 0.2680
      Episode_Reward/rew_ang_vel_z: 0.4923
    Episode_Reward/pen_base_height: -0.1677
      Episode_Reward/pen_lin_vel_z: -0.0216
     Episode_Reward/pen_ang_vel_xy: -0.0313
   Episode_Reward/pen_joint_torque: -0.0231
    Episode_Reward/pen_joint_accel: -0.0143
    Episode_Reward/pen_action_rate: -0.0203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0052
   Episode_Reward/pen_joint_powers: -0.0085
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0444
Episode_Reward/pen_flat_orientation: -0.1027
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0266
   Episode_Reward/foot_landing_vel: -0.0217
   Episode_Reward/test_gait_reward: -0.1473
Metrics/base_velocity/error_vel_xy: 0.5923
Metrics/base_velocity/error_vel_yaw: 0.1315
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 21.2083
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 1.09s
                        Total time: 457.60s
                               ETA: 2796.5s

################################################################################
                     [1m Learning iteration 422/3000 [0m                      

                       Computation: 90522 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.7453
                    Surrogate loss: 0.0063
             Mean action noise std: 0.4168
                     Learning rate: 0.0000
                       Mean reward: 6.91
               Mean episode length: 174.72
       Episode_Reward/keep_balance: 0.1665
     Episode_Reward/rew_lin_vel_xy: 0.2958
      Episode_Reward/rew_ang_vel_z: 0.5188
    Episode_Reward/pen_base_height: -0.1688
      Episode_Reward/pen_lin_vel_z: -0.0219
     Episode_Reward/pen_ang_vel_xy: -0.0319
   Episode_Reward/pen_joint_torque: -0.0239
    Episode_Reward/pen_joint_accel: -0.0155
    Episode_Reward/pen_action_rate: -0.0215
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0055
   Episode_Reward/pen_joint_powers: -0.0088
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0471
Episode_Reward/pen_flat_orientation: -0.1061
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0274
   Episode_Reward/foot_landing_vel: -0.0227
   Episode_Reward/test_gait_reward: -0.1541
Metrics/base_velocity/error_vel_xy: 0.5987
Metrics/base_velocity/error_vel_yaw: 0.1392
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 24.5417
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 1.09s
                        Total time: 458.68s
                               ETA: 2795.5s

################################################################################
                     [1m Learning iteration 423/3000 [0m                      

                       Computation: 90800 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.7134
                    Surrogate loss: 0.0065
             Mean action noise std: 0.4168
                     Learning rate: 0.0000
                       Mean reward: 7.21
               Mean episode length: 181.31
       Episode_Reward/keep_balance: 0.1738
     Episode_Reward/rew_lin_vel_xy: 0.2930
      Episode_Reward/rew_ang_vel_z: 0.5413
    Episode_Reward/pen_base_height: -0.1719
      Episode_Reward/pen_lin_vel_z: -0.0227
     Episode_Reward/pen_ang_vel_xy: -0.0331
   Episode_Reward/pen_joint_torque: -0.0250
    Episode_Reward/pen_joint_accel: -0.0157
    Episode_Reward/pen_action_rate: -0.0227
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0058
   Episode_Reward/pen_joint_powers: -0.0093
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0492
Episode_Reward/pen_flat_orientation: -0.1112
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0290
   Episode_Reward/foot_landing_vel: -0.0245
   Episode_Reward/test_gait_reward: -0.1601
Metrics/base_velocity/error_vel_xy: 0.6351
Metrics/base_velocity/error_vel_yaw: 0.1451
      Episode_Termination/time_out: 0.2083
  Episode_Termination/base_contact: 24.0417
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 1.08s
                        Total time: 459.76s
                               ETA: 2794.4s

################################################################################
                     [1m Learning iteration 424/3000 [0m                      

                       Computation: 90323 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.7109
                    Surrogate loss: -0.0012
             Mean action noise std: 0.4170
                     Learning rate: 0.0004
                       Mean reward: 6.46
               Mean episode length: 168.07
       Episode_Reward/keep_balance: 0.1804
     Episode_Reward/rew_lin_vel_xy: 0.3174
      Episode_Reward/rew_ang_vel_z: 0.5605
    Episode_Reward/pen_base_height: -0.1775
      Episode_Reward/pen_lin_vel_z: -0.0236
     Episode_Reward/pen_ang_vel_xy: -0.0337
   Episode_Reward/pen_joint_torque: -0.0268
    Episode_Reward/pen_joint_accel: -0.0165
    Episode_Reward/pen_action_rate: -0.0238
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0060
   Episode_Reward/pen_joint_powers: -0.0098
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0509
Episode_Reward/pen_flat_orientation: -0.1138
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0303
   Episode_Reward/foot_landing_vel: -0.0254
   Episode_Reward/test_gait_reward: -0.1663
Metrics/base_velocity/error_vel_xy: 0.6555
Metrics/base_velocity/error_vel_yaw: 0.1533
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 23.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 1.09s
                        Total time: 460.85s
                               ETA: 2793.3s

################################################################################
                     [1m Learning iteration 425/3000 [0m                      

                       Computation: 90152 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.7539
                    Surrogate loss: 0.0005
             Mean action noise std: 0.4175
                     Learning rate: 0.0004
                       Mean reward: 6.10
               Mean episode length: 165.67
       Episode_Reward/keep_balance: 0.1693
     Episode_Reward/rew_lin_vel_xy: 0.2978
      Episode_Reward/rew_ang_vel_z: 0.5300
    Episode_Reward/pen_base_height: -0.1703
      Episode_Reward/pen_lin_vel_z: -0.0224
     Episode_Reward/pen_ang_vel_xy: -0.0323
   Episode_Reward/pen_joint_torque: -0.0251
    Episode_Reward/pen_joint_accel: -0.0149
    Episode_Reward/pen_action_rate: -0.0220
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0055
   Episode_Reward/pen_joint_powers: -0.0091
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0479
Episode_Reward/pen_flat_orientation: -0.1066
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0285
   Episode_Reward/foot_landing_vel: -0.0227
   Episode_Reward/test_gait_reward: -0.1558
Metrics/base_velocity/error_vel_xy: 0.6243
Metrics/base_velocity/error_vel_yaw: 0.1394
      Episode_Termination/time_out: 0.1667
  Episode_Termination/base_contact: 22.2083
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 1.09s
                        Total time: 461.94s
                               ETA: 2792.3s

################################################################################
                     [1m Learning iteration 426/3000 [0m                      

                       Computation: 90586 steps/s (collection: 0.958s, learning 0.127s)
               Value function loss: 0.8225
                    Surrogate loss: -0.0017
             Mean action noise std: 0.4177
                     Learning rate: 0.0009
                       Mean reward: 7.76
               Mean episode length: 179.74
       Episode_Reward/keep_balance: 0.1678
     Episode_Reward/rew_lin_vel_xy: 0.2970
      Episode_Reward/rew_ang_vel_z: 0.5190
    Episode_Reward/pen_base_height: -0.1727
      Episode_Reward/pen_lin_vel_z: -0.0232
     Episode_Reward/pen_ang_vel_xy: -0.0332
   Episode_Reward/pen_joint_torque: -0.0255
    Episode_Reward/pen_joint_accel: -0.0166
    Episode_Reward/pen_action_rate: -0.0224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0058
   Episode_Reward/pen_joint_powers: -0.0093
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0480
Episode_Reward/pen_flat_orientation: -0.1075
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0300
   Episode_Reward/foot_landing_vel: -0.0243
   Episode_Reward/test_gait_reward: -0.1562
Metrics/base_velocity/error_vel_xy: 0.6028
Metrics/base_velocity/error_vel_yaw: 0.1443
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 21.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 1.09s
                        Total time: 463.03s
                               ETA: 2791.2s

################################################################################
                     [1m Learning iteration 427/3000 [0m                      

                       Computation: 90644 steps/s (collection: 0.959s, learning 0.125s)
               Value function loss: 0.8497
                    Surrogate loss: 0.0019
             Mean action noise std: 0.4178
                     Learning rate: 0.0006
                       Mean reward: 6.62
               Mean episode length: 168.29
       Episode_Reward/keep_balance: 0.1710
     Episode_Reward/rew_lin_vel_xy: 0.3004
      Episode_Reward/rew_ang_vel_z: 0.5298
    Episode_Reward/pen_base_height: -0.1730
      Episode_Reward/pen_lin_vel_z: -0.0232
     Episode_Reward/pen_ang_vel_xy: -0.0330
   Episode_Reward/pen_joint_torque: -0.0270
    Episode_Reward/pen_joint_accel: -0.0139
    Episode_Reward/pen_action_rate: -0.0227
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0056
   Episode_Reward/pen_joint_powers: -0.0095
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0485
Episode_Reward/pen_flat_orientation: -0.1045
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0302
   Episode_Reward/foot_landing_vel: -0.0235
   Episode_Reward/test_gait_reward: -0.1580
Metrics/base_velocity/error_vel_xy: 0.6168
Metrics/base_velocity/error_vel_yaw: 0.1451
      Episode_Termination/time_out: 0.1667
  Episode_Termination/base_contact: 18.7083
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 1.08s
                        Total time: 464.11s
                               ETA: 2790.1s

################################################################################
                     [1m Learning iteration 428/3000 [0m                      

                       Computation: 90615 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.8524
                    Surrogate loss: 0.0015
             Mean action noise std: 0.4184
                     Learning rate: 0.0009
                       Mean reward: 6.29
               Mean episode length: 150.65
       Episode_Reward/keep_balance: 0.1605
     Episode_Reward/rew_lin_vel_xy: 0.2863
      Episode_Reward/rew_ang_vel_z: 0.4955
    Episode_Reward/pen_base_height: -0.1668
      Episode_Reward/pen_lin_vel_z: -0.0218
     Episode_Reward/pen_ang_vel_xy: -0.0321
   Episode_Reward/pen_joint_torque: -0.0237
    Episode_Reward/pen_joint_accel: -0.0147
    Episode_Reward/pen_action_rate: -0.0210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0054
   Episode_Reward/pen_joint_powers: -0.0087
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0454
Episode_Reward/pen_flat_orientation: -0.0998
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0282
   Episode_Reward/foot_landing_vel: -0.0218
   Episode_Reward/test_gait_reward: -0.1491
Metrics/base_velocity/error_vel_xy: 0.5745
Metrics/base_velocity/error_vel_yaw: 0.1382
      Episode_Termination/time_out: 0.1250
  Episode_Termination/base_contact: 18.8750
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 1.08s
                        Total time: 465.20s
                               ETA: 2789.0s

################################################################################
                     [1m Learning iteration 429/3000 [0m                      

                       Computation: 91713 steps/s (collection: 0.947s, learning 0.125s)
               Value function loss: 0.7779
                    Surrogate loss: 0.0132
             Mean action noise std: 0.4187
                     Learning rate: 0.0001
                       Mean reward: 5.76
               Mean episode length: 161.95
       Episode_Reward/keep_balance: 0.1595
     Episode_Reward/rew_lin_vel_xy: 0.2870
      Episode_Reward/rew_ang_vel_z: 0.4936
    Episode_Reward/pen_base_height: -0.1678
      Episode_Reward/pen_lin_vel_z: -0.0211
     Episode_Reward/pen_ang_vel_xy: -0.0310
   Episode_Reward/pen_joint_torque: -0.0235
    Episode_Reward/pen_joint_accel: -0.0150
    Episode_Reward/pen_action_rate: -0.0207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0052
   Episode_Reward/pen_joint_powers: -0.0084
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0456
Episode_Reward/pen_flat_orientation: -0.0995
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0266
   Episode_Reward/foot_landing_vel: -0.0217
   Episode_Reward/test_gait_reward: -0.1483
Metrics/base_velocity/error_vel_xy: 0.5757
Metrics/base_velocity/error_vel_yaw: 0.1358
      Episode_Termination/time_out: 0.0833
  Episode_Termination/base_contact: 19.8333
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 1.07s
                        Total time: 466.27s
                               ETA: 2787.9s

################################################################################
                     [1m Learning iteration 430/3000 [0m                      

                       Computation: 91475 steps/s (collection: 0.950s, learning 0.125s)
               Value function loss: 0.6763
                    Surrogate loss: -0.0018
             Mean action noise std: 0.4189
                     Learning rate: 0.0006
                       Mean reward: 6.40
               Mean episode length: 167.70
       Episode_Reward/keep_balance: 0.1847
     Episode_Reward/rew_lin_vel_xy: 0.3189
      Episode_Reward/rew_ang_vel_z: 0.5770
    Episode_Reward/pen_base_height: -0.1767
      Episode_Reward/pen_lin_vel_z: -0.0235
     Episode_Reward/pen_ang_vel_xy: -0.0338
   Episode_Reward/pen_joint_torque: -0.0275
    Episode_Reward/pen_joint_accel: -0.0166
    Episode_Reward/pen_action_rate: -0.0247
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0061
   Episode_Reward/pen_joint_powers: -0.0100
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.0527
Episode_Reward/pen_flat_orientation: -0.1099
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0301
   Episode_Reward/foot_landing_vel: -0.0259
   Episode_Reward/test_gait_reward: -0.1694
Metrics/base_velocity/error_vel_xy: 0.6649
Metrics/base_velocity/error_vel_yaw: 0.1532
      Episode_Termination/time_out: 0.2500
  Episode_Termination/base_contact: 26.3750
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 1.07s
                        Total time: 467.34s
                               ETA: 2786.7s

################################################################################
                     [1m Learning iteration 431/3000 [0m                      

                       Computation: 90098 steps/s (collection: 0.965s, learning 0.126s)
               Value function loss: 0.7319
                    Surrogate loss: 0.0007
             Mean action noise std: 0.4189
                     Learning rate: 0.0006
                       Mean reward: 8.07
               Mean episode length: 191.77
       Episode_Reward/keep_balance: 0.1915
     Episode_Reward/rew_lin_vel_xy: 0.3559
      Episode_Reward/rew_ang_vel_z: 0.5996
    Episode_Reward/pen_base_height: -0.1797
      Episode_Reward/pen_lin_vel_z: -0.0242
     Episode_Reward/pen_ang_vel_xy: -0.0340
   Episode_Reward/pen_joint_torque: -0.0288
    Episode_Reward/pen_joint_accel: -0.0168
    Episode_Reward/pen_action_rate: -0.0254
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0062
   Episode_Reward/pen_joint_powers: -0.0103
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0544
Episode_Reward/pen_flat_orientation: -0.1096
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0319
   Episode_Reward/foot_landing_vel: -0.0266
   Episode_Reward/test_gait_reward: -0.1762
Metrics/base_velocity/error_vel_xy: 0.6644
Metrics/base_velocity/error_vel_yaw: 0.1578
      Episode_Termination/time_out: 0.2500
  Episode_Termination/base_contact: 21.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 1.09s
                        Total time: 468.44s
                               ETA: 2785.7s

################################################################################
                     [1m Learning iteration 432/3000 [0m                      

                       Computation: 90783 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.7804
                    Surrogate loss: -0.0011
             Mean action noise std: 0.4193
                     Learning rate: 0.0009
                       Mean reward: 4.51
               Mean episode length: 138.23
       Episode_Reward/keep_balance: 0.1753
     Episode_Reward/rew_lin_vel_xy: 0.2992
      Episode_Reward/rew_ang_vel_z: 0.5468
    Episode_Reward/pen_base_height: -0.1706
      Episode_Reward/pen_lin_vel_z: -0.0220
     Episode_Reward/pen_ang_vel_xy: -0.0326
   Episode_Reward/pen_joint_torque: -0.0255
    Episode_Reward/pen_joint_accel: -0.0152
    Episode_Reward/pen_action_rate: -0.0227
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0056
   Episode_Reward/pen_joint_powers: -0.0092
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0492
Episode_Reward/pen_flat_orientation: -0.1035
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0277
   Episode_Reward/foot_landing_vel: -0.0232
   Episode_Reward/test_gait_reward: -0.1619
Metrics/base_velocity/error_vel_xy: 0.6365
Metrics/base_velocity/error_vel_yaw: 0.1457
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 1.08s
                        Total time: 469.52s
                               ETA: 2784.6s

################################################################################
                     [1m Learning iteration 433/3000 [0m                      

                       Computation: 91272 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 0.7482
                    Surrogate loss: 0.0027
             Mean action noise std: 0.4199
                     Learning rate: 0.0009
                       Mean reward: 8.12
               Mean episode length: 213.70
       Episode_Reward/keep_balance: 0.1951
     Episode_Reward/rew_lin_vel_xy: 0.3354
      Episode_Reward/rew_ang_vel_z: 0.6047
    Episode_Reward/pen_base_height: -0.1830
      Episode_Reward/pen_lin_vel_z: -0.0264
     Episode_Reward/pen_ang_vel_xy: -0.0353
   Episode_Reward/pen_joint_torque: -0.0305
    Episode_Reward/pen_joint_accel: -0.0178
    Episode_Reward/pen_action_rate: -0.0269
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0067
   Episode_Reward/pen_joint_powers: -0.0110
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0559
Episode_Reward/pen_flat_orientation: -0.1144
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0357
   Episode_Reward/foot_landing_vel: -0.0277
   Episode_Reward/test_gait_reward: -0.1793
Metrics/base_velocity/error_vel_xy: 0.6971
Metrics/base_velocity/error_vel_yaw: 0.1655
      Episode_Termination/time_out: 0.3750
  Episode_Termination/base_contact: 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 1.08s
                        Total time: 470.60s
                               ETA: 2783.5s

################################################################################
                     [1m Learning iteration 434/3000 [0m                      

                       Computation: 91035 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.6805
                    Surrogate loss: 0.0026
             Mean action noise std: 0.4201
                     Learning rate: 0.0006
                       Mean reward: 8.52
               Mean episode length: 196.06
       Episode_Reward/keep_balance: 0.1922
     Episode_Reward/rew_lin_vel_xy: 0.3433
      Episode_Reward/rew_ang_vel_z: 0.5948
    Episode_Reward/pen_base_height: -0.1823
      Episode_Reward/pen_lin_vel_z: -0.0254
     Episode_Reward/pen_ang_vel_xy: -0.0360
   Episode_Reward/pen_joint_torque: -0.0286
    Episode_Reward/pen_joint_accel: -0.0173
    Episode_Reward/pen_action_rate: -0.0262
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0066
   Episode_Reward/pen_joint_powers: -0.0106
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0548
Episode_Reward/pen_flat_orientation: -0.1174
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0353
   Episode_Reward/foot_landing_vel: -0.0278
   Episode_Reward/test_gait_reward: -0.1781
Metrics/base_velocity/error_vel_xy: 0.6798
Metrics/base_velocity/error_vel_yaw: 0.1649
      Episode_Termination/time_out: 0.2083
  Episode_Termination/base_contact: 15.2083
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 1.08s
                        Total time: 471.68s
                               ETA: 2782.3s

################################################################################
                     [1m Learning iteration 435/3000 [0m                      

                       Computation: 92359 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 0.7225
                    Surrogate loss: 0.0015
             Mean action noise std: 0.4202
                     Learning rate: 0.0006
                       Mean reward: 6.28
               Mean episode length: 199.95
       Episode_Reward/keep_balance: 0.1866
     Episode_Reward/rew_lin_vel_xy: 0.3130
      Episode_Reward/rew_ang_vel_z: 0.5800
    Episode_Reward/pen_base_height: -0.1764
      Episode_Reward/pen_lin_vel_z: -0.0236
     Episode_Reward/pen_ang_vel_xy: -0.0339
   Episode_Reward/pen_joint_torque: -0.0283
    Episode_Reward/pen_joint_accel: -0.0160
    Episode_Reward/pen_action_rate: -0.0251
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0061
   Episode_Reward/pen_joint_powers: -0.0101
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0538
Episode_Reward/pen_flat_orientation: -0.1062
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0321
   Episode_Reward/foot_landing_vel: -0.0254
   Episode_Reward/test_gait_reward: -0.1726
Metrics/base_velocity/error_vel_xy: 0.6825
Metrics/base_velocity/error_vel_yaw: 0.1585
      Episode_Termination/time_out: 0.2500
  Episode_Termination/base_contact: 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 1.06s
                        Total time: 472.74s
                               ETA: 2781.1s

################################################################################
                     [1m Learning iteration 436/3000 [0m                      

                       Computation: 90501 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.7168
                    Surrogate loss: -0.0014
             Mean action noise std: 0.4200
                     Learning rate: 0.0009
                       Mean reward: 8.31
               Mean episode length: 191.02
       Episode_Reward/keep_balance: 0.1910
     Episode_Reward/rew_lin_vel_xy: 0.3412
      Episode_Reward/rew_ang_vel_z: 0.5881
    Episode_Reward/pen_base_height: -0.1811
      Episode_Reward/pen_lin_vel_z: -0.0252
     Episode_Reward/pen_ang_vel_xy: -0.0351
   Episode_Reward/pen_joint_torque: -0.0300
    Episode_Reward/pen_joint_accel: -0.0174
    Episode_Reward/pen_action_rate: -0.0262
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0066
   Episode_Reward/pen_joint_powers: -0.0109
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0549
Episode_Reward/pen_flat_orientation: -0.1114
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0354
   Episode_Reward/foot_landing_vel: -0.0276
   Episode_Reward/test_gait_reward: -0.1767
Metrics/base_velocity/error_vel_xy: 0.6871
Metrics/base_velocity/error_vel_yaw: 0.1650
      Episode_Termination/time_out: 0.3333
  Episode_Termination/base_contact: 14.4583
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 1.09s
                        Total time: 473.83s
                               ETA: 2780.1s

################################################################################
                     [1m Learning iteration 437/3000 [0m                      

                       Computation: 91017 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.7840
                    Surrogate loss: 0.0019
             Mean action noise std: 0.4200
                     Learning rate: 0.0009
                       Mean reward: 10.48
               Mean episode length: 213.70
       Episode_Reward/keep_balance: 0.2254
     Episode_Reward/rew_lin_vel_xy: 0.4301
      Episode_Reward/rew_ang_vel_z: 0.6978
    Episode_Reward/pen_base_height: -0.1941
      Episode_Reward/pen_lin_vel_z: -0.0284
     Episode_Reward/pen_ang_vel_xy: -0.0377
   Episode_Reward/pen_joint_torque: -0.0350
    Episode_Reward/pen_joint_accel: -0.0195
    Episode_Reward/pen_action_rate: -0.0314
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0075
   Episode_Reward/pen_joint_powers: -0.0126
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0656
Episode_Reward/pen_flat_orientation: -0.1214
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0402
   Episode_Reward/foot_landing_vel: -0.0321
   Episode_Reward/test_gait_reward: -0.2064
Metrics/base_velocity/error_vel_xy: 0.7648
Metrics/base_velocity/error_vel_yaw: 0.1917
      Episode_Termination/time_out: 0.6667
  Episode_Termination/base_contact: 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 1.08s
                        Total time: 474.91s
                               ETA: 2779.0s

################################################################################
                     [1m Learning iteration 438/3000 [0m                      

                       Computation: 91365 steps/s (collection: 0.951s, learning 0.125s)
               Value function loss: 0.8436
                    Surrogate loss: 0.0001
             Mean action noise std: 0.4203
                     Learning rate: 0.0013
                       Mean reward: 8.51
               Mean episode length: 186.71
       Episode_Reward/keep_balance: 0.2090
     Episode_Reward/rew_lin_vel_xy: 0.3706
      Episode_Reward/rew_ang_vel_z: 0.6470
    Episode_Reward/pen_base_height: -0.1887
      Episode_Reward/pen_lin_vel_z: -0.0275
     Episode_Reward/pen_ang_vel_xy: -0.0370
   Episode_Reward/pen_joint_torque: -0.0326
    Episode_Reward/pen_joint_accel: -0.0186
    Episode_Reward/pen_action_rate: -0.0293
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0071
   Episode_Reward/pen_joint_powers: -0.0117
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0612
Episode_Reward/pen_flat_orientation: -0.1159
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0384
   Episode_Reward/foot_landing_vel: -0.0291
   Episode_Reward/test_gait_reward: -0.1926
Metrics/base_velocity/error_vel_xy: 0.7470
Metrics/base_velocity/error_vel_yaw: 0.1784
      Episode_Termination/time_out: 0.3333
  Episode_Termination/base_contact: 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 1.08s
                        Total time: 475.98s
                               ETA: 2777.8s

################################################################################
                     [1m Learning iteration 439/3000 [0m                      

                       Computation: 90228 steps/s (collection: 0.961s, learning 0.128s)
               Value function loss: 1.0870
                    Surrogate loss: -0.0007
             Mean action noise std: 0.4198
                     Learning rate: 0.0029
                       Mean reward: 9.34
               Mean episode length: 244.56
       Episode_Reward/keep_balance: 0.2230
     Episode_Reward/rew_lin_vel_xy: 0.3889
      Episode_Reward/rew_ang_vel_z: 0.6870
    Episode_Reward/pen_base_height: -0.1940
      Episode_Reward/pen_lin_vel_z: -0.0286
     Episode_Reward/pen_ang_vel_xy: -0.0378
   Episode_Reward/pen_joint_torque: -0.0342
    Episode_Reward/pen_joint_accel: -0.0216
    Episode_Reward/pen_action_rate: -0.0313
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0077
   Episode_Reward/pen_joint_powers: -0.0126
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0655
Episode_Reward/pen_flat_orientation: -0.1206
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0402
   Episode_Reward/foot_landing_vel: -0.0313
   Episode_Reward/test_gait_reward: -0.2056
Metrics/base_velocity/error_vel_xy: 0.7722
Metrics/base_velocity/error_vel_yaw: 0.1922
      Episode_Termination/time_out: 0.6667
  Episode_Termination/base_contact: 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 1.09s
                        Total time: 477.07s
                               ETA: 2776.8s

################################################################################
                     [1m Learning iteration 440/3000 [0m                      

                       Computation: 90782 steps/s (collection: 0.957s, learning 0.126s)
               Value function loss: 1.0808
                    Surrogate loss: 0.0031
             Mean action noise std: 0.4196
                     Learning rate: 0.0013
                       Mean reward: 10.20
               Mean episode length: 229.35
       Episode_Reward/keep_balance: 0.2210
     Episode_Reward/rew_lin_vel_xy: 0.4006
      Episode_Reward/rew_ang_vel_z: 0.6869
    Episode_Reward/pen_base_height: -0.1925
      Episode_Reward/pen_lin_vel_z: -0.0278
     Episode_Reward/pen_ang_vel_xy: -0.0380
   Episode_Reward/pen_joint_torque: -0.0333
    Episode_Reward/pen_joint_accel: -0.0194
    Episode_Reward/pen_action_rate: -0.0309
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0075
   Episode_Reward/pen_joint_powers: -0.0122
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0649
Episode_Reward/pen_flat_orientation: -0.1190
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0398
   Episode_Reward/foot_landing_vel: -0.0314
   Episode_Reward/test_gait_reward: -0.2039
Metrics/base_velocity/error_vel_xy: 0.7662
Metrics/base_velocity/error_vel_yaw: 0.1858
      Episode_Termination/time_out: 0.2917
  Episode_Termination/base_contact: 15.7917
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 1.08s
                        Total time: 478.15s
                               ETA: 2775.7s

################################################################################
                     [1m Learning iteration 441/3000 [0m                      

                       Computation: 92202 steps/s (collection: 0.942s, learning 0.124s)
               Value function loss: 0.6782
                    Surrogate loss: 0.0049
             Mean action noise std: 0.4202
                     Learning rate: 0.0002
                       Mean reward: 13.06
               Mean episode length: 256.21
       Episode_Reward/keep_balance: 0.2439
     Episode_Reward/rew_lin_vel_xy: 0.4443
      Episode_Reward/rew_ang_vel_z: 0.7670
    Episode_Reward/pen_base_height: -0.2002
      Episode_Reward/pen_lin_vel_z: -0.0294
     Episode_Reward/pen_ang_vel_xy: -0.0389
   Episode_Reward/pen_joint_torque: -0.0376
    Episode_Reward/pen_joint_accel: -0.0221
    Episode_Reward/pen_action_rate: -0.0339
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0079
   Episode_Reward/pen_joint_powers: -0.0134
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0707
Episode_Reward/pen_flat_orientation: -0.1232
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0408
   Episode_Reward/foot_landing_vel: -0.0329
   Episode_Reward/test_gait_reward: -0.2237
Metrics/base_velocity/error_vel_xy: 0.8517
Metrics/base_velocity/error_vel_yaw: 0.1978
      Episode_Termination/time_out: 0.4167
  Episode_Termination/base_contact: 19.9583
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 1.07s
                        Total time: 479.22s
                               ETA: 2774.5s

################################################################################
                     [1m Learning iteration 442/3000 [0m                      

                       Computation: 92111 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 0.6934
                    Surrogate loss: 0.0034
             Mean action noise std: 0.4205
                     Learning rate: 0.0001
                       Mean reward: 10.38
               Mean episode length: 227.03
       Episode_Reward/keep_balance: 0.2286
     Episode_Reward/rew_lin_vel_xy: 0.4155
      Episode_Reward/rew_ang_vel_z: 0.7091
    Episode_Reward/pen_base_height: -0.1932
      Episode_Reward/pen_lin_vel_z: -0.0276
     Episode_Reward/pen_ang_vel_xy: -0.0381
   Episode_Reward/pen_joint_torque: -0.0341
    Episode_Reward/pen_joint_accel: -0.0196
    Episode_Reward/pen_action_rate: -0.0316
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0074
   Episode_Reward/pen_joint_powers: -0.0124
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0665
Episode_Reward/pen_flat_orientation: -0.1206
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0381
   Episode_Reward/foot_landing_vel: -0.0309
   Episode_Reward/test_gait_reward: -0.2100
Metrics/base_velocity/error_vel_xy: 0.8034
Metrics/base_velocity/error_vel_yaw: 0.1937
      Episode_Termination/time_out: 0.4167
  Episode_Termination/base_contact: 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 1.07s
                        Total time: 480.29s
                               ETA: 2773.3s

################################################################################
                     [1m Learning iteration 443/3000 [0m                      

                       Computation: 91274 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.6497
                    Surrogate loss: -0.0011
             Mean action noise std: 0.4207
                     Learning rate: 0.0006
                       Mean reward: 8.19
               Mean episode length: 194.33
       Episode_Reward/keep_balance: 0.2264
     Episode_Reward/rew_lin_vel_xy: 0.4174
      Episode_Reward/rew_ang_vel_z: 0.7068
    Episode_Reward/pen_base_height: -0.1921
      Episode_Reward/pen_lin_vel_z: -0.0270
     Episode_Reward/pen_ang_vel_xy: -0.0373
   Episode_Reward/pen_joint_torque: -0.0342
    Episode_Reward/pen_joint_accel: -0.0206
    Episode_Reward/pen_action_rate: -0.0311
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0072
   Episode_Reward/pen_joint_powers: -0.0121
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0658
Episode_Reward/pen_flat_orientation: -0.1155
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0370
   Episode_Reward/foot_landing_vel: -0.0288
   Episode_Reward/test_gait_reward: -0.2084
Metrics/base_velocity/error_vel_xy: 0.7730
Metrics/base_velocity/error_vel_yaw: 0.1882
      Episode_Termination/time_out: 0.3750
  Episode_Termination/base_contact: 18.1250
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 1.08s
                        Total time: 481.36s
                               ETA: 2772.2s

################################################################################
                     [1m Learning iteration 444/3000 [0m                      

                       Computation: 89997 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.7200
                    Surrogate loss: -0.0024
             Mean action noise std: 0.4214
                     Learning rate: 0.0013
                       Mean reward: 12.88
               Mean episode length: 248.86
       Episode_Reward/keep_balance: 0.2294
     Episode_Reward/rew_lin_vel_xy: 0.4136
      Episode_Reward/rew_ang_vel_z: 0.7218
    Episode_Reward/pen_base_height: -0.1944
      Episode_Reward/pen_lin_vel_z: -0.0274
     Episode_Reward/pen_ang_vel_xy: -0.0377
   Episode_Reward/pen_joint_torque: -0.0340
    Episode_Reward/pen_joint_accel: -0.0191
    Episode_Reward/pen_action_rate: -0.0316
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0073
   Episode_Reward/pen_joint_powers: -0.0124
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0665
Episode_Reward/pen_flat_orientation: -0.1193
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0375
   Episode_Reward/foot_landing_vel: -0.0306
   Episode_Reward/test_gait_reward: -0.2104
Metrics/base_velocity/error_vel_xy: 0.7927
Metrics/base_velocity/error_vel_yaw: 0.1863
      Episode_Termination/time_out: 0.5417
  Episode_Termination/base_contact: 20.5000
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 1.09s
                        Total time: 482.46s
                               ETA: 2771.1s

################################################################################
                     [1m Learning iteration 445/3000 [0m                      

                       Computation: 90368 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.8197
                    Surrogate loss: 0.0005
             Mean action noise std: 0.4215
                     Learning rate: 0.0013
                       Mean reward: 7.78
               Mean episode length: 197.17
       Episode_Reward/keep_balance: 0.2390
     Episode_Reward/rew_lin_vel_xy: 0.4526
      Episode_Reward/rew_ang_vel_z: 0.7508
    Episode_Reward/pen_base_height: -0.1973
      Episode_Reward/pen_lin_vel_z: -0.0284
     Episode_Reward/pen_ang_vel_xy: -0.0386
   Episode_Reward/pen_joint_torque: -0.0363
    Episode_Reward/pen_joint_accel: -0.0211
    Episode_Reward/pen_action_rate: -0.0334
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0076
   Episode_Reward/pen_joint_powers: -0.0130
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0700
Episode_Reward/pen_flat_orientation: -0.1251
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0379
   Episode_Reward/foot_landing_vel: -0.0314
   Episode_Reward/test_gait_reward: -0.2196
Metrics/base_velocity/error_vel_xy: 0.8179
Metrics/base_velocity/error_vel_yaw: 0.1951
      Episode_Termination/time_out: 0.7083
  Episode_Termination/base_contact: 18.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 1.09s
                        Total time: 483.54s
                               ETA: 2770.1s

################################################################################
                     [1m Learning iteration 446/3000 [0m                      

                       Computation: 91151 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.7983
                    Surrogate loss: -0.0028
             Mean action noise std: 0.4209
                     Learning rate: 0.0019
                       Mean reward: 9.78
               Mean episode length: 211.67
       Episode_Reward/keep_balance: 0.2113
     Episode_Reward/rew_lin_vel_xy: 0.3954
      Episode_Reward/rew_ang_vel_z: 0.6614
    Episode_Reward/pen_base_height: -0.1862
      Episode_Reward/pen_lin_vel_z: -0.0255
     Episode_Reward/pen_ang_vel_xy: -0.0364
   Episode_Reward/pen_joint_torque: -0.0311
    Episode_Reward/pen_joint_accel: -0.0188
    Episode_Reward/pen_action_rate: -0.0291
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0067
   Episode_Reward/pen_joint_powers: -0.0112
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0613
Episode_Reward/pen_flat_orientation: -0.1150
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0343
   Episode_Reward/foot_landing_vel: -0.0280
   Episode_Reward/test_gait_reward: -0.1944
Metrics/base_velocity/error_vel_xy: 0.7154
Metrics/base_velocity/error_vel_yaw: 0.1743
      Episode_Termination/time_out: 0.3333
  Episode_Termination/base_contact: 17.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 1.08s
                        Total time: 484.62s
                               ETA: 2769.0s

################################################################################
                     [1m Learning iteration 447/3000 [0m                      

                       Computation: 90511 steps/s (collection: 0.960s, learning 0.126s)
               Value function loss: 0.7651
                    Surrogate loss: 0.0094
             Mean action noise std: 0.4211
                     Learning rate: 0.0003
                       Mean reward: 8.69
               Mean episode length: 191.83
       Episode_Reward/keep_balance: 0.1950
     Episode_Reward/rew_lin_vel_xy: 0.3539
      Episode_Reward/rew_ang_vel_z: 0.6079
    Episode_Reward/pen_base_height: -0.1788
      Episode_Reward/pen_lin_vel_z: -0.0238
     Episode_Reward/pen_ang_vel_xy: -0.0343
   Episode_Reward/pen_joint_torque: -0.0289
    Episode_Reward/pen_joint_accel: -0.0170
    Episode_Reward/pen_action_rate: -0.0266
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0062
   Episode_Reward/pen_joint_powers: -0.0105
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0566
Episode_Reward/pen_flat_orientation: -0.1087
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0311
   Episode_Reward/foot_landing_vel: -0.0262
   Episode_Reward/test_gait_reward: -0.1796
Metrics/base_velocity/error_vel_xy: 0.6863
Metrics/base_velocity/error_vel_yaw: 0.1628
      Episode_Termination/time_out: 0.5833
  Episode_Termination/base_contact: 18.0417
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 1.09s
                        Total time: 485.71s
                               ETA: 2767.9s

################################################################################
                     [1m Learning iteration 448/3000 [0m                      

                       Computation: 91253 steps/s (collection: 0.952s, learning 0.125s)
               Value function loss: 0.7183
                    Surrogate loss: 0.0018
             Mean action noise std: 0.4218
                     Learning rate: 0.0006
                       Mean reward: 11.18
               Mean episode length: 254.48
       Episode_Reward/keep_balance: 0.2251
     Episode_Reward/rew_lin_vel_xy: 0.4301
      Episode_Reward/rew_ang_vel_z: 0.6999
    Episode_Reward/pen_base_height: -0.1911
      Episode_Reward/pen_lin_vel_z: -0.0274
     Episode_Reward/pen_ang_vel_xy: -0.0376
   Episode_Reward/pen_joint_torque: -0.0348
    Episode_Reward/pen_joint_accel: -0.0199
    Episode_Reward/pen_action_rate: -0.0314
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0074
   Episode_Reward/pen_joint_powers: -0.0125
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0656
Episode_Reward/pen_flat_orientation: -0.1171
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0375
   Episode_Reward/foot_landing_vel: -0.0313
   Episode_Reward/test_gait_reward: -0.2070
Metrics/base_velocity/error_vel_xy: 0.7604
Metrics/base_velocity/error_vel_yaw: 0.1881
      Episode_Termination/time_out: 0.8750
  Episode_Termination/base_contact: 16.1667
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 1.08s
                        Total time: 486.79s
                               ETA: 2766.8s

################################################################################
                     [1m Learning iteration 449/3000 [0m                      

                       Computation: 90079 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.7504
                    Surrogate loss: 0.0069
             Mean action noise std: 0.4225
                     Learning rate: 0.0002
                       Mean reward: 11.41
               Mean episode length: 254.20
       Episode_Reward/keep_balance: 0.2194
     Episode_Reward/rew_lin_vel_xy: 0.3850
      Episode_Reward/rew_ang_vel_z: 0.6795
    Episode_Reward/pen_base_height: -0.1904
      Episode_Reward/pen_lin_vel_z: -0.0259
     Episode_Reward/pen_ang_vel_xy: -0.0358
   Episode_Reward/pen_joint_torque: -0.0330
    Episode_Reward/pen_joint_accel: -0.0192
    Episode_Reward/pen_action_rate: -0.0303
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0070
   Episode_Reward/pen_joint_powers: -0.0118
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0642
Episode_Reward/pen_flat_orientation: -0.1159
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0363
   Episode_Reward/foot_landing_vel: -0.0294
   Episode_Reward/test_gait_reward: -0.2011
Metrics/base_velocity/error_vel_xy: 0.7889
Metrics/base_velocity/error_vel_yaw: 0.1854
      Episode_Termination/time_out: 0.3333
  Episode_Termination/base_contact: 14.3750
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 1.09s
                        Total time: 487.88s
                               ETA: 2765.7s

################################################################################
                     [1m Learning iteration 450/3000 [0m                      

                       Computation: 90019 steps/s (collection: 0.967s, learning 0.125s)
               Value function loss: 0.7281
                    Surrogate loss: 0.0112
             Mean action noise std: 0.4226
                     Learning rate: 0.0000
                       Mean reward: 11.15
               Mean episode length: 229.98
       Episode_Reward/keep_balance: 0.2203
     Episode_Reward/rew_lin_vel_xy: 0.3981
      Episode_Reward/rew_ang_vel_z: 0.6875
    Episode_Reward/pen_base_height: -0.1893
      Episode_Reward/pen_lin_vel_z: -0.0264
     Episode_Reward/pen_ang_vel_xy: -0.0361
   Episode_Reward/pen_joint_torque: -0.0332
    Episode_Reward/pen_joint_accel: -0.0183
    Episode_Reward/pen_action_rate: -0.0306
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0070
   Episode_Reward/pen_joint_powers: -0.0119
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0646
Episode_Reward/pen_flat_orientation: -0.1157
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0373
   Episode_Reward/foot_landing_vel: -0.0290
   Episode_Reward/test_gait_reward: -0.2026
Metrics/base_velocity/error_vel_xy: 0.7710
Metrics/base_velocity/error_vel_yaw: 0.1823
      Episode_Termination/time_out: 0.6250
  Episode_Termination/base_contact: 19.1250
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 1.09s
                        Total time: 488.97s
                               ETA: 2764.7s

################################################################################
                     [1m Learning iteration 451/3000 [0m                      

                       Computation: 91290 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.6509
                    Surrogate loss: 0.0041
             Mean action noise std: 0.4226
                     Learning rate: 0.0000
                       Mean reward: 9.65
               Mean episode length: 202.29
       Episode_Reward/keep_balance: 0.2110
     Episode_Reward/rew_lin_vel_xy: 0.3919
      Episode_Reward/rew_ang_vel_z: 0.6563
    Episode_Reward/pen_base_height: -0.1851
      Episode_Reward/pen_lin_vel_z: -0.0252
     Episode_Reward/pen_ang_vel_xy: -0.0355
   Episode_Reward/pen_joint_torque: -0.0311
    Episode_Reward/pen_joint_accel: -0.0191
    Episode_Reward/pen_action_rate: -0.0292
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0067
   Episode_Reward/pen_joint_powers: -0.0112
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0615
Episode_Reward/pen_flat_orientation: -0.1134
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0349
   Episode_Reward/foot_landing_vel: -0.0279
   Episode_Reward/test_gait_reward: -0.1933
Metrics/base_velocity/error_vel_xy: 0.7227
Metrics/base_velocity/error_vel_yaw: 0.1763
      Episode_Termination/time_out: 0.4583
  Episode_Termination/base_contact: 19.8333
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 1.08s
                        Total time: 490.05s
                               ETA: 2763.6s

################################################################################
                     [1m Learning iteration 452/3000 [0m                      

                       Computation: 91399 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.7019
                    Surrogate loss: 0.0057
             Mean action noise std: 0.4226
                     Learning rate: 0.0000
                       Mean reward: 9.86
               Mean episode length: 211.80
       Episode_Reward/keep_balance: 0.2306
     Episode_Reward/rew_lin_vel_xy: 0.4423
      Episode_Reward/rew_ang_vel_z: 0.7170
    Episode_Reward/pen_base_height: -0.1932
      Episode_Reward/pen_lin_vel_z: -0.0272
     Episode_Reward/pen_ang_vel_xy: -0.0373
   Episode_Reward/pen_joint_torque: -0.0344
    Episode_Reward/pen_joint_accel: -0.0209
    Episode_Reward/pen_action_rate: -0.0321
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0073
   Episode_Reward/pen_joint_powers: -0.0123
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0676
Episode_Reward/pen_flat_orientation: -0.1191
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0382
   Episode_Reward/foot_landing_vel: -0.0299
   Episode_Reward/test_gait_reward: -0.2123
Metrics/base_velocity/error_vel_xy: 0.7751
Metrics/base_velocity/error_vel_yaw: 0.1925
      Episode_Termination/time_out: 0.4583
  Episode_Termination/base_contact: 18.3333
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 1.08s
                        Total time: 491.12s
                               ETA: 2762.4s

################################################################################
                     [1m Learning iteration 453/3000 [0m                      

                       Computation: 92286 steps/s (collection: 0.942s, learning 0.124s)
               Value function loss: 0.8302
                    Surrogate loss: 0.0119
             Mean action noise std: 0.4226
                     Learning rate: 0.0000
                       Mean reward: 11.16
               Mean episode length: 237.07
       Episode_Reward/keep_balance: 0.2434
     Episode_Reward/rew_lin_vel_xy: 0.4578
      Episode_Reward/rew_ang_vel_z: 0.7581
    Episode_Reward/pen_base_height: -0.1993
      Episode_Reward/pen_lin_vel_z: -0.0290
     Episode_Reward/pen_ang_vel_xy: -0.0393
   Episode_Reward/pen_joint_torque: -0.0373
    Episode_Reward/pen_joint_accel: -0.0219
    Episode_Reward/pen_action_rate: -0.0346
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0079
   Episode_Reward/pen_joint_powers: -0.0134
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0720
Episode_Reward/pen_flat_orientation: -0.1258
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0409
   Episode_Reward/foot_landing_vel: -0.0337
   Episode_Reward/test_gait_reward: -0.2234
Metrics/base_velocity/error_vel_xy: 0.8306
Metrics/base_velocity/error_vel_yaw: 0.2025
      Episode_Termination/time_out: 0.7083
  Episode_Termination/base_contact: 17.1250
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 1.07s
                        Total time: 492.19s
                               ETA: 2761.2s

################################################################################
                     [1m Learning iteration 454/3000 [0m                      

                       Computation: 91718 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.7373
                    Surrogate loss: 0.0111
             Mean action noise std: 0.4226
                     Learning rate: 0.0001
                       Mean reward: 9.83
               Mean episode length: 226.81
       Episode_Reward/keep_balance: 0.2086
     Episode_Reward/rew_lin_vel_xy: 0.3662
      Episode_Reward/rew_ang_vel_z: 0.6509
    Episode_Reward/pen_base_height: -0.1833
      Episode_Reward/pen_lin_vel_z: -0.0250
     Episode_Reward/pen_ang_vel_xy: -0.0358
   Episode_Reward/pen_joint_torque: -0.0313
    Episode_Reward/pen_joint_accel: -0.0181
    Episode_Reward/pen_action_rate: -0.0290
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0066
   Episode_Reward/pen_joint_powers: -0.0111
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0609
Episode_Reward/pen_flat_orientation: -0.1116
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0341
   Episode_Reward/foot_landing_vel: -0.0264
   Episode_Reward/test_gait_reward: -0.1919
Metrics/base_velocity/error_vel_xy: 0.7447
Metrics/base_velocity/error_vel_yaw: 0.1747
      Episode_Termination/time_out: 0.6250
  Episode_Termination/base_contact: 17.8333
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 1.07s
                        Total time: 493.26s
                               ETA: 2760.1s

################################################################################
                     [1m Learning iteration 455/3000 [0m                      

                       Computation: 92065 steps/s (collection: 0.941s, learning 0.126s)
               Value function loss: 0.6405
                    Surrogate loss: 0.0095
             Mean action noise std: 0.4227
                     Learning rate: 0.0000
                       Mean reward: 9.72
               Mean episode length: 220.84
       Episode_Reward/keep_balance: 0.2307
     Episode_Reward/rew_lin_vel_xy: 0.4316
      Episode_Reward/rew_ang_vel_z: 0.7174
    Episode_Reward/pen_base_height: -0.1926
      Episode_Reward/pen_lin_vel_z: -0.0276
     Episode_Reward/pen_ang_vel_xy: -0.0373
   Episode_Reward/pen_joint_torque: -0.0355
    Episode_Reward/pen_joint_accel: -0.0206
    Episode_Reward/pen_action_rate: -0.0328
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0075
   Episode_Reward/pen_joint_powers: -0.0127
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0682
Episode_Reward/pen_flat_orientation: -0.1176
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0382
   Episode_Reward/foot_landing_vel: -0.0307
   Episode_Reward/test_gait_reward: -0.2113
Metrics/base_velocity/error_vel_xy: 0.7827
Metrics/base_velocity/error_vel_yaw: 0.1936
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 22.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 1.07s
                        Total time: 494.33s
                               ETA: 2758.9s

################################################################################
                     [1m Learning iteration 456/3000 [0m                      

                       Computation: 91403 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.7661
                    Surrogate loss: 0.0015
             Mean action noise std: 0.4230
                     Learning rate: 0.0001
                       Mean reward: 11.06
               Mean episode length: 226.68
       Episode_Reward/keep_balance: 0.2454
     Episode_Reward/rew_lin_vel_xy: 0.4446
      Episode_Reward/rew_ang_vel_z: 0.7619
    Episode_Reward/pen_base_height: -0.1973
      Episode_Reward/pen_lin_vel_z: -0.0280
     Episode_Reward/pen_ang_vel_xy: -0.0381
   Episode_Reward/pen_joint_torque: -0.0369
    Episode_Reward/pen_joint_accel: -0.0202
    Episode_Reward/pen_action_rate: -0.0344
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0075
   Episode_Reward/pen_joint_powers: -0.0129
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0727
Episode_Reward/pen_flat_orientation: -0.1188
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0389
   Episode_Reward/foot_landing_vel: -0.0310
   Episode_Reward/test_gait_reward: -0.2242
Metrics/base_velocity/error_vel_xy: 0.8331
Metrics/base_velocity/error_vel_yaw: 0.2062
      Episode_Termination/time_out: 0.7500
  Episode_Termination/base_contact: 19.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 1.08s
                        Total time: 495.40s
                               ETA: 2757.8s

################################################################################
                     [1m Learning iteration 457/3000 [0m                      

                       Computation: 91605 steps/s (collection: 0.948s, learning 0.125s)
               Value function loss: 0.8461
                    Surrogate loss: 0.0067
             Mean action noise std: 0.4232
                     Learning rate: 0.0001
                       Mean reward: 8.32
               Mean episode length: 173.82
       Episode_Reward/keep_balance: 0.2106
     Episode_Reward/rew_lin_vel_xy: 0.4074
      Episode_Reward/rew_ang_vel_z: 0.6594
    Episode_Reward/pen_base_height: -0.1819
      Episode_Reward/pen_lin_vel_z: -0.0242
     Episode_Reward/pen_ang_vel_xy: -0.0342
   Episode_Reward/pen_joint_torque: -0.0308
    Episode_Reward/pen_joint_accel: -0.0173
    Episode_Reward/pen_action_rate: -0.0287
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0063
   Episode_Reward/pen_joint_powers: -0.0108
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0614
Episode_Reward/pen_flat_orientation: -0.1063
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0329
   Episode_Reward/foot_landing_vel: -0.0260
   Episode_Reward/test_gait_reward: -0.1935
Metrics/base_velocity/error_vel_xy: 0.7073
Metrics/base_velocity/error_vel_yaw: 0.1730
      Episode_Termination/time_out: 0.3333
  Episode_Termination/base_contact: 15.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 1.07s
                        Total time: 496.48s
                               ETA: 2756.6s

################################################################################
                     [1m Learning iteration 458/3000 [0m                      

                       Computation: 93086 steps/s (collection: 0.931s, learning 0.125s)
               Value function loss: 0.7810
                    Surrogate loss: 0.0088
             Mean action noise std: 0.4234
                     Learning rate: 0.0000
                       Mean reward: 10.54
               Mean episode length: 231.50
       Episode_Reward/keep_balance: 0.2033
     Episode_Reward/rew_lin_vel_xy: 0.3674
      Episode_Reward/rew_ang_vel_z: 0.6254
    Episode_Reward/pen_base_height: -0.1819
      Episode_Reward/pen_lin_vel_z: -0.0253
     Episode_Reward/pen_ang_vel_xy: -0.0354
   Episode_Reward/pen_joint_torque: -0.0308
    Episode_Reward/pen_joint_accel: -0.0178
    Episode_Reward/pen_action_rate: -0.0290
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0066
   Episode_Reward/pen_joint_powers: -0.0112
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0611
Episode_Reward/pen_flat_orientation: -0.1107
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0355
   Episode_Reward/foot_landing_vel: -0.0277
   Episode_Reward/test_gait_reward: -0.1866
Metrics/base_velocity/error_vel_xy: 0.7103
Metrics/base_velocity/error_vel_yaw: 0.1756
      Episode_Termination/time_out: 0.8750
  Episode_Termination/base_contact: 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 1.06s
                        Total time: 497.53s
                               ETA: 2755.4s

################################################################################
                     [1m Learning iteration 459/3000 [0m                      

                       Computation: 91679 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.6925
                    Surrogate loss: 0.0091
             Mean action noise std: 0.4234
                     Learning rate: 0.0000
                       Mean reward: 12.58
               Mean episode length: 231.69
       Episode_Reward/keep_balance: 0.2144
     Episode_Reward/rew_lin_vel_xy: 0.4119
      Episode_Reward/rew_ang_vel_z: 0.6670
    Episode_Reward/pen_base_height: -0.1855
      Episode_Reward/pen_lin_vel_z: -0.0254
     Episode_Reward/pen_ang_vel_xy: -0.0357
   Episode_Reward/pen_joint_torque: -0.0320
    Episode_Reward/pen_joint_accel: -0.0183
    Episode_Reward/pen_action_rate: -0.0302
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0067
   Episode_Reward/pen_joint_powers: -0.0114
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0637
Episode_Reward/pen_flat_orientation: -0.1111
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0349
   Episode_Reward/foot_landing_vel: -0.0279
   Episode_Reward/test_gait_reward: -0.1973
Metrics/base_velocity/error_vel_xy: 0.7321
Metrics/base_velocity/error_vel_yaw: 0.1796
      Episode_Termination/time_out: 0.7500
  Episode_Termination/base_contact: 21.5417
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 1.07s
                        Total time: 498.60s
                               ETA: 2754.2s

################################################################################
                     [1m Learning iteration 460/3000 [0m                      

                       Computation: 90745 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.7111
                    Surrogate loss: 0.0075
             Mean action noise std: 0.4235
                     Learning rate: 0.0000
                       Mean reward: 11.41
               Mean episode length: 216.20
       Episode_Reward/keep_balance: 0.2493
     Episode_Reward/rew_lin_vel_xy: 0.5034
      Episode_Reward/rew_ang_vel_z: 0.7773
    Episode_Reward/pen_base_height: -0.1974
      Episode_Reward/pen_lin_vel_z: -0.0287
     Episode_Reward/pen_ang_vel_xy: -0.0397
   Episode_Reward/pen_joint_torque: -0.0380
    Episode_Reward/pen_joint_accel: -0.0210
    Episode_Reward/pen_action_rate: -0.0354
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0078
   Episode_Reward/pen_joint_powers: -0.0135
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0738
Episode_Reward/pen_flat_orientation: -0.1230
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0401
   Episode_Reward/foot_landing_vel: -0.0319
   Episode_Reward/test_gait_reward: -0.2292
Metrics/base_velocity/error_vel_xy: 0.8155
Metrics/base_velocity/error_vel_yaw: 0.2069
      Episode_Termination/time_out: 0.8750
  Episode_Termination/base_contact: 20.7500
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 1.08s
                        Total time: 499.69s
                               ETA: 2753.2s

################################################################################
                     [1m Learning iteration 461/3000 [0m                      

                       Computation: 90852 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 0.7651
                    Surrogate loss: -0.0017
             Mean action noise std: 0.4234
                     Learning rate: 0.0001
                       Mean reward: 10.89
               Mean episode length: 221.93
       Episode_Reward/keep_balance: 0.2035
     Episode_Reward/rew_lin_vel_xy: 0.3740
      Episode_Reward/rew_ang_vel_z: 0.6347
    Episode_Reward/pen_base_height: -0.1787
      Episode_Reward/pen_lin_vel_z: -0.0231
     Episode_Reward/pen_ang_vel_xy: -0.0342
   Episode_Reward/pen_joint_torque: -0.0299
    Episode_Reward/pen_joint_accel: -0.0163
    Episode_Reward/pen_action_rate: -0.0279
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0061
   Episode_Reward/pen_joint_powers: -0.0105
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0598
Episode_Reward/pen_flat_orientation: -0.1053
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0317
   Episode_Reward/foot_landing_vel: -0.0252
   Episode_Reward/test_gait_reward: -0.1877
Metrics/base_velocity/error_vel_xy: 0.7122
Metrics/base_velocity/error_vel_yaw: 0.1692
      Episode_Termination/time_out: 0.4167
  Episode_Termination/base_contact: 16.6250
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 1.08s
                        Total time: 500.77s
                               ETA: 2752.1s

################################################################################
                     [1m Learning iteration 462/3000 [0m                      

                       Computation: 91288 steps/s (collection: 0.952s, learning 0.125s)
               Value function loss: 0.7500
                    Surrogate loss: -0.0025
             Mean action noise std: 0.4230
                     Learning rate: 0.0004
                       Mean reward: 6.53
               Mean episode length: 182.27
       Episode_Reward/keep_balance: 0.1998
     Episode_Reward/rew_lin_vel_xy: 0.3153
      Episode_Reward/rew_ang_vel_z: 0.6198
    Episode_Reward/pen_base_height: -0.1806
      Episode_Reward/pen_lin_vel_z: -0.0247
     Episode_Reward/pen_ang_vel_xy: -0.0356
   Episode_Reward/pen_joint_torque: -0.0312
    Episode_Reward/pen_joint_accel: -0.0183
    Episode_Reward/pen_action_rate: -0.0284
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0067
   Episode_Reward/pen_joint_powers: -0.0112
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0595
Episode_Reward/pen_flat_orientation: -0.1079
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0350
   Episode_Reward/foot_landing_vel: -0.0276
   Episode_Reward/test_gait_reward: -0.1860
Metrics/base_velocity/error_vel_xy: 0.7237
Metrics/base_velocity/error_vel_yaw: 0.1699
      Episode_Termination/time_out: 0.5417
  Episode_Termination/base_contact: 14.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 1.08s
                        Total time: 501.85s
                               ETA: 2750.9s

################################################################################
                     [1m Learning iteration 463/3000 [0m                      

                       Computation: 91179 steps/s (collection: 0.953s, learning 0.125s)
               Value function loss: 0.9178
                    Surrogate loss: -0.0003
             Mean action noise std: 0.4227
                     Learning rate: 0.0009
                       Mean reward: 12.35
               Mean episode length: 241.60
       Episode_Reward/keep_balance: 0.2278
     Episode_Reward/rew_lin_vel_xy: 0.4444
      Episode_Reward/rew_ang_vel_z: 0.7064
    Episode_Reward/pen_base_height: -0.1878
      Episode_Reward/pen_lin_vel_z: -0.0264
     Episode_Reward/pen_ang_vel_xy: -0.0367
   Episode_Reward/pen_joint_torque: -0.0340
    Episode_Reward/pen_joint_accel: -0.0185
    Episode_Reward/pen_action_rate: -0.0324
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0069
   Episode_Reward/pen_joint_powers: -0.0120
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0682
Episode_Reward/pen_flat_orientation: -0.1103
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0357
   Episode_Reward/foot_landing_vel: -0.0283
   Episode_Reward/test_gait_reward: -0.2087
Metrics/base_velocity/error_vel_xy: 0.7641
Metrics/base_velocity/error_vel_yaw: 0.1919
      Episode_Termination/time_out: 0.5000
  Episode_Termination/base_contact: 14.6250
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 1.08s
                        Total time: 502.92s
                               ETA: 2749.8s

################################################################################
                     [1m Learning iteration 464/3000 [0m                      

                       Computation: 91368 steps/s (collection: 0.951s, learning 0.125s)
               Value function loss: 0.9603
                    Surrogate loss: 0.0027
             Mean action noise std: 0.4231
                     Learning rate: 0.0006
                       Mean reward: 12.56
               Mean episode length: 229.59
       Episode_Reward/keep_balance: 0.2225
     Episode_Reward/rew_lin_vel_xy: 0.4175
      Episode_Reward/rew_ang_vel_z: 0.6917
    Episode_Reward/pen_base_height: -0.1889
      Episode_Reward/pen_lin_vel_z: -0.0269
     Episode_Reward/pen_ang_vel_xy: -0.0368
   Episode_Reward/pen_joint_torque: -0.0343
    Episode_Reward/pen_joint_accel: -0.0197
    Episode_Reward/pen_action_rate: -0.0322
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0071
   Episode_Reward/pen_joint_powers: -0.0121
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0675
Episode_Reward/pen_flat_orientation: -0.1095
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0369
   Episode_Reward/foot_landing_vel: -0.0295
   Episode_Reward/test_gait_reward: -0.2038
Metrics/base_velocity/error_vel_xy: 0.7710
Metrics/base_velocity/error_vel_yaw: 0.1866
      Episode_Termination/time_out: 0.7917
  Episode_Termination/base_contact: 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 1.08s
                        Total time: 504.00s
                               ETA: 2748.7s

################################################################################
                     [1m Learning iteration 465/3000 [0m                      

                       Computation: 90823 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.8109
                    Surrogate loss: 0.0058
             Mean action noise std: 0.4231
                     Learning rate: 0.0001
                       Mean reward: 11.80
               Mean episode length: 254.81
       Episode_Reward/keep_balance: 0.2340
     Episode_Reward/rew_lin_vel_xy: 0.3977
      Episode_Reward/rew_ang_vel_z: 0.7256
    Episode_Reward/pen_base_height: -0.1940
      Episode_Reward/pen_lin_vel_z: -0.0283
     Episode_Reward/pen_ang_vel_xy: -0.0381
   Episode_Reward/pen_joint_torque: -0.0364
    Episode_Reward/pen_joint_accel: -0.0205
    Episode_Reward/pen_action_rate: -0.0337
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0075
   Episode_Reward/pen_joint_powers: -0.0129
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0699
Episode_Reward/pen_flat_orientation: -0.1146
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0383
   Episode_Reward/foot_landing_vel: -0.0314
   Episode_Reward/test_gait_reward: -0.2159
Metrics/base_velocity/error_vel_xy: 0.8354
Metrics/base_velocity/error_vel_yaw: 0.1991
      Episode_Termination/time_out: 0.8333
  Episode_Termination/base_contact: 16.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 1.08s
                        Total time: 505.08s
                               ETA: 2747.6s

################################################################################
                     [1m Learning iteration 466/3000 [0m                      

                       Computation: 91505 steps/s (collection: 0.950s, learning 0.125s)
               Value function loss: 0.7767
                    Surrogate loss: -0.0011
             Mean action noise std: 0.4233
                     Learning rate: 0.0004
                       Mean reward: 13.04
               Mean episode length: 262.05
       Episode_Reward/keep_balance: 0.2266
     Episode_Reward/rew_lin_vel_xy: 0.4291
      Episode_Reward/rew_ang_vel_z: 0.7101
    Episode_Reward/pen_base_height: -0.1885
      Episode_Reward/pen_lin_vel_z: -0.0271
     Episode_Reward/pen_ang_vel_xy: -0.0371
   Episode_Reward/pen_joint_torque: -0.0354
    Episode_Reward/pen_joint_accel: -0.0183
    Episode_Reward/pen_action_rate: -0.0327
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0070
   Episode_Reward/pen_joint_powers: -0.0124
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0675
Episode_Reward/pen_flat_orientation: -0.1078
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0367
   Episode_Reward/foot_landing_vel: -0.0296
   Episode_Reward/test_gait_reward: -0.2073
Metrics/base_velocity/error_vel_xy: 0.7752
Metrics/base_velocity/error_vel_yaw: 0.1866
      Episode_Termination/time_out: 0.9167
  Episode_Termination/base_contact: 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 1.07s
                        Total time: 506.16s
                               ETA: 2746.5s

################################################################################
                     [1m Learning iteration 467/3000 [0m                      

                       Computation: 91495 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.7614
                    Surrogate loss: 0.0032
             Mean action noise std: 0.4234
                     Learning rate: 0.0003
                       Mean reward: 10.44
               Mean episode length: 233.80
       Episode_Reward/keep_balance: 0.2326
     Episode_Reward/rew_lin_vel_xy: 0.4459
      Episode_Reward/rew_ang_vel_z: 0.7197
    Episode_Reward/pen_base_height: -0.1919
      Episode_Reward/pen_lin_vel_z: -0.0285
     Episode_Reward/pen_ang_vel_xy: -0.0379
   Episode_Reward/pen_joint_torque: -0.0372
    Episode_Reward/pen_joint_accel: -0.0197
    Episode_Reward/pen_action_rate: -0.0339
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0074
   Episode_Reward/pen_joint_powers: -0.0129
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0698
Episode_Reward/pen_flat_orientation: -0.1139
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0391
   Episode_Reward/foot_landing_vel: -0.0308
   Episode_Reward/test_gait_reward: -0.2142
Metrics/base_velocity/error_vel_xy: 0.7939
Metrics/base_velocity/error_vel_yaw: 0.1993
      Episode_Termination/time_out: 0.7917
  Episode_Termination/base_contact: 13.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 1.07s
                        Total time: 507.23s
                               ETA: 2745.3s

################################################################################
                     [1m Learning iteration 468/3000 [0m                      

                       Computation: 90370 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.7650
                    Surrogate loss: -0.0013
             Mean action noise std: 0.4231
                     Learning rate: 0.0006
                       Mean reward: 11.74
               Mean episode length: 265.37
       Episode_Reward/keep_balance: 0.2516
     Episode_Reward/rew_lin_vel_xy: 0.4342
      Episode_Reward/rew_ang_vel_z: 0.7819
    Episode_Reward/pen_base_height: -0.2022
      Episode_Reward/pen_lin_vel_z: -0.0310
     Episode_Reward/pen_ang_vel_xy: -0.0405
   Episode_Reward/pen_joint_torque: -0.0407
    Episode_Reward/pen_joint_accel: -0.0240
    Episode_Reward/pen_action_rate: -0.0377
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0085
   Episode_Reward/pen_joint_powers: -0.0144
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0766
Episode_Reward/pen_flat_orientation: -0.1192
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0460
   Episode_Reward/foot_landing_vel: -0.0359
   Episode_Reward/test_gait_reward: -0.2310
Metrics/base_velocity/error_vel_xy: 0.8949
Metrics/base_velocity/error_vel_yaw: 0.2123
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 1.09s
                        Total time: 508.32s
                               ETA: 2744.3s

################################################################################
                     [1m Learning iteration 469/3000 [0m                      

                       Computation: 90728 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.7878
                    Surrogate loss: -0.0023
             Mean action noise std: 0.4229
                     Learning rate: 0.0013
                       Mean reward: 10.30
               Mean episode length: 229.39
       Episode_Reward/keep_balance: 0.2358
     Episode_Reward/rew_lin_vel_xy: 0.4022
      Episode_Reward/rew_ang_vel_z: 0.7343
    Episode_Reward/pen_base_height: -0.1913
      Episode_Reward/pen_lin_vel_z: -0.0285
     Episode_Reward/pen_ang_vel_xy: -0.0386
   Episode_Reward/pen_joint_torque: -0.0392
    Episode_Reward/pen_joint_accel: -0.0192
    Episode_Reward/pen_action_rate: -0.0343
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0076
   Episode_Reward/pen_joint_powers: -0.0135
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0704
Episode_Reward/pen_flat_orientation: -0.1094
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0397
   Episode_Reward/foot_landing_vel: -0.0315
   Episode_Reward/test_gait_reward: -0.2155
Metrics/base_velocity/error_vel_xy: 0.8347
Metrics/base_velocity/error_vel_yaw: 0.1970
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 1.08s
                        Total time: 509.40s
                               ETA: 2743.2s

################################################################################
                     [1m Learning iteration 470/3000 [0m                      

                       Computation: 89929 steps/s (collection: 0.967s, learning 0.126s)
               Value function loss: 0.8233
                    Surrogate loss: 0.0053
             Mean action noise std: 0.4237
                     Learning rate: 0.0009
                       Mean reward: 12.73
               Mean episode length: 248.50
       Episode_Reward/keep_balance: 0.2478
     Episode_Reward/rew_lin_vel_xy: 0.4448
      Episode_Reward/rew_ang_vel_z: 0.7720
    Episode_Reward/pen_base_height: -0.1968
      Episode_Reward/pen_lin_vel_z: -0.0290
     Episode_Reward/pen_ang_vel_xy: -0.0386
   Episode_Reward/pen_joint_torque: -0.0400
    Episode_Reward/pen_joint_accel: -0.0211
    Episode_Reward/pen_action_rate: -0.0362
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0078
   Episode_Reward/pen_joint_powers: -0.0137
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0744
Episode_Reward/pen_flat_orientation: -0.1080
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0407
   Episode_Reward/foot_landing_vel: -0.0322
   Episode_Reward/test_gait_reward: -0.2271
Metrics/base_velocity/error_vel_xy: 0.8644
Metrics/base_velocity/error_vel_yaw: 0.2069
      Episode_Termination/time_out: 0.7083
  Episode_Termination/base_contact: 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 1.09s
                        Total time: 510.50s
                               ETA: 2742.2s

################################################################################
                     [1m Learning iteration 471/3000 [0m                      

                       Computation: 90199 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.8096
                    Surrogate loss: 0.0053
             Mean action noise std: 0.4242
                     Learning rate: 0.0002
                       Mean reward: 11.92
               Mean episode length: 248.90
       Episode_Reward/keep_balance: 0.2647
     Episode_Reward/rew_lin_vel_xy: 0.4997
      Episode_Reward/rew_ang_vel_z: 0.8268
    Episode_Reward/pen_base_height: -0.2027
      Episode_Reward/pen_lin_vel_z: -0.0306
     Episode_Reward/pen_ang_vel_xy: -0.0399
   Episode_Reward/pen_joint_torque: -0.0440
    Episode_Reward/pen_joint_accel: -0.0222
    Episode_Reward/pen_action_rate: -0.0385
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0082
   Episode_Reward/pen_joint_powers: -0.0148
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0788
Episode_Reward/pen_flat_orientation: -0.1118
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0434
   Episode_Reward/foot_landing_vel: -0.0341
   Episode_Reward/test_gait_reward: -0.2406
Metrics/base_velocity/error_vel_xy: 0.9083
Metrics/base_velocity/error_vel_yaw: 0.2191
      Episode_Termination/time_out: 0.9167
  Episode_Termination/base_contact: 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 1.09s
                        Total time: 511.59s
                               ETA: 2741.1s

################################################################################
                     [1m Learning iteration 472/3000 [0m                      

                       Computation: 90280 steps/s (collection: 0.960s, learning 0.129s)
               Value function loss: 0.6951
                    Surrogate loss: 0.0104
             Mean action noise std: 0.4243
                     Learning rate: 0.0000
                       Mean reward: 14.75
               Mean episode length: 302.40
       Episode_Reward/keep_balance: 0.2957
     Episode_Reward/rew_lin_vel_xy: 0.5188
      Episode_Reward/rew_ang_vel_z: 0.9210
    Episode_Reward/pen_base_height: -0.2181
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.0450
   Episode_Reward/pen_joint_torque: -0.0516
    Episode_Reward/pen_joint_accel: -0.0268
    Episode_Reward/pen_action_rate: -0.0458
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0101
   Episode_Reward/pen_joint_powers: -0.0178
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0912
Episode_Reward/pen_flat_orientation: -0.1286
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0526
   Episode_Reward/foot_landing_vel: -0.0437
   Episode_Reward/test_gait_reward: -0.2717
Metrics/base_velocity/error_vel_xy: 1.0639
Metrics/base_velocity/error_vel_yaw: 0.2471
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 1.09s
                        Total time: 512.67s
                               ETA: 2740.0s

################################################################################
                     [1m Learning iteration 473/3000 [0m                      

                       Computation: 90941 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.6318
                    Surrogate loss: 0.0043
             Mean action noise std: 0.4244
                     Learning rate: 0.0000
                       Mean reward: 11.51
               Mean episode length: 244.24
       Episode_Reward/keep_balance: 0.2743
     Episode_Reward/rew_lin_vel_xy: 0.5203
      Episode_Reward/rew_ang_vel_z: 0.8501
    Episode_Reward/pen_base_height: -0.2136
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.0429
   Episode_Reward/pen_joint_torque: -0.0465
    Episode_Reward/pen_joint_accel: -0.0259
    Episode_Reward/pen_action_rate: -0.0419
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0096
   Episode_Reward/pen_joint_powers: -0.0162
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0846
Episode_Reward/pen_flat_orientation: -0.1254
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0541
   Episode_Reward/foot_landing_vel: -0.0402
   Episode_Reward/test_gait_reward: -0.2530
Metrics/base_velocity/error_vel_xy: 0.9097
Metrics/base_velocity/error_vel_yaw: 0.2325
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 1.08s
                        Total time: 513.76s
                               ETA: 2738.9s

################################################################################
                     [1m Learning iteration 474/3000 [0m                      

                       Computation: 91168 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.6682
                    Surrogate loss: 0.0018
             Mean action noise std: 0.4247
                     Learning rate: 0.0001
                       Mean reward: 12.12
               Mean episode length: 258.08
       Episode_Reward/keep_balance: 0.2519
     Episode_Reward/rew_lin_vel_xy: 0.4484
      Episode_Reward/rew_ang_vel_z: 0.7843
    Episode_Reward/pen_base_height: -0.2008
      Episode_Reward/pen_lin_vel_z: -0.0304
     Episode_Reward/pen_ang_vel_xy: -0.0393
   Episode_Reward/pen_joint_torque: -0.0399
    Episode_Reward/pen_joint_accel: -0.0209
    Episode_Reward/pen_action_rate: -0.0369
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0079
   Episode_Reward/pen_joint_powers: -0.0138
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0756
Episode_Reward/pen_flat_orientation: -0.1106
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0438
   Episode_Reward/foot_landing_vel: -0.0325
   Episode_Reward/test_gait_reward: -0.2310
Metrics/base_velocity/error_vel_xy: 0.8677
Metrics/base_velocity/error_vel_yaw: 0.2107
      Episode_Termination/time_out: 0.6250
  Episode_Termination/base_contact: 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 1.08s
                        Total time: 514.83s
                               ETA: 2737.8s

################################################################################
                     [1m Learning iteration 475/3000 [0m                      

                       Computation: 91643 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.7326
                    Surrogate loss: -0.0003
             Mean action noise std: 0.4254
                     Learning rate: 0.0003
                       Mean reward: 14.23
               Mean episode length: 259.16
       Episode_Reward/keep_balance: 0.2657
     Episode_Reward/rew_lin_vel_xy: 0.5068
      Episode_Reward/rew_ang_vel_z: 0.8280
    Episode_Reward/pen_base_height: -0.2070
      Episode_Reward/pen_lin_vel_z: -0.0319
     Episode_Reward/pen_ang_vel_xy: -0.0408
   Episode_Reward/pen_joint_torque: -0.0444
    Episode_Reward/pen_joint_accel: -0.0232
    Episode_Reward/pen_action_rate: -0.0399
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0087
   Episode_Reward/pen_joint_powers: -0.0153
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0809
Episode_Reward/pen_flat_orientation: -0.1157
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0458
   Episode_Reward/foot_landing_vel: -0.0357
   Episode_Reward/test_gait_reward: -0.2432
Metrics/base_velocity/error_vel_xy: 0.9085
Metrics/base_velocity/error_vel_yaw: 0.2223
      Episode_Termination/time_out: 1.0000
  Episode_Termination/base_contact: 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 1.07s
                        Total time: 515.91s
                               ETA: 2736.7s

################################################################################
                     [1m Learning iteration 476/3000 [0m                      

                       Computation: 89506 steps/s (collection: 0.972s, learning 0.126s)
               Value function loss: 0.7318
                    Surrogate loss: -0.0018
             Mean action noise std: 0.4262
                     Learning rate: 0.0006
                       Mean reward: 11.23
               Mean episode length: 240.48
       Episode_Reward/keep_balance: 0.2406
     Episode_Reward/rew_lin_vel_xy: 0.4304
      Episode_Reward/rew_ang_vel_z: 0.7439
    Episode_Reward/pen_base_height: -0.1973
      Episode_Reward/pen_lin_vel_z: -0.0291
     Episode_Reward/pen_ang_vel_xy: -0.0378
   Episode_Reward/pen_joint_torque: -0.0379
    Episode_Reward/pen_joint_accel: -0.0188
    Episode_Reward/pen_action_rate: -0.0355
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0076
   Episode_Reward/pen_joint_powers: -0.0132
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0735
Episode_Reward/pen_flat_orientation: -0.1068
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0425
   Episode_Reward/foot_landing_vel: -0.0327
   Episode_Reward/test_gait_reward: -0.2212
Metrics/base_velocity/error_vel_xy: 0.8473
Metrics/base_velocity/error_vel_yaw: 0.2044
      Episode_Termination/time_out: 0.5417
  Episode_Termination/base_contact: 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 1.10s
                        Total time: 517.00s
                               ETA: 2735.7s

################################################################################
                     [1m Learning iteration 477/3000 [0m                      

                       Computation: 89925 steps/s (collection: 0.963s, learning 0.130s)
               Value function loss: 0.8771
                    Surrogate loss: -0.0020
             Mean action noise std: 0.4268
                     Learning rate: 0.0013
                       Mean reward: 11.16
               Mean episode length: 257.15
       Episode_Reward/keep_balance: 0.2351
     Episode_Reward/rew_lin_vel_xy: 0.4325
      Episode_Reward/rew_ang_vel_z: 0.7260
    Episode_Reward/pen_base_height: -0.1990
      Episode_Reward/pen_lin_vel_z: -0.0313
     Episode_Reward/pen_ang_vel_xy: -0.0383
   Episode_Reward/pen_joint_torque: -0.0404
    Episode_Reward/pen_joint_accel: -0.0216
    Episode_Reward/pen_action_rate: -0.0357
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0080
   Episode_Reward/pen_joint_powers: -0.0140
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0725
Episode_Reward/pen_flat_orientation: -0.1056
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0450
   Episode_Reward/foot_landing_vel: -0.0337
   Episode_Reward/test_gait_reward: -0.2173
Metrics/base_velocity/error_vel_xy: 0.8197
Metrics/base_velocity/error_vel_yaw: 0.2011
      Episode_Termination/time_out: 0.7083
  Episode_Termination/base_contact: 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 1.09s
                        Total time: 518.10s
                               ETA: 2734.6s

################################################################################
                     [1m Learning iteration 478/3000 [0m                      

                       Computation: 89445 steps/s (collection: 0.971s, learning 0.128s)
               Value function loss: 0.9264
                    Surrogate loss: 0.0263
             Mean action noise std: 0.4271
                     Learning rate: 0.0001
                       Mean reward: 16.43
               Mean episode length: 297.06
       Episode_Reward/keep_balance: 0.2651
     Episode_Reward/rew_lin_vel_xy: 0.5076
      Episode_Reward/rew_ang_vel_z: 0.8191
    Episode_Reward/pen_base_height: -0.2068
      Episode_Reward/pen_lin_vel_z: -0.0318
     Episode_Reward/pen_ang_vel_xy: -0.0408
   Episode_Reward/pen_joint_torque: -0.0425
    Episode_Reward/pen_joint_accel: -0.0236
    Episode_Reward/pen_action_rate: -0.0397
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0085
   Episode_Reward/pen_joint_powers: -0.0147
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0825
Episode_Reward/pen_flat_orientation: -0.1114
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0460
   Episode_Reward/foot_landing_vel: -0.0343
   Episode_Reward/test_gait_reward: -0.2423
Metrics/base_velocity/error_vel_xy: 0.8906
Metrics/base_velocity/error_vel_yaw: 0.2272
      Episode_Termination/time_out: 0.7083
  Episode_Termination/base_contact: 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 1.10s
                        Total time: 519.20s
                               ETA: 2733.6s

################################################################################
                     [1m Learning iteration 479/3000 [0m                      

                       Computation: 89693 steps/s (collection: 0.969s, learning 0.127s)
               Value function loss: 0.7554
                    Surrogate loss: 0.0001
             Mean action noise std: 0.4271
                     Learning rate: 0.0003
                       Mean reward: 17.90
               Mean episode length: 351.38
       Episode_Reward/keep_balance: 0.3037
     Episode_Reward/rew_lin_vel_xy: 0.5640
      Episode_Reward/rew_ang_vel_z: 0.9442
    Episode_Reward/pen_base_height: -0.2271
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.0458
   Episode_Reward/pen_joint_torque: -0.0528
    Episode_Reward/pen_joint_accel: -0.0260
    Episode_Reward/pen_action_rate: -0.0471
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0101
   Episode_Reward/pen_joint_powers: -0.0179
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0949
Episode_Reward/pen_flat_orientation: -0.1218
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0571
   Episode_Reward/foot_landing_vel: -0.0431
   Episode_Reward/test_gait_reward: -0.2787
Metrics/base_velocity/error_vel_xy: 1.0373
Metrics/base_velocity/error_vel_yaw: 0.2554
      Episode_Termination/time_out: 0.9583
  Episode_Termination/base_contact: 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 1.10s
                        Total time: 520.29s
                               ETA: 2732.6s

################################################################################
                     [1m Learning iteration 480/3000 [0m                      

                       Computation: 89423 steps/s (collection: 0.970s, learning 0.129s)
               Value function loss: 0.7872
                    Surrogate loss: -0.0012
             Mean action noise std: 0.4269
                     Learning rate: 0.0006
                       Mean reward: 9.67
               Mean episode length: 216.22
       Episode_Reward/keep_balance: 0.2638
     Episode_Reward/rew_lin_vel_xy: 0.5190
      Episode_Reward/rew_ang_vel_z: 0.8207
    Episode_Reward/pen_base_height: -0.2066
      Episode_Reward/pen_lin_vel_z: -0.0326
     Episode_Reward/pen_ang_vel_xy: -0.0415
   Episode_Reward/pen_joint_torque: -0.0435
    Episode_Reward/pen_joint_accel: -0.0228
    Episode_Reward/pen_action_rate: -0.0398
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0084
   Episode_Reward/pen_joint_powers: -0.0149
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0813
Episode_Reward/pen_flat_orientation: -0.1069
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0467
   Episode_Reward/foot_landing_vel: -0.0361
   Episode_Reward/test_gait_reward: -0.2408
Metrics/base_velocity/error_vel_xy: 0.8996
Metrics/base_velocity/error_vel_yaw: 0.2229
      Episode_Termination/time_out: 0.5833
  Episode_Termination/base_contact: 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 1.10s
                        Total time: 521.39s
                               ETA: 2731.6s

################################################################################
                     [1m Learning iteration 481/3000 [0m                      

                       Computation: 89752 steps/s (collection: 0.969s, learning 0.126s)
               Value function loss: 0.8927
                    Surrogate loss: -0.0017
             Mean action noise std: 0.4266
                     Learning rate: 0.0013
                       Mean reward: 14.66
               Mean episode length: 297.21
       Episode_Reward/keep_balance: 0.2964
     Episode_Reward/rew_lin_vel_xy: 0.5635
      Episode_Reward/rew_ang_vel_z: 0.9149
    Episode_Reward/pen_base_height: -0.2234
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.0441
   Episode_Reward/pen_joint_torque: -0.0514
    Episode_Reward/pen_joint_accel: -0.0261
    Episode_Reward/pen_action_rate: -0.0463
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0100
   Episode_Reward/pen_joint_powers: -0.0175
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0933
Episode_Reward/pen_flat_orientation: -0.1176
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0582
   Episode_Reward/foot_landing_vel: -0.0426
   Episode_Reward/test_gait_reward: -0.2696
Metrics/base_velocity/error_vel_xy: 1.0120
Metrics/base_velocity/error_vel_yaw: 0.2536
      Episode_Termination/time_out: 0.8750
  Episode_Termination/base_contact: 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 1.10s
                        Total time: 522.49s
                               ETA: 2730.6s

################################################################################
                     [1m Learning iteration 482/3000 [0m                      

                       Computation: 89503 steps/s (collection: 0.973s, learning 0.125s)
               Value function loss: 1.1553
                    Surrogate loss: 0.0030
             Mean action noise std: 0.4264
                     Learning rate: 0.0006
                       Mean reward: 12.47
               Mean episode length: 264.89
       Episode_Reward/keep_balance: 0.2699
     Episode_Reward/rew_lin_vel_xy: 0.4869
      Episode_Reward/rew_ang_vel_z: 0.8406
    Episode_Reward/pen_base_height: -0.2086
      Episode_Reward/pen_lin_vel_z: -0.0335
     Episode_Reward/pen_ang_vel_xy: -0.0419
   Episode_Reward/pen_joint_torque: -0.0464
    Episode_Reward/pen_joint_accel: -0.0238
    Episode_Reward/pen_action_rate: -0.0413
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0087
   Episode_Reward/pen_joint_powers: -0.0156
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0840
Episode_Reward/pen_flat_orientation: -0.1083
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0486
   Episode_Reward/foot_landing_vel: -0.0376
   Episode_Reward/test_gait_reward: -0.2471
Metrics/base_velocity/error_vel_xy: 0.9387
Metrics/base_velocity/error_vel_yaw: 0.2262
      Episode_Termination/time_out: 0.8333
  Episode_Termination/base_contact: 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 1.10s
                        Total time: 523.59s
                               ETA: 2729.6s

################################################################################
                     [1m Learning iteration 483/3000 [0m                      

                       Computation: 90512 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.7764
                    Surrogate loss: 0.0019
             Mean action noise std: 0.4266
                     Learning rate: 0.0004
                       Mean reward: 12.39
               Mean episode length: 260.02
       Episode_Reward/keep_balance: 0.3133
     Episode_Reward/rew_lin_vel_xy: 0.5795
      Episode_Reward/rew_ang_vel_z: 0.9810
    Episode_Reward/pen_base_height: -0.2248
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.0448
   Episode_Reward/pen_joint_torque: -0.0547
    Episode_Reward/pen_joint_accel: -0.0256
    Episode_Reward/pen_action_rate: -0.0482
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0100
   Episode_Reward/pen_joint_powers: -0.0182
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0970
Episode_Reward/pen_flat_orientation: -0.1163
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0560
   Episode_Reward/foot_landing_vel: -0.0428
   Episode_Reward/test_gait_reward: -0.2834
Metrics/base_velocity/error_vel_xy: 1.0759
Metrics/base_velocity/error_vel_yaw: 0.2583
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 1.09s
                        Total time: 524.67s
                               ETA: 2728.5s

################################################################################
                     [1m Learning iteration 484/3000 [0m                      

                       Computation: 90238 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.6871
                    Surrogate loss: 0.0061
             Mean action noise std: 0.4269
                     Learning rate: 0.0001
                       Mean reward: 11.56
               Mean episode length: 264.26
       Episode_Reward/keep_balance: 0.2641
     Episode_Reward/rew_lin_vel_xy: 0.4676
      Episode_Reward/rew_ang_vel_z: 0.8279
    Episode_Reward/pen_base_height: -0.2038
      Episode_Reward/pen_lin_vel_z: -0.0317
     Episode_Reward/pen_ang_vel_xy: -0.0400
   Episode_Reward/pen_joint_torque: -0.0435
    Episode_Reward/pen_joint_accel: -0.0224
    Episode_Reward/pen_action_rate: -0.0396
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0081
   Episode_Reward/pen_joint_powers: -0.0146
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0813
Episode_Reward/pen_flat_orientation: -0.1019
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0449
   Episode_Reward/foot_landing_vel: -0.0353
   Episode_Reward/test_gait_reward: -0.2405
Metrics/base_velocity/error_vel_xy: 0.9441
Metrics/base_velocity/error_vel_yaw: 0.2184
      Episode_Termination/time_out: 0.8750
  Episode_Termination/base_contact: 11.5833
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 1.09s
                        Total time: 525.76s
                               ETA: 2727.5s

################################################################################
                     [1m Learning iteration 485/3000 [0m                      

                       Computation: 90741 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.7824
                    Surrogate loss: 0.0044
             Mean action noise std: 0.4270
                     Learning rate: 0.0000
                       Mean reward: 16.73
               Mean episode length: 314.28
       Episode_Reward/keep_balance: 0.2944
     Episode_Reward/rew_lin_vel_xy: 0.5835
      Episode_Reward/rew_ang_vel_z: 0.9225
    Episode_Reward/pen_base_height: -0.2152
      Episode_Reward/pen_lin_vel_z: -0.0340
     Episode_Reward/pen_ang_vel_xy: -0.0429
   Episode_Reward/pen_joint_torque: -0.0482
    Episode_Reward/pen_joint_accel: -0.0244
    Episode_Reward/pen_action_rate: -0.0441
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0090
   Episode_Reward/pen_joint_powers: -0.0163
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0911
Episode_Reward/pen_flat_orientation: -0.1083
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0487
   Episode_Reward/foot_landing_vel: -0.0376
   Episode_Reward/test_gait_reward: -0.2668
Metrics/base_velocity/error_vel_xy: 0.9848
Metrics/base_velocity/error_vel_yaw: 0.2433
      Episode_Termination/time_out: 0.7500
  Episode_Termination/base_contact: 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 1.08s
                        Total time: 526.84s
                               ETA: 2726.4s

################################################################################
                     [1m Learning iteration 486/3000 [0m                      

                       Computation: 91160 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.7240
                    Surrogate loss: 0.0076
             Mean action noise std: 0.4272
                     Learning rate: 0.0000
                       Mean reward: 19.05
               Mean episode length: 342.57
       Episode_Reward/keep_balance: 0.3325
     Episode_Reward/rew_lin_vel_xy: 0.6588
      Episode_Reward/rew_ang_vel_z: 1.0438
    Episode_Reward/pen_base_height: -0.2338
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.0460
   Episode_Reward/pen_joint_torque: -0.0575
    Episode_Reward/pen_joint_accel: -0.0285
    Episode_Reward/pen_action_rate: -0.0520
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0106
   Episode_Reward/pen_joint_powers: -0.0190
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1045
Episode_Reward/pen_flat_orientation: -0.1156
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0602
   Episode_Reward/foot_landing_vel: -0.0467
   Episode_Reward/test_gait_reward: -0.3017
Metrics/base_velocity/error_vel_xy: 1.0938
Metrics/base_velocity/error_vel_yaw: 0.2708
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 1.08s
                        Total time: 527.92s
                               ETA: 2725.3s

################################################################################
                     [1m Learning iteration 487/3000 [0m                      

                       Computation: 90881 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.7566
                    Surrogate loss: 0.0003
             Mean action noise std: 0.4275
                     Learning rate: 0.0001
                       Mean reward: 15.14
               Mean episode length: 289.96
       Episode_Reward/keep_balance: 0.2757
     Episode_Reward/rew_lin_vel_xy: 0.5245
      Episode_Reward/rew_ang_vel_z: 0.8606
    Episode_Reward/pen_base_height: -0.2083
      Episode_Reward/pen_lin_vel_z: -0.0331
     Episode_Reward/pen_ang_vel_xy: -0.0411
   Episode_Reward/pen_joint_torque: -0.0448
    Episode_Reward/pen_joint_accel: -0.0245
    Episode_Reward/pen_action_rate: -0.0419
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0086
   Episode_Reward/pen_joint_powers: -0.0153
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0862
Episode_Reward/pen_flat_orientation: -0.1047
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0463
   Episode_Reward/foot_landing_vel: -0.0369
   Episode_Reward/test_gait_reward: -0.2516
Metrics/base_velocity/error_vel_xy: 0.9453
Metrics/base_velocity/error_vel_yaw: 0.2297
      Episode_Termination/time_out: 0.9167
  Episode_Termination/base_contact: 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 1.08s
                        Total time: 529.00s
                               ETA: 2724.2s

################################################################################
                     [1m Learning iteration 488/3000 [0m                      

                       Computation: 89966 steps/s (collection: 0.967s, learning 0.125s)
               Value function loss: 0.7592
                    Surrogate loss: -0.0018
             Mean action noise std: 0.4274
                     Learning rate: 0.0003
                       Mean reward: 14.14
               Mean episode length: 298.61
       Episode_Reward/keep_balance: 0.2895
     Episode_Reward/rew_lin_vel_xy: 0.5155
      Episode_Reward/rew_ang_vel_z: 0.9028
    Episode_Reward/pen_base_height: -0.2157
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.0437
   Episode_Reward/pen_joint_torque: -0.0495
    Episode_Reward/pen_joint_accel: -0.0242
    Episode_Reward/pen_action_rate: -0.0444
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0092
   Episode_Reward/pen_joint_powers: -0.0166
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0901
Episode_Reward/pen_flat_orientation: -0.1081
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0508
   Episode_Reward/foot_landing_vel: -0.0387
   Episode_Reward/test_gait_reward: -0.2676
Metrics/base_velocity/error_vel_xy: 1.0196
Metrics/base_velocity/error_vel_yaw: 0.2424
      Episode_Termination/time_out: 1.0000
  Episode_Termination/base_contact: 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 1.09s
                        Total time: 530.10s
                               ETA: 2723.1s

################################################################################
                     [1m Learning iteration 489/3000 [0m                      

                       Computation: 89705 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 0.9743
                    Surrogate loss: -0.0007
             Mean action noise std: 0.4281
                     Learning rate: 0.0009
                       Mean reward: 15.39
               Mean episode length: 291.58
       Episode_Reward/keep_balance: 0.3099
     Episode_Reward/rew_lin_vel_xy: 0.5757
      Episode_Reward/rew_ang_vel_z: 0.9629
    Episode_Reward/pen_base_height: -0.2240
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.0438
   Episode_Reward/pen_joint_torque: -0.0534
    Episode_Reward/pen_joint_accel: -0.0265
    Episode_Reward/pen_action_rate: -0.0485
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0100
   Episode_Reward/pen_joint_powers: -0.0179
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0983
Episode_Reward/pen_flat_orientation: -0.1110
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0548
   Episode_Reward/foot_landing_vel: -0.0436
   Episode_Reward/test_gait_reward: -0.2816
Metrics/base_velocity/error_vel_xy: 1.0465
Metrics/base_velocity/error_vel_yaw: 0.2591
      Episode_Termination/time_out: 1.0000
  Episode_Termination/base_contact: 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 1.10s
                        Total time: 531.19s
                               ETA: 2722.1s

################################################################################
                     [1m Learning iteration 490/3000 [0m                      

                       Computation: 90829 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.9936
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4289
                     Learning rate: 0.0013
                       Mean reward: 20.59
               Mean episode length: 338.20
       Episode_Reward/keep_balance: 0.3140
     Episode_Reward/rew_lin_vel_xy: 0.6293
      Episode_Reward/rew_ang_vel_z: 0.9731
    Episode_Reward/pen_base_height: -0.2292
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.0467
   Episode_Reward/pen_joint_torque: -0.0547
    Episode_Reward/pen_joint_accel: -0.0268
    Episode_Reward/pen_action_rate: -0.0496
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0103
   Episode_Reward/pen_joint_powers: -0.0185
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0999
Episode_Reward/pen_flat_orientation: -0.1100
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0577
   Episode_Reward/foot_landing_vel: -0.0445
   Episode_Reward/test_gait_reward: -0.2848
Metrics/base_velocity/error_vel_xy: 1.0053
Metrics/base_velocity/error_vel_yaw: 0.2663
      Episode_Termination/time_out: 0.9583
  Episode_Termination/base_contact: 11.8750
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 1.08s
                        Total time: 532.28s
                               ETA: 2721.0s

################################################################################
                     [1m Learning iteration 491/3000 [0m                      

                       Computation: 90981 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.9601
                    Surrogate loss: 0.0042
             Mean action noise std: 0.4289
                     Learning rate: 0.0003
                       Mean reward: 15.21
               Mean episode length: 281.67
       Episode_Reward/keep_balance: 0.2921
     Episode_Reward/rew_lin_vel_xy: 0.5552
      Episode_Reward/rew_ang_vel_z: 0.9161
    Episode_Reward/pen_base_height: -0.2188
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.0417
   Episode_Reward/pen_joint_torque: -0.0501
    Episode_Reward/pen_joint_accel: -0.0237
    Episode_Reward/pen_action_rate: -0.0448
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0089
   Episode_Reward/pen_joint_powers: -0.0164
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0916
Episode_Reward/pen_flat_orientation: -0.1035
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0496
   Episode_Reward/foot_landing_vel: -0.0382
   Episode_Reward/test_gait_reward: -0.2677
Metrics/base_velocity/error_vel_xy: 0.9759
Metrics/base_velocity/error_vel_yaw: 0.2407
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 1.08s
                        Total time: 533.36s
                               ETA: 2719.9s

################################################################################
                     [1m Learning iteration 492/3000 [0m                      

                       Computation: 90894 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.8460
                    Surrogate loss: -0.0022
             Mean action noise std: 0.4289
                     Learning rate: 0.0009
                       Mean reward: 16.49
               Mean episode length: 307.54
       Episode_Reward/keep_balance: 0.3208
     Episode_Reward/rew_lin_vel_xy: 0.6310
      Episode_Reward/rew_ang_vel_z: 1.0003
    Episode_Reward/pen_base_height: -0.2229
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.0447
   Episode_Reward/pen_joint_torque: -0.0519
    Episode_Reward/pen_joint_accel: -0.0261
    Episode_Reward/pen_action_rate: -0.0491
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0097
   Episode_Reward/pen_joint_powers: -0.0175
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.1019
Episode_Reward/pen_flat_orientation: -0.1090
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0520
   Episode_Reward/foot_landing_vel: -0.0415
   Episode_Reward/test_gait_reward: -0.2937
Metrics/base_velocity/error_vel_xy: 1.0656
Metrics/base_velocity/error_vel_yaw: 0.2679
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 1.08s
                        Total time: 534.44s
                               ETA: 2718.8s

################################################################################
                     [1m Learning iteration 493/3000 [0m                      

                       Computation: 88241 steps/s (collection: 0.991s, learning 0.123s)
               Value function loss: 1.0141
                    Surrogate loss: -0.0026
             Mean action noise std: 0.4290
                     Learning rate: 0.0019
                       Mean reward: 21.59
               Mean episode length: 362.45
       Episode_Reward/keep_balance: 0.3373
     Episode_Reward/rew_lin_vel_xy: 0.6644
      Episode_Reward/rew_ang_vel_z: 1.0550
    Episode_Reward/pen_base_height: -0.2289
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.0470
   Episode_Reward/pen_joint_torque: -0.0593
    Episode_Reward/pen_joint_accel: -0.0303
    Episode_Reward/pen_action_rate: -0.0537
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0108
   Episode_Reward/pen_joint_powers: -0.0196
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1076
Episode_Reward/pen_flat_orientation: -0.1112
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0599
   Episode_Reward/foot_landing_vel: -0.0476
   Episode_Reward/test_gait_reward: -0.3070
Metrics/base_velocity/error_vel_xy: 1.1057
Metrics/base_velocity/error_vel_yaw: 0.2782
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 1.11s
                        Total time: 535.55s
                               ETA: 2717.9s

################################################################################
                     [1m Learning iteration 494/3000 [0m                      

                       Computation: 91530 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 0.9743
                    Surrogate loss: 0.0025
             Mean action noise std: 0.4292
                     Learning rate: 0.0009
                       Mean reward: 13.87
               Mean episode length: 269.89
       Episode_Reward/keep_balance: 0.3179
     Episode_Reward/rew_lin_vel_xy: 0.6690
      Episode_Reward/rew_ang_vel_z: 0.9893
    Episode_Reward/pen_base_height: -0.2237
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.0460
   Episode_Reward/pen_joint_torque: -0.0547
    Episode_Reward/pen_joint_accel: -0.0273
    Episode_Reward/pen_action_rate: -0.0507
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0102
   Episode_Reward/pen_joint_powers: -0.0184
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1020
Episode_Reward/pen_flat_orientation: -0.1114
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0565
   Episode_Reward/foot_landing_vel: -0.0449
   Episode_Reward/test_gait_reward: -0.2904
Metrics/base_velocity/error_vel_xy: 1.0159
Metrics/base_velocity/error_vel_yaw: 0.2671
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 1.07s
                        Total time: 536.63s
                               ETA: 2716.7s

################################################################################
                     [1m Learning iteration 495/3000 [0m                      

                       Computation: 91189 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.8254
                    Surrogate loss: 0.0073
             Mean action noise std: 0.4294
                     Learning rate: 0.0001
                       Mean reward: 19.36
               Mean episode length: 368.42
       Episode_Reward/keep_balance: 0.3504
     Episode_Reward/rew_lin_vel_xy: 0.6438
      Episode_Reward/rew_ang_vel_z: 1.0969
    Episode_Reward/pen_base_height: -0.2387
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.0479
   Episode_Reward/pen_joint_torque: -0.0600
    Episode_Reward/pen_joint_accel: -0.0289
    Episode_Reward/pen_action_rate: -0.0557
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0109
   Episode_Reward/pen_joint_powers: -0.0199
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1126
Episode_Reward/pen_flat_orientation: -0.1136
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0605
   Episode_Reward/foot_landing_vel: -0.0468
   Episode_Reward/test_gait_reward: -0.3217
Metrics/base_velocity/error_vel_xy: 1.1814
Metrics/base_velocity/error_vel_yaw: 0.2889
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 1.08s
                        Total time: 537.70s
                               ETA: 2715.6s

################################################################################
                     [1m Learning iteration 496/3000 [0m                      

                       Computation: 90756 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.7688
                    Surrogate loss: 0.0015
             Mean action noise std: 0.4294
                     Learning rate: 0.0003
                       Mean reward: 16.26
               Mean episode length: 314.77
       Episode_Reward/keep_balance: 0.3649
     Episode_Reward/rew_lin_vel_xy: 0.7126
      Episode_Reward/rew_ang_vel_z: 1.1468
    Episode_Reward/pen_base_height: -0.2431
      Episode_Reward/pen_lin_vel_z: -0.0433
     Episode_Reward/pen_ang_vel_xy: -0.0485
   Episode_Reward/pen_joint_torque: -0.0643
    Episode_Reward/pen_joint_accel: -0.0294
    Episode_Reward/pen_action_rate: -0.0575
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0114
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1155
Episode_Reward/pen_flat_orientation: -0.1148
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0639
   Episode_Reward/foot_landing_vel: -0.0488
   Episode_Reward/test_gait_reward: -0.3324
Metrics/base_velocity/error_vel_xy: 1.1916
Metrics/base_velocity/error_vel_yaw: 0.2972
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 1.08s
                        Total time: 538.79s
                               ETA: 2714.5s

################################################################################
                     [1m Learning iteration 497/3000 [0m                      

                       Computation: 89913 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.6900
                    Surrogate loss: -0.0012
             Mean action noise std: 0.4301
                     Learning rate: 0.0006
                       Mean reward: 16.69
               Mean episode length: 304.47
       Episode_Reward/keep_balance: 0.3344
     Episode_Reward/rew_lin_vel_xy: 0.6271
      Episode_Reward/rew_ang_vel_z: 1.0530
    Episode_Reward/pen_base_height: -0.2274
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.0452
   Episode_Reward/pen_joint_torque: -0.0570
    Episode_Reward/pen_joint_accel: -0.0276
    Episode_Reward/pen_action_rate: -0.0527
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0101
   Episode_Reward/pen_joint_powers: -0.0188
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1074
Episode_Reward/pen_flat_orientation: -0.1067
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0562
   Episode_Reward/foot_landing_vel: -0.0437
   Episode_Reward/test_gait_reward: -0.3060
Metrics/base_velocity/error_vel_xy: 1.1334
Metrics/base_velocity/error_vel_yaw: 0.2711
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 1.09s
                        Total time: 539.88s
                               ETA: 2713.5s

################################################################################
                     [1m Learning iteration 498/3000 [0m                      

                       Computation: 89263 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.8078
                    Surrogate loss: -0.0011
             Mean action noise std: 0.4311
                     Learning rate: 0.0013
                       Mean reward: 19.10
               Mean episode length: 334.01
       Episode_Reward/keep_balance: 0.3427
     Episode_Reward/rew_lin_vel_xy: 0.7127
      Episode_Reward/rew_ang_vel_z: 1.0777
    Episode_Reward/pen_base_height: -0.2299
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.0465
   Episode_Reward/pen_joint_torque: -0.0590
    Episode_Reward/pen_joint_accel: -0.0282
    Episode_Reward/pen_action_rate: -0.0540
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0104
   Episode_Reward/pen_joint_powers: -0.0193
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1101
Episode_Reward/pen_flat_orientation: -0.1105
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0575
   Episode_Reward/foot_landing_vel: -0.0454
   Episode_Reward/test_gait_reward: -0.3129
Metrics/base_velocity/error_vel_xy: 1.1133
Metrics/base_velocity/error_vel_yaw: 0.2792
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 1.10s
                        Total time: 540.98s
                               ETA: 2712.5s

################################################################################
                     [1m Learning iteration 499/3000 [0m                      

                       Computation: 90332 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.9019
                    Surrogate loss: 0.0015
             Mean action noise std: 0.4313
                     Learning rate: 0.0009
                       Mean reward: 14.37
               Mean episode length: 271.42
       Episode_Reward/keep_balance: 0.3032
     Episode_Reward/rew_lin_vel_xy: 0.5887
      Episode_Reward/rew_ang_vel_z: 0.9521
    Episode_Reward/pen_base_height: -0.2142
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.0444
   Episode_Reward/pen_joint_torque: -0.0513
    Episode_Reward/pen_joint_accel: -0.0259
    Episode_Reward/pen_action_rate: -0.0479
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0095
   Episode_Reward/pen_joint_powers: -0.0173
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0973
Episode_Reward/pen_flat_orientation: -0.1044
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0528
   Episode_Reward/foot_landing_vel: -0.0426
   Episode_Reward/test_gait_reward: -0.2768
Metrics/base_velocity/error_vel_xy: 1.0133
Metrics/base_velocity/error_vel_yaw: 0.2475
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 1.09s
                        Total time: 542.07s
                               ETA: 2711.4s

################################################################################
                     [1m Learning iteration 500/3000 [0m                      

                       Computation: 90215 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.8008
                    Surrogate loss: 0.0014
             Mean action noise std: 0.4313
                     Learning rate: 0.0006
                       Mean reward: 17.29
               Mean episode length: 316.09
       Episode_Reward/keep_balance: 0.3102
     Episode_Reward/rew_lin_vel_xy: 0.5988
      Episode_Reward/rew_ang_vel_z: 0.9738
    Episode_Reward/pen_base_height: -0.2149
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.0439
   Episode_Reward/pen_joint_torque: -0.0520
    Episode_Reward/pen_joint_accel: -0.0267
    Episode_Reward/pen_action_rate: -0.0490
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0095
   Episode_Reward/pen_joint_powers: -0.0173
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1007
Episode_Reward/pen_flat_orientation: -0.1049
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0535
   Episode_Reward/foot_landing_vel: -0.0409
   Episode_Reward/test_gait_reward: -0.2827
Metrics/base_velocity/error_vel_xy: 1.0370
Metrics/base_velocity/error_vel_yaw: 0.2546
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 1.09s
                        Total time: 543.16s
                               ETA: 2710.4s

################################################################################
                     [1m Learning iteration 501/3000 [0m                      

                       Computation: 90600 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 0.7467
                    Surrogate loss: -0.0025
             Mean action noise std: 0.4319
                     Learning rate: 0.0009
                       Mean reward: 20.49
               Mean episode length: 374.13
       Episode_Reward/keep_balance: 0.3860
     Episode_Reward/rew_lin_vel_xy: 0.7292
      Episode_Reward/rew_ang_vel_z: 1.2052
    Episode_Reward/pen_base_height: -0.2422
      Episode_Reward/pen_lin_vel_z: -0.0456
     Episode_Reward/pen_ang_vel_xy: -0.0521
   Episode_Reward/pen_joint_torque: -0.0655
    Episode_Reward/pen_joint_accel: -0.0330
    Episode_Reward/pen_action_rate: -0.0628
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0122
   Episode_Reward/pen_joint_powers: -0.0222
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1260
Episode_Reward/pen_flat_orientation: -0.1180
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0691
   Episode_Reward/foot_landing_vel: -0.0521
   Episode_Reward/test_gait_reward: -0.3528
Metrics/base_velocity/error_vel_xy: 1.2914
Metrics/base_velocity/error_vel_yaw: 0.3192
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 1.09s
                        Total time: 544.24s
                               ETA: 2709.3s

################################################################################
                     [1m Learning iteration 502/3000 [0m                      

                       Computation: 91147 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.8434
                    Surrogate loss: 0.0012
             Mean action noise std: 0.4322
                     Learning rate: 0.0006
                       Mean reward: 17.59
               Mean episode length: 325.74
       Episode_Reward/keep_balance: 0.3486
     Episode_Reward/rew_lin_vel_xy: 0.7207
      Episode_Reward/rew_ang_vel_z: 1.0940
    Episode_Reward/pen_base_height: -0.2337
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.0474
   Episode_Reward/pen_joint_torque: -0.0611
    Episode_Reward/pen_joint_accel: -0.0294
    Episode_Reward/pen_action_rate: -0.0567
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0110
   Episode_Reward/pen_joint_powers: -0.0201
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1138
Episode_Reward/pen_flat_orientation: -0.1109
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0642
   Episode_Reward/foot_landing_vel: -0.0482
   Episode_Reward/test_gait_reward: -0.3193
Metrics/base_velocity/error_vel_xy: 1.1441
Metrics/base_velocity/error_vel_yaw: 0.2852
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 1.08s
                        Total time: 545.32s
                               ETA: 2708.2s

################################################################################
                     [1m Learning iteration 503/3000 [0m                      

                       Computation: 90534 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.8339
                    Surrogate loss: 0.0018
             Mean action noise std: 0.4326
                     Learning rate: 0.0003
                       Mean reward: 20.00
               Mean episode length: 354.85
       Episode_Reward/keep_balance: 0.3560
     Episode_Reward/rew_lin_vel_xy: 0.6643
      Episode_Reward/rew_ang_vel_z: 1.1178
    Episode_Reward/pen_base_height: -0.2337
      Episode_Reward/pen_lin_vel_z: -0.0420
     Episode_Reward/pen_ang_vel_xy: -0.0490
   Episode_Reward/pen_joint_torque: -0.0622
    Episode_Reward/pen_joint_accel: -0.0295
    Episode_Reward/pen_action_rate: -0.0572
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0113
   Episode_Reward/pen_joint_powers: -0.0207
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1144
Episode_Reward/pen_flat_orientation: -0.1138
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0625
   Episode_Reward/foot_landing_vel: -0.0489
   Episode_Reward/test_gait_reward: -0.3266
Metrics/base_velocity/error_vel_xy: 1.2183
Metrics/base_velocity/error_vel_yaw: 0.2920
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 1.09s
                        Total time: 546.41s
                               ETA: 2707.1s

################################################################################
                     [1m Learning iteration 504/3000 [0m                      

                       Computation: 90874 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.7785
                    Surrogate loss: -0.0018
             Mean action noise std: 0.4327
                     Learning rate: 0.0006
                       Mean reward: 21.96
               Mean episode length: 340.27
       Episode_Reward/keep_balance: 0.3397
     Episode_Reward/rew_lin_vel_xy: 0.6532
      Episode_Reward/rew_ang_vel_z: 1.0658
    Episode_Reward/pen_base_height: -0.2251
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.0452
   Episode_Reward/pen_joint_torque: -0.0569
    Episode_Reward/pen_joint_accel: -0.0278
    Episode_Reward/pen_action_rate: -0.0542
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0102
   Episode_Reward/pen_joint_powers: -0.0187
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1107
Episode_Reward/pen_flat_orientation: -0.1088
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0599
   Episode_Reward/foot_landing_vel: -0.0441
   Episode_Reward/test_gait_reward: -0.3123
Metrics/base_velocity/error_vel_xy: 1.1568
Metrics/base_velocity/error_vel_yaw: 0.2772
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 11.7917
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 1.08s
                        Total time: 547.49s
                               ETA: 2706.0s

################################################################################
                     [1m Learning iteration 505/3000 [0m                      

                       Computation: 90577 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.8488
                    Surrogate loss: -0.0010
             Mean action noise std: 0.4324
                     Learning rate: 0.0009
                       Mean reward: 18.29
               Mean episode length: 353.83
       Episode_Reward/keep_balance: 0.3684
     Episode_Reward/rew_lin_vel_xy: 0.7212
      Episode_Reward/rew_ang_vel_z: 1.1523
    Episode_Reward/pen_base_height: -0.2372
      Episode_Reward/pen_lin_vel_z: -0.0438
     Episode_Reward/pen_ang_vel_xy: -0.0493
   Episode_Reward/pen_joint_torque: -0.0645
    Episode_Reward/pen_joint_accel: -0.0313
    Episode_Reward/pen_action_rate: -0.0598
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0117
   Episode_Reward/pen_joint_powers: -0.0214
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1206
Episode_Reward/pen_flat_orientation: -0.1154
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0671
   Episode_Reward/foot_landing_vel: -0.0494
   Episode_Reward/test_gait_reward: -0.3390
Metrics/base_velocity/error_vel_xy: 1.2386
Metrics/base_velocity/error_vel_yaw: 0.3034
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 1.09s
                        Total time: 548.58s
                               ETA: 2704.9s

################################################################################
                     [1m Learning iteration 506/3000 [0m                      

                       Computation: 90802 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 1.0206
                    Surrogate loss: -0.0009
             Mean action noise std: 0.4323
                     Learning rate: 0.0013
                       Mean reward: 22.59
               Mean episode length: 370.34
       Episode_Reward/keep_balance: 0.3600
     Episode_Reward/rew_lin_vel_xy: 0.7211
      Episode_Reward/rew_ang_vel_z: 1.1299
    Episode_Reward/pen_base_height: -0.2360
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.0478
   Episode_Reward/pen_joint_torque: -0.0627
    Episode_Reward/pen_joint_accel: -0.0298
    Episode_Reward/pen_action_rate: -0.0583
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0111
   Episode_Reward/pen_joint_powers: -0.0206
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1177
Episode_Reward/pen_flat_orientation: -0.1110
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0640
   Episode_Reward/foot_landing_vel: -0.0473
   Episode_Reward/test_gait_reward: -0.3308
Metrics/base_velocity/error_vel_xy: 1.1721
Metrics/base_velocity/error_vel_yaw: 0.2932
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 1.08s
                        Total time: 549.66s
                               ETA: 2703.8s

################################################################################
                     [1m Learning iteration 507/3000 [0m                      

                       Computation: 90661 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 1.2834
                    Surrogate loss: 0.0020
             Mean action noise std: 0.4330
                     Learning rate: 0.0013
                       Mean reward: 16.02
               Mean episode length: 304.30
       Episode_Reward/keep_balance: 0.3361
     Episode_Reward/rew_lin_vel_xy: 0.6977
      Episode_Reward/rew_ang_vel_z: 1.0531
    Episode_Reward/pen_base_height: -0.2189
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.0473
   Episode_Reward/pen_joint_torque: -0.0566
    Episode_Reward/pen_joint_accel: -0.0291
    Episode_Reward/pen_action_rate: -0.0544
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0104
   Episode_Reward/pen_joint_powers: -0.0191
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1101
Episode_Reward/pen_flat_orientation: -0.1097
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0558
   Episode_Reward/foot_landing_vel: -0.0438
   Episode_Reward/test_gait_reward: -0.3087
Metrics/base_velocity/error_vel_xy: 1.0884
Metrics/base_velocity/error_vel_yaw: 0.2747
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 1.08s
                        Total time: 550.74s
                               ETA: 2702.8s

################################################################################
                     [1m Learning iteration 508/3000 [0m                      

                       Computation: 89746 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 1.2197
                    Surrogate loss: 0.0130
             Mean action noise std: 0.4332
                     Learning rate: 0.0000
                       Mean reward: 18.56
               Mean episode length: 333.70
       Episode_Reward/keep_balance: 0.3542
     Episode_Reward/rew_lin_vel_xy: 0.7174
      Episode_Reward/rew_ang_vel_z: 1.1147
    Episode_Reward/pen_base_height: -0.2345
      Episode_Reward/pen_lin_vel_z: -0.0422
     Episode_Reward/pen_ang_vel_xy: -0.0475
   Episode_Reward/pen_joint_torque: -0.0619
    Episode_Reward/pen_joint_accel: -0.0288
    Episode_Reward/pen_action_rate: -0.0577
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0108
   Episode_Reward/pen_joint_powers: -0.0201
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1167
Episode_Reward/pen_flat_orientation: -0.1080
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0632
   Episode_Reward/foot_landing_vel: -0.0462
   Episode_Reward/test_gait_reward: -0.3241
Metrics/base_velocity/error_vel_xy: 1.1779
Metrics/base_velocity/error_vel_yaw: 0.2876
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 1.10s
                        Total time: 551.84s
                               ETA: 2701.7s

################################################################################
                     [1m Learning iteration 509/3000 [0m                      

                       Computation: 91637 steps/s (collection: 0.951s, learning 0.121s)
               Value function loss: 0.9038
                    Surrogate loss: 0.0055
             Mean action noise std: 0.4333
                     Learning rate: 0.0000
                       Mean reward: 16.33
               Mean episode length: 314.92
       Episode_Reward/keep_balance: 0.3344
     Episode_Reward/rew_lin_vel_xy: 0.6282
      Episode_Reward/rew_ang_vel_z: 1.0470
    Episode_Reward/pen_base_height: -0.2260
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.0478
   Episode_Reward/pen_joint_torque: -0.0593
    Episode_Reward/pen_joint_accel: -0.0294
    Episode_Reward/pen_action_rate: -0.0547
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0108
   Episode_Reward/pen_joint_powers: -0.0196
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1104
Episode_Reward/pen_flat_orientation: -0.1100
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0603
   Episode_Reward/foot_landing_vel: -0.0459
   Episode_Reward/test_gait_reward: -0.3104
Metrics/base_velocity/error_vel_xy: 1.1350
Metrics/base_velocity/error_vel_yaw: 0.2754
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 1.07s
                        Total time: 552.91s
                               ETA: 2700.6s

################################################################################
                     [1m Learning iteration 510/3000 [0m                      

                       Computation: 91066 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.8062
                    Surrogate loss: -0.0015
             Mean action noise std: 0.4336
                     Learning rate: 0.0003
                       Mean reward: 18.95
               Mean episode length: 340.96
       Episode_Reward/keep_balance: 0.3479
     Episode_Reward/rew_lin_vel_xy: 0.6304
      Episode_Reward/rew_ang_vel_z: 1.0919
    Episode_Reward/pen_base_height: -0.2234
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.0469
   Episode_Reward/pen_joint_torque: -0.0580
    Episode_Reward/pen_joint_accel: -0.0287
    Episode_Reward/pen_action_rate: -0.0557
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0102
   Episode_Reward/pen_joint_powers: -0.0190
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1138
Episode_Reward/pen_flat_orientation: -0.1046
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0555
   Episode_Reward/foot_landing_vel: -0.0445
   Episode_Reward/test_gait_reward: -0.3188
Metrics/base_velocity/error_vel_xy: 1.2159
Metrics/base_velocity/error_vel_yaw: 0.2850
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 1.08s
                        Total time: 553.99s
                               ETA: 2699.5s

################################################################################
                     [1m Learning iteration 511/3000 [0m                      

                       Computation: 89223 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.7962
                    Surrogate loss: -0.0006
             Mean action noise std: 0.4343
                     Learning rate: 0.0006
                       Mean reward: 16.88
               Mean episode length: 328.06
       Episode_Reward/keep_balance: 0.3260
     Episode_Reward/rew_lin_vel_xy: 0.6415
      Episode_Reward/rew_ang_vel_z: 1.0118
    Episode_Reward/pen_base_height: -0.2213
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.0477
   Episode_Reward/pen_joint_torque: -0.0579
    Episode_Reward/pen_joint_accel: -0.0267
    Episode_Reward/pen_action_rate: -0.0530
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0105
   Episode_Reward/pen_joint_powers: -0.0193
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1073
Episode_Reward/pen_flat_orientation: -0.1110
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0595
   Episode_Reward/foot_landing_vel: -0.0442
   Episode_Reward/test_gait_reward: -0.3032
Metrics/base_velocity/error_vel_xy: 1.0814
Metrics/base_velocity/error_vel_yaw: 0.2754
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 1.10s
                        Total time: 555.09s
                               ETA: 2698.5s

################################################################################
                     [1m Learning iteration 512/3000 [0m                      

                       Computation: 86359 steps/s (collection: 1.017s, learning 0.122s)
               Value function loss: 0.8782
                    Surrogate loss: -0.0014
             Mean action noise std: 0.4349
                     Learning rate: 0.0009
                       Mean reward: 15.07
               Mean episode length: 263.66
       Episode_Reward/keep_balance: 0.2693
     Episode_Reward/rew_lin_vel_xy: 0.5306
      Episode_Reward/rew_ang_vel_z: 0.8316
    Episode_Reward/pen_base_height: -0.1951
      Episode_Reward/pen_lin_vel_z: -0.0311
     Episode_Reward/pen_ang_vel_xy: -0.0405
   Episode_Reward/pen_joint_torque: -0.0428
    Episode_Reward/pen_joint_accel: -0.0212
    Episode_Reward/pen_action_rate: -0.0425
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0081
   Episode_Reward/pen_joint_powers: -0.0146
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0887
Episode_Reward/pen_flat_orientation: -0.0943
  Episode_Reward/pen_feet_distance: 0.0000
Episode_Reward/pen_feet_regulation: -0.0460
   Episode_Reward/foot_landing_vel: -0.0331
   Episode_Reward/test_gait_reward: -0.2494
Metrics/base_velocity/error_vel_xy: 0.9039
Metrics/base_velocity/error_vel_yaw: 0.2310
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 1.14s
                        Total time: 556.23s
                               ETA: 2697.7s

################################################################################
                     [1m Learning iteration 513/3000 [0m                      

                       Computation: 91153 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.9519
                    Surrogate loss: 0.0060
             Mean action noise std: 0.4356
                     Learning rate: 0.0002
                       Mean reward: 24.82
               Mean episode length: 405.19
       Episode_Reward/keep_balance: 0.3522
     Episode_Reward/rew_lin_vel_xy: 0.6977
      Episode_Reward/rew_ang_vel_z: 1.0891
    Episode_Reward/pen_base_height: -0.2267
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.0488
   Episode_Reward/pen_joint_torque: -0.0609
    Episode_Reward/pen_joint_accel: -0.0291
    Episode_Reward/pen_action_rate: -0.0575
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0111
   Episode_Reward/pen_joint_powers: -0.0203
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1171
Episode_Reward/pen_flat_orientation: -0.1094
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0619
   Episode_Reward/foot_landing_vel: -0.0472
   Episode_Reward/test_gait_reward: -0.3266
Metrics/base_velocity/error_vel_xy: 1.1711
Metrics/base_velocity/error_vel_yaw: 0.2992
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 1.08s
                        Total time: 557.31s
                               ETA: 2696.5s

################################################################################
                     [1m Learning iteration 514/3000 [0m                      

                       Computation: 91590 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 0.7288
                    Surrogate loss: -0.0013
             Mean action noise std: 0.4356
                     Learning rate: 0.0004
                       Mean reward: 16.56
               Mean episode length: 302.94
       Episode_Reward/keep_balance: 0.3344
     Episode_Reward/rew_lin_vel_xy: 0.6467
      Episode_Reward/rew_ang_vel_z: 1.0218
    Episode_Reward/pen_base_height: -0.2271
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.0482
   Episode_Reward/pen_joint_torque: -0.0593
    Episode_Reward/pen_joint_accel: -0.0286
    Episode_Reward/pen_action_rate: -0.0556
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0108
   Episode_Reward/pen_joint_powers: -0.0199
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1120
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0625
   Episode_Reward/foot_landing_vel: -0.0466
   Episode_Reward/test_gait_reward: -0.3107
Metrics/base_velocity/error_vel_xy: 1.1286
Metrics/base_velocity/error_vel_yaw: 0.2930
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 9.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 1.07s
                        Total time: 558.38s
                               ETA: 2695.4s

################################################################################
                     [1m Learning iteration 515/3000 [0m                      

                       Computation: 91530 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.7656
                    Surrogate loss: -0.0026
             Mean action noise std: 0.4358
                     Learning rate: 0.0009
                       Mean reward: 19.59
               Mean episode length: 345.95
       Episode_Reward/keep_balance: 0.3441
     Episode_Reward/rew_lin_vel_xy: 0.7052
      Episode_Reward/rew_ang_vel_z: 1.0653
    Episode_Reward/pen_base_height: -0.2238
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.0485
   Episode_Reward/pen_joint_torque: -0.0591
    Episode_Reward/pen_joint_accel: -0.0291
    Episode_Reward/pen_action_rate: -0.0561
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0107
   Episode_Reward/pen_joint_powers: -0.0197
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1145
Episode_Reward/pen_flat_orientation: -0.1105
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0617
   Episode_Reward/foot_landing_vel: -0.0457
   Episode_Reward/test_gait_reward: -0.3184
Metrics/base_velocity/error_vel_xy: 1.1177
Metrics/base_velocity/error_vel_yaw: 0.2916
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 1.07s
                        Total time: 559.46s
                               ETA: 2694.3s

################################################################################
                     [1m Learning iteration 516/3000 [0m                      

                       Computation: 91203 steps/s (collection: 0.952s, learning 0.126s)
               Value function loss: 0.9030
                    Surrogate loss: 0.0005
             Mean action noise std: 0.4362
                     Learning rate: 0.0006
                       Mean reward: 21.07
               Mean episode length: 374.85
       Episode_Reward/keep_balance: 0.3207
     Episode_Reward/rew_lin_vel_xy: 0.6588
      Episode_Reward/rew_ang_vel_z: 0.9857
    Episode_Reward/pen_base_height: -0.2228
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.0465
   Episode_Reward/pen_joint_torque: -0.0550
    Episode_Reward/pen_joint_accel: -0.0275
    Episode_Reward/pen_action_rate: -0.0524
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0102
   Episode_Reward/pen_joint_powers: -0.0185
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1072
Episode_Reward/pen_flat_orientation: -0.1086
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0584
   Episode_Reward/foot_landing_vel: -0.0427
   Episode_Reward/test_gait_reward: -0.2988
Metrics/base_velocity/error_vel_xy: 1.0368
Metrics/base_velocity/error_vel_yaw: 0.2778
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 1.08s
                        Total time: 560.53s
                               ETA: 2693.2s

################################################################################
                     [1m Learning iteration 517/3000 [0m                      

                       Computation: 90386 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.8116
                    Surrogate loss: -0.0010
             Mean action noise std: 0.4368
                     Learning rate: 0.0004
                       Mean reward: 20.12
               Mean episode length: 371.49
       Episode_Reward/keep_balance: 0.3833
     Episode_Reward/rew_lin_vel_xy: 0.7867
      Episode_Reward/rew_ang_vel_z: 1.1817
    Episode_Reward/pen_base_height: -0.2357
      Episode_Reward/pen_lin_vel_z: -0.0467
     Episode_Reward/pen_ang_vel_xy: -0.0532
   Episode_Reward/pen_joint_torque: -0.0681
    Episode_Reward/pen_joint_accel: -0.0327
    Episode_Reward/pen_action_rate: -0.0645
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0127
   Episode_Reward/pen_joint_powers: -0.0231
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1292
Episode_Reward/pen_flat_orientation: -0.1225
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0733
   Episode_Reward/foot_landing_vel: -0.0563
   Episode_Reward/test_gait_reward: -0.3552
Metrics/base_velocity/error_vel_xy: 1.2674
Metrics/base_velocity/error_vel_yaw: 0.3276
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 1.09s
                        Total time: 561.62s
                               ETA: 2692.1s

################################################################################
                     [1m Learning iteration 518/3000 [0m                      

                       Computation: 90828 steps/s (collection: 0.957s, learning 0.126s)
               Value function loss: 0.7586
                    Surrogate loss: -0.0009
             Mean action noise std: 0.4377
                     Learning rate: 0.0006
                       Mean reward: 16.34
               Mean episode length: 322.17
       Episode_Reward/keep_balance: 0.3019
     Episode_Reward/rew_lin_vel_xy: 0.5902
      Episode_Reward/rew_ang_vel_z: 0.9207
    Episode_Reward/pen_base_height: -0.2117
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.0447
   Episode_Reward/pen_joint_torque: -0.0501
    Episode_Reward/pen_joint_accel: -0.0253
    Episode_Reward/pen_action_rate: -0.0496
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0096
   Episode_Reward/pen_joint_powers: -0.0172
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1018
Episode_Reward/pen_flat_orientation: -0.1058
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0570
   Episode_Reward/foot_landing_vel: -0.0388
   Episode_Reward/test_gait_reward: -0.2817
Metrics/base_velocity/error_vel_xy: 1.0116
Metrics/base_velocity/error_vel_yaw: 0.2661
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 1.08s
                        Total time: 562.70s
                               ETA: 2691.0s

################################################################################
                     [1m Learning iteration 519/3000 [0m                      

                       Computation: 90804 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.8071
                    Surrogate loss: -0.0013
             Mean action noise std: 0.4380
                     Learning rate: 0.0009
                       Mean reward: 19.10
               Mean episode length: 341.57
       Episode_Reward/keep_balance: 0.3561
     Episode_Reward/rew_lin_vel_xy: 0.6945
      Episode_Reward/rew_ang_vel_z: 1.0943
    Episode_Reward/pen_base_height: -0.2313
      Episode_Reward/pen_lin_vel_z: -0.0420
     Episode_Reward/pen_ang_vel_xy: -0.0509
   Episode_Reward/pen_joint_torque: -0.0606
    Episode_Reward/pen_joint_accel: -0.0302
    Episode_Reward/pen_action_rate: -0.0591
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0116
   Episode_Reward/pen_joint_powers: -0.0208
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1196
Episode_Reward/pen_flat_orientation: -0.1211
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0664
   Episode_Reward/foot_landing_vel: -0.0500
   Episode_Reward/test_gait_reward: -0.3306
Metrics/base_velocity/error_vel_xy: 1.2001
Metrics/base_velocity/error_vel_yaw: 0.3097
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 1.08s
                        Total time: 563.79s
                               ETA: 2689.9s

################################################################################
                     [1m Learning iteration 520/3000 [0m                      

                       Computation: 90783 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.9169
                    Surrogate loss: 0.0020
             Mean action noise std: 0.4381
                     Learning rate: 0.0004
                       Mean reward: 22.25
               Mean episode length: 396.14
       Episode_Reward/keep_balance: 0.3616
     Episode_Reward/rew_lin_vel_xy: 0.7538
      Episode_Reward/rew_ang_vel_z: 1.1109
    Episode_Reward/pen_base_height: -0.2303
      Episode_Reward/pen_lin_vel_z: -0.0430
     Episode_Reward/pen_ang_vel_xy: -0.0510
   Episode_Reward/pen_joint_torque: -0.0628
    Episode_Reward/pen_joint_accel: -0.0311
    Episode_Reward/pen_action_rate: -0.0607
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0116
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1219
Episode_Reward/pen_flat_orientation: -0.1131
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0669
   Episode_Reward/foot_landing_vel: -0.0480
   Episode_Reward/test_gait_reward: -0.3353
Metrics/base_velocity/error_vel_xy: 1.1755
Metrics/base_velocity/error_vel_yaw: 0.3148
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 1.08s
                        Total time: 564.87s
                               ETA: 2688.8s

################################################################################
                     [1m Learning iteration 521/3000 [0m                      

                       Computation: 90730 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.8768
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4384
                     Learning rate: 0.0009
                       Mean reward: 21.58
               Mean episode length: 390.18
       Episode_Reward/keep_balance: 0.3700
     Episode_Reward/rew_lin_vel_xy: 0.7317
      Episode_Reward/rew_ang_vel_z: 1.1342
    Episode_Reward/pen_base_height: -0.2374
      Episode_Reward/pen_lin_vel_z: -0.0452
     Episode_Reward/pen_ang_vel_xy: -0.0520
   Episode_Reward/pen_joint_torque: -0.0674
    Episode_Reward/pen_joint_accel: -0.0325
    Episode_Reward/pen_action_rate: -0.0623
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0121
   Episode_Reward/pen_joint_powers: -0.0225
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1243
Episode_Reward/pen_flat_orientation: -0.1167
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0705
   Episode_Reward/foot_landing_vel: -0.0511
   Episode_Reward/test_gait_reward: -0.3427
Metrics/base_velocity/error_vel_xy: 1.2320
Metrics/base_velocity/error_vel_yaw: 0.3203
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 1.08s
                        Total time: 565.95s
                               ETA: 2687.7s

################################################################################
                     [1m Learning iteration 522/3000 [0m                      

                       Computation: 90342 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.8744
                    Surrogate loss: 0.0005
             Mean action noise std: 0.4393
                     Learning rate: 0.0013
                       Mean reward: 17.57
               Mean episode length: 320.10
       Episode_Reward/keep_balance: 0.3120
     Episode_Reward/rew_lin_vel_xy: 0.6178
      Episode_Reward/rew_ang_vel_z: 0.9580
    Episode_Reward/pen_base_height: -0.2129
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.0454
   Episode_Reward/pen_joint_torque: -0.0515
    Episode_Reward/pen_joint_accel: -0.0249
    Episode_Reward/pen_action_rate: -0.0510
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0095
   Episode_Reward/pen_joint_powers: -0.0174
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1056
Episode_Reward/pen_flat_orientation: -0.1057
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0565
   Episode_Reward/foot_landing_vel: -0.0389
   Episode_Reward/test_gait_reward: -0.2893
Metrics/base_velocity/error_vel_xy: 1.0427
Metrics/base_velocity/error_vel_yaw: 0.2713
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 1.09s
                        Total time: 567.04s
                               ETA: 2686.7s

################################################################################
                     [1m Learning iteration 523/3000 [0m                      

                       Computation: 89707 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 0.9730
                    Surrogate loss: -0.0002
             Mean action noise std: 0.4393
                     Learning rate: 0.0006
                       Mean reward: 18.90
               Mean episode length: 334.87
       Episode_Reward/keep_balance: 0.3617
     Episode_Reward/rew_lin_vel_xy: 0.7306
      Episode_Reward/rew_ang_vel_z: 1.0952
    Episode_Reward/pen_base_height: -0.2303
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.0521
   Episode_Reward/pen_joint_torque: -0.0618
    Episode_Reward/pen_joint_accel: -0.0320
    Episode_Reward/pen_action_rate: -0.0603
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0115
   Episode_Reward/pen_joint_powers: -0.0209
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1222
Episode_Reward/pen_flat_orientation: -0.1167
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0658
   Episode_Reward/foot_landing_vel: -0.0469
   Episode_Reward/test_gait_reward: -0.3344
Metrics/base_velocity/error_vel_xy: 1.2309
Metrics/base_velocity/error_vel_yaw: 0.3252
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 9.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 1.10s
                        Total time: 568.14s
                               ETA: 2685.6s

################################################################################
                     [1m Learning iteration 524/3000 [0m                      

                       Computation: 90284 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.7352
                    Surrogate loss: 0.0033
             Mean action noise std: 0.4394
                     Learning rate: 0.0001
                       Mean reward: 20.02
               Mean episode length: 352.61
       Episode_Reward/keep_balance: 0.3374
     Episode_Reward/rew_lin_vel_xy: 0.6762
      Episode_Reward/rew_ang_vel_z: 1.0279
    Episode_Reward/pen_base_height: -0.2203
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.0493
   Episode_Reward/pen_joint_torque: -0.0577
    Episode_Reward/pen_joint_accel: -0.0286
    Episode_Reward/pen_action_rate: -0.0562
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0107
   Episode_Reward/pen_joint_powers: -0.0196
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1138
Episode_Reward/pen_flat_orientation: -0.1111
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0614
   Episode_Reward/foot_landing_vel: -0.0445
   Episode_Reward/test_gait_reward: -0.3113
Metrics/base_velocity/error_vel_xy: 1.1360
Metrics/base_velocity/error_vel_yaw: 0.2989
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 1.09s
                        Total time: 569.23s
                               ETA: 2684.6s

################################################################################
                     [1m Learning iteration 525/3000 [0m                      

                       Computation: 90896 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 0.7955
                    Surrogate loss: 0.0078
             Mean action noise std: 0.4396
                     Learning rate: 0.0000
                       Mean reward: 21.96
               Mean episode length: 377.39
       Episode_Reward/keep_balance: 0.3700
     Episode_Reward/rew_lin_vel_xy: 0.7732
      Episode_Reward/rew_ang_vel_z: 1.1225
    Episode_Reward/pen_base_height: -0.2378
      Episode_Reward/pen_lin_vel_z: -0.0451
     Episode_Reward/pen_ang_vel_xy: -0.0527
   Episode_Reward/pen_joint_torque: -0.0640
    Episode_Reward/pen_joint_accel: -0.0326
    Episode_Reward/pen_action_rate: -0.0628
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0124
   Episode_Reward/pen_joint_powers: -0.0221
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1265
Episode_Reward/pen_flat_orientation: -0.1204
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0713
   Episode_Reward/foot_landing_vel: -0.0528
   Episode_Reward/test_gait_reward: -0.3432
Metrics/base_velocity/error_vel_xy: 1.2031
Metrics/base_velocity/error_vel_yaw: 0.3310
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 1.08s
                        Total time: 570.31s
                               ETA: 2683.5s

################################################################################
                     [1m Learning iteration 526/3000 [0m                      

                       Computation: 89802 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.7276
                    Surrogate loss: 0.0017
             Mean action noise std: 0.4396
                     Learning rate: 0.0001
                       Mean reward: 19.79
               Mean episode length: 360.90
       Episode_Reward/keep_balance: 0.3495
     Episode_Reward/rew_lin_vel_xy: 0.7290
      Episode_Reward/rew_ang_vel_z: 1.0580
    Episode_Reward/pen_base_height: -0.2313
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.0507
   Episode_Reward/pen_joint_torque: -0.0597
    Episode_Reward/pen_joint_accel: -0.0311
    Episode_Reward/pen_action_rate: -0.0587
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0117
   Episode_Reward/pen_joint_powers: -0.0206
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1184
Episode_Reward/pen_flat_orientation: -0.1171
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0718
   Episode_Reward/foot_landing_vel: -0.0475
   Episode_Reward/test_gait_reward: -0.3264
Metrics/base_velocity/error_vel_xy: 1.1174
Metrics/base_velocity/error_vel_yaw: 0.3126
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 1.09s
                        Total time: 571.40s
                               ETA: 2682.4s

################################################################################
                     [1m Learning iteration 527/3000 [0m                      

                       Computation: 89742 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.7933
                    Surrogate loss: 0.0014
             Mean action noise std: 0.4400
                     Learning rate: 0.0002
                       Mean reward: 20.40
               Mean episode length: 369.57
       Episode_Reward/keep_balance: 0.3310
     Episode_Reward/rew_lin_vel_xy: 0.6774
      Episode_Reward/rew_ang_vel_z: 1.0079
    Episode_Reward/pen_base_height: -0.2177
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.0477
   Episode_Reward/pen_joint_torque: -0.0561
    Episode_Reward/pen_joint_accel: -0.0272
    Episode_Reward/pen_action_rate: -0.0547
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0104
   Episode_Reward/pen_joint_powers: -0.0192
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1113
Episode_Reward/pen_flat_orientation: -0.1110
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0620
   Episode_Reward/foot_landing_vel: -0.0425
   Episode_Reward/test_gait_reward: -0.3050
Metrics/base_velocity/error_vel_xy: 1.0800
Metrics/base_velocity/error_vel_yaw: 0.2933
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 1.10s
                        Total time: 572.50s
                               ETA: 2681.4s

################################################################################
                     [1m Learning iteration 528/3000 [0m                      

                       Computation: 90311 steps/s (collection: 0.964s, learning 0.125s)
               Value function loss: 0.7993
                    Surrogate loss: 0.0012
             Mean action noise std: 0.4407
                     Learning rate: 0.0004
                       Mean reward: 23.67
               Mean episode length: 424.83
       Episode_Reward/keep_balance: 0.3674
     Episode_Reward/rew_lin_vel_xy: 0.7333
      Episode_Reward/rew_ang_vel_z: 1.1222
    Episode_Reward/pen_base_height: -0.2316
      Episode_Reward/pen_lin_vel_z: -0.0427
     Episode_Reward/pen_ang_vel_xy: -0.0529
   Episode_Reward/pen_joint_torque: -0.0628
    Episode_Reward/pen_joint_accel: -0.0318
    Episode_Reward/pen_action_rate: -0.0624
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0121
   Episode_Reward/pen_joint_powers: -0.0218
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1255
Episode_Reward/pen_flat_orientation: -0.1211
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0675
   Episode_Reward/foot_landing_vel: -0.0518
   Episode_Reward/test_gait_reward: -0.3426
Metrics/base_velocity/error_vel_xy: 1.2348
Metrics/base_velocity/error_vel_yaw: 0.3229
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 1.09s
                        Total time: 573.59s
                               ETA: 2680.3s

################################################################################
                     [1m Learning iteration 529/3000 [0m                      

                       Computation: 90953 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.7691
                    Surrogate loss: -0.0019
             Mean action noise std: 0.4409
                     Learning rate: 0.0009
                       Mean reward: 19.85
               Mean episode length: 335.32
       Episode_Reward/keep_balance: 0.3905
     Episode_Reward/rew_lin_vel_xy: 0.8095
      Episode_Reward/rew_ang_vel_z: 1.1859
    Episode_Reward/pen_base_height: -0.2493
      Episode_Reward/pen_lin_vel_z: -0.0482
     Episode_Reward/pen_ang_vel_xy: -0.0552
   Episode_Reward/pen_joint_torque: -0.0706
    Episode_Reward/pen_joint_accel: -0.0345
    Episode_Reward/pen_action_rate: -0.0673
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0241
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1331
Episode_Reward/pen_flat_orientation: -0.1276
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0825
   Episode_Reward/foot_landing_vel: -0.0557
   Episode_Reward/test_gait_reward: -0.3656
Metrics/base_velocity/error_vel_xy: 1.2867
Metrics/base_velocity/error_vel_yaw: 0.3473
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 1.08s
                        Total time: 574.67s
                               ETA: 2679.2s

################################################################################
                     [1m Learning iteration 530/3000 [0m                      

                       Computation: 90623 steps/s (collection: 0.960s, learning 0.125s)
               Value function loss: 0.8810
                    Surrogate loss: -0.0003
             Mean action noise std: 0.4411
                     Learning rate: 0.0013
                       Mean reward: 24.50
               Mean episode length: 418.00
       Episode_Reward/keep_balance: 0.4082
     Episode_Reward/rew_lin_vel_xy: 0.8899
      Episode_Reward/rew_ang_vel_z: 1.2468
    Episode_Reward/pen_base_height: -0.2455
      Episode_Reward/pen_lin_vel_z: -0.0464
     Episode_Reward/pen_ang_vel_xy: -0.0551
   Episode_Reward/pen_joint_torque: -0.0688
    Episode_Reward/pen_joint_accel: -0.0347
    Episode_Reward/pen_action_rate: -0.0687
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0131
   Episode_Reward/pen_joint_powers: -0.0237
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1389
Episode_Reward/pen_flat_orientation: -0.1280
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0769
   Episode_Reward/foot_landing_vel: -0.0525
   Episode_Reward/test_gait_reward: -0.3785
Metrics/base_velocity/error_vel_xy: 1.2661
Metrics/base_velocity/error_vel_yaw: 0.3569
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 1.08s
                        Total time: 575.75s
                               ETA: 2678.2s

################################################################################
                     [1m Learning iteration 531/3000 [0m                      

                       Computation: 91086 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.9454
                    Surrogate loss: 0.0058
             Mean action noise std: 0.4417
                     Learning rate: 0.0003
                       Mean reward: 23.89
               Mean episode length: 436.74
       Episode_Reward/keep_balance: 0.3781
     Episode_Reward/rew_lin_vel_xy: 0.7287
      Episode_Reward/rew_ang_vel_z: 1.1430
    Episode_Reward/pen_base_height: -0.2386
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.0550
   Episode_Reward/pen_joint_torque: -0.0661
    Episode_Reward/pen_joint_accel: -0.0335
    Episode_Reward/pen_action_rate: -0.0650
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0130
   Episode_Reward/pen_joint_powers: -0.0232
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1296
Episode_Reward/pen_flat_orientation: -0.1237
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0773
   Episode_Reward/foot_landing_vel: -0.0528
   Episode_Reward/test_gait_reward: -0.3529
Metrics/base_velocity/error_vel_xy: 1.2787
Metrics/base_velocity/error_vel_yaw: 0.3401
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 1.08s
                        Total time: 576.83s
                               ETA: 2677.1s

################################################################################
                     [1m Learning iteration 532/3000 [0m                      

                       Computation: 91684 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.8330
                    Surrogate loss: 0.0026
             Mean action noise std: 0.4423
                     Learning rate: 0.0002
                       Mean reward: 20.94
               Mean episode length: 384.20
       Episode_Reward/keep_balance: 0.4025
     Episode_Reward/rew_lin_vel_xy: 0.8434
      Episode_Reward/rew_ang_vel_z: 1.2277
    Episode_Reward/pen_base_height: -0.2430
      Episode_Reward/pen_lin_vel_z: -0.0457
     Episode_Reward/pen_ang_vel_xy: -0.0538
   Episode_Reward/pen_joint_torque: -0.0687
    Episode_Reward/pen_joint_accel: -0.0332
    Episode_Reward/pen_action_rate: -0.0690
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0131
   Episode_Reward/pen_joint_powers: -0.0237
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.1387
Episode_Reward/pen_flat_orientation: -0.1181
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0787
   Episode_Reward/foot_landing_vel: -0.0523
   Episode_Reward/test_gait_reward: -0.3722
Metrics/base_velocity/error_vel_xy: 1.2739
Metrics/base_velocity/error_vel_yaw: 0.3529
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 1.07s
                        Total time: 577.90s
                               ETA: 2675.9s

################################################################################
                     [1m Learning iteration 533/3000 [0m                      

                       Computation: 90889 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 0.8416
                    Surrogate loss: 0.0015
             Mean action noise std: 0.4429
                     Learning rate: 0.0003
                       Mean reward: 18.55
               Mean episode length: 357.85
       Episode_Reward/keep_balance: 0.3894
     Episode_Reward/rew_lin_vel_xy: 0.7619
      Episode_Reward/rew_ang_vel_z: 1.1824
    Episode_Reward/pen_base_height: -0.2388
      Episode_Reward/pen_lin_vel_z: -0.0460
     Episode_Reward/pen_ang_vel_xy: -0.0552
   Episode_Reward/pen_joint_torque: -0.0697
    Episode_Reward/pen_joint_accel: -0.0342
    Episode_Reward/pen_action_rate: -0.0674
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0131
   Episode_Reward/pen_joint_powers: -0.0238
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.1344
Episode_Reward/pen_flat_orientation: -0.1232
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0768
   Episode_Reward/foot_landing_vel: -0.0535
   Episode_Reward/test_gait_reward: -0.3623
Metrics/base_velocity/error_vel_xy: 1.2751
Metrics/base_velocity/error_vel_yaw: 0.3446
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 1.08s
                        Total time: 578.98s
                               ETA: 2674.8s

################################################################################
                     [1m Learning iteration 534/3000 [0m                      

                       Computation: 90751 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.9203
                    Surrogate loss: 0.0092
             Mean action noise std: 0.4432
                     Learning rate: 0.0000
                       Mean reward: 20.55
               Mean episode length: 358.98
       Episode_Reward/keep_balance: 0.3724
     Episode_Reward/rew_lin_vel_xy: 0.8547
      Episode_Reward/rew_ang_vel_z: 1.1325
    Episode_Reward/pen_base_height: -0.2294
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.0524
   Episode_Reward/pen_joint_torque: -0.0611
    Episode_Reward/pen_joint_accel: -0.0321
    Episode_Reward/pen_action_rate: -0.0627
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0120
   Episode_Reward/pen_joint_powers: -0.0215
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1269
Episode_Reward/pen_flat_orientation: -0.1179
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0676
   Episode_Reward/foot_landing_vel: -0.0481
   Episode_Reward/test_gait_reward: -0.3454
Metrics/base_velocity/error_vel_xy: 1.1756
Metrics/base_velocity/error_vel_yaw: 0.3298
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 1.08s
                        Total time: 580.07s
                               ETA: 2673.7s

################################################################################
                     [1m Learning iteration 535/3000 [0m                      

                       Computation: 90088 steps/s (collection: 0.967s, learning 0.125s)
               Value function loss: 0.7845
                    Surrogate loss: 0.0012
             Mean action noise std: 0.4433
                     Learning rate: 0.0001
                       Mean reward: 19.87
               Mean episode length: 353.80
       Episode_Reward/keep_balance: 0.3725
     Episode_Reward/rew_lin_vel_xy: 0.7674
      Episode_Reward/rew_ang_vel_z: 1.1317
    Episode_Reward/pen_base_height: -0.2326
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.0545
   Episode_Reward/pen_joint_torque: -0.0650
    Episode_Reward/pen_joint_accel: -0.0317
    Episode_Reward/pen_action_rate: -0.0637
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0122
   Episode_Reward/pen_joint_powers: -0.0225
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1270
Episode_Reward/pen_flat_orientation: -0.1178
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0701
   Episode_Reward/foot_landing_vel: -0.0484
   Episode_Reward/test_gait_reward: -0.3458
Metrics/base_velocity/error_vel_xy: 1.2259
Metrics/base_velocity/error_vel_yaw: 0.3301
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 1.09s
                        Total time: 581.16s
                               ETA: 2672.7s

################################################################################
                     [1m Learning iteration 536/3000 [0m                      

                       Computation: 89813 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.7642
                    Surrogate loss: 0.0034
             Mean action noise std: 0.4434
                     Learning rate: 0.0001
                       Mean reward: 22.63
               Mean episode length: 388.67
       Episode_Reward/keep_balance: 0.3635
     Episode_Reward/rew_lin_vel_xy: 0.7586
      Episode_Reward/rew_ang_vel_z: 1.0929
    Episode_Reward/pen_base_height: -0.2317
      Episode_Reward/pen_lin_vel_z: -0.0399
     Episode_Reward/pen_ang_vel_xy: -0.0507
   Episode_Reward/pen_joint_torque: -0.0601
    Episode_Reward/pen_joint_accel: -0.0297
    Episode_Reward/pen_action_rate: -0.0611
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0116
   Episode_Reward/pen_joint_powers: -0.0208
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1248
Episode_Reward/pen_flat_orientation: -0.1180
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0694
   Episode_Reward/foot_landing_vel: -0.0459
   Episode_Reward/test_gait_reward: -0.3377
Metrics/base_velocity/error_vel_xy: 1.1610
Metrics/base_velocity/error_vel_yaw: 0.3315
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 1.09s
                        Total time: 582.25s
                               ETA: 2671.6s

################################################################################
                     [1m Learning iteration 537/3000 [0m                      

                       Computation: 90679 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.8010
                    Surrogate loss: 0.0063
             Mean action noise std: 0.4436
                     Learning rate: 0.0000
                       Mean reward: 19.89
               Mean episode length: 361.45
       Episode_Reward/keep_balance: 0.3732
     Episode_Reward/rew_lin_vel_xy: 0.7838
      Episode_Reward/rew_ang_vel_z: 1.1283
    Episode_Reward/pen_base_height: -0.2344
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.0534
   Episode_Reward/pen_joint_torque: -0.0624
    Episode_Reward/pen_joint_accel: -0.0325
    Episode_Reward/pen_action_rate: -0.0638
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0121
   Episode_Reward/pen_joint_powers: -0.0218
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1286
Episode_Reward/pen_flat_orientation: -0.1210
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0729
   Episode_Reward/foot_landing_vel: -0.0483
   Episode_Reward/test_gait_reward: -0.3481
Metrics/base_velocity/error_vel_xy: 1.1908
Metrics/base_velocity/error_vel_yaw: 0.3361
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 1.08s
                        Total time: 583.34s
                               ETA: 2670.6s

################################################################################
                     [1m Learning iteration 538/3000 [0m                      

                       Computation: 90596 steps/s (collection: 0.960s, learning 0.125s)
               Value function loss: 0.7942
                    Surrogate loss: 0.0007
             Mean action noise std: 0.4439
                     Learning rate: 0.0001
                       Mean reward: 18.56
               Mean episode length: 348.99
       Episode_Reward/keep_balance: 0.3649
     Episode_Reward/rew_lin_vel_xy: 0.7532
      Episode_Reward/rew_ang_vel_z: 1.0963
    Episode_Reward/pen_base_height: -0.2251
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.0492
   Episode_Reward/pen_joint_torque: -0.0614
    Episode_Reward/pen_joint_accel: -0.0332
    Episode_Reward/pen_action_rate: -0.0623
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0119
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1271
Episode_Reward/pen_flat_orientation: -0.1158
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0697
   Episode_Reward/foot_landing_vel: -0.0478
   Episode_Reward/test_gait_reward: -0.3392
Metrics/base_velocity/error_vel_xy: 1.2028
Metrics/base_velocity/error_vel_yaw: 0.3321
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 1.09s
                        Total time: 584.42s
                               ETA: 2669.5s

################################################################################
                     [1m Learning iteration 539/3000 [0m                      

                       Computation: 91407 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.8370
                    Surrogate loss: 0.0052
             Mean action noise std: 0.4442
                     Learning rate: 0.0001
                       Mean reward: 23.82
               Mean episode length: 421.63
       Episode_Reward/keep_balance: 0.3884
     Episode_Reward/rew_lin_vel_xy: 0.7866
      Episode_Reward/rew_ang_vel_z: 1.1750
    Episode_Reward/pen_base_height: -0.2390
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.0544
   Episode_Reward/pen_joint_torque: -0.0671
    Episode_Reward/pen_joint_accel: -0.0341
    Episode_Reward/pen_action_rate: -0.0664
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0126
   Episode_Reward/pen_joint_powers: -0.0230
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1335
Episode_Reward/pen_flat_orientation: -0.1232
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0755
   Episode_Reward/foot_landing_vel: -0.0522
   Episode_Reward/test_gait_reward: -0.3618
Metrics/base_velocity/error_vel_xy: 1.2633
Metrics/base_velocity/error_vel_yaw: 0.3485
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 1.08s
                        Total time: 585.50s
                               ETA: 2668.4s

################################################################################
                     [1m Learning iteration 540/3000 [0m                      

                       Computation: 89472 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.8673
                    Surrogate loss: 0.0019
             Mean action noise std: 0.4444
                     Learning rate: 0.0002
                       Mean reward: 21.46
               Mean episode length: 368.01
       Episode_Reward/keep_balance: 0.3888
     Episode_Reward/rew_lin_vel_xy: 0.8620
      Episode_Reward/rew_ang_vel_z: 1.1736
    Episode_Reward/pen_base_height: -0.2340
      Episode_Reward/pen_lin_vel_z: -0.0446
     Episode_Reward/pen_ang_vel_xy: -0.0568
   Episode_Reward/pen_joint_torque: -0.0675
    Episode_Reward/pen_joint_accel: -0.0335
    Episode_Reward/pen_action_rate: -0.0675
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0130
   Episode_Reward/pen_joint_powers: -0.0236
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.1343
Episode_Reward/pen_flat_orientation: -0.1224
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0743
   Episode_Reward/foot_landing_vel: -0.0510
   Episode_Reward/test_gait_reward: -0.3614
Metrics/base_velocity/error_vel_xy: 1.2450
Metrics/base_velocity/error_vel_yaw: 0.3515
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 1.10s
                        Total time: 586.60s
                               ETA: 2667.3s

################################################################################
                     [1m Learning iteration 541/3000 [0m                      

                       Computation: 91362 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.8716
                    Surrogate loss: -0.0005
             Mean action noise std: 0.4446
                     Learning rate: 0.0004
                       Mean reward: 24.92
               Mean episode length: 408.06
       Episode_Reward/keep_balance: 0.4178
     Episode_Reward/rew_lin_vel_xy: 0.9129
      Episode_Reward/rew_ang_vel_z: 1.2529
    Episode_Reward/pen_base_height: -0.2471
      Episode_Reward/pen_lin_vel_z: -0.0483
     Episode_Reward/pen_ang_vel_xy: -0.0578
   Episode_Reward/pen_joint_torque: -0.0718
    Episode_Reward/pen_joint_accel: -0.0395
    Episode_Reward/pen_action_rate: -0.0734
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0142
   Episode_Reward/pen_joint_powers: -0.0251
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1462
Episode_Reward/pen_flat_orientation: -0.1303
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0862
   Episode_Reward/foot_landing_vel: -0.0586
   Episode_Reward/test_gait_reward: -0.3889
Metrics/base_velocity/error_vel_xy: 1.3134
Metrics/base_velocity/error_vel_yaw: 0.3828
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 1.08s
                        Total time: 587.67s
                               ETA: 2666.2s

################################################################################
                     [1m Learning iteration 542/3000 [0m                      

                       Computation: 91506 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.9588
                    Surrogate loss: -0.0023
             Mean action noise std: 0.4450
                     Learning rate: 0.0013
                       Mean reward: 24.07
               Mean episode length: 410.70
       Episode_Reward/keep_balance: 0.3641
     Episode_Reward/rew_lin_vel_xy: 0.7612
      Episode_Reward/rew_ang_vel_z: 1.1003
    Episode_Reward/pen_base_height: -0.2305
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.0529
   Episode_Reward/pen_joint_torque: -0.0605
    Episode_Reward/pen_joint_accel: -0.0310
    Episode_Reward/pen_action_rate: -0.0621
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0121
   Episode_Reward/pen_joint_powers: -0.0214
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1257
Episode_Reward/pen_flat_orientation: -0.1219
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0736
   Episode_Reward/foot_landing_vel: -0.0485
   Episode_Reward/test_gait_reward: -0.3397
Metrics/base_velocity/error_vel_xy: 1.1924
Metrics/base_velocity/error_vel_yaw: 0.3285
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 1.07s
                        Total time: 588.75s
                               ETA: 2665.1s

################################################################################
                     [1m Learning iteration 543/3000 [0m                      

                       Computation: 90902 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 1.0515
                    Surrogate loss: 0.0000
             Mean action noise std: 0.4453
                     Learning rate: 0.0006
                       Mean reward: 24.37
               Mean episode length: 396.25
       Episode_Reward/keep_balance: 0.4259
     Episode_Reward/rew_lin_vel_xy: 0.9885
      Episode_Reward/rew_ang_vel_z: 1.2909
    Episode_Reward/pen_base_height: -0.2431
      Episode_Reward/pen_lin_vel_z: -0.0472
     Episode_Reward/pen_ang_vel_xy: -0.0585
   Episode_Reward/pen_joint_torque: -0.0705
    Episode_Reward/pen_joint_accel: -0.0351
    Episode_Reward/pen_action_rate: -0.0737
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0247
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1481
Episode_Reward/pen_flat_orientation: -0.1290
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0818
   Episode_Reward/foot_landing_vel: -0.0531
   Episode_Reward/test_gait_reward: -0.3925
Metrics/base_velocity/error_vel_xy: 1.3153
Metrics/base_velocity/error_vel_yaw: 0.3797
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 1.08s
                        Total time: 589.83s
                               ETA: 2664.0s

################################################################################
                     [1m Learning iteration 544/3000 [0m                      

                       Computation: 89163 steps/s (collection: 0.980s, learning 0.122s)
               Value function loss: 0.9781
                    Surrogate loss: -0.0013
             Mean action noise std: 0.4455
                     Learning rate: 0.0013
                       Mean reward: 22.59
               Mean episode length: 370.40
       Episode_Reward/keep_balance: 0.3612
     Episode_Reward/rew_lin_vel_xy: 0.7880
      Episode_Reward/rew_ang_vel_z: 1.0891
    Episode_Reward/pen_base_height: -0.2270
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.0527
   Episode_Reward/pen_joint_torque: -0.0602
    Episode_Reward/pen_joint_accel: -0.0321
    Episode_Reward/pen_action_rate: -0.0619
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0119
   Episode_Reward/pen_joint_powers: -0.0212
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1250
Episode_Reward/pen_flat_orientation: -0.1167
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0690
   Episode_Reward/foot_landing_vel: -0.0471
   Episode_Reward/test_gait_reward: -0.3351
Metrics/base_velocity/error_vel_xy: 1.1720
Metrics/base_velocity/error_vel_yaw: 0.3284
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 1.10s
                        Total time: 590.93s
                               ETA: 2663.0s

################################################################################
                     [1m Learning iteration 545/3000 [0m                      

                       Computation: 90938 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 1.1407
                    Surrogate loss: 0.0010
             Mean action noise std: 0.4454
                     Learning rate: 0.0019
                       Mean reward: 22.41
               Mean episode length: 365.86
       Episode_Reward/keep_balance: 0.3657
     Episode_Reward/rew_lin_vel_xy: 0.8832
      Episode_Reward/rew_ang_vel_z: 1.1131
    Episode_Reward/pen_base_height: -0.2277
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.0506
   Episode_Reward/pen_joint_torque: -0.0598
    Episode_Reward/pen_joint_accel: -0.0314
    Episode_Reward/pen_action_rate: -0.0616
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0117
   Episode_Reward/pen_joint_powers: -0.0207
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1257
Episode_Reward/pen_flat_orientation: -0.1175
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0696
   Episode_Reward/foot_landing_vel: -0.0475
   Episode_Reward/test_gait_reward: -0.3394
Metrics/base_velocity/error_vel_xy: 1.1324
Metrics/base_velocity/error_vel_yaw: 0.3233
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 1.08s
                        Total time: 592.01s
                               ETA: 2661.9s

################################################################################
                     [1m Learning iteration 546/3000 [0m                      

                       Computation: 91370 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 1.0512
                    Surrogate loss: 0.0024
             Mean action noise std: 0.4459
                     Learning rate: 0.0004
                       Mean reward: 18.04
               Mean episode length: 338.31
       Episode_Reward/keep_balance: 0.3627
     Episode_Reward/rew_lin_vel_xy: 0.7805
      Episode_Reward/rew_ang_vel_z: 1.0926
    Episode_Reward/pen_base_height: -0.2253
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.0525
   Episode_Reward/pen_joint_torque: -0.0607
    Episode_Reward/pen_joint_accel: -0.0307
    Episode_Reward/pen_action_rate: -0.0624
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0119
   Episode_Reward/pen_joint_powers: -0.0213
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1259
Episode_Reward/pen_flat_orientation: -0.1189
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0706
   Episode_Reward/foot_landing_vel: -0.0490
   Episode_Reward/test_gait_reward: -0.3370
Metrics/base_velocity/error_vel_xy: 1.1592
Metrics/base_velocity/error_vel_yaw: 0.3299
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 1.08s
                        Total time: 593.09s
                               ETA: 2660.8s

################################################################################
                     [1m Learning iteration 547/3000 [0m                      

                       Computation: 90157 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.9036
                    Surrogate loss: -0.0006
             Mean action noise std: 0.4468
                     Learning rate: 0.0009
                       Mean reward: 17.39
               Mean episode length: 339.62
       Episode_Reward/keep_balance: 0.3479
     Episode_Reward/rew_lin_vel_xy: 0.7259
      Episode_Reward/rew_ang_vel_z: 1.0431
    Episode_Reward/pen_base_height: -0.2214
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.0510
   Episode_Reward/pen_joint_torque: -0.0588
    Episode_Reward/pen_joint_accel: -0.0314
    Episode_Reward/pen_action_rate: -0.0599
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0115
   Episode_Reward/pen_joint_powers: -0.0205
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1214
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0681
   Episode_Reward/foot_landing_vel: -0.0461
   Episode_Reward/test_gait_reward: -0.3244
Metrics/base_velocity/error_vel_xy: 1.1355
Metrics/base_velocity/error_vel_yaw: 0.3199
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 1.09s
                        Total time: 594.18s
                               ETA: 2659.7s

################################################################################
                     [1m Learning iteration 548/3000 [0m                      

                       Computation: 90659 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 1.0807
                    Surrogate loss: 0.0022
             Mean action noise std: 0.4475
                     Learning rate: 0.0004
                       Mean reward: 19.38
               Mean episode length: 359.07
       Episode_Reward/keep_balance: 0.3781
     Episode_Reward/rew_lin_vel_xy: 0.8911
      Episode_Reward/rew_ang_vel_z: 1.1299
    Episode_Reward/pen_base_height: -0.2363
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.0540
   Episode_Reward/pen_joint_torque: -0.0649
    Episode_Reward/pen_joint_accel: -0.0369
    Episode_Reward/pen_action_rate: -0.0660
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0128
   Episode_Reward/pen_joint_powers: -0.0225
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1328
Episode_Reward/pen_flat_orientation: -0.1186
  Episode_Reward/pen_feet_distance: 0.0000
Episode_Reward/pen_feet_regulation: -0.0771
   Episode_Reward/foot_landing_vel: -0.0492
   Episode_Reward/test_gait_reward: -0.3546
Metrics/base_velocity/error_vel_xy: 1.1641
Metrics/base_velocity/error_vel_yaw: 0.3480
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 1.08s
                        Total time: 595.26s
                               ETA: 2658.6s

################################################################################
                     [1m Learning iteration 549/3000 [0m                      

                       Computation: 89736 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.9033
                    Surrogate loss: -0.0025
             Mean action noise std: 0.4474
                     Learning rate: 0.0009
                       Mean reward: 24.93
               Mean episode length: 412.99
       Episode_Reward/keep_balance: 0.3896
     Episode_Reward/rew_lin_vel_xy: 0.9088
      Episode_Reward/rew_ang_vel_z: 1.1713
    Episode_Reward/pen_base_height: -0.2391
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.0560
   Episode_Reward/pen_joint_torque: -0.0651
    Episode_Reward/pen_joint_accel: -0.0350
    Episode_Reward/pen_action_rate: -0.0679
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0129
   Episode_Reward/pen_joint_powers: -0.0230
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1359
Episode_Reward/pen_flat_orientation: -0.1227
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0778
   Episode_Reward/foot_landing_vel: -0.0506
   Episode_Reward/test_gait_reward: -0.3641
Metrics/base_velocity/error_vel_xy: 1.2309
Metrics/base_velocity/error_vel_yaw: 0.3550
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 1.10s
                        Total time: 596.36s
                               ETA: 2657.6s

################################################################################
                     [1m Learning iteration 550/3000 [0m                      

                       Computation: 89390 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.8995
                    Surrogate loss: -0.0025
             Mean action noise std: 0.4473
                     Learning rate: 0.0019
                       Mean reward: 21.25
               Mean episode length: 389.74
       Episode_Reward/keep_balance: 0.3689
     Episode_Reward/rew_lin_vel_xy: 0.7803
      Episode_Reward/rew_ang_vel_z: 1.1187
    Episode_Reward/pen_base_height: -0.2298
      Episode_Reward/pen_lin_vel_z: -0.0438
     Episode_Reward/pen_ang_vel_xy: -0.0542
   Episode_Reward/pen_joint_torque: -0.0652
    Episode_Reward/pen_joint_accel: -0.0319
    Episode_Reward/pen_action_rate: -0.0646
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0127
   Episode_Reward/pen_joint_powers: -0.0226
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1283
Episode_Reward/pen_flat_orientation: -0.1199
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0781
   Episode_Reward/foot_landing_vel: -0.0526
   Episode_Reward/test_gait_reward: -0.3417
Metrics/base_velocity/error_vel_xy: 1.2369
Metrics/base_velocity/error_vel_yaw: 0.3296
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 1.10s
                        Total time: 597.46s
                               ETA: 2656.6s

################################################################################
                     [1m Learning iteration 551/3000 [0m                      

                       Computation: 90515 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 1.0082
                    Surrogate loss: 0.0012
             Mean action noise std: 0.4478
                     Learning rate: 0.0009
                       Mean reward: 19.36
               Mean episode length: 345.24
       Episode_Reward/keep_balance: 0.3779
     Episode_Reward/rew_lin_vel_xy: 0.8290
      Episode_Reward/rew_ang_vel_z: 1.1428
    Episode_Reward/pen_base_height: -0.2298
      Episode_Reward/pen_lin_vel_z: -0.0419
     Episode_Reward/pen_ang_vel_xy: -0.0519
   Episode_Reward/pen_joint_torque: -0.0640
    Episode_Reward/pen_joint_accel: -0.0339
    Episode_Reward/pen_action_rate: -0.0655
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0124
   Episode_Reward/pen_joint_powers: -0.0222
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1322
Episode_Reward/pen_flat_orientation: -0.1191
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0754
   Episode_Reward/foot_landing_vel: -0.0484
   Episode_Reward/test_gait_reward: -0.3524
Metrics/base_velocity/error_vel_xy: 1.2054
Metrics/base_velocity/error_vel_yaw: 0.3403
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 1.09s
                        Total time: 598.54s
                               ETA: 2655.5s

################################################################################
                     [1m Learning iteration 552/3000 [0m                      

                       Computation: 90507 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.9321
                    Surrogate loss: 0.0014
             Mean action noise std: 0.4482
                     Learning rate: 0.0009
                       Mean reward: 20.17
               Mean episode length: 336.72
       Episode_Reward/keep_balance: 0.3611
     Episode_Reward/rew_lin_vel_xy: 0.8318
      Episode_Reward/rew_ang_vel_z: 1.0975
    Episode_Reward/pen_base_height: -0.2239
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.0529
   Episode_Reward/pen_joint_torque: -0.0617
    Episode_Reward/pen_joint_accel: -0.0317
    Episode_Reward/pen_action_rate: -0.0627
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0119
   Episode_Reward/pen_joint_powers: -0.0214
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1262
Episode_Reward/pen_flat_orientation: -0.1173
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0699
   Episode_Reward/foot_landing_vel: -0.0466
   Episode_Reward/test_gait_reward: -0.3359
Metrics/base_velocity/error_vel_xy: 1.1435
Metrics/base_velocity/error_vel_yaw: 0.3219
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 1.09s
                        Total time: 599.63s
                               ETA: 2654.4s

################################################################################
                     [1m Learning iteration 553/3000 [0m                      

                       Computation: 90093 steps/s (collection: 0.965s, learning 0.127s)
               Value function loss: 0.9770
                    Surrogate loss: 0.0002
             Mean action noise std: 0.4485
                     Learning rate: 0.0009
                       Mean reward: 25.18
               Mean episode length: 404.78
       Episode_Reward/keep_balance: 0.3775
     Episode_Reward/rew_lin_vel_xy: 0.8795
      Episode_Reward/rew_ang_vel_z: 1.1273
    Episode_Reward/pen_base_height: -0.2331
      Episode_Reward/pen_lin_vel_z: -0.0443
     Episode_Reward/pen_ang_vel_xy: -0.0561
   Episode_Reward/pen_joint_torque: -0.0638
    Episode_Reward/pen_joint_accel: -0.0317
    Episode_Reward/pen_action_rate: -0.0664
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0131
   Episode_Reward/pen_joint_powers: -0.0230
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1323
Episode_Reward/pen_flat_orientation: -0.1247
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0792
   Episode_Reward/foot_landing_vel: -0.0528
   Episode_Reward/test_gait_reward: -0.3533
Metrics/base_velocity/error_vel_xy: 1.1593
Metrics/base_velocity/error_vel_yaw: 0.3494
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 1.09s
                        Total time: 600.72s
                               ETA: 2653.4s

################################################################################
                     [1m Learning iteration 554/3000 [0m                      

                       Computation: 89751 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 1.0930
                    Surrogate loss: 0.0013
             Mean action noise std: 0.4489
                     Learning rate: 0.0006
                       Mean reward: 17.21
               Mean episode length: 297.61
       Episode_Reward/keep_balance: 0.2986
     Episode_Reward/rew_lin_vel_xy: 0.6925
      Episode_Reward/rew_ang_vel_z: 0.9004
    Episode_Reward/pen_base_height: -0.2049
      Episode_Reward/pen_lin_vel_z: -0.0342
     Episode_Reward/pen_ang_vel_xy: -0.0456
   Episode_Reward/pen_joint_torque: -0.0483
    Episode_Reward/pen_joint_accel: -0.0257
    Episode_Reward/pen_action_rate: -0.0505
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0097
   Episode_Reward/pen_joint_powers: -0.0171
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1040
Episode_Reward/pen_flat_orientation: -0.1036
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0591
   Episode_Reward/foot_landing_vel: -0.0383
   Episode_Reward/test_gait_reward: -0.2786
Metrics/base_velocity/error_vel_xy: 0.9719
Metrics/base_velocity/error_vel_yaw: 0.2728
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 1.10s
                        Total time: 601.82s
                               ETA: 2652.3s

################################################################################
                     [1m Learning iteration 555/3000 [0m                      

                       Computation: 91162 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 1.0719
                    Surrogate loss: -0.0016
             Mean action noise std: 0.4497
                     Learning rate: 0.0006
                       Mean reward: 18.72
               Mean episode length: 320.31
       Episode_Reward/keep_balance: 0.3498
     Episode_Reward/rew_lin_vel_xy: 0.8164
      Episode_Reward/rew_ang_vel_z: 1.0536
    Episode_Reward/pen_base_height: -0.2199
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.0505
   Episode_Reward/pen_joint_torque: -0.0567
    Episode_Reward/pen_joint_accel: -0.0293
    Episode_Reward/pen_action_rate: -0.0596
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0111
   Episode_Reward/pen_joint_powers: -0.0199
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1216
Episode_Reward/pen_flat_orientation: -0.1135
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0658
   Episode_Reward/foot_landing_vel: -0.0436
   Episode_Reward/test_gait_reward: -0.3259
Metrics/base_velocity/error_vel_xy: 1.0972
Metrics/base_velocity/error_vel_yaw: 0.3168
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 1.08s
                        Total time: 602.89s
                               ETA: 2651.2s

################################################################################
                     [1m Learning iteration 556/3000 [0m                      

                       Computation: 91415 steps/s (collection: 0.948s, learning 0.127s)
               Value function loss: 1.0980
                    Surrogate loss: -0.0025
             Mean action noise std: 0.4501
                     Learning rate: 0.0013
                       Mean reward: 24.25
               Mean episode length: 368.37
       Episode_Reward/keep_balance: 0.3604
     Episode_Reward/rew_lin_vel_xy: 0.8169
      Episode_Reward/rew_ang_vel_z: 1.0891
    Episode_Reward/pen_base_height: -0.2234
      Episode_Reward/pen_lin_vel_z: -0.0389
     Episode_Reward/pen_ang_vel_xy: -0.0525
   Episode_Reward/pen_joint_torque: -0.0600
    Episode_Reward/pen_joint_accel: -0.0313
    Episode_Reward/pen_action_rate: -0.0617
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0114
   Episode_Reward/pen_joint_powers: -0.0207
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1267
Episode_Reward/pen_flat_orientation: -0.1137
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0646
   Episode_Reward/foot_landing_vel: -0.0446
   Episode_Reward/test_gait_reward: -0.3356
Metrics/base_velocity/error_vel_xy: 1.1694
Metrics/base_velocity/error_vel_yaw: 0.3256
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 1.08s
                        Total time: 603.97s
                               ETA: 2650.1s

################################################################################
                     [1m Learning iteration 557/3000 [0m                      

                       Computation: 90774 steps/s (collection: 0.954s, learning 0.129s)
               Value function loss: 1.7252
                    Surrogate loss: 0.0001
             Mean action noise std: 0.4511
                     Learning rate: 0.0009
                       Mean reward: 15.88
               Mean episode length: 264.82
       Episode_Reward/keep_balance: 0.3207
     Episode_Reward/rew_lin_vel_xy: 0.7662
      Episode_Reward/rew_ang_vel_z: 0.9715
    Episode_Reward/pen_base_height: -0.2091
      Episode_Reward/pen_lin_vel_z: -0.0348
     Episode_Reward/pen_ang_vel_xy: -0.0469
   Episode_Reward/pen_joint_torque: -0.0503
    Episode_Reward/pen_joint_accel: -0.0270
    Episode_Reward/pen_action_rate: -0.0539
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0101
   Episode_Reward/pen_joint_powers: -0.0178
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1117
Episode_Reward/pen_flat_orientation: -0.1053
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0575
   Episode_Reward/foot_landing_vel: -0.0396
   Episode_Reward/test_gait_reward: -0.2986
Metrics/base_velocity/error_vel_xy: 0.9891
Metrics/base_velocity/error_vel_yaw: 0.2885
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 1.08s
                        Total time: 605.05s
                               ETA: 2649.0s

################################################################################
                     [1m Learning iteration 558/3000 [0m                      

                       Computation: 91251 steps/s (collection: 0.949s, learning 0.129s)
               Value function loss: 1.2137
                    Surrogate loss: 0.0004
             Mean action noise std: 0.4517
                     Learning rate: 0.0009
                       Mean reward: 15.57
               Mean episode length: 280.91
       Episode_Reward/keep_balance: 0.3178
     Episode_Reward/rew_lin_vel_xy: 0.7579
      Episode_Reward/rew_ang_vel_z: 0.9541
    Episode_Reward/pen_base_height: -0.2088
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.0482
   Episode_Reward/pen_joint_torque: -0.0524
    Episode_Reward/pen_joint_accel: -0.0283
    Episode_Reward/pen_action_rate: -0.0543
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0105
   Episode_Reward/pen_joint_powers: -0.0185
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1116
Episode_Reward/pen_flat_orientation: -0.1057
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0614
   Episode_Reward/foot_landing_vel: -0.0412
   Episode_Reward/test_gait_reward: -0.2967
Metrics/base_velocity/error_vel_xy: 0.9967
Metrics/base_velocity/error_vel_yaw: 0.2922
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 1.08s
                        Total time: 606.13s
                               ETA: 2647.9s

################################################################################
                     [1m Learning iteration 559/3000 [0m                      

                       Computation: 86836 steps/s (collection: 0.993s, learning 0.139s)
               Value function loss: 1.1885
                    Surrogate loss: -0.0016
             Mean action noise std: 0.4521
                     Learning rate: 0.0009
                       Mean reward: 16.37
               Mean episode length: 283.87
       Episode_Reward/keep_balance: 0.3144
     Episode_Reward/rew_lin_vel_xy: 0.6910
      Episode_Reward/rew_ang_vel_z: 0.9503
    Episode_Reward/pen_base_height: -0.2082
      Episode_Reward/pen_lin_vel_z: -0.0344
     Episode_Reward/pen_ang_vel_xy: -0.0472
   Episode_Reward/pen_joint_torque: -0.0515
    Episode_Reward/pen_joint_accel: -0.0272
    Episode_Reward/pen_action_rate: -0.0533
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0100
   Episode_Reward/pen_joint_powers: -0.0178
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1101
Episode_Reward/pen_flat_orientation: -0.1041
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0574
   Episode_Reward/foot_landing_vel: -0.0409
   Episode_Reward/test_gait_reward: -0.2934
Metrics/base_velocity/error_vel_xy: 1.0265
Metrics/base_velocity/error_vel_yaw: 0.2854
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 1.13s
                        Total time: 607.26s
                               ETA: 2647.0s

################################################################################
                     [1m Learning iteration 560/3000 [0m                      

                       Computation: 90063 steps/s (collection: 0.962s, learning 0.130s)
               Value function loss: 1.0883
                    Surrogate loss: 0.0009
             Mean action noise std: 0.4524
                     Learning rate: 0.0004
                       Mean reward: 19.82
               Mean episode length: 341.12
       Episode_Reward/keep_balance: 0.3286
     Episode_Reward/rew_lin_vel_xy: 0.7247
      Episode_Reward/rew_ang_vel_z: 0.9820
    Episode_Reward/pen_base_height: -0.2199
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.0509
   Episode_Reward/pen_joint_torque: -0.0555
    Episode_Reward/pen_joint_accel: -0.0303
    Episode_Reward/pen_action_rate: -0.0574
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0114
   Episode_Reward/pen_joint_powers: -0.0197
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1175
Episode_Reward/pen_flat_orientation: -0.1136
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0680
   Episode_Reward/foot_landing_vel: -0.0467
   Episode_Reward/test_gait_reward: -0.3085
Metrics/base_velocity/error_vel_xy: 1.0590
Metrics/base_velocity/error_vel_yaw: 0.3059
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 1.09s
                        Total time: 608.35s
                               ETA: 2646.0s

################################################################################
                     [1m Learning iteration 561/3000 [0m                      

                       Computation: 90067 steps/s (collection: 0.963s, learning 0.129s)
               Value function loss: 1.1008
                    Surrogate loss: 0.0005
             Mean action noise std: 0.4530
                     Learning rate: 0.0006
                       Mean reward: 17.67
               Mean episode length: 322.13
       Episode_Reward/keep_balance: 0.2965
     Episode_Reward/rew_lin_vel_xy: 0.6681
      Episode_Reward/rew_ang_vel_z: 0.8905
    Episode_Reward/pen_base_height: -0.2107
      Episode_Reward/pen_lin_vel_z: -0.0349
     Episode_Reward/pen_ang_vel_xy: -0.0470
   Episode_Reward/pen_joint_torque: -0.0490
    Episode_Reward/pen_joint_accel: -0.0283
    Episode_Reward/pen_action_rate: -0.0513
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0103
   Episode_Reward/pen_joint_powers: -0.0174
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.1055
Episode_Reward/pen_flat_orientation: -0.1038
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0602
   Episode_Reward/foot_landing_vel: -0.0421
   Episode_Reward/test_gait_reward: -0.2785
Metrics/base_velocity/error_vel_xy: 0.9474
Metrics/base_velocity/error_vel_yaw: 0.2730
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 1.09s
                        Total time: 609.44s
                               ETA: 2644.9s

################################################################################
                     [1m Learning iteration 562/3000 [0m                      

                       Computation: 89660 steps/s (collection: 0.967s, learning 0.129s)
               Value function loss: 1.1125
                    Surrogate loss: -0.0005
             Mean action noise std: 0.4538
                     Learning rate: 0.0009
                       Mean reward: 16.49
               Mean episode length: 279.38
       Episode_Reward/keep_balance: 0.2904
     Episode_Reward/rew_lin_vel_xy: 0.6775
      Episode_Reward/rew_ang_vel_z: 0.8667
    Episode_Reward/pen_base_height: -0.2059
      Episode_Reward/pen_lin_vel_z: -0.0342
     Episode_Reward/pen_ang_vel_xy: -0.0459
   Episode_Reward/pen_joint_torque: -0.0477
    Episode_Reward/pen_joint_accel: -0.0259
    Episode_Reward/pen_action_rate: -0.0501
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0096
   Episode_Reward/pen_joint_powers: -0.0168
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1039
Episode_Reward/pen_flat_orientation: -0.1030
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0570
   Episode_Reward/foot_landing_vel: -0.0391
   Episode_Reward/test_gait_reward: -0.2726
Metrics/base_velocity/error_vel_xy: 0.9127
Metrics/base_velocity/error_vel_yaw: 0.2717
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 1.10s
                        Total time: 610.54s
                               ETA: 2643.9s

################################################################################
                     [1m Learning iteration 563/3000 [0m                      

                       Computation: 89403 steps/s (collection: 0.973s, learning 0.127s)
               Value function loss: 1.5324
                    Surrogate loss: 0.0037
             Mean action noise std: 0.4540
                     Learning rate: 0.0000
                       Mean reward: 21.83
               Mean episode length: 338.65
       Episode_Reward/keep_balance: 0.3269
     Episode_Reward/rew_lin_vel_xy: 0.7672
      Episode_Reward/rew_ang_vel_z: 0.9861
    Episode_Reward/pen_base_height: -0.2143
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.0490
   Episode_Reward/pen_joint_torque: -0.0561
    Episode_Reward/pen_joint_accel: -0.0284
    Episode_Reward/pen_action_rate: -0.0562
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0104
   Episode_Reward/pen_joint_powers: -0.0190
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1151
Episode_Reward/pen_flat_orientation: -0.1049
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0605
   Episode_Reward/foot_landing_vel: -0.0407
   Episode_Reward/test_gait_reward: -0.3047
Metrics/base_velocity/error_vel_xy: 1.0244
Metrics/base_velocity/error_vel_yaw: 0.2956
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 14.0833
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 1.10s
                        Total time: 611.64s
                               ETA: 2642.9s

################################################################################
                     [1m Learning iteration 564/3000 [0m                      

                       Computation: 89259 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 1.0047
                    Surrogate loss: -0.0011
             Mean action noise std: 0.4542
                     Learning rate: 0.0003
                       Mean reward: 18.60
               Mean episode length: 326.41
       Episode_Reward/keep_balance: 0.2908
     Episode_Reward/rew_lin_vel_xy: 0.6726
      Episode_Reward/rew_ang_vel_z: 0.8750
    Episode_Reward/pen_base_height: -0.2033
      Episode_Reward/pen_lin_vel_z: -0.0329
     Episode_Reward/pen_ang_vel_xy: -0.0457
   Episode_Reward/pen_joint_torque: -0.0465
    Episode_Reward/pen_joint_accel: -0.0244
    Episode_Reward/pen_action_rate: -0.0501
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0094
   Episode_Reward/pen_joint_powers: -0.0163
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1039
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0559
   Episode_Reward/foot_landing_vel: -0.0370
   Episode_Reward/test_gait_reward: -0.2732
Metrics/base_velocity/error_vel_xy: 0.9078
Metrics/base_velocity/error_vel_yaw: 0.2666
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 1.10s
                        Total time: 612.74s
                               ETA: 2641.8s

################################################################################
                     [1m Learning iteration 565/3000 [0m                      

                       Computation: 90151 steps/s (collection: 0.965s, learning 0.125s)
               Value function loss: 1.0467
                    Surrogate loss: -0.0021
             Mean action noise std: 0.4552
                     Learning rate: 0.0009
                       Mean reward: 15.85
               Mean episode length: 309.38
       Episode_Reward/keep_balance: 0.2864
     Episode_Reward/rew_lin_vel_xy: 0.6724
      Episode_Reward/rew_ang_vel_z: 0.8528
    Episode_Reward/pen_base_height: -0.2046
      Episode_Reward/pen_lin_vel_z: -0.0319
     Episode_Reward/pen_ang_vel_xy: -0.0451
   Episode_Reward/pen_joint_torque: -0.0468
    Episode_Reward/pen_joint_accel: -0.0247
    Episode_Reward/pen_action_rate: -0.0491
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0093
   Episode_Reward/pen_joint_powers: -0.0163
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1024
Episode_Reward/pen_flat_orientation: -0.0998
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0532
   Episode_Reward/foot_landing_vel: -0.0371
   Episode_Reward/test_gait_reward: -0.2684
Metrics/base_velocity/error_vel_xy: 0.8937
Metrics/base_velocity/error_vel_yaw: 0.2677
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 1.09s
                        Total time: 613.83s
                               ETA: 2640.8s

################################################################################
                     [1m Learning iteration 566/3000 [0m                      

                       Computation: 88853 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 1.0253
                    Surrogate loss: -0.0021
             Mean action noise std: 0.4557
                     Learning rate: 0.0013
                       Mean reward: 16.39
               Mean episode length: 294.24
       Episode_Reward/keep_balance: 0.2983
     Episode_Reward/rew_lin_vel_xy: 0.7225
      Episode_Reward/rew_ang_vel_z: 0.8879
    Episode_Reward/pen_base_height: -0.2083
      Episode_Reward/pen_lin_vel_z: -0.0334
     Episode_Reward/pen_ang_vel_xy: -0.0461
   Episode_Reward/pen_joint_torque: -0.0505
    Episode_Reward/pen_joint_accel: -0.0239
    Episode_Reward/pen_action_rate: -0.0509
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0096
   Episode_Reward/pen_joint_powers: -0.0173
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1057
Episode_Reward/pen_flat_orientation: -0.1021
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0570
   Episode_Reward/foot_landing_vel: -0.0378
   Episode_Reward/test_gait_reward: -0.2792
Metrics/base_velocity/error_vel_xy: 0.9087
Metrics/base_velocity/error_vel_yaw: 0.2794
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 11.0417
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 1.11s
                        Total time: 614.94s
                               ETA: 2639.8s

################################################################################
                     [1m Learning iteration 567/3000 [0m                      

                       Computation: 90470 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 1.0271
                    Surrogate loss: 0.0048
             Mean action noise std: 0.4563
                     Learning rate: 0.0003
                       Mean reward: 16.13
               Mean episode length: 274.95
       Episode_Reward/keep_balance: 0.2825
     Episode_Reward/rew_lin_vel_xy: 0.6729
      Episode_Reward/rew_ang_vel_z: 0.8378
    Episode_Reward/pen_base_height: -0.2052
      Episode_Reward/pen_lin_vel_z: -0.0342
     Episode_Reward/pen_ang_vel_xy: -0.0465
   Episode_Reward/pen_joint_torque: -0.0479
    Episode_Reward/pen_joint_accel: -0.0257
    Episode_Reward/pen_action_rate: -0.0495
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0100
   Episode_Reward/pen_joint_powers: -0.0170
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1022
Episode_Reward/pen_flat_orientation: -0.1042
  Episode_Reward/pen_feet_distance: 0.0000
Episode_Reward/pen_feet_regulation: -0.0607
   Episode_Reward/foot_landing_vel: -0.0390
   Episode_Reward/test_gait_reward: -0.2664
Metrics/base_velocity/error_vel_xy: 0.8809
Metrics/base_velocity/error_vel_yaw: 0.2671
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 1.09s
                        Total time: 616.03s
                               ETA: 2638.7s

################################################################################
                     [1m Learning iteration 568/3000 [0m                      

                       Computation: 89879 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 1.0345
                    Surrogate loss: 0.0017
             Mean action noise std: 0.4570
                     Learning rate: 0.0002
                       Mean reward: 18.93
               Mean episode length: 330.07
       Episode_Reward/keep_balance: 0.2943
     Episode_Reward/rew_lin_vel_xy: 0.6786
      Episode_Reward/rew_ang_vel_z: 0.8739
    Episode_Reward/pen_base_height: -0.2093
      Episode_Reward/pen_lin_vel_z: -0.0350
     Episode_Reward/pen_ang_vel_xy: -0.0465
   Episode_Reward/pen_joint_torque: -0.0515
    Episode_Reward/pen_joint_accel: -0.0246
    Episode_Reward/pen_action_rate: -0.0516
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0100
   Episode_Reward/pen_joint_powers: -0.0177
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1054
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0611
   Episode_Reward/foot_landing_vel: -0.0390
   Episode_Reward/test_gait_reward: -0.2759
Metrics/base_velocity/error_vel_xy: 0.9423
Metrics/base_velocity/error_vel_yaw: 0.2766
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 1.09s
                        Total time: 617.12s
                               ETA: 2637.7s

################################################################################
                     [1m Learning iteration 569/3000 [0m                      

                       Computation: 90285 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.9378
                    Surrogate loss: 0.0028
             Mean action noise std: 0.4573
                     Learning rate: 0.0001
                       Mean reward: 20.31
               Mean episode length: 337.39
       Episode_Reward/keep_balance: 0.3454
     Episode_Reward/rew_lin_vel_xy: 0.8222
      Episode_Reward/rew_ang_vel_z: 1.0344
    Episode_Reward/pen_base_height: -0.2264
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.0520
   Episode_Reward/pen_joint_torque: -0.0623
    Episode_Reward/pen_joint_accel: -0.0313
    Episode_Reward/pen_action_rate: -0.0620
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0119
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1258
Episode_Reward/pen_flat_orientation: -0.1128
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0756
   Episode_Reward/foot_landing_vel: -0.0481
   Episode_Reward/test_gait_reward: -0.3232
Metrics/base_velocity/error_vel_xy: 1.0722
Metrics/base_velocity/error_vel_yaw: 0.3207
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 1.09s
                        Total time: 618.21s
                               ETA: 2636.6s

################################################################################
                     [1m Learning iteration 570/3000 [0m                      

                       Computation: 91785 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.7876
                    Surrogate loss: -0.0017
             Mean action noise std: 0.4577
                     Learning rate: 0.0003
                       Mean reward: 15.70
               Mean episode length: 296.41
       Episode_Reward/keep_balance: 0.3028
     Episode_Reward/rew_lin_vel_xy: 0.6652
      Episode_Reward/rew_ang_vel_z: 0.9072
    Episode_Reward/pen_base_height: -0.2150
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.0481
   Episode_Reward/pen_joint_torque: -0.0515
    Episode_Reward/pen_joint_accel: -0.0265
    Episode_Reward/pen_action_rate: -0.0537
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0104
   Episode_Reward/pen_joint_powers: -0.0181
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1105
Episode_Reward/pen_flat_orientation: -0.1018
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0640
   Episode_Reward/foot_landing_vel: -0.0416
   Episode_Reward/test_gait_reward: -0.2854
Metrics/base_velocity/error_vel_xy: 1.0015
Metrics/base_velocity/error_vel_yaw: 0.2797
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 1.07s
                        Total time: 619.28s
                               ETA: 2635.5s

################################################################################
                     [1m Learning iteration 571/3000 [0m                      

                       Computation: 92078 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 0.9866
                    Surrogate loss: -0.0022
             Mean action noise std: 0.4582
                     Learning rate: 0.0006
                       Mean reward: 18.62
               Mean episode length: 312.78
       Episode_Reward/keep_balance: 0.3039
     Episode_Reward/rew_lin_vel_xy: 0.7274
      Episode_Reward/rew_ang_vel_z: 0.9093
    Episode_Reward/pen_base_height: -0.2124
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.0472
   Episode_Reward/pen_joint_torque: -0.0520
    Episode_Reward/pen_joint_accel: -0.0274
    Episode_Reward/pen_action_rate: -0.0532
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0100
   Episode_Reward/pen_joint_powers: -0.0177
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1103
Episode_Reward/pen_flat_orientation: -0.1024
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0612
   Episode_Reward/foot_landing_vel: -0.0397
   Episode_Reward/test_gait_reward: -0.2865
Metrics/base_velocity/error_vel_xy: 0.9556
Metrics/base_velocity/error_vel_yaw: 0.2814
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 1.07s
                        Total time: 620.35s
                               ETA: 2634.3s

################################################################################
                     [1m Learning iteration 572/3000 [0m                      

                       Computation: 91135 steps/s (collection: 0.953s, learning 0.126s)
               Value function loss: 1.0735
                    Surrogate loss: -0.0009
             Mean action noise std: 0.4590
                     Learning rate: 0.0013
                       Mean reward: 19.71
               Mean episode length: 340.36
       Episode_Reward/keep_balance: 0.3399
     Episode_Reward/rew_lin_vel_xy: 0.7381
      Episode_Reward/rew_ang_vel_z: 1.0128
    Episode_Reward/pen_base_height: -0.2324
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.0510
   Episode_Reward/pen_joint_torque: -0.0590
    Episode_Reward/pen_joint_accel: -0.0308
    Episode_Reward/pen_action_rate: -0.0614
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0118
   Episode_Reward/pen_joint_powers: -0.0204
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1248
Episode_Reward/pen_flat_orientation: -0.1068
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0739
   Episode_Reward/foot_landing_vel: -0.0449
   Episode_Reward/test_gait_reward: -0.3184
Metrics/base_velocity/error_vel_xy: 1.1110
Metrics/base_velocity/error_vel_yaw: 0.3178
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 1.08s
                        Total time: 621.43s
                               ETA: 2633.2s

################################################################################
                     [1m Learning iteration 573/3000 [0m                      

                       Computation: 89448 steps/s (collection: 0.974s, learning 0.125s)
               Value function loss: 1.0714
                    Surrogate loss: 0.0126
             Mean action noise std: 0.4597
                     Learning rate: 0.0000
                       Mean reward: 14.49
               Mean episode length: 276.65
       Episode_Reward/keep_balance: 0.2810
     Episode_Reward/rew_lin_vel_xy: 0.6525
      Episode_Reward/rew_ang_vel_z: 0.8398
    Episode_Reward/pen_base_height: -0.2056
      Episode_Reward/pen_lin_vel_z: -0.0333
     Episode_Reward/pen_ang_vel_xy: -0.0455
   Episode_Reward/pen_joint_torque: -0.0473
    Episode_Reward/pen_joint_accel: -0.0247
    Episode_Reward/pen_action_rate: -0.0494
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0095
   Episode_Reward/pen_joint_powers: -0.0166
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1024
Episode_Reward/pen_flat_orientation: -0.1007
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0593
   Episode_Reward/foot_landing_vel: -0.0381
   Episode_Reward/test_gait_reward: -0.2659
Metrics/base_velocity/error_vel_xy: 0.9077
Metrics/base_velocity/error_vel_yaw: 0.2628
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 1.10s
                        Total time: 622.52s
                               ETA: 2632.2s

################################################################################
                     [1m Learning iteration 574/3000 [0m                      

                       Computation: 90752 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.9711
                    Surrogate loss: 0.0056
             Mean action noise std: 0.4598
                     Learning rate: 0.0000
                       Mean reward: 16.13
               Mean episode length: 288.07
       Episode_Reward/keep_balance: 0.2742
     Episode_Reward/rew_lin_vel_xy: 0.6276
      Episode_Reward/rew_ang_vel_z: 0.8159
    Episode_Reward/pen_base_height: -0.2031
      Episode_Reward/pen_lin_vel_z: -0.0312
     Episode_Reward/pen_ang_vel_xy: -0.0439
   Episode_Reward/pen_joint_torque: -0.0444
    Episode_Reward/pen_joint_accel: -0.0242
    Episode_Reward/pen_action_rate: -0.0476
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0093
   Episode_Reward/pen_joint_powers: -0.0158
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1008
Episode_Reward/pen_flat_orientation: -0.0993
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0556
   Episode_Reward/foot_landing_vel: -0.0373
   Episode_Reward/test_gait_reward: -0.2596
Metrics/base_velocity/error_vel_xy: 0.8630
Metrics/base_velocity/error_vel_yaw: 0.2592
      Episode_Termination/time_out: 0.6667
  Episode_Termination/base_contact: 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 1.08s
                        Total time: 623.61s
                               ETA: 2631.1s

################################################################################
                     [1m Learning iteration 575/3000 [0m                      

                       Computation: 91110 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 1.0402
                    Surrogate loss: 0.0047
             Mean action noise std: 0.4599
                     Learning rate: 0.0001
                       Mean reward: 17.96
               Mean episode length: 341.76
       Episode_Reward/keep_balance: 0.3205
     Episode_Reward/rew_lin_vel_xy: 0.6887
      Episode_Reward/rew_ang_vel_z: 0.9629
    Episode_Reward/pen_base_height: -0.2137
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.0487
   Episode_Reward/pen_joint_torque: -0.0560
    Episode_Reward/pen_joint_accel: -0.0287
    Episode_Reward/pen_action_rate: -0.0567
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0106
   Episode_Reward/pen_joint_powers: -0.0190
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1179
Episode_Reward/pen_flat_orientation: -0.1044
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0621
   Episode_Reward/foot_landing_vel: -0.0410
   Episode_Reward/test_gait_reward: -0.2999
Metrics/base_velocity/error_vel_xy: 1.0315
Metrics/base_velocity/error_vel_yaw: 0.2942
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 1.08s
                        Total time: 624.69s
                               ETA: 2630.0s

################################################################################
                     [1m Learning iteration 576/3000 [0m                      

                       Computation: 91888 steps/s (collection: 0.946s, learning 0.124s)
               Value function loss: 1.0176
                    Surrogate loss: 0.0004
             Mean action noise std: 0.4601
                     Learning rate: 0.0001
                       Mean reward: 16.76
               Mean episode length: 297.09
       Episode_Reward/keep_balance: 0.3029
     Episode_Reward/rew_lin_vel_xy: 0.6900
      Episode_Reward/rew_ang_vel_z: 0.9177
    Episode_Reward/pen_base_height: -0.2089
      Episode_Reward/pen_lin_vel_z: -0.0348
     Episode_Reward/pen_ang_vel_xy: -0.0479
   Episode_Reward/pen_joint_torque: -0.0512
    Episode_Reward/pen_joint_accel: -0.0265
    Episode_Reward/pen_action_rate: -0.0531
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0101
   Episode_Reward/pen_joint_powers: -0.0179
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1095
Episode_Reward/pen_flat_orientation: -0.1030
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0594
   Episode_Reward/foot_landing_vel: -0.0410
   Episode_Reward/test_gait_reward: -0.2857
Metrics/base_velocity/error_vel_xy: 0.9695
Metrics/base_velocity/error_vel_yaw: 0.2725
      Episode_Termination/time_out: 1.0000
  Episode_Termination/base_contact: 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 1.07s
                        Total time: 625.76s
                               ETA: 2628.8s

################################################################################
                     [1m Learning iteration 577/3000 [0m                      

                       Computation: 91608 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.9032
                    Surrogate loss: -0.0015
             Mean action noise std: 0.4607
                     Learning rate: 0.0003
                       Mean reward: 20.44
               Mean episode length: 341.81
       Episode_Reward/keep_balance: 0.3221
     Episode_Reward/rew_lin_vel_xy: 0.7158
      Episode_Reward/rew_ang_vel_z: 0.9740
    Episode_Reward/pen_base_height: -0.2146
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.0481
   Episode_Reward/pen_joint_torque: -0.0536
    Episode_Reward/pen_joint_accel: -0.0276
    Episode_Reward/pen_action_rate: -0.0568
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0104
   Episode_Reward/pen_joint_powers: -0.0184
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1188
Episode_Reward/pen_flat_orientation: -0.1042
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0623
   Episode_Reward/foot_landing_vel: -0.0420
   Episode_Reward/test_gait_reward: -0.3017
Metrics/base_velocity/error_vel_xy: 1.0440
Metrics/base_velocity/error_vel_yaw: 0.2917
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 1.07s
                        Total time: 626.83s
                               ETA: 2627.7s

################################################################################
                     [1m Learning iteration 578/3000 [0m                      

                       Computation: 90413 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.9953
                    Surrogate loss: -0.0019
             Mean action noise std: 0.4614
                     Learning rate: 0.0006
                       Mean reward: 18.09
               Mean episode length: 315.46
       Episode_Reward/keep_balance: 0.3336
     Episode_Reward/rew_lin_vel_xy: 0.8188
      Episode_Reward/rew_ang_vel_z: 1.0009
    Episode_Reward/pen_base_height: -0.2206
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.0506
   Episode_Reward/pen_joint_torque: -0.0561
    Episode_Reward/pen_joint_accel: -0.0287
    Episode_Reward/pen_action_rate: -0.0592
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0110
   Episode_Reward/pen_joint_powers: -0.0195
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1239
Episode_Reward/pen_flat_orientation: -0.1115
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0651
   Episode_Reward/foot_landing_vel: -0.0446
   Episode_Reward/test_gait_reward: -0.3130
Metrics/base_velocity/error_vel_xy: 1.0464
Metrics/base_velocity/error_vel_yaw: 0.3076
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 15.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 1.09s
                        Total time: 627.92s
                               ETA: 2626.6s

################################################################################
                     [1m Learning iteration 579/3000 [0m                      

                       Computation: 91385 steps/s (collection: 0.951s, learning 0.124s)
               Value function loss: 1.2592
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4617
                     Learning rate: 0.0013
                       Mean reward: 19.09
               Mean episode length: 309.71
       Episode_Reward/keep_balance: 0.3171
     Episode_Reward/rew_lin_vel_xy: 0.7805
      Episode_Reward/rew_ang_vel_z: 0.9642
    Episode_Reward/pen_base_height: -0.2092
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.0494
   Episode_Reward/pen_joint_torque: -0.0536
    Episode_Reward/pen_joint_accel: -0.0269
    Episode_Reward/pen_action_rate: -0.0562
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0103
   Episode_Reward/pen_joint_powers: -0.0184
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1167
Episode_Reward/pen_flat_orientation: -0.1096
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0607
   Episode_Reward/foot_landing_vel: -0.0417
   Episode_Reward/test_gait_reward: -0.2984
Metrics/base_velocity/error_vel_xy: 0.9804
Metrics/base_velocity/error_vel_yaw: 0.2832
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 1.08s
                        Total time: 628.99s
                               ETA: 2625.5s

################################################################################
                     [1m Learning iteration 580/3000 [0m                      

                       Computation: 91314 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 1.4065
                    Surrogate loss: 0.0026
             Mean action noise std: 0.4616
                     Learning rate: 0.0004
                       Mean reward: 15.53
               Mean episode length: 274.09
       Episode_Reward/keep_balance: 0.2638
     Episode_Reward/rew_lin_vel_xy: 0.5919
      Episode_Reward/rew_ang_vel_z: 0.7983
    Episode_Reward/pen_base_height: -0.1949
      Episode_Reward/pen_lin_vel_z: -0.0293
     Episode_Reward/pen_ang_vel_xy: -0.0420
   Episode_Reward/pen_joint_torque: -0.0425
    Episode_Reward/pen_joint_accel: -0.0238
    Episode_Reward/pen_action_rate: -0.0455
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0084
   Episode_Reward/pen_joint_powers: -0.0147
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0964
Episode_Reward/pen_flat_orientation: -0.0981
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0496
   Episode_Reward/foot_landing_vel: -0.0327
   Episode_Reward/test_gait_reward: -0.2490
Metrics/base_velocity/error_vel_xy: 0.8587
Metrics/base_velocity/error_vel_yaw: 0.2393
      Episode_Termination/time_out: 0.9167
  Episode_Termination/base_contact: 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 1.08s
                        Total time: 630.07s
                               ETA: 2624.4s

################################################################################
                     [1m Learning iteration 581/3000 [0m                      

                       Computation: 90543 steps/s (collection: 0.960s, learning 0.126s)
               Value function loss: 1.1166
                    Surrogate loss: 0.0007
             Mean action noise std: 0.4623
                     Learning rate: 0.0006
                       Mean reward: 14.05
               Mean episode length: 285.87
       Episode_Reward/keep_balance: 0.2842
     Episode_Reward/rew_lin_vel_xy: 0.6971
      Episode_Reward/rew_ang_vel_z: 0.8609
    Episode_Reward/pen_base_height: -0.2039
      Episode_Reward/pen_lin_vel_z: -0.0320
     Episode_Reward/pen_ang_vel_xy: -0.0450
   Episode_Reward/pen_joint_torque: -0.0474
    Episode_Reward/pen_joint_accel: -0.0238
    Episode_Reward/pen_action_rate: -0.0497
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0093
   Episode_Reward/pen_joint_powers: -0.0164
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1035
Episode_Reward/pen_flat_orientation: -0.1006
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0553
   Episode_Reward/foot_landing_vel: -0.0367
   Episode_Reward/test_gait_reward: -0.2681
Metrics/base_velocity/error_vel_xy: 0.8830
Metrics/base_velocity/error_vel_yaw: 0.2567
      Episode_Termination/time_out: 0.9167
  Episode_Termination/base_contact: 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 1.09s
                        Total time: 631.15s
                               ETA: 2623.3s

################################################################################
                     [1m Learning iteration 582/3000 [0m                      

                       Computation: 91108 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 1.2161
                    Surrogate loss: -0.0018
             Mean action noise std: 0.4634
                     Learning rate: 0.0013
                       Mean reward: 22.58
               Mean episode length: 384.58
       Episode_Reward/keep_balance: 0.3215
     Episode_Reward/rew_lin_vel_xy: 0.7462
      Episode_Reward/rew_ang_vel_z: 0.9680
    Episode_Reward/pen_base_height: -0.2178
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.0505
   Episode_Reward/pen_joint_torque: -0.0550
    Episode_Reward/pen_joint_accel: -0.0278
    Episode_Reward/pen_action_rate: -0.0581
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0109
   Episode_Reward/pen_joint_powers: -0.0191
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1200
Episode_Reward/pen_flat_orientation: -0.1116
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0666
   Episode_Reward/foot_landing_vel: -0.0424
   Episode_Reward/test_gait_reward: -0.3034
Metrics/base_velocity/error_vel_xy: 1.0086
Metrics/base_velocity/error_vel_yaw: 0.2940
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 1.08s
                        Total time: 632.23s
                               ETA: 2622.2s

################################################################################
                     [1m Learning iteration 583/3000 [0m                      

                       Computation: 91208 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 1.2568
                    Surrogate loss: 0.0018
             Mean action noise std: 0.4639
                     Learning rate: 0.0009
                       Mean reward: 20.18
               Mean episode length: 343.04
       Episode_Reward/keep_balance: 0.3227
     Episode_Reward/rew_lin_vel_xy: 0.7607
      Episode_Reward/rew_ang_vel_z: 0.9627
    Episode_Reward/pen_base_height: -0.2154
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.0499
   Episode_Reward/pen_joint_torque: -0.0563
    Episode_Reward/pen_joint_accel: -0.0271
    Episode_Reward/pen_action_rate: -0.0578
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0108
   Episode_Reward/pen_joint_powers: -0.0194
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1197
Episode_Reward/pen_flat_orientation: -0.1134
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0647
   Episode_Reward/foot_landing_vel: -0.0426
   Episode_Reward/test_gait_reward: -0.3023
Metrics/base_velocity/error_vel_xy: 1.0307
Metrics/base_velocity/error_vel_yaw: 0.3008
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 1.08s
                        Total time: 633.31s
                               ETA: 2621.1s

################################################################################
                     [1m Learning iteration 584/3000 [0m                      

                       Computation: 91615 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 1.2252
                    Surrogate loss: 0.0027
             Mean action noise std: 0.4646
                     Learning rate: 0.0004
                       Mean reward: 15.09
               Mean episode length: 272.85
       Episode_Reward/keep_balance: 0.2955
     Episode_Reward/rew_lin_vel_xy: 0.7576
      Episode_Reward/rew_ang_vel_z: 0.8990
    Episode_Reward/pen_base_height: -0.2036
      Episode_Reward/pen_lin_vel_z: -0.0329
     Episode_Reward/pen_ang_vel_xy: -0.0459
   Episode_Reward/pen_joint_torque: -0.0477
    Episode_Reward/pen_joint_accel: -0.0255
    Episode_Reward/pen_action_rate: -0.0517
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0098
   Episode_Reward/pen_joint_powers: -0.0169
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1086
Episode_Reward/pen_flat_orientation: -0.1081
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0570
   Episode_Reward/foot_landing_vel: -0.0384
   Episode_Reward/test_gait_reward: -0.2790
Metrics/base_velocity/error_vel_xy: 0.9136
Metrics/base_velocity/error_vel_yaw: 0.2645
      Episode_Termination/time_out: 1.0000
  Episode_Termination/base_contact: 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 1.07s
                        Total time: 634.38s
                               ETA: 2620.0s

################################################################################
                     [1m Learning iteration 585/3000 [0m                      

                       Computation: 91792 steps/s (collection: 0.947s, learning 0.124s)
               Value function loss: 1.0405
                    Surrogate loss: 0.0033
             Mean action noise std: 0.4652
                     Learning rate: 0.0004
                       Mean reward: 16.44
               Mean episode length: 282.99
       Episode_Reward/keep_balance: 0.3011
     Episode_Reward/rew_lin_vel_xy: 0.7600
      Episode_Reward/rew_ang_vel_z: 0.9053
    Episode_Reward/pen_base_height: -0.2062
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.0482
   Episode_Reward/pen_joint_torque: -0.0515
    Episode_Reward/pen_joint_accel: -0.0271
    Episode_Reward/pen_action_rate: -0.0538
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0102
   Episode_Reward/pen_joint_powers: -0.0180
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1113
Episode_Reward/pen_flat_orientation: -0.1089
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0621
   Episode_Reward/foot_landing_vel: -0.0383
   Episode_Reward/test_gait_reward: -0.2843
Metrics/base_velocity/error_vel_xy: 0.9204
Metrics/base_velocity/error_vel_yaw: 0.2778
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 1.07s
                        Total time: 635.46s
                               ETA: 2618.8s

################################################################################
                     [1m Learning iteration 586/3000 [0m                      

                       Computation: 91395 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.9720
                    Surrogate loss: 0.0002
             Mean action noise std: 0.4657
                     Learning rate: 0.0003
                       Mean reward: 16.03
               Mean episode length: 285.92
       Episode_Reward/keep_balance: 0.3097
     Episode_Reward/rew_lin_vel_xy: 0.7884
      Episode_Reward/rew_ang_vel_z: 0.9339
    Episode_Reward/pen_base_height: -0.2077
      Episode_Reward/pen_lin_vel_z: -0.0350
     Episode_Reward/pen_ang_vel_xy: -0.0492
   Episode_Reward/pen_joint_torque: -0.0506
    Episode_Reward/pen_joint_accel: -0.0293
    Episode_Reward/pen_action_rate: -0.0556
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0106
   Episode_Reward/pen_joint_powers: -0.0181
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1160
Episode_Reward/pen_flat_orientation: -0.1152
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0625
   Episode_Reward/foot_landing_vel: -0.0419
   Episode_Reward/test_gait_reward: -0.2929
Metrics/base_velocity/error_vel_xy: 0.9401
Metrics/base_velocity/error_vel_yaw: 0.2824
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 12.7917
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 1.08s
                        Total time: 636.53s
                               ETA: 2617.7s

################################################################################
                     [1m Learning iteration 587/3000 [0m                      

                       Computation: 91098 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.9363
                    Surrogate loss: 0.0000
             Mean action noise std: 0.4666
                     Learning rate: 0.0003
                       Mean reward: 19.78
               Mean episode length: 326.89
       Episode_Reward/keep_balance: 0.3372
     Episode_Reward/rew_lin_vel_xy: 0.7893
      Episode_Reward/rew_ang_vel_z: 1.0163
    Episode_Reward/pen_base_height: -0.2194
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.0516
   Episode_Reward/pen_joint_torque: -0.0556
    Episode_Reward/pen_joint_accel: -0.0281
    Episode_Reward/pen_action_rate: -0.0601
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0110
   Episode_Reward/pen_joint_powers: -0.0196
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1257
Episode_Reward/pen_flat_orientation: -0.1185
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0671
   Episode_Reward/foot_landing_vel: -0.0419
   Episode_Reward/test_gait_reward: -0.3177
Metrics/base_velocity/error_vel_xy: 1.0503
Metrics/base_velocity/error_vel_yaw: 0.3080
      Episode_Termination/time_out: 1.0000
  Episode_Termination/base_contact: 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 1.08s
                        Total time: 637.61s
                               ETA: 2616.6s

################################################################################
                     [1m Learning iteration 588/3000 [0m                      

                       Computation: 92147 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 0.9267
                    Surrogate loss: 0.0051
             Mean action noise std: 0.4671
                     Learning rate: 0.0001
                       Mean reward: 19.69
               Mean episode length: 345.21
       Episode_Reward/keep_balance: 0.3446
     Episode_Reward/rew_lin_vel_xy: 0.8344
      Episode_Reward/rew_ang_vel_z: 1.0284
    Episode_Reward/pen_base_height: -0.2215
      Episode_Reward/pen_lin_vel_z: -0.0402
     Episode_Reward/pen_ang_vel_xy: -0.0529
   Episode_Reward/pen_joint_torque: -0.0596
    Episode_Reward/pen_joint_accel: -0.0296
    Episode_Reward/pen_action_rate: -0.0632
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0119
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1299
Episode_Reward/pen_flat_orientation: -0.1195
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0753
   Episode_Reward/foot_landing_vel: -0.0458
   Episode_Reward/test_gait_reward: -0.3272
Metrics/base_velocity/error_vel_xy: 1.0556
Metrics/base_velocity/error_vel_yaw: 0.3216
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 1.07s
                        Total time: 638.68s
                               ETA: 2615.4s

################################################################################
                     [1m Learning iteration 589/3000 [0m                      

                       Computation: 91813 steps/s (collection: 0.947s, learning 0.124s)
               Value function loss: 0.9890
                    Surrogate loss: 0.0074
             Mean action noise std: 0.4674
                     Learning rate: 0.0000
                       Mean reward: 21.76
               Mean episode length: 355.25
       Episode_Reward/keep_balance: 0.3204
     Episode_Reward/rew_lin_vel_xy: 0.7388
      Episode_Reward/rew_ang_vel_z: 0.9650
    Episode_Reward/pen_base_height: -0.2105
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.0492
   Episode_Reward/pen_joint_torque: -0.0544
    Episode_Reward/pen_joint_accel: -0.0283
    Episode_Reward/pen_action_rate: -0.0575
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0108
   Episode_Reward/pen_joint_powers: -0.0190
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1206
Episode_Reward/pen_flat_orientation: -0.1128
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0661
   Episode_Reward/foot_landing_vel: -0.0419
   Episode_Reward/test_gait_reward: -0.3019
Metrics/base_velocity/error_vel_xy: 1.0320
Metrics/base_velocity/error_vel_yaw: 0.2934
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 1.07s
                        Total time: 639.75s
                               ETA: 2614.3s

################################################################################
                     [1m Learning iteration 590/3000 [0m                      

                       Computation: 91602 steps/s (collection: 0.948s, learning 0.125s)
               Value function loss: 1.0325
                    Surrogate loss: 0.0002
             Mean action noise std: 0.4681
                     Learning rate: 0.0001
                       Mean reward: 19.91
               Mean episode length: 327.04
       Episode_Reward/keep_balance: 0.3052
     Episode_Reward/rew_lin_vel_xy: 0.7124
      Episode_Reward/rew_ang_vel_z: 0.9190
    Episode_Reward/pen_base_height: -0.2085
      Episode_Reward/pen_lin_vel_z: -0.0346
     Episode_Reward/pen_ang_vel_xy: -0.0480
   Episode_Reward/pen_joint_torque: -0.0505
    Episode_Reward/pen_joint_accel: -0.0266
    Episode_Reward/pen_action_rate: -0.0548
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0103
   Episode_Reward/pen_joint_powers: -0.0179
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1152
Episode_Reward/pen_flat_orientation: -0.1115
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0632
   Episode_Reward/foot_landing_vel: -0.0391
   Episode_Reward/test_gait_reward: -0.2902
Metrics/base_velocity/error_vel_xy: 0.9892
Metrics/base_velocity/error_vel_yaw: 0.2820
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 1.07s
                        Total time: 640.82s
                               ETA: 2613.2s

################################################################################
                     [1m Learning iteration 591/3000 [0m                      

                       Computation: 90801 steps/s (collection: 0.958s, learning 0.125s)
               Value function loss: 1.1154
                    Surrogate loss: 0.0006
             Mean action noise std: 0.4688
                     Learning rate: 0.0004
                       Mean reward: 19.15
               Mean episode length: 315.80
       Episode_Reward/keep_balance: 0.3164
     Episode_Reward/rew_lin_vel_xy: 0.7727
      Episode_Reward/rew_ang_vel_z: 0.9564
    Episode_Reward/pen_base_height: -0.2122
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.0497
   Episode_Reward/pen_joint_torque: -0.0522
    Episode_Reward/pen_joint_accel: -0.0292
    Episode_Reward/pen_action_rate: -0.0571
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0107
   Episode_Reward/pen_joint_powers: -0.0186
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1201
Episode_Reward/pen_flat_orientation: -0.1178
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0640
   Episode_Reward/foot_landing_vel: -0.0413
   Episode_Reward/test_gait_reward: -0.2991
Metrics/base_velocity/error_vel_xy: 0.9799
Metrics/base_velocity/error_vel_yaw: 0.2867
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 1.08s
                        Total time: 641.90s
                               ETA: 2612.1s

################################################################################
                     [1m Learning iteration 592/3000 [0m                      

                       Computation: 89843 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 1.1638
                    Surrogate loss: -0.0002
             Mean action noise std: 0.4700
                     Learning rate: 0.0004
                       Mean reward: 20.40
               Mean episode length: 331.00
       Episode_Reward/keep_balance: 0.3402
     Episode_Reward/rew_lin_vel_xy: 0.8139
      Episode_Reward/rew_ang_vel_z: 1.0397
    Episode_Reward/pen_base_height: -0.2205
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.0509
   Episode_Reward/pen_joint_torque: -0.0575
    Episode_Reward/pen_joint_accel: -0.0290
    Episode_Reward/pen_action_rate: -0.0613
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0114
   Episode_Reward/pen_joint_powers: -0.0200
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1275
Episode_Reward/pen_flat_orientation: -0.1157
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0709
   Episode_Reward/foot_landing_vel: -0.0434
   Episode_Reward/test_gait_reward: -0.3195
Metrics/base_velocity/error_vel_xy: 1.0586
Metrics/base_velocity/error_vel_yaw: 0.2993
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 1.09s
                        Total time: 643.00s
                               ETA: 2611.0s

################################################################################
                     [1m Learning iteration 593/3000 [0m                      

                       Computation: 88851 steps/s (collection: 0.982s, learning 0.125s)
               Value function loss: 1.1148
                    Surrogate loss: -0.0022
             Mean action noise std: 0.4703
                     Learning rate: 0.0009
                       Mean reward: 18.85
               Mean episode length: 301.39
       Episode_Reward/keep_balance: 0.3247
     Episode_Reward/rew_lin_vel_xy: 0.7898
      Episode_Reward/rew_ang_vel_z: 0.9894
    Episode_Reward/pen_base_height: -0.2163
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.0500
   Episode_Reward/pen_joint_torque: -0.0542
    Episode_Reward/pen_joint_accel: -0.0278
    Episode_Reward/pen_action_rate: -0.0580
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0106
   Episode_Reward/pen_joint_powers: -0.0190
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1215
Episode_Reward/pen_flat_orientation: -0.1141
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0634
   Episode_Reward/foot_landing_vel: -0.0406
   Episode_Reward/test_gait_reward: -0.3075
Metrics/base_velocity/error_vel_xy: 1.0045
Metrics/base_velocity/error_vel_yaw: 0.2894
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 13.1250
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 1.11s
                        Total time: 644.10s
                               ETA: 2610.0s

################################################################################
                     [1m Learning iteration 594/3000 [0m                      

                       Computation: 89932 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 1.3917
                    Surrogate loss: 0.0044
             Mean action noise std: 0.4704
                     Learning rate: 0.0003
                       Mean reward: 21.63
               Mean episode length: 309.58
       Episode_Reward/keep_balance: 0.3094
     Episode_Reward/rew_lin_vel_xy: 0.7837
      Episode_Reward/rew_ang_vel_z: 0.9396
    Episode_Reward/pen_base_height: -0.2122
      Episode_Reward/pen_lin_vel_z: -0.0343
     Episode_Reward/pen_ang_vel_xy: -0.0499
   Episode_Reward/pen_joint_torque: -0.0509
    Episode_Reward/pen_joint_accel: -0.0261
    Episode_Reward/pen_action_rate: -0.0553
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0102
   Episode_Reward/pen_joint_powers: -0.0181
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1161
Episode_Reward/pen_flat_orientation: -0.1091
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0609
   Episode_Reward/foot_landing_vel: -0.0381
   Episode_Reward/test_gait_reward: -0.2923
Metrics/base_velocity/error_vel_xy: 0.9421
Metrics/base_velocity/error_vel_yaw: 0.2789
      Episode_Termination/time_out: 0.8333
  Episode_Termination/base_contact: 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 1.09s
                        Total time: 645.20s
                               ETA: 2609.0s

################################################################################
                     [1m Learning iteration 595/3000 [0m                      

                       Computation: 90381 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 1.0840
                    Surrogate loss: 0.0006
             Mean action noise std: 0.4707
                     Learning rate: 0.0004
                       Mean reward: 15.27
               Mean episode length: 263.75
       Episode_Reward/keep_balance: 0.3091
     Episode_Reward/rew_lin_vel_xy: 0.7552
      Episode_Reward/rew_ang_vel_z: 0.9378
    Episode_Reward/pen_base_height: -0.2101
      Episode_Reward/pen_lin_vel_z: -0.0345
     Episode_Reward/pen_ang_vel_xy: -0.0502
   Episode_Reward/pen_joint_torque: -0.0503
    Episode_Reward/pen_joint_accel: -0.0271
    Episode_Reward/pen_action_rate: -0.0557
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0104
   Episode_Reward/pen_joint_powers: -0.0180
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1180
Episode_Reward/pen_flat_orientation: -0.1144
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0613
   Episode_Reward/foot_landing_vel: -0.0399
   Episode_Reward/test_gait_reward: -0.2927
Metrics/base_velocity/error_vel_xy: 0.9459
Metrics/base_velocity/error_vel_yaw: 0.2796
      Episode_Termination/time_out: 0.9167
  Episode_Termination/base_contact: 11.5000
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 1.09s
                        Total time: 646.28s
                               ETA: 2607.9s

################################################################################
                     [1m Learning iteration 596/3000 [0m                      

                       Computation: 90868 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 1.0004
                    Surrogate loss: -0.0000
             Mean action noise std: 0.4711
                     Learning rate: 0.0004
                       Mean reward: 19.88
               Mean episode length: 333.21
       Episode_Reward/keep_balance: 0.3223
     Episode_Reward/rew_lin_vel_xy: 0.7596
      Episode_Reward/rew_ang_vel_z: 0.9758
    Episode_Reward/pen_base_height: -0.2163
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.0517
   Episode_Reward/pen_joint_torque: -0.0542
    Episode_Reward/pen_joint_accel: -0.0301
    Episode_Reward/pen_action_rate: -0.0588
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0112
   Episode_Reward/pen_joint_powers: -0.0193
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1226
Episode_Reward/pen_flat_orientation: -0.1139
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0684
   Episode_Reward/foot_landing_vel: -0.0412
   Episode_Reward/test_gait_reward: -0.3041
Metrics/base_velocity/error_vel_xy: 1.0032
Metrics/base_velocity/error_vel_yaw: 0.2909
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 1.08s
                        Total time: 647.37s
                               ETA: 2606.8s

################################################################################
                     [1m Learning iteration 597/3000 [0m                      

                       Computation: 90103 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 1.1145
                    Surrogate loss: -0.0006
             Mean action noise std: 0.4714
                     Learning rate: 0.0004
                       Mean reward: 17.37
               Mean episode length: 273.15
       Episode_Reward/keep_balance: 0.2895
     Episode_Reward/rew_lin_vel_xy: 0.7351
      Episode_Reward/rew_ang_vel_z: 0.8767
    Episode_Reward/pen_base_height: -0.2015
      Episode_Reward/pen_lin_vel_z: -0.0322
     Episode_Reward/pen_ang_vel_xy: -0.0466
   Episode_Reward/pen_joint_torque: -0.0474
    Episode_Reward/pen_joint_accel: -0.0238
    Episode_Reward/pen_action_rate: -0.0516
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0095
   Episode_Reward/pen_joint_powers: -0.0168
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1096
Episode_Reward/pen_flat_orientation: -0.1075
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0563
   Episode_Reward/foot_landing_vel: -0.0349
   Episode_Reward/test_gait_reward: -0.2750
Metrics/base_velocity/error_vel_xy: 0.9008
Metrics/base_velocity/error_vel_yaw: 0.2618
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 1.09s
                        Total time: 648.46s
                               ETA: 2605.8s

################################################################################
                     [1m Learning iteration 598/3000 [0m                      

                       Computation: 90152 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 1.1026
                    Surrogate loss: 0.0050
             Mean action noise std: 0.4718
                     Learning rate: 0.0000
                       Mean reward: 19.56
               Mean episode length: 316.54
       Episode_Reward/keep_balance: 0.3150
     Episode_Reward/rew_lin_vel_xy: 0.7816
      Episode_Reward/rew_ang_vel_z: 0.9485
    Episode_Reward/pen_base_height: -0.2134
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.0504
   Episode_Reward/pen_joint_torque: -0.0545
    Episode_Reward/pen_joint_accel: -0.0269
    Episode_Reward/pen_action_rate: -0.0579
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0112
   Episode_Reward/pen_joint_powers: -0.0195
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1210
Episode_Reward/pen_flat_orientation: -0.1163
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0674
   Episode_Reward/foot_landing_vel: -0.0438
   Episode_Reward/test_gait_reward: -0.2993
Metrics/base_velocity/error_vel_xy: 0.9705
Metrics/base_velocity/error_vel_yaw: 0.2892
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 1.09s
                        Total time: 649.55s
                               ETA: 2604.7s

################################################################################
                     [1m Learning iteration 599/3000 [0m                      

                       Computation: 90938 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.9178
                    Surrogate loss: -0.0016
             Mean action noise std: 0.4720
                     Learning rate: 0.0003
                       Mean reward: 22.82
               Mean episode length: 341.44
       Episode_Reward/keep_balance: 0.3099
     Episode_Reward/rew_lin_vel_xy: 0.8028
      Episode_Reward/rew_ang_vel_z: 0.9430
    Episode_Reward/pen_base_height: -0.2090
      Episode_Reward/pen_lin_vel_z: -0.0340
     Episode_Reward/pen_ang_vel_xy: -0.0486
   Episode_Reward/pen_joint_torque: -0.0495
    Episode_Reward/pen_joint_accel: -0.0253
    Episode_Reward/pen_action_rate: -0.0553
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0100
   Episode_Reward/pen_joint_powers: -0.0177
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1178
Episode_Reward/pen_flat_orientation: -0.1097
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0601
   Episode_Reward/foot_landing_vel: -0.0388
   Episode_Reward/test_gait_reward: -0.2913
Metrics/base_velocity/error_vel_xy: 0.9196
Metrics/base_velocity/error_vel_yaw: 0.2771
      Episode_Termination/time_out: 0.8333
  Episode_Termination/base_contact: 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 1.08s
                        Total time: 650.63s
                               ETA: 2603.6s

################################################################################
                     [1m Learning iteration 600/3000 [0m                      

                       Computation: 89971 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 1.0966
                    Surrogate loss: -0.0005
             Mean action noise std: 0.4721
                     Learning rate: 0.0002
                       Mean reward: 25.08
               Mean episode length: 394.96
       Episode_Reward/keep_balance: 0.3352
     Episode_Reward/rew_lin_vel_xy: 0.7974
      Episode_Reward/rew_ang_vel_z: 1.0200
    Episode_Reward/pen_base_height: -0.2154
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.0508
   Episode_Reward/pen_joint_torque: -0.0559
    Episode_Reward/pen_joint_accel: -0.0292
    Episode_Reward/pen_action_rate: -0.0607
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0111
   Episode_Reward/pen_joint_powers: -0.0196
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1280
Episode_Reward/pen_flat_orientation: -0.1130
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0661
   Episode_Reward/foot_landing_vel: -0.0421
   Episode_Reward/test_gait_reward: -0.3153
Metrics/base_velocity/error_vel_xy: 1.0700
Metrics/base_velocity/error_vel_yaw: 0.3010
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 1.09s
                        Total time: 651.72s
                               ETA: 2602.5s

################################################################################
                     [1m Learning iteration 601/3000 [0m                      

                       Computation: 90533 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.9991
                    Surrogate loss: -0.0001
             Mean action noise std: 0.4721
                     Learning rate: 0.0006
                       Mean reward: 22.68
               Mean episode length: 358.50
       Episode_Reward/keep_balance: 0.3410
     Episode_Reward/rew_lin_vel_xy: 0.8396
      Episode_Reward/rew_ang_vel_z: 1.0306
    Episode_Reward/pen_base_height: -0.2209
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.0540
   Episode_Reward/pen_joint_torque: -0.0594
    Episode_Reward/pen_joint_accel: -0.0312
    Episode_Reward/pen_action_rate: -0.0637
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0120
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1323
Episode_Reward/pen_flat_orientation: -0.1181
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0747
   Episode_Reward/foot_landing_vel: -0.0449
   Episode_Reward/test_gait_reward: -0.3230
Metrics/base_velocity/error_vel_xy: 1.0473
Metrics/base_velocity/error_vel_yaw: 0.3102
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 1.09s
                        Total time: 652.81s
                               ETA: 2601.5s

################################################################################
                     [1m Learning iteration 602/3000 [0m                      

                       Computation: 91725 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.8772
                    Surrogate loss: 0.0008
             Mean action noise std: 0.4729
                     Learning rate: 0.0004
                       Mean reward: 22.02
               Mean episode length: 349.94
       Episode_Reward/keep_balance: 0.3294
     Episode_Reward/rew_lin_vel_xy: 0.8173
      Episode_Reward/rew_ang_vel_z: 0.9940
    Episode_Reward/pen_base_height: -0.2176
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.0515
   Episode_Reward/pen_joint_torque: -0.0573
    Episode_Reward/pen_joint_accel: -0.0301
    Episode_Reward/pen_action_rate: -0.0613
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0116
   Episode_Reward/pen_joint_powers: -0.0201
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1283
Episode_Reward/pen_flat_orientation: -0.1141
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0704
   Episode_Reward/foot_landing_vel: -0.0451
   Episode_Reward/test_gait_reward: -0.3121
Metrics/base_velocity/error_vel_xy: 1.0212
Metrics/base_velocity/error_vel_yaw: 0.2997
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 1.07s
                        Total time: 653.88s
                               ETA: 2600.3s

################################################################################
                     [1m Learning iteration 603/3000 [0m                      

                       Computation: 90350 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 0.9718
                    Surrogate loss: -0.0025
             Mean action noise std: 0.4738
                     Learning rate: 0.0009
                       Mean reward: 21.65
               Mean episode length: 348.13
       Episode_Reward/keep_balance: 0.3560
     Episode_Reward/rew_lin_vel_xy: 0.8864
      Episode_Reward/rew_ang_vel_z: 1.0810
    Episode_Reward/pen_base_height: -0.2242
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.0547
   Episode_Reward/pen_joint_torque: -0.0610
    Episode_Reward/pen_joint_accel: -0.0301
    Episode_Reward/pen_action_rate: -0.0661
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0122
   Episode_Reward/pen_joint_powers: -0.0215
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1373
Episode_Reward/pen_flat_orientation: -0.1188
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0751
   Episode_Reward/foot_landing_vel: -0.0467
   Episode_Reward/test_gait_reward: -0.3377
Metrics/base_velocity/error_vel_xy: 1.1044
Metrics/base_velocity/error_vel_yaw: 0.3192
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 1.09s
                        Total time: 654.97s
                               ETA: 2599.3s

################################################################################
                     [1m Learning iteration 604/3000 [0m                      

                       Computation: 90409 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 1.1386
                    Surrogate loss: 0.0030
             Mean action noise std: 0.4746
                     Learning rate: 0.0001
                       Mean reward: 23.51
               Mean episode length: 380.54
       Episode_Reward/keep_balance: 0.3826
     Episode_Reward/rew_lin_vel_xy: 0.8786
      Episode_Reward/rew_ang_vel_z: 1.1542
    Episode_Reward/pen_base_height: -0.2302
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.0572
   Episode_Reward/pen_joint_torque: -0.0668
    Episode_Reward/pen_joint_accel: -0.0355
    Episode_Reward/pen_action_rate: -0.0727
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0234
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.1499
Episode_Reward/pen_flat_orientation: -0.1246
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0837
   Episode_Reward/foot_landing_vel: -0.0499
   Episode_Reward/test_gait_reward: -0.3606
Metrics/base_velocity/error_vel_xy: 1.2198
Metrics/base_velocity/error_vel_yaw: 0.3491
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 1.09s
                        Total time: 656.05s
                               ETA: 2598.2s

################################################################################
                     [1m Learning iteration 605/3000 [0m                      

                       Computation: 85859 steps/s (collection: 1.022s, learning 0.123s)
               Value function loss: 0.9013
                    Surrogate loss: 0.0020
             Mean action noise std: 0.4748
                     Learning rate: 0.0002
                       Mean reward: 16.02
               Mean episode length: 308.70
       Episode_Reward/keep_balance: 0.3467
     Episode_Reward/rew_lin_vel_xy: 0.8184
      Episode_Reward/rew_ang_vel_z: 1.0404
    Episode_Reward/pen_base_height: -0.2201
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.0553
   Episode_Reward/pen_joint_torque: -0.0599
    Episode_Reward/pen_joint_accel: -0.0324
    Episode_Reward/pen_action_rate: -0.0659
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0125
   Episode_Reward/pen_joint_powers: -0.0215
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1368
Episode_Reward/pen_flat_orientation: -0.1272
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0785
   Episode_Reward/foot_landing_vel: -0.0460
   Episode_Reward/test_gait_reward: -0.3301
Metrics/base_velocity/error_vel_xy: 1.0749
Metrics/base_velocity/error_vel_yaw: 0.3220
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 1.14s
                        Total time: 657.20s
                               ETA: 2597.3s

################################################################################
                     [1m Learning iteration 606/3000 [0m                      

                       Computation: 90423 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.8329
                    Surrogate loss: 0.0002
             Mean action noise std: 0.4751
                     Learning rate: 0.0003
                       Mean reward: 21.38
               Mean episode length: 381.50
       Episode_Reward/keep_balance: 0.3471
     Episode_Reward/rew_lin_vel_xy: 0.8261
      Episode_Reward/rew_ang_vel_z: 1.0386
    Episode_Reward/pen_base_height: -0.2246
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.0549
   Episode_Reward/pen_joint_torque: -0.0592
    Episode_Reward/pen_joint_accel: -0.0323
    Episode_Reward/pen_action_rate: -0.0659
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0127
   Episode_Reward/pen_joint_powers: -0.0216
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1370
Episode_Reward/pen_flat_orientation: -0.1252
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0797
   Episode_Reward/foot_landing_vel: -0.0480
   Episode_Reward/test_gait_reward: -0.3299
Metrics/base_velocity/error_vel_xy: 1.0948
Metrics/base_velocity/error_vel_yaw: 0.3223
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 1.09s
                        Total time: 658.29s
                               ETA: 2596.3s

################################################################################
                     [1m Learning iteration 607/3000 [0m                      

                       Computation: 89205 steps/s (collection: 0.977s, learning 0.125s)
               Value function loss: 0.8293
                    Surrogate loss: -0.0005
             Mean action noise std: 0.4753
                     Learning rate: 0.0004
                       Mean reward: 21.26
               Mean episode length: 342.39
       Episode_Reward/keep_balance: 0.3427
     Episode_Reward/rew_lin_vel_xy: 0.8232
      Episode_Reward/rew_ang_vel_z: 1.0325
    Episode_Reward/pen_base_height: -0.2174
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.0527
   Episode_Reward/pen_joint_torque: -0.0579
    Episode_Reward/pen_joint_accel: -0.0320
    Episode_Reward/pen_action_rate: -0.0642
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0118
   Episode_Reward/pen_joint_powers: -0.0206
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1342
Episode_Reward/pen_flat_orientation: -0.1167
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0729
   Episode_Reward/foot_landing_vel: -0.0446
   Episode_Reward/test_gait_reward: -0.3252
Metrics/base_velocity/error_vel_xy: 1.0784
Metrics/base_velocity/error_vel_yaw: 0.3136
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 1.10s
                        Total time: 659.39s
                               ETA: 2595.3s

################################################################################
                     [1m Learning iteration 608/3000 [0m                      

                       Computation: 90875 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 1.1762
                    Surrogate loss: 0.0000
             Mean action noise std: 0.4757
                     Learning rate: 0.0006
                       Mean reward: 16.49
               Mean episode length: 328.28
       Episode_Reward/keep_balance: 0.3193
     Episode_Reward/rew_lin_vel_xy: 0.7360
      Episode_Reward/rew_ang_vel_z: 0.9658
    Episode_Reward/pen_base_height: -0.2112
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.0517
   Episode_Reward/pen_joint_torque: -0.0535
    Episode_Reward/pen_joint_accel: -0.0309
    Episode_Reward/pen_action_rate: -0.0599
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0114
   Episode_Reward/pen_joint_powers: -0.0193
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1256
Episode_Reward/pen_flat_orientation: -0.1179
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.0702
   Episode_Reward/foot_landing_vel: -0.0431
   Episode_Reward/test_gait_reward: -0.3033
Metrics/base_velocity/error_vel_xy: 1.0336
Metrics/base_velocity/error_vel_yaw: 0.2902
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 1.08s
                        Total time: 660.47s
                               ETA: 2594.2s

################################################################################
                     [1m Learning iteration 609/3000 [0m                      

                       Computation: 91084 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 1.1673
                    Surrogate loss: 0.0010
             Mean action noise std: 0.4762
                     Learning rate: 0.0004
                       Mean reward: 22.26
               Mean episode length: 373.76
       Episode_Reward/keep_balance: 0.3678
     Episode_Reward/rew_lin_vel_xy: 0.9292
      Episode_Reward/rew_ang_vel_z: 1.1102
    Episode_Reward/pen_base_height: -0.2287
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.0570
   Episode_Reward/pen_joint_torque: -0.0616
    Episode_Reward/pen_joint_accel: -0.0347
    Episode_Reward/pen_action_rate: -0.0696
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0225
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1447
Episode_Reward/pen_flat_orientation: -0.1292
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0828
   Episode_Reward/foot_landing_vel: -0.0487
   Episode_Reward/test_gait_reward: -0.3470
Metrics/base_velocity/error_vel_xy: 1.1217
Metrics/base_velocity/error_vel_yaw: 0.3350
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 1.08s
                        Total time: 661.55s
                               ETA: 2593.1s

################################################################################
                     [1m Learning iteration 610/3000 [0m                      

                       Computation: 91132 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.9679
                    Surrogate loss: 0.0011
             Mean action noise std: 0.4761
                     Learning rate: 0.0003
                       Mean reward: 22.12
               Mean episode length: 349.73
       Episode_Reward/keep_balance: 0.3655
     Episode_Reward/rew_lin_vel_xy: 0.9104
      Episode_Reward/rew_ang_vel_z: 1.1118
    Episode_Reward/pen_base_height: -0.2288
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.0574
   Episode_Reward/pen_joint_torque: -0.0622
    Episode_Reward/pen_joint_accel: -0.0290
    Episode_Reward/pen_action_rate: -0.0683
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0122
   Episode_Reward/pen_joint_powers: -0.0219
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1438
Episode_Reward/pen_flat_orientation: -0.1286
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0733
   Episode_Reward/foot_landing_vel: -0.0445
   Episode_Reward/test_gait_reward: -0.3475
Metrics/base_velocity/error_vel_xy: 1.1248
Metrics/base_velocity/error_vel_yaw: 0.3252
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 1.08s
                        Total time: 662.63s
                               ETA: 2591.9s

################################################################################
                     [1m Learning iteration 611/3000 [0m                      

                       Computation: 91070 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.9310
                    Surrogate loss: -0.0025
             Mean action noise std: 0.4767
                     Learning rate: 0.0006
                       Mean reward: 21.62
               Mean episode length: 333.45
       Episode_Reward/keep_balance: 0.3166
     Episode_Reward/rew_lin_vel_xy: 0.7963
      Episode_Reward/rew_ang_vel_z: 0.9598
    Episode_Reward/pen_base_height: -0.2129
      Episode_Reward/pen_lin_vel_z: -0.0347
     Episode_Reward/pen_ang_vel_xy: -0.0502
   Episode_Reward/pen_joint_torque: -0.0508
    Episode_Reward/pen_joint_accel: -0.0261
    Episode_Reward/pen_action_rate: -0.0585
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0106
   Episode_Reward/pen_joint_powers: -0.0182
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1250
Episode_Reward/pen_flat_orientation: -0.1186
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0660
   Episode_Reward/foot_landing_vel: -0.0394
   Episode_Reward/test_gait_reward: -0.3009
Metrics/base_velocity/error_vel_xy: 0.9872
Metrics/base_velocity/error_vel_yaw: 0.2855
      Episode_Termination/time_out: 0.7917
  Episode_Termination/base_contact: 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 1.08s
                        Total time: 663.71s
                               ETA: 2590.8s

################################################################################
                     [1m Learning iteration 612/3000 [0m                      

                       Computation: 90686 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 1.1174
                    Surrogate loss: -0.0009
             Mean action noise std: 0.4773
                     Learning rate: 0.0009
                       Mean reward: 27.93
               Mean episode length: 426.86
       Episode_Reward/keep_balance: 0.4024
     Episode_Reward/rew_lin_vel_xy: 1.0240
      Episode_Reward/rew_ang_vel_z: 1.2225
    Episode_Reward/pen_base_height: -0.2368
      Episode_Reward/pen_lin_vel_z: -0.0448
     Episode_Reward/pen_ang_vel_xy: -0.0600
   Episode_Reward/pen_joint_torque: -0.0703
    Episode_Reward/pen_joint_accel: -0.0366
    Episode_Reward/pen_action_rate: -0.0769
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0249
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1591
Episode_Reward/pen_flat_orientation: -0.1319
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0879
   Episode_Reward/foot_landing_vel: -0.0523
   Episode_Reward/test_gait_reward: -0.3802
Metrics/base_velocity/error_vel_xy: 1.2172
Metrics/base_velocity/error_vel_yaw: 0.3601
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 1.08s
                        Total time: 664.79s
                               ETA: 2589.8s

################################################################################
                     [1m Learning iteration 613/3000 [0m                      

                       Computation: 90487 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.9165
                    Surrogate loss: 0.0032
             Mean action noise std: 0.4778
                     Learning rate: 0.0001
                       Mean reward: 23.21
               Mean episode length: 387.02
       Episode_Reward/keep_balance: 0.3927
     Episode_Reward/rew_lin_vel_xy: 1.0131
      Episode_Reward/rew_ang_vel_z: 1.1946
    Episode_Reward/pen_base_height: -0.2378
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.0608
   Episode_Reward/pen_joint_torque: -0.0644
    Episode_Reward/pen_joint_accel: -0.0331
    Episode_Reward/pen_action_rate: -0.0753
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0236
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1562
Episode_Reward/pen_flat_orientation: -0.1389
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0861
   Episode_Reward/foot_landing_vel: -0.0516
   Episode_Reward/test_gait_reward: -0.3718
Metrics/base_velocity/error_vel_xy: 1.1598
Metrics/base_velocity/error_vel_yaw: 0.3523
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 1.09s
                        Total time: 665.88s
                               ETA: 2588.7s

################################################################################
                     [1m Learning iteration 614/3000 [0m                      

                       Computation: 90724 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.8935
                    Surrogate loss: 0.0020
             Mean action noise std: 0.4778
                     Learning rate: 0.0001
                       Mean reward: 18.93
               Mean episode length: 320.38
       Episode_Reward/keep_balance: 0.3077
     Episode_Reward/rew_lin_vel_xy: 0.7466
      Episode_Reward/rew_ang_vel_z: 0.9205
    Episode_Reward/pen_base_height: -0.2130
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.0501
   Episode_Reward/pen_joint_torque: -0.0511
    Episode_Reward/pen_joint_accel: -0.0268
    Episode_Reward/pen_action_rate: -0.0582
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0110
   Episode_Reward/pen_joint_powers: -0.0186
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1229
Episode_Reward/pen_flat_orientation: -0.1150
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0718
   Episode_Reward/foot_landing_vel: -0.0413
   Episode_Reward/test_gait_reward: -0.2937
Metrics/base_velocity/error_vel_xy: 0.9846
Metrics/base_velocity/error_vel_yaw: 0.2876
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 1.08s
                        Total time: 666.96s
                               ETA: 2587.6s

################################################################################
                     [1m Learning iteration 615/3000 [0m                      

                       Computation: 90084 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.9598
                    Surrogate loss: -0.0019
             Mean action noise std: 0.4778
                     Learning rate: 0.0001
                       Mean reward: 20.78
               Mean episode length: 364.67
       Episode_Reward/keep_balance: 0.3487
     Episode_Reward/rew_lin_vel_xy: 0.8138
      Episode_Reward/rew_ang_vel_z: 1.0491
    Episode_Reward/pen_base_height: -0.2275
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.0548
   Episode_Reward/pen_joint_torque: -0.0606
    Episode_Reward/pen_joint_accel: -0.0307
    Episode_Reward/pen_action_rate: -0.0670
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0125
   Episode_Reward/pen_joint_powers: -0.0216
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1405
Episode_Reward/pen_flat_orientation: -0.1231
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0831
   Episode_Reward/foot_landing_vel: -0.0473
   Episode_Reward/test_gait_reward: -0.3288
Metrics/base_velocity/error_vel_xy: 1.1271
Metrics/base_velocity/error_vel_yaw: 0.3210
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 1.09s
                        Total time: 668.05s
                               ETA: 2586.5s

################################################################################
                     [1m Learning iteration 616/3000 [0m                      

                       Computation: 91044 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.9540
                    Surrogate loss: -0.0010
             Mean action noise std: 0.4781
                     Learning rate: 0.0004
                       Mean reward: 24.51
               Mean episode length: 390.46
       Episode_Reward/keep_balance: 0.4168
     Episode_Reward/rew_lin_vel_xy: 1.1069
      Episode_Reward/rew_ang_vel_z: 1.2635
    Episode_Reward/pen_base_height: -0.2438
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.0625
   Episode_Reward/pen_joint_torque: -0.0722
    Episode_Reward/pen_joint_accel: -0.0379
    Episode_Reward/pen_action_rate: -0.0803
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0256
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1678
Episode_Reward/pen_flat_orientation: -0.1380
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0896
   Episode_Reward/foot_landing_vel: -0.0564
   Episode_Reward/test_gait_reward: -0.3950
Metrics/base_velocity/error_vel_xy: 1.2424
Metrics/base_velocity/error_vel_yaw: 0.3738
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 1.08s
                        Total time: 669.13s
                               ETA: 2585.4s

################################################################################
                     [1m Learning iteration 617/3000 [0m                      

                       Computation: 91009 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.9418
                    Surrogate loss: -0.0020
             Mean action noise std: 0.4785
                     Learning rate: 0.0009
                       Mean reward: 20.27
               Mean episode length: 344.36
       Episode_Reward/keep_balance: 0.3409
     Episode_Reward/rew_lin_vel_xy: 0.8844
      Episode_Reward/rew_ang_vel_z: 1.0314
    Episode_Reward/pen_base_height: -0.2252
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.0533
   Episode_Reward/pen_joint_torque: -0.0585
    Episode_Reward/pen_joint_accel: -0.0299
    Episode_Reward/pen_action_rate: -0.0652
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0120
   Episode_Reward/pen_joint_powers: -0.0209
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1373
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0773
   Episode_Reward/foot_landing_vel: -0.0444
   Episode_Reward/test_gait_reward: -0.3234
Metrics/base_velocity/error_vel_xy: 1.0282
Metrics/base_velocity/error_vel_yaw: 0.3086
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 1.08s
                        Total time: 670.21s
                               ETA: 2584.3s

################################################################################
                     [1m Learning iteration 618/3000 [0m                      

                       Computation: 90174 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 1.0356
                    Surrogate loss: 0.0001
             Mean action noise std: 0.4786
                     Learning rate: 0.0006
                       Mean reward: 21.62
               Mean episode length: 333.00
       Episode_Reward/keep_balance: 0.3363
     Episode_Reward/rew_lin_vel_xy: 0.8936
      Episode_Reward/rew_ang_vel_z: 1.0295
    Episode_Reward/pen_base_height: -0.2206
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.0527
   Episode_Reward/pen_joint_torque: -0.0557
    Episode_Reward/pen_joint_accel: -0.0287
    Episode_Reward/pen_action_rate: -0.0630
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0115
   Episode_Reward/pen_joint_powers: -0.0201
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1346
Episode_Reward/pen_flat_orientation: -0.1186
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0710
   Episode_Reward/foot_landing_vel: -0.0417
   Episode_Reward/test_gait_reward: -0.3181
Metrics/base_velocity/error_vel_xy: 1.0069
Metrics/base_velocity/error_vel_yaw: 0.2966
      Episode_Termination/time_out: 0.9583
  Episode_Termination/base_contact: 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 1.09s
                        Total time: 671.30s
                               ETA: 2583.3s

################################################################################
                     [1m Learning iteration 619/3000 [0m                      

                       Computation: 90647 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 1.0195
                    Surrogate loss: -0.0012
             Mean action noise std: 0.4789
                     Learning rate: 0.0009
                       Mean reward: 30.01
               Mean episode length: 464.60
       Episode_Reward/keep_balance: 0.3929
     Episode_Reward/rew_lin_vel_xy: 0.9692
      Episode_Reward/rew_ang_vel_z: 1.2000
    Episode_Reward/pen_base_height: -0.2329
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.0567
   Episode_Reward/pen_joint_torque: -0.0657
    Episode_Reward/pen_joint_accel: -0.0339
    Episode_Reward/pen_action_rate: -0.0746
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0232
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1569
Episode_Reward/pen_flat_orientation: -0.1283
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0854
   Episode_Reward/foot_landing_vel: -0.0505
   Episode_Reward/test_gait_reward: -0.3710
Metrics/base_velocity/error_vel_xy: 1.2153
Metrics/base_velocity/error_vel_yaw: 0.3482
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 1.08s
                        Total time: 672.39s
                               ETA: 2582.2s

################################################################################
                     [1m Learning iteration 620/3000 [0m                      

                       Computation: 90868 steps/s (collection: 0.956s, learning 0.126s)
               Value function loss: 0.9409
                    Surrogate loss: 0.0030
             Mean action noise std: 0.4791
                     Learning rate: 0.0001
                       Mean reward: 22.40
               Mean episode length: 369.21
       Episode_Reward/keep_balance: 0.4219
     Episode_Reward/rew_lin_vel_xy: 1.0968
      Episode_Reward/rew_ang_vel_z: 1.2849
    Episode_Reward/pen_base_height: -0.2469
      Episode_Reward/pen_lin_vel_z: -0.0470
     Episode_Reward/pen_ang_vel_xy: -0.0617
   Episode_Reward/pen_joint_torque: -0.0739
    Episode_Reward/pen_joint_accel: -0.0394
    Episode_Reward/pen_action_rate: -0.0828
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0151
   Episode_Reward/pen_joint_powers: -0.0262
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1715
Episode_Reward/pen_flat_orientation: -0.1395
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0934
   Episode_Reward/foot_landing_vel: -0.0568
   Episode_Reward/test_gait_reward: -0.3974
Metrics/base_velocity/error_vel_xy: 1.2654
Metrics/base_velocity/error_vel_yaw: 0.3749
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 1.08s
                        Total time: 673.47s
                               ETA: 2581.1s

################################################################################
                     [1m Learning iteration 621/3000 [0m                      

                       Computation: 90053 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.9435
                    Surrogate loss: 0.0036
             Mean action noise std: 0.4793
                     Learning rate: 0.0001
                       Mean reward: 27.66
               Mean episode length: 417.48
       Episode_Reward/keep_balance: 0.3989
     Episode_Reward/rew_lin_vel_xy: 1.0110
      Episode_Reward/rew_ang_vel_z: 1.2089
    Episode_Reward/pen_base_height: -0.2399
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.0589
   Episode_Reward/pen_joint_torque: -0.0661
    Episode_Reward/pen_joint_accel: -0.0366
    Episode_Reward/pen_action_rate: -0.0765
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0140
   Episode_Reward/pen_joint_powers: -0.0238
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1625
Episode_Reward/pen_flat_orientation: -0.1341
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0887
   Episode_Reward/foot_landing_vel: -0.0518
   Episode_Reward/test_gait_reward: -0.3772
Metrics/base_velocity/error_vel_xy: 1.2078
Metrics/base_velocity/error_vel_yaw: 0.3591
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 1.09s
                        Total time: 674.56s
                               ETA: 2580.0s

################################################################################
                     [1m Learning iteration 622/3000 [0m                      

                       Computation: 91756 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.8687
                    Surrogate loss: -0.0006
             Mean action noise std: 0.4797
                     Learning rate: 0.0002
                       Mean reward: 20.03
               Mean episode length: 352.24
       Episode_Reward/keep_balance: 0.3862
     Episode_Reward/rew_lin_vel_xy: 1.0663
      Episode_Reward/rew_ang_vel_z: 1.1657
    Episode_Reward/pen_base_height: -0.2444
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.0578
   Episode_Reward/pen_joint_torque: -0.0663
    Episode_Reward/pen_joint_accel: -0.0363
    Episode_Reward/pen_action_rate: -0.0749
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0241
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1573
Episode_Reward/pen_flat_orientation: -0.1364
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0914
   Episode_Reward/foot_landing_vel: -0.0552
   Episode_Reward/test_gait_reward: -0.3690
Metrics/base_velocity/error_vel_xy: 1.1227
Metrics/base_velocity/error_vel_yaw: 0.3526
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 1.07s
                        Total time: 675.63s
                               ETA: 2578.9s

################################################################################
                     [1m Learning iteration 623/3000 [0m                      

                       Computation: 90477 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.9623
                    Surrogate loss: -0.0017
             Mean action noise std: 0.4800
                     Learning rate: 0.0004
                       Mean reward: 27.14
               Mean episode length: 405.42
       Episode_Reward/keep_balance: 0.3971
     Episode_Reward/rew_lin_vel_xy: 1.0459
      Episode_Reward/rew_ang_vel_z: 1.2012
    Episode_Reward/pen_base_height: -0.2413
      Episode_Reward/pen_lin_vel_z: -0.0446
     Episode_Reward/pen_ang_vel_xy: -0.0590
   Episode_Reward/pen_joint_torque: -0.0689
    Episode_Reward/pen_joint_accel: -0.0364
    Episode_Reward/pen_action_rate: -0.0774
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0142
   Episode_Reward/pen_joint_powers: -0.0245
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1611
Episode_Reward/pen_flat_orientation: -0.1346
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0906
   Episode_Reward/foot_landing_vel: -0.0533
   Episode_Reward/test_gait_reward: -0.3753
Metrics/base_velocity/error_vel_xy: 1.1870
Metrics/base_velocity/error_vel_yaw: 0.3592
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 1.09s
                        Total time: 676.72s
                               ETA: 2577.8s

################################################################################
                     [1m Learning iteration 624/3000 [0m                      

                       Computation: 91372 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 1.0995
                    Surrogate loss: -0.0020
             Mean action noise std: 0.4807
                     Learning rate: 0.0009
                       Mean reward: 23.79
               Mean episode length: 384.50
       Episode_Reward/keep_balance: 0.4058
     Episode_Reward/rew_lin_vel_xy: 1.0290
      Episode_Reward/rew_ang_vel_z: 1.2343
    Episode_Reward/pen_base_height: -0.2427
      Episode_Reward/pen_lin_vel_z: -0.0449
     Episode_Reward/pen_ang_vel_xy: -0.0593
   Episode_Reward/pen_joint_torque: -0.0696
    Episode_Reward/pen_joint_accel: -0.0361
    Episode_Reward/pen_action_rate: -0.0787
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0247
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1657
Episode_Reward/pen_flat_orientation: -0.1372
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0895
   Episode_Reward/foot_landing_vel: -0.0517
   Episode_Reward/test_gait_reward: -0.3797
Metrics/base_velocity/error_vel_xy: 1.2408
Metrics/base_velocity/error_vel_yaw: 0.3617
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 1.08s
                        Total time: 677.79s
                               ETA: 2576.7s

################################################################################
                     [1m Learning iteration 625/3000 [0m                      

                       Computation: 92006 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 1.2161
                    Surrogate loss: 0.0026
             Mean action noise std: 0.4815
                     Learning rate: 0.0003
                       Mean reward: 28.95
               Mean episode length: 421.21
       Episode_Reward/keep_balance: 0.4429
     Episode_Reward/rew_lin_vel_xy: 1.1466
      Episode_Reward/rew_ang_vel_z: 1.3450
    Episode_Reward/pen_base_height: -0.2527
      Episode_Reward/pen_lin_vel_z: -0.0487
     Episode_Reward/pen_ang_vel_xy: -0.0624
   Episode_Reward/pen_joint_torque: -0.0779
    Episode_Reward/pen_joint_accel: -0.0370
    Episode_Reward/pen_action_rate: -0.0868
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0153
   Episode_Reward/pen_joint_powers: -0.0273
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1816
Episode_Reward/pen_flat_orientation: -0.1399
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.1000
   Episode_Reward/foot_landing_vel: -0.0581
   Episode_Reward/test_gait_reward: -0.4153
Metrics/base_velocity/error_vel_xy: 1.3154
Metrics/base_velocity/error_vel_yaw: 0.3965
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 1.07s
                        Total time: 678.86s
                               ETA: 2575.6s

################################################################################
                     [1m Learning iteration 626/3000 [0m                      

                       Computation: 90854 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.9703
                    Surrogate loss: 0.0000
             Mean action noise std: 0.4819
                     Learning rate: 0.0004
                       Mean reward: 24.25
               Mean episode length: 379.57
       Episode_Reward/keep_balance: 0.3738
     Episode_Reward/rew_lin_vel_xy: 0.9569
      Episode_Reward/rew_ang_vel_z: 1.1389
    Episode_Reward/pen_base_height: -0.2304
      Episode_Reward/pen_lin_vel_z: -0.0414
     Episode_Reward/pen_ang_vel_xy: -0.0562
   Episode_Reward/pen_joint_torque: -0.0620
    Episode_Reward/pen_joint_accel: -0.0322
    Episode_Reward/pen_action_rate: -0.0722
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0130
   Episode_Reward/pen_joint_powers: -0.0224
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1523
Episode_Reward/pen_flat_orientation: -0.1265
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0822
   Episode_Reward/foot_landing_vel: -0.0494
   Episode_Reward/test_gait_reward: -0.3528
Metrics/base_velocity/error_vel_xy: 1.1416
Metrics/base_velocity/error_vel_yaw: 0.3319
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 1.08s
                        Total time: 679.94s
                               ETA: 2574.5s

################################################################################
                     [1m Learning iteration 627/3000 [0m                      

                       Computation: 86640 steps/s (collection: 1.010s, learning 0.125s)
               Value function loss: 1.0203
                    Surrogate loss: -0.0020
             Mean action noise std: 0.4830
                     Learning rate: 0.0009
                       Mean reward: 27.72
               Mean episode length: 437.57
       Episode_Reward/keep_balance: 0.4138
     Episode_Reward/rew_lin_vel_xy: 1.0305
      Episode_Reward/rew_ang_vel_z: 1.2578
    Episode_Reward/pen_base_height: -0.2437
      Episode_Reward/pen_lin_vel_z: -0.0462
     Episode_Reward/pen_ang_vel_xy: -0.0613
   Episode_Reward/pen_joint_torque: -0.0701
    Episode_Reward/pen_joint_accel: -0.0357
    Episode_Reward/pen_action_rate: -0.0818
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0145
   Episode_Reward/pen_joint_powers: -0.0252
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1703
Episode_Reward/pen_flat_orientation: -0.1296
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0929
   Episode_Reward/foot_landing_vel: -0.0535
   Episode_Reward/test_gait_reward: -0.3903
Metrics/base_velocity/error_vel_xy: 1.2762
Metrics/base_velocity/error_vel_yaw: 0.3711
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 1.13s
                        Total time: 681.08s
                               ETA: 2573.6s

################################################################################
                     [1m Learning iteration 628/3000 [0m                      

                       Computation: 88240 steps/s (collection: 0.985s, learning 0.129s)
               Value function loss: 0.9800
                    Surrogate loss: 0.0006
             Mean action noise std: 0.4835
                     Learning rate: 0.0006
                       Mean reward: 24.06
               Mean episode length: 388.70
       Episode_Reward/keep_balance: 0.4041
     Episode_Reward/rew_lin_vel_xy: 0.9772
      Episode_Reward/rew_ang_vel_z: 1.2219
    Episode_Reward/pen_base_height: -0.2421
      Episode_Reward/pen_lin_vel_z: -0.0468
     Episode_Reward/pen_ang_vel_xy: -0.0602
   Episode_Reward/pen_joint_torque: -0.0713
    Episode_Reward/pen_joint_accel: -0.0366
    Episode_Reward/pen_action_rate: -0.0798
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0146
   Episode_Reward/pen_joint_powers: -0.0254
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.1667
Episode_Reward/pen_flat_orientation: -0.1413
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0952
   Episode_Reward/foot_landing_vel: -0.0551
   Episode_Reward/test_gait_reward: -0.3807
Metrics/base_velocity/error_vel_xy: 1.2867
Metrics/base_velocity/error_vel_yaw: 0.3677
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 1.11s
                        Total time: 682.19s
                               ETA: 2572.6s

################################################################################
                     [1m Learning iteration 629/3000 [0m                      

                       Computation: 89264 steps/s (collection: 0.972s, learning 0.129s)
               Value function loss: 0.9155
                    Surrogate loss: 0.0020
             Mean action noise std: 0.4840
                     Learning rate: 0.0002
                       Mean reward: 22.68
               Mean episode length: 367.39
       Episode_Reward/keep_balance: 0.3911
     Episode_Reward/rew_lin_vel_xy: 0.9890
      Episode_Reward/rew_ang_vel_z: 1.1778
    Episode_Reward/pen_base_height: -0.2342
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.0582
   Episode_Reward/pen_joint_torque: -0.0667
    Episode_Reward/pen_joint_accel: -0.0356
    Episode_Reward/pen_action_rate: -0.0772
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0241
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1632
Episode_Reward/pen_flat_orientation: -0.1300
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0895
   Episode_Reward/foot_landing_vel: -0.0528
   Episode_Reward/test_gait_reward: -0.3686
Metrics/base_velocity/error_vel_xy: 1.2083
Metrics/base_velocity/error_vel_yaw: 0.3577
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 1.10s
                        Total time: 683.29s
                               ETA: 2571.6s

################################################################################
                     [1m Learning iteration 630/3000 [0m                      

                       Computation: 89799 steps/s (collection: 0.965s, learning 0.130s)
               Value function loss: 0.8731
                    Surrogate loss: -0.0003
             Mean action noise std: 0.4838
                     Learning rate: 0.0003
                       Mean reward: 25.89
               Mean episode length: 403.71
       Episode_Reward/keep_balance: 0.4426
     Episode_Reward/rew_lin_vel_xy: 1.1837
      Episode_Reward/rew_ang_vel_z: 1.3396
    Episode_Reward/pen_base_height: -0.2599
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.0651
   Episode_Reward/pen_joint_torque: -0.0774
    Episode_Reward/pen_joint_accel: -0.0406
    Episode_Reward/pen_action_rate: -0.0883
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0161
   Episode_Reward/pen_joint_powers: -0.0279
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.1827
Episode_Reward/pen_flat_orientation: -0.1393
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1050
   Episode_Reward/foot_landing_vel: -0.0598
   Episode_Reward/test_gait_reward: -0.4171
Metrics/base_velocity/error_vel_xy: 1.3287
Metrics/base_velocity/error_vel_yaw: 0.4003
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 1.09s
                        Total time: 684.39s
                               ETA: 2570.5s

################################################################################
                     [1m Learning iteration 631/3000 [0m                      

                       Computation: 90820 steps/s (collection: 0.953s, learning 0.129s)
               Value function loss: 0.9375
                    Surrogate loss: 0.0006
             Mean action noise std: 0.4839
                     Learning rate: 0.0004
                       Mean reward: 24.81
               Mean episode length: 397.25
       Episode_Reward/keep_balance: 0.3704
     Episode_Reward/rew_lin_vel_xy: 0.9637
      Episode_Reward/rew_ang_vel_z: 1.1179
    Episode_Reward/pen_base_height: -0.2331
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.0571
   Episode_Reward/pen_joint_torque: -0.0632
    Episode_Reward/pen_joint_accel: -0.0315
    Episode_Reward/pen_action_rate: -0.0735
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0133
   Episode_Reward/pen_joint_powers: -0.0228
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1561
Episode_Reward/pen_flat_orientation: -0.1290
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0870
   Episode_Reward/foot_landing_vel: -0.0488
   Episode_Reward/test_gait_reward: -0.3512
Metrics/base_velocity/error_vel_xy: 1.1295
Metrics/base_velocity/error_vel_yaw: 0.3408
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 1.08s
                        Total time: 685.47s
                               ETA: 2569.4s

################################################################################
                     [1m Learning iteration 632/3000 [0m                      

                       Computation: 88465 steps/s (collection: 0.981s, learning 0.130s)
               Value function loss: 0.9566
                    Surrogate loss: -0.0000
             Mean action noise std: 0.4844
                     Learning rate: 0.0004
                       Mean reward: 31.22
               Mean episode length: 456.62
       Episode_Reward/keep_balance: 0.4251
     Episode_Reward/rew_lin_vel_xy: 1.1463
      Episode_Reward/rew_ang_vel_z: 1.2861
    Episode_Reward/pen_base_height: -0.2562
      Episode_Reward/pen_lin_vel_z: -0.0491
     Episode_Reward/pen_ang_vel_xy: -0.0617
   Episode_Reward/pen_joint_torque: -0.0739
    Episode_Reward/pen_joint_accel: -0.0402
    Episode_Reward/pen_action_rate: -0.0852
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0157
   Episode_Reward/pen_joint_powers: -0.0268
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1798
Episode_Reward/pen_flat_orientation: -0.1404
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1040
   Episode_Reward/foot_landing_vel: -0.0598
   Episode_Reward/test_gait_reward: -0.4024
Metrics/base_velocity/error_vel_xy: 1.2783
Metrics/base_velocity/error_vel_yaw: 0.3846
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 1.11s
                        Total time: 686.58s
                               ETA: 2568.4s

################################################################################
                     [1m Learning iteration 633/3000 [0m                      

                       Computation: 89198 steps/s (collection: 0.973s, learning 0.129s)
               Value function loss: 0.8621
                    Surrogate loss: -0.0030
             Mean action noise std: 0.4838
                     Learning rate: 0.0006
                       Mean reward: 26.00
               Mean episode length: 430.02
       Episode_Reward/keep_balance: 0.4246
     Episode_Reward/rew_lin_vel_xy: 1.0527
      Episode_Reward/rew_ang_vel_z: 1.2827
    Episode_Reward/pen_base_height: -0.2539
      Episode_Reward/pen_lin_vel_z: -0.0497
     Episode_Reward/pen_ang_vel_xy: -0.0632
   Episode_Reward/pen_joint_torque: -0.0764
    Episode_Reward/pen_joint_accel: -0.0370
    Episode_Reward/pen_action_rate: -0.0858
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0156
   Episode_Reward/pen_joint_powers: -0.0274
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1782
Episode_Reward/pen_flat_orientation: -0.1417
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1019
   Episode_Reward/foot_landing_vel: -0.0595
   Episode_Reward/test_gait_reward: -0.3996
Metrics/base_velocity/error_vel_xy: 1.3412
Metrics/base_velocity/error_vel_yaw: 0.3856
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 1.10s
                        Total time: 687.68s
                               ETA: 2567.4s

################################################################################
                     [1m Learning iteration 634/3000 [0m                      

                       Computation: 89842 steps/s (collection: 0.965s, learning 0.129s)
               Value function loss: 0.9220
                    Surrogate loss: 0.0004
             Mean action noise std: 0.4839
                     Learning rate: 0.0004
                       Mean reward: 22.40
               Mean episode length: 376.82
       Episode_Reward/keep_balance: 0.3731
     Episode_Reward/rew_lin_vel_xy: 0.9225
      Episode_Reward/rew_ang_vel_z: 1.1241
    Episode_Reward/pen_base_height: -0.2352
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.0569
   Episode_Reward/pen_joint_torque: -0.0644
    Episode_Reward/pen_joint_accel: -0.0366
    Episode_Reward/pen_action_rate: -0.0743
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0135
   Episode_Reward/pen_joint_powers: -0.0232
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1569
Episode_Reward/pen_flat_orientation: -0.1295
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0886
   Episode_Reward/foot_landing_vel: -0.0498
   Episode_Reward/test_gait_reward: -0.3530
Metrics/base_velocity/error_vel_xy: 1.1463
Metrics/base_velocity/error_vel_yaw: 0.3416
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 1.09s
                        Total time: 688.78s
                               ETA: 2566.4s

################################################################################
                     [1m Learning iteration 635/3000 [0m                      

                       Computation: 89704 steps/s (collection: 0.969s, learning 0.127s)
               Value function loss: 0.9370
                    Surrogate loss: 0.0014
             Mean action noise std: 0.4840
                     Learning rate: 0.0002
                       Mean reward: 31.38
               Mean episode length: 457.52
       Episode_Reward/keep_balance: 0.4368
     Episode_Reward/rew_lin_vel_xy: 1.1012
      Episode_Reward/rew_ang_vel_z: 1.3406
    Episode_Reward/pen_base_height: -0.2463
      Episode_Reward/pen_lin_vel_z: -0.0471
     Episode_Reward/pen_ang_vel_xy: -0.0610
   Episode_Reward/pen_joint_torque: -0.0733
    Episode_Reward/pen_joint_accel: -0.0380
    Episode_Reward/pen_action_rate: -0.0859
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0151
   Episode_Reward/pen_joint_powers: -0.0264
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1819
Episode_Reward/pen_flat_orientation: -0.1328
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0937
   Episode_Reward/foot_landing_vel: -0.0579
   Episode_Reward/test_gait_reward: -0.4098
Metrics/base_velocity/error_vel_xy: 1.3510
Metrics/base_velocity/error_vel_yaw: 0.3827
      Episode_Termination/time_out: 2.2917
  Episode_Termination/base_contact: 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 1.10s
                        Total time: 689.87s
                               ETA: 2565.3s

################################################################################
                     [1m Learning iteration 636/3000 [0m                      

                       Computation: 91449 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.8784
                    Surrogate loss: -0.0015
             Mean action noise std: 0.4847
                     Learning rate: 0.0003
                       Mean reward: 23.06
               Mean episode length: 368.84
       Episode_Reward/keep_balance: 0.4134
     Episode_Reward/rew_lin_vel_xy: 1.0675
      Episode_Reward/rew_ang_vel_z: 1.2587
    Episode_Reward/pen_base_height: -0.2470
      Episode_Reward/pen_lin_vel_z: -0.0470
     Episode_Reward/pen_ang_vel_xy: -0.0591
   Episode_Reward/pen_joint_torque: -0.0740
    Episode_Reward/pen_joint_accel: -0.0395
    Episode_Reward/pen_action_rate: -0.0830
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0149
   Episode_Reward/pen_joint_powers: -0.0260
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.1741
Episode_Reward/pen_flat_orientation: -0.1334
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0962
   Episode_Reward/foot_landing_vel: -0.0551
   Episode_Reward/test_gait_reward: -0.3888
Metrics/base_velocity/error_vel_xy: 1.2380
Metrics/base_velocity/error_vel_yaw: 0.3680
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 1.07s
                        Total time: 690.95s
                               ETA: 2564.2s

################################################################################
                     [1m Learning iteration 637/3000 [0m                      

                       Computation: 88325 steps/s (collection: 0.984s, learning 0.129s)
               Value function loss: 0.8990
                    Surrogate loss: -0.0001
             Mean action noise std: 0.4849
                     Learning rate: 0.0004
                       Mean reward: 27.79
               Mean episode length: 432.64
       Episode_Reward/keep_balance: 0.4317
     Episode_Reward/rew_lin_vel_xy: 1.0533
      Episode_Reward/rew_ang_vel_z: 1.3118
    Episode_Reward/pen_base_height: -0.2521
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.0628
   Episode_Reward/pen_joint_torque: -0.0788
    Episode_Reward/pen_joint_accel: -0.0397
    Episode_Reward/pen_action_rate: -0.0887
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0160
   Episode_Reward/pen_joint_powers: -0.0279
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.1833
Episode_Reward/pen_flat_orientation: -0.1341
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1069
   Episode_Reward/foot_landing_vel: -0.0575
   Episode_Reward/test_gait_reward: -0.4088
Metrics/base_velocity/error_vel_xy: 1.3909
Metrics/base_velocity/error_vel_yaw: 0.3860
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 1.11s
                        Total time: 692.06s
                               ETA: 2563.2s

################################################################################
                     [1m Learning iteration 638/3000 [0m                      

                       Computation: 91443 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.9363
                    Surrogate loss: -0.0019
             Mean action noise std: 0.4850
                     Learning rate: 0.0006
                       Mean reward: 34.28
               Mean episode length: 506.53
       Episode_Reward/keep_balance: 0.5023
     Episode_Reward/rew_lin_vel_xy: 1.2989
      Episode_Reward/rew_ang_vel_z: 1.5326
    Episode_Reward/pen_base_height: -0.2703
      Episode_Reward/pen_lin_vel_z: -0.0550
     Episode_Reward/pen_ang_vel_xy: -0.0674
   Episode_Reward/pen_joint_torque: -0.0898
    Episode_Reward/pen_joint_accel: -0.0466
    Episode_Reward/pen_action_rate: -0.1022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0178
   Episode_Reward/pen_joint_powers: -0.0314
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2137
Episode_Reward/pen_flat_orientation: -0.1452
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1164
   Episode_Reward/foot_landing_vel: -0.0656
   Episode_Reward/test_gait_reward: -0.4742
Metrics/base_velocity/error_vel_xy: 1.5246
Metrics/base_velocity/error_vel_yaw: 0.4445
      Episode_Termination/time_out: 2.2917
  Episode_Termination/base_contact: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 1.08s
                        Total time: 693.14s
                               ETA: 2562.1s

################################################################################
                     [1m Learning iteration 639/3000 [0m                      

                       Computation: 89703 steps/s (collection: 0.966s, learning 0.130s)
               Value function loss: 1.1324
                    Surrogate loss: 0.0009
             Mean action noise std: 0.4847
                     Learning rate: 0.0004
                       Mean reward: 29.01
               Mean episode length: 483.17
       Episode_Reward/keep_balance: 0.4381
     Episode_Reward/rew_lin_vel_xy: 1.0704
      Episode_Reward/rew_ang_vel_z: 1.3218
    Episode_Reward/pen_base_height: -0.2620
      Episode_Reward/pen_lin_vel_z: -0.0509
     Episode_Reward/pen_ang_vel_xy: -0.0651
   Episode_Reward/pen_joint_torque: -0.0787
    Episode_Reward/pen_joint_accel: -0.0398
    Episode_Reward/pen_action_rate: -0.0900
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0164
   Episode_Reward/pen_joint_powers: -0.0284
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1872
Episode_Reward/pen_flat_orientation: -0.1405
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1116
   Episode_Reward/foot_landing_vel: -0.0590
   Episode_Reward/test_gait_reward: -0.4141
Metrics/base_velocity/error_vel_xy: 1.4114
Metrics/base_velocity/error_vel_yaw: 0.3987
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 1.10s
                        Total time: 694.23s
                               ETA: 2561.1s

################################################################################
                     [1m Learning iteration 640/3000 [0m                      

                       Computation: 91101 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.9075
                    Surrogate loss: -0.0035
             Mean action noise std: 0.4854
                     Learning rate: 0.0009
                       Mean reward: 25.02
               Mean episode length: 394.80
       Episode_Reward/keep_balance: 0.3758
     Episode_Reward/rew_lin_vel_xy: 1.0091
      Episode_Reward/rew_ang_vel_z: 1.1370
    Episode_Reward/pen_base_height: -0.2377
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.0578
   Episode_Reward/pen_joint_torque: -0.0634
    Episode_Reward/pen_joint_accel: -0.0347
    Episode_Reward/pen_action_rate: -0.0759
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0236
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1595
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0927
   Episode_Reward/foot_landing_vel: -0.0524
   Episode_Reward/test_gait_reward: -0.3562
Metrics/base_velocity/error_vel_xy: 1.1286
Metrics/base_velocity/error_vel_yaw: 0.3409
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 1.08s
                        Total time: 695.31s
                               ETA: 2560.0s

################################################################################
                     [1m Learning iteration 641/3000 [0m                      

                       Computation: 91058 steps/s (collection: 0.955s, learning 0.125s)
               Value function loss: 1.0589
                    Surrogate loss: -0.0025
             Mean action noise std: 0.4858
                     Learning rate: 0.0013
                       Mean reward: 24.14
               Mean episode length: 375.66
       Episode_Reward/keep_balance: 0.3949
     Episode_Reward/rew_lin_vel_xy: 1.0870
      Episode_Reward/rew_ang_vel_z: 1.1917
    Episode_Reward/pen_base_height: -0.2393
      Episode_Reward/pen_lin_vel_z: -0.0440
     Episode_Reward/pen_ang_vel_xy: -0.0558
   Episode_Reward/pen_joint_torque: -0.0664
    Episode_Reward/pen_joint_accel: -0.0339
    Episode_Reward/pen_action_rate: -0.0786
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0138
   Episode_Reward/pen_joint_powers: -0.0239
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1684
Episode_Reward/pen_flat_orientation: -0.1245
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0939
   Episode_Reward/foot_landing_vel: -0.0523
   Episode_Reward/test_gait_reward: -0.3720
Metrics/base_velocity/error_vel_xy: 1.1744
Metrics/base_velocity/error_vel_yaw: 0.3605
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 1.08s
                        Total time: 696.39s
                               ETA: 2558.9s

################################################################################
                     [1m Learning iteration 642/3000 [0m                      

                       Computation: 89290 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 1.1301
                    Surrogate loss: 0.0021
             Mean action noise std: 0.4858
                     Learning rate: 0.0002
                       Mean reward: 22.42
               Mean episode length: 383.04
       Episode_Reward/keep_balance: 0.4091
     Episode_Reward/rew_lin_vel_xy: 1.0230
      Episode_Reward/rew_ang_vel_z: 1.2382
    Episode_Reward/pen_base_height: -0.2409
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.0593
   Episode_Reward/pen_joint_torque: -0.0692
    Episode_Reward/pen_joint_accel: -0.0376
    Episode_Reward/pen_action_rate: -0.0821
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0143
   Episode_Reward/pen_joint_powers: -0.0247
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1752
Episode_Reward/pen_flat_orientation: -0.1271
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0918
   Episode_Reward/foot_landing_vel: -0.0527
   Episode_Reward/test_gait_reward: -0.3842
Metrics/base_velocity/error_vel_xy: 1.3384
Metrics/base_velocity/error_vel_yaw: 0.3705
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 1.10s
                        Total time: 697.49s
                               ETA: 2557.8s

################################################################################
                     [1m Learning iteration 643/3000 [0m                      

                       Computation: 90022 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.9917
                    Surrogate loss: 0.0103
             Mean action noise std: 0.4859
                     Learning rate: 0.0000
                       Mean reward: 29.87
               Mean episode length: 472.51
       Episode_Reward/keep_balance: 0.4359
     Episode_Reward/rew_lin_vel_xy: 1.1222
      Episode_Reward/rew_ang_vel_z: 1.3094
    Episode_Reward/pen_base_height: -0.2592
      Episode_Reward/pen_lin_vel_z: -0.0503
     Episode_Reward/pen_ang_vel_xy: -0.0619
   Episode_Reward/pen_joint_torque: -0.0794
    Episode_Reward/pen_joint_accel: -0.0405
    Episode_Reward/pen_action_rate: -0.0895
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0279
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1872
Episode_Reward/pen_flat_orientation: -0.1297
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1081
   Episode_Reward/foot_landing_vel: -0.0603
   Episode_Reward/test_gait_reward: -0.4112
Metrics/base_velocity/error_vel_xy: 1.3243
Metrics/base_velocity/error_vel_yaw: 0.4019
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 1.09s
                        Total time: 698.59s
                               ETA: 2556.8s

################################################################################
                     [1m Learning iteration 644/3000 [0m                      

                       Computation: 89887 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.8951
                    Surrogate loss: 0.0063
             Mean action noise std: 0.4860
                     Learning rate: 0.0000
                       Mean reward: 27.70
               Mean episode length: 444.75
       Episode_Reward/keep_balance: 0.4427
     Episode_Reward/rew_lin_vel_xy: 1.2308
      Episode_Reward/rew_ang_vel_z: 1.3576
    Episode_Reward/pen_base_height: -0.2565
      Episode_Reward/pen_lin_vel_z: -0.0500
     Episode_Reward/pen_ang_vel_xy: -0.0617
   Episode_Reward/pen_joint_torque: -0.0795
    Episode_Reward/pen_joint_accel: -0.0400
    Episode_Reward/pen_action_rate: -0.0893
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0279
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1875
Episode_Reward/pen_flat_orientation: -0.1357
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1065
   Episode_Reward/foot_landing_vel: -0.0609
   Episode_Reward/test_gait_reward: -0.4168
Metrics/base_velocity/error_vel_xy: 1.2922
Metrics/base_velocity/error_vel_yaw: 0.3862
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 1.09s
                        Total time: 699.68s
                               ETA: 2555.7s

################################################################################
                     [1m Learning iteration 645/3000 [0m                      

                       Computation: 90377 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.9338
                    Surrogate loss: -0.0012
             Mean action noise std: 0.4861
                     Learning rate: 0.0001
                       Mean reward: 26.07
               Mean episode length: 394.64
       Episode_Reward/keep_balance: 0.4438
     Episode_Reward/rew_lin_vel_xy: 1.1522
      Episode_Reward/rew_ang_vel_z: 1.3601
    Episode_Reward/pen_base_height: -0.2562
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.0617
   Episode_Reward/pen_joint_torque: -0.0796
    Episode_Reward/pen_joint_accel: -0.0379
    Episode_Reward/pen_action_rate: -0.0899
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0158
   Episode_Reward/pen_joint_powers: -0.0280
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1885
Episode_Reward/pen_flat_orientation: -0.1327
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1058
   Episode_Reward/foot_landing_vel: -0.0587
   Episode_Reward/test_gait_reward: -0.4185
Metrics/base_velocity/error_vel_xy: 1.3683
Metrics/base_velocity/error_vel_yaw: 0.3878
      Episode_Termination/time_out: 2.5833
  Episode_Termination/base_contact: 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 1.09s
                        Total time: 700.77s
                               ETA: 2554.7s

################################################################################
                     [1m Learning iteration 646/3000 [0m                      

                       Computation: 90424 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 1.0344
                    Surrogate loss: -0.0019
             Mean action noise std: 0.4862
                     Learning rate: 0.0004
                       Mean reward: 25.76
               Mean episode length: 404.68
       Episode_Reward/keep_balance: 0.4017
     Episode_Reward/rew_lin_vel_xy: 1.0467
      Episode_Reward/rew_ang_vel_z: 1.2280
    Episode_Reward/pen_base_height: -0.2394
      Episode_Reward/pen_lin_vel_z: -0.0437
     Episode_Reward/pen_ang_vel_xy: -0.0565
   Episode_Reward/pen_joint_torque: -0.0712
    Episode_Reward/pen_joint_accel: -0.0374
    Episode_Reward/pen_action_rate: -0.0802
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0245
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1704
Episode_Reward/pen_flat_orientation: -0.1223
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0888
   Episode_Reward/foot_landing_vel: -0.0516
   Episode_Reward/test_gait_reward: -0.3761
Metrics/base_velocity/error_vel_xy: 1.2393
Metrics/base_velocity/error_vel_yaw: 0.3544
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 1.09s
                        Total time: 701.85s
                               ETA: 2553.6s

################################################################################
                     [1m Learning iteration 647/3000 [0m                      

                       Computation: 90660 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.9103
                    Surrogate loss: 0.0044
             Mean action noise std: 0.4862
                     Learning rate: 0.0001
                       Mean reward: 26.23
               Mean episode length: 406.51
       Episode_Reward/keep_balance: 0.3987
     Episode_Reward/rew_lin_vel_xy: 1.0480
      Episode_Reward/rew_ang_vel_z: 1.1991
    Episode_Reward/pen_base_height: -0.2418
      Episode_Reward/pen_lin_vel_z: -0.0452
     Episode_Reward/pen_ang_vel_xy: -0.0570
   Episode_Reward/pen_joint_torque: -0.0709
    Episode_Reward/pen_joint_accel: -0.0363
    Episode_Reward/pen_action_rate: -0.0812
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0249
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1736
Episode_Reward/pen_flat_orientation: -0.1317
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0975
   Episode_Reward/foot_landing_vel: -0.0533
   Episode_Reward/test_gait_reward: -0.3760
Metrics/base_velocity/error_vel_xy: 1.2579
Metrics/base_velocity/error_vel_yaw: 0.3675
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 1.08s
                        Total time: 702.94s
                               ETA: 2552.5s

################################################################################
                     [1m Learning iteration 648/3000 [0m                      

                       Computation: 91119 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.8830
                    Surrogate loss: 0.0012
             Mean action noise std: 0.4863
                     Learning rate: 0.0002
                       Mean reward: 24.45
               Mean episode length: 427.93
       Episode_Reward/keep_balance: 0.4237
     Episode_Reward/rew_lin_vel_xy: 1.0010
      Episode_Reward/rew_ang_vel_z: 1.2870
    Episode_Reward/pen_base_height: -0.2514
      Episode_Reward/pen_lin_vel_z: -0.0481
     Episode_Reward/pen_ang_vel_xy: -0.0607
   Episode_Reward/pen_joint_torque: -0.0761
    Episode_Reward/pen_joint_accel: -0.0401
    Episode_Reward/pen_action_rate: -0.0869
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0153
   Episode_Reward/pen_joint_powers: -0.0267
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1827
Episode_Reward/pen_flat_orientation: -0.1323
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1042
   Episode_Reward/foot_landing_vel: -0.0593
   Episode_Reward/test_gait_reward: -0.3989
Metrics/base_velocity/error_vel_xy: 1.4216
Metrics/base_velocity/error_vel_yaw: 0.3807
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 1.08s
                        Total time: 704.02s
                               ETA: 2551.4s

################################################################################
                     [1m Learning iteration 649/3000 [0m                      

                       Computation: 90944 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.9868
                    Surrogate loss: 0.0024
             Mean action noise std: 0.4859
                     Learning rate: 0.0001
                       Mean reward: 23.74
               Mean episode length: 370.05
       Episode_Reward/keep_balance: 0.3639
     Episode_Reward/rew_lin_vel_xy: 0.9532
      Episode_Reward/rew_ang_vel_z: 1.1129
    Episode_Reward/pen_base_height: -0.2267
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.0518
   Episode_Reward/pen_joint_torque: -0.0629
    Episode_Reward/pen_joint_accel: -0.0298
    Episode_Reward/pen_action_rate: -0.0716
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0121
   Episode_Reward/pen_joint_powers: -0.0218
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1532
Episode_Reward/pen_flat_orientation: -0.1156
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0791
   Episode_Reward/foot_landing_vel: -0.0439
   Episode_Reward/test_gait_reward: -0.3416
Metrics/base_velocity/error_vel_xy: 1.1441
Metrics/base_velocity/error_vel_yaw: 0.3216
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 1.08s
                        Total time: 705.10s
                               ETA: 2550.3s

################################################################################
                     [1m Learning iteration 650/3000 [0m                      

                       Computation: 86797 steps/s (collection: 0.961s, learning 0.172s)
               Value function loss: 0.9281
                    Surrogate loss: -0.0019
             Mean action noise std: 0.4857
                     Learning rate: 0.0003
                       Mean reward: 28.99
               Mean episode length: 439.65
       Episode_Reward/keep_balance: 0.3933
     Episode_Reward/rew_lin_vel_xy: 1.0481
      Episode_Reward/rew_ang_vel_z: 1.1951
    Episode_Reward/pen_base_height: -0.2430
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.0582
   Episode_Reward/pen_joint_torque: -0.0687
    Episode_Reward/pen_joint_accel: -0.0358
    Episode_Reward/pen_action_rate: -0.0796
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0246
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1690
Episode_Reward/pen_flat_orientation: -0.1265
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0934
   Episode_Reward/foot_landing_vel: -0.0530
   Episode_Reward/test_gait_reward: -0.3702
Metrics/base_velocity/error_vel_xy: 1.2014
Metrics/base_velocity/error_vel_yaw: 0.3530
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 1.13s
                        Total time: 706.23s
                               ETA: 2549.4s

################################################################################
                     [1m Learning iteration 651/3000 [0m                      

                       Computation: 90995 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 1.0599
                    Surrogate loss: 0.0013
             Mean action noise std: 0.4856
                     Learning rate: 0.0002
                       Mean reward: 21.01
               Mean episode length: 358.41
       Episode_Reward/keep_balance: 0.3864
     Episode_Reward/rew_lin_vel_xy: 1.0210
      Episode_Reward/rew_ang_vel_z: 1.1748
    Episode_Reward/pen_base_height: -0.2404
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.0548
   Episode_Reward/pen_joint_torque: -0.0681
    Episode_Reward/pen_joint_accel: -0.0352
    Episode_Reward/pen_action_rate: -0.0774
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0239
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1647
Episode_Reward/pen_flat_orientation: -0.1209
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0932
   Episode_Reward/foot_landing_vel: -0.0522
   Episode_Reward/test_gait_reward: -0.3650
Metrics/base_velocity/error_vel_xy: 1.1761
Metrics/base_velocity/error_vel_yaw: 0.3464
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 9.7500
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 1.08s
                        Total time: 707.31s
                               ETA: 2548.3s

################################################################################
                     [1m Learning iteration 652/3000 [0m                      

                       Computation: 90156 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.9683
                    Surrogate loss: -0.0003
             Mean action noise std: 0.4863
                     Learning rate: 0.0004
                       Mean reward: 25.28
               Mean episode length: 398.39
       Episode_Reward/keep_balance: 0.3742
     Episode_Reward/rew_lin_vel_xy: 0.9708
      Episode_Reward/rew_ang_vel_z: 1.1404
    Episode_Reward/pen_base_height: -0.2371
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.0553
   Episode_Reward/pen_joint_torque: -0.0673
    Episode_Reward/pen_joint_accel: -0.0327
    Episode_Reward/pen_action_rate: -0.0758
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0135
   Episode_Reward/pen_joint_powers: -0.0237
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1602
Episode_Reward/pen_flat_orientation: -0.1207
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0927
   Episode_Reward/foot_landing_vel: -0.0505
   Episode_Reward/test_gait_reward: -0.3530
Metrics/base_velocity/error_vel_xy: 1.1822
Metrics/base_velocity/error_vel_yaw: 0.3338
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 1.09s
                        Total time: 708.40s
                               ETA: 2547.2s

################################################################################
                     [1m Learning iteration 653/3000 [0m                      

                       Computation: 88780 steps/s (collection: 0.982s, learning 0.125s)
               Value function loss: 1.0193
                    Surrogate loss: -0.0012
             Mean action noise std: 0.4865
                     Learning rate: 0.0009
                       Mean reward: 26.97
               Mean episode length: 397.58
       Episode_Reward/keep_balance: 0.3770
     Episode_Reward/rew_lin_vel_xy: 1.0350
      Episode_Reward/rew_ang_vel_z: 1.1447
    Episode_Reward/pen_base_height: -0.2367
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.0551
   Episode_Reward/pen_joint_torque: -0.0690
    Episode_Reward/pen_joint_accel: -0.0354
    Episode_Reward/pen_action_rate: -0.0768
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0140
   Episode_Reward/pen_joint_powers: -0.0243
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1619
Episode_Reward/pen_flat_orientation: -0.1176
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0932
   Episode_Reward/foot_landing_vel: -0.0534
   Episode_Reward/test_gait_reward: -0.3582
Metrics/base_velocity/error_vel_xy: 1.1426
Metrics/base_velocity/error_vel_yaw: 0.3369
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 1.11s
                        Total time: 709.51s
                               ETA: 2546.2s

################################################################################
                     [1m Learning iteration 654/3000 [0m                      

                       Computation: 88869 steps/s (collection: 0.981s, learning 0.125s)
               Value function loss: 1.1003
                    Surrogate loss: 0.0048
             Mean action noise std: 0.4866
                     Learning rate: 0.0001
                       Mean reward: 24.23
               Mean episode length: 363.16
       Episode_Reward/keep_balance: 0.4033
     Episode_Reward/rew_lin_vel_xy: 1.0575
      Episode_Reward/rew_ang_vel_z: 1.2283
    Episode_Reward/pen_base_height: -0.2450
      Episode_Reward/pen_lin_vel_z: -0.0456
     Episode_Reward/pen_ang_vel_xy: -0.0570
   Episode_Reward/pen_joint_torque: -0.0701
    Episode_Reward/pen_joint_accel: -0.0350
    Episode_Reward/pen_action_rate: -0.0818
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0140
   Episode_Reward/pen_joint_powers: -0.0246
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1735
Episode_Reward/pen_flat_orientation: -0.1225
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0953
   Episode_Reward/foot_landing_vel: -0.0531
   Episode_Reward/test_gait_reward: -0.3782
Metrics/base_velocity/error_vel_xy: 1.2402
Metrics/base_velocity/error_vel_yaw: 0.3590
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 1.11s
                        Total time: 710.61s
                               ETA: 2545.2s

################################################################################
                     [1m Learning iteration 655/3000 [0m                      

                       Computation: 89158 steps/s (collection: 0.978s, learning 0.124s)
               Value function loss: 0.9606
                    Surrogate loss: 0.0090
             Mean action noise std: 0.4866
                     Learning rate: 0.0000
                       Mean reward: 22.71
               Mean episode length: 363.09
       Episode_Reward/keep_balance: 0.3749
     Episode_Reward/rew_lin_vel_xy: 1.0407
      Episode_Reward/rew_ang_vel_z: 1.1394
    Episode_Reward/pen_base_height: -0.2356
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.0547
   Episode_Reward/pen_joint_torque: -0.0650
    Episode_Reward/pen_joint_accel: -0.0329
    Episode_Reward/pen_action_rate: -0.0752
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0232
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1611
Episode_Reward/pen_flat_orientation: -0.1195
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0923
   Episode_Reward/foot_landing_vel: -0.0500
   Episode_Reward/test_gait_reward: -0.3525
Metrics/base_velocity/error_vel_xy: 1.0928
Metrics/base_velocity/error_vel_yaw: 0.3377
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 1.10s
                        Total time: 711.72s
                               ETA: 2544.2s

################################################################################
                     [1m Learning iteration 656/3000 [0m                      

                       Computation: 90185 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.8520
                    Surrogate loss: 0.0046
             Mean action noise std: 0.4866
                     Learning rate: 0.0000
                       Mean reward: 26.60
               Mean episode length: 414.07
       Episode_Reward/keep_balance: 0.4326
     Episode_Reward/rew_lin_vel_xy: 1.1695
      Episode_Reward/rew_ang_vel_z: 1.3372
    Episode_Reward/pen_base_height: -0.2537
      Episode_Reward/pen_lin_vel_z: -0.0497
     Episode_Reward/pen_ang_vel_xy: -0.0594
   Episode_Reward/pen_joint_torque: -0.0780
    Episode_Reward/pen_joint_accel: -0.0380
    Episode_Reward/pen_action_rate: -0.0875
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0150
   Episode_Reward/pen_joint_powers: -0.0269
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1844
Episode_Reward/pen_flat_orientation: -0.1296
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1017
   Episode_Reward/foot_landing_vel: -0.0567
   Episode_Reward/test_gait_reward: -0.4073
Metrics/base_velocity/error_vel_xy: 1.2944
Metrics/base_velocity/error_vel_yaw: 0.3716
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 1.09s
                        Total time: 712.81s
                               ETA: 2543.1s

################################################################################
                     [1m Learning iteration 657/3000 [0m                      

                       Computation: 90653 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.8579
                    Surrogate loss: 0.0149
             Mean action noise std: 0.4866
                     Learning rate: 0.0000
                       Mean reward: 25.35
               Mean episode length: 396.28
       Episode_Reward/keep_balance: 0.3803
     Episode_Reward/rew_lin_vel_xy: 1.0022
      Episode_Reward/rew_ang_vel_z: 1.1525
    Episode_Reward/pen_base_height: -0.2388
      Episode_Reward/pen_lin_vel_z: -0.0449
     Episode_Reward/pen_ang_vel_xy: -0.0565
   Episode_Reward/pen_joint_torque: -0.0660
    Episode_Reward/pen_joint_accel: -0.0367
    Episode_Reward/pen_action_rate: -0.0776
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0236
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1654
Episode_Reward/pen_flat_orientation: -0.1186
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0940
   Episode_Reward/foot_landing_vel: -0.0546
   Episode_Reward/test_gait_reward: -0.3587
Metrics/base_velocity/error_vel_xy: 1.1795
Metrics/base_velocity/error_vel_yaw: 0.3429
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 9.7500
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 1.08s
                        Total time: 713.89s
                               ETA: 2542.0s

################################################################################
                     [1m Learning iteration 658/3000 [0m                      

                       Computation: 91552 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 0.8964
                    Surrogate loss: 0.0054
             Mean action noise std: 0.4866
                     Learning rate: 0.0000
                       Mean reward: 23.72
               Mean episode length: 388.88
       Episode_Reward/keep_balance: 0.4007
     Episode_Reward/rew_lin_vel_xy: 1.0321
      Episode_Reward/rew_ang_vel_z: 1.2090
    Episode_Reward/pen_base_height: -0.2472
      Episode_Reward/pen_lin_vel_z: -0.0459
     Episode_Reward/pen_ang_vel_xy: -0.0573
   Episode_Reward/pen_joint_torque: -0.0724
    Episode_Reward/pen_joint_accel: -0.0351
    Episode_Reward/pen_action_rate: -0.0817
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0250
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1751
Episode_Reward/pen_flat_orientation: -0.1243
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0968
   Episode_Reward/foot_landing_vel: -0.0537
   Episode_Reward/test_gait_reward: -0.3776
Metrics/base_velocity/error_vel_xy: 1.2499
Metrics/base_velocity/error_vel_yaw: 0.3661
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 1.07s
                        Total time: 714.97s
                               ETA: 2540.9s

################################################################################
                     [1m Learning iteration 659/3000 [0m                      

                       Computation: 91524 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.9070
                    Surrogate loss: 0.0085
             Mean action noise std: 0.4867
                     Learning rate: 0.0000
                       Mean reward: 29.29
               Mean episode length: 444.08
       Episode_Reward/keep_balance: 0.4145
     Episode_Reward/rew_lin_vel_xy: 1.0670
      Episode_Reward/rew_ang_vel_z: 1.2723
    Episode_Reward/pen_base_height: -0.2472
      Episode_Reward/pen_lin_vel_z: -0.0475
     Episode_Reward/pen_ang_vel_xy: -0.0594
   Episode_Reward/pen_joint_torque: -0.0740
    Episode_Reward/pen_joint_accel: -0.0369
    Episode_Reward/pen_action_rate: -0.0839
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0143
   Episode_Reward/pen_joint_powers: -0.0258
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1780
Episode_Reward/pen_flat_orientation: -0.1223
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0977
   Episode_Reward/foot_landing_vel: -0.0542
   Episode_Reward/test_gait_reward: -0.3918
Metrics/base_velocity/error_vel_xy: 1.3049
Metrics/base_velocity/error_vel_yaw: 0.3617
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 1.07s
                        Total time: 716.04s
                               ETA: 2539.8s

################################################################################
                     [1m Learning iteration 660/3000 [0m                      

                       Computation: 90380 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.9831
                    Surrogate loss: 0.0007
             Mean action noise std: 0.4869
                     Learning rate: 0.0001
                       Mean reward: 26.51
               Mean episode length: 381.01
       Episode_Reward/keep_balance: 0.3790
     Episode_Reward/rew_lin_vel_xy: 1.0582
      Episode_Reward/rew_ang_vel_z: 1.1583
    Episode_Reward/pen_base_height: -0.2353
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.0541
   Episode_Reward/pen_joint_torque: -0.0644
    Episode_Reward/pen_joint_accel: -0.0325
    Episode_Reward/pen_action_rate: -0.0758
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0126
   Episode_Reward/pen_joint_powers: -0.0223
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1630
Episode_Reward/pen_flat_orientation: -0.1148
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0835
   Episode_Reward/foot_landing_vel: -0.0501
   Episode_Reward/test_gait_reward: -0.3566
Metrics/base_velocity/error_vel_xy: 1.1392
Metrics/base_velocity/error_vel_yaw: 0.3365
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 1.09s
                        Total time: 717.13s
                               ETA: 2538.7s

################################################################################
                     [1m Learning iteration 661/3000 [0m                      

                       Computation: 89764 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 0.8431
                    Surrogate loss: -0.0019
             Mean action noise std: 0.4870
                     Learning rate: 0.0003
                       Mean reward: 31.29
               Mean episode length: 441.53
       Episode_Reward/keep_balance: 0.4261
     Episode_Reward/rew_lin_vel_xy: 1.1855
      Episode_Reward/rew_ang_vel_z: 1.3066
    Episode_Reward/pen_base_height: -0.2517
      Episode_Reward/pen_lin_vel_z: -0.0478
     Episode_Reward/pen_ang_vel_xy: -0.0591
   Episode_Reward/pen_joint_torque: -0.0740
    Episode_Reward/pen_joint_accel: -0.0365
    Episode_Reward/pen_action_rate: -0.0867
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0145
   Episode_Reward/pen_joint_powers: -0.0258
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1840
Episode_Reward/pen_flat_orientation: -0.1273
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0989
   Episode_Reward/foot_landing_vel: -0.0588
   Episode_Reward/test_gait_reward: -0.4011
Metrics/base_velocity/error_vel_xy: 1.2429
Metrics/base_velocity/error_vel_yaw: 0.3728
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 1.10s
                        Total time: 718.22s
                               ETA: 2537.6s

################################################################################
                     [1m Learning iteration 662/3000 [0m                      

                       Computation: 90841 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 1.0279
                    Surrogate loss: 0.0010
             Mean action noise std: 0.4871
                     Learning rate: 0.0001
                       Mean reward: 23.58
               Mean episode length: 410.17
       Episode_Reward/keep_balance: 0.3954
     Episode_Reward/rew_lin_vel_xy: 1.0558
      Episode_Reward/rew_ang_vel_z: 1.2013
    Episode_Reward/pen_base_height: -0.2445
      Episode_Reward/pen_lin_vel_z: -0.0474
     Episode_Reward/pen_ang_vel_xy: -0.0567
   Episode_Reward/pen_joint_torque: -0.0724
    Episode_Reward/pen_joint_accel: -0.0386
    Episode_Reward/pen_action_rate: -0.0819
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0253
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1726
Episode_Reward/pen_flat_orientation: -0.1231
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1001
   Episode_Reward/foot_landing_vel: -0.0582
   Episode_Reward/test_gait_reward: -0.3715
Metrics/base_velocity/error_vel_xy: 1.2355
Metrics/base_velocity/error_vel_yaw: 0.3543
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 1.08s
                        Total time: 719.30s
                               ETA: 2536.6s

################################################################################
                     [1m Learning iteration 663/3000 [0m                      

                       Computation: 90973 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.9827
                    Surrogate loss: -0.0016
             Mean action noise std: 0.4872
                     Learning rate: 0.0004
                       Mean reward: 22.62
               Mean episode length: 336.76
       Episode_Reward/keep_balance: 0.3599
     Episode_Reward/rew_lin_vel_xy: 0.9636
      Episode_Reward/rew_ang_vel_z: 1.1014
    Episode_Reward/pen_base_height: -0.2312
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.0527
   Episode_Reward/pen_joint_torque: -0.0627
    Episode_Reward/pen_joint_accel: -0.0291
    Episode_Reward/pen_action_rate: -0.0714
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0124
   Episode_Reward/pen_joint_powers: -0.0220
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1540
Episode_Reward/pen_flat_orientation: -0.1113
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0845
   Episode_Reward/foot_landing_vel: -0.0476
   Episode_Reward/test_gait_reward: -0.3409
Metrics/base_velocity/error_vel_xy: 1.1116
Metrics/base_velocity/error_vel_yaw: 0.3185
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 1.08s
                        Total time: 720.38s
                               ETA: 2535.5s

################################################################################
                     [1m Learning iteration 664/3000 [0m                      

                       Computation: 89669 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.8882
                    Surrogate loss: -0.0017
             Mean action noise std: 0.4880
                     Learning rate: 0.0009
                       Mean reward: 19.76
               Mean episode length: 333.80
       Episode_Reward/keep_balance: 0.3791
     Episode_Reward/rew_lin_vel_xy: 0.9954
      Episode_Reward/rew_ang_vel_z: 1.1641
    Episode_Reward/pen_base_height: -0.2392
      Episode_Reward/pen_lin_vel_z: -0.0438
     Episode_Reward/pen_ang_vel_xy: -0.0543
   Episode_Reward/pen_joint_torque: -0.0675
    Episode_Reward/pen_joint_accel: -0.0342
    Episode_Reward/pen_action_rate: -0.0761
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0131
   Episode_Reward/pen_joint_powers: -0.0234
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1617
Episode_Reward/pen_flat_orientation: -0.1150
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0862
   Episode_Reward/foot_landing_vel: -0.0514
   Episode_Reward/test_gait_reward: -0.3583
Metrics/base_velocity/error_vel_xy: 1.1961
Metrics/base_velocity/error_vel_yaw: 0.3319
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 1.10s
                        Total time: 721.48s
                               ETA: 2534.4s

################################################################################
                     [1m Learning iteration 665/3000 [0m                      

                       Computation: 91350 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.9973
                    Surrogate loss: 0.0023
             Mean action noise std: 0.4883
                     Learning rate: 0.0004
                       Mean reward: 24.65
               Mean episode length: 372.09
       Episode_Reward/keep_balance: 0.3914
     Episode_Reward/rew_lin_vel_xy: 1.0406
      Episode_Reward/rew_ang_vel_z: 1.2099
    Episode_Reward/pen_base_height: -0.2385
      Episode_Reward/pen_lin_vel_z: -0.0430
     Episode_Reward/pen_ang_vel_xy: -0.0547
   Episode_Reward/pen_joint_torque: -0.0676
    Episode_Reward/pen_joint_accel: -0.0331
    Episode_Reward/pen_action_rate: -0.0778
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0131
   Episode_Reward/pen_joint_powers: -0.0234
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1667
Episode_Reward/pen_flat_orientation: -0.1161
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0883
   Episode_Reward/foot_landing_vel: -0.0500
   Episode_Reward/test_gait_reward: -0.3673
Metrics/base_velocity/error_vel_xy: 1.2066
Metrics/base_velocity/error_vel_yaw: 0.3359
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 1.08s
                        Total time: 722.56s
                               ETA: 2533.3s

################################################################################
                     [1m Learning iteration 666/3000 [0m                      

                       Computation: 91309 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 0.8633
                    Surrogate loss: 0.0051
             Mean action noise std: 0.4883
                     Learning rate: 0.0001
                       Mean reward: 27.86
               Mean episode length: 430.34
       Episode_Reward/keep_balance: 0.4473
     Episode_Reward/rew_lin_vel_xy: 1.1316
      Episode_Reward/rew_ang_vel_z: 1.3791
    Episode_Reward/pen_base_height: -0.2565
      Episode_Reward/pen_lin_vel_z: -0.0497
     Episode_Reward/pen_ang_vel_xy: -0.0610
   Episode_Reward/pen_joint_torque: -0.0799
    Episode_Reward/pen_joint_accel: -0.0401
    Episode_Reward/pen_action_rate: -0.0918
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0155
   Episode_Reward/pen_joint_powers: -0.0275
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.1954
Episode_Reward/pen_flat_orientation: -0.1265
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.1052
   Episode_Reward/foot_landing_vel: -0.0601
   Episode_Reward/test_gait_reward: -0.4185
Metrics/base_velocity/error_vel_xy: 1.4383
Metrics/base_velocity/error_vel_yaw: 0.3842
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 1.08s
                        Total time: 723.63s
                               ETA: 2532.2s

################################################################################
                     [1m Learning iteration 667/3000 [0m                      

                       Computation: 89708 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 0.8912
                    Surrogate loss: -0.0002
             Mean action noise std: 0.4883
                     Learning rate: 0.0002
                       Mean reward: 26.06
               Mean episode length: 393.62
       Episode_Reward/keep_balance: 0.3737
     Episode_Reward/rew_lin_vel_xy: 0.9956
      Episode_Reward/rew_ang_vel_z: 1.1546
    Episode_Reward/pen_base_height: -0.2312
      Episode_Reward/pen_lin_vel_z: -0.0420
     Episode_Reward/pen_ang_vel_xy: -0.0547
   Episode_Reward/pen_joint_torque: -0.0662
    Episode_Reward/pen_joint_accel: -0.0352
    Episode_Reward/pen_action_rate: -0.0752
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0130
   Episode_Reward/pen_joint_powers: -0.0230
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1611
Episode_Reward/pen_flat_orientation: -0.1105
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0879
   Episode_Reward/foot_landing_vel: -0.0499
   Episode_Reward/test_gait_reward: -0.3542
Metrics/base_velocity/error_vel_xy: 1.1366
Metrics/base_velocity/error_vel_yaw: 0.3214
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 1.10s
                        Total time: 724.73s
                               ETA: 2531.1s

################################################################################
                     [1m Learning iteration 668/3000 [0m                      

                       Computation: 90613 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.9728
                    Surrogate loss: 0.0006
             Mean action noise std: 0.4884
                     Learning rate: 0.0002
                       Mean reward: 26.77
               Mean episode length: 399.21
       Episode_Reward/keep_balance: 0.4163
     Episode_Reward/rew_lin_vel_xy: 1.1092
      Episode_Reward/rew_ang_vel_z: 1.2737
    Episode_Reward/pen_base_height: -0.2504
      Episode_Reward/pen_lin_vel_z: -0.0496
     Episode_Reward/pen_ang_vel_xy: -0.0589
   Episode_Reward/pen_joint_torque: -0.0756
    Episode_Reward/pen_joint_accel: -0.0404
    Episode_Reward/pen_action_rate: -0.0860
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0152
   Episode_Reward/pen_joint_powers: -0.0265
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1804
Episode_Reward/pen_flat_orientation: -0.1192
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1038
   Episode_Reward/foot_landing_vel: -0.0588
   Episode_Reward/test_gait_reward: -0.3947
Metrics/base_velocity/error_vel_xy: 1.2938
Metrics/base_velocity/error_vel_yaw: 0.3672
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 1.08s
                        Total time: 725.81s
                               ETA: 2530.0s

################################################################################
                     [1m Learning iteration 669/3000 [0m                      

                       Computation: 90212 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.9335
                    Surrogate loss: -0.0017
             Mean action noise std: 0.4890
                     Learning rate: 0.0006
                       Mean reward: 25.44
               Mean episode length: 392.39
       Episode_Reward/keep_balance: 0.3915
     Episode_Reward/rew_lin_vel_xy: 1.0123
      Episode_Reward/rew_ang_vel_z: 1.2059
    Episode_Reward/pen_base_height: -0.2375
      Episode_Reward/pen_lin_vel_z: -0.0443
     Episode_Reward/pen_ang_vel_xy: -0.0557
   Episode_Reward/pen_joint_torque: -0.0694
    Episode_Reward/pen_joint_accel: -0.0348
    Episode_Reward/pen_action_rate: -0.0785
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0240
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1674
Episode_Reward/pen_flat_orientation: -0.1140
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0895
   Episode_Reward/foot_landing_vel: -0.0522
   Episode_Reward/test_gait_reward: -0.3680
Metrics/base_velocity/error_vel_xy: 1.2492
Metrics/base_velocity/error_vel_yaw: 0.3374
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 1.09s
                        Total time: 726.90s
                               ETA: 2529.0s

################################################################################
                     [1m Learning iteration 670/3000 [0m                      

                       Computation: 91046 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 1.2002
                    Surrogate loss: 0.0044
             Mean action noise std: 0.4891
                     Learning rate: 0.0001
                       Mean reward: 24.80
               Mean episode length: 422.35
       Episode_Reward/keep_balance: 0.4030
     Episode_Reward/rew_lin_vel_xy: 1.0338
      Episode_Reward/rew_ang_vel_z: 1.2286
    Episode_Reward/pen_base_height: -0.2533
      Episode_Reward/pen_lin_vel_z: -0.0481
     Episode_Reward/pen_ang_vel_xy: -0.0585
   Episode_Reward/pen_joint_torque: -0.0734
    Episode_Reward/pen_joint_accel: -0.0382
    Episode_Reward/pen_action_rate: -0.0827
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0150
   Episode_Reward/pen_joint_powers: -0.0259
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1743
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1049
   Episode_Reward/foot_landing_vel: -0.0574
   Episode_Reward/test_gait_reward: -0.3850
Metrics/base_velocity/error_vel_xy: 1.2828
Metrics/base_velocity/error_vel_yaw: 0.3572
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 1.08s
                        Total time: 727.98s
                               ETA: 2527.9s

################################################################################
                     [1m Learning iteration 671/3000 [0m                      

                       Computation: 91149 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.9313
                    Surrogate loss: -0.0025
             Mean action noise std: 0.4895
                     Learning rate: 0.0003
                       Mean reward: 28.06
               Mean episode length: 409.75
       Episode_Reward/keep_balance: 0.3601
     Episode_Reward/rew_lin_vel_xy: 0.9804
      Episode_Reward/rew_ang_vel_z: 1.1014
    Episode_Reward/pen_base_height: -0.2316
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.0528
   Episode_Reward/pen_joint_torque: -0.0616
    Episode_Reward/pen_joint_accel: -0.0340
    Episode_Reward/pen_action_rate: -0.0721
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0124
   Episode_Reward/pen_joint_powers: -0.0217
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1554
Episode_Reward/pen_flat_orientation: -0.1090
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0835
   Episode_Reward/foot_landing_vel: -0.0475
   Episode_Reward/test_gait_reward: -0.3389
Metrics/base_velocity/error_vel_xy: 1.0973
Metrics/base_velocity/error_vel_yaw: 0.3189
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 1.08s
                        Total time: 729.06s
                               ETA: 2526.8s

################################################################################
                     [1m Learning iteration 672/3000 [0m                      

                       Computation: 90955 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.9626
                    Surrogate loss: -0.0028
             Mean action noise std: 0.4891
                     Learning rate: 0.0006
                       Mean reward: 22.33
               Mean episode length: 345.59
       Episode_Reward/keep_balance: 0.3649
     Episode_Reward/rew_lin_vel_xy: 0.9908
      Episode_Reward/rew_ang_vel_z: 1.1125
    Episode_Reward/pen_base_height: -0.2345
      Episode_Reward/pen_lin_vel_z: -0.0423
     Episode_Reward/pen_ang_vel_xy: -0.0540
   Episode_Reward/pen_joint_torque: -0.0651
    Episode_Reward/pen_joint_accel: -0.0340
    Episode_Reward/pen_action_rate: -0.0739
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0229
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1591
Episode_Reward/pen_flat_orientation: -0.1102
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0912
   Episode_Reward/foot_landing_vel: -0.0501
   Episode_Reward/test_gait_reward: -0.3464
Metrics/base_velocity/error_vel_xy: 1.1015
Metrics/base_velocity/error_vel_yaw: 0.3243
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 1.08s
                        Total time: 730.14s
                               ETA: 2525.7s

################################################################################
                     [1m Learning iteration 673/3000 [0m                      

                       Computation: 90049 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 1.1386
                    Surrogate loss: -0.0017
             Mean action noise std: 0.4893
                     Learning rate: 0.0013
                       Mean reward: 28.22
               Mean episode length: 425.37
       Episode_Reward/keep_balance: 0.4287
     Episode_Reward/rew_lin_vel_xy: 1.1811
      Episode_Reward/rew_ang_vel_z: 1.3160
    Episode_Reward/pen_base_height: -0.2592
      Episode_Reward/pen_lin_vel_z: -0.0496
     Episode_Reward/pen_ang_vel_xy: -0.0605
   Episode_Reward/pen_joint_torque: -0.0774
    Episode_Reward/pen_joint_accel: -0.0365
    Episode_Reward/pen_action_rate: -0.0869
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0265
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1850
Episode_Reward/pen_flat_orientation: -0.1230
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1024
   Episode_Reward/foot_landing_vel: -0.0582
   Episode_Reward/test_gait_reward: -0.4017
Metrics/base_velocity/error_vel_xy: 1.3250
Metrics/base_velocity/error_vel_yaw: 0.3743
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 8.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 1.09s
                        Total time: 731.24s
                               ETA: 2524.6s

################################################################################
                     [1m Learning iteration 674/3000 [0m                      

                       Computation: 90599 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 1.3233
                    Surrogate loss: 0.0002
             Mean action noise std: 0.4893
                     Learning rate: 0.0009
                       Mean reward: 25.02
               Mean episode length: 412.86
       Episode_Reward/keep_balance: 0.4277
     Episode_Reward/rew_lin_vel_xy: 1.1487
      Episode_Reward/rew_ang_vel_z: 1.3054
    Episode_Reward/pen_base_height: -0.2559
      Episode_Reward/pen_lin_vel_z: -0.0506
     Episode_Reward/pen_ang_vel_xy: -0.0596
   Episode_Reward/pen_joint_torque: -0.0786
    Episode_Reward/pen_joint_accel: -0.0401
    Episode_Reward/pen_action_rate: -0.0881
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0155
   Episode_Reward/pen_joint_powers: -0.0274
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1867
Episode_Reward/pen_flat_orientation: -0.1178
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1058
   Episode_Reward/foot_landing_vel: -0.0615
   Episode_Reward/test_gait_reward: -0.4037
Metrics/base_velocity/error_vel_xy: 1.3277
Metrics/base_velocity/error_vel_yaw: 0.3772
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 1.09s
                        Total time: 732.32s
                               ETA: 2523.5s

################################################################################
                     [1m Learning iteration 675/3000 [0m                      

                       Computation: 90940 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 1.2280
                    Surrogate loss: 0.0019
             Mean action noise std: 0.4894
                     Learning rate: 0.0004
                       Mean reward: 24.52
               Mean episode length: 373.34
       Episode_Reward/keep_balance: 0.3690
     Episode_Reward/rew_lin_vel_xy: 1.0087
      Episode_Reward/rew_ang_vel_z: 1.1336
    Episode_Reward/pen_base_height: -0.2362
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.0546
   Episode_Reward/pen_joint_torque: -0.0671
    Episode_Reward/pen_joint_accel: -0.0339
    Episode_Reward/pen_action_rate: -0.0747
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0131
   Episode_Reward/pen_joint_powers: -0.0234
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1582
Episode_Reward/pen_flat_orientation: -0.1144
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0926
   Episode_Reward/foot_landing_vel: -0.0494
   Episode_Reward/test_gait_reward: -0.3487
Metrics/base_velocity/error_vel_xy: 1.1417
Metrics/base_velocity/error_vel_yaw: 0.3233
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 1.08s
                        Total time: 733.40s
                               ETA: 2522.4s

################################################################################
                     [1m Learning iteration 676/3000 [0m                      

                       Computation: 89733 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 1.0311
                    Surrogate loss: 0.0013
             Mean action noise std: 0.4900
                     Learning rate: 0.0003
                       Mean reward: 24.74
               Mean episode length: 381.60
       Episode_Reward/keep_balance: 0.3784
     Episode_Reward/rew_lin_vel_xy: 1.0238
      Episode_Reward/rew_ang_vel_z: 1.1543
    Episode_Reward/pen_base_height: -0.2405
      Episode_Reward/pen_lin_vel_z: -0.0451
     Episode_Reward/pen_ang_vel_xy: -0.0562
   Episode_Reward/pen_joint_torque: -0.0670
    Episode_Reward/pen_joint_accel: -0.0362
    Episode_Reward/pen_action_rate: -0.0770
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0139
   Episode_Reward/pen_joint_powers: -0.0239
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1646
Episode_Reward/pen_flat_orientation: -0.1148
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0945
   Episode_Reward/foot_landing_vel: -0.0537
   Episode_Reward/test_gait_reward: -0.3586
Metrics/base_velocity/error_vel_xy: 1.1078
Metrics/base_velocity/error_vel_yaw: 0.3361
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 1.10s
                        Total time: 734.50s
                               ETA: 2521.4s

################################################################################
                     [1m Learning iteration 677/3000 [0m                      

                       Computation: 89900 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 1.0635
                    Surrogate loss: -0.0011
             Mean action noise std: 0.4904
                     Learning rate: 0.0006
                       Mean reward: 23.71
               Mean episode length: 372.95
       Episode_Reward/keep_balance: 0.3727
     Episode_Reward/rew_lin_vel_xy: 0.9878
      Episode_Reward/rew_ang_vel_z: 1.1416
    Episode_Reward/pen_base_height: -0.2401
      Episode_Reward/pen_lin_vel_z: -0.0447
     Episode_Reward/pen_ang_vel_xy: -0.0548
   Episode_Reward/pen_joint_torque: -0.0676
    Episode_Reward/pen_joint_accel: -0.0345
    Episode_Reward/pen_action_rate: -0.0755
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0235
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1609
Episode_Reward/pen_flat_orientation: -0.1150
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0941
   Episode_Reward/foot_landing_vel: -0.0512
   Episode_Reward/test_gait_reward: -0.3532
Metrics/base_velocity/error_vel_xy: 1.1533
Metrics/base_velocity/error_vel_yaw: 0.3287
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 1.09s
                        Total time: 735.59s
                               ETA: 2520.3s

################################################################################
                     [1m Learning iteration 678/3000 [0m                      

                       Computation: 90081 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 1.0759
                    Surrogate loss: 0.0051
             Mean action noise std: 0.4906
                     Learning rate: 0.0002
                       Mean reward: 27.22
               Mean episode length: 395.19
       Episode_Reward/keep_balance: 0.3968
     Episode_Reward/rew_lin_vel_xy: 1.1319
      Episode_Reward/rew_ang_vel_z: 1.2085
    Episode_Reward/pen_base_height: -0.2504
      Episode_Reward/pen_lin_vel_z: -0.0467
     Episode_Reward/pen_ang_vel_xy: -0.0573
   Episode_Reward/pen_joint_torque: -0.0707
    Episode_Reward/pen_joint_accel: -0.0378
    Episode_Reward/pen_action_rate: -0.0805
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0247
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1734
Episode_Reward/pen_flat_orientation: -0.1163
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0950
   Episode_Reward/foot_landing_vel: -0.0529
   Episode_Reward/test_gait_reward: -0.3748
Metrics/base_velocity/error_vel_xy: 1.1678
Metrics/base_velocity/error_vel_yaw: 0.3551
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 1.09s
                        Total time: 736.68s
                               ETA: 2519.3s

################################################################################
                     [1m Learning iteration 679/3000 [0m                      

                       Computation: 89493 steps/s (collection: 0.972s, learning 0.126s)
               Value function loss: 1.0321
                    Surrogate loss: 0.0061
             Mean action noise std: 0.4907
                     Learning rate: 0.0001
                       Mean reward: 22.90
               Mean episode length: 358.03
       Episode_Reward/keep_balance: 0.3715
     Episode_Reward/rew_lin_vel_xy: 0.9996
      Episode_Reward/rew_ang_vel_z: 1.1390
    Episode_Reward/pen_base_height: -0.2421
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.0546
   Episode_Reward/pen_joint_torque: -0.0668
    Episode_Reward/pen_joint_accel: -0.0334
    Episode_Reward/pen_action_rate: -0.0748
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0233
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1600
Episode_Reward/pen_flat_orientation: -0.1131
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0926
   Episode_Reward/foot_landing_vel: -0.0500
   Episode_Reward/test_gait_reward: -0.3484
Metrics/base_velocity/error_vel_xy: 1.1561
Metrics/base_velocity/error_vel_yaw: 0.3264
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 1.10s
                        Total time: 737.78s
                               ETA: 2518.2s

################################################################################
                     [1m Learning iteration 680/3000 [0m                      

                       Computation: 90696 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.9335
                    Surrogate loss: -0.0009
             Mean action noise std: 0.4911
                     Learning rate: 0.0004
                       Mean reward: 21.36
               Mean episode length: 362.66
       Episode_Reward/keep_balance: 0.3904
     Episode_Reward/rew_lin_vel_xy: 1.0083
      Episode_Reward/rew_ang_vel_z: 1.2048
    Episode_Reward/pen_base_height: -0.2451
      Episode_Reward/pen_lin_vel_z: -0.0462
     Episode_Reward/pen_ang_vel_xy: -0.0557
   Episode_Reward/pen_joint_torque: -0.0712
    Episode_Reward/pen_joint_accel: -0.0339
    Episode_Reward/pen_action_rate: -0.0785
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0135
   Episode_Reward/pen_joint_powers: -0.0243
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1680
Episode_Reward/pen_flat_orientation: -0.1087
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0932
   Episode_Reward/foot_landing_vel: -0.0525
   Episode_Reward/test_gait_reward: -0.3677
Metrics/base_velocity/error_vel_xy: 1.2242
Metrics/base_velocity/error_vel_yaw: 0.3361
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 1.08s
                        Total time: 738.86s
                               ETA: 2517.1s

################################################################################
                     [1m Learning iteration 681/3000 [0m                      

                       Computation: 91359 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 1.0141
                    Surrogate loss: -0.0005
             Mean action noise std: 0.4914
                     Learning rate: 0.0006
                       Mean reward: 20.67
               Mean episode length: 350.24
       Episode_Reward/keep_balance: 0.3597
     Episode_Reward/rew_lin_vel_xy: 0.9347
      Episode_Reward/rew_ang_vel_z: 1.1035
    Episode_Reward/pen_base_height: -0.2347
      Episode_Reward/pen_lin_vel_z: -0.0422
     Episode_Reward/pen_ang_vel_xy: -0.0540
   Episode_Reward/pen_joint_torque: -0.0634
    Episode_Reward/pen_joint_accel: -0.0307
    Episode_Reward/pen_action_rate: -0.0722
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0125
   Episode_Reward/pen_joint_powers: -0.0221
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1558
Episode_Reward/pen_flat_orientation: -0.1077
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0854
   Episode_Reward/foot_landing_vel: -0.0500
   Episode_Reward/test_gait_reward: -0.3398
Metrics/base_velocity/error_vel_xy: 1.1160
Metrics/base_velocity/error_vel_yaw: 0.3174
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 1.08s
                        Total time: 739.94s
                               ETA: 2516.0s

################################################################################
                     [1m Learning iteration 682/3000 [0m                      

                       Computation: 91499 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.9859
                    Surrogate loss: -0.0005
             Mean action noise std: 0.4921
                     Learning rate: 0.0009
                       Mean reward: 26.68
               Mean episode length: 407.18
       Episode_Reward/keep_balance: 0.4075
     Episode_Reward/rew_lin_vel_xy: 1.0920
      Episode_Reward/rew_ang_vel_z: 1.2485
    Episode_Reward/pen_base_height: -0.2559
      Episode_Reward/pen_lin_vel_z: -0.0489
     Episode_Reward/pen_ang_vel_xy: -0.0581
   Episode_Reward/pen_joint_torque: -0.0743
    Episode_Reward/pen_joint_accel: -0.0367
    Episode_Reward/pen_action_rate: -0.0829
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0143
   Episode_Reward/pen_joint_powers: -0.0257
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1773
Episode_Reward/pen_flat_orientation: -0.1154
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1002
   Episode_Reward/foot_landing_vel: -0.0544
   Episode_Reward/test_gait_reward: -0.3840
Metrics/base_velocity/error_vel_xy: 1.2459
Metrics/base_velocity/error_vel_yaw: 0.3585
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 1.07s
                        Total time: 741.01s
                               ETA: 2514.9s

################################################################################
                     [1m Learning iteration 683/3000 [0m                      

                       Computation: 89812 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 1.1566
                    Surrogate loss: 0.0027
             Mean action noise std: 0.4923
                     Learning rate: 0.0003
                       Mean reward: 29.81
               Mean episode length: 422.13
       Episode_Reward/keep_balance: 0.4094
     Episode_Reward/rew_lin_vel_xy: 1.1121
      Episode_Reward/rew_ang_vel_z: 1.2655
    Episode_Reward/pen_base_height: -0.2498
      Episode_Reward/pen_lin_vel_z: -0.0471
     Episode_Reward/pen_ang_vel_xy: -0.0573
   Episode_Reward/pen_joint_torque: -0.0744
    Episode_Reward/pen_joint_accel: -0.0334
    Episode_Reward/pen_action_rate: -0.0814
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0253
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1749
Episode_Reward/pen_flat_orientation: -0.1154
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0929
   Episode_Reward/foot_landing_vel: -0.0527
   Episode_Reward/test_gait_reward: -0.3869
Metrics/base_velocity/error_vel_xy: 1.2267
Metrics/base_velocity/error_vel_yaw: 0.3506
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 1.09s
                        Total time: 742.11s
                               ETA: 2513.8s

################################################################################
                     [1m Learning iteration 684/3000 [0m                      

                       Computation: 91176 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.0299
                    Surrogate loss: -0.0003
             Mean action noise std: 0.4923
                     Learning rate: 0.0003
                       Mean reward: 21.68
               Mean episode length: 343.68
       Episode_Reward/keep_balance: 0.3347
     Episode_Reward/rew_lin_vel_xy: 0.9236
      Episode_Reward/rew_ang_vel_z: 1.0336
    Episode_Reward/pen_base_height: -0.2277
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.0509
   Episode_Reward/pen_joint_torque: -0.0578
    Episode_Reward/pen_joint_accel: -0.0281
    Episode_Reward/pen_action_rate: -0.0659
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0113
   Episode_Reward/pen_joint_powers: -0.0202
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1427
Episode_Reward/pen_flat_orientation: -0.1046
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0774
   Episode_Reward/foot_landing_vel: -0.0424
   Episode_Reward/test_gait_reward: -0.3148
Metrics/base_velocity/error_vel_xy: 1.0053
Metrics/base_velocity/error_vel_yaw: 0.2888
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 1.08s
                        Total time: 743.19s
                               ETA: 2512.7s

################################################################################
                     [1m Learning iteration 685/3000 [0m                      

                       Computation: 90677 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 1.0228
                    Surrogate loss: -0.0022
             Mean action noise std: 0.4929
                     Learning rate: 0.0006
                       Mean reward: 23.46
               Mean episode length: 356.03
       Episode_Reward/keep_balance: 0.3686
     Episode_Reward/rew_lin_vel_xy: 0.9940
      Episode_Reward/rew_ang_vel_z: 1.1299
    Episode_Reward/pen_base_height: -0.2350
      Episode_Reward/pen_lin_vel_z: -0.0447
     Episode_Reward/pen_ang_vel_xy: -0.0547
   Episode_Reward/pen_joint_torque: -0.0667
    Episode_Reward/pen_joint_accel: -0.0334
    Episode_Reward/pen_action_rate: -0.0749
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0233
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1601
Episode_Reward/pen_flat_orientation: -0.1077
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0923
   Episode_Reward/foot_landing_vel: -0.0514
   Episode_Reward/test_gait_reward: -0.3474
Metrics/base_velocity/error_vel_xy: 1.1238
Metrics/base_velocity/error_vel_yaw: 0.3236
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 1.08s
                        Total time: 744.27s
                               ETA: 2511.6s

################################################################################
                     [1m Learning iteration 686/3000 [0m                      

                       Computation: 91703 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 1.0332
                    Surrogate loss: 0.0022
             Mean action noise std: 0.4939
                     Learning rate: 0.0001
                       Mean reward: 28.51
               Mean episode length: 385.85
       Episode_Reward/keep_balance: 0.3743
     Episode_Reward/rew_lin_vel_xy: 1.0641
      Episode_Reward/rew_ang_vel_z: 1.1566
    Episode_Reward/pen_base_height: -0.2387
      Episode_Reward/pen_lin_vel_z: -0.0459
     Episode_Reward/pen_ang_vel_xy: -0.0558
   Episode_Reward/pen_joint_torque: -0.0701
    Episode_Reward/pen_joint_accel: -0.0313
    Episode_Reward/pen_action_rate: -0.0759
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0241
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1613
Episode_Reward/pen_flat_orientation: -0.1105
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0926
   Episode_Reward/foot_landing_vel: -0.0510
   Episode_Reward/test_gait_reward: -0.3546
Metrics/base_velocity/error_vel_xy: 1.0730
Metrics/base_velocity/error_vel_yaw: 0.3215
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 1.07s
                        Total time: 745.34s
                               ETA: 2510.5s

################################################################################
                     [1m Learning iteration 687/3000 [0m                      

                       Computation: 91607 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 1.1243
                    Surrogate loss: 0.0014
             Mean action noise std: 0.4940
                     Learning rate: 0.0003
                       Mean reward: 24.57
               Mean episode length: 378.54
       Episode_Reward/keep_balance: 0.3804
     Episode_Reward/rew_lin_vel_xy: 0.9840
      Episode_Reward/rew_ang_vel_z: 1.1749
    Episode_Reward/pen_base_height: -0.2392
      Episode_Reward/pen_lin_vel_z: -0.0425
     Episode_Reward/pen_ang_vel_xy: -0.0555
   Episode_Reward/pen_joint_torque: -0.0667
    Episode_Reward/pen_joint_accel: -0.0328
    Episode_Reward/pen_action_rate: -0.0762
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0130
   Episode_Reward/pen_joint_powers: -0.0232
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1652
Episode_Reward/pen_flat_orientation: -0.1094
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0878
   Episode_Reward/foot_landing_vel: -0.0468
   Episode_Reward/test_gait_reward: -0.3579
Metrics/base_velocity/error_vel_xy: 1.2100
Metrics/base_velocity/error_vel_yaw: 0.3274
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 1.07s
                        Total time: 746.42s
                               ETA: 2509.4s

################################################################################
                     [1m Learning iteration 688/3000 [0m                      

                       Computation: 92656 steps/s (collection: 0.939s, learning 0.121s)
               Value function loss: 0.9239
                    Surrogate loss: 0.0008
             Mean action noise std: 0.4944
                     Learning rate: 0.0002
                       Mean reward: 21.41
               Mean episode length: 347.94
       Episode_Reward/keep_balance: 0.3480
     Episode_Reward/rew_lin_vel_xy: 0.9000
      Episode_Reward/rew_ang_vel_z: 1.0666
    Episode_Reward/pen_base_height: -0.2267
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.0516
   Episode_Reward/pen_joint_torque: -0.0622
    Episode_Reward/pen_joint_accel: -0.0292
    Episode_Reward/pen_action_rate: -0.0693
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0117
   Episode_Reward/pen_joint_powers: -0.0213
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1514
Episode_Reward/pen_flat_orientation: -0.1046
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0787
   Episode_Reward/foot_landing_vel: -0.0447
   Episode_Reward/test_gait_reward: -0.3290
Metrics/base_velocity/error_vel_xy: 1.0873
Metrics/base_velocity/error_vel_yaw: 0.3053
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 1.06s
                        Total time: 747.48s
                               ETA: 2508.2s

################################################################################
                     [1m Learning iteration 689/3000 [0m                      

                       Computation: 91373 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.8920
                    Surrogate loss: -0.0026
             Mean action noise std: 0.4957
                     Learning rate: 0.0006
                       Mean reward: 24.36
               Mean episode length: 367.40
       Episode_Reward/keep_balance: 0.3438
     Episode_Reward/rew_lin_vel_xy: 0.9359
      Episode_Reward/rew_ang_vel_z: 1.0549
    Episode_Reward/pen_base_height: -0.2283
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.0525
   Episode_Reward/pen_joint_torque: -0.0622
    Episode_Reward/pen_joint_accel: -0.0281
    Episode_Reward/pen_action_rate: -0.0684
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0119
   Episode_Reward/pen_joint_powers: -0.0215
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1485
Episode_Reward/pen_flat_orientation: -0.1092
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0844
   Episode_Reward/foot_landing_vel: -0.0439
   Episode_Reward/test_gait_reward: -0.3245
Metrics/base_velocity/error_vel_xy: 1.0502
Metrics/base_velocity/error_vel_yaw: 0.3019
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 11.7083
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 1.08s
                        Total time: 748.55s
                               ETA: 2507.1s

################################################################################
                     [1m Learning iteration 690/3000 [0m                      

                       Computation: 90730 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 1.1811
                    Surrogate loss: -0.0008
             Mean action noise std: 0.4964
                     Learning rate: 0.0006
                       Mean reward: 21.92
               Mean episode length: 328.48
       Episode_Reward/keep_balance: 0.3459
     Episode_Reward/rew_lin_vel_xy: 0.9301
      Episode_Reward/rew_ang_vel_z: 1.0704
    Episode_Reward/pen_base_height: -0.2285
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.0508
   Episode_Reward/pen_joint_torque: -0.0599
    Episode_Reward/pen_joint_accel: -0.0286
    Episode_Reward/pen_action_rate: -0.0673
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0114
   Episode_Reward/pen_joint_powers: -0.0206
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.1470
Episode_Reward/pen_flat_orientation: -0.1067
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0765
   Episode_Reward/foot_landing_vel: -0.0429
   Episode_Reward/test_gait_reward: -0.3260
Metrics/base_velocity/error_vel_xy: 1.0608
Metrics/base_velocity/error_vel_yaw: 0.2966
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 1.08s
                        Total time: 749.64s
                               ETA: 2506.0s

################################################################################
                     [1m Learning iteration 691/3000 [0m                      

                       Computation: 91538 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.0433
                    Surrogate loss: 0.0002
             Mean action noise std: 0.4967
                     Learning rate: 0.0003
                       Mean reward: 21.74
               Mean episode length: 358.53
       Episode_Reward/keep_balance: 0.4120
     Episode_Reward/rew_lin_vel_xy: 1.1078
      Episode_Reward/rew_ang_vel_z: 1.2803
    Episode_Reward/pen_base_height: -0.2418
      Episode_Reward/pen_lin_vel_z: -0.0455
     Episode_Reward/pen_ang_vel_xy: -0.0573
   Episode_Reward/pen_joint_torque: -0.0713
    Episode_Reward/pen_joint_accel: -0.0333
    Episode_Reward/pen_action_rate: -0.0817
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0135
   Episode_Reward/pen_joint_powers: -0.0246
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1781
Episode_Reward/pen_flat_orientation: -0.1134
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0930
   Episode_Reward/foot_landing_vel: -0.0491
   Episode_Reward/test_gait_reward: -0.3865
Metrics/base_velocity/error_vel_xy: 1.2557
Metrics/base_velocity/error_vel_yaw: 0.3488
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 1.07s
                        Total time: 750.71s
                               ETA: 2504.9s

################################################################################
                     [1m Learning iteration 692/3000 [0m                      

                       Computation: 90921 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.9424
                    Surrogate loss: 0.0048
             Mean action noise std: 0.4968
                     Learning rate: 0.0001
                       Mean reward: 22.49
               Mean episode length: 334.16
       Episode_Reward/keep_balance: 0.3464
     Episode_Reward/rew_lin_vel_xy: 0.9405
      Episode_Reward/rew_ang_vel_z: 1.0688
    Episode_Reward/pen_base_height: -0.2252
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.0515
   Episode_Reward/pen_joint_torque: -0.0625
    Episode_Reward/pen_joint_accel: -0.0298
    Episode_Reward/pen_action_rate: -0.0693
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0118
   Episode_Reward/pen_joint_powers: -0.0215
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1491
Episode_Reward/pen_flat_orientation: -0.1060
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0805
   Episode_Reward/foot_landing_vel: -0.0450
   Episode_Reward/test_gait_reward: -0.3266
Metrics/base_velocity/error_vel_xy: 1.0642
Metrics/base_velocity/error_vel_yaw: 0.3004
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 1.08s
                        Total time: 751.79s
                               ETA: 2503.8s

################################################################################
                     [1m Learning iteration 693/3000 [0m                      

                       Computation: 90078 steps/s (collection: 0.962s, learning 0.130s)
               Value function loss: 1.0306
                    Surrogate loss: -0.0017
             Mean action noise std: 0.4971
                     Learning rate: 0.0003
                       Mean reward: 27.06
               Mean episode length: 401.70
       Episode_Reward/keep_balance: 0.3743
     Episode_Reward/rew_lin_vel_xy: 1.0087
      Episode_Reward/rew_ang_vel_z: 1.1462
    Episode_Reward/pen_base_height: -0.2332
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.0558
   Episode_Reward/pen_joint_torque: -0.0650
    Episode_Reward/pen_joint_accel: -0.0313
    Episode_Reward/pen_action_rate: -0.0758
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0232
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1644
Episode_Reward/pen_flat_orientation: -0.1107
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0900
   Episode_Reward/foot_landing_vel: -0.0506
   Episode_Reward/test_gait_reward: -0.3548
Metrics/base_velocity/error_vel_xy: 1.1465
Metrics/base_velocity/error_vel_yaw: 0.3291
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 1.09s
                        Total time: 752.88s
                               ETA: 2502.7s

################################################################################
                     [1m Learning iteration 694/3000 [0m                      

                       Computation: 85727 steps/s (collection: 1.024s, learning 0.123s)
               Value function loss: 0.9398
                    Surrogate loss: -0.0009
             Mean action noise std: 0.4980
                     Learning rate: 0.0003
                       Mean reward: 29.21
               Mean episode length: 422.43
       Episode_Reward/keep_balance: 0.4041
     Episode_Reward/rew_lin_vel_xy: 1.0931
      Episode_Reward/rew_ang_vel_z: 1.2402
    Episode_Reward/pen_base_height: -0.2460
      Episode_Reward/pen_lin_vel_z: -0.0483
     Episode_Reward/pen_ang_vel_xy: -0.0590
   Episode_Reward/pen_joint_torque: -0.0739
    Episode_Reward/pen_joint_accel: -0.0373
    Episode_Reward/pen_action_rate: -0.0828
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0146
   Episode_Reward/pen_joint_powers: -0.0259
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1775
Episode_Reward/pen_flat_orientation: -0.1213
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1013
   Episode_Reward/foot_landing_vel: -0.0560
   Episode_Reward/test_gait_reward: -0.3823
Metrics/base_velocity/error_vel_xy: 1.2175
Metrics/base_velocity/error_vel_yaw: 0.3537
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 1.15s
                        Total time: 754.03s
                               ETA: 2501.9s

################################################################################
                     [1m Learning iteration 695/3000 [0m                      

                       Computation: 91332 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.9596
                    Surrogate loss: 0.0016
             Mean action noise std: 0.4980
                     Learning rate: 0.0001
                       Mean reward: 23.32
               Mean episode length: 362.67
       Episode_Reward/keep_balance: 0.4009
     Episode_Reward/rew_lin_vel_xy: 1.1227
      Episode_Reward/rew_ang_vel_z: 1.2377
    Episode_Reward/pen_base_height: -0.2401
      Episode_Reward/pen_lin_vel_z: -0.0455
     Episode_Reward/pen_ang_vel_xy: -0.0569
   Episode_Reward/pen_joint_torque: -0.0719
    Episode_Reward/pen_joint_accel: -0.0357
    Episode_Reward/pen_action_rate: -0.0810
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0248
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1748
Episode_Reward/pen_flat_orientation: -0.1110
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0943
   Episode_Reward/foot_landing_vel: -0.0497
   Episode_Reward/test_gait_reward: -0.3748
Metrics/base_velocity/error_vel_xy: 1.1765
Metrics/base_velocity/error_vel_yaw: 0.3437
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 1.08s
                        Total time: 755.11s
                               ETA: 2500.7s

################################################################################
                     [1m Learning iteration 696/3000 [0m                      

                       Computation: 91414 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.9589
                    Surrogate loss: -0.0034
             Mean action noise std: 0.4976
                     Learning rate: 0.0003
                       Mean reward: 24.17
               Mean episode length: 384.51
       Episode_Reward/keep_balance: 0.3972
     Episode_Reward/rew_lin_vel_xy: 1.0224
      Episode_Reward/rew_ang_vel_z: 1.2231
    Episode_Reward/pen_base_height: -0.2463
      Episode_Reward/pen_lin_vel_z: -0.0465
     Episode_Reward/pen_ang_vel_xy: -0.0578
   Episode_Reward/pen_joint_torque: -0.0720
    Episode_Reward/pen_joint_accel: -0.0373
    Episode_Reward/pen_action_rate: -0.0811
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0250
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1758
Episode_Reward/pen_flat_orientation: -0.1189
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0970
   Episode_Reward/foot_landing_vel: -0.0546
   Episode_Reward/test_gait_reward: -0.3745
Metrics/base_velocity/error_vel_xy: 1.2635
Metrics/base_velocity/error_vel_yaw: 0.3446
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 1.08s
                        Total time: 756.18s
                               ETA: 2499.6s

################################################################################
                     [1m Learning iteration 697/3000 [0m                      

                       Computation: 91752 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.9053
                    Surrogate loss: -0.0024
             Mean action noise std: 0.4967
                     Learning rate: 0.0006
                       Mean reward: 28.80
               Mean episode length: 441.44
       Episode_Reward/keep_balance: 0.4262
     Episode_Reward/rew_lin_vel_xy: 1.2295
      Episode_Reward/rew_ang_vel_z: 1.2964
    Episode_Reward/pen_base_height: -0.2583
      Episode_Reward/pen_lin_vel_z: -0.0507
     Episode_Reward/pen_ang_vel_xy: -0.0622
   Episode_Reward/pen_joint_torque: -0.0779
    Episode_Reward/pen_joint_accel: -0.0373
    Episode_Reward/pen_action_rate: -0.0886
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0156
   Episode_Reward/pen_joint_powers: -0.0274
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1901
Episode_Reward/pen_flat_orientation: -0.1173
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1098
   Episode_Reward/foot_landing_vel: -0.0566
   Episode_Reward/test_gait_reward: -0.4067
Metrics/base_velocity/error_vel_xy: 1.2574
Metrics/base_velocity/error_vel_yaw: 0.3811
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 1.07s
                        Total time: 757.25s
                               ETA: 2498.5s

################################################################################
                     [1m Learning iteration 698/3000 [0m                      

                       Computation: 90475 steps/s (collection: 0.965s, learning 0.121s)
               Value function loss: 0.9843
                    Surrogate loss: 0.0004
             Mean action noise std: 0.4967
                     Learning rate: 0.0003
                       Mean reward: 26.01
               Mean episode length: 397.47
       Episode_Reward/keep_balance: 0.4033
     Episode_Reward/rew_lin_vel_xy: 1.0481
      Episode_Reward/rew_ang_vel_z: 1.2312
    Episode_Reward/pen_base_height: -0.2428
      Episode_Reward/pen_lin_vel_z: -0.0455
     Episode_Reward/pen_ang_vel_xy: -0.0595
   Episode_Reward/pen_joint_torque: -0.0710
    Episode_Reward/pen_joint_accel: -0.0376
    Episode_Reward/pen_action_rate: -0.0827
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0139
   Episode_Reward/pen_joint_powers: -0.0248
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1792
Episode_Reward/pen_flat_orientation: -0.1127
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0925
   Episode_Reward/foot_landing_vel: -0.0531
   Episode_Reward/test_gait_reward: -0.3799
Metrics/base_velocity/error_vel_xy: 1.2855
Metrics/base_velocity/error_vel_yaw: 0.3578
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 1.09s
                        Total time: 758.34s
                               ETA: 2497.4s

################################################################################
                     [1m Learning iteration 699/3000 [0m                      

                       Computation: 91683 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.9664
                    Surrogate loss: 0.0055
             Mean action noise std: 0.4969
                     Learning rate: 0.0000
                       Mean reward: 29.37
               Mean episode length: 465.44
       Episode_Reward/keep_balance: 0.4555
     Episode_Reward/rew_lin_vel_xy: 1.1889
      Episode_Reward/rew_ang_vel_z: 1.4049
    Episode_Reward/pen_base_height: -0.2604
      Episode_Reward/pen_lin_vel_z: -0.0533
     Episode_Reward/pen_ang_vel_xy: -0.0652
   Episode_Reward/pen_joint_torque: -0.0854
    Episode_Reward/pen_joint_accel: -0.0415
    Episode_Reward/pen_action_rate: -0.0956
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0164
   Episode_Reward/pen_joint_powers: -0.0294
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2016
Episode_Reward/pen_flat_orientation: -0.1173
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1156
   Episode_Reward/foot_landing_vel: -0.0628
   Episode_Reward/test_gait_reward: -0.4306
Metrics/base_velocity/error_vel_xy: 1.4015
Metrics/base_velocity/error_vel_yaw: 0.3935
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 1.07s
                        Total time: 759.41s
                               ETA: 2496.3s

################################################################################
                     [1m Learning iteration 700/3000 [0m                      

                       Computation: 91558 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.9234
                    Surrogate loss: 0.0061
             Mean action noise std: 0.4970
                     Learning rate: 0.0000
                       Mean reward: 21.63
               Mean episode length: 333.22
       Episode_Reward/keep_balance: 0.3880
     Episode_Reward/rew_lin_vel_xy: 1.0400
      Episode_Reward/rew_ang_vel_z: 1.1798
    Episode_Reward/pen_base_height: -0.2401
      Episode_Reward/pen_lin_vel_z: -0.0471
     Episode_Reward/pen_ang_vel_xy: -0.0594
   Episode_Reward/pen_joint_torque: -0.0731
    Episode_Reward/pen_joint_accel: -0.0367
    Episode_Reward/pen_action_rate: -0.0817
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0145
   Episode_Reward/pen_joint_powers: -0.0254
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.1740
Episode_Reward/pen_flat_orientation: -0.1130
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1015
   Episode_Reward/foot_landing_vel: -0.0548
   Episode_Reward/test_gait_reward: -0.3670
Metrics/base_velocity/error_vel_xy: 1.1738
Metrics/base_velocity/error_vel_yaw: 0.3500
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 1.07s
                        Total time: 760.48s
                               ETA: 2495.2s

################################################################################
                     [1m Learning iteration 701/3000 [0m                      

                       Computation: 91436 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.9476
                    Surrogate loss: -0.0018
             Mean action noise std: 0.4973
                     Learning rate: 0.0003
                       Mean reward: 27.25
               Mean episode length: 400.05
       Episode_Reward/keep_balance: 0.4181
     Episode_Reward/rew_lin_vel_xy: 1.1369
      Episode_Reward/rew_ang_vel_z: 1.2798
    Episode_Reward/pen_base_height: -0.2420
      Episode_Reward/pen_lin_vel_z: -0.0465
     Episode_Reward/pen_ang_vel_xy: -0.0592
   Episode_Reward/pen_joint_torque: -0.0724
    Episode_Reward/pen_joint_accel: -0.0362
    Episode_Reward/pen_action_rate: -0.0860
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0145
   Episode_Reward/pen_joint_powers: -0.0255
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1864
Episode_Reward/pen_flat_orientation: -0.1140
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0979
   Episode_Reward/foot_landing_vel: -0.0560
   Episode_Reward/test_gait_reward: -0.3963
Metrics/base_velocity/error_vel_xy: 1.3004
Metrics/base_velocity/error_vel_yaw: 0.3675
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 1.08s
                        Total time: 761.56s
                               ETA: 2494.1s

################################################################################
                     [1m Learning iteration 702/3000 [0m                      

                       Computation: 91781 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 1.1012
                    Surrogate loss: 0.0015
             Mean action noise std: 0.4974
                     Learning rate: 0.0003
                       Mean reward: 29.14
               Mean episode length: 431.33
       Episode_Reward/keep_balance: 0.4131
     Episode_Reward/rew_lin_vel_xy: 1.0945
      Episode_Reward/rew_ang_vel_z: 1.2659
    Episode_Reward/pen_base_height: -0.2469
      Episode_Reward/pen_lin_vel_z: -0.0460
     Episode_Reward/pen_ang_vel_xy: -0.0599
   Episode_Reward/pen_joint_torque: -0.0709
    Episode_Reward/pen_joint_accel: -0.0355
    Episode_Reward/pen_action_rate: -0.0842
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0143
   Episode_Reward/pen_joint_powers: -0.0252
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1835
Episode_Reward/pen_flat_orientation: -0.1134
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0996
   Episode_Reward/foot_landing_vel: -0.0533
   Episode_Reward/test_gait_reward: -0.3913
Metrics/base_velocity/error_vel_xy: 1.2766
Metrics/base_velocity/error_vel_yaw: 0.3630
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 1.07s
                        Total time: 762.63s
                               ETA: 2492.9s

################################################################################
                     [1m Learning iteration 703/3000 [0m                      

                       Computation: 90803 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 1.0530
                    Surrogate loss: -0.0009
             Mean action noise std: 0.4974
                     Learning rate: 0.0006
                       Mean reward: 28.02
               Mean episode length: 412.62
       Episode_Reward/keep_balance: 0.4438
     Episode_Reward/rew_lin_vel_xy: 1.2186
      Episode_Reward/rew_ang_vel_z: 1.3602
    Episode_Reward/pen_base_height: -0.2577
      Episode_Reward/pen_lin_vel_z: -0.0519
     Episode_Reward/pen_ang_vel_xy: -0.0627
   Episode_Reward/pen_joint_torque: -0.0778
    Episode_Reward/pen_joint_accel: -0.0393
    Episode_Reward/pen_action_rate: -0.0930
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0158
   Episode_Reward/pen_joint_powers: -0.0277
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1995
Episode_Reward/pen_flat_orientation: -0.1202
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1065
   Episode_Reward/foot_landing_vel: -0.0624
   Episode_Reward/test_gait_reward: -0.4190
Metrics/base_velocity/error_vel_xy: 1.3403
Metrics/base_velocity/error_vel_yaw: 0.3905
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 1.08s
                        Total time: 763.71s
                               ETA: 2491.8s

################################################################################
                     [1m Learning iteration 704/3000 [0m                      

                       Computation: 90883 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 1.0446
                    Surrogate loss: 0.0004
             Mean action noise std: 0.4974
                     Learning rate: 0.0006
                       Mean reward: 25.88
               Mean episode length: 366.73
       Episode_Reward/keep_balance: 0.3981
     Episode_Reward/rew_lin_vel_xy: 1.0759
      Episode_Reward/rew_ang_vel_z: 1.2211
    Episode_Reward/pen_base_height: -0.2340
      Episode_Reward/pen_lin_vel_z: -0.0420
     Episode_Reward/pen_ang_vel_xy: -0.0557
   Episode_Reward/pen_joint_torque: -0.0684
    Episode_Reward/pen_joint_accel: -0.0362
    Episode_Reward/pen_action_rate: -0.0804
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0235
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1754
Episode_Reward/pen_flat_orientation: -0.1076
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0882
   Episode_Reward/foot_landing_vel: -0.0485
   Episode_Reward/test_gait_reward: -0.3724
Metrics/base_velocity/error_vel_xy: 1.2068
Metrics/base_velocity/error_vel_yaw: 0.3490
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 1.08s
                        Total time: 764.80s
                               ETA: 2490.7s

################################################################################
                     [1m Learning iteration 705/3000 [0m                      

                       Computation: 90109 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.9714
                    Surrogate loss: 0.0033
             Mean action noise std: 0.4972
                     Learning rate: 0.0002
                       Mean reward: 28.47
               Mean episode length: 405.27
       Episode_Reward/keep_balance: 0.3912
     Episode_Reward/rew_lin_vel_xy: 1.1080
      Episode_Reward/rew_ang_vel_z: 1.2030
    Episode_Reward/pen_base_height: -0.2370
      Episode_Reward/pen_lin_vel_z: -0.0425
     Episode_Reward/pen_ang_vel_xy: -0.0577
   Episode_Reward/pen_joint_torque: -0.0669
    Episode_Reward/pen_joint_accel: -0.0334
    Episode_Reward/pen_action_rate: -0.0790
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0133
   Episode_Reward/pen_joint_powers: -0.0235
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1721
Episode_Reward/pen_flat_orientation: -0.1111
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0895
   Episode_Reward/foot_landing_vel: -0.0485
   Episode_Reward/test_gait_reward: -0.3712
Metrics/base_velocity/error_vel_xy: 1.1586
Metrics/base_velocity/error_vel_yaw: 0.3407
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 1.09s
                        Total time: 765.89s
                               ETA: 2489.7s

################################################################################
                     [1m Learning iteration 706/3000 [0m                      

                       Computation: 91850 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 1.0250
                    Surrogate loss: 0.0037
             Mean action noise std: 0.4972
                     Learning rate: 0.0001
                       Mean reward: 30.43
               Mean episode length: 431.56
       Episode_Reward/keep_balance: 0.4072
     Episode_Reward/rew_lin_vel_xy: 1.1201
      Episode_Reward/rew_ang_vel_z: 1.2525
    Episode_Reward/pen_base_height: -0.2444
      Episode_Reward/pen_lin_vel_z: -0.0449
     Episode_Reward/pen_ang_vel_xy: -0.0581
   Episode_Reward/pen_joint_torque: -0.0717
    Episode_Reward/pen_joint_accel: -0.0361
    Episode_Reward/pen_action_rate: -0.0827
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0251
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1794
Episode_Reward/pen_flat_orientation: -0.1129
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0974
   Episode_Reward/foot_landing_vel: -0.0515
   Episode_Reward/test_gait_reward: -0.3856
Metrics/base_velocity/error_vel_xy: 1.2306
Metrics/base_velocity/error_vel_yaw: 0.3542
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 1.07s
                        Total time: 766.96s
                               ETA: 2488.5s

################################################################################
                     [1m Learning iteration 707/3000 [0m                      

                       Computation: 92045 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.9825
                    Surrogate loss: 0.0053
             Mean action noise std: 0.4972
                     Learning rate: 0.0000
                       Mean reward: 24.29
               Mean episode length: 384.94
       Episode_Reward/keep_balance: 0.3986
     Episode_Reward/rew_lin_vel_xy: 1.0694
      Episode_Reward/rew_ang_vel_z: 1.2238
    Episode_Reward/pen_base_height: -0.2379
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.0586
   Episode_Reward/pen_joint_torque: -0.0685
    Episode_Reward/pen_joint_accel: -0.0359
    Episode_Reward/pen_action_rate: -0.0820
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0140
   Episode_Reward/pen_joint_powers: -0.0243
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1774
Episode_Reward/pen_flat_orientation: -0.1151
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0974
   Episode_Reward/foot_landing_vel: -0.0530
   Episode_Reward/test_gait_reward: -0.3766
Metrics/base_velocity/error_vel_xy: 1.2039
Metrics/base_velocity/error_vel_yaw: 0.3498
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 1.07s
                        Total time: 768.02s
                               ETA: 2487.4s

################################################################################
                     [1m Learning iteration 708/3000 [0m                      

                       Computation: 91106 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.9605
                    Surrogate loss: -0.0021
             Mean action noise std: 0.4973
                     Learning rate: 0.0001
                       Mean reward: 25.42
               Mean episode length: 373.79
       Episode_Reward/keep_balance: 0.3842
     Episode_Reward/rew_lin_vel_xy: 1.0801
      Episode_Reward/rew_ang_vel_z: 1.1779
    Episode_Reward/pen_base_height: -0.2389
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.0582
   Episode_Reward/pen_joint_torque: -0.0673
    Episode_Reward/pen_joint_accel: -0.0349
    Episode_Reward/pen_action_rate: -0.0793
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0237
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1720
Episode_Reward/pen_flat_orientation: -0.1108
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0926
   Episode_Reward/foot_landing_vel: -0.0500
   Episode_Reward/test_gait_reward: -0.3638
Metrics/base_velocity/error_vel_xy: 1.1698
Metrics/base_velocity/error_vel_yaw: 0.3381
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 1.08s
                        Total time: 769.10s
                               ETA: 2486.3s

################################################################################
                     [1m Learning iteration 709/3000 [0m                      

                       Computation: 90944 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.9617
                    Surrogate loss: -0.0006
             Mean action noise std: 0.4983
                     Learning rate: 0.0004
                       Mean reward: 31.16
               Mean episode length: 419.51
       Episode_Reward/keep_balance: 0.4246
     Episode_Reward/rew_lin_vel_xy: 1.1640
      Episode_Reward/rew_ang_vel_z: 1.3153
    Episode_Reward/pen_base_height: -0.2501
      Episode_Reward/pen_lin_vel_z: -0.0497
     Episode_Reward/pen_ang_vel_xy: -0.0629
   Episode_Reward/pen_joint_torque: -0.0784
    Episode_Reward/pen_joint_accel: -0.0441
    Episode_Reward/pen_action_rate: -0.0896
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0157
   Episode_Reward/pen_joint_powers: -0.0274
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1893
Episode_Reward/pen_flat_orientation: -0.1173
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.1050
   Episode_Reward/foot_landing_vel: -0.0592
   Episode_Reward/test_gait_reward: -0.4043
Metrics/base_velocity/error_vel_xy: 1.3334
Metrics/base_velocity/error_vel_yaw: 0.3614
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 1.08s
                        Total time: 770.18s
                               ETA: 2485.2s

################################################################################
                     [1m Learning iteration 710/3000 [0m                      

                       Computation: 91825 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 1.1313
                    Surrogate loss: -0.0021
             Mean action noise std: 0.4990
                     Learning rate: 0.0009
                       Mean reward: 31.20
               Mean episode length: 440.61
       Episode_Reward/keep_balance: 0.4106
     Episode_Reward/rew_lin_vel_xy: 1.2196
      Episode_Reward/rew_ang_vel_z: 1.2610
    Episode_Reward/pen_base_height: -0.2419
      Episode_Reward/pen_lin_vel_z: -0.0449
     Episode_Reward/pen_ang_vel_xy: -0.0598
   Episode_Reward/pen_joint_torque: -0.0698
    Episode_Reward/pen_joint_accel: -0.0336
    Episode_Reward/pen_action_rate: -0.0840
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0246
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1821
Episode_Reward/pen_flat_orientation: -0.1139
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0940
   Episode_Reward/foot_landing_vel: -0.0514
   Episode_Reward/test_gait_reward: -0.3877
Metrics/base_velocity/error_vel_xy: 1.1846
Metrics/base_velocity/error_vel_yaw: 0.3590
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 1.07s
                        Total time: 771.25s
                               ETA: 2484.1s

################################################################################
                     [1m Learning iteration 711/3000 [0m                      

                       Computation: 91783 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 1.4739
                    Surrogate loss: 0.0008
             Mean action noise std: 0.4985
                     Learning rate: 0.0004
                       Mean reward: 24.95
               Mean episode length: 373.56
       Episode_Reward/keep_balance: 0.3566
     Episode_Reward/rew_lin_vel_xy: 1.0137
      Episode_Reward/rew_ang_vel_z: 1.0933
    Episode_Reward/pen_base_height: -0.2323
      Episode_Reward/pen_lin_vel_z: -0.0399
     Episode_Reward/pen_ang_vel_xy: -0.0531
   Episode_Reward/pen_joint_torque: -0.0612
    Episode_Reward/pen_joint_accel: -0.0318
    Episode_Reward/pen_action_rate: -0.0720
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0124
   Episode_Reward/pen_joint_powers: -0.0216
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1568
Episode_Reward/pen_flat_orientation: -0.1100
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0842
   Episode_Reward/foot_landing_vel: -0.0463
   Episode_Reward/test_gait_reward: -0.3394
Metrics/base_velocity/error_vel_xy: 1.0747
Metrics/base_velocity/error_vel_yaw: 0.3131
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 1.07s
                        Total time: 772.33s
                               ETA: 2482.9s

################################################################################
                     [1m Learning iteration 712/3000 [0m                      

                       Computation: 91507 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.9505
                    Surrogate loss: -0.0013
             Mean action noise std: 0.4979
                     Learning rate: 0.0004
                       Mean reward: 26.38
               Mean episode length: 388.76
       Episode_Reward/keep_balance: 0.3826
     Episode_Reward/rew_lin_vel_xy: 1.0678
      Episode_Reward/rew_ang_vel_z: 1.1767
    Episode_Reward/pen_base_height: -0.2325
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.0571
   Episode_Reward/pen_joint_torque: -0.0658
    Episode_Reward/pen_joint_accel: -0.0331
    Episode_Reward/pen_action_rate: -0.0779
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0130
   Episode_Reward/pen_joint_powers: -0.0231
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1693
Episode_Reward/pen_flat_orientation: -0.1124
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0879
   Episode_Reward/foot_landing_vel: -0.0468
   Episode_Reward/test_gait_reward: -0.3633
Metrics/base_velocity/error_vel_xy: 1.1573
Metrics/base_velocity/error_vel_yaw: 0.3328
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 1.07s
                        Total time: 773.40s
                               ETA: 2481.8s

################################################################################
                     [1m Learning iteration 713/3000 [0m                      

                       Computation: 91220 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.9593
                    Surrogate loss: -0.0004
             Mean action noise std: 0.4981
                     Learning rate: 0.0004
                       Mean reward: 26.16
               Mean episode length: 381.12
       Episode_Reward/keep_balance: 0.3697
     Episode_Reward/rew_lin_vel_xy: 1.0202
      Episode_Reward/rew_ang_vel_z: 1.1367
    Episode_Reward/pen_base_height: -0.2301
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.0536
   Episode_Reward/pen_joint_torque: -0.0625
    Episode_Reward/pen_joint_accel: -0.0305
    Episode_Reward/pen_action_rate: -0.0748
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0123
   Episode_Reward/pen_joint_powers: -0.0219
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1628
Episode_Reward/pen_flat_orientation: -0.1132
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0838
   Episode_Reward/foot_landing_vel: -0.0463
   Episode_Reward/test_gait_reward: -0.3482
Metrics/base_velocity/error_vel_xy: 1.1034
Metrics/base_velocity/error_vel_yaw: 0.3220
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 1.08s
                        Total time: 774.48s
                               ETA: 2480.7s

################################################################################
                     [1m Learning iteration 714/3000 [0m                      

                       Computation: 91545 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.9479
                    Surrogate loss: 0.0001
             Mean action noise std: 0.4976
                     Learning rate: 0.0003
                       Mean reward: 26.16
               Mean episode length: 388.82
       Episode_Reward/keep_balance: 0.3958
     Episode_Reward/rew_lin_vel_xy: 1.1069
      Episode_Reward/rew_ang_vel_z: 1.2097
    Episode_Reward/pen_base_height: -0.2379
      Episode_Reward/pen_lin_vel_z: -0.0443
     Episode_Reward/pen_ang_vel_xy: -0.0589
   Episode_Reward/pen_joint_torque: -0.0699
    Episode_Reward/pen_joint_accel: -0.0343
    Episode_Reward/pen_action_rate: -0.0822
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0138
   Episode_Reward/pen_joint_powers: -0.0247
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1778
Episode_Reward/pen_flat_orientation: -0.1160
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0976
   Episode_Reward/foot_landing_vel: -0.0510
   Episode_Reward/test_gait_reward: -0.3756
Metrics/base_velocity/error_vel_xy: 1.2023
Metrics/base_velocity/error_vel_yaw: 0.3483
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 1.07s
                        Total time: 775.55s
                               ETA: 2479.6s

################################################################################
                     [1m Learning iteration 715/3000 [0m                      

                       Computation: 91636 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.9739
                    Surrogate loss: -0.0023
             Mean action noise std: 0.4974
                     Learning rate: 0.0004
                       Mean reward: 30.21
               Mean episode length: 455.81
       Episode_Reward/keep_balance: 0.4471
     Episode_Reward/rew_lin_vel_xy: 1.2401
      Episode_Reward/rew_ang_vel_z: 1.3554
    Episode_Reward/pen_base_height: -0.2580
      Episode_Reward/pen_lin_vel_z: -0.0496
     Episode_Reward/pen_ang_vel_xy: -0.0663
   Episode_Reward/pen_joint_torque: -0.0816
    Episode_Reward/pen_joint_accel: -0.0414
    Episode_Reward/pen_action_rate: -0.0942
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0164
   Episode_Reward/pen_joint_powers: -0.0287
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2006
Episode_Reward/pen_flat_orientation: -0.1228
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1164
   Episode_Reward/foot_landing_vel: -0.0582
   Episode_Reward/test_gait_reward: -0.4254
Metrics/base_velocity/error_vel_xy: 1.3341
Metrics/base_velocity/error_vel_yaw: 0.4035
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 1.07s
                        Total time: 776.62s
                               ETA: 2478.5s

################################################################################
                     [1m Learning iteration 716/3000 [0m                      

                       Computation: 91148 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.9508
                    Surrogate loss: 0.0005
             Mean action noise std: 0.4972
                     Learning rate: 0.0004
                       Mean reward: 23.13
               Mean episode length: 381.86
       Episode_Reward/keep_balance: 0.4275
     Episode_Reward/rew_lin_vel_xy: 1.2156
      Episode_Reward/rew_ang_vel_z: 1.3008
    Episode_Reward/pen_base_height: -0.2526
      Episode_Reward/pen_lin_vel_z: -0.0500
     Episode_Reward/pen_ang_vel_xy: -0.0633
   Episode_Reward/pen_joint_torque: -0.0766
    Episode_Reward/pen_joint_accel: -0.0403
    Episode_Reward/pen_action_rate: -0.0904
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0156
   Episode_Reward/pen_joint_powers: -0.0273
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.1936
Episode_Reward/pen_flat_orientation: -0.1241
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1114
   Episode_Reward/foot_landing_vel: -0.0595
   Episode_Reward/test_gait_reward: -0.4072
Metrics/base_velocity/error_vel_xy: 1.2871
Metrics/base_velocity/error_vel_yaw: 0.3829
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 1.08s
                        Total time: 777.70s
                               ETA: 2477.4s

################################################################################
                     [1m Learning iteration 717/3000 [0m                      

                       Computation: 91688 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 1.1997
                    Surrogate loss: -0.0016
             Mean action noise std: 0.4970
                     Learning rate: 0.0009
                       Mean reward: 29.52
               Mean episode length: 408.23
       Episode_Reward/keep_balance: 0.4095
     Episode_Reward/rew_lin_vel_xy: 1.1734
      Episode_Reward/rew_ang_vel_z: 1.2552
    Episode_Reward/pen_base_height: -0.2451
      Episode_Reward/pen_lin_vel_z: -0.0453
     Episode_Reward/pen_ang_vel_xy: -0.0598
   Episode_Reward/pen_joint_torque: -0.0703
    Episode_Reward/pen_joint_accel: -0.0352
    Episode_Reward/pen_action_rate: -0.0850
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0250
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1825
Episode_Reward/pen_flat_orientation: -0.1206
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0967
   Episode_Reward/foot_landing_vel: -0.0520
   Episode_Reward/test_gait_reward: -0.3874
Metrics/base_velocity/error_vel_xy: 1.1888
Metrics/base_velocity/error_vel_yaw: 0.3584
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 1.07s
                        Total time: 778.78s
                               ETA: 2476.2s

################################################################################
                     [1m Learning iteration 718/3000 [0m                      

                       Computation: 90438 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 1.4507
                    Surrogate loss: 0.0048
             Mean action noise std: 0.4975
                     Learning rate: 0.0003
                       Mean reward: 32.73
               Mean episode length: 457.72
       Episode_Reward/keep_balance: 0.4136
     Episode_Reward/rew_lin_vel_xy: 1.2161
      Episode_Reward/rew_ang_vel_z: 1.2639
    Episode_Reward/pen_base_height: -0.2502
      Episode_Reward/pen_lin_vel_z: -0.0467
     Episode_Reward/pen_ang_vel_xy: -0.0618
   Episode_Reward/pen_joint_torque: -0.0722
    Episode_Reward/pen_joint_accel: -0.0372
    Episode_Reward/pen_action_rate: -0.0867
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0149
   Episode_Reward/pen_joint_powers: -0.0260
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1855
Episode_Reward/pen_flat_orientation: -0.1224
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1059
   Episode_Reward/foot_landing_vel: -0.0567
   Episode_Reward/test_gait_reward: -0.3927
Metrics/base_velocity/error_vel_xy: 1.1931
Metrics/base_velocity/error_vel_yaw: 0.3678
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 1.09s
                        Total time: 779.86s
                               ETA: 2475.2s

################################################################################
                     [1m Learning iteration 719/3000 [0m                      

                       Computation: 91175 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.2036
                    Surrogate loss: -0.0010
             Mean action noise std: 0.4980
                     Learning rate: 0.0009
                       Mean reward: 35.46
               Mean episode length: 485.29
       Episode_Reward/keep_balance: 0.4242
     Episode_Reward/rew_lin_vel_xy: 1.3638
      Episode_Reward/rew_ang_vel_z: 1.2870
    Episode_Reward/pen_base_height: -0.2586
      Episode_Reward/pen_lin_vel_z: -0.0478
     Episode_Reward/pen_ang_vel_xy: -0.0643
   Episode_Reward/pen_joint_torque: -0.0767
    Episode_Reward/pen_joint_accel: -0.0379
    Episode_Reward/pen_action_rate: -0.0894
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0154
   Episode_Reward/pen_joint_powers: -0.0272
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1908
Episode_Reward/pen_flat_orientation: -0.1260
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1079
   Episode_Reward/foot_landing_vel: -0.0568
   Episode_Reward/test_gait_reward: -0.4032
Metrics/base_velocity/error_vel_xy: 1.1454
Metrics/base_velocity/error_vel_yaw: 0.3838
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 7.5833
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 1.08s
                        Total time: 780.94s
                               ETA: 2474.1s

################################################################################
                     [1m Learning iteration 720/3000 [0m                      

                       Computation: 89803 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 1.2177
                    Surrogate loss: 0.0017
             Mean action noise std: 0.4994
                     Learning rate: 0.0006
                       Mean reward: 25.20
               Mean episode length: 380.98
       Episode_Reward/keep_balance: 0.3927
     Episode_Reward/rew_lin_vel_xy: 1.0678
      Episode_Reward/rew_ang_vel_z: 1.1973
    Episode_Reward/pen_base_height: -0.2374
      Episode_Reward/pen_lin_vel_z: -0.0422
     Episode_Reward/pen_ang_vel_xy: -0.0593
   Episode_Reward/pen_joint_torque: -0.0672
    Episode_Reward/pen_joint_accel: -0.0337
    Episode_Reward/pen_action_rate: -0.0808
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0238
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1756
Episode_Reward/pen_flat_orientation: -0.1192
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0934
   Episode_Reward/foot_landing_vel: -0.0468
   Episode_Reward/test_gait_reward: -0.3718
Metrics/base_velocity/error_vel_xy: 1.1957
Metrics/base_velocity/error_vel_yaw: 0.3490
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 9.2500
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 1.09s
                        Total time: 782.03s
                               ETA: 2473.0s

################################################################################
                     [1m Learning iteration 721/3000 [0m                      

                       Computation: 90385 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 1.1691
                    Surrogate loss: -0.0001
             Mean action noise std: 0.4998
                     Learning rate: 0.0006
                       Mean reward: 25.35
               Mean episode length: 367.74
       Episode_Reward/keep_balance: 0.3926
     Episode_Reward/rew_lin_vel_xy: 1.1235
      Episode_Reward/rew_ang_vel_z: 1.2083
    Episode_Reward/pen_base_height: -0.2329
      Episode_Reward/pen_lin_vel_z: -0.0406
     Episode_Reward/pen_ang_vel_xy: -0.0573
   Episode_Reward/pen_joint_torque: -0.0656
    Episode_Reward/pen_joint_accel: -0.0346
    Episode_Reward/pen_action_rate: -0.0801
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0131
   Episode_Reward/pen_joint_powers: -0.0231
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1751
Episode_Reward/pen_flat_orientation: -0.1137
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0890
   Episode_Reward/foot_landing_vel: -0.0474
   Episode_Reward/test_gait_reward: -0.3703
Metrics/base_velocity/error_vel_xy: 1.1655
Metrics/base_velocity/error_vel_yaw: 0.3398
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 1.09s
                        Total time: 783.12s
                               ETA: 2471.9s

################################################################################
                     [1m Learning iteration 722/3000 [0m                      

                       Computation: 90463 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 1.2809
                    Surrogate loss: 0.0029
             Mean action noise std: 0.5003
                     Learning rate: 0.0001
                       Mean reward: 28.97
               Mean episode length: 421.65
       Episode_Reward/keep_balance: 0.4131
     Episode_Reward/rew_lin_vel_xy: 1.2207
      Episode_Reward/rew_ang_vel_z: 1.2664
    Episode_Reward/pen_base_height: -0.2463
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.0630
   Episode_Reward/pen_joint_torque: -0.0720
    Episode_Reward/pen_joint_accel: -0.0366
    Episode_Reward/pen_action_rate: -0.0860
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0146
   Episode_Reward/pen_joint_powers: -0.0256
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1847
Episode_Reward/pen_flat_orientation: -0.1245
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1018
   Episode_Reward/foot_landing_vel: -0.0513
   Episode_Reward/test_gait_reward: -0.3941
Metrics/base_velocity/error_vel_xy: 1.2182
Metrics/base_velocity/error_vel_yaw: 0.3607
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 10.4583
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 1.09s
                        Total time: 784.21s
                               ETA: 2470.9s

################################################################################
                     [1m Learning iteration 723/3000 [0m                      

                       Computation: 90046 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 1.0140
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5005
                     Learning rate: 0.0006
                       Mean reward: 28.00
               Mean episode length: 429.63
       Episode_Reward/keep_balance: 0.4248
     Episode_Reward/rew_lin_vel_xy: 1.1664
      Episode_Reward/rew_ang_vel_z: 1.3007
    Episode_Reward/pen_base_height: -0.2462
      Episode_Reward/pen_lin_vel_z: -0.0446
     Episode_Reward/pen_ang_vel_xy: -0.0629
   Episode_Reward/pen_joint_torque: -0.0735
    Episode_Reward/pen_joint_accel: -0.0351
    Episode_Reward/pen_action_rate: -0.0884
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0145
   Episode_Reward/pen_joint_powers: -0.0260
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1904
Episode_Reward/pen_flat_orientation: -0.1263
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1017
   Episode_Reward/foot_landing_vel: -0.0514
   Episode_Reward/test_gait_reward: -0.4011
Metrics/base_velocity/error_vel_xy: 1.2773
Metrics/base_velocity/error_vel_yaw: 0.3752
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 9.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 1.09s
                        Total time: 785.30s
                               ETA: 2469.8s

################################################################################
                     [1m Learning iteration 724/3000 [0m                      

                       Computation: 91033 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 1.0813
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5009
                     Learning rate: 0.0009
                       Mean reward: 26.59
               Mean episode length: 391.41
       Episode_Reward/keep_balance: 0.3939
     Episode_Reward/rew_lin_vel_xy: 1.1771
      Episode_Reward/rew_ang_vel_z: 1.2031
    Episode_Reward/pen_base_height: -0.2385
      Episode_Reward/pen_lin_vel_z: -0.0425
     Episode_Reward/pen_ang_vel_xy: -0.0596
   Episode_Reward/pen_joint_torque: -0.0683
    Episode_Reward/pen_joint_accel: -0.0368
    Episode_Reward/pen_action_rate: -0.0821
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0138
   Episode_Reward/pen_joint_powers: -0.0241
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1782
Episode_Reward/pen_flat_orientation: -0.1221
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0956
   Episode_Reward/foot_landing_vel: -0.0502
   Episode_Reward/test_gait_reward: -0.3743
Metrics/base_velocity/error_vel_xy: 1.1159
Metrics/base_velocity/error_vel_yaw: 0.3473
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 1.08s
                        Total time: 786.38s
                               ETA: 2468.7s

################################################################################
                     [1m Learning iteration 725/3000 [0m                      

                       Computation: 90466 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.9590
                    Surrogate loss: 0.0026
             Mean action noise std: 0.5022
                     Learning rate: 0.0004
                       Mean reward: 22.31
               Mean episode length: 333.80
       Episode_Reward/keep_balance: 0.3822
     Episode_Reward/rew_lin_vel_xy: 1.1377
      Episode_Reward/rew_ang_vel_z: 1.1684
    Episode_Reward/pen_base_height: -0.2337
      Episode_Reward/pen_lin_vel_z: -0.0399
     Episode_Reward/pen_ang_vel_xy: -0.0573
   Episode_Reward/pen_joint_torque: -0.0658
    Episode_Reward/pen_joint_accel: -0.0313
    Episode_Reward/pen_action_rate: -0.0779
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0130
   Episode_Reward/pen_joint_powers: -0.0231
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1697
Episode_Reward/pen_flat_orientation: -0.1197
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0917
   Episode_Reward/foot_landing_vel: -0.0449
   Episode_Reward/test_gait_reward: -0.3629
Metrics/base_velocity/error_vel_xy: 1.0930
Metrics/base_velocity/error_vel_yaw: 0.3383
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 1.09s
                        Total time: 787.47s
                               ETA: 2467.6s

################################################################################
                     [1m Learning iteration 726/3000 [0m                      

                       Computation: 90415 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 1.0105
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5026
                     Learning rate: 0.0006
                       Mean reward: 27.14
               Mean episode length: 409.13
       Episode_Reward/keep_balance: 0.4219
     Episode_Reward/rew_lin_vel_xy: 1.1970
      Episode_Reward/rew_ang_vel_z: 1.2968
    Episode_Reward/pen_base_height: -0.2404
      Episode_Reward/pen_lin_vel_z: -0.0433
     Episode_Reward/pen_ang_vel_xy: -0.0626
   Episode_Reward/pen_joint_torque: -0.0721
    Episode_Reward/pen_joint_accel: -0.0340
    Episode_Reward/pen_action_rate: -0.0876
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0254
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1889
Episode_Reward/pen_flat_orientation: -0.1170
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0994
   Episode_Reward/foot_landing_vel: -0.0490
   Episode_Reward/test_gait_reward: -0.3991
Metrics/base_velocity/error_vel_xy: 1.2505
Metrics/base_velocity/error_vel_yaw: 0.3652
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 1.09s
                        Total time: 788.55s
                               ETA: 2466.5s

################################################################################
                     [1m Learning iteration 727/3000 [0m                      

                       Computation: 91445 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 1.0629
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5028
                     Learning rate: 0.0004
                       Mean reward: 32.87
               Mean episode length: 447.40
       Episode_Reward/keep_balance: 0.3932
     Episode_Reward/rew_lin_vel_xy: 1.1016
      Episode_Reward/rew_ang_vel_z: 1.2113
    Episode_Reward/pen_base_height: -0.2327
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.0568
   Episode_Reward/pen_joint_torque: -0.0681
    Episode_Reward/pen_joint_accel: -0.0332
    Episode_Reward/pen_action_rate: -0.0808
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0237
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1753
Episode_Reward/pen_flat_orientation: -0.1147
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0889
   Episode_Reward/foot_landing_vel: -0.0471
   Episode_Reward/test_gait_reward: -0.3716
Metrics/base_velocity/error_vel_xy: 1.1776
Metrics/base_velocity/error_vel_yaw: 0.3401
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 1.07s
                        Total time: 789.63s
                               ETA: 2465.4s

################################################################################
                     [1m Learning iteration 728/3000 [0m                      

                       Computation: 91825 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.0403
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5030
                     Learning rate: 0.0004
                       Mean reward: 27.01
               Mean episode length: 379.83
       Episode_Reward/keep_balance: 0.4090
     Episode_Reward/rew_lin_vel_xy: 1.1821
      Episode_Reward/rew_ang_vel_z: 1.2519
    Episode_Reward/pen_base_height: -0.2369
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.0607
   Episode_Reward/pen_joint_torque: -0.0720
    Episode_Reward/pen_joint_accel: -0.0359
    Episode_Reward/pen_action_rate: -0.0860
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0145
   Episode_Reward/pen_joint_powers: -0.0255
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1847
Episode_Reward/pen_flat_orientation: -0.1241
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1023
   Episode_Reward/foot_landing_vel: -0.0506
   Episode_Reward/test_gait_reward: -0.3871
Metrics/base_velocity/error_vel_xy: 1.2267
Metrics/base_velocity/error_vel_yaw: 0.3589
      Episode_Termination/time_out: 2.5833
  Episode_Termination/base_contact: 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 1.07s
                        Total time: 790.70s
                               ETA: 2464.3s

################################################################################
                     [1m Learning iteration 729/3000 [0m                      

                       Computation: 88712 steps/s (collection: 0.986s, learning 0.122s)
               Value function loss: 1.0173
                    Surrogate loss: 0.0007
             Mean action noise std: 0.5033
                     Learning rate: 0.0004
                       Mean reward: 26.78
               Mean episode length: 376.66
       Episode_Reward/keep_balance: 0.3946
     Episode_Reward/rew_lin_vel_xy: 1.1005
      Episode_Reward/rew_ang_vel_z: 1.2142
    Episode_Reward/pen_base_height: -0.2353
      Episode_Reward/pen_lin_vel_z: -0.0402
     Episode_Reward/pen_ang_vel_xy: -0.0588
   Episode_Reward/pen_joint_torque: -0.0686
    Episode_Reward/pen_joint_accel: -0.0331
    Episode_Reward/pen_action_rate: -0.0808
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0131
   Episode_Reward/pen_joint_powers: -0.0238
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1768
Episode_Reward/pen_flat_orientation: -0.1191
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0890
   Episode_Reward/foot_landing_vel: -0.0460
   Episode_Reward/test_gait_reward: -0.3745
Metrics/base_velocity/error_vel_xy: 1.2053
Metrics/base_velocity/error_vel_yaw: 0.3412
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 1.11s
                        Total time: 791.81s
                               ETA: 2463.3s

################################################################################
                     [1m Learning iteration 730/3000 [0m                      

                       Computation: 91742 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 1.0652
                    Surrogate loss: -0.0016
             Mean action noise std: 0.5041
                     Learning rate: 0.0009
                       Mean reward: 25.83
               Mean episode length: 391.61
       Episode_Reward/keep_balance: 0.3658
     Episode_Reward/rew_lin_vel_xy: 1.0174
      Episode_Reward/rew_ang_vel_z: 1.1111
    Episode_Reward/pen_base_height: -0.2221
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.0556
   Episode_Reward/pen_joint_torque: -0.0602
    Episode_Reward/pen_joint_accel: -0.0287
    Episode_Reward/pen_action_rate: -0.0752
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0122
   Episode_Reward/pen_joint_powers: -0.0213
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1658
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0856
   Episode_Reward/foot_landing_vel: -0.0422
   Episode_Reward/test_gait_reward: -0.3456
Metrics/base_velocity/error_vel_xy: 1.1203
Metrics/base_velocity/error_vel_yaw: 0.3287
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 9.2500
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 1.07s
                        Total time: 792.88s
                               ETA: 2462.2s

################################################################################
                     [1m Learning iteration 731/3000 [0m                      

                       Computation: 89501 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 1.1218
                    Surrogate loss: 0.0014
             Mean action noise std: 0.5046
                     Learning rate: 0.0002
                       Mean reward: 28.97
               Mean episode length: 417.02
       Episode_Reward/keep_balance: 0.3982
     Episode_Reward/rew_lin_vel_xy: 1.1055
      Episode_Reward/rew_ang_vel_z: 1.2100
    Episode_Reward/pen_base_height: -0.2377
      Episode_Reward/pen_lin_vel_z: -0.0422
     Episode_Reward/pen_ang_vel_xy: -0.0603
   Episode_Reward/pen_joint_torque: -0.0693
    Episode_Reward/pen_joint_accel: -0.0364
    Episode_Reward/pen_action_rate: -0.0841
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0143
   Episode_Reward/pen_joint_powers: -0.0247
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1807
Episode_Reward/pen_flat_orientation: -0.1202
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1020
   Episode_Reward/foot_landing_vel: -0.0503
   Episode_Reward/test_gait_reward: -0.3794
Metrics/base_velocity/error_vel_xy: 1.2059
Metrics/base_velocity/error_vel_yaw: 0.3569
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 1.10s
                        Total time: 793.98s
                               ETA: 2461.1s

################################################################################
                     [1m Learning iteration 732/3000 [0m                      

                       Computation: 91154 steps/s (collection: 0.957s, learning 0.121s)
               Value function loss: 1.0152
                    Surrogate loss: -0.0016
             Mean action noise std: 0.5047
                     Learning rate: 0.0004
                       Mean reward: 25.66
               Mean episode length: 352.78
       Episode_Reward/keep_balance: 0.3613
     Episode_Reward/rew_lin_vel_xy: 1.0344
      Episode_Reward/rew_ang_vel_z: 1.1006
    Episode_Reward/pen_base_height: -0.2213
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.0560
   Episode_Reward/pen_joint_torque: -0.0608
    Episode_Reward/pen_joint_accel: -0.0309
    Episode_Reward/pen_action_rate: -0.0752
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0122
   Episode_Reward/pen_joint_powers: -0.0215
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1634
Episode_Reward/pen_flat_orientation: -0.1131
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0871
   Episode_Reward/foot_landing_vel: -0.0426
   Episode_Reward/test_gait_reward: -0.3418
Metrics/base_velocity/error_vel_xy: 1.0737
Metrics/base_velocity/error_vel_yaw: 0.3222
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 1.08s
                        Total time: 795.06s
                               ETA: 2460.0s

################################################################################
                     [1m Learning iteration 733/3000 [0m                      

                       Computation: 90213 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 1.0489
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5044
                     Learning rate: 0.0006
                       Mean reward: 24.80
               Mean episode length: 379.23
       Episode_Reward/keep_balance: 0.3494
     Episode_Reward/rew_lin_vel_xy: 0.9986
      Episode_Reward/rew_ang_vel_z: 1.0679
    Episode_Reward/pen_base_height: -0.2191
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.0554
   Episode_Reward/pen_joint_torque: -0.0598
    Episode_Reward/pen_joint_accel: -0.0293
    Episode_Reward/pen_action_rate: -0.0730
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0121
   Episode_Reward/pen_joint_powers: -0.0212
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1583
Episode_Reward/pen_flat_orientation: -0.1122
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0846
   Episode_Reward/foot_landing_vel: -0.0429
   Episode_Reward/test_gait_reward: -0.3329
Metrics/base_velocity/error_vel_xy: 1.0218
Metrics/base_velocity/error_vel_yaw: 0.3098
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 1.09s
                        Total time: 796.15s
                               ETA: 2458.9s

################################################################################
                     [1m Learning iteration 734/3000 [0m                      

                       Computation: 91068 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 1.1119
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5049
                     Learning rate: 0.0006
                       Mean reward: 27.19
               Mean episode length: 379.70
       Episode_Reward/keep_balance: 0.3724
     Episode_Reward/rew_lin_vel_xy: 1.1098
      Episode_Reward/rew_ang_vel_z: 1.1395
    Episode_Reward/pen_base_height: -0.2280
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.0585
   Episode_Reward/pen_joint_torque: -0.0652
    Episode_Reward/pen_joint_accel: -0.0343
    Episode_Reward/pen_action_rate: -0.0781
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0131
   Episode_Reward/pen_joint_powers: -0.0231
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1682
Episode_Reward/pen_flat_orientation: -0.1139
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0895
   Episode_Reward/foot_landing_vel: -0.0458
   Episode_Reward/test_gait_reward: -0.3549
Metrics/base_velocity/error_vel_xy: 1.0558
Metrics/base_velocity/error_vel_yaw: 0.3278
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 1.08s
                        Total time: 797.23s
                               ETA: 2457.8s

################################################################################
                     [1m Learning iteration 735/3000 [0m                      

                       Computation: 91482 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 1.1206
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5050
                     Learning rate: 0.0004
                       Mean reward: 26.58
               Mean episode length: 387.54
       Episode_Reward/keep_balance: 0.3654
     Episode_Reward/rew_lin_vel_xy: 1.0630
      Episode_Reward/rew_ang_vel_z: 1.1092
    Episode_Reward/pen_base_height: -0.2327
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.0596
   Episode_Reward/pen_joint_torque: -0.0665
    Episode_Reward/pen_joint_accel: -0.0339
    Episode_Reward/pen_action_rate: -0.0783
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0240
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1676
Episode_Reward/pen_flat_orientation: -0.1176
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0958
   Episode_Reward/foot_landing_vel: -0.0472
   Episode_Reward/test_gait_reward: -0.3513
Metrics/base_velocity/error_vel_xy: 1.0754
Metrics/base_velocity/error_vel_yaw: 0.3301
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 1.07s
                        Total time: 798.30s
                               ETA: 2456.7s

################################################################################
                     [1m Learning iteration 736/3000 [0m                      

                       Computation: 92119 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 1.1074
                    Surrogate loss: -0.0028
             Mean action noise std: 0.5052
                     Learning rate: 0.0009
                       Mean reward: 27.49
               Mean episode length: 398.16
       Episode_Reward/keep_balance: 0.4149
     Episode_Reward/rew_lin_vel_xy: 1.1508
      Episode_Reward/rew_ang_vel_z: 1.2608
    Episode_Reward/pen_base_height: -0.2436
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.0631
   Episode_Reward/pen_joint_torque: -0.0728
    Episode_Reward/pen_joint_accel: -0.0352
    Episode_Reward/pen_action_rate: -0.0887
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0148
   Episode_Reward/pen_joint_powers: -0.0259
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1913
Episode_Reward/pen_flat_orientation: -0.1232
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1012
   Episode_Reward/foot_landing_vel: -0.0528
   Episode_Reward/test_gait_reward: -0.3959
Metrics/base_velocity/error_vel_xy: 1.2439
Metrics/base_velocity/error_vel_yaw: 0.3731
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 1.07s
                        Total time: 799.37s
                               ETA: 2455.6s

################################################################################
                     [1m Learning iteration 737/3000 [0m                      

                       Computation: 91715 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 1.1624
                    Surrogate loss: 0.0016
             Mean action noise std: 0.5057
                     Learning rate: 0.0004
                       Mean reward: 22.30
               Mean episode length: 370.89
       Episode_Reward/keep_balance: 0.3752
     Episode_Reward/rew_lin_vel_xy: 0.9826
      Episode_Reward/rew_ang_vel_z: 1.1385
    Episode_Reward/pen_base_height: -0.2243
      Episode_Reward/pen_lin_vel_z: -0.0389
     Episode_Reward/pen_ang_vel_xy: -0.0568
   Episode_Reward/pen_joint_torque: -0.0647
    Episode_Reward/pen_joint_accel: -0.0328
    Episode_Reward/pen_action_rate: -0.0791
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0129
   Episode_Reward/pen_joint_powers: -0.0226
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1729
Episode_Reward/pen_flat_orientation: -0.1139
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0909
   Episode_Reward/foot_landing_vel: -0.0440
   Episode_Reward/test_gait_reward: -0.3569
Metrics/base_velocity/error_vel_xy: 1.1910
Metrics/base_velocity/error_vel_yaw: 0.3366
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 1.07s
                        Total time: 800.44s
                               ETA: 2454.5s

################################################################################
                     [1m Learning iteration 738/3000 [0m                      

                       Computation: 91484 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.2163
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5061
                     Learning rate: 0.0004
                       Mean reward: 30.59
               Mean episode length: 437.45
       Episode_Reward/keep_balance: 0.4042
     Episode_Reward/rew_lin_vel_xy: 1.1355
      Episode_Reward/rew_ang_vel_z: 1.2306
    Episode_Reward/pen_base_height: -0.2428
      Episode_Reward/pen_lin_vel_z: -0.0423
     Episode_Reward/pen_ang_vel_xy: -0.0617
   Episode_Reward/pen_joint_torque: -0.0720
    Episode_Reward/pen_joint_accel: -0.0358
    Episode_Reward/pen_action_rate: -0.0857
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0142
   Episode_Reward/pen_joint_powers: -0.0251
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1855
Episode_Reward/pen_flat_orientation: -0.1239
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1012
   Episode_Reward/foot_landing_vel: -0.0500
   Episode_Reward/test_gait_reward: -0.3834
Metrics/base_velocity/error_vel_xy: 1.2174
Metrics/base_velocity/error_vel_yaw: 0.3619
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 1.07s
                        Total time: 801.51s
                               ETA: 2453.3s

################################################################################
                     [1m Learning iteration 739/3000 [0m                      

                       Computation: 89913 steps/s (collection: 0.965s, learning 0.128s)
               Value function loss: 1.0347
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5064
                     Learning rate: 0.0009
                       Mean reward: 29.16
               Mean episode length: 428.38
       Episode_Reward/keep_balance: 0.4126
     Episode_Reward/rew_lin_vel_xy: 1.1700
      Episode_Reward/rew_ang_vel_z: 1.2528
    Episode_Reward/pen_base_height: -0.2375
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.0614
   Episode_Reward/pen_joint_torque: -0.0710
    Episode_Reward/pen_joint_accel: -0.0357
    Episode_Reward/pen_action_rate: -0.0879
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0145
   Episode_Reward/pen_joint_powers: -0.0253
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.1913
Episode_Reward/pen_flat_orientation: -0.1216
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1012
   Episode_Reward/foot_landing_vel: -0.0516
   Episode_Reward/test_gait_reward: -0.3941
Metrics/base_velocity/error_vel_xy: 1.2214
Metrics/base_velocity/error_vel_yaw: 0.3721
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 1.09s
                        Total time: 802.61s
                               ETA: 2452.3s

################################################################################
                     [1m Learning iteration 740/3000 [0m                      

                       Computation: 90022 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 1.2781
                    Surrogate loss: 0.0041
             Mean action noise std: 0.5068
                     Learning rate: 0.0002
                       Mean reward: 26.41
               Mean episode length: 401.26
       Episode_Reward/keep_balance: 0.3686
     Episode_Reward/rew_lin_vel_xy: 1.0047
      Episode_Reward/rew_ang_vel_z: 1.1237
    Episode_Reward/pen_base_height: -0.2267
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.0579
   Episode_Reward/pen_joint_torque: -0.0646
    Episode_Reward/pen_joint_accel: -0.0337
    Episode_Reward/pen_action_rate: -0.0785
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0130
   Episode_Reward/pen_joint_powers: -0.0227
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1695
Episode_Reward/pen_flat_orientation: -0.1169
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0917
   Episode_Reward/foot_landing_vel: -0.0469
   Episode_Reward/test_gait_reward: -0.3539
Metrics/base_velocity/error_vel_xy: 1.1410
Metrics/base_velocity/error_vel_yaw: 0.3278
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 1.09s
                        Total time: 803.70s
                               ETA: 2451.2s

################################################################################
                     [1m Learning iteration 741/3000 [0m                      

                       Computation: 89794 steps/s (collection: 0.969s, learning 0.126s)
               Value function loss: 1.0229
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5070
                     Learning rate: 0.0002
                       Mean reward: 26.91
               Mean episode length: 377.62
       Episode_Reward/keep_balance: 0.3644
     Episode_Reward/rew_lin_vel_xy: 1.0595
      Episode_Reward/rew_ang_vel_z: 1.1110
    Episode_Reward/pen_base_height: -0.2212
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.0568
   Episode_Reward/pen_joint_torque: -0.0612
    Episode_Reward/pen_joint_accel: -0.0315
    Episode_Reward/pen_action_rate: -0.0758
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0123
   Episode_Reward/pen_joint_powers: -0.0215
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1676
Episode_Reward/pen_flat_orientation: -0.1110
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0830
   Episode_Reward/foot_landing_vel: -0.0418
   Episode_Reward/test_gait_reward: -0.3459
Metrics/base_velocity/error_vel_xy: 1.0698
Metrics/base_velocity/error_vel_yaw: 0.3244
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 1.09s
                        Total time: 804.79s
                               ETA: 2450.2s

################################################################################
                     [1m Learning iteration 742/3000 [0m                      

                       Computation: 90904 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 0.9908
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5073
                     Learning rate: 0.0004
                       Mean reward: 24.09
               Mean episode length: 377.69
       Episode_Reward/keep_balance: 0.3772
     Episode_Reward/rew_lin_vel_xy: 1.0501
      Episode_Reward/rew_ang_vel_z: 1.1582
    Episode_Reward/pen_base_height: -0.2304
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.0581
   Episode_Reward/pen_joint_torque: -0.0670
    Episode_Reward/pen_joint_accel: -0.0319
    Episode_Reward/pen_action_rate: -0.0802
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0233
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1732
Episode_Reward/pen_flat_orientation: -0.1145
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0943
   Episode_Reward/foot_landing_vel: -0.0482
   Episode_Reward/test_gait_reward: -0.3607
Metrics/base_velocity/error_vel_xy: 1.1468
Metrics/base_velocity/error_vel_yaw: 0.3293
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 1.08s
                        Total time: 805.88s
                               ETA: 2449.1s

################################################################################
                     [1m Learning iteration 743/3000 [0m                      

                       Computation: 91215 steps/s (collection: 0.953s, learning 0.125s)
               Value function loss: 0.7991
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5082
                     Learning rate: 0.0006
                       Mean reward: 22.07
               Mean episode length: 344.11
       Episode_Reward/keep_balance: 0.3722
     Episode_Reward/rew_lin_vel_xy: 1.0499
      Episode_Reward/rew_ang_vel_z: 1.1310
    Episode_Reward/pen_base_height: -0.2221
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.0564
   Episode_Reward/pen_joint_torque: -0.0632
    Episode_Reward/pen_joint_accel: -0.0331
    Episode_Reward/pen_action_rate: -0.0778
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0126
   Episode_Reward/pen_joint_powers: -0.0223
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1709
Episode_Reward/pen_flat_orientation: -0.1132
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0850
   Episode_Reward/foot_landing_vel: -0.0435
   Episode_Reward/test_gait_reward: -0.3533
Metrics/base_velocity/error_vel_xy: 1.1111
Metrics/base_velocity/error_vel_yaw: 0.3321
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 1.08s
                        Total time: 806.95s
                               ETA: 2448.0s

################################################################################
                     [1m Learning iteration 744/3000 [0m                      

                       Computation: 89459 steps/s (collection: 0.973s, learning 0.126s)
               Value function loss: 0.8996
                    Surrogate loss: 0.0002
             Mean action noise std: 0.5089
                     Learning rate: 0.0004
                       Mean reward: 23.94
               Mean episode length: 350.20
       Episode_Reward/keep_balance: 0.3649
     Episode_Reward/rew_lin_vel_xy: 1.0554
      Episode_Reward/rew_ang_vel_z: 1.1008
    Episode_Reward/pen_base_height: -0.2247
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.0572
   Episode_Reward/pen_joint_torque: -0.0619
    Episode_Reward/pen_joint_accel: -0.0323
    Episode_Reward/pen_action_rate: -0.0775
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0131
   Episode_Reward/pen_joint_powers: -0.0223
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1704
Episode_Reward/pen_flat_orientation: -0.1123
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0922
   Episode_Reward/foot_landing_vel: -0.0447
   Episode_Reward/test_gait_reward: -0.3498
Metrics/base_velocity/error_vel_xy: 1.0757
Metrics/base_velocity/error_vel_yaw: 0.3342
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 1.10s
                        Total time: 808.05s
                               ETA: 2446.9s

################################################################################
                     [1m Learning iteration 745/3000 [0m                      

                       Computation: 90330 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.9585
                    Surrogate loss: 0.0009
             Mean action noise std: 0.5090
                     Learning rate: 0.0002
                       Mean reward: 26.61
               Mean episode length: 402.83
       Episode_Reward/keep_balance: 0.3947
     Episode_Reward/rew_lin_vel_xy: 1.1377
      Episode_Reward/rew_ang_vel_z: 1.2026
    Episode_Reward/pen_base_height: -0.2341
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.0605
   Episode_Reward/pen_joint_torque: -0.0679
    Episode_Reward/pen_joint_accel: -0.0356
    Episode_Reward/pen_action_rate: -0.0835
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0139
   Episode_Reward/pen_joint_powers: -0.0241
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1829
Episode_Reward/pen_flat_orientation: -0.1156
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0968
   Episode_Reward/foot_landing_vel: -0.0481
   Episode_Reward/test_gait_reward: -0.3758
Metrics/base_velocity/error_vel_xy: 1.1765
Metrics/base_velocity/error_vel_yaw: 0.3517
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 1.09s
                        Total time: 809.14s
                               ETA: 2445.9s

################################################################################
                     [1m Learning iteration 746/3000 [0m                      

                       Computation: 90638 steps/s (collection: 0.958s, learning 0.126s)
               Value function loss: 0.9500
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5090
                     Learning rate: 0.0004
                       Mean reward: 35.30
               Mean episode length: 485.72
       Episode_Reward/keep_balance: 0.4490
     Episode_Reward/rew_lin_vel_xy: 1.2937
      Episode_Reward/rew_ang_vel_z: 1.3885
    Episode_Reward/pen_base_height: -0.2501
      Episode_Reward/pen_lin_vel_z: -0.0451
     Episode_Reward/pen_ang_vel_xy: -0.0664
   Episode_Reward/pen_joint_torque: -0.0769
    Episode_Reward/pen_joint_accel: -0.0375
    Episode_Reward/pen_action_rate: -0.0950
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0152
   Episode_Reward/pen_joint_powers: -0.0271
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2058
Episode_Reward/pen_flat_orientation: -0.1220
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1065
   Episode_Reward/foot_landing_vel: -0.0525
   Episode_Reward/test_gait_reward: -0.4245
Metrics/base_velocity/error_vel_xy: 1.3647
Metrics/base_velocity/error_vel_yaw: 0.3860
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 1.08s
                        Total time: 810.22s
                               ETA: 2444.8s

################################################################################
                     [1m Learning iteration 747/3000 [0m                      

                       Computation: 90048 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 1.0606
                    Surrogate loss: -0.0008
             Mean action noise std: 0.5098
                     Learning rate: 0.0006
                       Mean reward: 35.69
               Mean episode length: 511.90
       Episode_Reward/keep_balance: 0.4918
     Episode_Reward/rew_lin_vel_xy: 1.4020
      Episode_Reward/rew_ang_vel_z: 1.5065
    Episode_Reward/pen_base_height: -0.2650
      Episode_Reward/pen_lin_vel_z: -0.0502
     Episode_Reward/pen_ang_vel_xy: -0.0700
   Episode_Reward/pen_joint_torque: -0.0898
    Episode_Reward/pen_joint_accel: -0.0413
    Episode_Reward/pen_action_rate: -0.1063
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0172
   Episode_Reward/pen_joint_powers: -0.0308
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2291
Episode_Reward/pen_flat_orientation: -0.1306
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1206
   Episode_Reward/foot_landing_vel: -0.0612
   Episode_Reward/test_gait_reward: -0.4676
Metrics/base_velocity/error_vel_xy: 1.4781
Metrics/base_velocity/error_vel_yaw: 0.4312
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 1.09s
                        Total time: 811.32s
                               ETA: 2443.7s

################################################################################
                     [1m Learning iteration 748/3000 [0m                      

                       Computation: 89265 steps/s (collection: 0.978s, learning 0.124s)
               Value function loss: 0.9236
                    Surrogate loss: 0.0014
             Mean action noise std: 0.5095
                     Learning rate: 0.0001
                       Mean reward: 28.98
               Mean episode length: 434.66
       Episode_Reward/keep_balance: 0.4234
     Episode_Reward/rew_lin_vel_xy: 1.1725
      Episode_Reward/rew_ang_vel_z: 1.2892
    Episode_Reward/pen_base_height: -0.2433
      Episode_Reward/pen_lin_vel_z: -0.0441
     Episode_Reward/pen_ang_vel_xy: -0.0642
   Episode_Reward/pen_joint_torque: -0.0748
    Episode_Reward/pen_joint_accel: -0.0386
    Episode_Reward/pen_action_rate: -0.0924
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0151
   Episode_Reward/pen_joint_powers: -0.0262
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1995
Episode_Reward/pen_flat_orientation: -0.1188
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1064
   Episode_Reward/foot_landing_vel: -0.0558
   Episode_Reward/test_gait_reward: -0.4024
Metrics/base_velocity/error_vel_xy: 1.3115
Metrics/base_velocity/error_vel_yaw: 0.3764
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 1.10s
                        Total time: 812.42s
                               ETA: 2442.7s

################################################################################
                     [1m Learning iteration 749/3000 [0m                      

                       Computation: 91590 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.8538
                    Surrogate loss: 0.0039
             Mean action noise std: 0.5096
                     Learning rate: 0.0000
                       Mean reward: 39.40
               Mean episode length: 546.18
       Episode_Reward/keep_balance: 0.5074
     Episode_Reward/rew_lin_vel_xy: 1.5218
      Episode_Reward/rew_ang_vel_z: 1.5429
    Episode_Reward/pen_base_height: -0.2670
      Episode_Reward/pen_lin_vel_z: -0.0520
     Episode_Reward/pen_ang_vel_xy: -0.0739
   Episode_Reward/pen_joint_torque: -0.0901
    Episode_Reward/pen_joint_accel: -0.0430
    Episode_Reward/pen_action_rate: -0.1122
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0182
   Episode_Reward/pen_joint_powers: -0.0317
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2427
Episode_Reward/pen_flat_orientation: -0.1283
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1286
   Episode_Reward/foot_landing_vel: -0.0641
   Episode_Reward/test_gait_reward: -0.4838
Metrics/base_velocity/error_vel_xy: 1.4638
Metrics/base_velocity/error_vel_yaw: 0.4518
      Episode_Termination/time_out: 2.5833
  Episode_Termination/base_contact: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 1.07s
                        Total time: 813.49s
                               ETA: 2441.6s

################################################################################
                     [1m Learning iteration 750/3000 [0m                      

                       Computation: 89995 steps/s (collection: 0.967s, learning 0.126s)
               Value function loss: 0.9639
                    Surrogate loss: 0.0066
             Mean action noise std: 0.5097
                     Learning rate: 0.0000
                       Mean reward: 30.17
               Mean episode length: 434.41
       Episode_Reward/keep_balance: 0.4782
     Episode_Reward/rew_lin_vel_xy: 1.4424
      Episode_Reward/rew_ang_vel_z: 1.4684
    Episode_Reward/pen_base_height: -0.2629
      Episode_Reward/pen_lin_vel_z: -0.0490
     Episode_Reward/pen_ang_vel_xy: -0.0718
   Episode_Reward/pen_joint_torque: -0.0842
    Episode_Reward/pen_joint_accel: -0.0425
    Episode_Reward/pen_action_rate: -0.1043
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0175
   Episode_Reward/pen_joint_powers: -0.0301
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2255
Episode_Reward/pen_flat_orientation: -0.1309
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.1295
   Episode_Reward/foot_landing_vel: -0.0614
   Episode_Reward/test_gait_reward: -0.4579
Metrics/base_velocity/error_vel_xy: 1.3927
Metrics/base_velocity/error_vel_yaw: 0.4163
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 1.09s
                        Total time: 814.58s
                               ETA: 2440.5s

################################################################################
                     [1m Learning iteration 751/3000 [0m                      

                       Computation: 91194 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.8940
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5101
                     Learning rate: 0.0001
                       Mean reward: 32.95
               Mean episode length: 460.67
       Episode_Reward/keep_balance: 0.4678
     Episode_Reward/rew_lin_vel_xy: 1.2375
      Episode_Reward/rew_ang_vel_z: 1.4456
    Episode_Reward/pen_base_height: -0.2524
      Episode_Reward/pen_lin_vel_z: -0.0468
     Episode_Reward/pen_ang_vel_xy: -0.0685
   Episode_Reward/pen_joint_torque: -0.0821
    Episode_Reward/pen_joint_accel: -0.0396
    Episode_Reward/pen_action_rate: -0.1010
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0161
   Episode_Reward/pen_joint_powers: -0.0285
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2179
Episode_Reward/pen_flat_orientation: -0.1210
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1127
   Episode_Reward/foot_landing_vel: -0.0584
   Episode_Reward/test_gait_reward: -0.4457
Metrics/base_velocity/error_vel_xy: 1.4972
Metrics/base_velocity/error_vel_yaw: 0.4017
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 1.08s
                        Total time: 815.66s
                               ETA: 2439.4s

################################################################################
                     [1m Learning iteration 752/3000 [0m                      

                       Computation: 91540 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.0160
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5108
                     Learning rate: 0.0003
                       Mean reward: 30.19
               Mean episode length: 437.77
       Episode_Reward/keep_balance: 0.4357
     Episode_Reward/rew_lin_vel_xy: 1.3149
      Episode_Reward/rew_ang_vel_z: 1.3306
    Episode_Reward/pen_base_height: -0.2458
      Episode_Reward/pen_lin_vel_z: -0.0443
     Episode_Reward/pen_ang_vel_xy: -0.0662
   Episode_Reward/pen_joint_torque: -0.0760
    Episode_Reward/pen_joint_accel: -0.0396
    Episode_Reward/pen_action_rate: -0.0948
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0153
   Episode_Reward/pen_joint_powers: -0.0268
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.2066
Episode_Reward/pen_flat_orientation: -0.1129
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1055
   Episode_Reward/foot_landing_vel: -0.0549
   Episode_Reward/test_gait_reward: -0.4146
Metrics/base_velocity/error_vel_xy: 1.2269
Metrics/base_velocity/error_vel_yaw: 0.3857
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 1.07s
                        Total time: 816.74s
                               ETA: 2438.3s

################################################################################
                     [1m Learning iteration 753/3000 [0m                      

                       Computation: 91126 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.0714
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5113
                     Learning rate: 0.0006
                       Mean reward: 27.91
               Mean episode length: 409.87
       Episode_Reward/keep_balance: 0.4178
     Episode_Reward/rew_lin_vel_xy: 1.1089
      Episode_Reward/rew_ang_vel_z: 1.2851
    Episode_Reward/pen_base_height: -0.2353
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.0618
   Episode_Reward/pen_joint_torque: -0.0711
    Episode_Reward/pen_joint_accel: -0.0368
    Episode_Reward/pen_action_rate: -0.0893
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0249
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1970
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0949
   Episode_Reward/foot_landing_vel: -0.0488
   Episode_Reward/test_gait_reward: -0.3962
Metrics/base_velocity/error_vel_xy: 1.3251
Metrics/base_velocity/error_vel_yaw: 0.3626
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 1.08s
                        Total time: 817.81s
                               ETA: 2437.2s

################################################################################
                     [1m Learning iteration 754/3000 [0m                      

                       Computation: 90849 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 1.1609
                    Surrogate loss: 0.0009
             Mean action noise std: 0.5117
                     Learning rate: 0.0004
                       Mean reward: 30.80
               Mean episode length: 438.96
       Episode_Reward/keep_balance: 0.4451
     Episode_Reward/rew_lin_vel_xy: 1.2945
      Episode_Reward/rew_ang_vel_z: 1.3573
    Episode_Reward/pen_base_height: -0.2493
      Episode_Reward/pen_lin_vel_z: -0.0437
     Episode_Reward/pen_ang_vel_xy: -0.0657
   Episode_Reward/pen_joint_torque: -0.0747
    Episode_Reward/pen_joint_accel: -0.0372
    Episode_Reward/pen_action_rate: -0.0957
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0152
   Episode_Reward/pen_joint_powers: -0.0266
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.2110
Episode_Reward/pen_flat_orientation: -0.1209
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1048
   Episode_Reward/foot_landing_vel: -0.0545
   Episode_Reward/test_gait_reward: -0.4227
Metrics/base_velocity/error_vel_xy: 1.3240
Metrics/base_velocity/error_vel_yaw: 0.3944
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 7.5833
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 1.08s
                        Total time: 818.90s
                               ETA: 2436.1s

################################################################################
                     [1m Learning iteration 755/3000 [0m                      

                       Computation: 90210 steps/s (collection: 0.964s, learning 0.126s)
               Value function loss: 0.9403
                    Surrogate loss: 0.0012
             Mean action noise std: 0.5125
                     Learning rate: 0.0003
                       Mean reward: 26.35
               Mean episode length: 393.28
       Episode_Reward/keep_balance: 0.4038
     Episode_Reward/rew_lin_vel_xy: 1.1868
      Episode_Reward/rew_ang_vel_z: 1.2310
    Episode_Reward/pen_base_height: -0.2387
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.0607
   Episode_Reward/pen_joint_torque: -0.0702
    Episode_Reward/pen_joint_accel: -0.0374
    Episode_Reward/pen_action_rate: -0.0875
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0143
   Episode_Reward/pen_joint_powers: -0.0247
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1923
Episode_Reward/pen_flat_orientation: -0.1149
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1026
   Episode_Reward/foot_landing_vel: -0.0515
   Episode_Reward/test_gait_reward: -0.3854
Metrics/base_velocity/error_vel_xy: 1.1821
Metrics/base_velocity/error_vel_yaw: 0.3591
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 1.09s
                        Total time: 819.99s
                               ETA: 2435.0s

################################################################################
                     [1m Learning iteration 756/3000 [0m                      

                       Computation: 90278 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 1.1091
                    Surrogate loss: -0.0008
             Mean action noise std: 0.5132
                     Learning rate: 0.0004
                       Mean reward: 28.96
               Mean episode length: 416.61
       Episode_Reward/keep_balance: 0.4442
     Episode_Reward/rew_lin_vel_xy: 1.2688
      Episode_Reward/rew_ang_vel_z: 1.3541
    Episode_Reward/pen_base_height: -0.2512
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.0646
   Episode_Reward/pen_joint_torque: -0.0784
    Episode_Reward/pen_joint_accel: -0.0397
    Episode_Reward/pen_action_rate: -0.0964
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0155
   Episode_Reward/pen_joint_powers: -0.0270
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.2116
Episode_Reward/pen_flat_orientation: -0.1179
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1111
   Episode_Reward/foot_landing_vel: -0.0547
   Episode_Reward/test_gait_reward: -0.4224
Metrics/base_velocity/error_vel_xy: 1.3575
Metrics/base_velocity/error_vel_yaw: 0.3949
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 1.09s
                        Total time: 821.07s
                               ETA: 2433.9s

################################################################################
                     [1m Learning iteration 757/3000 [0m                      

                       Computation: 90561 steps/s (collection: 0.960s, learning 0.126s)
               Value function loss: 1.0554
                    Surrogate loss: 0.0003
             Mean action noise std: 0.5135
                     Learning rate: 0.0003
                       Mean reward: 35.32
               Mean episode length: 485.47
       Episode_Reward/keep_balance: 0.4469
     Episode_Reward/rew_lin_vel_xy: 1.3931
      Episode_Reward/rew_ang_vel_z: 1.3577
    Episode_Reward/pen_base_height: -0.2538
      Episode_Reward/pen_lin_vel_z: -0.0452
     Episode_Reward/pen_ang_vel_xy: -0.0657
   Episode_Reward/pen_joint_torque: -0.0803
    Episode_Reward/pen_joint_accel: -0.0396
    Episode_Reward/pen_action_rate: -0.0974
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0157
   Episode_Reward/pen_joint_powers: -0.0277
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.2123
Episode_Reward/pen_flat_orientation: -0.1203
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1100
   Episode_Reward/foot_landing_vel: -0.0558
   Episode_Reward/test_gait_reward: -0.4233
Metrics/base_velocity/error_vel_xy: 1.2463
Metrics/base_velocity/error_vel_yaw: 0.4010
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 1.09s
                        Total time: 822.16s
                               ETA: 2432.9s

################################################################################
                     [1m Learning iteration 758/3000 [0m                      

                       Computation: 90498 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.8768
                    Surrogate loss: 0.0003
             Mean action noise std: 0.5137
                     Learning rate: 0.0003
                       Mean reward: 30.48
               Mean episode length: 425.50
       Episode_Reward/keep_balance: 0.4212
     Episode_Reward/rew_lin_vel_xy: 1.2335
      Episode_Reward/rew_ang_vel_z: 1.2818
    Episode_Reward/pen_base_height: -0.2439
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.0625
   Episode_Reward/pen_joint_torque: -0.0733
    Episode_Reward/pen_joint_accel: -0.0360
    Episode_Reward/pen_action_rate: -0.0916
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0258
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.2017
Episode_Reward/pen_flat_orientation: -0.1152
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1058
   Episode_Reward/foot_landing_vel: -0.0536
   Episode_Reward/test_gait_reward: -0.4004
Metrics/base_velocity/error_vel_xy: 1.2493
Metrics/base_velocity/error_vel_yaw: 0.3753
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 1.09s
                        Total time: 823.25s
                               ETA: 2431.8s

################################################################################
                     [1m Learning iteration 759/3000 [0m                      

                       Computation: 90319 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.9424
                    Surrogate loss: -0.0034
             Mean action noise std: 0.5133
                     Learning rate: 0.0006
                       Mean reward: 36.79
               Mean episode length: 498.76
       Episode_Reward/keep_balance: 0.4679
     Episode_Reward/rew_lin_vel_xy: 1.3516
      Episode_Reward/rew_ang_vel_z: 1.4438
    Episode_Reward/pen_base_height: -0.2597
      Episode_Reward/pen_lin_vel_z: -0.0475
     Episode_Reward/pen_ang_vel_xy: -0.0671
   Episode_Reward/pen_joint_torque: -0.0816
    Episode_Reward/pen_joint_accel: -0.0396
    Episode_Reward/pen_action_rate: -0.1018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0160
   Episode_Reward/pen_joint_powers: -0.0283
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2230
Episode_Reward/pen_flat_orientation: -0.1187
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1111
   Episode_Reward/foot_landing_vel: -0.0597
   Episode_Reward/test_gait_reward: -0.4441
Metrics/base_velocity/error_vel_xy: 1.3771
Metrics/base_velocity/error_vel_yaw: 0.4018
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 1.09s
                        Total time: 824.33s
                               ETA: 2430.7s

################################################################################
                     [1m Learning iteration 760/3000 [0m                      

                       Computation: 91368 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 1.0357
                    Surrogate loss: 0.0026
             Mean action noise std: 0.5132
                     Learning rate: 0.0003
                       Mean reward: 34.33
               Mean episode length: 515.82
       Episode_Reward/keep_balance: 0.4329
     Episode_Reward/rew_lin_vel_xy: 1.2215
      Episode_Reward/rew_ang_vel_z: 1.3131
    Episode_Reward/pen_base_height: -0.2483
      Episode_Reward/pen_lin_vel_z: -0.0440
     Episode_Reward/pen_ang_vel_xy: -0.0645
   Episode_Reward/pen_joint_torque: -0.0761
    Episode_Reward/pen_joint_accel: -0.0384
    Episode_Reward/pen_action_rate: -0.0954
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0157
   Episode_Reward/pen_joint_powers: -0.0271
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2102
Episode_Reward/pen_flat_orientation: -0.1153
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1122
   Episode_Reward/foot_landing_vel: -0.0559
   Episode_Reward/test_gait_reward: -0.4146
Metrics/base_velocity/error_vel_xy: 1.3012
Metrics/base_velocity/error_vel_yaw: 0.3895
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 1.08s
                        Total time: 825.41s
                               ETA: 2429.6s

################################################################################
                     [1m Learning iteration 761/3000 [0m                      

                       Computation: 89772 steps/s (collection: 0.968s, learning 0.127s)
               Value function loss: 1.1801
                    Surrogate loss: -0.0002
             Mean action noise std: 0.5131
                     Learning rate: 0.0004
                       Mean reward: 32.14
               Mean episode length: 443.20
       Episode_Reward/keep_balance: 0.4191
     Episode_Reward/rew_lin_vel_xy: 1.2506
      Episode_Reward/rew_ang_vel_z: 1.2662
    Episode_Reward/pen_base_height: -0.2417
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.0622
   Episode_Reward/pen_joint_torque: -0.0743
    Episode_Reward/pen_joint_accel: -0.0381
    Episode_Reward/pen_action_rate: -0.0923
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0156
   Episode_Reward/pen_joint_powers: -0.0263
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2040
Episode_Reward/pen_flat_orientation: -0.1149
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1091
   Episode_Reward/foot_landing_vel: -0.0578
   Episode_Reward/test_gait_reward: -0.4012
Metrics/base_velocity/error_vel_xy: 1.1892
Metrics/base_velocity/error_vel_yaw: 0.3816
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 1.10s
                        Total time: 826.51s
                               ETA: 2428.5s

################################################################################
                     [1m Learning iteration 762/3000 [0m                      

                       Computation: 90618 steps/s (collection: 0.960s, learning 0.125s)
               Value function loss: 1.0547
                    Surrogate loss: 0.0067
             Mean action noise std: 0.5129
                     Learning rate: 0.0001
                       Mean reward: 31.66
               Mean episode length: 468.21
       Episode_Reward/keep_balance: 0.4687
     Episode_Reward/rew_lin_vel_xy: 1.3709
      Episode_Reward/rew_ang_vel_z: 1.4303
    Episode_Reward/pen_base_height: -0.2579
      Episode_Reward/pen_lin_vel_z: -0.0495
     Episode_Reward/pen_ang_vel_xy: -0.0676
   Episode_Reward/pen_joint_torque: -0.0860
    Episode_Reward/pen_joint_accel: -0.0456
    Episode_Reward/pen_action_rate: -0.1047
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0172
   Episode_Reward/pen_joint_powers: -0.0298
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2268
Episode_Reward/pen_flat_orientation: -0.1210
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1241
   Episode_Reward/foot_landing_vel: -0.0600
   Episode_Reward/test_gait_reward: -0.4473
Metrics/base_velocity/error_vel_xy: 1.4053
Metrics/base_velocity/error_vel_yaw: 0.4141
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 1.08s
                        Total time: 827.59s
                               ETA: 2427.5s

################################################################################
                     [1m Learning iteration 763/3000 [0m                      

                       Computation: 91157 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.9503
                    Surrogate loss: -0.0000
             Mean action noise std: 0.5129
                     Learning rate: 0.0002
                       Mean reward: 33.39
               Mean episode length: 434.46
       Episode_Reward/keep_balance: 0.4748
     Episode_Reward/rew_lin_vel_xy: 1.3435
      Episode_Reward/rew_ang_vel_z: 1.4447
    Episode_Reward/pen_base_height: -0.2538
      Episode_Reward/pen_lin_vel_z: -0.0469
     Episode_Reward/pen_ang_vel_xy: -0.0672
   Episode_Reward/pen_joint_torque: -0.0828
    Episode_Reward/pen_joint_accel: -0.0420
    Episode_Reward/pen_action_rate: -0.1050
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0166
   Episode_Reward/pen_joint_powers: -0.0289
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.2317
Episode_Reward/pen_flat_orientation: -0.1138
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1152
   Episode_Reward/foot_landing_vel: -0.0590
   Episode_Reward/test_gait_reward: -0.4508
Metrics/base_velocity/error_vel_xy: 1.4271
Metrics/base_velocity/error_vel_yaw: 0.4228
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 1.08s
                        Total time: 828.67s
                               ETA: 2426.4s

################################################################################
                     [1m Learning iteration 764/3000 [0m                      

                       Computation: 90662 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 1.0315
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5129
                     Learning rate: 0.0004
                       Mean reward: 25.20
               Mean episode length: 374.83
       Episode_Reward/keep_balance: 0.4261
     Episode_Reward/rew_lin_vel_xy: 1.2150
      Episode_Reward/rew_ang_vel_z: 1.3071
    Episode_Reward/pen_base_height: -0.2410
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.0630
   Episode_Reward/pen_joint_torque: -0.0746
    Episode_Reward/pen_joint_accel: -0.0356
    Episode_Reward/pen_action_rate: -0.0924
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0259
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2055
Episode_Reward/pen_flat_orientation: -0.1124
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1037
   Episode_Reward/foot_landing_vel: -0.0518
   Episode_Reward/test_gait_reward: -0.4037
Metrics/base_velocity/error_vel_xy: 1.2981
Metrics/base_velocity/error_vel_yaw: 0.3724
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 1.08s
                        Total time: 829.75s
                               ETA: 2425.3s

################################################################################
                     [1m Learning iteration 765/3000 [0m                      

                       Computation: 88769 steps/s (collection: 0.980s, learning 0.127s)
               Value function loss: 1.0769
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5122
                     Learning rate: 0.0006
                       Mean reward: 29.10
               Mean episode length: 408.24
       Episode_Reward/keep_balance: 0.4472
     Episode_Reward/rew_lin_vel_xy: 1.2945
      Episode_Reward/rew_ang_vel_z: 1.3612
    Episode_Reward/pen_base_height: -0.2480
      Episode_Reward/pen_lin_vel_z: -0.0438
     Episode_Reward/pen_ang_vel_xy: -0.0647
   Episode_Reward/pen_joint_torque: -0.0795
    Episode_Reward/pen_joint_accel: -0.0419
    Episode_Reward/pen_action_rate: -0.0986
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0276
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2168
Episode_Reward/pen_flat_orientation: -0.1147
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1117
   Episode_Reward/foot_landing_vel: -0.0565
   Episode_Reward/test_gait_reward: -0.4236
Metrics/base_velocity/error_vel_xy: 1.3318
Metrics/base_velocity/error_vel_yaw: 0.3974
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 1.11s
                        Total time: 830.86s
                               ETA: 2424.2s

################################################################################
                     [1m Learning iteration 766/3000 [0m                      

                       Computation: 91124 steps/s (collection: 0.954s, learning 0.125s)
               Value function loss: 1.0465
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5123
                     Learning rate: 0.0009
                       Mean reward: 29.09
               Mean episode length: 441.13
       Episode_Reward/keep_balance: 0.4520
     Episode_Reward/rew_lin_vel_xy: 1.2775
      Episode_Reward/rew_ang_vel_z: 1.3824
    Episode_Reward/pen_base_height: -0.2460
      Episode_Reward/pen_lin_vel_z: -0.0449
     Episode_Reward/pen_ang_vel_xy: -0.0658
   Episode_Reward/pen_joint_torque: -0.0799
    Episode_Reward/pen_joint_accel: -0.0398
    Episode_Reward/pen_action_rate: -0.0990
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0157
   Episode_Reward/pen_joint_powers: -0.0277
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2181
Episode_Reward/pen_flat_orientation: -0.1156
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1109
   Episode_Reward/foot_landing_vel: -0.0539
   Episode_Reward/test_gait_reward: -0.4305
Metrics/base_velocity/error_vel_xy: 1.3227
Metrics/base_velocity/error_vel_yaw: 0.3990
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 1.08s
                        Total time: 831.94s
                               ETA: 2423.1s

################################################################################
                     [1m Learning iteration 767/3000 [0m                      

                       Computation: 89731 steps/s (collection: 0.968s, learning 0.127s)
               Value function loss: 1.2706
                    Surrogate loss: 0.0022
             Mean action noise std: 0.5123
                     Learning rate: 0.0004
                       Mean reward: 28.02
               Mean episode length: 385.42
       Episode_Reward/keep_balance: 0.4075
     Episode_Reward/rew_lin_vel_xy: 1.2262
      Episode_Reward/rew_ang_vel_z: 1.2407
    Episode_Reward/pen_base_height: -0.2325
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.0608
   Episode_Reward/pen_joint_torque: -0.0700
    Episode_Reward/pen_joint_accel: -0.0349
    Episode_Reward/pen_action_rate: -0.0887
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0247
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.1974
Episode_Reward/pen_flat_orientation: -0.1083
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1020
   Episode_Reward/foot_landing_vel: -0.0494
   Episode_Reward/test_gait_reward: -0.3889
Metrics/base_velocity/error_vel_xy: 1.1867
Metrics/base_velocity/error_vel_yaw: 0.3633
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 1.10s
                        Total time: 833.03s
                               ETA: 2422.1s

################################################################################
                     [1m Learning iteration 768/3000 [0m                      

                       Computation: 88035 steps/s (collection: 0.986s, learning 0.131s)
               Value function loss: 1.0861
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5122
                     Learning rate: 0.0004
                       Mean reward: 31.01
               Mean episode length: 455.49
       Episode_Reward/keep_balance: 0.4503
     Episode_Reward/rew_lin_vel_xy: 1.3035
      Episode_Reward/rew_ang_vel_z: 1.3727
    Episode_Reward/pen_base_height: -0.2410
      Episode_Reward/pen_lin_vel_z: -0.0440
     Episode_Reward/pen_ang_vel_xy: -0.0642
   Episode_Reward/pen_joint_torque: -0.0786
    Episode_Reward/pen_joint_accel: -0.0404
    Episode_Reward/pen_action_rate: -0.0998
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0157
   Episode_Reward/pen_joint_powers: -0.0274
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2195
Episode_Reward/pen_flat_orientation: -0.1103
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.1106
   Episode_Reward/foot_landing_vel: -0.0559
   Episode_Reward/test_gait_reward: -0.4295
Metrics/base_velocity/error_vel_xy: 1.3357
Metrics/base_velocity/error_vel_yaw: 0.4000
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 7.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 1.12s
                        Total time: 834.15s
                               ETA: 2421.1s

################################################################################
                     [1m Learning iteration 769/3000 [0m                      

                       Computation: 88833 steps/s (collection: 0.979s, learning 0.127s)
               Value function loss: 1.0835
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5116
                     Learning rate: 0.0006
                       Mean reward: 31.96
               Mean episode length: 425.44
       Episode_Reward/keep_balance: 0.3981
     Episode_Reward/rew_lin_vel_xy: 1.2280
      Episode_Reward/rew_ang_vel_z: 1.2150
    Episode_Reward/pen_base_height: -0.2359
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.0590
   Episode_Reward/pen_joint_torque: -0.0723
    Episode_Reward/pen_joint_accel: -0.0379
    Episode_Reward/pen_action_rate: -0.0889
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0254
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.1940
Episode_Reward/pen_flat_orientation: -0.1066
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1050
   Episode_Reward/foot_landing_vel: -0.0539
   Episode_Reward/test_gait_reward: -0.3799
Metrics/base_velocity/error_vel_xy: 1.1188
Metrics/base_velocity/error_vel_yaw: 0.3530
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 1.11s
                        Total time: 835.26s
                               ETA: 2420.1s

################################################################################
                     [1m Learning iteration 770/3000 [0m                      

                       Computation: 91003 steps/s (collection: 0.955s, learning 0.125s)
               Value function loss: 1.0590
                    Surrogate loss: 0.0002
             Mean action noise std: 0.5120
                     Learning rate: 0.0003
                       Mean reward: 32.83
               Mean episode length: 466.74
       Episode_Reward/keep_balance: 0.4525
     Episode_Reward/rew_lin_vel_xy: 1.2811
      Episode_Reward/rew_ang_vel_z: 1.3807
    Episode_Reward/pen_base_height: -0.2436
      Episode_Reward/pen_lin_vel_z: -0.0438
     Episode_Reward/pen_ang_vel_xy: -0.0652
   Episode_Reward/pen_joint_torque: -0.0775
    Episode_Reward/pen_joint_accel: -0.0392
    Episode_Reward/pen_action_rate: -0.0994
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0156
   Episode_Reward/pen_joint_powers: -0.0272
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2217
Episode_Reward/pen_flat_orientation: -0.1091
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1068
   Episode_Reward/foot_landing_vel: -0.0557
   Episode_Reward/test_gait_reward: -0.4295
Metrics/base_velocity/error_vel_xy: 1.4100
Metrics/base_velocity/error_vel_yaw: 0.4008
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 1.08s
                        Total time: 836.34s
                               ETA: 2419.0s

################################################################################
                     [1m Learning iteration 771/3000 [0m                      

                       Computation: 90443 steps/s (collection: 0.960s, learning 0.127s)
               Value function loss: 0.9377
                    Surrogate loss: 0.0013
             Mean action noise std: 0.5125
                     Learning rate: 0.0001
                       Mean reward: 31.54
               Mean episode length: 470.22
       Episode_Reward/keep_balance: 0.4570
     Episode_Reward/rew_lin_vel_xy: 1.3437
      Episode_Reward/rew_ang_vel_z: 1.3951
    Episode_Reward/pen_base_height: -0.2437
      Episode_Reward/pen_lin_vel_z: -0.0447
     Episode_Reward/pen_ang_vel_xy: -0.0640
   Episode_Reward/pen_joint_torque: -0.0809
    Episode_Reward/pen_joint_accel: -0.0400
    Episode_Reward/pen_action_rate: -0.1013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0280
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2230
Episode_Reward/pen_flat_orientation: -0.1113
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1119
   Episode_Reward/foot_landing_vel: -0.0560
   Episode_Reward/test_gait_reward: -0.4357
Metrics/base_velocity/error_vel_xy: 1.3455
Metrics/base_velocity/error_vel_yaw: 0.4038
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 1.09s
                        Total time: 837.43s
                               ETA: 2417.9s

################################################################################
                     [1m Learning iteration 772/3000 [0m                      

                       Computation: 90790 steps/s (collection: 0.957s, learning 0.126s)
               Value function loss: 0.9313
                    Surrogate loss: -0.0033
             Mean action noise std: 0.5128
                     Learning rate: 0.0004
                       Mean reward: 27.27
               Mean episode length: 434.47
       Episode_Reward/keep_balance: 0.4586
     Episode_Reward/rew_lin_vel_xy: 1.2110
      Episode_Reward/rew_ang_vel_z: 1.3878
    Episode_Reward/pen_base_height: -0.2516
      Episode_Reward/pen_lin_vel_z: -0.0461
     Episode_Reward/pen_ang_vel_xy: -0.0658
   Episode_Reward/pen_joint_torque: -0.0817
    Episode_Reward/pen_joint_accel: -0.0419
    Episode_Reward/pen_action_rate: -0.1034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0163
   Episode_Reward/pen_joint_powers: -0.0284
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2262
Episode_Reward/pen_flat_orientation: -0.1125
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1163
   Episode_Reward/foot_landing_vel: -0.0607
   Episode_Reward/test_gait_reward: -0.4371
Metrics/base_velocity/error_vel_xy: 1.4423
Metrics/base_velocity/error_vel_yaw: 0.4184
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 1.08s
                        Total time: 838.51s
                               ETA: 2416.8s

################################################################################
                     [1m Learning iteration 773/3000 [0m                      

                       Computation: 89905 steps/s (collection: 0.967s, learning 0.127s)
               Value function loss: 1.2541
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5144
                     Learning rate: 0.0009
                       Mean reward: 27.60
               Mean episode length: 424.04
       Episode_Reward/keep_balance: 0.4166
     Episode_Reward/rew_lin_vel_xy: 1.1569
      Episode_Reward/rew_ang_vel_z: 1.2735
    Episode_Reward/pen_base_height: -0.2385
      Episode_Reward/pen_lin_vel_z: -0.0419
     Episode_Reward/pen_ang_vel_xy: -0.0612
   Episode_Reward/pen_joint_torque: -0.0733
    Episode_Reward/pen_joint_accel: -0.0381
    Episode_Reward/pen_action_rate: -0.0925
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0150
   Episode_Reward/pen_joint_powers: -0.0257
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2022
Episode_Reward/pen_flat_orientation: -0.1090
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1103
   Episode_Reward/foot_landing_vel: -0.0523
   Episode_Reward/test_gait_reward: -0.3976
Metrics/base_velocity/error_vel_xy: 1.2768
Metrics/base_velocity/error_vel_yaw: 0.3684
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 1.09s
                        Total time: 839.60s
                               ETA: 2415.8s

################################################################################
                     [1m Learning iteration 774/3000 [0m                      

                       Computation: 90831 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 1.1289
                    Surrogate loss: 0.0035
             Mean action noise std: 0.5151
                     Learning rate: 0.0003
                       Mean reward: 34.78
               Mean episode length: 467.32
       Episode_Reward/keep_balance: 0.4902
     Episode_Reward/rew_lin_vel_xy: 1.5445
      Episode_Reward/rew_ang_vel_z: 1.5034
    Episode_Reward/pen_base_height: -0.2598
      Episode_Reward/pen_lin_vel_z: -0.0495
     Episode_Reward/pen_ang_vel_xy: -0.0685
   Episode_Reward/pen_joint_torque: -0.0874
    Episode_Reward/pen_joint_accel: -0.0415
    Episode_Reward/pen_action_rate: -0.1092
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0172
   Episode_Reward/pen_joint_powers: -0.0305
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2397
Episode_Reward/pen_flat_orientation: -0.1125
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.1241
   Episode_Reward/foot_landing_vel: -0.0635
   Episode_Reward/test_gait_reward: -0.4677
Metrics/base_velocity/error_vel_xy: 1.3550
Metrics/base_velocity/error_vel_yaw: 0.4275
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 1.08s
                        Total time: 840.68s
                               ETA: 2414.7s

################################################################################
                     [1m Learning iteration 775/3000 [0m                      

                       Computation: 88974 steps/s (collection: 0.979s, learning 0.126s)
               Value function loss: 1.1028
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5154
                     Learning rate: 0.0004
                       Mean reward: 31.68
               Mean episode length: 479.16
       Episode_Reward/keep_balance: 0.4687
     Episode_Reward/rew_lin_vel_xy: 1.3535
      Episode_Reward/rew_ang_vel_z: 1.4409
    Episode_Reward/pen_base_height: -0.2492
      Episode_Reward/pen_lin_vel_z: -0.0457
     Episode_Reward/pen_ang_vel_xy: -0.0650
   Episode_Reward/pen_joint_torque: -0.0843
    Episode_Reward/pen_joint_accel: -0.0390
    Episode_Reward/pen_action_rate: -0.1043
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0163
   Episode_Reward/pen_joint_powers: -0.0292
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2281
Episode_Reward/pen_flat_orientation: -0.1024
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1166
   Episode_Reward/foot_landing_vel: -0.0597
   Episode_Reward/test_gait_reward: -0.4448
Metrics/base_velocity/error_vel_xy: 1.3804
Metrics/base_velocity/error_vel_yaw: 0.4080
      Episode_Termination/time_out: 2.5833
  Episode_Termination/base_contact: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 1.10s
                        Total time: 841.79s
                               ETA: 2413.6s

################################################################################
                     [1m Learning iteration 776/3000 [0m                      

                       Computation: 91179 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.9690
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5163
                     Learning rate: 0.0006
                       Mean reward: 29.54
               Mean episode length: 435.43
       Episode_Reward/keep_balance: 0.4380
     Episode_Reward/rew_lin_vel_xy: 1.3192
      Episode_Reward/rew_ang_vel_z: 1.3159
    Episode_Reward/pen_base_height: -0.2489
      Episode_Reward/pen_lin_vel_z: -0.0459
     Episode_Reward/pen_ang_vel_xy: -0.0630
   Episode_Reward/pen_joint_torque: -0.0789
    Episode_Reward/pen_joint_accel: -0.0400
    Episode_Reward/pen_action_rate: -0.0986
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0161
   Episode_Reward/pen_joint_powers: -0.0280
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2164
Episode_Reward/pen_flat_orientation: -0.1091
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1166
   Episode_Reward/foot_landing_vel: -0.0599
   Episode_Reward/test_gait_reward: -0.4203
Metrics/base_velocity/error_vel_xy: 1.2503
Metrics/base_velocity/error_vel_yaw: 0.4037
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 1.08s
                        Total time: 842.87s
                               ETA: 2412.5s

################################################################################
                     [1m Learning iteration 777/3000 [0m                      

                       Computation: 91213 steps/s (collection: 0.952s, learning 0.126s)
               Value function loss: 1.1068
                    Surrogate loss: 0.0014
             Mean action noise std: 0.5172
                     Learning rate: 0.0003
                       Mean reward: 29.87
               Mean episode length: 435.91
       Episode_Reward/keep_balance: 0.4386
     Episode_Reward/rew_lin_vel_xy: 1.2983
      Episode_Reward/rew_ang_vel_z: 1.3295
    Episode_Reward/pen_base_height: -0.2531
      Episode_Reward/pen_lin_vel_z: -0.0447
     Episode_Reward/pen_ang_vel_xy: -0.0635
   Episode_Reward/pen_joint_torque: -0.0792
    Episode_Reward/pen_joint_accel: -0.0437
    Episode_Reward/pen_action_rate: -0.0991
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0162
   Episode_Reward/pen_joint_powers: -0.0277
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2180
Episode_Reward/pen_flat_orientation: -0.1116
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1161
   Episode_Reward/foot_landing_vel: -0.0599
   Episode_Reward/test_gait_reward: -0.4178
Metrics/base_velocity/error_vel_xy: 1.3167
Metrics/base_velocity/error_vel_yaw: 0.3955
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 1.08s
                        Total time: 843.94s
                               ETA: 2411.4s

################################################################################
                     [1m Learning iteration 778/3000 [0m                      

                       Computation: 90867 steps/s (collection: 0.955s, learning 0.127s)
               Value function loss: 0.9649
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5172
                     Learning rate: 0.0003
                       Mean reward: 33.76
               Mean episode length: 480.27
       Episode_Reward/keep_balance: 0.4694
     Episode_Reward/rew_lin_vel_xy: 1.4056
      Episode_Reward/rew_ang_vel_z: 1.4338
    Episode_Reward/pen_base_height: -0.2541
      Episode_Reward/pen_lin_vel_z: -0.0479
     Episode_Reward/pen_ang_vel_xy: -0.0652
   Episode_Reward/pen_joint_torque: -0.0871
    Episode_Reward/pen_joint_accel: -0.0396
    Episode_Reward/pen_action_rate: -0.1051
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0168
   Episode_Reward/pen_joint_powers: -0.0299
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2291
Episode_Reward/pen_flat_orientation: -0.1106
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1235
   Episode_Reward/foot_landing_vel: -0.0590
   Episode_Reward/test_gait_reward: -0.4472
Metrics/base_velocity/error_vel_xy: 1.3425
Metrics/base_velocity/error_vel_yaw: 0.4161
      Episode_Termination/time_out: 2.2917
  Episode_Termination/base_contact: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 1.08s
                        Total time: 845.03s
                               ETA: 2410.3s

################################################################################
                     [1m Learning iteration 779/3000 [0m                      

                       Computation: 89993 steps/s (collection: 0.967s, learning 0.126s)
               Value function loss: 0.8874
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5177
                     Learning rate: 0.0001
                       Mean reward: 32.95
               Mean episode length: 488.27
       Episode_Reward/keep_balance: 0.4744
     Episode_Reward/rew_lin_vel_xy: 1.3560
      Episode_Reward/rew_ang_vel_z: 1.4272
    Episode_Reward/pen_base_height: -0.2568
      Episode_Reward/pen_lin_vel_z: -0.0482
     Episode_Reward/pen_ang_vel_xy: -0.0671
   Episode_Reward/pen_joint_torque: -0.0864
    Episode_Reward/pen_joint_accel: -0.0455
    Episode_Reward/pen_action_rate: -0.1083
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0175
   Episode_Reward/pen_joint_powers: -0.0300
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2388
Episode_Reward/pen_flat_orientation: -0.1109
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1281
   Episode_Reward/foot_landing_vel: -0.0630
   Episode_Reward/test_gait_reward: -0.4545
Metrics/base_velocity/error_vel_xy: 1.3931
Metrics/base_velocity/error_vel_yaw: 0.4347
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 1.09s
                        Total time: 846.12s
                               ETA: 2409.3s

################################################################################
                     [1m Learning iteration 780/3000 [0m                      

                       Computation: 89691 steps/s (collection: 0.970s, learning 0.126s)
               Value function loss: 0.9884
                    Surrogate loss: 0.0008
             Mean action noise std: 0.5180
                     Learning rate: 0.0002
                       Mean reward: 36.95
               Mean episode length: 509.68
       Episode_Reward/keep_balance: 0.5499
     Episode_Reward/rew_lin_vel_xy: 1.6614
      Episode_Reward/rew_ang_vel_z: 1.6758
    Episode_Reward/pen_base_height: -0.2781
      Episode_Reward/pen_lin_vel_z: -0.0565
     Episode_Reward/pen_ang_vel_xy: -0.0750
   Episode_Reward/pen_joint_torque: -0.1052
    Episode_Reward/pen_joint_accel: -0.0517
    Episode_Reward/pen_action_rate: -0.1262
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0205
   Episode_Reward/pen_joint_powers: -0.0361
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2731
Episode_Reward/pen_flat_orientation: -0.1178
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1502
   Episode_Reward/foot_landing_vel: -0.0728
   Episode_Reward/test_gait_reward: -0.5238
Metrics/base_velocity/error_vel_xy: 1.5847
Metrics/base_velocity/error_vel_yaw: 0.4888
      Episode_Termination/time_out: 2.7500
  Episode_Termination/base_contact: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 1.10s
                        Total time: 847.21s
                               ETA: 2408.2s

################################################################################
                     [1m Learning iteration 781/3000 [0m                      

                       Computation: 89748 steps/s (collection: 0.970s, learning 0.126s)
               Value function loss: 0.9596
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5183
                     Learning rate: 0.0003
                       Mean reward: 28.40
               Mean episode length: 420.84
       Episode_Reward/keep_balance: 0.4395
     Episode_Reward/rew_lin_vel_xy: 1.2332
      Episode_Reward/rew_ang_vel_z: 1.3197
    Episode_Reward/pen_base_height: -0.2470
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.0629
   Episode_Reward/pen_joint_torque: -0.0789
    Episode_Reward/pen_joint_accel: -0.0388
    Episode_Reward/pen_action_rate: -0.0994
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0156
   Episode_Reward/pen_joint_powers: -0.0274
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2200
Episode_Reward/pen_flat_orientation: -0.1082
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1095
   Episode_Reward/foot_landing_vel: -0.0577
   Episode_Reward/test_gait_reward: -0.4199
Metrics/base_velocity/error_vel_xy: 1.3340
Metrics/base_velocity/error_vel_yaw: 0.4079
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 1.10s
                        Total time: 848.31s
                               ETA: 2407.2s

################################################################################
                     [1m Learning iteration 782/3000 [0m                      

                       Computation: 89269 steps/s (collection: 0.974s, learning 0.127s)
               Value function loss: 0.9817
                    Surrogate loss: -0.0031
             Mean action noise std: 0.5184
                     Learning rate: 0.0004
                       Mean reward: 34.54
               Mean episode length: 517.53
       Episode_Reward/keep_balance: 0.5221
     Episode_Reward/rew_lin_vel_xy: 1.4994
      Episode_Reward/rew_ang_vel_z: 1.5668
    Episode_Reward/pen_base_height: -0.2749
      Episode_Reward/pen_lin_vel_z: -0.0534
     Episode_Reward/pen_ang_vel_xy: -0.0740
   Episode_Reward/pen_joint_torque: -0.0944
    Episode_Reward/pen_joint_accel: -0.0503
    Episode_Reward/pen_action_rate: -0.1209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0194
   Episode_Reward/pen_joint_powers: -0.0332
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2656
Episode_Reward/pen_flat_orientation: -0.1172
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1440
   Episode_Reward/foot_landing_vel: -0.0703
   Episode_Reward/test_gait_reward: -0.4984
Metrics/base_velocity/error_vel_xy: 1.5330
Metrics/base_velocity/error_vel_yaw: 0.4821
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 1.10s
                        Total time: 849.41s
                               ETA: 2406.1s

################################################################################
                     [1m Learning iteration 783/3000 [0m                      

                       Computation: 89958 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 1.0370
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5184
                     Learning rate: 0.0003
                       Mean reward: 33.44
               Mean episode length: 457.42
       Episode_Reward/keep_balance: 0.4549
     Episode_Reward/rew_lin_vel_xy: 1.3691
      Episode_Reward/rew_ang_vel_z: 1.3792
    Episode_Reward/pen_base_height: -0.2517
      Episode_Reward/pen_lin_vel_z: -0.0467
     Episode_Reward/pen_ang_vel_xy: -0.0643
   Episode_Reward/pen_joint_torque: -0.0828
    Episode_Reward/pen_joint_accel: -0.0408
    Episode_Reward/pen_action_rate: -0.1034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0166
   Episode_Reward/pen_joint_powers: -0.0288
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2256
Episode_Reward/pen_flat_orientation: -0.1109
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1195
   Episode_Reward/foot_landing_vel: -0.0609
   Episode_Reward/test_gait_reward: -0.4340
Metrics/base_velocity/error_vel_xy: 1.3246
Metrics/base_velocity/error_vel_yaw: 0.4097
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 1.09s
                        Total time: 850.50s
                               ETA: 2405.1s

################################################################################
                     [1m Learning iteration 784/3000 [0m                      

                       Computation: 90722 steps/s (collection: 0.957s, learning 0.127s)
               Value function loss: 1.0869
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5182
                     Learning rate: 0.0009
                       Mean reward: 34.86
               Mean episode length: 504.90
       Episode_Reward/keep_balance: 0.5142
     Episode_Reward/rew_lin_vel_xy: 1.5022
      Episode_Reward/rew_ang_vel_z: 1.5627
    Episode_Reward/pen_base_height: -0.2683
      Episode_Reward/pen_lin_vel_z: -0.0511
     Episode_Reward/pen_ang_vel_xy: -0.0703
   Episode_Reward/pen_joint_torque: -0.0930
    Episode_Reward/pen_joint_accel: -0.0436
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0182
   Episode_Reward/pen_joint_powers: -0.0322
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2570
Episode_Reward/pen_flat_orientation: -0.1206
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1358
   Episode_Reward/foot_landing_vel: -0.0663
   Episode_Reward/test_gait_reward: -0.4887
Metrics/base_velocity/error_vel_xy: 1.5146
Metrics/base_velocity/error_vel_yaw: 0.4578
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 1.08s
                        Total time: 851.59s
                               ETA: 2404.0s

################################################################################
                     [1m Learning iteration 785/3000 [0m                      

                       Computation: 89544 steps/s (collection: 0.970s, learning 0.128s)
               Value function loss: 1.2357
                    Surrogate loss: 0.0027
             Mean action noise std: 0.5183
                     Learning rate: 0.0002
                       Mean reward: 33.25
               Mean episode length: 468.25
       Episode_Reward/keep_balance: 0.4801
     Episode_Reward/rew_lin_vel_xy: 1.4250
      Episode_Reward/rew_ang_vel_z: 1.4405
    Episode_Reward/pen_base_height: -0.2555
      Episode_Reward/pen_lin_vel_z: -0.0472
     Episode_Reward/pen_ang_vel_xy: -0.0689
   Episode_Reward/pen_joint_torque: -0.0843
    Episode_Reward/pen_joint_accel: -0.0449
    Episode_Reward/pen_action_rate: -0.1100
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0174
   Episode_Reward/pen_joint_powers: -0.0297
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2439
Episode_Reward/pen_flat_orientation: -0.1101
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1241
   Episode_Reward/foot_landing_vel: -0.0626
   Episode_Reward/test_gait_reward: -0.4554
Metrics/base_velocity/error_vel_xy: 1.4525
Metrics/base_velocity/error_vel_yaw: 0.4448
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 1.10s
                        Total time: 852.69s
                               ETA: 2402.9s

################################################################################
                     [1m Learning iteration 786/3000 [0m                      

                       Computation: 89547 steps/s (collection: 0.972s, learning 0.126s)
               Value function loss: 0.9821
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5192
                     Learning rate: 0.0004
                       Mean reward: 33.70
               Mean episode length: 460.54
       Episode_Reward/keep_balance: 0.4910
     Episode_Reward/rew_lin_vel_xy: 1.5110
      Episode_Reward/rew_ang_vel_z: 1.4783
    Episode_Reward/pen_base_height: -0.2627
      Episode_Reward/pen_lin_vel_z: -0.0500
     Episode_Reward/pen_ang_vel_xy: -0.0691
   Episode_Reward/pen_joint_torque: -0.0882
    Episode_Reward/pen_joint_accel: -0.0431
    Episode_Reward/pen_action_rate: -0.1127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0176
   Episode_Reward/pen_joint_powers: -0.0311
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2499
Episode_Reward/pen_flat_orientation: -0.1116
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1255
   Episode_Reward/foot_landing_vel: -0.0642
   Episode_Reward/test_gait_reward: -0.4693
Metrics/base_velocity/error_vel_xy: 1.3838
Metrics/base_velocity/error_vel_yaw: 0.4493
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 1.10s
                        Total time: 853.78s
                               ETA: 2401.9s

################################################################################
                     [1m Learning iteration 787/3000 [0m                      

                       Computation: 90178 steps/s (collection: 0.962s, learning 0.128s)
               Value function loss: 1.0484
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5197
                     Learning rate: 0.0004
                       Mean reward: 35.08
               Mean episode length: 510.57
       Episode_Reward/keep_balance: 0.5179
     Episode_Reward/rew_lin_vel_xy: 1.4288
      Episode_Reward/rew_ang_vel_z: 1.5731
    Episode_Reward/pen_base_height: -0.2724
      Episode_Reward/pen_lin_vel_z: -0.0542
     Episode_Reward/pen_ang_vel_xy: -0.0712
   Episode_Reward/pen_joint_torque: -0.0989
    Episode_Reward/pen_joint_accel: -0.0503
    Episode_Reward/pen_action_rate: -0.1205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0194
   Episode_Reward/pen_joint_powers: -0.0338
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2615
Episode_Reward/pen_flat_orientation: -0.1108
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.1430
   Episode_Reward/foot_landing_vel: -0.0715
   Episode_Reward/test_gait_reward: -0.4909
Metrics/base_velocity/error_vel_xy: 1.6647
Metrics/base_velocity/error_vel_yaw: 0.4646
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 1.09s
                        Total time: 854.87s
                               ETA: 2400.8s

################################################################################
                     [1m Learning iteration 788/3000 [0m                      

                       Computation: 90930 steps/s (collection: 0.956s, learning 0.126s)
               Value function loss: 0.8568
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5196
                     Learning rate: 0.0003
                       Mean reward: 32.76
               Mean episode length: 491.81
       Episode_Reward/keep_balance: 0.4955
     Episode_Reward/rew_lin_vel_xy: 1.3720
      Episode_Reward/rew_ang_vel_z: 1.4906
    Episode_Reward/pen_base_height: -0.2644
      Episode_Reward/pen_lin_vel_z: -0.0500
     Episode_Reward/pen_ang_vel_xy: -0.0702
   Episode_Reward/pen_joint_torque: -0.0915
    Episode_Reward/pen_joint_accel: -0.0449
    Episode_Reward/pen_action_rate: -0.1135
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0180
   Episode_Reward/pen_joint_powers: -0.0317
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2499
Episode_Reward/pen_flat_orientation: -0.1126
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1333
   Episode_Reward/foot_landing_vel: -0.0623
   Episode_Reward/test_gait_reward: -0.4697
Metrics/base_velocity/error_vel_xy: 1.4994
Metrics/base_velocity/error_vel_yaw: 0.4569
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 1.08s
                        Total time: 855.95s
                               ETA: 2399.7s

################################################################################
                     [1m Learning iteration 789/3000 [0m                      

                       Computation: 90682 steps/s (collection: 0.956s, learning 0.128s)
               Value function loss: 0.9988
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5192
                     Learning rate: 0.0004
                       Mean reward: 35.14
               Mean episode length: 527.16
       Episode_Reward/keep_balance: 0.5065
     Episode_Reward/rew_lin_vel_xy: 1.5036
      Episode_Reward/rew_ang_vel_z: 1.5204
    Episode_Reward/pen_base_height: -0.2745
      Episode_Reward/pen_lin_vel_z: -0.0530
     Episode_Reward/pen_ang_vel_xy: -0.0722
   Episode_Reward/pen_joint_torque: -0.0959
    Episode_Reward/pen_joint_accel: -0.0451
    Episode_Reward/pen_action_rate: -0.1177
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0190
   Episode_Reward/pen_joint_powers: -0.0335
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2568
Episode_Reward/pen_flat_orientation: -0.1157
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1406
   Episode_Reward/foot_landing_vel: -0.0681
   Episode_Reward/test_gait_reward: -0.4817
Metrics/base_velocity/error_vel_xy: 1.4918
Metrics/base_velocity/error_vel_yaw: 0.4674
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 1.08s
                        Total time: 857.04s
                               ETA: 2398.6s

################################################################################
                     [1m Learning iteration 790/3000 [0m                      

                       Computation: 91388 steps/s (collection: 0.949s, learning 0.127s)
               Value function loss: 0.9707
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5197
                     Learning rate: 0.0006
                       Mean reward: 42.31
               Mean episode length: 547.51
       Episode_Reward/keep_balance: 0.5335
     Episode_Reward/rew_lin_vel_xy: 1.6781
      Episode_Reward/rew_ang_vel_z: 1.6104
    Episode_Reward/pen_base_height: -0.2769
      Episode_Reward/pen_lin_vel_z: -0.0537
     Episode_Reward/pen_ang_vel_xy: -0.0735
   Episode_Reward/pen_joint_torque: -0.0991
    Episode_Reward/pen_joint_accel: -0.0481
    Episode_Reward/pen_action_rate: -0.1237
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0197
   Episode_Reward/pen_joint_powers: -0.0344
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2708
Episode_Reward/pen_flat_orientation: -0.1149
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1461
   Episode_Reward/foot_landing_vel: -0.0715
   Episode_Reward/test_gait_reward: -0.5062
Metrics/base_velocity/error_vel_xy: 1.5280
Metrics/base_velocity/error_vel_yaw: 0.4852
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 1.08s
                        Total time: 858.11s
                               ETA: 2397.5s

################################################################################
                     [1m Learning iteration 791/3000 [0m                      

                       Computation: 89386 steps/s (collection: 0.974s, learning 0.126s)
               Value function loss: 0.9952
                    Surrogate loss: -0.0031
             Mean action noise std: 0.5200
                     Learning rate: 0.0009
                       Mean reward: 36.76
               Mean episode length: 507.40
       Episode_Reward/keep_balance: 0.5423
     Episode_Reward/rew_lin_vel_xy: 1.6427
      Episode_Reward/rew_ang_vel_z: 1.6491
    Episode_Reward/pen_base_height: -0.2801
      Episode_Reward/pen_lin_vel_z: -0.0549
     Episode_Reward/pen_ang_vel_xy: -0.0732
   Episode_Reward/pen_joint_torque: -0.1015
    Episode_Reward/pen_joint_accel: -0.0502
    Episode_Reward/pen_action_rate: -0.1255
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0193
   Episode_Reward/pen_joint_powers: -0.0344
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2742
Episode_Reward/pen_flat_orientation: -0.1127
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1443
   Episode_Reward/foot_landing_vel: -0.0695
   Episode_Reward/test_gait_reward: -0.5126
Metrics/base_velocity/error_vel_xy: 1.5094
Metrics/base_velocity/error_vel_yaw: 0.4835
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 1.10s
                        Total time: 859.21s
                               ETA: 2396.5s

################################################################################
                     [1m Learning iteration 792/3000 [0m                      

                       Computation: 90347 steps/s (collection: 0.961s, learning 0.127s)
               Value function loss: 1.0197
                    Surrogate loss: 0.0016
             Mean action noise std: 0.5209
                     Learning rate: 0.0003
                       Mean reward: 38.89
               Mean episode length: 541.95
       Episode_Reward/keep_balance: 0.5063
     Episode_Reward/rew_lin_vel_xy: 1.5952
      Episode_Reward/rew_ang_vel_z: 1.5361
    Episode_Reward/pen_base_height: -0.2690
      Episode_Reward/pen_lin_vel_z: -0.0495
     Episode_Reward/pen_ang_vel_xy: -0.0702
   Episode_Reward/pen_joint_torque: -0.0926
    Episode_Reward/pen_joint_accel: -0.0462
    Episode_Reward/pen_action_rate: -0.1164
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0182
   Episode_Reward/pen_joint_powers: -0.0320
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2578
Episode_Reward/pen_flat_orientation: -0.1087
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.1300
   Episode_Reward/foot_landing_vel: -0.0665
   Episode_Reward/test_gait_reward: -0.4821
Metrics/base_velocity/error_vel_xy: 1.4322
Metrics/base_velocity/error_vel_yaw: 0.4533
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 1.09s
                        Total time: 860.30s
                               ETA: 2395.4s

################################################################################
                     [1m Learning iteration 793/3000 [0m                      

                       Computation: 90880 steps/s (collection: 0.956s, learning 0.126s)
               Value function loss: 0.9767
                    Surrogate loss: 0.0007
             Mean action noise std: 0.5213
                     Learning rate: 0.0002
                       Mean reward: 33.96
               Mean episode length: 480.05
       Episode_Reward/keep_balance: 0.4827
     Episode_Reward/rew_lin_vel_xy: 1.4167
      Episode_Reward/rew_ang_vel_z: 1.4674
    Episode_Reward/pen_base_height: -0.2633
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.0701
   Episode_Reward/pen_joint_torque: -0.0881
    Episode_Reward/pen_joint_accel: -0.0418
    Episode_Reward/pen_action_rate: -0.1109
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0171
   Episode_Reward/pen_joint_powers: -0.0307
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2417
Episode_Reward/pen_flat_orientation: -0.1081
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1243
   Episode_Reward/foot_landing_vel: -0.0609
   Episode_Reward/test_gait_reward: -0.4580
Metrics/base_velocity/error_vel_xy: 1.4253
Metrics/base_velocity/error_vel_yaw: 0.4333
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 1.08s
                        Total time: 861.38s
                               ETA: 2394.3s

################################################################################
                     [1m Learning iteration 794/3000 [0m                      

                       Computation: 89363 steps/s (collection: 0.969s, learning 0.131s)
               Value function loss: 0.8741
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5217
                     Learning rate: 0.0004
                       Mean reward: 30.80
               Mean episode length: 443.68
       Episode_Reward/keep_balance: 0.4310
     Episode_Reward/rew_lin_vel_xy: 1.2261
      Episode_Reward/rew_ang_vel_z: 1.3003
    Episode_Reward/pen_base_height: -0.2434
      Episode_Reward/pen_lin_vel_z: -0.0430
     Episode_Reward/pen_ang_vel_xy: -0.0617
   Episode_Reward/pen_joint_torque: -0.0780
    Episode_Reward/pen_joint_accel: -0.0397
    Episode_Reward/pen_action_rate: -0.0985
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0155
   Episode_Reward/pen_joint_powers: -0.0271
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2182
Episode_Reward/pen_flat_orientation: -0.1044
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1105
   Episode_Reward/foot_landing_vel: -0.0563
   Episode_Reward/test_gait_reward: -0.4082
Metrics/base_velocity/error_vel_xy: 1.3032
Metrics/base_velocity/error_vel_yaw: 0.3949
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 1.10s
                        Total time: 862.48s
                               ETA: 2393.3s

################################################################################
                     [1m Learning iteration 795/3000 [0m                      

                       Computation: 90654 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.9582
                    Surrogate loss: 0.0000
             Mean action noise std: 0.5222
                     Learning rate: 0.0004
                       Mean reward: 32.48
               Mean episode length: 483.92
       Episode_Reward/keep_balance: 0.5232
     Episode_Reward/rew_lin_vel_xy: 1.5021
      Episode_Reward/rew_ang_vel_z: 1.5764
    Episode_Reward/pen_base_height: -0.2717
      Episode_Reward/pen_lin_vel_z: -0.0527
     Episode_Reward/pen_ang_vel_xy: -0.0713
   Episode_Reward/pen_joint_torque: -0.0978
    Episode_Reward/pen_joint_accel: -0.0458
    Episode_Reward/pen_action_rate: -0.1211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0189
   Episode_Reward/pen_joint_powers: -0.0337
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2669
Episode_Reward/pen_flat_orientation: -0.1118
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1387
   Episode_Reward/foot_landing_vel: -0.0668
   Episode_Reward/test_gait_reward: -0.4977
Metrics/base_velocity/error_vel_xy: 1.5940
Metrics/base_velocity/error_vel_yaw: 0.4806
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 1.08s
                        Total time: 863.57s
                               ETA: 2392.2s

################################################################################
                     [1m Learning iteration 796/3000 [0m                      

                       Computation: 89888 steps/s (collection: 0.968s, learning 0.125s)
               Value function loss: 0.9830
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5223
                     Learning rate: 0.0006
                       Mean reward: 36.71
               Mean episode length: 502.77
       Episode_Reward/keep_balance: 0.5145
     Episode_Reward/rew_lin_vel_xy: 1.5576
      Episode_Reward/rew_ang_vel_z: 1.5568
    Episode_Reward/pen_base_height: -0.2752
      Episode_Reward/pen_lin_vel_z: -0.0528
     Episode_Reward/pen_ang_vel_xy: -0.0716
   Episode_Reward/pen_joint_torque: -0.0944
    Episode_Reward/pen_joint_accel: -0.0487
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0192
   Episode_Reward/pen_joint_powers: -0.0332
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2626
Episode_Reward/pen_flat_orientation: -0.1103
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.1448
   Episode_Reward/foot_landing_vel: -0.0693
   Episode_Reward/test_gait_reward: -0.4892
Metrics/base_velocity/error_vel_xy: 1.4956
Metrics/base_velocity/error_vel_yaw: 0.4666
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 1.09s
                        Total time: 864.66s
                               ETA: 2391.1s

################################################################################
                     [1m Learning iteration 797/3000 [0m                      

                       Computation: 90592 steps/s (collection: 0.959s, learning 0.126s)
               Value function loss: 0.8787
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5221
                     Learning rate: 0.0006
                       Mean reward: 39.69
               Mean episode length: 533.74
       Episode_Reward/keep_balance: 0.5187
     Episode_Reward/rew_lin_vel_xy: 1.5664
      Episode_Reward/rew_ang_vel_z: 1.5710
    Episode_Reward/pen_base_height: -0.2634
      Episode_Reward/pen_lin_vel_z: -0.0511
     Episode_Reward/pen_ang_vel_xy: -0.0711
   Episode_Reward/pen_joint_torque: -0.0934
    Episode_Reward/pen_joint_accel: -0.0466
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0184
   Episode_Reward/pen_joint_powers: -0.0324
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2650
Episode_Reward/pen_flat_orientation: -0.1064
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1351
   Episode_Reward/foot_landing_vel: -0.0642
   Episode_Reward/test_gait_reward: -0.4925
Metrics/base_velocity/error_vel_xy: 1.5446
Metrics/base_velocity/error_vel_yaw: 0.4681
      Episode_Termination/time_out: 2.8750
  Episode_Termination/base_contact: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 1.09s
                        Total time: 865.75s
                               ETA: 2390.0s

################################################################################
                     [1m Learning iteration 798/3000 [0m                      

                       Computation: 90693 steps/s (collection: 0.957s, learning 0.127s)
               Value function loss: 1.0031
                    Surrogate loss: 0.0032
             Mean action noise std: 0.5220
                     Learning rate: 0.0001
                       Mean reward: 40.90
               Mean episode length: 564.48
       Episode_Reward/keep_balance: 0.5515
     Episode_Reward/rew_lin_vel_xy: 1.6056
      Episode_Reward/rew_ang_vel_z: 1.6787
    Episode_Reward/pen_base_height: -0.2748
      Episode_Reward/pen_lin_vel_z: -0.0530
     Episode_Reward/pen_ang_vel_xy: -0.0726
   Episode_Reward/pen_joint_torque: -0.1011
    Episode_Reward/pen_joint_accel: -0.0479
    Episode_Reward/pen_action_rate: -0.1265
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0191
   Episode_Reward/pen_joint_powers: -0.0344
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2786
Episode_Reward/pen_flat_orientation: -0.1066
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1428
   Episode_Reward/foot_landing_vel: -0.0676
   Episode_Reward/test_gait_reward: -0.5174
Metrics/base_velocity/error_vel_xy: 1.6484
Metrics/base_velocity/error_vel_yaw: 0.4899
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 1.08s
                        Total time: 866.83s
                               ETA: 2388.9s

################################################################################
                     [1m Learning iteration 799/3000 [0m                      

                       Computation: 90568 steps/s (collection: 0.958s, learning 0.127s)
               Value function loss: 0.9764
                    Surrogate loss: 0.0126
             Mean action noise std: 0.5220
                     Learning rate: 0.0000
                       Mean reward: 35.20
               Mean episode length: 533.78
       Episode_Reward/keep_balance: 0.5583
     Episode_Reward/rew_lin_vel_xy: 1.5913
      Episode_Reward/rew_ang_vel_z: 1.6696
    Episode_Reward/pen_base_height: -0.2858
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.0769
   Episode_Reward/pen_joint_torque: -0.1032
    Episode_Reward/pen_joint_accel: -0.0536
    Episode_Reward/pen_action_rate: -0.1316
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0206
   Episode_Reward/pen_joint_powers: -0.0361
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2892
Episode_Reward/pen_flat_orientation: -0.1116
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1529
   Episode_Reward/foot_landing_vel: -0.0755
   Episode_Reward/test_gait_reward: -0.5293
Metrics/base_velocity/error_vel_xy: 1.6858
Metrics/base_velocity/error_vel_yaw: 0.5187
      Episode_Termination/time_out: 2.7917
  Episode_Termination/base_contact: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 1.09s
                        Total time: 867.92s
                               ETA: 2387.9s

################################################################################
                     [1m Learning iteration 800/3000 [0m                      

                       Computation: 90466 steps/s (collection: 0.959s, learning 0.128s)
               Value function loss: 1.0465
                    Surrogate loss: 0.0082
             Mean action noise std: 0.5221
                     Learning rate: 0.0000
                       Mean reward: 37.17
               Mean episode length: 501.26
       Episode_Reward/keep_balance: 0.5664
     Episode_Reward/rew_lin_vel_xy: 1.7514
      Episode_Reward/rew_ang_vel_z: 1.7128
    Episode_Reward/pen_base_height: -0.2928
      Episode_Reward/pen_lin_vel_z: -0.0582
     Episode_Reward/pen_ang_vel_xy: -0.0774
   Episode_Reward/pen_joint_torque: -0.1049
    Episode_Reward/pen_joint_accel: -0.0518
    Episode_Reward/pen_action_rate: -0.1333
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0209
   Episode_Reward/pen_joint_powers: -0.0367
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2899
Episode_Reward/pen_flat_orientation: -0.1147
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1564
   Episode_Reward/foot_landing_vel: -0.0775
   Episode_Reward/test_gait_reward: -0.5364
Metrics/base_velocity/error_vel_xy: 1.6048
Metrics/base_velocity/error_vel_yaw: 0.5114
      Episode_Termination/time_out: 2.6667
  Episode_Termination/base_contact: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 1.09s
                        Total time: 869.00s
                               ETA: 2386.8s

################################################################################
                     [1m Learning iteration 801/3000 [0m                      

                       Computation: 90262 steps/s (collection: 0.963s, learning 0.126s)
               Value function loss: 1.0086
                    Surrogate loss: 0.0041
             Mean action noise std: 0.5220
                     Learning rate: 0.0000
                       Mean reward: 35.62
               Mean episode length: 489.29
       Episode_Reward/keep_balance: 0.5109
     Episode_Reward/rew_lin_vel_xy: 1.5854
      Episode_Reward/rew_ang_vel_z: 1.5563
    Episode_Reward/pen_base_height: -0.2721
      Episode_Reward/pen_lin_vel_z: -0.0529
     Episode_Reward/pen_ang_vel_xy: -0.0714
   Episode_Reward/pen_joint_torque: -0.0955
    Episode_Reward/pen_joint_accel: -0.0452
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0185
   Episode_Reward/pen_joint_powers: -0.0333
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2604
Episode_Reward/pen_flat_orientation: -0.1060
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1349
   Episode_Reward/foot_landing_vel: -0.0693
   Episode_Reward/test_gait_reward: -0.4844
Metrics/base_velocity/error_vel_xy: 1.4395
Metrics/base_velocity/error_vel_yaw: 0.4534
      Episode_Termination/time_out: 2.5833
  Episode_Termination/base_contact: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 1.09s
                        Total time: 870.09s
                               ETA: 2385.7s

################################################################################
                     [1m Learning iteration 802/3000 [0m                      

                       Computation: 90866 steps/s (collection: 0.955s, learning 0.127s)
               Value function loss: 0.9097
                    Surrogate loss: 0.0028
             Mean action noise std: 0.5220
                     Learning rate: 0.0000
                       Mean reward: 35.64
               Mean episode length: 514.62
       Episode_Reward/keep_balance: 0.4807
     Episode_Reward/rew_lin_vel_xy: 1.4244
      Episode_Reward/rew_ang_vel_z: 1.4644
    Episode_Reward/pen_base_height: -0.2711
      Episode_Reward/pen_lin_vel_z: -0.0492
     Episode_Reward/pen_ang_vel_xy: -0.0699
   Episode_Reward/pen_joint_torque: -0.0890
    Episode_Reward/pen_joint_accel: -0.0428
    Episode_Reward/pen_action_rate: -0.1116
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0172
   Episode_Reward/pen_joint_powers: -0.0307
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2455
Episode_Reward/pen_flat_orientation: -0.1103
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.1266
   Episode_Reward/foot_landing_vel: -0.0624
   Episode_Reward/test_gait_reward: -0.4547
Metrics/base_velocity/error_vel_xy: 1.4214
Metrics/base_velocity/error_vel_yaw: 0.4300
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 1.08s
                        Total time: 871.17s
                               ETA: 2384.6s

################################################################################
                     [1m Learning iteration 803/3000 [0m                      

                       Computation: 90933 steps/s (collection: 0.955s, learning 0.126s)
               Value function loss: 0.9881
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5223
                     Learning rate: 0.0002
                       Mean reward: 35.56
               Mean episode length: 503.45
       Episode_Reward/keep_balance: 0.4892
     Episode_Reward/rew_lin_vel_xy: 1.5103
      Episode_Reward/rew_ang_vel_z: 1.4622
    Episode_Reward/pen_base_height: -0.2663
      Episode_Reward/pen_lin_vel_z: -0.0508
     Episode_Reward/pen_ang_vel_xy: -0.0710
   Episode_Reward/pen_joint_torque: -0.0892
    Episode_Reward/pen_joint_accel: -0.0448
    Episode_Reward/pen_action_rate: -0.1148
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0179
   Episode_Reward/pen_joint_powers: -0.0313
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2553
Episode_Reward/pen_flat_orientation: -0.1091
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1315
   Episode_Reward/foot_landing_vel: -0.0637
   Episode_Reward/test_gait_reward: -0.4650
Metrics/base_velocity/error_vel_xy: 1.4064
Metrics/base_velocity/error_vel_yaw: 0.4560
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 1.08s
                        Total time: 872.25s
                               ETA: 2383.5s

################################################################################
                     [1m Learning iteration 804/3000 [0m                      

                       Computation: 91192 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.0241
                    Surrogate loss: 0.0011
             Mean action noise std: 0.5222
                     Learning rate: 0.0001
                       Mean reward: 45.32
               Mean episode length: 603.21
       Episode_Reward/keep_balance: 0.5568
     Episode_Reward/rew_lin_vel_xy: 1.7367
      Episode_Reward/rew_ang_vel_z: 1.6869
    Episode_Reward/pen_base_height: -0.2833
      Episode_Reward/pen_lin_vel_z: -0.0540
     Episode_Reward/pen_ang_vel_xy: -0.0744
   Episode_Reward/pen_joint_torque: -0.1027
    Episode_Reward/pen_joint_accel: -0.0476
    Episode_Reward/pen_action_rate: -0.1286
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0195
   Episode_Reward/pen_joint_powers: -0.0353
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2858
Episode_Reward/pen_flat_orientation: -0.1081
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.1454
   Episode_Reward/foot_landing_vel: -0.0707
   Episode_Reward/test_gait_reward: -0.5245
Metrics/base_velocity/error_vel_xy: 1.6217
Metrics/base_velocity/error_vel_yaw: 0.5002
      Episode_Termination/time_out: 3.0000
  Episode_Termination/base_contact: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 1.08s
                        Total time: 873.33s
                               ETA: 2382.4s

################################################################################
                     [1m Learning iteration 805/3000 [0m                      

                       Computation: 90660 steps/s (collection: 0.957s, learning 0.127s)
               Value function loss: 0.9820
                    Surrogate loss: -0.0029
             Mean action noise std: 0.5221
                     Learning rate: 0.0002
                       Mean reward: 40.06
               Mean episode length: 559.46
       Episode_Reward/keep_balance: 0.5548
     Episode_Reward/rew_lin_vel_xy: 1.6658
      Episode_Reward/rew_ang_vel_z: 1.6852
    Episode_Reward/pen_base_height: -0.2846
      Episode_Reward/pen_lin_vel_z: -0.0558
     Episode_Reward/pen_ang_vel_xy: -0.0760
   Episode_Reward/pen_joint_torque: -0.1039
    Episode_Reward/pen_joint_accel: -0.0499
    Episode_Reward/pen_action_rate: -0.1295
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0199
   Episode_Reward/pen_joint_powers: -0.0358
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2860
Episode_Reward/pen_flat_orientation: -0.1089
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1468
   Episode_Reward/foot_landing_vel: -0.0711
   Episode_Reward/test_gait_reward: -0.5248
Metrics/base_velocity/error_vel_xy: 1.6589
Metrics/base_velocity/error_vel_yaw: 0.4957
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 1.08s
                        Total time: 874.42s
                               ETA: 2381.3s

################################################################################
                     [1m Learning iteration 806/3000 [0m                      

                       Computation: 90281 steps/s (collection: 0.963s, learning 0.126s)
               Value function loss: 0.9456
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5214
                     Learning rate: 0.0004
                       Mean reward: 38.89
               Mean episode length: 522.32
       Episode_Reward/keep_balance: 0.5276
     Episode_Reward/rew_lin_vel_xy: 1.6123
      Episode_Reward/rew_ang_vel_z: 1.5986
    Episode_Reward/pen_base_height: -0.2761
      Episode_Reward/pen_lin_vel_z: -0.0546
     Episode_Reward/pen_ang_vel_xy: -0.0741
   Episode_Reward/pen_joint_torque: -0.1010
    Episode_Reward/pen_joint_accel: -0.0449
    Episode_Reward/pen_action_rate: -0.1234
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0190
   Episode_Reward/pen_joint_powers: -0.0345
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2714
Episode_Reward/pen_flat_orientation: -0.1091
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1471
   Episode_Reward/foot_landing_vel: -0.0686
   Episode_Reward/test_gait_reward: -0.4981
Metrics/base_velocity/error_vel_xy: 1.5200
Metrics/base_velocity/error_vel_yaw: 0.4760
      Episode_Termination/time_out: 2.7500
  Episode_Termination/base_contact: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 1.09s
                        Total time: 875.51s
                               ETA: 2380.2s

################################################################################
                     [1m Learning iteration 807/3000 [0m                      

                       Computation: 91926 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.9864
                    Surrogate loss: -0.0016
             Mean action noise std: 0.5206
                     Learning rate: 0.0006
                       Mean reward: 38.38
               Mean episode length: 513.30
       Episode_Reward/keep_balance: 0.5378
     Episode_Reward/rew_lin_vel_xy: 1.7101
      Episode_Reward/rew_ang_vel_z: 1.6229
    Episode_Reward/pen_base_height: -0.2811
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.0754
   Episode_Reward/pen_joint_torque: -0.1015
    Episode_Reward/pen_joint_accel: -0.0489
    Episode_Reward/pen_action_rate: -0.1269
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0195
   Episode_Reward/pen_joint_powers: -0.0351
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2800
Episode_Reward/pen_flat_orientation: -0.1083
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.1482
   Episode_Reward/foot_landing_vel: -0.0688
   Episode_Reward/test_gait_reward: -0.5130
Metrics/base_velocity/error_vel_xy: 1.5221
Metrics/base_velocity/error_vel_yaw: 0.4892
      Episode_Termination/time_out: 2.7083
  Episode_Termination/base_contact: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 1.07s
                        Total time: 876.58s
                               ETA: 2379.1s

################################################################################
                     [1m Learning iteration 808/3000 [0m                      

                       Computation: 90482 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 1.0509
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5206
                     Learning rate: 0.0004
                       Mean reward: 35.71
               Mean episode length: 501.78
       Episode_Reward/keep_balance: 0.5059
     Episode_Reward/rew_lin_vel_xy: 1.5874
      Episode_Reward/rew_ang_vel_z: 1.5338
    Episode_Reward/pen_base_height: -0.2725
      Episode_Reward/pen_lin_vel_z: -0.0541
     Episode_Reward/pen_ang_vel_xy: -0.0728
   Episode_Reward/pen_joint_torque: -0.0947
    Episode_Reward/pen_joint_accel: -0.0451
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0185
   Episode_Reward/pen_joint_powers: -0.0329
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2630
Episode_Reward/pen_flat_orientation: -0.1061
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1413
   Episode_Reward/foot_landing_vel: -0.0675
   Episode_Reward/test_gait_reward: -0.4773
Metrics/base_velocity/error_vel_xy: 1.4215
Metrics/base_velocity/error_vel_yaw: 0.4582
      Episode_Termination/time_out: 2.5833
  Episode_Termination/base_contact: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 1.09s
                        Total time: 877.66s
                               ETA: 2378.0s

################################################################################
                     [1m Learning iteration 809/3000 [0m                      

                       Computation: 92384 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 1.1113
                    Surrogate loss: 0.0041
             Mean action noise std: 0.5209
                     Learning rate: 0.0002
                       Mean reward: 38.67
               Mean episode length: 513.11
       Episode_Reward/keep_balance: 0.4915
     Episode_Reward/rew_lin_vel_xy: 1.4932
      Episode_Reward/rew_ang_vel_z: 1.4989
    Episode_Reward/pen_base_height: -0.2572
      Episode_Reward/pen_lin_vel_z: -0.0477
     Episode_Reward/pen_ang_vel_xy: -0.0699
   Episode_Reward/pen_joint_torque: -0.0885
    Episode_Reward/pen_joint_accel: -0.0416
    Episode_Reward/pen_action_rate: -0.1133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0172
   Episode_Reward/pen_joint_powers: -0.0306
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2532
Episode_Reward/pen_flat_orientation: -0.1050
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1250
   Episode_Reward/foot_landing_vel: -0.0594
   Episode_Reward/test_gait_reward: -0.4636
Metrics/base_velocity/error_vel_xy: 1.3992
Metrics/base_velocity/error_vel_yaw: 0.4364
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 1.06s
                        Total time: 878.73s
                               ETA: 2376.9s

################################################################################
                     [1m Learning iteration 810/3000 [0m                      

                       Computation: 91289 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.9425
                    Surrogate loss: 0.0041
             Mean action noise std: 0.5211
                     Learning rate: 0.0000
                       Mean reward: 37.80
               Mean episode length: 477.86
       Episode_Reward/keep_balance: 0.4558
     Episode_Reward/rew_lin_vel_xy: 1.3991
      Episode_Reward/rew_ang_vel_z: 1.3807
    Episode_Reward/pen_base_height: -0.2532
      Episode_Reward/pen_lin_vel_z: -0.0463
     Episode_Reward/pen_ang_vel_xy: -0.0646
   Episode_Reward/pen_joint_torque: -0.0849
    Episode_Reward/pen_joint_accel: -0.0388
    Episode_Reward/pen_action_rate: -0.1046
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0162
   Episode_Reward/pen_joint_powers: -0.0291
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2330
Episode_Reward/pen_flat_orientation: -0.1042
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1222
   Episode_Reward/foot_landing_vel: -0.0584
   Episode_Reward/test_gait_reward: -0.4316
Metrics/base_velocity/error_vel_xy: 1.3052
Metrics/base_velocity/error_vel_yaw: 0.4125
      Episode_Termination/time_out: 2.2917
  Episode_Termination/base_contact: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 1.08s
                        Total time: 879.80s
                               ETA: 2375.8s

################################################################################
                     [1m Learning iteration 811/3000 [0m                      

                       Computation: 90304 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.9946
                    Surrogate loss: 0.0070
             Mean action noise std: 0.5211
                     Learning rate: 0.0000
                       Mean reward: 42.15
               Mean episode length: 580.68
       Episode_Reward/keep_balance: 0.5670
     Episode_Reward/rew_lin_vel_xy: 1.6920
      Episode_Reward/rew_ang_vel_z: 1.7192
    Episode_Reward/pen_base_height: -0.2822
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.0784
   Episode_Reward/pen_joint_torque: -0.1082
    Episode_Reward/pen_joint_accel: -0.0517
    Episode_Reward/pen_action_rate: -0.1337
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0206
   Episode_Reward/pen_joint_powers: -0.0371
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2956
Episode_Reward/pen_flat_orientation: -0.1099
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1598
   Episode_Reward/foot_landing_vel: -0.0720
   Episode_Reward/test_gait_reward: -0.5355
Metrics/base_velocity/error_vel_xy: 1.7048
Metrics/base_velocity/error_vel_yaw: 0.5109
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 1.09s
                        Total time: 880.89s
                               ETA: 2374.7s

################################################################################
                     [1m Learning iteration 812/3000 [0m                      

                       Computation: 92198 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 1.0058
                    Surrogate loss: 0.0028
             Mean action noise std: 0.5212
                     Learning rate: 0.0000
                       Mean reward: 36.30
               Mean episode length: 500.37
       Episode_Reward/keep_balance: 0.5218
     Episode_Reward/rew_lin_vel_xy: 1.6377
      Episode_Reward/rew_ang_vel_z: 1.5822
    Episode_Reward/pen_base_height: -0.2715
      Episode_Reward/pen_lin_vel_z: -0.0506
     Episode_Reward/pen_ang_vel_xy: -0.0725
   Episode_Reward/pen_joint_torque: -0.0936
    Episode_Reward/pen_joint_accel: -0.0475
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0184
   Episode_Reward/pen_joint_powers: -0.0327
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2702
Episode_Reward/pen_flat_orientation: -0.1065
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1341
   Episode_Reward/foot_landing_vel: -0.0653
   Episode_Reward/test_gait_reward: -0.4938
Metrics/base_velocity/error_vel_xy: 1.4537
Metrics/base_velocity/error_vel_yaw: 0.4678
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 1.07s
                        Total time: 881.96s
                               ETA: 2373.6s

################################################################################
                     [1m Learning iteration 813/3000 [0m                      

                       Computation: 91672 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 1.0352
                    Surrogate loss: 0.0025
             Mean action noise std: 0.5215
                     Learning rate: 0.0001
                       Mean reward: 29.01
               Mean episode length: 417.93
       Episode_Reward/keep_balance: 0.4824
     Episode_Reward/rew_lin_vel_xy: 1.4777
      Episode_Reward/rew_ang_vel_z: 1.4636
    Episode_Reward/pen_base_height: -0.2581
      Episode_Reward/pen_lin_vel_z: -0.0487
     Episode_Reward/pen_ang_vel_xy: -0.0688
   Episode_Reward/pen_joint_torque: -0.0872
    Episode_Reward/pen_joint_accel: -0.0407
    Episode_Reward/pen_action_rate: -0.1120
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0172
   Episode_Reward/pen_joint_powers: -0.0303
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2506
Episode_Reward/pen_flat_orientation: -0.1056
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1306
   Episode_Reward/foot_landing_vel: -0.0632
   Episode_Reward/test_gait_reward: -0.4555
Metrics/base_velocity/error_vel_xy: 1.4022
Metrics/base_velocity/error_vel_yaw: 0.4347
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 1.07s
                        Total time: 883.03s
                               ETA: 2372.5s

################################################################################
                     [1m Learning iteration 814/3000 [0m                      

                       Computation: 91157 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.8992
                    Surrogate loss: 0.0061
             Mean action noise std: 0.5216
                     Learning rate: 0.0000
                       Mean reward: 38.15
               Mean episode length: 506.83
       Episode_Reward/keep_balance: 0.4930
     Episode_Reward/rew_lin_vel_xy: 1.5417
      Episode_Reward/rew_ang_vel_z: 1.4991
    Episode_Reward/pen_base_height: -0.2580
      Episode_Reward/pen_lin_vel_z: -0.0489
     Episode_Reward/pen_ang_vel_xy: -0.0681
   Episode_Reward/pen_joint_torque: -0.0920
    Episode_Reward/pen_joint_accel: -0.0421
    Episode_Reward/pen_action_rate: -0.1138
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0174
   Episode_Reward/pen_joint_powers: -0.0315
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2535
Episode_Reward/pen_flat_orientation: -0.1001
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1299
   Episode_Reward/foot_landing_vel: -0.0619
   Episode_Reward/test_gait_reward: -0.4654
Metrics/base_velocity/error_vel_xy: 1.3915
Metrics/base_velocity/error_vel_yaw: 0.4388
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 1.08s
                        Total time: 884.11s
                               ETA: 2371.4s

################################################################################
                     [1m Learning iteration 815/3000 [0m                      

                       Computation: 90896 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.9546
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5216
                     Learning rate: 0.0001
                       Mean reward: 29.21
               Mean episode length: 405.97
       Episode_Reward/keep_balance: 0.4929
     Episode_Reward/rew_lin_vel_xy: 1.5316
      Episode_Reward/rew_ang_vel_z: 1.4940
    Episode_Reward/pen_base_height: -0.2584
      Episode_Reward/pen_lin_vel_z: -0.0480
     Episode_Reward/pen_ang_vel_xy: -0.0703
   Episode_Reward/pen_joint_torque: -0.0880
    Episode_Reward/pen_joint_accel: -0.0446
    Episode_Reward/pen_action_rate: -0.1147
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0172
   Episode_Reward/pen_joint_powers: -0.0306
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2570
Episode_Reward/pen_flat_orientation: -0.1029
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1302
   Episode_Reward/foot_landing_vel: -0.0591
   Episode_Reward/test_gait_reward: -0.4660
Metrics/base_velocity/error_vel_xy: 1.4382
Metrics/base_velocity/error_vel_yaw: 0.4444
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 1.08s
                        Total time: 885.19s
                               ETA: 2370.3s

################################################################################
                     [1m Learning iteration 816/3000 [0m                      

                       Computation: 88038 steps/s (collection: 0.991s, learning 0.126s)
               Value function loss: 1.0960
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5218
                     Learning rate: 0.0002
                       Mean reward: 31.21
               Mean episode length: 448.76
       Episode_Reward/keep_balance: 0.4554
     Episode_Reward/rew_lin_vel_xy: 1.3171
      Episode_Reward/rew_ang_vel_z: 1.3802
    Episode_Reward/pen_base_height: -0.2508
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.0656
   Episode_Reward/pen_joint_torque: -0.0817
    Episode_Reward/pen_joint_accel: -0.0403
    Episode_Reward/pen_action_rate: -0.1050
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0284
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2361
Episode_Reward/pen_flat_orientation: -0.0998
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1172
   Episode_Reward/foot_landing_vel: -0.0576
   Episode_Reward/test_gait_reward: -0.4288
Metrics/base_velocity/error_vel_xy: 1.3670
Metrics/base_velocity/error_vel_yaw: 0.4121
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 1.12s
                        Total time: 886.31s
                               ETA: 2369.3s

################################################################################
                     [1m Learning iteration 817/3000 [0m                      

                       Computation: 91196 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.1531
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5223
                     Learning rate: 0.0006
                       Mean reward: 38.78
               Mean episode length: 507.08
       Episode_Reward/keep_balance: 0.5147
     Episode_Reward/rew_lin_vel_xy: 1.6385
      Episode_Reward/rew_ang_vel_z: 1.5663
    Episode_Reward/pen_base_height: -0.2680
      Episode_Reward/pen_lin_vel_z: -0.0510
     Episode_Reward/pen_ang_vel_xy: -0.0725
   Episode_Reward/pen_joint_torque: -0.0944
    Episode_Reward/pen_joint_accel: -0.0462
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0183
   Episode_Reward/pen_joint_powers: -0.0327
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2679
Episode_Reward/pen_flat_orientation: -0.1014
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1365
   Episode_Reward/foot_landing_vel: -0.0671
   Episode_Reward/test_gait_reward: -0.4868
Metrics/base_velocity/error_vel_xy: 1.4376
Metrics/base_velocity/error_vel_yaw: 0.4562
      Episode_Termination/time_out: 2.8333
  Episode_Termination/base_contact: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 1.08s
                        Total time: 887.38s
                               ETA: 2368.2s

################################################################################
                     [1m Learning iteration 818/3000 [0m                      

                       Computation: 89722 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 1.0455
                    Surrogate loss: -0.0042
             Mean action noise std: 0.5214
                     Learning rate: 0.0013
                       Mean reward: 32.75
               Mean episode length: 475.10
       Episode_Reward/keep_balance: 0.4488
     Episode_Reward/rew_lin_vel_xy: 1.3141
      Episode_Reward/rew_ang_vel_z: 1.3464
    Episode_Reward/pen_base_height: -0.2518
      Episode_Reward/pen_lin_vel_z: -0.0470
     Episode_Reward/pen_ang_vel_xy: -0.0683
   Episode_Reward/pen_joint_torque: -0.0836
    Episode_Reward/pen_joint_accel: -0.0428
    Episode_Reward/pen_action_rate: -0.1046
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0166
   Episode_Reward/pen_joint_powers: -0.0292
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2324
Episode_Reward/pen_flat_orientation: -0.1003
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1257
   Episode_Reward/foot_landing_vel: -0.0578
   Episode_Reward/test_gait_reward: -0.4272
Metrics/base_velocity/error_vel_xy: 1.3380
Metrics/base_velocity/error_vel_yaw: 0.4161
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 1.10s
                        Total time: 888.48s
                               ETA: 2367.1s

################################################################################
                     [1m Learning iteration 819/3000 [0m                      

                       Computation: 91311 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 1.4276
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5215
                     Learning rate: 0.0019
                       Mean reward: 34.89
               Mean episode length: 523.00
       Episode_Reward/keep_balance: 0.4838
     Episode_Reward/rew_lin_vel_xy: 1.3543
      Episode_Reward/rew_ang_vel_z: 1.4654
    Episode_Reward/pen_base_height: -0.2606
      Episode_Reward/pen_lin_vel_z: -0.0486
     Episode_Reward/pen_ang_vel_xy: -0.0719
   Episode_Reward/pen_joint_torque: -0.0900
    Episode_Reward/pen_joint_accel: -0.0451
    Episode_Reward/pen_action_rate: -0.1131
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0181
   Episode_Reward/pen_joint_powers: -0.0315
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2525
Episode_Reward/pen_flat_orientation: -0.1039
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1342
   Episode_Reward/foot_landing_vel: -0.0652
   Episode_Reward/test_gait_reward: -0.4578
Metrics/base_velocity/error_vel_xy: 1.4581
Metrics/base_velocity/error_vel_yaw: 0.4352
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 1.08s
                        Total time: 889.56s
                               ETA: 2366.0s

################################################################################
                     [1m Learning iteration 820/3000 [0m                      

                       Computation: 90222 steps/s (collection: 0.964s, learning 0.125s)
               Value function loss: 1.3748
                    Surrogate loss: 0.0023
             Mean action noise std: 0.5222
                     Learning rate: 0.0006
                       Mean reward: 34.68
               Mean episode length: 508.98
       Episode_Reward/keep_balance: 0.4971
     Episode_Reward/rew_lin_vel_xy: 1.5022
      Episode_Reward/rew_ang_vel_z: 1.5059
    Episode_Reward/pen_base_height: -0.2688
      Episode_Reward/pen_lin_vel_z: -0.0510
     Episode_Reward/pen_ang_vel_xy: -0.0731
   Episode_Reward/pen_joint_torque: -0.0957
    Episode_Reward/pen_joint_accel: -0.0447
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0183
   Episode_Reward/pen_joint_powers: -0.0328
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2572
Episode_Reward/pen_flat_orientation: -0.1045
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1396
   Episode_Reward/foot_landing_vel: -0.0619
   Episode_Reward/test_gait_reward: -0.4720
Metrics/base_velocity/error_vel_xy: 1.4583
Metrics/base_velocity/error_vel_yaw: 0.4486
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 1.09s
                        Total time: 890.65s
                               ETA: 2364.9s

################################################################################
                     [1m Learning iteration 821/3000 [0m                      

                       Computation: 89449 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 1.1498
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5236
                     Learning rate: 0.0013
                       Mean reward: 35.20
               Mean episode length: 493.71
       Episode_Reward/keep_balance: 0.4841
     Episode_Reward/rew_lin_vel_xy: 1.4491
      Episode_Reward/rew_ang_vel_z: 1.4596
    Episode_Reward/pen_base_height: -0.2587
      Episode_Reward/pen_lin_vel_z: -0.0490
     Episode_Reward/pen_ang_vel_xy: -0.0707
   Episode_Reward/pen_joint_torque: -0.0917
    Episode_Reward/pen_joint_accel: -0.0427
    Episode_Reward/pen_action_rate: -0.1136
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0175
   Episode_Reward/pen_joint_powers: -0.0314
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2515
Episode_Reward/pen_flat_orientation: -0.1018
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1347
   Episode_Reward/foot_landing_vel: -0.0614
   Episode_Reward/test_gait_reward: -0.4587
Metrics/base_velocity/error_vel_xy: 1.4126
Metrics/base_velocity/error_vel_yaw: 0.4420
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 1.10s
                        Total time: 891.74s
                               ETA: 2363.9s

################################################################################
                     [1m Learning iteration 822/3000 [0m                      

                       Computation: 91314 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 1.0986
                    Surrogate loss: 0.0026
             Mean action noise std: 0.5242
                     Learning rate: 0.0004
                       Mean reward: 40.09
               Mean episode length: 554.10
       Episode_Reward/keep_balance: 0.5040
     Episode_Reward/rew_lin_vel_xy: 1.4799
      Episode_Reward/rew_ang_vel_z: 1.5424
    Episode_Reward/pen_base_height: -0.2627
      Episode_Reward/pen_lin_vel_z: -0.0481
     Episode_Reward/pen_ang_vel_xy: -0.0687
   Episode_Reward/pen_joint_torque: -0.0934
    Episode_Reward/pen_joint_accel: -0.0422
    Episode_Reward/pen_action_rate: -0.1143
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0168
   Episode_Reward/pen_joint_powers: -0.0312
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2569
Episode_Reward/pen_flat_orientation: -0.1016
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1223
   Episode_Reward/foot_landing_vel: -0.0604
   Episode_Reward/test_gait_reward: -0.4701
Metrics/base_velocity/error_vel_xy: 1.4874
Metrics/base_velocity/error_vel_yaw: 0.4443
      Episode_Termination/time_out: 2.2917
  Episode_Termination/base_contact: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 1.08s
                        Total time: 892.82s
                               ETA: 2362.8s

################################################################################
                     [1m Learning iteration 823/3000 [0m                      

                       Computation: 89707 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 1.0365
                    Surrogate loss: -0.0024
             Mean action noise std: 0.5243
                     Learning rate: 0.0009
                       Mean reward: 33.47
               Mean episode length: 483.25
       Episode_Reward/keep_balance: 0.4480
     Episode_Reward/rew_lin_vel_xy: 1.3499
      Episode_Reward/rew_ang_vel_z: 1.3378
    Episode_Reward/pen_base_height: -0.2521
      Episode_Reward/pen_lin_vel_z: -0.0460
     Episode_Reward/pen_ang_vel_xy: -0.0685
   Episode_Reward/pen_joint_torque: -0.0817
    Episode_Reward/pen_joint_accel: -0.0412
    Episode_Reward/pen_action_rate: -0.1041
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0166
   Episode_Reward/pen_joint_powers: -0.0290
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2333
Episode_Reward/pen_flat_orientation: -0.1019
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1267
   Episode_Reward/foot_landing_vel: -0.0571
   Episode_Reward/test_gait_reward: -0.4256
Metrics/base_velocity/error_vel_xy: 1.3176
Metrics/base_velocity/error_vel_yaw: 0.4191
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 1.10s
                        Total time: 893.92s
                               ETA: 2361.7s

################################################################################
                     [1m Learning iteration 824/3000 [0m                      

                       Computation: 89772 steps/s (collection: 0.969s, learning 0.126s)
               Value function loss: 1.6497
                    Surrogate loss: 0.0028
             Mean action noise std: 0.5246
                     Learning rate: 0.0003
                       Mean reward: 32.22
               Mean episode length: 485.54
       Episode_Reward/keep_balance: 0.5014
     Episode_Reward/rew_lin_vel_xy: 1.5027
      Episode_Reward/rew_ang_vel_z: 1.5006
    Episode_Reward/pen_base_height: -0.2727
      Episode_Reward/pen_lin_vel_z: -0.0505
     Episode_Reward/pen_ang_vel_xy: -0.0737
   Episode_Reward/pen_joint_torque: -0.0912
    Episode_Reward/pen_joint_accel: -0.0456
    Episode_Reward/pen_action_rate: -0.1170
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0180
   Episode_Reward/pen_joint_powers: -0.0317
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2637
Episode_Reward/pen_flat_orientation: -0.1092
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1347
   Episode_Reward/foot_landing_vel: -0.0650
   Episode_Reward/test_gait_reward: -0.4743
Metrics/base_velocity/error_vel_xy: 1.4405
Metrics/base_velocity/error_vel_yaw: 0.4649
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 1.10s
                        Total time: 895.01s
                               ETA: 2360.7s

################################################################################
                     [1m Learning iteration 825/3000 [0m                      

                       Computation: 90833 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 1.1120
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5252
                     Learning rate: 0.0004
                       Mean reward: 34.17
               Mean episode length: 473.74
       Episode_Reward/keep_balance: 0.4917
     Episode_Reward/rew_lin_vel_xy: 1.5068
      Episode_Reward/rew_ang_vel_z: 1.4988
    Episode_Reward/pen_base_height: -0.2630
      Episode_Reward/pen_lin_vel_z: -0.0506
     Episode_Reward/pen_ang_vel_xy: -0.0702
   Episode_Reward/pen_joint_torque: -0.0916
    Episode_Reward/pen_joint_accel: -0.0445
    Episode_Reward/pen_action_rate: -0.1137
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0178
   Episode_Reward/pen_joint_powers: -0.0317
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2523
Episode_Reward/pen_flat_orientation: -0.1016
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1334
   Episode_Reward/foot_landing_vel: -0.0675
   Episode_Reward/test_gait_reward: -0.4646
Metrics/base_velocity/error_vel_xy: 1.4411
Metrics/base_velocity/error_vel_yaw: 0.4352
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 1.08s
                        Total time: 896.09s
                               ETA: 2359.6s

################################################################################
                     [1m Learning iteration 826/3000 [0m                      

                       Computation: 91173 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.9830
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5254
                     Learning rate: 0.0009
                       Mean reward: 30.18
               Mean episode length: 404.94
       Episode_Reward/keep_balance: 0.4183
     Episode_Reward/rew_lin_vel_xy: 1.2530
      Episode_Reward/rew_ang_vel_z: 1.2709
    Episode_Reward/pen_base_height: -0.2399
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.0604
   Episode_Reward/pen_joint_torque: -0.0731
    Episode_Reward/pen_joint_accel: -0.0361
    Episode_Reward/pen_action_rate: -0.0942
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0139
   Episode_Reward/pen_joint_powers: -0.0249
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2149
Episode_Reward/pen_flat_orientation: -0.0973
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.1038
   Episode_Reward/foot_landing_vel: -0.0481
   Episode_Reward/test_gait_reward: -0.3901
Metrics/base_velocity/error_vel_xy: 1.2712
Metrics/base_velocity/error_vel_yaw: 0.3743
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 1.08s
                        Total time: 897.17s
                               ETA: 2358.5s

################################################################################
                     [1m Learning iteration 827/3000 [0m                      

                       Computation: 90153 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 1.0281
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5255
                     Learning rate: 0.0006
                       Mean reward: 35.86
               Mean episode length: 493.57
       Episode_Reward/keep_balance: 0.4665
     Episode_Reward/rew_lin_vel_xy: 1.4795
      Episode_Reward/rew_ang_vel_z: 1.4097
    Episode_Reward/pen_base_height: -0.2545
      Episode_Reward/pen_lin_vel_z: -0.0467
     Episode_Reward/pen_ang_vel_xy: -0.0681
   Episode_Reward/pen_joint_torque: -0.0854
    Episode_Reward/pen_joint_accel: -0.0429
    Episode_Reward/pen_action_rate: -0.1076
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0167
   Episode_Reward/pen_joint_powers: -0.0295
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2415
Episode_Reward/pen_flat_orientation: -0.1007
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.1244
   Episode_Reward/foot_landing_vel: -0.0594
   Episode_Reward/test_gait_reward: -0.4407
Metrics/base_velocity/error_vel_xy: 1.3226
Metrics/base_velocity/error_vel_yaw: 0.4272
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 1.09s
                        Total time: 898.26s
                               ETA: 2357.4s

################################################################################
                     [1m Learning iteration 828/3000 [0m                      

                       Computation: 91001 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.9221
                    Surrogate loss: -0.0024
             Mean action noise std: 0.5260
                     Learning rate: 0.0006
                       Mean reward: 33.38
               Mean episode length: 472.61
       Episode_Reward/keep_balance: 0.4402
     Episode_Reward/rew_lin_vel_xy: 1.3481
      Episode_Reward/rew_ang_vel_z: 1.3224
    Episode_Reward/pen_base_height: -0.2507
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.0660
   Episode_Reward/pen_joint_torque: -0.0807
    Episode_Reward/pen_joint_accel: -0.0400
    Episode_Reward/pen_action_rate: -0.1011
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0161
   Episode_Reward/pen_joint_powers: -0.0283
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2272
Episode_Reward/pen_flat_orientation: -0.1031
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1211
   Episode_Reward/foot_landing_vel: -0.0563
   Episode_Reward/test_gait_reward: -0.4182
Metrics/base_velocity/error_vel_xy: 1.2507
Metrics/base_velocity/error_vel_yaw: 0.4063
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 1.08s
                        Total time: 899.34s
                               ETA: 2356.3s

################################################################################
                     [1m Learning iteration 829/3000 [0m                      

                       Computation: 91477 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 1.0242
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5262
                     Learning rate: 0.0006
                       Mean reward: 34.05
               Mean episode length: 470.20
       Episode_Reward/keep_balance: 0.5066
     Episode_Reward/rew_lin_vel_xy: 1.5968
      Episode_Reward/rew_ang_vel_z: 1.5278
    Episode_Reward/pen_base_height: -0.2681
      Episode_Reward/pen_lin_vel_z: -0.0509
     Episode_Reward/pen_ang_vel_xy: -0.0747
   Episode_Reward/pen_joint_torque: -0.0952
    Episode_Reward/pen_joint_accel: -0.0457
    Episode_Reward/pen_action_rate: -0.1190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0187
   Episode_Reward/pen_joint_powers: -0.0331
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2641
Episode_Reward/pen_flat_orientation: -0.1052
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1440
   Episode_Reward/foot_landing_vel: -0.0652
   Episode_Reward/test_gait_reward: -0.4810
Metrics/base_velocity/error_vel_xy: 1.4629
Metrics/base_velocity/error_vel_yaw: 0.4620
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 1.07s
                        Total time: 900.42s
                               ETA: 2355.2s

################################################################################
                     [1m Learning iteration 830/3000 [0m                      

                       Computation: 90861 steps/s (collection: 0.956s, learning 0.125s)
               Value function loss: 1.0505
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5258
                     Learning rate: 0.0006
                       Mean reward: 39.21
               Mean episode length: 566.60
       Episode_Reward/keep_balance: 0.5661
     Episode_Reward/rew_lin_vel_xy: 1.6770
      Episode_Reward/rew_ang_vel_z: 1.6997
    Episode_Reward/pen_base_height: -0.2815
      Episode_Reward/pen_lin_vel_z: -0.0572
     Episode_Reward/pen_ang_vel_xy: -0.0807
   Episode_Reward/pen_joint_torque: -0.1089
    Episode_Reward/pen_joint_accel: -0.0501
    Episode_Reward/pen_action_rate: -0.1334
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0203
   Episode_Reward/pen_joint_powers: -0.0370
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2957
Episode_Reward/pen_flat_orientation: -0.1077
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1515
   Episode_Reward/foot_landing_vel: -0.0730
   Episode_Reward/test_gait_reward: -0.5338
Metrics/base_velocity/error_vel_xy: 1.6936
Metrics/base_velocity/error_vel_yaw: 0.5189
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 1.08s
                        Total time: 901.50s
                               ETA: 2354.1s

################################################################################
                     [1m Learning iteration 831/3000 [0m                      

                       Computation: 91473 steps/s (collection: 0.950s, learning 0.124s)
               Value function loss: 1.1432
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5259
                     Learning rate: 0.0009
                       Mean reward: 36.63
               Mean episode length: 541.21
       Episode_Reward/keep_balance: 0.4903
     Episode_Reward/rew_lin_vel_xy: 1.4177
      Episode_Reward/rew_ang_vel_z: 1.4705
    Episode_Reward/pen_base_height: -0.2637
      Episode_Reward/pen_lin_vel_z: -0.0501
     Episode_Reward/pen_ang_vel_xy: -0.0733
   Episode_Reward/pen_joint_torque: -0.0947
    Episode_Reward/pen_joint_accel: -0.0444
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0181
   Episode_Reward/pen_joint_powers: -0.0324
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2561
Episode_Reward/pen_flat_orientation: -0.1023
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1379
   Episode_Reward/foot_landing_vel: -0.0632
   Episode_Reward/test_gait_reward: -0.4642
Metrics/base_velocity/error_vel_xy: 1.4603
Metrics/base_velocity/error_vel_yaw: 0.4524
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 1.07s
                        Total time: 902.57s
                               ETA: 2353.0s

################################################################################
                     [1m Learning iteration 832/3000 [0m                      

                       Computation: 90849 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 1.0165
                    Surrogate loss: 0.0001
             Mean action noise std: 0.5265
                     Learning rate: 0.0006
                       Mean reward: 30.46
               Mean episode length: 495.18
       Episode_Reward/keep_balance: 0.5707
     Episode_Reward/rew_lin_vel_xy: 1.6957
      Episode_Reward/rew_ang_vel_z: 1.7060
    Episode_Reward/pen_base_height: -0.2866
      Episode_Reward/pen_lin_vel_z: -0.0585
     Episode_Reward/pen_ang_vel_xy: -0.0812
   Episode_Reward/pen_joint_torque: -0.1097
    Episode_Reward/pen_joint_accel: -0.0530
    Episode_Reward/pen_action_rate: -0.1366
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0210
   Episode_Reward/pen_joint_powers: -0.0376
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.3011
Episode_Reward/pen_flat_orientation: -0.1108
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1651
   Episode_Reward/foot_landing_vel: -0.0789
   Episode_Reward/test_gait_reward: -0.5392
Metrics/base_velocity/error_vel_xy: 1.7542
Metrics/base_velocity/error_vel_yaw: 0.5311
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 1.08s
                        Total time: 903.66s
                               ETA: 2351.9s

################################################################################
                     [1m Learning iteration 833/3000 [0m                      

                       Computation: 90864 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.9781
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5268
                     Learning rate: 0.0006
                       Mean reward: 35.32
               Mean episode length: 462.42
       Episode_Reward/keep_balance: 0.4604
     Episode_Reward/rew_lin_vel_xy: 1.4860
      Episode_Reward/rew_ang_vel_z: 1.4012
    Episode_Reward/pen_base_height: -0.2507
      Episode_Reward/pen_lin_vel_z: -0.0454
     Episode_Reward/pen_ang_vel_xy: -0.0677
   Episode_Reward/pen_joint_torque: -0.0855
    Episode_Reward/pen_joint_accel: -0.0398
    Episode_Reward/pen_action_rate: -0.1056
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0163
   Episode_Reward/pen_joint_powers: -0.0293
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2369
Episode_Reward/pen_flat_orientation: -0.1020
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1231
   Episode_Reward/foot_landing_vel: -0.0580
   Episode_Reward/test_gait_reward: -0.4353
Metrics/base_velocity/error_vel_xy: 1.3054
Metrics/base_velocity/error_vel_yaw: 0.4090
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 1.08s
                        Total time: 904.74s
                               ETA: 2350.8s

################################################################################
                     [1m Learning iteration 834/3000 [0m                      

                       Computation: 91235 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 1.0157
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5264
                     Learning rate: 0.0006
                       Mean reward: 38.73
               Mean episode length: 539.78
       Episode_Reward/keep_balance: 0.5714
     Episode_Reward/rew_lin_vel_xy: 1.7295
      Episode_Reward/rew_ang_vel_z: 1.7287
    Episode_Reward/pen_base_height: -0.2831
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.0803
   Episode_Reward/pen_joint_torque: -0.1073
    Episode_Reward/pen_joint_accel: -0.0525
    Episode_Reward/pen_action_rate: -0.1337
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0202
   Episode_Reward/pen_joint_powers: -0.0367
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2976
Episode_Reward/pen_flat_orientation: -0.1070
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.1558
   Episode_Reward/foot_landing_vel: -0.0735
   Episode_Reward/test_gait_reward: -0.5391
Metrics/base_velocity/error_vel_xy: 1.6567
Metrics/base_velocity/error_vel_yaw: 0.5153
      Episode_Termination/time_out: 2.5833
  Episode_Termination/base_contact: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 1.08s
                        Total time: 905.82s
                               ETA: 2349.7s

################################################################################
                     [1m Learning iteration 835/3000 [0m                      

                       Computation: 91119 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.9639
                    Surrogate loss: 0.0033
             Mean action noise std: 0.5264
                     Learning rate: 0.0001
                       Mean reward: 35.01
               Mean episode length: 483.29
       Episode_Reward/keep_balance: 0.4702
     Episode_Reward/rew_lin_vel_xy: 1.3760
      Episode_Reward/rew_ang_vel_z: 1.4061
    Episode_Reward/pen_base_height: -0.2539
      Episode_Reward/pen_lin_vel_z: -0.0465
     Episode_Reward/pen_ang_vel_xy: -0.0703
   Episode_Reward/pen_joint_torque: -0.0856
    Episode_Reward/pen_joint_accel: -0.0417
    Episode_Reward/pen_action_rate: -0.1089
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0166
   Episode_Reward/pen_joint_powers: -0.0297
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.2448
Episode_Reward/pen_flat_orientation: -0.0972
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1242
   Episode_Reward/foot_landing_vel: -0.0592
   Episode_Reward/test_gait_reward: -0.4441
Metrics/base_velocity/error_vel_xy: 1.4330
Metrics/base_velocity/error_vel_yaw: 0.4360
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 1.08s
                        Total time: 906.89s
                               ETA: 2348.6s

################################################################################
                     [1m Learning iteration 836/3000 [0m                      

                       Computation: 89960 steps/s (collection: 0.966s, learning 0.126s)
               Value function loss: 0.9407
                    Surrogate loss: -0.0034
             Mean action noise std: 0.5267
                     Learning rate: 0.0004
                       Mean reward: 31.40
               Mean episode length: 480.90
       Episode_Reward/keep_balance: 0.5027
     Episode_Reward/rew_lin_vel_xy: 1.4020
      Episode_Reward/rew_ang_vel_z: 1.5110
    Episode_Reward/pen_base_height: -0.2636
      Episode_Reward/pen_lin_vel_z: -0.0497
     Episode_Reward/pen_ang_vel_xy: -0.0739
   Episode_Reward/pen_joint_torque: -0.0927
    Episode_Reward/pen_joint_accel: -0.0458
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0185
   Episode_Reward/pen_joint_powers: -0.0323
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2634
Episode_Reward/pen_flat_orientation: -0.1030
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1393
   Episode_Reward/foot_landing_vel: -0.0657
   Episode_Reward/test_gait_reward: -0.4737
Metrics/base_velocity/error_vel_xy: 1.5916
Metrics/base_velocity/error_vel_yaw: 0.4594
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 1.09s
                        Total time: 907.99s
                               ETA: 2347.5s

################################################################################
                     [1m Learning iteration 837/3000 [0m                      

                       Computation: 90956 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.9202
                    Surrogate loss: -0.0000
             Mean action noise std: 0.5273
                     Learning rate: 0.0004
                       Mean reward: 39.23
               Mean episode length: 507.11
       Episode_Reward/keep_balance: 0.5196
     Episode_Reward/rew_lin_vel_xy: 1.7620
      Episode_Reward/rew_ang_vel_z: 1.5817
    Episode_Reward/pen_base_height: -0.2779
      Episode_Reward/pen_lin_vel_z: -0.0500
     Episode_Reward/pen_ang_vel_xy: -0.0735
   Episode_Reward/pen_joint_torque: -0.0950
    Episode_Reward/pen_joint_accel: -0.0462
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0181
   Episode_Reward/pen_joint_powers: -0.0327
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2681
Episode_Reward/pen_flat_orientation: -0.1080
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.1358
   Episode_Reward/foot_landing_vel: -0.0616
   Episode_Reward/test_gait_reward: -0.4899
Metrics/base_velocity/error_vel_xy: 1.4226
Metrics/base_velocity/error_vel_yaw: 0.4625
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 1.08s
                        Total time: 909.07s
                               ETA: 2346.4s

################################################################################
                     [1m Learning iteration 838/3000 [0m                      

                       Computation: 90399 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.9987
                    Surrogate loss: 0.0025
             Mean action noise std: 0.5279
                     Learning rate: 0.0002
                       Mean reward: 39.12
               Mean episode length: 533.28
       Episode_Reward/keep_balance: 0.5254
     Episode_Reward/rew_lin_vel_xy: 1.5843
      Episode_Reward/rew_ang_vel_z: 1.5691
    Episode_Reward/pen_base_height: -0.2746
      Episode_Reward/pen_lin_vel_z: -0.0529
     Episode_Reward/pen_ang_vel_xy: -0.0760
   Episode_Reward/pen_joint_torque: -0.0980
    Episode_Reward/pen_joint_accel: -0.0477
    Episode_Reward/pen_action_rate: -0.1237
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0194
   Episode_Reward/pen_joint_powers: -0.0338
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2757
Episode_Reward/pen_flat_orientation: -0.1067
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1532
   Episode_Reward/foot_landing_vel: -0.0705
   Episode_Reward/test_gait_reward: -0.4949
Metrics/base_velocity/error_vel_xy: 1.5941
Metrics/base_velocity/error_vel_yaw: 0.4887
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 1.09s
                        Total time: 910.16s
                               ETA: 2345.4s

################################################################################
                     [1m Learning iteration 839/3000 [0m                      

                       Computation: 90584 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 1.0455
                    Surrogate loss: -0.0024
             Mean action noise std: 0.5281
                     Learning rate: 0.0006
                       Mean reward: 42.74
               Mean episode length: 595.67
       Episode_Reward/keep_balance: 0.5309
     Episode_Reward/rew_lin_vel_xy: 1.6306
      Episode_Reward/rew_ang_vel_z: 1.5857
    Episode_Reward/pen_base_height: -0.2758
      Episode_Reward/pen_lin_vel_z: -0.0524
     Episode_Reward/pen_ang_vel_xy: -0.0772
   Episode_Reward/pen_joint_torque: -0.0974
    Episode_Reward/pen_joint_accel: -0.0483
    Episode_Reward/pen_action_rate: -0.1257
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0192
   Episode_Reward/pen_joint_powers: -0.0337
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2816
Episode_Reward/pen_flat_orientation: -0.1062
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1470
   Episode_Reward/foot_landing_vel: -0.0703
   Episode_Reward/test_gait_reward: -0.4992
Metrics/base_velocity/error_vel_xy: 1.6013
Metrics/base_velocity/error_vel_yaw: 0.4945
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 1.09s
                        Total time: 911.24s
                               ETA: 2344.3s

################################################################################
                     [1m Learning iteration 840/3000 [0m                      

                       Computation: 90764 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 1.1425
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5282
                     Learning rate: 0.0006
                       Mean reward: 36.96
               Mean episode length: 536.33
       Episode_Reward/keep_balance: 0.5240
     Episode_Reward/rew_lin_vel_xy: 1.5426
      Episode_Reward/rew_ang_vel_z: 1.5636
    Episode_Reward/pen_base_height: -0.2750
      Episode_Reward/pen_lin_vel_z: -0.0512
     Episode_Reward/pen_ang_vel_xy: -0.0764
   Episode_Reward/pen_joint_torque: -0.0983
    Episode_Reward/pen_joint_accel: -0.0477
    Episode_Reward/pen_action_rate: -0.1231
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0195
   Episode_Reward/pen_joint_powers: -0.0339
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2747
Episode_Reward/pen_flat_orientation: -0.1049
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1465
   Episode_Reward/foot_landing_vel: -0.0714
   Episode_Reward/test_gait_reward: -0.4961
Metrics/base_velocity/error_vel_xy: 1.5561
Metrics/base_velocity/error_vel_yaw: 0.4889
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 1.08s
                        Total time: 912.32s
                               ETA: 2343.2s

################################################################################
                     [1m Learning iteration 841/3000 [0m                      

                       Computation: 91123 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 1.2214
                    Surrogate loss: 0.0113
             Mean action noise std: 0.5283
                     Learning rate: 0.0000
                       Mean reward: 43.78
               Mean episode length: 604.28
       Episode_Reward/keep_balance: 0.5410
     Episode_Reward/rew_lin_vel_xy: 1.6498
      Episode_Reward/rew_ang_vel_z: 1.6259
    Episode_Reward/pen_base_height: -0.2806
      Episode_Reward/pen_lin_vel_z: -0.0550
     Episode_Reward/pen_ang_vel_xy: -0.0784
   Episode_Reward/pen_joint_torque: -0.1016
    Episode_Reward/pen_joint_accel: -0.0523
    Episode_Reward/pen_action_rate: -0.1269
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0200
   Episode_Reward/pen_joint_powers: -0.0352
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2832
Episode_Reward/pen_flat_orientation: -0.1034
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1519
   Episode_Reward/foot_landing_vel: -0.0713
   Episode_Reward/test_gait_reward: -0.5122
Metrics/base_velocity/error_vel_xy: 1.6150
Metrics/base_velocity/error_vel_yaw: 0.4960
      Episode_Termination/time_out: 2.9167
  Episode_Termination/base_contact: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 1.08s
                        Total time: 913.40s
                               ETA: 2342.1s

################################################################################
                     [1m Learning iteration 842/3000 [0m                      

                       Computation: 91164 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.1845
                    Surrogate loss: 0.0065
             Mean action noise std: 0.5283
                     Learning rate: 0.0000
                       Mean reward: 32.98
               Mean episode length: 478.93
       Episode_Reward/keep_balance: 0.5112
     Episode_Reward/rew_lin_vel_xy: 1.5035
      Episode_Reward/rew_ang_vel_z: 1.5412
    Episode_Reward/pen_base_height: -0.2710
      Episode_Reward/pen_lin_vel_z: -0.0524
     Episode_Reward/pen_ang_vel_xy: -0.0742
   Episode_Reward/pen_joint_torque: -0.0951
    Episode_Reward/pen_joint_accel: -0.0453
    Episode_Reward/pen_action_rate: -0.1195
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0183
   Episode_Reward/pen_joint_powers: -0.0328
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2651
Episode_Reward/pen_flat_orientation: -0.1015
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1379
   Episode_Reward/foot_landing_vel: -0.0684
   Episode_Reward/test_gait_reward: -0.4830
Metrics/base_velocity/error_vel_xy: 1.5523
Metrics/base_velocity/error_vel_yaw: 0.4646
      Episode_Termination/time_out: 2.7083
  Episode_Termination/base_contact: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 1.08s
                        Total time: 914.48s
                               ETA: 2341.0s

################################################################################
                     [1m Learning iteration 843/3000 [0m                      

                       Computation: 90622 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 1.0702
                    Surrogate loss: 0.0025
             Mean action noise std: 0.5285
                     Learning rate: 0.0001
                       Mean reward: 37.76
               Mean episode length: 508.70
       Episode_Reward/keep_balance: 0.5093
     Episode_Reward/rew_lin_vel_xy: 1.5733
      Episode_Reward/rew_ang_vel_z: 1.5359
    Episode_Reward/pen_base_height: -0.2708
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.0741
   Episode_Reward/pen_joint_torque: -0.0937
    Episode_Reward/pen_joint_accel: -0.0467
    Episode_Reward/pen_action_rate: -0.1179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0184
   Episode_Reward/pen_joint_powers: -0.0324
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2646
Episode_Reward/pen_flat_orientation: -0.1070
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1390
   Episode_Reward/foot_landing_vel: -0.0674
   Episode_Reward/test_gait_reward: -0.4799
Metrics/base_velocity/error_vel_xy: 1.4765
Metrics/base_velocity/error_vel_yaw: 0.4641
      Episode_Termination/time_out: 2.5833
  Episode_Termination/base_contact: 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 1.08s
                        Total time: 915.57s
                               ETA: 2339.9s

################################################################################
                     [1m Learning iteration 844/3000 [0m                      

                       Computation: 91448 steps/s (collection: 0.948s, learning 0.127s)
               Value function loss: 0.9842
                    Surrogate loss: -0.0000
             Mean action noise std: 0.5287
                     Learning rate: 0.0002
                       Mean reward: 40.89
               Mean episode length: 536.46
       Episode_Reward/keep_balance: 0.5212
     Episode_Reward/rew_lin_vel_xy: 1.7565
      Episode_Reward/rew_ang_vel_z: 1.5784
    Episode_Reward/pen_base_height: -0.2818
      Episode_Reward/pen_lin_vel_z: -0.0508
     Episode_Reward/pen_ang_vel_xy: -0.0769
   Episode_Reward/pen_joint_torque: -0.0953
    Episode_Reward/pen_joint_accel: -0.0469
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0188
   Episode_Reward/pen_joint_powers: -0.0332
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2692
Episode_Reward/pen_flat_orientation: -0.1099
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1392
   Episode_Reward/foot_landing_vel: -0.0683
   Episode_Reward/test_gait_reward: -0.4932
Metrics/base_velocity/error_vel_xy: 1.4160
Metrics/base_velocity/error_vel_yaw: 0.4702
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 7.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 1.07s
                        Total time: 916.64s
                               ETA: 2338.8s

################################################################################
                     [1m Learning iteration 845/3000 [0m                      

                       Computation: 89362 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 0.9692
                    Surrogate loss: -0.0008
             Mean action noise std: 0.5289
                     Learning rate: 0.0004
                       Mean reward: 30.36
               Mean episode length: 451.05
       Episode_Reward/keep_balance: 0.4577
     Episode_Reward/rew_lin_vel_xy: 1.3873
      Episode_Reward/rew_ang_vel_z: 1.3746
    Episode_Reward/pen_base_height: -0.2576
      Episode_Reward/pen_lin_vel_z: -0.0454
     Episode_Reward/pen_ang_vel_xy: -0.0694
   Episode_Reward/pen_joint_torque: -0.0857
    Episode_Reward/pen_joint_accel: -0.0427
    Episode_Reward/pen_action_rate: -0.1058
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0169
   Episode_Reward/pen_joint_powers: -0.0295
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2375
Episode_Reward/pen_flat_orientation: -0.1045
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1261
   Episode_Reward/foot_landing_vel: -0.0602
   Episode_Reward/test_gait_reward: -0.4340
Metrics/base_velocity/error_vel_xy: 1.3472
Metrics/base_velocity/error_vel_yaw: 0.4213
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 1.10s
                        Total time: 917.74s
                               ETA: 2337.7s

################################################################################
                     [1m Learning iteration 846/3000 [0m                      

                       Computation: 90307 steps/s (collection: 0.964s, learning 0.125s)
               Value function loss: 1.1649
                    Surrogate loss: -0.0024
             Mean action noise std: 0.5291
                     Learning rate: 0.0009
                       Mean reward: 44.31
               Mean episode length: 607.90
       Episode_Reward/keep_balance: 0.5552
     Episode_Reward/rew_lin_vel_xy: 1.6847
      Episode_Reward/rew_ang_vel_z: 1.6669
    Episode_Reward/pen_base_height: -0.2830
      Episode_Reward/pen_lin_vel_z: -0.0552
     Episode_Reward/pen_ang_vel_xy: -0.0804
   Episode_Reward/pen_joint_torque: -0.1062
    Episode_Reward/pen_joint_accel: -0.0522
    Episode_Reward/pen_action_rate: -0.1301
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0202
   Episode_Reward/pen_joint_powers: -0.0361
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2916
Episode_Reward/pen_flat_orientation: -0.1094
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1529
   Episode_Reward/foot_landing_vel: -0.0722
   Episode_Reward/test_gait_reward: -0.5229
Metrics/base_velocity/error_vel_xy: 1.6684
Metrics/base_velocity/error_vel_yaw: 0.5093
      Episode_Termination/time_out: 2.9583
  Episode_Termination/base_contact: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 1.09s
                        Total time: 918.83s
                               ETA: 2336.7s

################################################################################
                     [1m Learning iteration 847/3000 [0m                      

                       Computation: 89192 steps/s (collection: 0.977s, learning 0.125s)
               Value function loss: 0.9730
                    Surrogate loss: 0.0014
             Mean action noise std: 0.5290
                     Learning rate: 0.0002
                       Mean reward: 32.37
               Mean episode length: 481.44
       Episode_Reward/keep_balance: 0.5366
     Episode_Reward/rew_lin_vel_xy: 1.5464
      Episode_Reward/rew_ang_vel_z: 1.6156
    Episode_Reward/pen_base_height: -0.2786
      Episode_Reward/pen_lin_vel_z: -0.0545
     Episode_Reward/pen_ang_vel_xy: -0.0763
   Episode_Reward/pen_joint_torque: -0.1004
    Episode_Reward/pen_joint_accel: -0.0509
    Episode_Reward/pen_action_rate: -0.1245
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0197
   Episode_Reward/pen_joint_powers: -0.0348
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2791
Episode_Reward/pen_flat_orientation: -0.1090
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1511
   Episode_Reward/foot_landing_vel: -0.0731
   Episode_Reward/test_gait_reward: -0.5061
Metrics/base_velocity/error_vel_xy: 1.7249
Metrics/base_velocity/error_vel_yaw: 0.4918
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 1.10s
                        Total time: 919.93s
                               ETA: 2335.6s

################################################################################
                     [1m Learning iteration 848/3000 [0m                      

                       Computation: 89944 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.9998
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5292
                     Learning rate: 0.0004
                       Mean reward: 35.82
               Mean episode length: 490.63
       Episode_Reward/keep_balance: 0.4714
     Episode_Reward/rew_lin_vel_xy: 1.5020
      Episode_Reward/rew_ang_vel_z: 1.4177
    Episode_Reward/pen_base_height: -0.2566
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.0685
   Episode_Reward/pen_joint_torque: -0.0867
    Episode_Reward/pen_joint_accel: -0.0393
    Episode_Reward/pen_action_rate: -0.1077
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0163
   Episode_Reward/pen_joint_powers: -0.0294
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2444
Episode_Reward/pen_flat_orientation: -0.1013
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1196
   Episode_Reward/foot_landing_vel: -0.0595
   Episode_Reward/test_gait_reward: -0.4428
Metrics/base_velocity/error_vel_xy: 1.3412
Metrics/base_velocity/error_vel_yaw: 0.4328
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 1.09s
                        Total time: 921.02s
                               ETA: 2334.6s

################################################################################
                     [1m Learning iteration 849/3000 [0m                      

                       Computation: 89302 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 1.2915
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5298
                     Learning rate: 0.0009
                       Mean reward: 34.55
               Mean episode length: 528.40
       Episode_Reward/keep_balance: 0.5177
     Episode_Reward/rew_lin_vel_xy: 1.6046
      Episode_Reward/rew_ang_vel_z: 1.5504
    Episode_Reward/pen_base_height: -0.2695
      Episode_Reward/pen_lin_vel_z: -0.0536
     Episode_Reward/pen_ang_vel_xy: -0.0784
   Episode_Reward/pen_joint_torque: -0.0963
    Episode_Reward/pen_joint_accel: -0.0499
    Episode_Reward/pen_action_rate: -0.1219
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0197
   Episode_Reward/pen_joint_powers: -0.0342
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2720
Episode_Reward/pen_flat_orientation: -0.1082
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1508
   Episode_Reward/foot_landing_vel: -0.0696
   Episode_Reward/test_gait_reward: -0.4913
Metrics/base_velocity/error_vel_xy: 1.5066
Metrics/base_velocity/error_vel_yaw: 0.4794
      Episode_Termination/time_out: 2.7917
  Episode_Termination/base_contact: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 1.10s
                        Total time: 922.13s
                               ETA: 2333.5s

################################################################################
                     [1m Learning iteration 850/3000 [0m                      

                       Computation: 89759 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 1.1911
                    Surrogate loss: 0.0009
             Mean action noise std: 0.5303
                     Learning rate: 0.0006
                       Mean reward: 32.83
               Mean episode length: 440.89
       Episode_Reward/keep_balance: 0.5319
     Episode_Reward/rew_lin_vel_xy: 1.6731
      Episode_Reward/rew_ang_vel_z: 1.6158
    Episode_Reward/pen_base_height: -0.2759
      Episode_Reward/pen_lin_vel_z: -0.0524
     Episode_Reward/pen_ang_vel_xy: -0.0759
   Episode_Reward/pen_joint_torque: -0.0977
    Episode_Reward/pen_joint_accel: -0.0471
    Episode_Reward/pen_action_rate: -0.1224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0188
   Episode_Reward/pen_joint_powers: -0.0336
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2749
Episode_Reward/pen_flat_orientation: -0.1067
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1421
   Episode_Reward/foot_landing_vel: -0.0667
   Episode_Reward/test_gait_reward: -0.5003
Metrics/base_velocity/error_vel_xy: 1.4977
Metrics/base_velocity/error_vel_yaw: 0.4766
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 1.10s
                        Total time: 923.22s
                               ETA: 2332.5s

################################################################################
                     [1m Learning iteration 851/3000 [0m                      

                       Computation: 85274 steps/s (collection: 1.025s, learning 0.128s)
               Value function loss: 1.2366
                    Surrogate loss: 0.0032
             Mean action noise std: 0.5305
                     Learning rate: 0.0001
                       Mean reward: 37.02
               Mean episode length: 490.62
       Episode_Reward/keep_balance: 0.4747
     Episode_Reward/rew_lin_vel_xy: 1.4854
      Episode_Reward/rew_ang_vel_z: 1.4355
    Episode_Reward/pen_base_height: -0.2535
      Episode_Reward/pen_lin_vel_z: -0.0449
     Episode_Reward/pen_ang_vel_xy: -0.0699
   Episode_Reward/pen_joint_torque: -0.0814
    Episode_Reward/pen_joint_accel: -0.0399
    Episode_Reward/pen_action_rate: -0.1079
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0162
   Episode_Reward/pen_joint_powers: -0.0286
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2463
Episode_Reward/pen_flat_orientation: -0.1029
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1208
   Episode_Reward/foot_landing_vel: -0.0569
   Episode_Reward/test_gait_reward: -0.4462
Metrics/base_velocity/error_vel_xy: 1.3653
Metrics/base_velocity/error_vel_yaw: 0.4291
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 1.15s
                        Total time: 924.37s
                               ETA: 2331.5s

################################################################################
                     [1m Learning iteration 852/3000 [0m                      

                       Computation: 86946 steps/s (collection: 1.001s, learning 0.129s)
               Value function loss: 1.0881
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5309
                     Learning rate: 0.0003
                       Mean reward: 31.27
               Mean episode length: 475.76
       Episode_Reward/keep_balance: 0.4601
     Episode_Reward/rew_lin_vel_xy: 1.2576
      Episode_Reward/rew_ang_vel_z: 1.3920
    Episode_Reward/pen_base_height: -0.2500
      Episode_Reward/pen_lin_vel_z: -0.0429
     Episode_Reward/pen_ang_vel_xy: -0.0669
   Episode_Reward/pen_joint_torque: -0.0797
    Episode_Reward/pen_joint_accel: -0.0413
    Episode_Reward/pen_action_rate: -0.1034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0155
   Episode_Reward/pen_joint_powers: -0.0274
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2380
Episode_Reward/pen_flat_orientation: -0.0999
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.1127
   Episode_Reward/foot_landing_vel: -0.0545
   Episode_Reward/test_gait_reward: -0.4302
Metrics/base_velocity/error_vel_xy: 1.4363
Metrics/base_velocity/error_vel_yaw: 0.4171
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 1.13s
                        Total time: 925.50s
                               ETA: 2330.6s

################################################################################
                     [1m Learning iteration 853/3000 [0m                      

                       Computation: 88670 steps/s (collection: 0.984s, learning 0.125s)
               Value function loss: 1.0409
                    Surrogate loss: -0.0028
             Mean action noise std: 0.5308
                     Learning rate: 0.0006
                       Mean reward: 40.46
               Mean episode length: 536.51
       Episode_Reward/keep_balance: 0.4931
     Episode_Reward/rew_lin_vel_xy: 1.5526
      Episode_Reward/rew_ang_vel_z: 1.4848
    Episode_Reward/pen_base_height: -0.2629
      Episode_Reward/pen_lin_vel_z: -0.0480
     Episode_Reward/pen_ang_vel_xy: -0.0721
   Episode_Reward/pen_joint_torque: -0.0897
    Episode_Reward/pen_joint_accel: -0.0455
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0175
   Episode_Reward/pen_joint_powers: -0.0310
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2569
Episode_Reward/pen_flat_orientation: -0.1044
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1297
   Episode_Reward/foot_landing_vel: -0.0624
   Episode_Reward/test_gait_reward: -0.4648
Metrics/base_velocity/error_vel_xy: 1.4337
Metrics/base_velocity/error_vel_yaw: 0.4503
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 1.11s
                        Total time: 926.61s
                               ETA: 2329.6s

################################################################################
                     [1m Learning iteration 854/3000 [0m                      

                       Computation: 83390 steps/s (collection: 1.045s, learning 0.134s)
               Value function loss: 1.1050
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5309
                     Learning rate: 0.0002
                       Mean reward: 29.54
               Mean episode length: 425.57
       Episode_Reward/keep_balance: 0.4545
     Episode_Reward/rew_lin_vel_xy: 1.4395
      Episode_Reward/rew_ang_vel_z: 1.3618
    Episode_Reward/pen_base_height: -0.2546
      Episode_Reward/pen_lin_vel_z: -0.0468
     Episode_Reward/pen_ang_vel_xy: -0.0711
   Episode_Reward/pen_joint_torque: -0.0847
    Episode_Reward/pen_joint_accel: -0.0445
    Episode_Reward/pen_action_rate: -0.1054
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0170
   Episode_Reward/pen_joint_powers: -0.0296
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2369
Episode_Reward/pen_flat_orientation: -0.1047
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1284
   Episode_Reward/foot_landing_vel: -0.0603
   Episode_Reward/test_gait_reward: -0.4321
Metrics/base_velocity/error_vel_xy: 1.2921
Metrics/base_velocity/error_vel_yaw: 0.4208
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 1.18s
                        Total time: 927.79s
                               ETA: 2328.7s

################################################################################
                     [1m Learning iteration 855/3000 [0m                      

                       Computation: 81830 steps/s (collection: 1.067s, learning 0.134s)
               Value function loss: 1.0050
                    Surrogate loss: -0.0030
             Mean action noise std: 0.5309
                     Learning rate: 0.0004
                       Mean reward: 32.36
               Mean episode length: 438.63
       Episode_Reward/keep_balance: 0.4345
     Episode_Reward/rew_lin_vel_xy: 1.3821
      Episode_Reward/rew_ang_vel_z: 1.3039
    Episode_Reward/pen_base_height: -0.2464
      Episode_Reward/pen_lin_vel_z: -0.0419
     Episode_Reward/pen_ang_vel_xy: -0.0659
   Episode_Reward/pen_joint_torque: -0.0772
    Episode_Reward/pen_joint_accel: -0.0399
    Episode_Reward/pen_action_rate: -0.0999
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0273
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2260
Episode_Reward/pen_flat_orientation: -0.1012
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1222
   Episode_Reward/foot_landing_vel: -0.0541
   Episode_Reward/test_gait_reward: -0.4107
Metrics/base_velocity/error_vel_xy: 1.2640
Metrics/base_velocity/error_vel_yaw: 0.4016
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 1.20s
                        Total time: 928.99s
                               ETA: 2327.9s

################################################################################
                     [1m Learning iteration 856/3000 [0m                      

                       Computation: 87340 steps/s (collection: 1.001s, learning 0.124s)
               Value function loss: 1.0563
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5312
                     Learning rate: 0.0006
                       Mean reward: 34.19
               Mean episode length: 443.67
       Episode_Reward/keep_balance: 0.4445
     Episode_Reward/rew_lin_vel_xy: 1.3874
      Episode_Reward/rew_ang_vel_z: 1.3351
    Episode_Reward/pen_base_height: -0.2500
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.0670
   Episode_Reward/pen_joint_torque: -0.0834
    Episode_Reward/pen_joint_accel: -0.0394
    Episode_Reward/pen_action_rate: -0.1024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0162
   Episode_Reward/pen_joint_powers: -0.0288
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2317
Episode_Reward/pen_flat_orientation: -0.0991
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1255
   Episode_Reward/foot_landing_vel: -0.0569
   Episode_Reward/test_gait_reward: -0.4224
Metrics/base_velocity/error_vel_xy: 1.2655
Metrics/base_velocity/error_vel_yaw: 0.4088
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 1.13s
                        Total time: 930.12s
                               ETA: 2326.9s

################################################################################
                     [1m Learning iteration 857/3000 [0m                      

                       Computation: 89602 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 1.1327
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5320
                     Learning rate: 0.0009
                       Mean reward: 31.16
               Mean episode length: 444.37
       Episode_Reward/keep_balance: 0.4136
     Episode_Reward/rew_lin_vel_xy: 1.1934
      Episode_Reward/rew_ang_vel_z: 1.2307
    Episode_Reward/pen_base_height: -0.2399
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.0641
   Episode_Reward/pen_joint_torque: -0.0736
    Episode_Reward/pen_joint_accel: -0.0341
    Episode_Reward/pen_action_rate: -0.0948
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0148
   Episode_Reward/pen_joint_powers: -0.0258
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2158
Episode_Reward/pen_flat_orientation: -0.0971
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1149
   Episode_Reward/foot_landing_vel: -0.0509
   Episode_Reward/test_gait_reward: -0.3904
Metrics/base_velocity/error_vel_xy: 1.2496
Metrics/base_velocity/error_vel_yaw: 0.3900
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 7.2500
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 1.10s
                        Total time: 931.22s
                               ETA: 2325.9s

################################################################################
                     [1m Learning iteration 858/3000 [0m                      

                       Computation: 89701 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 1.0746
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5332
                     Learning rate: 0.0013
                       Mean reward: 29.81
               Mean episode length: 415.61
       Episode_Reward/keep_balance: 0.4502
     Episode_Reward/rew_lin_vel_xy: 1.4131
      Episode_Reward/rew_ang_vel_z: 1.3519
    Episode_Reward/pen_base_height: -0.2559
      Episode_Reward/pen_lin_vel_z: -0.0433
     Episode_Reward/pen_ang_vel_xy: -0.0687
   Episode_Reward/pen_joint_torque: -0.0795
    Episode_Reward/pen_joint_accel: -0.0412
    Episode_Reward/pen_action_rate: -0.1034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0161
   Episode_Reward/pen_joint_powers: -0.0280
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2365
Episode_Reward/pen_flat_orientation: -0.1018
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1199
   Episode_Reward/foot_landing_vel: -0.0570
   Episode_Reward/test_gait_reward: -0.4222
Metrics/base_velocity/error_vel_xy: 1.3124
Metrics/base_velocity/error_vel_yaw: 0.4150
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 1.10s
                        Total time: 932.31s
                               ETA: 2324.8s

################################################################################
                     [1m Learning iteration 859/3000 [0m                      

                       Computation: 87323 steps/s (collection: 1.004s, learning 0.122s)
               Value function loss: 1.0788
                    Surrogate loss: 0.0017
             Mean action noise std: 0.5337
                     Learning rate: 0.0006
                       Mean reward: 33.12
               Mean episode length: 455.28
       Episode_Reward/keep_balance: 0.4704
     Episode_Reward/rew_lin_vel_xy: 1.5032
      Episode_Reward/rew_ang_vel_z: 1.4014
    Episode_Reward/pen_base_height: -0.2639
      Episode_Reward/pen_lin_vel_z: -0.0468
     Episode_Reward/pen_ang_vel_xy: -0.0725
   Episode_Reward/pen_joint_torque: -0.0864
    Episode_Reward/pen_joint_accel: -0.0414
    Episode_Reward/pen_action_rate: -0.1088
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0171
   Episode_Reward/pen_joint_powers: -0.0302
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2457
Episode_Reward/pen_flat_orientation: -0.1062
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1304
   Episode_Reward/foot_landing_vel: -0.0610
   Episode_Reward/test_gait_reward: -0.4446
Metrics/base_velocity/error_vel_xy: 1.3267
Metrics/base_velocity/error_vel_yaw: 0.4397
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 1.13s
                        Total time: 933.44s
                               ETA: 2323.8s

################################################################################
                     [1m Learning iteration 860/3000 [0m                      

                       Computation: 88521 steps/s (collection: 0.984s, learning 0.126s)
               Value function loss: 1.1176
                    Surrogate loss: 0.0023
             Mean action noise std: 0.5344
                     Learning rate: 0.0001
                       Mean reward: 33.02
               Mean episode length: 475.47
       Episode_Reward/keep_balance: 0.4588
     Episode_Reward/rew_lin_vel_xy: 1.4205
      Episode_Reward/rew_ang_vel_z: 1.3601
    Episode_Reward/pen_base_height: -0.2610
      Episode_Reward/pen_lin_vel_z: -0.0473
     Episode_Reward/pen_ang_vel_xy: -0.0716
   Episode_Reward/pen_joint_torque: -0.0876
    Episode_Reward/pen_joint_accel: -0.0452
    Episode_Reward/pen_action_rate: -0.1075
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0175
   Episode_Reward/pen_joint_powers: -0.0306
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2414
Episode_Reward/pen_flat_orientation: -0.1043
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1319
   Episode_Reward/foot_landing_vel: -0.0629
   Episode_Reward/test_gait_reward: -0.4350
Metrics/base_velocity/error_vel_xy: 1.3234
Metrics/base_velocity/error_vel_yaw: 0.4360
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 1.11s
                        Total time: 934.55s
                               ETA: 2322.8s

################################################################################
                     [1m Learning iteration 861/3000 [0m                      

                       Computation: 86186 steps/s (collection: 1.015s, learning 0.125s)
               Value function loss: 1.0230
                    Surrogate loss: 0.0039
             Mean action noise std: 0.5346
                     Learning rate: 0.0001
                       Mean reward: 40.66
               Mean episode length: 539.45
       Episode_Reward/keep_balance: 0.4799
     Episode_Reward/rew_lin_vel_xy: 1.4863
      Episode_Reward/rew_ang_vel_z: 1.4370
    Episode_Reward/pen_base_height: -0.2533
      Episode_Reward/pen_lin_vel_z: -0.0467
     Episode_Reward/pen_ang_vel_xy: -0.0719
   Episode_Reward/pen_joint_torque: -0.0869
    Episode_Reward/pen_joint_accel: -0.0420
    Episode_Reward/pen_action_rate: -0.1107
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0171
   Episode_Reward/pen_joint_powers: -0.0302
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2519
Episode_Reward/pen_flat_orientation: -0.1000
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1269
   Episode_Reward/foot_landing_vel: -0.0600
   Episode_Reward/test_gait_reward: -0.4543
Metrics/base_velocity/error_vel_xy: 1.3908
Metrics/base_velocity/error_vel_yaw: 0.4433
      Episode_Termination/time_out: 2.5417
  Episode_Termination/base_contact: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 1.14s
                        Total time: 935.69s
                               ETA: 2321.9s

################################################################################
                     [1m Learning iteration 862/3000 [0m                      

                       Computation: 86640 steps/s (collection: 1.012s, learning 0.123s)
               Value function loss: 0.9971
                    Surrogate loss: 0.0011
             Mean action noise std: 0.5351
                     Learning rate: 0.0001
                       Mean reward: 32.73
               Mean episode length: 447.02
       Episode_Reward/keep_balance: 0.4518
     Episode_Reward/rew_lin_vel_xy: 1.4157
      Episode_Reward/rew_ang_vel_z: 1.3618
    Episode_Reward/pen_base_height: -0.2510
      Episode_Reward/pen_lin_vel_z: -0.0448
     Episode_Reward/pen_ang_vel_xy: -0.0689
   Episode_Reward/pen_joint_torque: -0.0841
    Episode_Reward/pen_joint_accel: -0.0401
    Episode_Reward/pen_action_rate: -0.1036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0161
   Episode_Reward/pen_joint_powers: -0.0288
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2349
Episode_Reward/pen_flat_orientation: -0.1006
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1223
   Episode_Reward/foot_landing_vel: -0.0550
   Episode_Reward/test_gait_reward: -0.4272
Metrics/base_velocity/error_vel_xy: 1.3101
Metrics/base_velocity/error_vel_yaw: 0.4118
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 1.13s
                        Total time: 936.82s
                               ETA: 2320.9s

################################################################################
                     [1m Learning iteration 863/3000 [0m                      

                       Computation: 91006 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 1.0016
                    Surrogate loss: -0.0016
             Mean action noise std: 0.5349
                     Learning rate: 0.0003
                       Mean reward: 39.20
               Mean episode length: 498.76
       Episode_Reward/keep_balance: 0.4888
     Episode_Reward/rew_lin_vel_xy: 1.5948
      Episode_Reward/rew_ang_vel_z: 1.4651
    Episode_Reward/pen_base_height: -0.2640
      Episode_Reward/pen_lin_vel_z: -0.0479
     Episode_Reward/pen_ang_vel_xy: -0.0729
   Episode_Reward/pen_joint_torque: -0.0928
    Episode_Reward/pen_joint_accel: -0.0409
    Episode_Reward/pen_action_rate: -0.1126
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0174
   Episode_Reward/pen_joint_powers: -0.0317
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2536
Episode_Reward/pen_flat_orientation: -0.1040
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1328
   Episode_Reward/foot_landing_vel: -0.0599
   Episode_Reward/test_gait_reward: -0.4600
Metrics/base_velocity/error_vel_xy: 1.3168
Metrics/base_velocity/error_vel_yaw: 0.4542
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 1.08s
                        Total time: 937.90s
                               ETA: 2319.8s

################################################################################
                     [1m Learning iteration 864/3000 [0m                      

                       Computation: 91113 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.0384
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5348
                     Learning rate: 0.0006
                       Mean reward: 30.66
               Mean episode length: 404.44
       Episode_Reward/keep_balance: 0.4142
     Episode_Reward/rew_lin_vel_xy: 1.3177
      Episode_Reward/rew_ang_vel_z: 1.2343
    Episode_Reward/pen_base_height: -0.2465
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.0642
   Episode_Reward/pen_joint_torque: -0.0759
    Episode_Reward/pen_joint_accel: -0.0370
    Episode_Reward/pen_action_rate: -0.0952
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0149
   Episode_Reward/pen_joint_powers: -0.0264
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2168
Episode_Reward/pen_flat_orientation: -0.1020
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1135
   Episode_Reward/foot_landing_vel: -0.0514
   Episode_Reward/test_gait_reward: -0.3936
Metrics/base_velocity/error_vel_xy: 1.1886
Metrics/base_velocity/error_vel_yaw: 0.3892
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 1.08s
                        Total time: 938.98s
                               ETA: 2318.7s

################################################################################
                     [1m Learning iteration 865/3000 [0m                      

                       Computation: 91214 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 1.2443
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5352
                     Learning rate: 0.0013
                       Mean reward: 33.98
               Mean episode length: 491.74
       Episode_Reward/keep_balance: 0.4838
     Episode_Reward/rew_lin_vel_xy: 1.5246
      Episode_Reward/rew_ang_vel_z: 1.4440
    Episode_Reward/pen_base_height: -0.2632
      Episode_Reward/pen_lin_vel_z: -0.0485
     Episode_Reward/pen_ang_vel_xy: -0.0736
   Episode_Reward/pen_joint_torque: -0.0894
    Episode_Reward/pen_joint_accel: -0.0435
    Episode_Reward/pen_action_rate: -0.1125
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0174
   Episode_Reward/pen_joint_powers: -0.0311
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2555
Episode_Reward/pen_flat_orientation: -0.1034
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1314
   Episode_Reward/foot_landing_vel: -0.0596
   Episode_Reward/test_gait_reward: -0.4551
Metrics/base_velocity/error_vel_xy: 1.3645
Metrics/base_velocity/error_vel_yaw: 0.4501
      Episode_Termination/time_out: 2.6667
  Episode_Termination/base_contact: 7.5833
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 1.08s
                        Total time: 940.06s
                               ETA: 2317.6s

################################################################################
                     [1m Learning iteration 866/3000 [0m                      

                       Computation: 91475 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.5971
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5353
                     Learning rate: 0.0006
                       Mean reward: 35.26
               Mean episode length: 481.36
       Episode_Reward/keep_balance: 0.4611
     Episode_Reward/rew_lin_vel_xy: 1.4832
      Episode_Reward/rew_ang_vel_z: 1.3856
    Episode_Reward/pen_base_height: -0.2584
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.0693
   Episode_Reward/pen_joint_torque: -0.0831
    Episode_Reward/pen_joint_accel: -0.0402
    Episode_Reward/pen_action_rate: -0.1073
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0165
   Episode_Reward/pen_joint_powers: -0.0291
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2433
Episode_Reward/pen_flat_orientation: -0.1044
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1271
   Episode_Reward/foot_landing_vel: -0.0572
   Episode_Reward/test_gait_reward: -0.4369
Metrics/base_velocity/error_vel_xy: 1.3246
Metrics/base_velocity/error_vel_yaw: 0.4255
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 1.07s
                        Total time: 941.13s
                               ETA: 2316.5s

################################################################################
                     [1m Learning iteration 867/3000 [0m                      

                       Computation: 91198 steps/s (collection: 0.950s, learning 0.128s)
               Value function loss: 0.9590
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5352
                     Learning rate: 0.0004
                       Mean reward: 33.05
               Mean episode length: 475.33
       Episode_Reward/keep_balance: 0.4431
     Episode_Reward/rew_lin_vel_xy: 1.3236
      Episode_Reward/rew_ang_vel_z: 1.3265
    Episode_Reward/pen_base_height: -0.2565
      Episode_Reward/pen_lin_vel_z: -0.0461
     Episode_Reward/pen_ang_vel_xy: -0.0682
   Episode_Reward/pen_joint_torque: -0.0828
    Episode_Reward/pen_joint_accel: -0.0395
    Episode_Reward/pen_action_rate: -0.1028
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0162
   Episode_Reward/pen_joint_powers: -0.0287
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2304
Episode_Reward/pen_flat_orientation: -0.1034
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1279
   Episode_Reward/foot_landing_vel: -0.0553
   Episode_Reward/test_gait_reward: -0.4173
Metrics/base_velocity/error_vel_xy: 1.3396
Metrics/base_velocity/error_vel_yaw: 0.4119
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 1.08s
                        Total time: 942.21s
                               ETA: 2315.4s

################################################################################
                     [1m Learning iteration 868/3000 [0m                      

                       Computation: 89124 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 1.0083
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5363
                     Learning rate: 0.0009
                       Mean reward: 34.44
               Mean episode length: 492.03
       Episode_Reward/keep_balance: 0.4601
     Episode_Reward/rew_lin_vel_xy: 1.4142
      Episode_Reward/rew_ang_vel_z: 1.3747
    Episode_Reward/pen_base_height: -0.2519
      Episode_Reward/pen_lin_vel_z: -0.0441
     Episode_Reward/pen_ang_vel_xy: -0.0690
   Episode_Reward/pen_joint_torque: -0.0823
    Episode_Reward/pen_joint_accel: -0.0386
    Episode_Reward/pen_action_rate: -0.1059
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0161
   Episode_Reward/pen_joint_powers: -0.0287
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2431
Episode_Reward/pen_flat_orientation: -0.1012
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1213
   Episode_Reward/foot_landing_vel: -0.0557
   Episode_Reward/test_gait_reward: -0.4339
Metrics/base_velocity/error_vel_xy: 1.3390
Metrics/base_velocity/error_vel_yaw: 0.4286
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 8.1667
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 1.10s
                        Total time: 943.32s
                               ETA: 2314.3s

################################################################################
                     [1m Learning iteration 869/3000 [0m                      

                       Computation: 89758 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.9702
                    Surrogate loss: 0.0033
             Mean action noise std: 0.5371
                     Learning rate: 0.0003
                       Mean reward: 37.15
               Mean episode length: 492.06
       Episode_Reward/keep_balance: 0.4687
     Episode_Reward/rew_lin_vel_xy: 1.5194
      Episode_Reward/rew_ang_vel_z: 1.4005
    Episode_Reward/pen_base_height: -0.2593
      Episode_Reward/pen_lin_vel_z: -0.0480
     Episode_Reward/pen_ang_vel_xy: -0.0703
   Episode_Reward/pen_joint_torque: -0.0890
    Episode_Reward/pen_joint_accel: -0.0455
    Episode_Reward/pen_action_rate: -0.1092
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0171
   Episode_Reward/pen_joint_powers: -0.0307
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2462
Episode_Reward/pen_flat_orientation: -0.1042
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1311
   Episode_Reward/foot_landing_vel: -0.0595
   Episode_Reward/test_gait_reward: -0.4470
Metrics/base_velocity/error_vel_xy: 1.3084
Metrics/base_velocity/error_vel_yaw: 0.4383
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 1.10s
                        Total time: 944.41s
                               ETA: 2313.3s

################################################################################
                     [1m Learning iteration 870/3000 [0m                      

                       Computation: 90438 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.9972
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5382
                     Learning rate: 0.0003
                       Mean reward: 25.70
               Mean episode length: 399.91
       Episode_Reward/keep_balance: 0.4195
     Episode_Reward/rew_lin_vel_xy: 1.2430
      Episode_Reward/rew_ang_vel_z: 1.2520
    Episode_Reward/pen_base_height: -0.2445
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.0645
   Episode_Reward/pen_joint_torque: -0.0786
    Episode_Reward/pen_joint_accel: -0.0404
    Episode_Reward/pen_action_rate: -0.0982
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0154
   Episode_Reward/pen_joint_powers: -0.0272
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2203
Episode_Reward/pen_flat_orientation: -0.0950
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1155
   Episode_Reward/foot_landing_vel: -0.0560
   Episode_Reward/test_gait_reward: -0.3958
Metrics/base_velocity/error_vel_xy: 1.2627
Metrics/base_velocity/error_vel_yaw: 0.3944
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 1.09s
                        Total time: 945.50s
                               ETA: 2312.2s

################################################################################
                     [1m Learning iteration 871/3000 [0m                      

                       Computation: 89735 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 0.9275
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5382
                     Learning rate: 0.0006
                       Mean reward: 27.64
               Mean episode length: 390.21
       Episode_Reward/keep_balance: 0.4051
     Episode_Reward/rew_lin_vel_xy: 1.2827
      Episode_Reward/rew_ang_vel_z: 1.2130
    Episode_Reward/pen_base_height: -0.2430
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.0629
   Episode_Reward/pen_joint_torque: -0.0736
    Episode_Reward/pen_joint_accel: -0.0343
    Episode_Reward/pen_action_rate: -0.0919
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0253
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2111
Episode_Reward/pen_flat_orientation: -0.0992
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1053
   Episode_Reward/foot_landing_vel: -0.0472
   Episode_Reward/test_gait_reward: -0.3818
Metrics/base_velocity/error_vel_xy: 1.1455
Metrics/base_velocity/error_vel_yaw: 0.3776
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 1.10s
                        Total time: 946.59s
                               ETA: 2311.1s

################################################################################
                     [1m Learning iteration 872/3000 [0m                      

                       Computation: 89472 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.9160
                    Surrogate loss: -0.0019
             Mean action noise std: 0.5386
                     Learning rate: 0.0013
                       Mean reward: 30.08
               Mean episode length: 465.71
       Episode_Reward/keep_balance: 0.4435
     Episode_Reward/rew_lin_vel_xy: 1.3919
      Episode_Reward/rew_ang_vel_z: 1.3178
    Episode_Reward/pen_base_height: -0.2592
      Episode_Reward/pen_lin_vel_z: -0.0459
     Episode_Reward/pen_ang_vel_xy: -0.0684
   Episode_Reward/pen_joint_torque: -0.0862
    Episode_Reward/pen_joint_accel: -0.0392
    Episode_Reward/pen_action_rate: -0.1026
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0161
   Episode_Reward/pen_joint_powers: -0.0292
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2312
Episode_Reward/pen_flat_orientation: -0.1049
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1243
   Episode_Reward/foot_landing_vel: -0.0564
   Episode_Reward/test_gait_reward: -0.4209
Metrics/base_velocity/error_vel_xy: 1.2830
Metrics/base_velocity/error_vel_yaw: 0.4186
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 1.10s
                        Total time: 947.69s
                               ETA: 2310.1s

################################################################################
                     [1m Learning iteration 873/3000 [0m                      

                       Computation: 91673 steps/s (collection: 0.951s, learning 0.121s)
               Value function loss: 1.0198
                    Surrogate loss: 0.0029
             Mean action noise std: 0.5397
                     Learning rate: 0.0003
                       Mean reward: 35.44
               Mean episode length: 463.67
       Episode_Reward/keep_balance: 0.4763
     Episode_Reward/rew_lin_vel_xy: 1.5306
      Episode_Reward/rew_ang_vel_z: 1.4249
    Episode_Reward/pen_base_height: -0.2655
      Episode_Reward/pen_lin_vel_z: -0.0489
     Episode_Reward/pen_ang_vel_xy: -0.0730
   Episode_Reward/pen_joint_torque: -0.0901
    Episode_Reward/pen_joint_accel: -0.0427
    Episode_Reward/pen_action_rate: -0.1117
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0177
   Episode_Reward/pen_joint_powers: -0.0312
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2505
Episode_Reward/pen_flat_orientation: -0.1092
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1384
   Episode_Reward/foot_landing_vel: -0.0607
   Episode_Reward/test_gait_reward: -0.4518
Metrics/base_velocity/error_vel_xy: 1.3559
Metrics/base_velocity/error_vel_yaw: 0.4447
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 1.07s
                        Total time: 948.76s
                               ETA: 2308.9s

################################################################################
                     [1m Learning iteration 874/3000 [0m                      

                       Computation: 91039 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.9561
                    Surrogate loss: -0.0011
             Mean action noise std: 0.5399
                     Learning rate: 0.0006
                       Mean reward: 31.20
               Mean episode length: 434.08
       Episode_Reward/keep_balance: 0.4578
     Episode_Reward/rew_lin_vel_xy: 1.3626
      Episode_Reward/rew_ang_vel_z: 1.3696
    Episode_Reward/pen_base_height: -0.2523
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.0684
   Episode_Reward/pen_joint_torque: -0.0868
    Episode_Reward/pen_joint_accel: -0.0385
    Episode_Reward/pen_action_rate: -0.1057
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0158
   Episode_Reward/pen_joint_powers: -0.0290
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2406
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1188
   Episode_Reward/foot_landing_vel: -0.0538
   Episode_Reward/test_gait_reward: -0.4271
Metrics/base_velocity/error_vel_xy: 1.3453
Metrics/base_velocity/error_vel_yaw: 0.4243
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 1.08s
                        Total time: 949.84s
                               ETA: 2307.8s

################################################################################
                     [1m Learning iteration 875/3000 [0m                      

                       Computation: 90734 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.9657
                    Surrogate loss: 0.0012
             Mean action noise std: 0.5396
                     Learning rate: 0.0003
                       Mean reward: 28.04
               Mean episode length: 398.11
       Episode_Reward/keep_balance: 0.3952
     Episode_Reward/rew_lin_vel_xy: 1.2246
      Episode_Reward/rew_ang_vel_z: 1.1948
    Episode_Reward/pen_base_height: -0.2411
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.0617
   Episode_Reward/pen_joint_torque: -0.0720
    Episode_Reward/pen_joint_accel: -0.0319
    Episode_Reward/pen_action_rate: -0.0895
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0136
   Episode_Reward/pen_joint_powers: -0.0246
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2059
Episode_Reward/pen_flat_orientation: -0.1000
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1013
   Episode_Reward/foot_landing_vel: -0.0450
   Episode_Reward/test_gait_reward: -0.3729
Metrics/base_velocity/error_vel_xy: 1.1215
Metrics/base_velocity/error_vel_yaw: 0.3593
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 1.08s
                        Total time: 950.93s
                               ETA: 2306.8s

################################################################################
                     [1m Learning iteration 876/3000 [0m                      

                       Computation: 89936 steps/s (collection: 0.967s, learning 0.126s)
               Value function loss: 0.9786
                    Surrogate loss: 0.0010
             Mean action noise std: 0.5395
                     Learning rate: 0.0002
                       Mean reward: 36.00
               Mean episode length: 471.44
       Episode_Reward/keep_balance: 0.4870
     Episode_Reward/rew_lin_vel_xy: 1.6065
      Episode_Reward/rew_ang_vel_z: 1.4634
    Episode_Reward/pen_base_height: -0.2671
      Episode_Reward/pen_lin_vel_z: -0.0483
     Episode_Reward/pen_ang_vel_xy: -0.0726
   Episode_Reward/pen_joint_torque: -0.0905
    Episode_Reward/pen_joint_accel: -0.0414
    Episode_Reward/pen_action_rate: -0.1130
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0169
   Episode_Reward/pen_joint_powers: -0.0310
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2563
Episode_Reward/pen_flat_orientation: -0.1038
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1275
   Episode_Reward/foot_landing_vel: -0.0604
   Episode_Reward/test_gait_reward: -0.4588
Metrics/base_velocity/error_vel_xy: 1.3142
Metrics/base_velocity/error_vel_yaw: 0.4483
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 1.09s
                        Total time: 952.02s
                               ETA: 2305.7s

################################################################################
                     [1m Learning iteration 877/3000 [0m                      

                       Computation: 91997 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 1.0027
                    Surrogate loss: -0.0032
             Mean action noise std: 0.5387
                     Learning rate: 0.0004
                       Mean reward: 30.59
               Mean episode length: 410.93
       Episode_Reward/keep_balance: 0.4759
     Episode_Reward/rew_lin_vel_xy: 1.5632
      Episode_Reward/rew_ang_vel_z: 1.4193
    Episode_Reward/pen_base_height: -0.2606
      Episode_Reward/pen_lin_vel_z: -0.0457
     Episode_Reward/pen_ang_vel_xy: -0.0702
   Episode_Reward/pen_joint_torque: -0.0887
    Episode_Reward/pen_joint_accel: -0.0388
    Episode_Reward/pen_action_rate: -0.1096
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0166
   Episode_Reward/pen_joint_powers: -0.0303
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2493
Episode_Reward/pen_flat_orientation: -0.0998
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1223
   Episode_Reward/foot_landing_vel: -0.0554
   Episode_Reward/test_gait_reward: -0.4484
Metrics/base_velocity/error_vel_xy: 1.3074
Metrics/base_velocity/error_vel_yaw: 0.4454
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 1.07s
                        Total time: 953.09s
                               ETA: 2304.6s

################################################################################
                     [1m Learning iteration 878/3000 [0m                      

                       Computation: 91619 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 1.0049
                    Surrogate loss: -0.0027
             Mean action noise std: 0.5376
                     Learning rate: 0.0009
                       Mean reward: 35.57
               Mean episode length: 477.11
       Episode_Reward/keep_balance: 0.4648
     Episode_Reward/rew_lin_vel_xy: 1.5418
      Episode_Reward/rew_ang_vel_z: 1.3842
    Episode_Reward/pen_base_height: -0.2596
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.0713
   Episode_Reward/pen_joint_torque: -0.0856
    Episode_Reward/pen_joint_accel: -0.0387
    Episode_Reward/pen_action_rate: -0.1087
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0166
   Episode_Reward/pen_joint_powers: -0.0296
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2476
Episode_Reward/pen_flat_orientation: -0.1034
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1267
   Episode_Reward/foot_landing_vel: -0.0558
   Episode_Reward/test_gait_reward: -0.4397
Metrics/base_velocity/error_vel_xy: 1.2555
Metrics/base_velocity/error_vel_yaw: 0.4363
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 1.07s
                        Total time: 954.16s
                               ETA: 2303.4s

################################################################################
                     [1m Learning iteration 879/3000 [0m                      

                       Computation: 90995 steps/s (collection: 0.955s, learning 0.126s)
               Value function loss: 1.0022
                    Surrogate loss: -0.0002
             Mean action noise std: 0.5376
                     Learning rate: 0.0006
                       Mean reward: 28.50
               Mean episode length: 442.13
       Episode_Reward/keep_balance: 0.3963
     Episode_Reward/rew_lin_vel_xy: 1.1896
      Episode_Reward/rew_ang_vel_z: 1.1798
    Episode_Reward/pen_base_height: -0.2420
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.0644
   Episode_Reward/pen_joint_torque: -0.0744
    Episode_Reward/pen_joint_accel: -0.0372
    Episode_Reward/pen_action_rate: -0.0928
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0150
   Episode_Reward/pen_joint_powers: -0.0259
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2101
Episode_Reward/pen_flat_orientation: -0.1015
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1156
   Episode_Reward/foot_landing_vel: -0.0490
   Episode_Reward/test_gait_reward: -0.3760
Metrics/base_velocity/error_vel_xy: 1.1754
Metrics/base_velocity/error_vel_yaw: 0.3773
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 1.08s
                        Total time: 955.24s
                               ETA: 2302.4s

################################################################################
                     [1m Learning iteration 880/3000 [0m                      

                       Computation: 91170 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 1.1119
                    Surrogate loss: -0.0011
             Mean action noise std: 0.5382
                     Learning rate: 0.0006
                       Mean reward: 25.36
               Mean episode length: 384.14
       Episode_Reward/keep_balance: 0.4093
     Episode_Reward/rew_lin_vel_xy: 1.2608
      Episode_Reward/rew_ang_vel_z: 1.2121
    Episode_Reward/pen_base_height: -0.2460
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.0643
   Episode_Reward/pen_joint_torque: -0.0772
    Episode_Reward/pen_joint_accel: -0.0367
    Episode_Reward/pen_action_rate: -0.0964
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0149
   Episode_Reward/pen_joint_powers: -0.0266
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2182
Episode_Reward/pen_flat_orientation: -0.0988
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1178
   Episode_Reward/foot_landing_vel: -0.0510
   Episode_Reward/test_gait_reward: -0.3864
Metrics/base_velocity/error_vel_xy: 1.2017
Metrics/base_velocity/error_vel_yaw: 0.3913
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 1.08s
                        Total time: 956.32s
                               ETA: 2301.2s

################################################################################
                     [1m Learning iteration 881/3000 [0m                      

                       Computation: 90230 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 1.0382
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5388
                     Learning rate: 0.0004
                       Mean reward: 31.61
               Mean episode length: 428.63
       Episode_Reward/keep_balance: 0.4635
     Episode_Reward/rew_lin_vel_xy: 1.4849
      Episode_Reward/rew_ang_vel_z: 1.3836
    Episode_Reward/pen_base_height: -0.2635
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.0687
   Episode_Reward/pen_joint_torque: -0.0853
    Episode_Reward/pen_joint_accel: -0.0396
    Episode_Reward/pen_action_rate: -0.1078
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0164
   Episode_Reward/pen_joint_powers: -0.0293
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2446
Episode_Reward/pen_flat_orientation: -0.1085
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.1271
   Episode_Reward/foot_landing_vel: -0.0556
   Episode_Reward/test_gait_reward: -0.4348
Metrics/base_velocity/error_vel_xy: 1.3175
Metrics/base_velocity/error_vel_yaw: 0.4334
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 1.09s
                        Total time: 957.41s
                               ETA: 2300.2s

################################################################################
                     [1m Learning iteration 882/3000 [0m                      

                       Computation: 92281 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 1.0221
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5394
                     Learning rate: 0.0009
                       Mean reward: 35.59
               Mean episode length: 455.01
       Episode_Reward/keep_balance: 0.4449
     Episode_Reward/rew_lin_vel_xy: 1.4461
      Episode_Reward/rew_ang_vel_z: 1.3123
    Episode_Reward/pen_base_height: -0.2522
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.0679
   Episode_Reward/pen_joint_torque: -0.0825
    Episode_Reward/pen_joint_accel: -0.0397
    Episode_Reward/pen_action_rate: -0.1038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0283
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2368
Episode_Reward/pen_flat_orientation: -0.1018
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1205
   Episode_Reward/foot_landing_vel: -0.0549
   Episode_Reward/test_gait_reward: -0.4209
Metrics/base_velocity/error_vel_xy: 1.2588
Metrics/base_velocity/error_vel_yaw: 0.4262
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 1.07s
                        Total time: 958.48s
                               ETA: 2299.0s

################################################################################
                     [1m Learning iteration 883/3000 [0m                      

                       Computation: 90992 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 1.1282
                    Surrogate loss: -0.0011
             Mean action noise std: 0.5396
                     Learning rate: 0.0013
                       Mean reward: 31.70
               Mean episode length: 466.39
       Episode_Reward/keep_balance: 0.4641
     Episode_Reward/rew_lin_vel_xy: 1.4131
      Episode_Reward/rew_ang_vel_z: 1.3826
    Episode_Reward/pen_base_height: -0.2611
      Episode_Reward/pen_lin_vel_z: -0.0477
     Episode_Reward/pen_ang_vel_xy: -0.0717
   Episode_Reward/pen_joint_torque: -0.0906
    Episode_Reward/pen_joint_accel: -0.0417
    Episode_Reward/pen_action_rate: -0.1107
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0174
   Episode_Reward/pen_joint_powers: -0.0309
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2473
Episode_Reward/pen_flat_orientation: -0.1016
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1341
   Episode_Reward/foot_landing_vel: -0.0615
   Episode_Reward/test_gait_reward: -0.4351
Metrics/base_velocity/error_vel_xy: 1.3716
Metrics/base_velocity/error_vel_yaw: 0.4352
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 1.08s
                        Total time: 959.56s
                               ETA: 2297.9s

################################################################################
                     [1m Learning iteration 884/3000 [0m                      

                       Computation: 91415 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 1.2171
                    Surrogate loss: 0.0082
             Mean action noise std: 0.5398
                     Learning rate: 0.0001
                       Mean reward: 37.64
               Mean episode length: 533.17
       Episode_Reward/keep_balance: 0.5390
     Episode_Reward/rew_lin_vel_xy: 1.6837
      Episode_Reward/rew_ang_vel_z: 1.6011
    Episode_Reward/pen_base_height: -0.2836
      Episode_Reward/pen_lin_vel_z: -0.0523
     Episode_Reward/pen_ang_vel_xy: -0.0780
   Episode_Reward/pen_joint_torque: -0.0995
    Episode_Reward/pen_joint_accel: -0.0481
    Episode_Reward/pen_action_rate: -0.1270
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0192
   Episode_Reward/pen_joint_powers: -0.0344
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2878
Episode_Reward/pen_flat_orientation: -0.1049
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1458
   Episode_Reward/foot_landing_vel: -0.0682
   Episode_Reward/test_gait_reward: -0.5051
Metrics/base_velocity/error_vel_xy: 1.5825
Metrics/base_velocity/error_vel_yaw: 0.5059
      Episode_Termination/time_out: 2.7917
  Episode_Termination/base_contact: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 1.08s
                        Total time: 960.63s
                               ETA: 2296.8s

################################################################################
                     [1m Learning iteration 885/3000 [0m                      

                       Computation: 91260 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 1.0207
                    Surrogate loss: 0.0066
             Mean action noise std: 0.5399
                     Learning rate: 0.0001
                       Mean reward: 38.00
               Mean episode length: 525.35
       Episode_Reward/keep_balance: 0.4796
     Episode_Reward/rew_lin_vel_xy: 1.5405
      Episode_Reward/rew_ang_vel_z: 1.4429
    Episode_Reward/pen_base_height: -0.2669
      Episode_Reward/pen_lin_vel_z: -0.0490
     Episode_Reward/pen_ang_vel_xy: -0.0706
   Episode_Reward/pen_joint_torque: -0.0937
    Episode_Reward/pen_joint_accel: -0.0446
    Episode_Reward/pen_action_rate: -0.1138
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0178
   Episode_Reward/pen_joint_powers: -0.0320
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2535
Episode_Reward/pen_flat_orientation: -0.1017
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.1388
   Episode_Reward/foot_landing_vel: -0.0633
   Episode_Reward/test_gait_reward: -0.4533
Metrics/base_velocity/error_vel_xy: 1.3698
Metrics/base_velocity/error_vel_yaw: 0.4387
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 1.08s
                        Total time: 961.71s
                               ETA: 2295.7s

################################################################################
                     [1m Learning iteration 886/3000 [0m                      

                       Computation: 90362 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 1.0212
                    Surrogate loss: 0.0032
             Mean action noise std: 0.5400
                     Learning rate: 0.0001
                       Mean reward: 34.22
               Mean episode length: 445.65
       Episode_Reward/keep_balance: 0.4743
     Episode_Reward/rew_lin_vel_xy: 1.5601
      Episode_Reward/rew_ang_vel_z: 1.4054
    Episode_Reward/pen_base_height: -0.2632
      Episode_Reward/pen_lin_vel_z: -0.0487
     Episode_Reward/pen_ang_vel_xy: -0.0718
   Episode_Reward/pen_joint_torque: -0.0908
    Episode_Reward/pen_joint_accel: -0.0430
    Episode_Reward/pen_action_rate: -0.1117
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0176
   Episode_Reward/pen_joint_powers: -0.0316
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2522
Episode_Reward/pen_flat_orientation: -0.1037
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1362
   Episode_Reward/foot_landing_vel: -0.0619
   Episode_Reward/test_gait_reward: -0.4490
Metrics/base_velocity/error_vel_xy: 1.2799
Metrics/base_velocity/error_vel_yaw: 0.4520
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 1.09s
                        Total time: 962.80s
                               ETA: 2294.6s

################################################################################
                     [1m Learning iteration 887/3000 [0m                      

                       Computation: 92362 steps/s (collection: 0.940s, learning 0.124s)
               Value function loss: 0.9678
                    Surrogate loss: 0.0010
             Mean action noise std: 0.5401
                     Learning rate: 0.0001
                       Mean reward: 34.49
               Mean episode length: 454.53
       Episode_Reward/keep_balance: 0.4672
     Episode_Reward/rew_lin_vel_xy: 1.5594
      Episode_Reward/rew_ang_vel_z: 1.4067
    Episode_Reward/pen_base_height: -0.2598
      Episode_Reward/pen_lin_vel_z: -0.0457
     Episode_Reward/pen_ang_vel_xy: -0.0692
   Episode_Reward/pen_joint_torque: -0.0892
    Episode_Reward/pen_joint_accel: -0.0409
    Episode_Reward/pen_action_rate: -0.1095
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0168
   Episode_Reward/pen_joint_powers: -0.0305
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2476
Episode_Reward/pen_flat_orientation: -0.0984
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.1304
   Episode_Reward/foot_landing_vel: -0.0581
   Episode_Reward/test_gait_reward: -0.4423
Metrics/base_velocity/error_vel_xy: 1.2454
Metrics/base_velocity/error_vel_yaw: 0.4253
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 1.06s
                        Total time: 963.86s
                               ETA: 2293.5s

################################################################################
                     [1m Learning iteration 888/3000 [0m                      

                       Computation: 91093 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 1.0271
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5399
                     Learning rate: 0.0002
                       Mean reward: 35.14
               Mean episode length: 495.71
       Episode_Reward/keep_balance: 0.5003
     Episode_Reward/rew_lin_vel_xy: 1.6437
      Episode_Reward/rew_ang_vel_z: 1.4892
    Episode_Reward/pen_base_height: -0.2698
      Episode_Reward/pen_lin_vel_z: -0.0482
     Episode_Reward/pen_ang_vel_xy: -0.0737
   Episode_Reward/pen_joint_torque: -0.0943
    Episode_Reward/pen_joint_accel: -0.0453
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0185
   Episode_Reward/pen_joint_powers: -0.0326
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2679
Episode_Reward/pen_flat_orientation: -0.1055
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1426
   Episode_Reward/foot_landing_vel: -0.0644
   Episode_Reward/test_gait_reward: -0.4706
Metrics/base_velocity/error_vel_xy: 1.3829
Metrics/base_velocity/error_vel_yaw: 0.4691
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 1.08s
                        Total time: 964.94s
                               ETA: 2292.4s

################################################################################
                     [1m Learning iteration 889/3000 [0m                      

                       Computation: 91794 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 1.1917
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5409
                     Learning rate: 0.0006
                       Mean reward: 31.28
               Mean episode length: 453.57
       Episode_Reward/keep_balance: 0.4876
     Episode_Reward/rew_lin_vel_xy: 1.4957
      Episode_Reward/rew_ang_vel_z: 1.4578
    Episode_Reward/pen_base_height: -0.2644
      Episode_Reward/pen_lin_vel_z: -0.0477
     Episode_Reward/pen_ang_vel_xy: -0.0727
   Episode_Reward/pen_joint_torque: -0.0938
    Episode_Reward/pen_joint_accel: -0.0417
    Episode_Reward/pen_action_rate: -0.1153
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0177
   Episode_Reward/pen_joint_powers: -0.0319
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2592
Episode_Reward/pen_flat_orientation: -0.1022
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1377
   Episode_Reward/foot_landing_vel: -0.0611
   Episode_Reward/test_gait_reward: -0.4572
Metrics/base_velocity/error_vel_xy: 1.4225
Metrics/base_velocity/error_vel_yaw: 0.4512
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 1.07s
                        Total time: 966.01s
                               ETA: 2291.3s

################################################################################
                     [1m Learning iteration 890/3000 [0m                      

                       Computation: 90345 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 1.2385
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5422
                     Learning rate: 0.0013
                       Mean reward: 31.27
               Mean episode length: 408.59
       Episode_Reward/keep_balance: 0.4333
     Episode_Reward/rew_lin_vel_xy: 1.4164
      Episode_Reward/rew_ang_vel_z: 1.3060
    Episode_Reward/pen_base_height: -0.2553
      Episode_Reward/pen_lin_vel_z: -0.0414
     Episode_Reward/pen_ang_vel_xy: -0.0641
   Episode_Reward/pen_joint_torque: -0.0802
    Episode_Reward/pen_joint_accel: -0.0367
    Episode_Reward/pen_action_rate: -0.0997
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0153
   Episode_Reward/pen_joint_powers: -0.0276
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2285
Episode_Reward/pen_flat_orientation: -0.1025
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.1169
   Episode_Reward/foot_landing_vel: -0.0514
   Episode_Reward/test_gait_reward: -0.4086
Metrics/base_velocity/error_vel_xy: 1.1969
Metrics/base_velocity/error_vel_yaw: 0.3948
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 1.09s
                        Total time: 967.10s
                               ETA: 2290.2s

################################################################################
                     [1m Learning iteration 891/3000 [0m                      

                       Computation: 90653 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 1.2265
                    Surrogate loss: 0.0001
             Mean action noise std: 0.5438
                     Learning rate: 0.0006
                       Mean reward: 40.66
               Mean episode length: 513.58
       Episode_Reward/keep_balance: 0.5000
     Episode_Reward/rew_lin_vel_xy: 1.6898
      Episode_Reward/rew_ang_vel_z: 1.5007
    Episode_Reward/pen_base_height: -0.2729
      Episode_Reward/pen_lin_vel_z: -0.0484
     Episode_Reward/pen_ang_vel_xy: -0.0738
   Episode_Reward/pen_joint_torque: -0.0944
    Episode_Reward/pen_joint_accel: -0.0446
    Episode_Reward/pen_action_rate: -0.1179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0180
   Episode_Reward/pen_joint_powers: -0.0323
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2650
Episode_Reward/pen_flat_orientation: -0.1104
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1377
   Episode_Reward/foot_landing_vel: -0.0620
   Episode_Reward/test_gait_reward: -0.4690
Metrics/base_velocity/error_vel_xy: 1.3484
Metrics/base_velocity/error_vel_yaw: 0.4601
      Episode_Termination/time_out: 2.8333
  Episode_Termination/base_contact: 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 1.08s
                        Total time: 968.18s
                               ETA: 2289.1s

################################################################################
                     [1m Learning iteration 892/3000 [0m                      

                       Computation: 90385 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 1.1471
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5447
                     Learning rate: 0.0006
                       Mean reward: 32.81
               Mean episode length: 438.87
       Episode_Reward/keep_balance: 0.4383
     Episode_Reward/rew_lin_vel_xy: 1.3620
      Episode_Reward/rew_ang_vel_z: 1.3087
    Episode_Reward/pen_base_height: -0.2533
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.0655
   Episode_Reward/pen_joint_torque: -0.0794
    Episode_Reward/pen_joint_accel: -0.0350
    Episode_Reward/pen_action_rate: -0.1017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0153
   Episode_Reward/pen_joint_powers: -0.0274
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2316
Episode_Reward/pen_flat_orientation: -0.1046
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1176
   Episode_Reward/foot_landing_vel: -0.0516
   Episode_Reward/test_gait_reward: -0.4104
Metrics/base_velocity/error_vel_xy: 1.2747
Metrics/base_velocity/error_vel_yaw: 0.4100
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 1.09s
                        Total time: 969.27s
                               ETA: 2288.0s

################################################################################
                     [1m Learning iteration 893/3000 [0m                      

                       Computation: 90134 steps/s (collection: 0.964s, learning 0.126s)
               Value function loss: 1.0926
                    Surrogate loss: 0.0024
             Mean action noise std: 0.5454
                     Learning rate: 0.0002
                       Mean reward: 35.62
               Mean episode length: 465.84
       Episode_Reward/keep_balance: 0.4773
     Episode_Reward/rew_lin_vel_xy: 1.6127
      Episode_Reward/rew_ang_vel_z: 1.4369
    Episode_Reward/pen_base_height: -0.2563
      Episode_Reward/pen_lin_vel_z: -0.0448
     Episode_Reward/pen_ang_vel_xy: -0.0679
   Episode_Reward/pen_joint_torque: -0.0868
    Episode_Reward/pen_joint_accel: -0.0438
    Episode_Reward/pen_action_rate: -0.1103
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0167
   Episode_Reward/pen_joint_powers: -0.0299
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2533
Episode_Reward/pen_flat_orientation: -0.1032
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1244
   Episode_Reward/foot_landing_vel: -0.0590
   Episode_Reward/test_gait_reward: -0.4450
Metrics/base_velocity/error_vel_xy: 1.2973
Metrics/base_velocity/error_vel_yaw: 0.4352
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 1.09s
                        Total time: 970.36s
                               ETA: 2287.0s

################################################################################
                     [1m Learning iteration 894/3000 [0m                      

                       Computation: 90213 steps/s (collection: 0.962s, learning 0.128s)
               Value function loss: 0.8991
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5451
                     Learning rate: 0.0003
                       Mean reward: 39.24
               Mean episode length: 515.66
       Episode_Reward/keep_balance: 0.4696
     Episode_Reward/rew_lin_vel_xy: 1.5298
      Episode_Reward/rew_ang_vel_z: 1.4053
    Episode_Reward/pen_base_height: -0.2547
      Episode_Reward/pen_lin_vel_z: -0.0461
     Episode_Reward/pen_ang_vel_xy: -0.0674
   Episode_Reward/pen_joint_torque: -0.0877
    Episode_Reward/pen_joint_accel: -0.0438
    Episode_Reward/pen_action_rate: -0.1113
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0170
   Episode_Reward/pen_joint_powers: -0.0302
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2516
Episode_Reward/pen_flat_orientation: -0.1018
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1342
   Episode_Reward/foot_landing_vel: -0.0595
   Episode_Reward/test_gait_reward: -0.4413
Metrics/base_velocity/error_vel_xy: 1.3058
Metrics/base_velocity/error_vel_yaw: 0.4369
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 1.09s
                        Total time: 971.45s
                               ETA: 2285.9s

################################################################################
                     [1m Learning iteration 895/3000 [0m                      

                       Computation: 90629 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 1.0609
                    Surrogate loss: 0.0019
             Mean action noise std: 0.5443
                     Learning rate: 0.0001
                       Mean reward: 34.88
               Mean episode length: 456.98
       Episode_Reward/keep_balance: 0.4605
     Episode_Reward/rew_lin_vel_xy: 1.4974
      Episode_Reward/rew_ang_vel_z: 1.3798
    Episode_Reward/pen_base_height: -0.2521
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.0686
   Episode_Reward/pen_joint_torque: -0.0861
    Episode_Reward/pen_joint_accel: -0.0428
    Episode_Reward/pen_action_rate: -0.1081
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0165
   Episode_Reward/pen_joint_powers: -0.0296
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2454
Episode_Reward/pen_flat_orientation: -0.1002
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1246
   Episode_Reward/foot_landing_vel: -0.0572
   Episode_Reward/test_gait_reward: -0.4313
Metrics/base_velocity/error_vel_xy: 1.2779
Metrics/base_velocity/error_vel_yaw: 0.4262
      Episode_Termination/time_out: 2.2917
  Episode_Termination/base_contact: 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 1.08s
                        Total time: 972.54s
                               ETA: 2284.8s

################################################################################
                     [1m Learning iteration 896/3000 [0m                      

                       Computation: 89522 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 1.0706
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5440
                     Learning rate: 0.0004
                       Mean reward: 34.14
               Mean episode length: 454.05
       Episode_Reward/keep_balance: 0.4798
     Episode_Reward/rew_lin_vel_xy: 1.5996
      Episode_Reward/rew_ang_vel_z: 1.4270
    Episode_Reward/pen_base_height: -0.2553
      Episode_Reward/pen_lin_vel_z: -0.0441
     Episode_Reward/pen_ang_vel_xy: -0.0703
   Episode_Reward/pen_joint_torque: -0.0875
    Episode_Reward/pen_joint_accel: -0.0407
    Episode_Reward/pen_action_rate: -0.1123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0166
   Episode_Reward/pen_joint_powers: -0.0300
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2580
Episode_Reward/pen_flat_orientation: -0.1038
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.1261
   Episode_Reward/foot_landing_vel: -0.0561
   Episode_Reward/test_gait_reward: -0.4503
Metrics/base_velocity/error_vel_xy: 1.3180
Metrics/base_velocity/error_vel_yaw: 0.4494
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 1.10s
                        Total time: 973.63s
                               ETA: 2283.8s

################################################################################
                     [1m Learning iteration 897/3000 [0m                      

                       Computation: 89278 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 1.2579
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5441
                     Learning rate: 0.0009
                       Mean reward: 28.81
               Mean episode length: 418.15
       Episode_Reward/keep_balance: 0.4158
     Episode_Reward/rew_lin_vel_xy: 1.3204
      Episode_Reward/rew_ang_vel_z: 1.2488
    Episode_Reward/pen_base_height: -0.2406
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.0610
   Episode_Reward/pen_joint_torque: -0.0777
    Episode_Reward/pen_joint_accel: -0.0343
    Episode_Reward/pen_action_rate: -0.0958
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0263
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2192
Episode_Reward/pen_flat_orientation: -0.0960
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1087
   Episode_Reward/foot_landing_vel: -0.0482
   Episode_Reward/test_gait_reward: -0.3904
Metrics/base_velocity/error_vel_xy: 1.1587
Metrics/base_velocity/error_vel_yaw: 0.3824
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 1.10s
                        Total time: 974.73s
                               ETA: 2282.7s

################################################################################
                     [1m Learning iteration 898/3000 [0m                      

                       Computation: 88330 steps/s (collection: 0.986s, learning 0.126s)
               Value function loss: 1.1673
                    Surrogate loss: -0.0019
             Mean action noise std: 0.5440
                     Learning rate: 0.0009
                       Mean reward: 31.84
               Mean episode length: 433.61
       Episode_Reward/keep_balance: 0.4173
     Episode_Reward/rew_lin_vel_xy: 1.3205
      Episode_Reward/rew_ang_vel_z: 1.2366
    Episode_Reward/pen_base_height: -0.2421
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.0635
   Episode_Reward/pen_joint_torque: -0.0760
    Episode_Reward/pen_joint_accel: -0.0387
    Episode_Reward/pen_action_rate: -0.0986
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0153
   Episode_Reward/pen_joint_powers: -0.0266
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2260
Episode_Reward/pen_flat_orientation: -0.1023
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1169
   Episode_Reward/foot_landing_vel: -0.0534
   Episode_Reward/test_gait_reward: -0.3921
Metrics/base_velocity/error_vel_xy: 1.1852
Metrics/base_velocity/error_vel_yaw: 0.3973
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 1.11s
                        Total time: 975.85s
                               ETA: 2281.7s

################################################################################
                     [1m Learning iteration 899/3000 [0m                      

                       Computation: 90158 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 1.2791
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5436
                     Learning rate: 0.0006
                       Mean reward: 28.42
               Mean episode length: 417.72
       Episode_Reward/keep_balance: 0.4286
     Episode_Reward/rew_lin_vel_xy: 1.3172
      Episode_Reward/rew_ang_vel_z: 1.2813
    Episode_Reward/pen_base_height: -0.2469
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.0640
   Episode_Reward/pen_joint_torque: -0.0797
    Episode_Reward/pen_joint_accel: -0.0362
    Episode_Reward/pen_action_rate: -0.1002
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0270
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2288
Episode_Reward/pen_flat_orientation: -0.1003
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.1137
   Episode_Reward/foot_landing_vel: -0.0499
   Episode_Reward/test_gait_reward: -0.4011
Metrics/base_velocity/error_vel_xy: 1.2800
Metrics/base_velocity/error_vel_yaw: 0.3986
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 1.09s
                        Total time: 976.94s
                               ETA: 2280.6s

################################################################################
                     [1m Learning iteration 900/3000 [0m                      

                       Computation: 90963 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 1.1781
                    Surrogate loss: -0.0034
             Mean action noise std: 0.5435
                     Learning rate: 0.0009
                       Mean reward: 35.03
               Mean episode length: 430.97
       Episode_Reward/keep_balance: 0.4357
     Episode_Reward/rew_lin_vel_xy: 1.5164
      Episode_Reward/rew_ang_vel_z: 1.3063
    Episode_Reward/pen_base_height: -0.2407
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.0655
   Episode_Reward/pen_joint_torque: -0.0761
    Episode_Reward/pen_joint_accel: -0.0369
    Episode_Reward/pen_action_rate: -0.1024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0151
   Episode_Reward/pen_joint_powers: -0.0270
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2351
Episode_Reward/pen_flat_orientation: -0.0982
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1157
   Episode_Reward/foot_landing_vel: -0.0517
   Episode_Reward/test_gait_reward: -0.4062
Metrics/base_velocity/error_vel_xy: 1.1914
Metrics/base_velocity/error_vel_yaw: 0.4024
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 1.08s
                        Total time: 978.02s
                               ETA: 2279.5s

################################################################################
                     [1m Learning iteration 901/3000 [0m                      

                       Computation: 90824 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 1.0854
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5443
                     Learning rate: 0.0006
                       Mean reward: 29.73
               Mean episode length: 416.20
       Episode_Reward/keep_balance: 0.4185
     Episode_Reward/rew_lin_vel_xy: 1.3017
      Episode_Reward/rew_ang_vel_z: 1.2353
    Episode_Reward/pen_base_height: -0.2413
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.0656
   Episode_Reward/pen_joint_torque: -0.0773
    Episode_Reward/pen_joint_accel: -0.0376
    Episode_Reward/pen_action_rate: -0.0998
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0153
   Episode_Reward/pen_joint_powers: -0.0270
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2270
Episode_Reward/pen_flat_orientation: -0.0980
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1177
   Episode_Reward/foot_landing_vel: -0.0530
   Episode_Reward/test_gait_reward: -0.3948
Metrics/base_velocity/error_vel_xy: 1.2050
Metrics/base_velocity/error_vel_yaw: 0.4031
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 1.08s
                        Total time: 979.10s
                               ETA: 2278.4s

################################################################################
                     [1m Learning iteration 902/3000 [0m                      

                       Computation: 91408 steps/s (collection: 0.954s, learning 0.121s)
               Value function loss: 1.3101
                    Surrogate loss: -0.0021
             Mean action noise std: 0.5461
                     Learning rate: 0.0013
                       Mean reward: 37.93
               Mean episode length: 517.52
       Episode_Reward/keep_balance: 0.4722
     Episode_Reward/rew_lin_vel_xy: 1.5091
      Episode_Reward/rew_ang_vel_z: 1.4193
    Episode_Reward/pen_base_height: -0.2529
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.0698
   Episode_Reward/pen_joint_torque: -0.0876
    Episode_Reward/pen_joint_accel: -0.0432
    Episode_Reward/pen_action_rate: -0.1111
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0165
   Episode_Reward/pen_joint_powers: -0.0302
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2531
Episode_Reward/pen_flat_orientation: -0.0986
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1236
   Episode_Reward/foot_landing_vel: -0.0557
   Episode_Reward/test_gait_reward: -0.4437
Metrics/base_velocity/error_vel_xy: 1.3298
Metrics/base_velocity/error_vel_yaw: 0.4337
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 1.08s
                        Total time: 980.18s
                               ETA: 2277.3s

################################################################################
                     [1m Learning iteration 903/3000 [0m                      

                       Computation: 90151 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 1.0937
                    Surrogate loss: 0.0028
             Mean action noise std: 0.5469
                     Learning rate: 0.0003
                       Mean reward: 32.96
               Mean episode length: 441.74
       Episode_Reward/keep_balance: 0.4535
     Episode_Reward/rew_lin_vel_xy: 1.3977
      Episode_Reward/rew_ang_vel_z: 1.3715
    Episode_Reward/pen_base_height: -0.2450
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.0673
   Episode_Reward/pen_joint_torque: -0.0848
    Episode_Reward/pen_joint_accel: -0.0390
    Episode_Reward/pen_action_rate: -0.1074
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0158
   Episode_Reward/pen_joint_powers: -0.0288
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2419
Episode_Reward/pen_flat_orientation: -0.0969
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1216
   Episode_Reward/foot_landing_vel: -0.0549
   Episode_Reward/test_gait_reward: -0.4239
Metrics/base_velocity/error_vel_xy: 1.3105
Metrics/base_velocity/error_vel_yaw: 0.4092
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 1.09s
                        Total time: 981.27s
                               ETA: 2276.2s

################################################################################
                     [1m Learning iteration 904/3000 [0m                      

                       Computation: 92050 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 1.1158
                    Surrogate loss: -0.0027
             Mean action noise std: 0.5469
                     Learning rate: 0.0006
                       Mean reward: 31.26
               Mean episode length: 415.12
       Episode_Reward/keep_balance: 0.4874
     Episode_Reward/rew_lin_vel_xy: 1.6144
      Episode_Reward/rew_ang_vel_z: 1.4571
    Episode_Reward/pen_base_height: -0.2569
      Episode_Reward/pen_lin_vel_z: -0.0477
     Episode_Reward/pen_ang_vel_xy: -0.0718
   Episode_Reward/pen_joint_torque: -0.0943
    Episode_Reward/pen_joint_accel: -0.0459
    Episode_Reward/pen_action_rate: -0.1178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0177
   Episode_Reward/pen_joint_powers: -0.0322
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2642
Episode_Reward/pen_flat_orientation: -0.1018
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.1384
   Episode_Reward/foot_landing_vel: -0.0584
   Episode_Reward/test_gait_reward: -0.4589
Metrics/base_velocity/error_vel_xy: 1.3211
Metrics/base_velocity/error_vel_yaw: 0.4515
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 1.07s
                        Total time: 982.33s
                               ETA: 2275.1s

################################################################################
                     [1m Learning iteration 905/3000 [0m                      

                       Computation: 89488 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 1.1044
                    Surrogate loss: -0.0032
             Mean action noise std: 0.5471
                     Learning rate: 0.0013
                       Mean reward: 34.37
               Mean episode length: 465.29
       Episode_Reward/keep_balance: 0.4927
     Episode_Reward/rew_lin_vel_xy: 1.5117
      Episode_Reward/rew_ang_vel_z: 1.4701
    Episode_Reward/pen_base_height: -0.2614
      Episode_Reward/pen_lin_vel_z: -0.0454
     Episode_Reward/pen_ang_vel_xy: -0.0709
   Episode_Reward/pen_joint_torque: -0.0917
    Episode_Reward/pen_joint_accel: -0.0425
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0175
   Episode_Reward/pen_joint_powers: -0.0315
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2642
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1325
   Episode_Reward/foot_landing_vel: -0.0610
   Episode_Reward/test_gait_reward: -0.4613
Metrics/base_velocity/error_vel_xy: 1.4522
Metrics/base_velocity/error_vel_yaw: 0.4588
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 1.10s
                        Total time: 983.43s
                               ETA: 2274.1s

################################################################################
                     [1m Learning iteration 906/3000 [0m                      

                       Computation: 89377 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 1.0280
                    Surrogate loss: 0.0004
             Mean action noise std: 0.5482
                     Learning rate: 0.0004
                       Mean reward: 37.07
               Mean episode length: 473.46
       Episode_Reward/keep_balance: 0.4822
     Episode_Reward/rew_lin_vel_xy: 1.5303
      Episode_Reward/rew_ang_vel_z: 1.4430
    Episode_Reward/pen_base_height: -0.2505
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.0708
   Episode_Reward/pen_joint_torque: -0.0888
    Episode_Reward/pen_joint_accel: -0.0427
    Episode_Reward/pen_action_rate: -0.1139
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0165
   Episode_Reward/pen_joint_powers: -0.0302
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2602
Episode_Reward/pen_flat_orientation: -0.0972
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1184
   Episode_Reward/foot_landing_vel: -0.0563
   Episode_Reward/test_gait_reward: -0.4525
Metrics/base_velocity/error_vel_xy: 1.3814
Metrics/base_velocity/error_vel_yaw: 0.4483
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 1.10s
                        Total time: 984.53s
                               ETA: 2273.0s

################################################################################
                     [1m Learning iteration 907/3000 [0m                      

                       Computation: 91174 steps/s (collection: 0.957s, learning 0.121s)
               Value function loss: 1.0620
                    Surrogate loss: 0.0012
             Mean action noise std: 0.5492
                     Learning rate: 0.0002
                       Mean reward: 39.11
               Mean episode length: 509.54
       Episode_Reward/keep_balance: 0.5074
     Episode_Reward/rew_lin_vel_xy: 1.6823
      Episode_Reward/rew_ang_vel_z: 1.5065
    Episode_Reward/pen_base_height: -0.2614
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.0747
   Episode_Reward/pen_joint_torque: -0.0952
    Episode_Reward/pen_joint_accel: -0.0468
    Episode_Reward/pen_action_rate: -0.1249
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0187
   Episode_Reward/pen_joint_powers: -0.0333
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2793
Episode_Reward/pen_flat_orientation: -0.0986
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.1456
   Episode_Reward/foot_landing_vel: -0.0675
   Episode_Reward/test_gait_reward: -0.4780
Metrics/base_velocity/error_vel_xy: 1.4021
Metrics/base_velocity/error_vel_yaw: 0.4787
      Episode_Termination/time_out: 2.8333
  Episode_Termination/base_contact: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 1.08s
                        Total time: 985.61s
                               ETA: 2271.9s

################################################################################
                     [1m Learning iteration 908/3000 [0m                      

                       Computation: 91915 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.0689
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5496
                     Learning rate: 0.0004
                       Mean reward: 39.57
               Mean episode length: 548.60
       Episode_Reward/keep_balance: 0.5059
     Episode_Reward/rew_lin_vel_xy: 1.6169
      Episode_Reward/rew_ang_vel_z: 1.5106
    Episode_Reward/pen_base_height: -0.2620
      Episode_Reward/pen_lin_vel_z: -0.0504
     Episode_Reward/pen_ang_vel_xy: -0.0766
   Episode_Reward/pen_joint_torque: -0.0983
    Episode_Reward/pen_joint_accel: -0.0510
    Episode_Reward/pen_action_rate: -0.1255
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0189
   Episode_Reward/pen_joint_powers: -0.0340
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2785
Episode_Reward/pen_flat_orientation: -0.0999
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.1440
   Episode_Reward/foot_landing_vel: -0.0686
   Episode_Reward/test_gait_reward: -0.4775
Metrics/base_velocity/error_vel_xy: 1.3899
Metrics/base_velocity/error_vel_yaw: 0.4719
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 1.07s
                        Total time: 986.68s
                               ETA: 2270.8s

################################################################################
                     [1m Learning iteration 909/3000 [0m                      

                       Computation: 91818 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.0772
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5501
                     Learning rate: 0.0003
                       Mean reward: 35.46
               Mean episode length: 492.16
       Episode_Reward/keep_balance: 0.5438
     Episode_Reward/rew_lin_vel_xy: 1.5589
      Episode_Reward/rew_ang_vel_z: 1.6216
    Episode_Reward/pen_base_height: -0.2717
      Episode_Reward/pen_lin_vel_z: -0.0525
     Episode_Reward/pen_ang_vel_xy: -0.0813
   Episode_Reward/pen_joint_torque: -0.1073
    Episode_Reward/pen_joint_accel: -0.0516
    Episode_Reward/pen_action_rate: -0.1335
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0198
   Episode_Reward/pen_joint_powers: -0.0363
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2961
Episode_Reward/pen_flat_orientation: -0.1037
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1556
   Episode_Reward/foot_landing_vel: -0.0673
   Episode_Reward/test_gait_reward: -0.5089
Metrics/base_velocity/error_vel_xy: 1.7212
Metrics/base_velocity/error_vel_yaw: 0.5062
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 1.07s
                        Total time: 987.75s
                               ETA: 2269.7s

################################################################################
                     [1m Learning iteration 910/3000 [0m                      

                       Computation: 91224 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.0364
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5501
                     Learning rate: 0.0003
                       Mean reward: 32.06
               Mean episode length: 444.31
       Episode_Reward/keep_balance: 0.4742
     Episode_Reward/rew_lin_vel_xy: 1.5301
      Episode_Reward/rew_ang_vel_z: 1.4190
    Episode_Reward/pen_base_height: -0.2557
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.0704
   Episode_Reward/pen_joint_torque: -0.0867
    Episode_Reward/pen_joint_accel: -0.0420
    Episode_Reward/pen_action_rate: -0.1132
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0166
   Episode_Reward/pen_joint_powers: -0.0301
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2572
Episode_Reward/pen_flat_orientation: -0.0998
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1232
   Episode_Reward/foot_landing_vel: -0.0562
   Episode_Reward/test_gait_reward: -0.4451
Metrics/base_velocity/error_vel_xy: 1.3535
Metrics/base_velocity/error_vel_yaw: 0.4415
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 1.08s
                        Total time: 988.83s
                               ETA: 2268.6s

################################################################################
                     [1m Learning iteration 911/3000 [0m                      

                       Computation: 90794 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 1.1260
                    Surrogate loss: -0.0016
             Mean action noise std: 0.5497
                     Learning rate: 0.0006
                       Mean reward: 33.85
               Mean episode length: 496.19
       Episode_Reward/keep_balance: 0.5218
     Episode_Reward/rew_lin_vel_xy: 1.6823
      Episode_Reward/rew_ang_vel_z: 1.5521
    Episode_Reward/pen_base_height: -0.2663
      Episode_Reward/pen_lin_vel_z: -0.0511
     Episode_Reward/pen_ang_vel_xy: -0.0772
   Episode_Reward/pen_joint_torque: -0.1006
    Episode_Reward/pen_joint_accel: -0.0477
    Episode_Reward/pen_action_rate: -0.1272
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0191
   Episode_Reward/pen_joint_powers: -0.0347
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2839
Episode_Reward/pen_flat_orientation: -0.1032
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1531
   Episode_Reward/foot_landing_vel: -0.0658
   Episode_Reward/test_gait_reward: -0.4911
Metrics/base_velocity/error_vel_xy: 1.4419
Metrics/base_velocity/error_vel_yaw: 0.4929
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 1.08s
                        Total time: 989.91s
                               ETA: 2267.5s

################################################################################
                     [1m Learning iteration 912/3000 [0m                      

                       Computation: 91944 steps/s (collection: 0.948s, learning 0.121s)
               Value function loss: 1.3182
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5499
                     Learning rate: 0.0013
                       Mean reward: 41.02
               Mean episode length: 544.57
       Episode_Reward/keep_balance: 0.5019
     Episode_Reward/rew_lin_vel_xy: 1.6313
      Episode_Reward/rew_ang_vel_z: 1.4961
    Episode_Reward/pen_base_height: -0.2638
      Episode_Reward/pen_lin_vel_z: -0.0491
     Episode_Reward/pen_ang_vel_xy: -0.0747
   Episode_Reward/pen_joint_torque: -0.0962
    Episode_Reward/pen_joint_accel: -0.0491
    Episode_Reward/pen_action_rate: -0.1239
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0187
   Episode_Reward/pen_joint_powers: -0.0334
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2765
Episode_Reward/pen_flat_orientation: -0.1003
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1490
   Episode_Reward/foot_landing_vel: -0.0638
   Episode_Reward/test_gait_reward: -0.4751
Metrics/base_velocity/error_vel_xy: 1.3715
Metrics/base_velocity/error_vel_yaw: 0.4709
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 1.07s
                        Total time: 990.98s
                               ETA: 2266.3s

################################################################################
                     [1m Learning iteration 913/3000 [0m                      

                       Computation: 92176 steps/s (collection: 0.945s, learning 0.121s)
               Value function loss: 1.2252
                    Surrogate loss: 0.0069
             Mean action noise std: 0.5507
                     Learning rate: 0.0002
                       Mean reward: 34.04
               Mean episode length: 437.87
       Episode_Reward/keep_balance: 0.4729
     Episode_Reward/rew_lin_vel_xy: 1.5401
      Episode_Reward/rew_ang_vel_z: 1.4111
    Episode_Reward/pen_base_height: -0.2480
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.0700
   Episode_Reward/pen_joint_torque: -0.0836
    Episode_Reward/pen_joint_accel: -0.0419
    Episode_Reward/pen_action_rate: -0.1144
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0168
   Episode_Reward/pen_joint_powers: -0.0296
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2594
Episode_Reward/pen_flat_orientation: -0.0976
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1289
   Episode_Reward/foot_landing_vel: -0.0579
   Episode_Reward/test_gait_reward: -0.4434
Metrics/base_velocity/error_vel_xy: 1.3091
Metrics/base_velocity/error_vel_yaw: 0.4433
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 1.07s
                        Total time: 992.05s
                               ETA: 2265.2s

################################################################################
                     [1m Learning iteration 914/3000 [0m                      

                       Computation: 89691 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.9787
                    Surrogate loss: 0.0018
             Mean action noise std: 0.5509
                     Learning rate: 0.0002
                       Mean reward: 37.62
               Mean episode length: 504.87
       Episode_Reward/keep_balance: 0.5187
     Episode_Reward/rew_lin_vel_xy: 1.6072
      Episode_Reward/rew_ang_vel_z: 1.5341
    Episode_Reward/pen_base_height: -0.2696
      Episode_Reward/pen_lin_vel_z: -0.0528
     Episode_Reward/pen_ang_vel_xy: -0.0778
   Episode_Reward/pen_joint_torque: -0.1033
    Episode_Reward/pen_joint_accel: -0.0473
    Episode_Reward/pen_action_rate: -0.1279
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0192
   Episode_Reward/pen_joint_powers: -0.0353
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2839
Episode_Reward/pen_flat_orientation: -0.1012
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1557
   Episode_Reward/foot_landing_vel: -0.0672
   Episode_Reward/test_gait_reward: -0.4885
Metrics/base_velocity/error_vel_xy: 1.5181
Metrics/base_velocity/error_vel_yaw: 0.4937
      Episode_Termination/time_out: 2.6667
  Episode_Termination/base_contact: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 1.10s
                        Total time: 993.14s
                               ETA: 2264.1s

################################################################################
                     [1m Learning iteration 915/3000 [0m                      

                       Computation: 89856 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 1.0651
                    Surrogate loss: -0.0027
             Mean action noise std: 0.5514
                     Learning rate: 0.0004
                       Mean reward: 41.28
               Mean episode length: 518.21
       Episode_Reward/keep_balance: 0.4911
     Episode_Reward/rew_lin_vel_xy: 1.6441
      Episode_Reward/rew_ang_vel_z: 1.4619
    Episode_Reward/pen_base_height: -0.2633
      Episode_Reward/pen_lin_vel_z: -0.0459
     Episode_Reward/pen_ang_vel_xy: -0.0725
   Episode_Reward/pen_joint_torque: -0.0952
    Episode_Reward/pen_joint_accel: -0.0423
    Episode_Reward/pen_action_rate: -0.1182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0180
   Episode_Reward/pen_joint_powers: -0.0329
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2663
Episode_Reward/pen_flat_orientation: -0.1025
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.1426
   Episode_Reward/foot_landing_vel: -0.0595
   Episode_Reward/test_gait_reward: -0.4630
Metrics/base_velocity/error_vel_xy: 1.3585
Metrics/base_velocity/error_vel_yaw: 0.4588
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 1.09s
                        Total time: 994.24s
                               ETA: 2263.1s

################################################################################
                     [1m Learning iteration 916/3000 [0m                      

                       Computation: 89448 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 1.0218
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5518
                     Learning rate: 0.0003
                       Mean reward: 41.25
               Mean episode length: 549.60
       Episode_Reward/keep_balance: 0.5026
     Episode_Reward/rew_lin_vel_xy: 1.7355
      Episode_Reward/rew_ang_vel_z: 1.4920
    Episode_Reward/pen_base_height: -0.2653
      Episode_Reward/pen_lin_vel_z: -0.0509
     Episode_Reward/pen_ang_vel_xy: -0.0775
   Episode_Reward/pen_joint_torque: -0.1013
    Episode_Reward/pen_joint_accel: -0.0459
    Episode_Reward/pen_action_rate: -0.1252
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0193
   Episode_Reward/pen_joint_powers: -0.0350
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2782
Episode_Reward/pen_flat_orientation: -0.1052
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1592
   Episode_Reward/foot_landing_vel: -0.0649
   Episode_Reward/test_gait_reward: -0.4785
Metrics/base_velocity/error_vel_xy: 1.3493
Metrics/base_velocity/error_vel_yaw: 0.4746
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 1.10s
                        Total time: 995.34s
                               ETA: 2262.0s

################################################################################
                     [1m Learning iteration 917/3000 [0m                      

                       Computation: 90999 steps/s (collection: 0.959s, learning 0.121s)
               Value function loss: 1.2190
                    Surrogate loss: 0.0004
             Mean action noise std: 0.5523
                     Learning rate: 0.0004
                       Mean reward: 41.00
               Mean episode length: 545.72
       Episode_Reward/keep_balance: 0.5123
     Episode_Reward/rew_lin_vel_xy: 1.6350
      Episode_Reward/rew_ang_vel_z: 1.5396
    Episode_Reward/pen_base_height: -0.2659
      Episode_Reward/pen_lin_vel_z: -0.0482
     Episode_Reward/pen_ang_vel_xy: -0.0758
   Episode_Reward/pen_joint_torque: -0.0954
    Episode_Reward/pen_joint_accel: -0.0455
    Episode_Reward/pen_action_rate: -0.1244
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0182
   Episode_Reward/pen_joint_powers: -0.0331
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2786
Episode_Reward/pen_flat_orientation: -0.1050
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1422
   Episode_Reward/foot_landing_vel: -0.0633
   Episode_Reward/test_gait_reward: -0.4792
Metrics/base_velocity/error_vel_xy: 1.4471
Metrics/base_velocity/error_vel_yaw: 0.4697
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 1.08s
                        Total time: 996.42s
                               ETA: 2260.9s

################################################################################
                     [1m Learning iteration 918/3000 [0m                      

                       Computation: 92254 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 1.0959
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5527
                     Learning rate: 0.0006
                       Mean reward: 32.66
               Mean episode length: 432.62
       Episode_Reward/keep_balance: 0.4654
     Episode_Reward/rew_lin_vel_xy: 1.5369
      Episode_Reward/rew_ang_vel_z: 1.3891
    Episode_Reward/pen_base_height: -0.2522
      Episode_Reward/pen_lin_vel_z: -0.0447
     Episode_Reward/pen_ang_vel_xy: -0.0712
   Episode_Reward/pen_joint_torque: -0.0860
    Episode_Reward/pen_joint_accel: -0.0412
    Episode_Reward/pen_action_rate: -0.1127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0169
   Episode_Reward/pen_joint_powers: -0.0302
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2526
Episode_Reward/pen_flat_orientation: -0.1027
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1264
   Episode_Reward/foot_landing_vel: -0.0580
   Episode_Reward/test_gait_reward: -0.4396
Metrics/base_velocity/error_vel_xy: 1.3010
Metrics/base_velocity/error_vel_yaw: 0.4369
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 1.07s
                        Total time: 997.48s
                               ETA: 2259.8s

################################################################################
                     [1m Learning iteration 919/3000 [0m                      

                       Computation: 91062 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 1.2207
                    Surrogate loss: 0.0002
             Mean action noise std: 0.5527
                     Learning rate: 0.0004
                       Mean reward: 32.36
               Mean episode length: 475.85
       Episode_Reward/keep_balance: 0.5225
     Episode_Reward/rew_lin_vel_xy: 1.7145
      Episode_Reward/rew_ang_vel_z: 1.5404
    Episode_Reward/pen_base_height: -0.2765
      Episode_Reward/pen_lin_vel_z: -0.0496
     Episode_Reward/pen_ang_vel_xy: -0.0762
   Episode_Reward/pen_joint_torque: -0.0983
    Episode_Reward/pen_joint_accel: -0.0478
    Episode_Reward/pen_action_rate: -0.1281
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0190
   Episode_Reward/pen_joint_powers: -0.0341
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2892
Episode_Reward/pen_flat_orientation: -0.1073
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.1448
   Episode_Reward/foot_landing_vel: -0.0634
   Episode_Reward/test_gait_reward: -0.4894
Metrics/base_velocity/error_vel_xy: 1.4980
Metrics/base_velocity/error_vel_yaw: 0.5012
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 1.08s
                        Total time: 998.56s
                               ETA: 2258.7s

################################################################################
                     [1m Learning iteration 920/3000 [0m                      

                       Computation: 91384 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 1.3823
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5531
                     Learning rate: 0.0004
                       Mean reward: 32.09
               Mean episode length: 441.83
       Episode_Reward/keep_balance: 0.4350
     Episode_Reward/rew_lin_vel_xy: 1.3525
      Episode_Reward/rew_ang_vel_z: 1.3024
    Episode_Reward/pen_base_height: -0.2449
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.0674
   Episode_Reward/pen_joint_torque: -0.0817
    Episode_Reward/pen_joint_accel: -0.0414
    Episode_Reward/pen_action_rate: -0.1044
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0157
   Episode_Reward/pen_joint_powers: -0.0283
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2379
Episode_Reward/pen_flat_orientation: -0.1016
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.1188
   Episode_Reward/foot_landing_vel: -0.0516
   Episode_Reward/test_gait_reward: -0.4106
Metrics/base_velocity/error_vel_xy: 1.2446
Metrics/base_velocity/error_vel_yaw: 0.4041
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 1.08s
                        Total time: 999.64s
                               ETA: 2257.6s

################################################################################
                     [1m Learning iteration 921/3000 [0m                      

                       Computation: 91796 steps/s (collection: 0.950s, learning 0.121s)
               Value function loss: 1.3624
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5537
                     Learning rate: 0.0009
                       Mean reward: 31.56
               Mean episode length: 412.90
       Episode_Reward/keep_balance: 0.4463
     Episode_Reward/rew_lin_vel_xy: 1.5302
      Episode_Reward/rew_ang_vel_z: 1.3207
    Episode_Reward/pen_base_height: -0.2531
      Episode_Reward/pen_lin_vel_z: -0.0425
     Episode_Reward/pen_ang_vel_xy: -0.0682
   Episode_Reward/pen_joint_torque: -0.0825
    Episode_Reward/pen_joint_accel: -0.0395
    Episode_Reward/pen_action_rate: -0.1081
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0162
   Episode_Reward/pen_joint_powers: -0.0289
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2430
Episode_Reward/pen_flat_orientation: -0.1025
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.1264
   Episode_Reward/foot_landing_vel: -0.0561
   Episode_Reward/test_gait_reward: -0.4228
Metrics/base_velocity/error_vel_xy: 1.1732
Metrics/base_velocity/error_vel_yaw: 0.4269
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 1.07s
                        Total time: 1000.71s
                               ETA: 2256.5s

################################################################################
                     [1m Learning iteration 922/3000 [0m                      

                       Computation: 91431 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 1.1109
                    Surrogate loss: 0.0009
             Mean action noise std: 0.5533
                     Learning rate: 0.0002
                       Mean reward: 33.78
               Mean episode length: 476.94
       Episode_Reward/keep_balance: 0.4617
     Episode_Reward/rew_lin_vel_xy: 1.4365
      Episode_Reward/rew_ang_vel_z: 1.3676
    Episode_Reward/pen_base_height: -0.2547
      Episode_Reward/pen_lin_vel_z: -0.0437
     Episode_Reward/pen_ang_vel_xy: -0.0698
   Episode_Reward/pen_joint_torque: -0.0869
    Episode_Reward/pen_joint_accel: -0.0403
    Episode_Reward/pen_action_rate: -0.1123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0165
   Episode_Reward/pen_joint_powers: -0.0300
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2539
Episode_Reward/pen_flat_orientation: -0.1005
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.1278
   Episode_Reward/foot_landing_vel: -0.0569
   Episode_Reward/test_gait_reward: -0.4325
Metrics/base_velocity/error_vel_xy: 1.3807
Metrics/base_velocity/error_vel_yaw: 0.4392
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 1.08s
                        Total time: 1001.78s
                               ETA: 2255.4s

################################################################################
                     [1m Learning iteration 923/3000 [0m                      

                       Computation: 91542 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.0301
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5533
                     Learning rate: 0.0004
                       Mean reward: 34.50
               Mean episode length: 477.55
       Episode_Reward/keep_balance: 0.4675
     Episode_Reward/rew_lin_vel_xy: 1.4894
      Episode_Reward/rew_ang_vel_z: 1.3941
    Episode_Reward/pen_base_height: -0.2592
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.0678
   Episode_Reward/pen_joint_torque: -0.0906
    Episode_Reward/pen_joint_accel: -0.0396
    Episode_Reward/pen_action_rate: -0.1123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0163
   Episode_Reward/pen_joint_powers: -0.0304
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2531
Episode_Reward/pen_flat_orientation: -0.1002
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1286
   Episode_Reward/foot_landing_vel: -0.0571
   Episode_Reward/test_gait_reward: -0.4372
Metrics/base_velocity/error_vel_xy: 1.3182
Metrics/base_velocity/error_vel_yaw: 0.4386
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 1.07s
                        Total time: 1002.86s
                               ETA: 2254.3s

################################################################################
                     [1m Learning iteration 924/3000 [0m                      

                       Computation: 91463 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.1211
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5542
                     Learning rate: 0.0003
                       Mean reward: 32.35
               Mean episode length: 471.70
       Episode_Reward/keep_balance: 0.4615
     Episode_Reward/rew_lin_vel_xy: 1.4836
      Episode_Reward/rew_ang_vel_z: 1.3657
    Episode_Reward/pen_base_height: -0.2541
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.0702
   Episode_Reward/pen_joint_torque: -0.0869
    Episode_Reward/pen_joint_accel: -0.0449
    Episode_Reward/pen_action_rate: -0.1127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0169
   Episode_Reward/pen_joint_powers: -0.0300
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2547
Episode_Reward/pen_flat_orientation: -0.1065
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1311
   Episode_Reward/foot_landing_vel: -0.0565
   Episode_Reward/test_gait_reward: -0.4338
Metrics/base_velocity/error_vel_xy: 1.3030
Metrics/base_velocity/error_vel_yaw: 0.4398
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 1.07s
                        Total time: 1003.93s
                               ETA: 2253.1s

################################################################################
                     [1m Learning iteration 925/3000 [0m                      

                       Computation: 91467 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.1360
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5550
                     Learning rate: 0.0004
                       Mean reward: 39.76
               Mean episode length: 533.17
       Episode_Reward/keep_balance: 0.4845
     Episode_Reward/rew_lin_vel_xy: 1.5506
      Episode_Reward/rew_ang_vel_z: 1.4312
    Episode_Reward/pen_base_height: -0.2627
      Episode_Reward/pen_lin_vel_z: -0.0473
     Episode_Reward/pen_ang_vel_xy: -0.0744
   Episode_Reward/pen_joint_torque: -0.0938
    Episode_Reward/pen_joint_accel: -0.0421
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0178
   Episode_Reward/pen_joint_powers: -0.0323
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2669
Episode_Reward/pen_flat_orientation: -0.1025
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1370
   Episode_Reward/foot_landing_vel: -0.0601
   Episode_Reward/test_gait_reward: -0.4573
Metrics/base_velocity/error_vel_xy: 1.4115
Metrics/base_velocity/error_vel_yaw: 0.4646
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 1.07s
                        Total time: 1005.01s
                               ETA: 2252.0s

################################################################################
                     [1m Learning iteration 926/3000 [0m                      

                       Computation: 90706 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 1.1225
                    Surrogate loss: 0.0007
             Mean action noise std: 0.5558
                     Learning rate: 0.0002
                       Mean reward: 30.33
               Mean episode length: 415.30
       Episode_Reward/keep_balance: 0.4592
     Episode_Reward/rew_lin_vel_xy: 1.4762
      Episode_Reward/rew_ang_vel_z: 1.3664
    Episode_Reward/pen_base_height: -0.2505
      Episode_Reward/pen_lin_vel_z: -0.0451
     Episode_Reward/pen_ang_vel_xy: -0.0710
   Episode_Reward/pen_joint_torque: -0.0867
    Episode_Reward/pen_joint_accel: -0.0423
    Episode_Reward/pen_action_rate: -0.1123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0166
   Episode_Reward/pen_joint_powers: -0.0300
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2517
Episode_Reward/pen_flat_orientation: -0.0967
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.1256
   Episode_Reward/foot_landing_vel: -0.0562
   Episode_Reward/test_gait_reward: -0.4292
Metrics/base_velocity/error_vel_xy: 1.2932
Metrics/base_velocity/error_vel_yaw: 0.4314
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 7.2500
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 1.08s
                        Total time: 1006.09s
                               ETA: 2251.0s

################################################################################
                     [1m Learning iteration 927/3000 [0m                      

                       Computation: 91955 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 1.0553
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5563
                     Learning rate: 0.0004
                       Mean reward: 31.05
               Mean episode length: 461.24
       Episode_Reward/keep_balance: 0.4612
     Episode_Reward/rew_lin_vel_xy: 1.4559
      Episode_Reward/rew_ang_vel_z: 1.3678
    Episode_Reward/pen_base_height: -0.2512
      Episode_Reward/pen_lin_vel_z: -0.0456
     Episode_Reward/pen_ang_vel_xy: -0.0727
   Episode_Reward/pen_joint_torque: -0.0885
    Episode_Reward/pen_joint_accel: -0.0440
    Episode_Reward/pen_action_rate: -0.1131
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0169
   Episode_Reward/pen_joint_powers: -0.0306
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2552
Episode_Reward/pen_flat_orientation: -0.0999
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1294
   Episode_Reward/foot_landing_vel: -0.0574
   Episode_Reward/test_gait_reward: -0.4345
Metrics/base_velocity/error_vel_xy: 1.3588
Metrics/base_velocity/error_vel_yaw: 0.4397
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 1.07s
                        Total time: 1007.16s
                               ETA: 2249.8s

################################################################################
                     [1m Learning iteration 928/3000 [0m                      

                       Computation: 91305 steps/s (collection: 0.955s, learning 0.121s)
               Value function loss: 1.1190
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5577
                     Learning rate: 0.0009
                       Mean reward: 35.21
               Mean episode length: 470.83
       Episode_Reward/keep_balance: 0.4624
     Episode_Reward/rew_lin_vel_xy: 1.5218
      Episode_Reward/rew_ang_vel_z: 1.3846
    Episode_Reward/pen_base_height: -0.2546
      Episode_Reward/pen_lin_vel_z: -0.0447
     Episode_Reward/pen_ang_vel_xy: -0.0705
   Episode_Reward/pen_joint_torque: -0.0896
    Episode_Reward/pen_joint_accel: -0.0427
    Episode_Reward/pen_action_rate: -0.1135
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0170
   Episode_Reward/pen_joint_powers: -0.0308
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2548
Episode_Reward/pen_flat_orientation: -0.1007
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1304
   Episode_Reward/foot_landing_vel: -0.0580
   Episode_Reward/test_gait_reward: -0.4373
Metrics/base_velocity/error_vel_xy: 1.2893
Metrics/base_velocity/error_vel_yaw: 0.4304
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 1.08s
                        Total time: 1008.24s
                               ETA: 2248.7s

################################################################################
                     [1m Learning iteration 929/3000 [0m                      

                       Computation: 91814 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.1425
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5577
                     Learning rate: 0.0009
                       Mean reward: 38.74
               Mean episode length: 513.46
       Episode_Reward/keep_balance: 0.5003
     Episode_Reward/rew_lin_vel_xy: 1.6500
      Episode_Reward/rew_ang_vel_z: 1.4892
    Episode_Reward/pen_base_height: -0.2601
      Episode_Reward/pen_lin_vel_z: -0.0468
     Episode_Reward/pen_ang_vel_xy: -0.0765
   Episode_Reward/pen_joint_torque: -0.0945
    Episode_Reward/pen_joint_accel: -0.0475
    Episode_Reward/pen_action_rate: -0.1228
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0183
   Episode_Reward/pen_joint_powers: -0.0328
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2773
Episode_Reward/pen_flat_orientation: -0.1046
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1403
   Episode_Reward/foot_landing_vel: -0.0631
   Episode_Reward/test_gait_reward: -0.4729
Metrics/base_velocity/error_vel_xy: 1.3703
Metrics/base_velocity/error_vel_yaw: 0.4707
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 1.07s
                        Total time: 1009.31s
                               ETA: 2247.6s

################################################################################
                     [1m Learning iteration 930/3000 [0m                      

                       Computation: 91205 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.0795
                    Surrogate loss: 0.0023
             Mean action noise std: 0.5575
                     Learning rate: 0.0001
                       Mean reward: 36.79
               Mean episode length: 527.28
       Episode_Reward/keep_balance: 0.5014
     Episode_Reward/rew_lin_vel_xy: 1.5407
      Episode_Reward/rew_ang_vel_z: 1.4893
    Episode_Reward/pen_base_height: -0.2617
      Episode_Reward/pen_lin_vel_z: -0.0475
     Episode_Reward/pen_ang_vel_xy: -0.0765
   Episode_Reward/pen_joint_torque: -0.0978
    Episode_Reward/pen_joint_accel: -0.0439
    Episode_Reward/pen_action_rate: -0.1234
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0181
   Episode_Reward/pen_joint_powers: -0.0334
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2767
Episode_Reward/pen_flat_orientation: -0.1038
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1398
   Episode_Reward/foot_landing_vel: -0.0603
   Episode_Reward/test_gait_reward: -0.4719
Metrics/base_velocity/error_vel_xy: 1.4749
Metrics/base_velocity/error_vel_yaw: 0.4724
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 1.08s
                        Total time: 1010.38s
                               ETA: 2246.5s

################################################################################
                     [1m Learning iteration 931/3000 [0m                      

                       Computation: 90418 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.9771
                    Surrogate loss: 0.0032
             Mean action noise std: 0.5579
                     Learning rate: 0.0001
                       Mean reward: 31.82
               Mean episode length: 449.67
       Episode_Reward/keep_balance: 0.4472
     Episode_Reward/rew_lin_vel_xy: 1.4042
      Episode_Reward/rew_ang_vel_z: 1.3251
    Episode_Reward/pen_base_height: -0.2574
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.0706
   Episode_Reward/pen_joint_torque: -0.0829
    Episode_Reward/pen_joint_accel: -0.0400
    Episode_Reward/pen_action_rate: -0.1099
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0165
   Episode_Reward/pen_joint_powers: -0.0292
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2494
Episode_Reward/pen_flat_orientation: -0.1060
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1297
   Episode_Reward/foot_landing_vel: -0.0535
   Episode_Reward/test_gait_reward: -0.4243
Metrics/base_velocity/error_vel_xy: 1.3005
Metrics/base_velocity/error_vel_yaw: 0.4256
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 1.09s
                        Total time: 1011.47s
                               ETA: 2245.4s

################################################################################
                     [1m Learning iteration 932/3000 [0m                      

                       Computation: 90776 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 1.0099
                    Surrogate loss: 0.0085
             Mean action noise std: 0.5580
                     Learning rate: 0.0000
                       Mean reward: 39.21
               Mean episode length: 512.07
       Episode_Reward/keep_balance: 0.4800
     Episode_Reward/rew_lin_vel_xy: 1.6169
      Episode_Reward/rew_ang_vel_z: 1.4328
    Episode_Reward/pen_base_height: -0.2590
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.0736
   Episode_Reward/pen_joint_torque: -0.0874
    Episode_Reward/pen_joint_accel: -0.0428
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0168
   Episode_Reward/pen_joint_powers: -0.0305
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2650
Episode_Reward/pen_flat_orientation: -0.1022
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.1288
   Episode_Reward/foot_landing_vel: -0.0546
   Episode_Reward/test_gait_reward: -0.4493
Metrics/base_velocity/error_vel_xy: 1.3240
Metrics/base_velocity/error_vel_yaw: 0.4501
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 1.08s
                        Total time: 1012.55s
                               ETA: 2244.3s

################################################################################
                     [1m Learning iteration 933/3000 [0m                      

                       Computation: 89914 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 1.0396
                    Surrogate loss: 0.0051
             Mean action noise std: 0.5581
                     Learning rate: 0.0000
                       Mean reward: 32.14
               Mean episode length: 467.55
       Episode_Reward/keep_balance: 0.5338
     Episode_Reward/rew_lin_vel_xy: 1.6729
      Episode_Reward/rew_ang_vel_z: 1.5823
    Episode_Reward/pen_base_height: -0.2660
      Episode_Reward/pen_lin_vel_z: -0.0518
     Episode_Reward/pen_ang_vel_xy: -0.0815
   Episode_Reward/pen_joint_torque: -0.1035
    Episode_Reward/pen_joint_accel: -0.0497
    Episode_Reward/pen_action_rate: -0.1330
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0196
   Episode_Reward/pen_joint_powers: -0.0359
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2958
Episode_Reward/pen_flat_orientation: -0.1035
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1470
   Episode_Reward/foot_landing_vel: -0.0664
   Episode_Reward/test_gait_reward: -0.5044
Metrics/base_velocity/error_vel_xy: 1.5479
Metrics/base_velocity/error_vel_yaw: 0.5051
      Episode_Termination/time_out: 3.0833
  Episode_Termination/base_contact: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 1.09s
                        Total time: 1013.65s
                               ETA: 2243.3s

################################################################################
                     [1m Learning iteration 934/3000 [0m                      

                       Computation: 90044 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.9576
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5581
                     Learning rate: 0.0001
                       Mean reward: 29.63
               Mean episode length: 430.88
       Episode_Reward/keep_balance: 0.4412
     Episode_Reward/rew_lin_vel_xy: 1.4019
      Episode_Reward/rew_ang_vel_z: 1.3057
    Episode_Reward/pen_base_height: -0.2461
      Episode_Reward/pen_lin_vel_z: -0.0402
     Episode_Reward/pen_ang_vel_xy: -0.0684
   Episode_Reward/pen_joint_torque: -0.0804
    Episode_Reward/pen_joint_accel: -0.0403
    Episode_Reward/pen_action_rate: -0.1069
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0157
   Episode_Reward/pen_joint_powers: -0.0279
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2436
Episode_Reward/pen_flat_orientation: -0.1005
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1178
   Episode_Reward/foot_landing_vel: -0.0505
   Episode_Reward/test_gait_reward: -0.4164
Metrics/base_velocity/error_vel_xy: 1.2652
Metrics/base_velocity/error_vel_yaw: 0.4224
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 1.09s
                        Total time: 1014.74s
                               ETA: 2242.2s

################################################################################
                     [1m Learning iteration 935/3000 [0m                      

                       Computation: 90027 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 1.0634
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5581
                     Learning rate: 0.0003
                       Mean reward: 33.17
               Mean episode length: 459.23
       Episode_Reward/keep_balance: 0.4680
     Episode_Reward/rew_lin_vel_xy: 1.4834
      Episode_Reward/rew_ang_vel_z: 1.3890
    Episode_Reward/pen_base_height: -0.2577
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.0712
   Episode_Reward/pen_joint_torque: -0.0888
    Episode_Reward/pen_joint_accel: -0.0390
    Episode_Reward/pen_action_rate: -0.1141
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0168
   Episode_Reward/pen_joint_powers: -0.0308
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2583
Episode_Reward/pen_flat_orientation: -0.1000
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1301
   Episode_Reward/foot_landing_vel: -0.0541
   Episode_Reward/test_gait_reward: -0.4417
Metrics/base_velocity/error_vel_xy: 1.3277
Metrics/base_velocity/error_vel_yaw: 0.4432
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 1.09s
                        Total time: 1015.83s
                               ETA: 2241.1s

################################################################################
                     [1m Learning iteration 936/3000 [0m                      

                       Computation: 89342 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 1.0841
                    Surrogate loss: -0.0028
             Mean action noise std: 0.5580
                     Learning rate: 0.0006
                       Mean reward: 34.62
               Mean episode length: 505.67
       Episode_Reward/keep_balance: 0.5424
     Episode_Reward/rew_lin_vel_xy: 1.6082
      Episode_Reward/rew_ang_vel_z: 1.6125
    Episode_Reward/pen_base_height: -0.2616
      Episode_Reward/pen_lin_vel_z: -0.0525
     Episode_Reward/pen_ang_vel_xy: -0.0800
   Episode_Reward/pen_joint_torque: -0.1061
    Episode_Reward/pen_joint_accel: -0.0498
    Episode_Reward/pen_action_rate: -0.1343
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0197
   Episode_Reward/pen_joint_powers: -0.0362
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2991
Episode_Reward/pen_flat_orientation: -0.1010
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1533
   Episode_Reward/foot_landing_vel: -0.0675
   Episode_Reward/test_gait_reward: -0.5081
Metrics/base_velocity/error_vel_xy: 1.6027
Metrics/base_velocity/error_vel_yaw: 0.5104
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 1.10s
                        Total time: 1016.93s
                               ETA: 2240.1s

################################################################################
                     [1m Learning iteration 937/3000 [0m                      

                       Computation: 91226 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.0822
                    Surrogate loss: -0.0039
             Mean action noise std: 0.5575
                     Learning rate: 0.0013
                       Mean reward: 36.72
               Mean episode length: 517.03
       Episode_Reward/keep_balance: 0.5113
     Episode_Reward/rew_lin_vel_xy: 1.5919
      Episode_Reward/rew_ang_vel_z: 1.5175
    Episode_Reward/pen_base_height: -0.2646
      Episode_Reward/pen_lin_vel_z: -0.0486
     Episode_Reward/pen_ang_vel_xy: -0.0798
   Episode_Reward/pen_joint_torque: -0.0981
    Episode_Reward/pen_joint_accel: -0.0473
    Episode_Reward/pen_action_rate: -0.1272
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0187
   Episode_Reward/pen_joint_powers: -0.0339
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2854
Episode_Reward/pen_flat_orientation: -0.1024
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1448
   Episode_Reward/foot_landing_vel: -0.0601
   Episode_Reward/test_gait_reward: -0.4814
Metrics/base_velocity/error_vel_xy: 1.4733
Metrics/base_velocity/error_vel_yaw: 0.4844
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 1.08s
                        Total time: 1018.01s
                               ETA: 2239.0s

################################################################################
                     [1m Learning iteration 938/3000 [0m                      

                       Computation: 91044 steps/s (collection: 0.958s, learning 0.121s)
               Value function loss: 1.2391
                    Surrogate loss: -0.0002
             Mean action noise std: 0.5572
                     Learning rate: 0.0009
                       Mean reward: 30.91
               Mean episode length: 436.20
       Episode_Reward/keep_balance: 0.4577
     Episode_Reward/rew_lin_vel_xy: 1.4883
      Episode_Reward/rew_ang_vel_z: 1.3574
    Episode_Reward/pen_base_height: -0.2563
      Episode_Reward/pen_lin_vel_z: -0.0427
     Episode_Reward/pen_ang_vel_xy: -0.0718
   Episode_Reward/pen_joint_torque: -0.0862
    Episode_Reward/pen_joint_accel: -0.0392
    Episode_Reward/pen_action_rate: -0.1122
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0165
   Episode_Reward/pen_joint_powers: -0.0297
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2570
Episode_Reward/pen_flat_orientation: -0.1009
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1295
   Episode_Reward/foot_landing_vel: -0.0552
   Episode_Reward/test_gait_reward: -0.4322
Metrics/base_velocity/error_vel_xy: 1.2598
Metrics/base_velocity/error_vel_yaw: 0.4368
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 1.08s
                        Total time: 1019.09s
                               ETA: 2237.9s

################################################################################
                     [1m Learning iteration 939/3000 [0m                      

                       Computation: 91061 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 1.2863
                    Surrogate loss: -0.0011
             Mean action noise std: 0.5577
                     Learning rate: 0.0006
                       Mean reward: 41.53
               Mean episode length: 526.44
       Episode_Reward/keep_balance: 0.5038
     Episode_Reward/rew_lin_vel_xy: 1.7038
      Episode_Reward/rew_ang_vel_z: 1.5084
    Episode_Reward/pen_base_height: -0.2620
      Episode_Reward/pen_lin_vel_z: -0.0464
     Episode_Reward/pen_ang_vel_xy: -0.0745
   Episode_Reward/pen_joint_torque: -0.0964
    Episode_Reward/pen_joint_accel: -0.0472
    Episode_Reward/pen_action_rate: -0.1227
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0180
   Episode_Reward/pen_joint_powers: -0.0329
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2764
Episode_Reward/pen_flat_orientation: -0.0991
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.1373
   Episode_Reward/foot_landing_vel: -0.0582
   Episode_Reward/test_gait_reward: -0.4786
Metrics/base_velocity/error_vel_xy: 1.3736
Metrics/base_velocity/error_vel_yaw: 0.4671
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 1.08s
                        Total time: 1020.17s
                               ETA: 2236.8s

################################################################################
                     [1m Learning iteration 940/3000 [0m                      

                       Computation: 91855 steps/s (collection: 0.949s, learning 0.121s)
               Value function loss: 1.0845
                    Surrogate loss: 0.0017
             Mean action noise std: 0.5580
                     Learning rate: 0.0003
                       Mean reward: 35.46
               Mean episode length: 463.27
       Episode_Reward/keep_balance: 0.4811
     Episode_Reward/rew_lin_vel_xy: 1.5272
      Episode_Reward/rew_ang_vel_z: 1.4294
    Episode_Reward/pen_base_height: -0.2626
      Episode_Reward/pen_lin_vel_z: -0.0457
     Episode_Reward/pen_ang_vel_xy: -0.0742
   Episode_Reward/pen_joint_torque: -0.0918
    Episode_Reward/pen_joint_accel: -0.0441
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0177
   Episode_Reward/pen_joint_powers: -0.0317
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2685
Episode_Reward/pen_flat_orientation: -0.1015
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1388
   Episode_Reward/foot_landing_vel: -0.0571
   Episode_Reward/test_gait_reward: -0.4522
Metrics/base_velocity/error_vel_xy: 1.3640
Metrics/base_velocity/error_vel_yaw: 0.4553
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 1.07s
                        Total time: 1021.24s
                               ETA: 2235.7s

################################################################################
                     [1m Learning iteration 941/3000 [0m                      

                       Computation: 91735 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 1.0780
                    Surrogate loss: -0.0008
             Mean action noise std: 0.5583
                     Learning rate: 0.0003
                       Mean reward: 35.22
               Mean episode length: 519.37
       Episode_Reward/keep_balance: 0.5178
     Episode_Reward/rew_lin_vel_xy: 1.5648
      Episode_Reward/rew_ang_vel_z: 1.5426
    Episode_Reward/pen_base_height: -0.2624
      Episode_Reward/pen_lin_vel_z: -0.0486
     Episode_Reward/pen_ang_vel_xy: -0.0801
   Episode_Reward/pen_joint_torque: -0.0986
    Episode_Reward/pen_joint_accel: -0.0432
    Episode_Reward/pen_action_rate: -0.1283
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0188
   Episode_Reward/pen_joint_powers: -0.0341
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.2881
Episode_Reward/pen_flat_orientation: -0.1016
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1474
   Episode_Reward/foot_landing_vel: -0.0614
   Episode_Reward/test_gait_reward: -0.4856
Metrics/base_velocity/error_vel_xy: 1.5792
Metrics/base_velocity/error_vel_yaw: 0.4849
      Episode_Termination/time_out: 2.8750
  Episode_Termination/base_contact: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 1.07s
                        Total time: 1022.31s
                               ETA: 2234.5s

################################################################################
                     [1m Learning iteration 942/3000 [0m                      

                       Computation: 91955 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.1118
                    Surrogate loss: -0.0028
             Mean action noise std: 0.5578
                     Learning rate: 0.0006
                       Mean reward: 37.26
               Mean episode length: 512.99
       Episode_Reward/keep_balance: 0.4558
     Episode_Reward/rew_lin_vel_xy: 1.5124
      Episode_Reward/rew_ang_vel_z: 1.3578
    Episode_Reward/pen_base_height: -0.2510
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.0709
   Episode_Reward/pen_joint_torque: -0.0845
    Episode_Reward/pen_joint_accel: -0.0380
    Episode_Reward/pen_action_rate: -0.1101
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0292
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2510
Episode_Reward/pen_flat_orientation: -0.0995
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1200
   Episode_Reward/foot_landing_vel: -0.0516
   Episode_Reward/test_gait_reward: -0.4297
Metrics/base_velocity/error_vel_xy: 1.2712
Metrics/base_velocity/error_vel_yaw: 0.4273
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 1.07s
                        Total time: 1023.38s
                               ETA: 2233.4s

################################################################################
                     [1m Learning iteration 943/3000 [0m                      

                       Computation: 91105 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 1.0770
                    Surrogate loss: 0.0032
             Mean action noise std: 0.5577
                     Learning rate: 0.0001
                       Mean reward: 39.48
               Mean episode length: 531.39
       Episode_Reward/keep_balance: 0.5080
     Episode_Reward/rew_lin_vel_xy: 1.5892
      Episode_Reward/rew_ang_vel_z: 1.5026
    Episode_Reward/pen_base_height: -0.2660
      Episode_Reward/pen_lin_vel_z: -0.0511
     Episode_Reward/pen_ang_vel_xy: -0.0821
   Episode_Reward/pen_joint_torque: -0.1013
    Episode_Reward/pen_joint_accel: -0.0461
    Episode_Reward/pen_action_rate: -0.1276
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0193
   Episode_Reward/pen_joint_powers: -0.0353
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2834
Episode_Reward/pen_flat_orientation: -0.1032
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1500
   Episode_Reward/foot_landing_vel: -0.0656
   Episode_Reward/test_gait_reward: -0.4810
Metrics/base_velocity/error_vel_xy: 1.4995
Metrics/base_velocity/error_vel_yaw: 0.4848
      Episode_Termination/time_out: 2.2917
  Episode_Termination/base_contact: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 1.08s
                        Total time: 1024.46s
                               ETA: 2232.3s

################################################################################
                     [1m Learning iteration 944/3000 [0m                      

                       Computation: 91560 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 1.0580
                    Surrogate loss: -0.0030
             Mean action noise std: 0.5587
                     Learning rate: 0.0003
                       Mean reward: 42.28
               Mean episode length: 558.03
       Episode_Reward/keep_balance: 0.5317
     Episode_Reward/rew_lin_vel_xy: 1.7670
      Episode_Reward/rew_ang_vel_z: 1.5750
    Episode_Reward/pen_base_height: -0.2780
      Episode_Reward/pen_lin_vel_z: -0.0518
     Episode_Reward/pen_ang_vel_xy: -0.0837
   Episode_Reward/pen_joint_torque: -0.1047
    Episode_Reward/pen_joint_accel: -0.0507
    Episode_Reward/pen_action_rate: -0.1336
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0204
   Episode_Reward/pen_joint_powers: -0.0365
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2986
Episode_Reward/pen_flat_orientation: -0.1080
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1601
   Episode_Reward/foot_landing_vel: -0.0672
   Episode_Reward/test_gait_reward: -0.5076
Metrics/base_velocity/error_vel_xy: 1.4654
Metrics/base_velocity/error_vel_yaw: 0.5045
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 1.07s
                        Total time: 1025.53s
                               ETA: 2231.2s

################################################################################
                     [1m Learning iteration 945/3000 [0m                      

                       Computation: 90101 steps/s (collection: 0.961s, learning 0.130s)
               Value function loss: 1.0779
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5595
                     Learning rate: 0.0006
                       Mean reward: 35.24
               Mean episode length: 486.90
       Episode_Reward/keep_balance: 0.5014
     Episode_Reward/rew_lin_vel_xy: 1.6046
      Episode_Reward/rew_ang_vel_z: 1.4955
    Episode_Reward/pen_base_height: -0.2691
      Episode_Reward/pen_lin_vel_z: -0.0477
     Episode_Reward/pen_ang_vel_xy: -0.0779
   Episode_Reward/pen_joint_torque: -0.0960
    Episode_Reward/pen_joint_accel: -0.0454
    Episode_Reward/pen_action_rate: -0.1229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0182
   Episode_Reward/pen_joint_powers: -0.0331
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2788
Episode_Reward/pen_flat_orientation: -0.1044
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1408
   Episode_Reward/foot_landing_vel: -0.0604
   Episode_Reward/test_gait_reward: -0.4713
Metrics/base_velocity/error_vel_xy: 1.4132
Metrics/base_velocity/error_vel_yaw: 0.4714
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 1.09s
                        Total time: 1026.62s
                               ETA: 2230.1s

################################################################################
                     [1m Learning iteration 946/3000 [0m                      

                       Computation: 91564 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.2302
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5604
                     Learning rate: 0.0013
                       Mean reward: 34.51
               Mean episode length: 495.92
       Episode_Reward/keep_balance: 0.5096
     Episode_Reward/rew_lin_vel_xy: 1.5789
      Episode_Reward/rew_ang_vel_z: 1.5030
    Episode_Reward/pen_base_height: -0.2629
      Episode_Reward/pen_lin_vel_z: -0.0490
     Episode_Reward/pen_ang_vel_xy: -0.0793
   Episode_Reward/pen_joint_torque: -0.1007
    Episode_Reward/pen_joint_accel: -0.0488
    Episode_Reward/pen_action_rate: -0.1267
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0190
   Episode_Reward/pen_joint_powers: -0.0345
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2865
Episode_Reward/pen_flat_orientation: -0.1041
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1434
   Episode_Reward/foot_landing_vel: -0.0619
   Episode_Reward/test_gait_reward: -0.4841
Metrics/base_velocity/error_vel_xy: 1.4617
Metrics/base_velocity/error_vel_yaw: 0.4916
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 1.07s
                        Total time: 1027.70s
                               ETA: 2229.0s

################################################################################
                     [1m Learning iteration 947/3000 [0m                      

                       Computation: 91054 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 1.3402
                    Surrogate loss: 0.0030
             Mean action noise std: 0.5610
                     Learning rate: 0.0002
                       Mean reward: 39.62
               Mean episode length: 531.24
       Episode_Reward/keep_balance: 0.5295
     Episode_Reward/rew_lin_vel_xy: 1.7498
      Episode_Reward/rew_ang_vel_z: 1.5755
    Episode_Reward/pen_base_height: -0.2705
      Episode_Reward/pen_lin_vel_z: -0.0518
     Episode_Reward/pen_ang_vel_xy: -0.0814
   Episode_Reward/pen_joint_torque: -0.1047
    Episode_Reward/pen_joint_accel: -0.0525
    Episode_Reward/pen_action_rate: -0.1319
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0198
   Episode_Reward/pen_joint_powers: -0.0360
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2960
Episode_Reward/pen_flat_orientation: -0.1046
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.1529
   Episode_Reward/foot_landing_vel: -0.0660
   Episode_Reward/test_gait_reward: -0.5031
Metrics/base_velocity/error_vel_xy: 1.4294
Metrics/base_velocity/error_vel_yaw: 0.4983
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 1.08s
                        Total time: 1028.78s
                               ETA: 2227.9s

################################################################################
                     [1m Learning iteration 948/3000 [0m                      

                       Computation: 92456 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 1.1872
                    Surrogate loss: -0.0019
             Mean action noise std: 0.5611
                     Learning rate: 0.0004
                       Mean reward: 45.96
               Mean episode length: 592.04
       Episode_Reward/keep_balance: 0.5621
     Episode_Reward/rew_lin_vel_xy: 1.8903
      Episode_Reward/rew_ang_vel_z: 1.6594
    Episode_Reward/pen_base_height: -0.2850
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.0847
   Episode_Reward/pen_joint_torque: -0.1094
    Episode_Reward/pen_joint_accel: -0.0552
    Episode_Reward/pen_action_rate: -0.1397
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0207
   Episode_Reward/pen_joint_powers: -0.0377
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3154
Episode_Reward/pen_flat_orientation: -0.1078
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1612
   Episode_Reward/foot_landing_vel: -0.0691
   Episode_Reward/test_gait_reward: -0.5298
Metrics/base_velocity/error_vel_xy: 1.5552
Metrics/base_velocity/error_vel_yaw: 0.5364
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 1.06s
                        Total time: 1029.84s
                               ETA: 2226.8s

################################################################################
                     [1m Learning iteration 949/3000 [0m                      

                       Computation: 91360 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 1.1362
                    Surrogate loss: -0.0029
             Mean action noise std: 0.5620
                     Learning rate: 0.0009
                       Mean reward: 36.54
               Mean episode length: 497.95
       Episode_Reward/keep_balance: 0.5068
     Episode_Reward/rew_lin_vel_xy: 1.6423
      Episode_Reward/rew_ang_vel_z: 1.4966
    Episode_Reward/pen_base_height: -0.2601
      Episode_Reward/pen_lin_vel_z: -0.0500
     Episode_Reward/pen_ang_vel_xy: -0.0794
   Episode_Reward/pen_joint_torque: -0.0991
    Episode_Reward/pen_joint_accel: -0.0505
    Episode_Reward/pen_action_rate: -0.1284
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0193
   Episode_Reward/pen_joint_powers: -0.0346
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2880
Episode_Reward/pen_flat_orientation: -0.1003
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.1496
   Episode_Reward/foot_landing_vel: -0.0669
   Episode_Reward/test_gait_reward: -0.4814
Metrics/base_velocity/error_vel_xy: 1.3753
Metrics/base_velocity/error_vel_yaw: 0.4862
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 1.08s
                        Total time: 1030.92s
                               ETA: 2225.7s

################################################################################
                     [1m Learning iteration 950/3000 [0m                      

                       Computation: 91782 steps/s (collection: 0.950s, learning 0.121s)
               Value function loss: 1.1334
                    Surrogate loss: 0.0024
             Mean action noise std: 0.5624
                     Learning rate: 0.0002
                       Mean reward: 43.60
               Mean episode length: 603.14
       Episode_Reward/keep_balance: 0.5569
     Episode_Reward/rew_lin_vel_xy: 1.8337
      Episode_Reward/rew_ang_vel_z: 1.6629
    Episode_Reward/pen_base_height: -0.2823
      Episode_Reward/pen_lin_vel_z: -0.0540
     Episode_Reward/pen_ang_vel_xy: -0.0851
   Episode_Reward/pen_joint_torque: -0.1106
    Episode_Reward/pen_joint_accel: -0.0528
    Episode_Reward/pen_action_rate: -0.1395
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0204
   Episode_Reward/pen_joint_powers: -0.0376
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.3123
Episode_Reward/pen_flat_orientation: -0.1060
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.1580
   Episode_Reward/foot_landing_vel: -0.0686
   Episode_Reward/test_gait_reward: -0.5251
Metrics/base_velocity/error_vel_xy: 1.5610
Metrics/base_velocity/error_vel_yaw: 0.5217
      Episode_Termination/time_out: 2.5833
  Episode_Termination/base_contact: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 1.07s
                        Total time: 1031.99s
                               ETA: 2224.6s

################################################################################
                     [1m Learning iteration 951/3000 [0m                      

                       Computation: 88543 steps/s (collection: 0.986s, learning 0.124s)
               Value function loss: 1.0459
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5625
                     Learning rate: 0.0004
                       Mean reward: 32.97
               Mean episode length: 469.83
       Episode_Reward/keep_balance: 0.4798
     Episode_Reward/rew_lin_vel_xy: 1.5125
      Episode_Reward/rew_ang_vel_z: 1.4265
    Episode_Reward/pen_base_height: -0.2573
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.0745
   Episode_Reward/pen_joint_torque: -0.0910
    Episode_Reward/pen_joint_accel: -0.0416
    Episode_Reward/pen_action_rate: -0.1163
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0169
   Episode_Reward/pen_joint_powers: -0.0311
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2667
Episode_Reward/pen_flat_orientation: -0.1035
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1283
   Episode_Reward/foot_landing_vel: -0.0542
   Episode_Reward/test_gait_reward: -0.4516
Metrics/base_velocity/error_vel_xy: 1.3391
Metrics/base_velocity/error_vel_yaw: 0.4519
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 1.11s
                        Total time: 1033.10s
                               ETA: 2223.5s

################################################################################
                     [1m Learning iteration 952/3000 [0m                      

                       Computation: 91333 steps/s (collection: 0.951s, learning 0.125s)
               Value function loss: 1.0355
                    Surrogate loss: -0.0036
             Mean action noise std: 0.5622
                     Learning rate: 0.0009
                       Mean reward: 40.15
               Mean episode length: 558.89
       Episode_Reward/keep_balance: 0.5644
     Episode_Reward/rew_lin_vel_xy: 1.7540
      Episode_Reward/rew_ang_vel_z: 1.6863
    Episode_Reward/pen_base_height: -0.2805
      Episode_Reward/pen_lin_vel_z: -0.0548
     Episode_Reward/pen_ang_vel_xy: -0.0859
   Episode_Reward/pen_joint_torque: -0.1100
    Episode_Reward/pen_joint_accel: -0.0540
    Episode_Reward/pen_action_rate: -0.1411
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0212
   Episode_Reward/pen_joint_powers: -0.0383
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.3159
Episode_Reward/pen_flat_orientation: -0.1077
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1715
   Episode_Reward/foot_landing_vel: -0.0708
   Episode_Reward/test_gait_reward: -0.5346
Metrics/base_velocity/error_vel_xy: 1.6398
Metrics/base_velocity/error_vel_yaw: 0.5240
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 1.08s
                        Total time: 1034.17s
                               ETA: 2222.4s

################################################################################
                     [1m Learning iteration 953/3000 [0m                      

                       Computation: 92455 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 1.0947
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5621
                     Learning rate: 0.0006
                       Mean reward: 37.80
               Mean episode length: 541.38
       Episode_Reward/keep_balance: 0.5118
     Episode_Reward/rew_lin_vel_xy: 1.5820
      Episode_Reward/rew_ang_vel_z: 1.4990
    Episode_Reward/pen_base_height: -0.2676
      Episode_Reward/pen_lin_vel_z: -0.0500
     Episode_Reward/pen_ang_vel_xy: -0.0784
   Episode_Reward/pen_joint_torque: -0.0998
    Episode_Reward/pen_joint_accel: -0.0481
    Episode_Reward/pen_action_rate: -0.1270
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0190
   Episode_Reward/pen_joint_powers: -0.0345
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2877
Episode_Reward/pen_flat_orientation: -0.1066
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1512
   Episode_Reward/foot_landing_vel: -0.0620
   Episode_Reward/test_gait_reward: -0.4834
Metrics/base_velocity/error_vel_xy: 1.5054
Metrics/base_velocity/error_vel_yaw: 0.5008
      Episode_Termination/time_out: 2.2917
  Episode_Termination/base_contact: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 1.06s
                        Total time: 1035.24s
                               ETA: 2221.3s

################################################################################
                     [1m Learning iteration 954/3000 [0m                      

                       Computation: 91990 steps/s (collection: 0.944s, learning 0.125s)
               Value function loss: 1.0684
                    Surrogate loss: -0.0034
             Mean action noise std: 0.5607
                     Learning rate: 0.0009
                       Mean reward: 39.24
               Mean episode length: 565.84
       Episode_Reward/keep_balance: 0.5542
     Episode_Reward/rew_lin_vel_xy: 1.6571
      Episode_Reward/rew_ang_vel_z: 1.6405
    Episode_Reward/pen_base_height: -0.2763
      Episode_Reward/pen_lin_vel_z: -0.0540
     Episode_Reward/pen_ang_vel_xy: -0.0890
   Episode_Reward/pen_joint_torque: -0.1074
    Episode_Reward/pen_joint_accel: -0.0555
    Episode_Reward/pen_action_rate: -0.1407
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0215
   Episode_Reward/pen_joint_powers: -0.0378
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3143
Episode_Reward/pen_flat_orientation: -0.1102
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1676
   Episode_Reward/foot_landing_vel: -0.0704
   Episode_Reward/test_gait_reward: -0.5257
Metrics/base_velocity/error_vel_xy: 1.6707
Metrics/base_velocity/error_vel_yaw: 0.5295
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 1.07s
                        Total time: 1036.31s
                               ETA: 2220.2s

################################################################################
                     [1m Learning iteration 955/3000 [0m                      

                       Computation: 92135 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 1.1914
                    Surrogate loss: -0.0024
             Mean action noise std: 0.5603
                     Learning rate: 0.0013
                       Mean reward: 45.30
               Mean episode length: 569.38
       Episode_Reward/keep_balance: 0.5485
     Episode_Reward/rew_lin_vel_xy: 1.8421
      Episode_Reward/rew_ang_vel_z: 1.6342
    Episode_Reward/pen_base_height: -0.2706
      Episode_Reward/pen_lin_vel_z: -0.0502
     Episode_Reward/pen_ang_vel_xy: -0.0842
   Episode_Reward/pen_joint_torque: -0.1028
    Episode_Reward/pen_joint_accel: -0.0514
    Episode_Reward/pen_action_rate: -0.1363
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0199
   Episode_Reward/pen_joint_powers: -0.0357
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.3091
Episode_Reward/pen_flat_orientation: -0.1034
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1511
   Episode_Reward/foot_landing_vel: -0.0670
   Episode_Reward/test_gait_reward: -0.5162
Metrics/base_velocity/error_vel_xy: 1.4965
Metrics/base_velocity/error_vel_yaw: 0.5140
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 1.07s
                        Total time: 1037.37s
                               ETA: 2219.1s

################################################################################
                     [1m Learning iteration 956/3000 [0m                      

                       Computation: 92024 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 1.1746
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5615
                     Learning rate: 0.0009
                       Mean reward: 45.17
               Mean episode length: 615.00
       Episode_Reward/keep_balance: 0.6485
     Episode_Reward/rew_lin_vel_xy: 2.0817
      Episode_Reward/rew_ang_vel_z: 1.9209
    Episode_Reward/pen_base_height: -0.3127
      Episode_Reward/pen_lin_vel_z: -0.0608
     Episode_Reward/pen_ang_vel_xy: -0.0996
   Episode_Reward/pen_joint_torque: -0.1293
    Episode_Reward/pen_joint_accel: -0.0593
    Episode_Reward/pen_action_rate: -0.1644
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0243
   Episode_Reward/pen_joint_powers: -0.0444
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.3684
Episode_Reward/pen_flat_orientation: -0.1150
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1870
   Episode_Reward/foot_landing_vel: -0.0791
   Episode_Reward/test_gait_reward: -0.6089
Metrics/base_velocity/error_vel_xy: 1.8145
Metrics/base_velocity/error_vel_yaw: 0.6116
      Episode_Termination/time_out: 2.7917
  Episode_Termination/base_contact: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 1.07s
                        Total time: 1038.44s
                               ETA: 2217.9s

################################################################################
                     [1m Learning iteration 957/3000 [0m                      

                       Computation: 91577 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.0817
                    Surrogate loss: 0.0000
             Mean action noise std: 0.5616
                     Learning rate: 0.0003
                       Mean reward: 35.73
               Mean episode length: 517.20
       Episode_Reward/keep_balance: 0.5330
     Episode_Reward/rew_lin_vel_xy: 1.6667
      Episode_Reward/rew_ang_vel_z: 1.5748
    Episode_Reward/pen_base_height: -0.2699
      Episode_Reward/pen_lin_vel_z: -0.0509
     Episode_Reward/pen_ang_vel_xy: -0.0823
   Episode_Reward/pen_joint_torque: -0.1035
    Episode_Reward/pen_joint_accel: -0.0497
    Episode_Reward/pen_action_rate: -0.1339
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0199
   Episode_Reward/pen_joint_powers: -0.0358
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.3040
Episode_Reward/pen_flat_orientation: -0.1050
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1522
   Episode_Reward/foot_landing_vel: -0.0675
   Episode_Reward/test_gait_reward: -0.5079
Metrics/base_velocity/error_vel_xy: 1.5671
Metrics/base_velocity/error_vel_yaw: 0.5088
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 1.07s
                        Total time: 1039.51s
                               ETA: 2216.8s

################################################################################
                     [1m Learning iteration 958/3000 [0m                      

                       Computation: 90924 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 1.1266
                    Surrogate loss: -0.0029
             Mean action noise std: 0.5608
                     Learning rate: 0.0006
                       Mean reward: 35.72
               Mean episode length: 483.91
       Episode_Reward/keep_balance: 0.5297
     Episode_Reward/rew_lin_vel_xy: 1.7068
      Episode_Reward/rew_ang_vel_z: 1.5797
    Episode_Reward/pen_base_height: -0.2717
      Episode_Reward/pen_lin_vel_z: -0.0496
     Episode_Reward/pen_ang_vel_xy: -0.0823
   Episode_Reward/pen_joint_torque: -0.0990
    Episode_Reward/pen_joint_accel: -0.0451
    Episode_Reward/pen_action_rate: -0.1306
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0194
   Episode_Reward/pen_joint_powers: -0.0346
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2985
Episode_Reward/pen_flat_orientation: -0.1126
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.1537
   Episode_Reward/foot_landing_vel: -0.0621
   Episode_Reward/test_gait_reward: -0.5019
Metrics/base_velocity/error_vel_xy: 1.5114
Metrics/base_velocity/error_vel_yaw: 0.4977
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 1.08s
                        Total time: 1040.60s
                               ETA: 2215.7s

################################################################################
                     [1m Learning iteration 959/3000 [0m                      

                       Computation: 91333 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 1.1818
                    Surrogate loss: 0.0016
             Mean action noise std: 0.5607
                     Learning rate: 0.0002
                       Mean reward: 35.31
               Mean episode length: 522.57
       Episode_Reward/keep_balance: 0.5498
     Episode_Reward/rew_lin_vel_xy: 1.6428
      Episode_Reward/rew_ang_vel_z: 1.6309
    Episode_Reward/pen_base_height: -0.2806
      Episode_Reward/pen_lin_vel_z: -0.0555
     Episode_Reward/pen_ang_vel_xy: -0.0891
   Episode_Reward/pen_joint_torque: -0.1108
    Episode_Reward/pen_joint_accel: -0.0515
    Episode_Reward/pen_action_rate: -0.1409
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0213
   Episode_Reward/pen_joint_powers: -0.0385
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.3114
Episode_Reward/pen_flat_orientation: -0.1110
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.1676
   Episode_Reward/foot_landing_vel: -0.0721
   Episode_Reward/test_gait_reward: -0.5248
Metrics/base_velocity/error_vel_xy: 1.6469
Metrics/base_velocity/error_vel_yaw: 0.5216
      Episode_Termination/time_out: 2.5417
  Episode_Termination/base_contact: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 1.08s
                        Total time: 1041.67s
                               ETA: 2214.6s

################################################################################
                     [1m Learning iteration 960/3000 [0m                      

                       Computation: 90878 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 1.1229
                    Surrogate loss: -0.0031
             Mean action noise std: 0.5617
                     Learning rate: 0.0004
                       Mean reward: 38.72
               Mean episode length: 506.85
       Episode_Reward/keep_balance: 0.5240
     Episode_Reward/rew_lin_vel_xy: 1.7372
      Episode_Reward/rew_ang_vel_z: 1.5647
    Episode_Reward/pen_base_height: -0.2751
      Episode_Reward/pen_lin_vel_z: -0.0488
     Episode_Reward/pen_ang_vel_xy: -0.0809
   Episode_Reward/pen_joint_torque: -0.0987
    Episode_Reward/pen_joint_accel: -0.0482
    Episode_Reward/pen_action_rate: -0.1290
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0189
   Episode_Reward/pen_joint_powers: -0.0342
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2944
Episode_Reward/pen_flat_orientation: -0.1129
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1431
   Episode_Reward/foot_landing_vel: -0.0617
   Episode_Reward/test_gait_reward: -0.4960
Metrics/base_velocity/error_vel_xy: 1.4285
Metrics/base_velocity/error_vel_yaw: 0.4886
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 1.08s
                        Total time: 1042.75s
                               ETA: 2213.5s

################################################################################
                     [1m Learning iteration 961/3000 [0m                      

                       Computation: 90471 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 1.1330
                    Surrogate loss: -0.0029
             Mean action noise std: 0.5624
                     Learning rate: 0.0009
                       Mean reward: 42.86
               Mean episode length: 562.43
       Episode_Reward/keep_balance: 0.5704
     Episode_Reward/rew_lin_vel_xy: 1.9368
      Episode_Reward/rew_ang_vel_z: 1.6820
    Episode_Reward/pen_base_height: -0.2807
      Episode_Reward/pen_lin_vel_z: -0.0541
     Episode_Reward/pen_ang_vel_xy: -0.0853
   Episode_Reward/pen_joint_torque: -0.1100
    Episode_Reward/pen_joint_accel: -0.0517
    Episode_Reward/pen_action_rate: -0.1428
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0215
   Episode_Reward/pen_joint_powers: -0.0384
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3226
Episode_Reward/pen_flat_orientation: -0.1084
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1698
   Episode_Reward/foot_landing_vel: -0.0697
   Episode_Reward/test_gait_reward: -0.5416
Metrics/base_velocity/error_vel_xy: 1.5529
Metrics/base_velocity/error_vel_yaw: 0.5453
      Episode_Termination/time_out: 3.0000
  Episode_Termination/base_contact: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 1.09s
                        Total time: 1043.84s
                               ETA: 2212.5s

################################################################################
                     [1m Learning iteration 962/3000 [0m                      

                       Computation: 90635 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 1.2720
                    Surrogate loss: -0.0030
             Mean action noise std: 0.5617
                     Learning rate: 0.0009
                       Mean reward: 35.19
               Mean episode length: 482.02
       Episode_Reward/keep_balance: 0.5104
     Episode_Reward/rew_lin_vel_xy: 1.6279
      Episode_Reward/rew_ang_vel_z: 1.5077
    Episode_Reward/pen_base_height: -0.2693
      Episode_Reward/pen_lin_vel_z: -0.0486
     Episode_Reward/pen_ang_vel_xy: -0.0809
   Episode_Reward/pen_joint_torque: -0.0990
    Episode_Reward/pen_joint_accel: -0.0455
    Episode_Reward/pen_action_rate: -0.1280
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0191
   Episode_Reward/pen_joint_powers: -0.0344
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2888
Episode_Reward/pen_flat_orientation: -0.1066
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1503
   Episode_Reward/foot_landing_vel: -0.0618
   Episode_Reward/test_gait_reward: -0.4865
Metrics/base_velocity/error_vel_xy: 1.4644
Metrics/base_velocity/error_vel_yaw: 0.4888
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 1.08s
                        Total time: 1044.92s
                               ETA: 2211.4s

################################################################################
                     [1m Learning iteration 963/3000 [0m                      

                       Computation: 90784 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 1.2925
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5621
                     Learning rate: 0.0013
                       Mean reward: 41.42
               Mean episode length: 561.41
       Episode_Reward/keep_balance: 0.5097
     Episode_Reward/rew_lin_vel_xy: 1.6470
      Episode_Reward/rew_ang_vel_z: 1.5190
    Episode_Reward/pen_base_height: -0.2631
      Episode_Reward/pen_lin_vel_z: -0.0477
     Episode_Reward/pen_ang_vel_xy: -0.0775
   Episode_Reward/pen_joint_torque: -0.0960
    Episode_Reward/pen_joint_accel: -0.0442
    Episode_Reward/pen_action_rate: -0.1252
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0185
   Episode_Reward/pen_joint_powers: -0.0334
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2848
Episode_Reward/pen_flat_orientation: -0.1051
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1449
   Episode_Reward/foot_landing_vel: -0.0613
   Episode_Reward/test_gait_reward: -0.4799
Metrics/base_velocity/error_vel_xy: 1.4494
Metrics/base_velocity/error_vel_yaw: 0.4774
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 1.08s
                        Total time: 1046.01s
                               ETA: 2210.3s

################################################################################
                     [1m Learning iteration 964/3000 [0m                      

                       Computation: 91687 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 1.2828
                    Surrogate loss: 0.0025
             Mean action noise std: 0.5627
                     Learning rate: 0.0003
                       Mean reward: 45.75
               Mean episode length: 592.92
       Episode_Reward/keep_balance: 0.5590
     Episode_Reward/rew_lin_vel_xy: 1.8143
      Episode_Reward/rew_ang_vel_z: 1.6549
    Episode_Reward/pen_base_height: -0.2889
      Episode_Reward/pen_lin_vel_z: -0.0537
     Episode_Reward/pen_ang_vel_xy: -0.0849
   Episode_Reward/pen_joint_torque: -0.1093
    Episode_Reward/pen_joint_accel: -0.0504
    Episode_Reward/pen_action_rate: -0.1403
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0213
   Episode_Reward/pen_joint_powers: -0.0383
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3157
Episode_Reward/pen_flat_orientation: -0.1162
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1691
   Episode_Reward/foot_landing_vel: -0.0707
   Episode_Reward/test_gait_reward: -0.5322
Metrics/base_velocity/error_vel_xy: 1.5374
Metrics/base_velocity/error_vel_yaw: 0.5334
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 1.07s
                        Total time: 1047.08s
                               ETA: 2209.2s

################################################################################
                     [1m Learning iteration 965/3000 [0m                      

                       Computation: 91661 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 1.0218
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5628
                     Learning rate: 0.0003
                       Mean reward: 39.36
               Mean episode length: 532.83
       Episode_Reward/keep_balance: 0.5344
     Episode_Reward/rew_lin_vel_xy: 1.7405
      Episode_Reward/rew_ang_vel_z: 1.5805
    Episode_Reward/pen_base_height: -0.2775
      Episode_Reward/pen_lin_vel_z: -0.0510
     Episode_Reward/pen_ang_vel_xy: -0.0815
   Episode_Reward/pen_joint_torque: -0.1045
    Episode_Reward/pen_joint_accel: -0.0523
    Episode_Reward/pen_action_rate: -0.1335
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0202
   Episode_Reward/pen_joint_powers: -0.0362
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.3019
Episode_Reward/pen_flat_orientation: -0.1097
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.1592
   Episode_Reward/foot_landing_vel: -0.0714
   Episode_Reward/test_gait_reward: -0.5095
Metrics/base_velocity/error_vel_xy: 1.4673
Metrics/base_velocity/error_vel_yaw: 0.5103
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 1.07s
                        Total time: 1048.15s
                               ETA: 2208.1s

################################################################################
                     [1m Learning iteration 966/3000 [0m                      

                       Computation: 92350 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 1.0322
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5630
                     Learning rate: 0.0003
                       Mean reward: 44.44
               Mean episode length: 602.90
       Episode_Reward/keep_balance: 0.6139
     Episode_Reward/rew_lin_vel_xy: 1.9953
      Episode_Reward/rew_ang_vel_z: 1.8460
    Episode_Reward/pen_base_height: -0.2955
      Episode_Reward/pen_lin_vel_z: -0.0606
     Episode_Reward/pen_ang_vel_xy: -0.0934
   Episode_Reward/pen_joint_torque: -0.1234
    Episode_Reward/pen_joint_accel: -0.0565
    Episode_Reward/pen_action_rate: -0.1549
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0230
   Episode_Reward/pen_joint_powers: -0.0426
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3446
Episode_Reward/pen_flat_orientation: -0.1125
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1800
   Episode_Reward/foot_landing_vel: -0.0776
   Episode_Reward/test_gait_reward: -0.5867
Metrics/base_velocity/error_vel_xy: 1.7621
Metrics/base_velocity/error_vel_yaw: 0.5585
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 1.06s
                        Total time: 1049.22s
                               ETA: 2206.9s

################################################################################
                     [1m Learning iteration 967/3000 [0m                      

                       Computation: 91752 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 1.0817
                    Surrogate loss: -0.0011
             Mean action noise std: 0.5632
                     Learning rate: 0.0006
                       Mean reward: 40.18
               Mean episode length: 556.88
       Episode_Reward/keep_balance: 0.6344
     Episode_Reward/rew_lin_vel_xy: 2.1887
      Episode_Reward/rew_ang_vel_z: 1.8785
    Episode_Reward/pen_base_height: -0.3024
      Episode_Reward/pen_lin_vel_z: -0.0616
     Episode_Reward/pen_ang_vel_xy: -0.0963
   Episode_Reward/pen_joint_torque: -0.1236
    Episode_Reward/pen_joint_accel: -0.0586
    Episode_Reward/pen_action_rate: -0.1606
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0239
   Episode_Reward/pen_joint_powers: -0.0433
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3616
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1940
   Episode_Reward/foot_landing_vel: -0.0790
   Episode_Reward/test_gait_reward: -0.6067
Metrics/base_velocity/error_vel_xy: 1.7260
Metrics/base_velocity/error_vel_yaw: 0.6003
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 1.07s
                        Total time: 1050.29s
                               ETA: 2205.8s

################################################################################
                     [1m Learning iteration 968/3000 [0m                      

                       Computation: 91324 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 1.1296
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5639
                     Learning rate: 0.0004
                       Mean reward: 48.67
               Mean episode length: 619.06
       Episode_Reward/keep_balance: 0.6501
     Episode_Reward/rew_lin_vel_xy: 2.2458
      Episode_Reward/rew_ang_vel_z: 1.9463
    Episode_Reward/pen_base_height: -0.3020
      Episode_Reward/pen_lin_vel_z: -0.0634
     Episode_Reward/pen_ang_vel_xy: -0.0954
   Episode_Reward/pen_joint_torque: -0.1259
    Episode_Reward/pen_joint_accel: -0.0633
    Episode_Reward/pen_action_rate: -0.1624
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0241
   Episode_Reward/pen_joint_powers: -0.0442
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.3652
Episode_Reward/pen_flat_orientation: -0.1130
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.1905
   Episode_Reward/foot_landing_vel: -0.0796
   Episode_Reward/test_gait_reward: -0.6191
Metrics/base_velocity/error_vel_xy: 1.7173
Metrics/base_velocity/error_vel_yaw: 0.6003
      Episode_Termination/time_out: 2.7917
  Episode_Termination/base_contact: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 1.08s
                        Total time: 1051.36s
                               ETA: 2204.7s

################################################################################
                     [1m Learning iteration 969/3000 [0m                      

                       Computation: 91650 steps/s (collection: 0.951s, learning 0.121s)
               Value function loss: 1.0723
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5640
                     Learning rate: 0.0009
                       Mean reward: 36.99
               Mean episode length: 507.83
       Episode_Reward/keep_balance: 0.5180
     Episode_Reward/rew_lin_vel_xy: 1.6570
      Episode_Reward/rew_ang_vel_z: 1.5504
    Episode_Reward/pen_base_height: -0.2802
      Episode_Reward/pen_lin_vel_z: -0.0471
     Episode_Reward/pen_ang_vel_xy: -0.0787
   Episode_Reward/pen_joint_torque: -0.0974
    Episode_Reward/pen_joint_accel: -0.0428
    Episode_Reward/pen_action_rate: -0.1257
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0183
   Episode_Reward/pen_joint_powers: -0.0336
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2863
Episode_Reward/pen_flat_orientation: -0.1100
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.1370
   Episode_Reward/foot_landing_vel: -0.0591
   Episode_Reward/test_gait_reward: -0.4910
Metrics/base_velocity/error_vel_xy: 1.4799
Metrics/base_velocity/error_vel_yaw: 0.4788
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 1.07s
                        Total time: 1052.44s
                               ETA: 2203.6s

################################################################################
                     [1m Learning iteration 970/3000 [0m                      

                       Computation: 91857 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.0536
                    Surrogate loss: 0.0024
             Mean action noise std: 0.5642
                     Learning rate: 0.0003
                       Mean reward: 43.41
               Mean episode length: 603.01
       Episode_Reward/keep_balance: 0.5950
     Episode_Reward/rew_lin_vel_xy: 1.9686
      Episode_Reward/rew_ang_vel_z: 1.7649
    Episode_Reward/pen_base_height: -0.2912
      Episode_Reward/pen_lin_vel_z: -0.0569
     Episode_Reward/pen_ang_vel_xy: -0.0906
   Episode_Reward/pen_joint_torque: -0.1152
    Episode_Reward/pen_joint_accel: -0.0563
    Episode_Reward/pen_action_rate: -0.1505
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0230
   Episode_Reward/pen_joint_powers: -0.0408
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3397
Episode_Reward/pen_flat_orientation: -0.1136
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1816
   Episode_Reward/foot_landing_vel: -0.0785
   Episode_Reward/test_gait_reward: -0.5691
Metrics/base_velocity/error_vel_xy: 1.6689
Metrics/base_velocity/error_vel_yaw: 0.5644
      Episode_Termination/time_out: 2.7917
  Episode_Termination/base_contact: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 1.07s
                        Total time: 1053.51s
                               ETA: 2202.5s

################################################################################
                     [1m Learning iteration 971/3000 [0m                      

                       Computation: 91213 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.0731
                    Surrogate loss: -0.0021
             Mean action noise std: 0.5643
                     Learning rate: 0.0006
                       Mean reward: 45.02
               Mean episode length: 601.98
       Episode_Reward/keep_balance: 0.6463
     Episode_Reward/rew_lin_vel_xy: 2.1342
      Episode_Reward/rew_ang_vel_z: 1.9259
    Episode_Reward/pen_base_height: -0.3011
      Episode_Reward/pen_lin_vel_z: -0.0624
     Episode_Reward/pen_ang_vel_xy: -0.0975
   Episode_Reward/pen_joint_torque: -0.1277
    Episode_Reward/pen_joint_accel: -0.0657
    Episode_Reward/pen_action_rate: -0.1645
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0248
   Episode_Reward/pen_joint_powers: -0.0446
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.3675
Episode_Reward/pen_flat_orientation: -0.1160
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1961
   Episode_Reward/foot_landing_vel: -0.0853
   Episode_Reward/test_gait_reward: -0.6212
Metrics/base_velocity/error_vel_xy: 1.7641
Metrics/base_velocity/error_vel_yaw: 0.6027
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 1.08s
                        Total time: 1054.58s
                               ETA: 2201.4s

################################################################################
                     [1m Learning iteration 972/3000 [0m                      

                       Computation: 88841 steps/s (collection: 0.982s, learning 0.124s)
               Value function loss: 1.2107
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5634
                     Learning rate: 0.0009
                       Mean reward: 44.02
               Mean episode length: 581.34
       Episode_Reward/keep_balance: 0.5992
     Episode_Reward/rew_lin_vel_xy: 2.0151
      Episode_Reward/rew_ang_vel_z: 1.7927
    Episode_Reward/pen_base_height: -0.2885
      Episode_Reward/pen_lin_vel_z: -0.0579
     Episode_Reward/pen_ang_vel_xy: -0.0910
   Episode_Reward/pen_joint_torque: -0.1148
    Episode_Reward/pen_joint_accel: -0.0548
    Episode_Reward/pen_action_rate: -0.1498
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0222
   Episode_Reward/pen_joint_powers: -0.0403
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3368
Episode_Reward/pen_flat_orientation: -0.1154
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1762
   Episode_Reward/foot_landing_vel: -0.0761
   Episode_Reward/test_gait_reward: -0.5743
Metrics/base_velocity/error_vel_xy: 1.6032
Metrics/base_velocity/error_vel_yaw: 0.5523
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 1.11s
                        Total time: 1055.69s
                               ETA: 2200.4s

################################################################################
                     [1m Learning iteration 973/3000 [0m                      

                       Computation: 91898 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.1509
                    Surrogate loss: -0.0033
             Mean action noise std: 0.5641
                     Learning rate: 0.0013
                       Mean reward: 41.95
               Mean episode length: 558.42
       Episode_Reward/keep_balance: 0.5538
     Episode_Reward/rew_lin_vel_xy: 1.8427
      Episode_Reward/rew_ang_vel_z: 1.6467
    Episode_Reward/pen_base_height: -0.2805
      Episode_Reward/pen_lin_vel_z: -0.0530
     Episode_Reward/pen_ang_vel_xy: -0.0834
   Episode_Reward/pen_joint_torque: -0.1039
    Episode_Reward/pen_joint_accel: -0.0531
    Episode_Reward/pen_action_rate: -0.1377
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0212
   Episode_Reward/pen_joint_powers: -0.0373
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.3132
Episode_Reward/pen_flat_orientation: -0.1148
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1692
   Episode_Reward/foot_landing_vel: -0.0701
   Episode_Reward/test_gait_reward: -0.5280
Metrics/base_velocity/error_vel_xy: 1.5096
Metrics/base_velocity/error_vel_yaw: 0.5200
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 1.07s
                        Total time: 1056.76s
                               ETA: 2199.2s

################################################################################
                     [1m Learning iteration 974/3000 [0m                      

                       Computation: 91405 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 1.3400
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5649
                     Learning rate: 0.0006
                       Mean reward: 45.30
               Mean episode length: 615.55
       Episode_Reward/keep_balance: 0.6409
     Episode_Reward/rew_lin_vel_xy: 2.1139
      Episode_Reward/rew_ang_vel_z: 1.9082
    Episode_Reward/pen_base_height: -0.2944
      Episode_Reward/pen_lin_vel_z: -0.0608
     Episode_Reward/pen_ang_vel_xy: -0.0956
   Episode_Reward/pen_joint_torque: -0.1254
    Episode_Reward/pen_joint_accel: -0.0576
    Episode_Reward/pen_action_rate: -0.1614
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0237
   Episode_Reward/pen_joint_powers: -0.0436
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.3629
Episode_Reward/pen_flat_orientation: -0.1131
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1864
   Episode_Reward/foot_landing_vel: -0.0754
   Episode_Reward/test_gait_reward: -0.6105
Metrics/base_velocity/error_vel_xy: 1.8416
Metrics/base_velocity/error_vel_yaw: 0.5974
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 1.08s
                        Total time: 1057.84s
                               ETA: 2198.1s

################################################################################
                     [1m Learning iteration 975/3000 [0m                      

                       Computation: 91483 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 1.1946
                    Surrogate loss: 0.0053
             Mean action noise std: 0.5650
                     Learning rate: 0.0001
                       Mean reward: 43.52
               Mean episode length: 585.05
       Episode_Reward/keep_balance: 0.5953
     Episode_Reward/rew_lin_vel_xy: 1.9482
      Episode_Reward/rew_ang_vel_z: 1.7554
    Episode_Reward/pen_base_height: -0.2913
      Episode_Reward/pen_lin_vel_z: -0.0576
     Episode_Reward/pen_ang_vel_xy: -0.0908
   Episode_Reward/pen_joint_torque: -0.1162
    Episode_Reward/pen_joint_accel: -0.0545
    Episode_Reward/pen_action_rate: -0.1489
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0223
   Episode_Reward/pen_joint_powers: -0.0408
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3365
Episode_Reward/pen_flat_orientation: -0.1161
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1711
   Episode_Reward/foot_landing_vel: -0.0730
   Episode_Reward/test_gait_reward: -0.5682
Metrics/base_velocity/error_vel_xy: 1.6604
Metrics/base_velocity/error_vel_yaw: 0.5712
      Episode_Termination/time_out: 2.9583
  Episode_Termination/base_contact: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 1.07s
                        Total time: 1058.91s
                               ETA: 2197.0s

################################################################################
                     [1m Learning iteration 976/3000 [0m                      

                       Computation: 91417 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 1.1197
                    Surrogate loss: 0.0042
             Mean action noise std: 0.5651
                     Learning rate: 0.0001
                       Mean reward: 40.02
               Mean episode length: 556.30
       Episode_Reward/keep_balance: 0.5729
     Episode_Reward/rew_lin_vel_xy: 1.8856
      Episode_Reward/rew_ang_vel_z: 1.6767
    Episode_Reward/pen_base_height: -0.2885
      Episode_Reward/pen_lin_vel_z: -0.0543
     Episode_Reward/pen_ang_vel_xy: -0.0897
   Episode_Reward/pen_joint_torque: -0.1103
    Episode_Reward/pen_joint_accel: -0.0511
    Episode_Reward/pen_action_rate: -0.1450
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0221
   Episode_Reward/pen_joint_powers: -0.0391
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3278
Episode_Reward/pen_flat_orientation: -0.1171
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.1709
   Episode_Reward/foot_landing_vel: -0.0722
   Episode_Reward/test_gait_reward: -0.5485
Metrics/base_velocity/error_vel_xy: 1.6645
Metrics/base_velocity/error_vel_yaw: 0.5561
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 1.08s
                        Total time: 1059.99s
                               ETA: 2195.9s

################################################################################
                     [1m Learning iteration 977/3000 [0m                      

                       Computation: 91265 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 1.0741
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5652
                     Learning rate: 0.0001
                       Mean reward: 42.49
               Mean episode length: 581.68
       Episode_Reward/keep_balance: 0.5760
     Episode_Reward/rew_lin_vel_xy: 1.8397
      Episode_Reward/rew_ang_vel_z: 1.6996
    Episode_Reward/pen_base_height: -0.2807
      Episode_Reward/pen_lin_vel_z: -0.0542
     Episode_Reward/pen_ang_vel_xy: -0.0869
   Episode_Reward/pen_joint_torque: -0.1073
    Episode_Reward/pen_joint_accel: -0.0542
    Episode_Reward/pen_action_rate: -0.1443
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0215
   Episode_Reward/pen_joint_powers: -0.0384
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3273
Episode_Reward/pen_flat_orientation: -0.1102
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1654
   Episode_Reward/foot_landing_vel: -0.0723
   Episode_Reward/test_gait_reward: -0.5503
Metrics/base_velocity/error_vel_xy: 1.6570
Metrics/base_velocity/error_vel_yaw: 0.5484
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 1.08s
                        Total time: 1061.06s
                               ETA: 2194.8s

################################################################################
                     [1m Learning iteration 978/3000 [0m                      

                       Computation: 90409 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 1.0959
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5652
                     Learning rate: 0.0006
                       Mean reward: 43.29
               Mean episode length: 585.11
       Episode_Reward/keep_balance: 0.6003
     Episode_Reward/rew_lin_vel_xy: 1.9352
      Episode_Reward/rew_ang_vel_z: 1.7814
    Episode_Reward/pen_base_height: -0.2942
      Episode_Reward/pen_lin_vel_z: -0.0597
     Episode_Reward/pen_ang_vel_xy: -0.0933
   Episode_Reward/pen_joint_torque: -0.1177
    Episode_Reward/pen_joint_accel: -0.0581
    Episode_Reward/pen_action_rate: -0.1548
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0234
   Episode_Reward/pen_joint_powers: -0.0418
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.3442
Episode_Reward/pen_flat_orientation: -0.1158
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1799
   Episode_Reward/foot_landing_vel: -0.0793
   Episode_Reward/test_gait_reward: -0.5773
Metrics/base_velocity/error_vel_xy: 1.6516
Metrics/base_velocity/error_vel_yaw: 0.5682
      Episode_Termination/time_out: 2.7917
  Episode_Termination/base_contact: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 1.09s
                        Total time: 1062.15s
                               ETA: 2193.7s

################################################################################
                     [1m Learning iteration 979/3000 [0m                      

                       Computation: 91869 steps/s (collection: 0.949s, learning 0.121s)
               Value function loss: 1.0578
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5648
                     Learning rate: 0.0009
                       Mean reward: 45.37
               Mean episode length: 589.73
       Episode_Reward/keep_balance: 0.5824
     Episode_Reward/rew_lin_vel_xy: 1.9690
      Episode_Reward/rew_ang_vel_z: 1.7259
    Episode_Reward/pen_base_height: -0.2807
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.0906
   Episode_Reward/pen_joint_torque: -0.1135
    Episode_Reward/pen_joint_accel: -0.0592
    Episode_Reward/pen_action_rate: -0.1486
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0222
   Episode_Reward/pen_joint_powers: -0.0397
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.3333
Episode_Reward/pen_flat_orientation: -0.1128
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1645
   Episode_Reward/foot_landing_vel: -0.0732
   Episode_Reward/test_gait_reward: -0.5569
Metrics/base_velocity/error_vel_xy: 1.5095
Metrics/base_velocity/error_vel_yaw: 0.5500
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 1.07s
                        Total time: 1063.22s
                               ETA: 2192.6s

################################################################################
                     [1m Learning iteration 980/3000 [0m                      

                       Computation: 92367 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 1.0621
                    Surrogate loss: -0.0016
             Mean action noise std: 0.5663
                     Learning rate: 0.0003
                       Mean reward: 43.86
               Mean episode length: 581.13
       Episode_Reward/keep_balance: 0.6305
     Episode_Reward/rew_lin_vel_xy: 2.1214
      Episode_Reward/rew_ang_vel_z: 1.8602
    Episode_Reward/pen_base_height: -0.2921
      Episode_Reward/pen_lin_vel_z: -0.0604
     Episode_Reward/pen_ang_vel_xy: -0.0943
   Episode_Reward/pen_joint_torque: -0.1209
    Episode_Reward/pen_joint_accel: -0.0645
    Episode_Reward/pen_action_rate: -0.1605
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0244
   Episode_Reward/pen_joint_powers: -0.0430
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.3611
Episode_Reward/pen_flat_orientation: -0.1171
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1963
   Episode_Reward/foot_landing_vel: -0.0817
   Episode_Reward/test_gait_reward: -0.6040
Metrics/base_velocity/error_vel_xy: 1.7348
Metrics/base_velocity/error_vel_yaw: 0.6013
      Episode_Termination/time_out: 2.7917
  Episode_Termination/base_contact: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 1.06s
                        Total time: 1064.29s
                               ETA: 2191.5s

################################################################################
                     [1m Learning iteration 981/3000 [0m                      

                       Computation: 89768 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.8934
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5665
                     Learning rate: 0.0002
                       Mean reward: 44.03
               Mean episode length: 615.21
       Episode_Reward/keep_balance: 0.6642
     Episode_Reward/rew_lin_vel_xy: 2.0436
      Episode_Reward/rew_ang_vel_z: 1.9889
    Episode_Reward/pen_base_height: -0.2989
      Episode_Reward/pen_lin_vel_z: -0.0638
     Episode_Reward/pen_ang_vel_xy: -0.0965
   Episode_Reward/pen_joint_torque: -0.1309
    Episode_Reward/pen_joint_accel: -0.0662
    Episode_Reward/pen_action_rate: -0.1684
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0251
   Episode_Reward/pen_joint_powers: -0.0457
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.3762
Episode_Reward/pen_flat_orientation: -0.1151
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1934
   Episode_Reward/foot_landing_vel: -0.0808
   Episode_Reward/test_gait_reward: -0.6372
Metrics/base_velocity/error_vel_xy: 1.9642
Metrics/base_velocity/error_vel_yaw: 0.6114
      Episode_Termination/time_out: 2.9167
  Episode_Termination/base_contact: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 1.10s
                        Total time: 1065.38s
                               ETA: 2190.4s

################################################################################
                     [1m Learning iteration 982/3000 [0m                      

                       Computation: 90627 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.9474
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5664
                     Learning rate: 0.0001
                       Mean reward: 47.90
               Mean episode length: 648.04
       Episode_Reward/keep_balance: 0.6132
     Episode_Reward/rew_lin_vel_xy: 1.9110
      Episode_Reward/rew_ang_vel_z: 1.8035
    Episode_Reward/pen_base_height: -0.2938
      Episode_Reward/pen_lin_vel_z: -0.0574
     Episode_Reward/pen_ang_vel_xy: -0.0926
   Episode_Reward/pen_joint_torque: -0.1191
    Episode_Reward/pen_joint_accel: -0.0570
    Episode_Reward/pen_action_rate: -0.1554
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0234
   Episode_Reward/pen_joint_powers: -0.0418
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3512
Episode_Reward/pen_flat_orientation: -0.1202
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1774
   Episode_Reward/foot_landing_vel: -0.0743
   Episode_Reward/test_gait_reward: -0.5921
Metrics/base_velocity/error_vel_xy: 1.7470
Metrics/base_velocity/error_vel_yaw: 0.5914
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 1.08s
                        Total time: 1066.46s
                               ETA: 2189.3s

################################################################################
                     [1m Learning iteration 983/3000 [0m                      

                       Computation: 90669 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 1.0170
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5662
                     Learning rate: 0.0002
                       Mean reward: 50.58
               Mean episode length: 648.10
       Episode_Reward/keep_balance: 0.6427
     Episode_Reward/rew_lin_vel_xy: 2.2172
      Episode_Reward/rew_ang_vel_z: 1.9149
    Episode_Reward/pen_base_height: -0.2989
      Episode_Reward/pen_lin_vel_z: -0.0609
     Episode_Reward/pen_ang_vel_xy: -0.0976
   Episode_Reward/pen_joint_torque: -0.1214
    Episode_Reward/pen_joint_accel: -0.0551
    Episode_Reward/pen_action_rate: -0.1625
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0242
   Episode_Reward/pen_joint_powers: -0.0435
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.3682
Episode_Reward/pen_flat_orientation: -0.1248
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.1884
   Episode_Reward/foot_landing_vel: -0.0811
   Episode_Reward/test_gait_reward: -0.6165
Metrics/base_velocity/error_vel_xy: 1.7195
Metrics/base_velocity/error_vel_yaw: 0.5992
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 1.08s
                        Total time: 1067.55s
                               ETA: 2188.3s

################################################################################
                     [1m Learning iteration 984/3000 [0m                      

                       Computation: 91034 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.9867
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5663
                     Learning rate: 0.0004
                       Mean reward: 51.16
               Mean episode length: 685.79
       Episode_Reward/keep_balance: 0.6327
     Episode_Reward/rew_lin_vel_xy: 2.0580
      Episode_Reward/rew_ang_vel_z: 1.8530
    Episode_Reward/pen_base_height: -0.2922
      Episode_Reward/pen_lin_vel_z: -0.0598
     Episode_Reward/pen_ang_vel_xy: -0.0958
   Episode_Reward/pen_joint_torque: -0.1238
    Episode_Reward/pen_joint_accel: -0.0567
    Episode_Reward/pen_action_rate: -0.1618
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0239
   Episode_Reward/pen_joint_powers: -0.0434
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.3618
Episode_Reward/pen_flat_orientation: -0.1183
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1866
   Episode_Reward/foot_landing_vel: -0.0786
   Episode_Reward/test_gait_reward: -0.6059
Metrics/base_velocity/error_vel_xy: 1.7723
Metrics/base_velocity/error_vel_yaw: 0.6140
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 1.08s
                        Total time: 1068.63s
                               ETA: 2187.2s

################################################################################
                     [1m Learning iteration 985/3000 [0m                      

                       Computation: 90869 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 1.0515
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5669
                     Learning rate: 0.0002
                       Mean reward: 42.36
               Mean episode length: 542.83
       Episode_Reward/keep_balance: 0.5873
     Episode_Reward/rew_lin_vel_xy: 2.0718
      Episode_Reward/rew_ang_vel_z: 1.7320
    Episode_Reward/pen_base_height: -0.2852
      Episode_Reward/pen_lin_vel_z: -0.0566
     Episode_Reward/pen_ang_vel_xy: -0.0893
   Episode_Reward/pen_joint_torque: -0.1127
    Episode_Reward/pen_joint_accel: -0.0586
    Episode_Reward/pen_action_rate: -0.1496
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0223
   Episode_Reward/pen_joint_powers: -0.0402
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3368
Episode_Reward/pen_flat_orientation: -0.1131
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1674
   Episode_Reward/foot_landing_vel: -0.0759
   Episode_Reward/test_gait_reward: -0.5663
Metrics/base_velocity/error_vel_xy: 1.5517
Metrics/base_velocity/error_vel_yaw: 0.5621
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 1.08s
                        Total time: 1069.71s
                               ETA: 2186.1s

################################################################################
                     [1m Learning iteration 986/3000 [0m                      

                       Computation: 91309 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 1.0511
                    Surrogate loss: 0.0028
             Mean action noise std: 0.5670
                     Learning rate: 0.0001
                       Mean reward: 50.89
               Mean episode length: 670.90
       Episode_Reward/keep_balance: 0.6419
     Episode_Reward/rew_lin_vel_xy: 2.0402
      Episode_Reward/rew_ang_vel_z: 1.8919
    Episode_Reward/pen_base_height: -0.2974
      Episode_Reward/pen_lin_vel_z: -0.0594
     Episode_Reward/pen_ang_vel_xy: -0.0975
   Episode_Reward/pen_joint_torque: -0.1210
    Episode_Reward/pen_joint_accel: -0.0611
    Episode_Reward/pen_action_rate: -0.1629
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0241
   Episode_Reward/pen_joint_powers: -0.0430
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3696
Episode_Reward/pen_flat_orientation: -0.1187
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.1843
   Episode_Reward/foot_landing_vel: -0.0768
   Episode_Reward/test_gait_reward: -0.6140
Metrics/base_velocity/error_vel_xy: 1.8486
Metrics/base_velocity/error_vel_yaw: 0.6133
      Episode_Termination/time_out: 2.5833
  Episode_Termination/base_contact: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 1.08s
                        Total time: 1070.79s
                               ETA: 2185.0s

################################################################################
                     [1m Learning iteration 987/3000 [0m                      

                       Computation: 87311 steps/s (collection: 1.000s, learning 0.126s)
               Value function loss: 0.9596
                    Surrogate loss: -0.0032
             Mean action noise std: 0.5670
                     Learning rate: 0.0003
                       Mean reward: 42.53
               Mean episode length: 592.23
       Episode_Reward/keep_balance: 0.5869
     Episode_Reward/rew_lin_vel_xy: 1.9291
      Episode_Reward/rew_ang_vel_z: 1.7361
    Episode_Reward/pen_base_height: -0.2851
      Episode_Reward/pen_lin_vel_z: -0.0541
     Episode_Reward/pen_ang_vel_xy: -0.0894
   Episode_Reward/pen_joint_torque: -0.1094
    Episode_Reward/pen_joint_accel: -0.0558
    Episode_Reward/pen_action_rate: -0.1474
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0219
   Episode_Reward/pen_joint_powers: -0.0388
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.3360
Episode_Reward/pen_flat_orientation: -0.1223
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1592
   Episode_Reward/foot_landing_vel: -0.0703
   Episode_Reward/test_gait_reward: -0.5605
Metrics/base_velocity/error_vel_xy: 1.6513
Metrics/base_velocity/error_vel_yaw: 0.5559
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 1.13s
                        Total time: 1071.91s
                               ETA: 2184.0s

################################################################################
                     [1m Learning iteration 988/3000 [0m                      

                       Computation: 88661 steps/s (collection: 0.984s, learning 0.125s)
               Value function loss: 1.0687
                    Surrogate loss: -0.0021
             Mean action noise std: 0.5679
                     Learning rate: 0.0004
                       Mean reward: 44.76
               Mean episode length: 620.45
       Episode_Reward/keep_balance: 0.6703
     Episode_Reward/rew_lin_vel_xy: 2.2986
      Episode_Reward/rew_ang_vel_z: 1.9682
    Episode_Reward/pen_base_height: -0.3067
      Episode_Reward/pen_lin_vel_z: -0.0632
     Episode_Reward/pen_ang_vel_xy: -0.0964
   Episode_Reward/pen_joint_torque: -0.1297
    Episode_Reward/pen_joint_accel: -0.0641
    Episode_Reward/pen_action_rate: -0.1691
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0250
   Episode_Reward/pen_joint_powers: -0.0452
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.3857
Episode_Reward/pen_flat_orientation: -0.1302
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1949
   Episode_Reward/foot_landing_vel: -0.0829
   Episode_Reward/test_gait_reward: -0.6466
Metrics/base_velocity/error_vel_xy: 1.8395
Metrics/base_velocity/error_vel_yaw: 0.6461
      Episode_Termination/time_out: 2.5833
  Episode_Termination/base_contact: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 1.11s
                        Total time: 1073.02s
                               ETA: 2182.9s

################################################################################
                     [1m Learning iteration 989/3000 [0m                      

                       Computation: 86230 steps/s (collection: 1.013s, learning 0.127s)
               Value function loss: 1.1206
                    Surrogate loss: -0.0011
             Mean action noise std: 0.5680
                     Learning rate: 0.0002
                       Mean reward: 48.32
               Mean episode length: 643.37
       Episode_Reward/keep_balance: 0.6407
     Episode_Reward/rew_lin_vel_xy: 2.0323
      Episode_Reward/rew_ang_vel_z: 1.8783
    Episode_Reward/pen_base_height: -0.2991
      Episode_Reward/pen_lin_vel_z: -0.0606
     Episode_Reward/pen_ang_vel_xy: -0.0958
   Episode_Reward/pen_joint_torque: -0.1225
    Episode_Reward/pen_joint_accel: -0.0655
    Episode_Reward/pen_action_rate: -0.1635
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0246
   Episode_Reward/pen_joint_powers: -0.0437
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.3680
Episode_Reward/pen_flat_orientation: -0.1248
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1882
   Episode_Reward/foot_landing_vel: -0.0790
   Episode_Reward/test_gait_reward: -0.6151
Metrics/base_velocity/error_vel_xy: 1.8059
Metrics/base_velocity/error_vel_yaw: 0.6200
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 1.14s
                        Total time: 1074.16s
                               ETA: 2182.0s

################################################################################
                     [1m Learning iteration 990/3000 [0m                      

                       Computation: 86555 steps/s (collection: 1.012s, learning 0.124s)
               Value function loss: 1.0803
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5680
                     Learning rate: 0.0003
                       Mean reward: 46.78
               Mean episode length: 620.14
       Episode_Reward/keep_balance: 0.6221
     Episode_Reward/rew_lin_vel_xy: 2.0725
      Episode_Reward/rew_ang_vel_z: 1.8481
    Episode_Reward/pen_base_height: -0.2853
      Episode_Reward/pen_lin_vel_z: -0.0571
     Episode_Reward/pen_ang_vel_xy: -0.0921
   Episode_Reward/pen_joint_torque: -0.1168
    Episode_Reward/pen_joint_accel: -0.0581
    Episode_Reward/pen_action_rate: -0.1569
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0227
   Episode_Reward/pen_joint_powers: -0.0414
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.3538
Episode_Reward/pen_flat_orientation: -0.1211
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.1715
   Episode_Reward/foot_landing_vel: -0.0730
   Episode_Reward/test_gait_reward: -0.5974
Metrics/base_velocity/error_vel_xy: 1.7029
Metrics/base_velocity/error_vel_yaw: 0.5822
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 1.14s
                        Total time: 1075.30s
                               ETA: 2181.0s

################################################################################
                     [1m Learning iteration 991/3000 [0m                      

                       Computation: 88070 steps/s (collection: 0.987s, learning 0.129s)
               Value function loss: 1.1625
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5682
                     Learning rate: 0.0004
                       Mean reward: 50.67
               Mean episode length: 688.72
       Episode_Reward/keep_balance: 0.6557
     Episode_Reward/rew_lin_vel_xy: 2.0702
      Episode_Reward/rew_ang_vel_z: 1.9328
    Episode_Reward/pen_base_height: -0.3018
      Episode_Reward/pen_lin_vel_z: -0.0618
     Episode_Reward/pen_ang_vel_xy: -0.1005
   Episode_Reward/pen_joint_torque: -0.1269
    Episode_Reward/pen_joint_accel: -0.0640
    Episode_Reward/pen_action_rate: -0.1698
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0250
   Episode_Reward/pen_joint_powers: -0.0450
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.3799
Episode_Reward/pen_flat_orientation: -0.1250
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.1904
   Episode_Reward/foot_landing_vel: -0.0812
   Episode_Reward/test_gait_reward: -0.6334
Metrics/base_velocity/error_vel_xy: 1.8838
Metrics/base_velocity/error_vel_yaw: 0.6261
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 1.12s
                        Total time: 1076.41s
                               ETA: 2180.0s

################################################################################
                     [1m Learning iteration 992/3000 [0m                      

                       Computation: 86952 steps/s (collection: 1.004s, learning 0.126s)
               Value function loss: 1.0677
                    Surrogate loss: -0.0024
             Mean action noise std: 0.5690
                     Learning rate: 0.0003
                       Mean reward: 47.51
               Mean episode length: 659.85
       Episode_Reward/keep_balance: 0.6940
     Episode_Reward/rew_lin_vel_xy: 2.2644
      Episode_Reward/rew_ang_vel_z: 2.0614
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0678
     Episode_Reward/pen_ang_vel_xy: -0.1080
   Episode_Reward/pen_joint_torque: -0.1401
    Episode_Reward/pen_joint_accel: -0.0664
    Episode_Reward/pen_action_rate: -0.1812
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0269
   Episode_Reward/pen_joint_powers: -0.0491
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.4012
Episode_Reward/pen_flat_orientation: -0.1268
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.2092
   Episode_Reward/foot_landing_vel: -0.0874
   Episode_Reward/test_gait_reward: -0.6686
Metrics/base_velocity/error_vel_xy: 1.9088
Metrics/base_velocity/error_vel_yaw: 0.6522
      Episode_Termination/time_out: 2.8333
  Episode_Termination/base_contact: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 1.13s
                        Total time: 1077.54s
                               ETA: 2179.0s

################################################################################
                     [1m Learning iteration 993/3000 [0m                      

                       Computation: 87550 steps/s (collection: 0.999s, learning 0.123s)
               Value function loss: 1.0551
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5688
                     Learning rate: 0.0003
                       Mean reward: 46.18
               Mean episode length: 601.62
       Episode_Reward/keep_balance: 0.5779
     Episode_Reward/rew_lin_vel_xy: 1.9871
      Episode_Reward/rew_ang_vel_z: 1.6928
    Episode_Reward/pen_base_height: -0.2876
      Episode_Reward/pen_lin_vel_z: -0.0571
     Episode_Reward/pen_ang_vel_xy: -0.0941
   Episode_Reward/pen_joint_torque: -0.1136
    Episode_Reward/pen_joint_accel: -0.0560
    Episode_Reward/pen_action_rate: -0.1504
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0229
   Episode_Reward/pen_joint_powers: -0.0407
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.3349
Episode_Reward/pen_flat_orientation: -0.1249
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.1795
   Episode_Reward/foot_landing_vel: -0.0731
   Episode_Reward/test_gait_reward: -0.5604
Metrics/base_velocity/error_vel_xy: 1.5111
Metrics/base_velocity/error_vel_yaw: 0.5649
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 1.12s
                        Total time: 1078.67s
                               ETA: 2178.0s

################################################################################
                     [1m Learning iteration 994/3000 [0m                      

                       Computation: 87095 steps/s (collection: 1.000s, learning 0.128s)
               Value function loss: 1.0172
                    Surrogate loss: -0.0033
             Mean action noise std: 0.5691
                     Learning rate: 0.0006
                       Mean reward: 42.25
               Mean episode length: 647.84
       Episode_Reward/keep_balance: 0.6352
     Episode_Reward/rew_lin_vel_xy: 1.8578
      Episode_Reward/rew_ang_vel_z: 1.8446
    Episode_Reward/pen_base_height: -0.2970
      Episode_Reward/pen_lin_vel_z: -0.0605
     Episode_Reward/pen_ang_vel_xy: -0.0987
   Episode_Reward/pen_joint_torque: -0.1256
    Episode_Reward/pen_joint_accel: -0.0656
    Episode_Reward/pen_action_rate: -0.1657
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0248
   Episode_Reward/pen_joint_powers: -0.0442
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.3736
Episode_Reward/pen_flat_orientation: -0.1271
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1938
   Episode_Reward/foot_landing_vel: -0.0785
   Episode_Reward/test_gait_reward: -0.6141
Metrics/base_velocity/error_vel_xy: 1.9315
Metrics/base_velocity/error_vel_yaw: 0.6304
      Episode_Termination/time_out: 2.2917
  Episode_Termination/base_contact: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 1.13s
                        Total time: 1079.80s
                               ETA: 2177.0s

################################################################################
                     [1m Learning iteration 995/3000 [0m                      

                       Computation: 86252 steps/s (collection: 1.012s, learning 0.128s)
               Value function loss: 1.1532
                    Surrogate loss: -0.0035
             Mean action noise std: 0.5711
                     Learning rate: 0.0009
                       Mean reward: 47.29
               Mean episode length: 655.17
       Episode_Reward/keep_balance: 0.6505
     Episode_Reward/rew_lin_vel_xy: 2.0922
      Episode_Reward/rew_ang_vel_z: 1.9007
    Episode_Reward/pen_base_height: -0.3061
      Episode_Reward/pen_lin_vel_z: -0.0624
     Episode_Reward/pen_ang_vel_xy: -0.0998
   Episode_Reward/pen_joint_torque: -0.1275
    Episode_Reward/pen_joint_accel: -0.0584
    Episode_Reward/pen_action_rate: -0.1691
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0253
   Episode_Reward/pen_joint_powers: -0.0455
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.3772
Episode_Reward/pen_flat_orientation: -0.1258
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.2039
   Episode_Reward/foot_landing_vel: -0.0777
   Episode_Reward/test_gait_reward: -0.6260
Metrics/base_velocity/error_vel_xy: 1.8123
Metrics/base_velocity/error_vel_yaw: 0.6309
      Episode_Termination/time_out: 2.6667
  Episode_Termination/base_contact: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 1.14s
                        Total time: 1080.94s
                               ETA: 2176.0s

################################################################################
                     [1m Learning iteration 996/3000 [0m                      

                       Computation: 89487 steps/s (collection: 0.969s, learning 0.130s)
               Value function loss: 1.1583
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5722
                     Learning rate: 0.0006
                       Mean reward: 51.17
               Mean episode length: 691.28
       Episode_Reward/keep_balance: 0.6814
     Episode_Reward/rew_lin_vel_xy: 2.2421
      Episode_Reward/rew_ang_vel_z: 2.0026
    Episode_Reward/pen_base_height: -0.3104
      Episode_Reward/pen_lin_vel_z: -0.0646
     Episode_Reward/pen_ang_vel_xy: -0.1048
   Episode_Reward/pen_joint_torque: -0.1308
    Episode_Reward/pen_joint_accel: -0.0640
    Episode_Reward/pen_action_rate: -0.1774
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0256
   Episode_Reward/pen_joint_powers: -0.0465
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.3980
Episode_Reward/pen_flat_orientation: -0.1303
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1975
   Episode_Reward/foot_landing_vel: -0.0827
   Episode_Reward/test_gait_reward: -0.6571
Metrics/base_velocity/error_vel_xy: 1.8931
Metrics/base_velocity/error_vel_yaw: 0.6523
      Episode_Termination/time_out: 2.5417
  Episode_Termination/base_contact: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 1.10s
                        Total time: 1082.03s
                               ETA: 2174.9s

################################################################################
                     [1m Learning iteration 997/3000 [0m                      

                       Computation: 92405 steps/s (collection: 0.936s, learning 0.128s)
               Value function loss: 1.0338
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5734
                     Learning rate: 0.0006
                       Mean reward: 45.53
               Mean episode length: 654.36
       Episode_Reward/keep_balance: 0.6881
     Episode_Reward/rew_lin_vel_xy: 2.2300
      Episode_Reward/rew_ang_vel_z: 2.0066
    Episode_Reward/pen_base_height: -0.3203
      Episode_Reward/pen_lin_vel_z: -0.0666
     Episode_Reward/pen_ang_vel_xy: -0.1103
   Episode_Reward/pen_joint_torque: -0.1389
    Episode_Reward/pen_joint_accel: -0.0727
    Episode_Reward/pen_action_rate: -0.1820
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0281
   Episode_Reward/pen_joint_powers: -0.0496
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.4033
Episode_Reward/pen_flat_orientation: -0.1292
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.2185
   Episode_Reward/foot_landing_vel: -0.0916
   Episode_Reward/test_gait_reward: -0.6610
Metrics/base_velocity/error_vel_xy: 1.9139
Metrics/base_velocity/error_vel_yaw: 0.6732
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 1.06s
                        Total time: 1083.10s
                               ETA: 2173.8s

################################################################################
                     [1m Learning iteration 998/3000 [0m                      

                       Computation: 88243 steps/s (collection: 0.986s, learning 0.128s)
               Value function loss: 1.0592
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5733
                     Learning rate: 0.0004
                       Mean reward: 52.43
               Mean episode length: 685.67
       Episode_Reward/keep_balance: 0.6768
     Episode_Reward/rew_lin_vel_xy: 2.1793
      Episode_Reward/rew_ang_vel_z: 2.0122
    Episode_Reward/pen_base_height: -0.3131
      Episode_Reward/pen_lin_vel_z: -0.0624
     Episode_Reward/pen_ang_vel_xy: -0.1007
   Episode_Reward/pen_joint_torque: -0.1310
    Episode_Reward/pen_joint_accel: -0.0622
    Episode_Reward/pen_action_rate: -0.1732
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0251
   Episode_Reward/pen_joint_powers: -0.0458
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.3897
Episode_Reward/pen_flat_orientation: -0.1285
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1916
   Episode_Reward/foot_landing_vel: -0.0802
   Episode_Reward/test_gait_reward: -0.6491
Metrics/base_velocity/error_vel_xy: 1.9192
Metrics/base_velocity/error_vel_yaw: 0.6345
      Episode_Termination/time_out: 2.9583
  Episode_Termination/base_contact: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 1.11s
                        Total time: 1084.21s
                               ETA: 2172.8s

################################################################################
                     [1m Learning iteration 999/3000 [0m                      

                       Computation: 86501 steps/s (collection: 1.008s, learning 0.128s)
               Value function loss: 1.0172
                    Surrogate loss: -0.0029
             Mean action noise std: 0.5731
                     Learning rate: 0.0004
                       Mean reward: 53.20
               Mean episode length: 721.45
       Episode_Reward/keep_balance: 0.7017
     Episode_Reward/rew_lin_vel_xy: 2.3358
      Episode_Reward/rew_ang_vel_z: 2.0577
    Episode_Reward/pen_base_height: -0.3128
      Episode_Reward/pen_lin_vel_z: -0.0694
     Episode_Reward/pen_ang_vel_xy: -0.1126
   Episode_Reward/pen_joint_torque: -0.1438
    Episode_Reward/pen_joint_accel: -0.0670
    Episode_Reward/pen_action_rate: -0.1833
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0273
   Episode_Reward/pen_joint_powers: -0.0500
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.4092
Episode_Reward/pen_flat_orientation: -0.1332
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.2121
   Episode_Reward/foot_landing_vel: -0.0894
   Episode_Reward/test_gait_reward: -0.6769
Metrics/base_velocity/error_vel_xy: 1.9180
Metrics/base_velocity/error_vel_yaw: 0.6796
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 1.14s
                        Total time: 1085.35s
                               ETA: 2171.8s

################################################################################
                     [1m Learning iteration 1000/3000 [0m                     

                       Computation: 88143 steps/s (collection: 0.990s, learning 0.125s)
               Value function loss: 1.0848
                    Surrogate loss: -0.0028
             Mean action noise std: 0.5740
                     Learning rate: 0.0006
                       Mean reward: 54.02
               Mean episode length: 697.05
       Episode_Reward/keep_balance: 0.6985
     Episode_Reward/rew_lin_vel_xy: 2.2723
      Episode_Reward/rew_ang_vel_z: 2.0591
    Episode_Reward/pen_base_height: -0.3126
      Episode_Reward/pen_lin_vel_z: -0.0652
     Episode_Reward/pen_ang_vel_xy: -0.1069
   Episode_Reward/pen_joint_torque: -0.1304
    Episode_Reward/pen_joint_accel: -0.0649
    Episode_Reward/pen_action_rate: -0.1809
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0265
   Episode_Reward/pen_joint_powers: -0.0467
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.4080
Episode_Reward/pen_flat_orientation: -0.1388
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2030
   Episode_Reward/foot_landing_vel: -0.0862
   Episode_Reward/test_gait_reward: -0.6662
Metrics/base_velocity/error_vel_xy: 1.9359
Metrics/base_velocity/error_vel_yaw: 0.6670
      Episode_Termination/time_out: 2.2917
  Episode_Termination/base_contact: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 1.12s
                        Total time: 1086.46s
                               ETA: 2170.8s

################################################################################
                     [1m Learning iteration 1001/3000 [0m                     

                       Computation: 87162 steps/s (collection: 1.003s, learning 0.124s)
               Value function loss: 1.0630
                    Surrogate loss: -0.0026
             Mean action noise std: 0.5756
                     Learning rate: 0.0009
                       Mean reward: 59.32
               Mean episode length: 754.78
       Episode_Reward/keep_balance: 0.7644
     Episode_Reward/rew_lin_vel_xy: 2.7287
      Episode_Reward/rew_ang_vel_z: 2.2802
    Episode_Reward/pen_base_height: -0.3281
      Episode_Reward/pen_lin_vel_z: -0.0701
     Episode_Reward/pen_ang_vel_xy: -0.1162
   Episode_Reward/pen_joint_torque: -0.1484
    Episode_Reward/pen_joint_accel: -0.0696
    Episode_Reward/pen_action_rate: -0.1987
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0285
   Episode_Reward/pen_joint_powers: -0.0522
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.4437
Episode_Reward/pen_flat_orientation: -0.1296
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.2168
   Episode_Reward/foot_landing_vel: -0.0937
   Episode_Reward/test_gait_reward: -0.7314
Metrics/base_velocity/error_vel_xy: 1.9709
Metrics/base_velocity/error_vel_yaw: 0.7072
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 1.13s
                        Total time: 1087.59s
                               ETA: 2169.8s

################################################################################
                     [1m Learning iteration 1002/3000 [0m                     

                       Computation: 89813 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 1.1501
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5750
                     Learning rate: 0.0009
                       Mean reward: 57.24
               Mean episode length: 730.95
       Episode_Reward/keep_balance: 0.7189
     Episode_Reward/rew_lin_vel_xy: 2.4247
      Episode_Reward/rew_ang_vel_z: 2.1276
    Episode_Reward/pen_base_height: -0.3241
      Episode_Reward/pen_lin_vel_z: -0.0652
     Episode_Reward/pen_ang_vel_xy: -0.1076
   Episode_Reward/pen_joint_torque: -0.1366
    Episode_Reward/pen_joint_accel: -0.0611
    Episode_Reward/pen_action_rate: -0.1844
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0261
   Episode_Reward/pen_joint_powers: -0.0480
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.4160
Episode_Reward/pen_flat_orientation: -0.1308
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.1985
   Episode_Reward/foot_landing_vel: -0.0830
   Episode_Reward/test_gait_reward: -0.6858
Metrics/base_velocity/error_vel_xy: 1.9472
Metrics/base_velocity/error_vel_yaw: 0.6792
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 1.09s
                        Total time: 1088.69s
                               ETA: 2168.7s

################################################################################
                     [1m Learning iteration 1003/3000 [0m                     

                       Computation: 90772 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 1.1194
                    Surrogate loss: 0.0036
             Mean action noise std: 0.5749
                     Learning rate: 0.0001
                       Mean reward: 56.64
               Mean episode length: 715.27
       Episode_Reward/keep_balance: 0.7156
     Episode_Reward/rew_lin_vel_xy: 2.5107
      Episode_Reward/rew_ang_vel_z: 2.1030
    Episode_Reward/pen_base_height: -0.3174
      Episode_Reward/pen_lin_vel_z: -0.0661
     Episode_Reward/pen_ang_vel_xy: -0.1112
   Episode_Reward/pen_joint_torque: -0.1385
    Episode_Reward/pen_joint_accel: -0.0664
    Episode_Reward/pen_action_rate: -0.1878
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0276
   Episode_Reward/pen_joint_powers: -0.0493
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.4219
Episode_Reward/pen_flat_orientation: -0.1350
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.2111
   Episode_Reward/foot_landing_vel: -0.0844
   Episode_Reward/test_gait_reward: -0.6847
Metrics/base_velocity/error_vel_xy: 1.8422
Metrics/base_velocity/error_vel_yaw: 0.6853
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 1.08s
                        Total time: 1089.77s
                               ETA: 2167.6s

################################################################################
                     [1m Learning iteration 1004/3000 [0m                     

                       Computation: 94399 steps/s (collection: 0.920s, learning 0.122s)
               Value function loss: 0.9393
                    Surrogate loss: -0.0031
             Mean action noise std: 0.5740
                     Learning rate: 0.0002
                       Mean reward: 57.59
               Mean episode length: 745.37
       Episode_Reward/keep_balance: 0.7469
     Episode_Reward/rew_lin_vel_xy: 2.5181
      Episode_Reward/rew_ang_vel_z: 2.2159
    Episode_Reward/pen_base_height: -0.3238
      Episode_Reward/pen_lin_vel_z: -0.0694
     Episode_Reward/pen_ang_vel_xy: -0.1137
   Episode_Reward/pen_joint_torque: -0.1423
    Episode_Reward/pen_joint_accel: -0.0693
    Episode_Reward/pen_action_rate: -0.1935
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0280
   Episode_Reward/pen_joint_powers: -0.0506
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.4383
Episode_Reward/pen_flat_orientation: -0.1346
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.2110
   Episode_Reward/foot_landing_vel: -0.0929
   Episode_Reward/test_gait_reward: -0.7169
Metrics/base_velocity/error_vel_xy: 2.0262
Metrics/base_velocity/error_vel_yaw: 0.7010
      Episode_Termination/time_out: 3.1250
  Episode_Termination/base_contact: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 1.04s
                        Total time: 1090.81s
                               ETA: 2166.4s

################################################################################
                     [1m Learning iteration 1005/3000 [0m                     

                       Computation: 91411 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.9619
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5731
                     Learning rate: 0.0003
                       Mean reward: 55.41
               Mean episode length: 737.35
       Episode_Reward/keep_balance: 0.7320
     Episode_Reward/rew_lin_vel_xy: 2.4550
      Episode_Reward/rew_ang_vel_z: 2.1626
    Episode_Reward/pen_base_height: -0.3170
      Episode_Reward/pen_lin_vel_z: -0.0675
     Episode_Reward/pen_ang_vel_xy: -0.1110
   Episode_Reward/pen_joint_torque: -0.1447
    Episode_Reward/pen_joint_accel: -0.0678
    Episode_Reward/pen_action_rate: -0.1919
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0273
   Episode_Reward/pen_joint_powers: -0.0505
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.4303
Episode_Reward/pen_flat_orientation: -0.1292
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.2075
   Episode_Reward/foot_landing_vel: -0.0887
   Episode_Reward/test_gait_reward: -0.7017
Metrics/base_velocity/error_vel_xy: 1.9557
Metrics/base_velocity/error_vel_yaw: 0.6920
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 1.08s
                        Total time: 1091.89s
                               ETA: 2165.3s

################################################################################
                     [1m Learning iteration 1006/3000 [0m                     

                       Computation: 91844 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 0.9790
                    Surrogate loss: -0.0030
             Mean action noise std: 0.5726
                     Learning rate: 0.0004
                       Mean reward: 57.88
               Mean episode length: 723.37
       Episode_Reward/keep_balance: 0.7449
     Episode_Reward/rew_lin_vel_xy: 2.6059
      Episode_Reward/rew_ang_vel_z: 2.1907
    Episode_Reward/pen_base_height: -0.3167
      Episode_Reward/pen_lin_vel_z: -0.0664
     Episode_Reward/pen_ang_vel_xy: -0.1084
   Episode_Reward/pen_joint_torque: -0.1431
    Episode_Reward/pen_joint_accel: -0.0678
    Episode_Reward/pen_action_rate: -0.1916
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0279
   Episode_Reward/pen_joint_powers: -0.0503
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.4337
Episode_Reward/pen_flat_orientation: -0.1322
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.2131
   Episode_Reward/foot_landing_vel: -0.0857
   Episode_Reward/test_gait_reward: -0.7118
Metrics/base_velocity/error_vel_xy: 1.9194
Metrics/base_velocity/error_vel_yaw: 0.7135
      Episode_Termination/time_out: 2.9583
  Episode_Termination/base_contact: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 1.07s
                        Total time: 1092.96s
                               ETA: 2164.2s

################################################################################
                     [1m Learning iteration 1007/3000 [0m                     

                       Computation: 93025 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 0.9509
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5728
                     Learning rate: 0.0003
                       Mean reward: 68.76
               Mean episode length: 837.60
       Episode_Reward/keep_balance: 0.8480
     Episode_Reward/rew_lin_vel_xy: 2.8513
      Episode_Reward/rew_ang_vel_z: 2.5251
    Episode_Reward/pen_base_height: -0.3451
      Episode_Reward/pen_lin_vel_z: -0.0782
     Episode_Reward/pen_ang_vel_xy: -0.1287
   Episode_Reward/pen_joint_torque: -0.1684
    Episode_Reward/pen_joint_accel: -0.0805
    Episode_Reward/pen_action_rate: -0.2230
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0318
   Episode_Reward/pen_joint_powers: -0.0584
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4957
Episode_Reward/pen_flat_orientation: -0.1383
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.2429
   Episode_Reward/foot_landing_vel: -0.1058
   Episode_Reward/test_gait_reward: -0.8133
Metrics/base_velocity/error_vel_xy: 2.2877
Metrics/base_velocity/error_vel_yaw: 0.7877
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 1.06s
                        Total time: 1094.01s
                               ETA: 2163.1s

################################################################################
                     [1m Learning iteration 1008/3000 [0m                     

                       Computation: 88745 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 0.9862
                    Surrogate loss: -0.0034
             Mean action noise std: 0.5723
                     Learning rate: 0.0004
                       Mean reward: 65.21
               Mean episode length: 843.47
       Episode_Reward/keep_balance: 0.8376
     Episode_Reward/rew_lin_vel_xy: 2.8090
      Episode_Reward/rew_ang_vel_z: 2.4940
    Episode_Reward/pen_base_height: -0.3484
      Episode_Reward/pen_lin_vel_z: -0.0813
     Episode_Reward/pen_ang_vel_xy: -0.1282
   Episode_Reward/pen_joint_torque: -0.1721
    Episode_Reward/pen_joint_accel: -0.0758
    Episode_Reward/pen_action_rate: -0.2239
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0323
   Episode_Reward/pen_joint_powers: -0.0599
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4950
Episode_Reward/pen_flat_orientation: -0.1406
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.2544
   Episode_Reward/foot_landing_vel: -0.1032
   Episode_Reward/test_gait_reward: -0.8073
Metrics/base_velocity/error_vel_xy: 2.2867
Metrics/base_velocity/error_vel_yaw: 0.7800
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 1.11s
                        Total time: 1095.12s
                               ETA: 2162.0s

################################################################################
                     [1m Learning iteration 1009/3000 [0m                     

                       Computation: 89738 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 1.0858
                    Surrogate loss: -0.0026
             Mean action noise std: 0.5736
                     Learning rate: 0.0006
                       Mean reward: 63.33
               Mean episode length: 793.33
       Episode_Reward/keep_balance: 0.8021
     Episode_Reward/rew_lin_vel_xy: 2.8725
      Episode_Reward/rew_ang_vel_z: 2.3597
    Episode_Reward/pen_base_height: -0.3301
      Episode_Reward/pen_lin_vel_z: -0.0734
     Episode_Reward/pen_ang_vel_xy: -0.1213
   Episode_Reward/pen_joint_torque: -0.1522
    Episode_Reward/pen_joint_accel: -0.0763
    Episode_Reward/pen_action_rate: -0.2127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0303
   Episode_Reward/pen_joint_powers: -0.0543
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.4774
Episode_Reward/pen_flat_orientation: -0.1338
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.2329
   Episode_Reward/foot_landing_vel: -0.0922
   Episode_Reward/test_gait_reward: -0.7681
Metrics/base_velocity/error_vel_xy: 2.0134
Metrics/base_velocity/error_vel_yaw: 0.7665
      Episode_Termination/time_out: 2.8333
  Episode_Termination/base_contact: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 1.10s
                        Total time: 1096.22s
                               ETA: 2161.0s

################################################################################
                     [1m Learning iteration 1010/3000 [0m                     

                       Computation: 92428 steps/s (collection: 0.942s, learning 0.121s)
               Value function loss: 1.0788
                    Surrogate loss: 0.0013
             Mean action noise std: 0.5739
                     Learning rate: 0.0001
                       Mean reward: 63.80
               Mean episode length: 802.89
       Episode_Reward/keep_balance: 0.7592
     Episode_Reward/rew_lin_vel_xy: 2.4455
      Episode_Reward/rew_ang_vel_z: 2.2663
    Episode_Reward/pen_base_height: -0.3176
      Episode_Reward/pen_lin_vel_z: -0.0684
     Episode_Reward/pen_ang_vel_xy: -0.1113
   Episode_Reward/pen_joint_torque: -0.1493
    Episode_Reward/pen_joint_accel: -0.0647
    Episode_Reward/pen_action_rate: -0.1950
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0272
   Episode_Reward/pen_joint_powers: -0.0513
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4400
Episode_Reward/pen_flat_orientation: -0.1264
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.2039
   Episode_Reward/foot_landing_vel: -0.0831
   Episode_Reward/test_gait_reward: -0.7230
Metrics/base_velocity/error_vel_xy: 2.1805
Metrics/base_velocity/error_vel_yaw: 0.7059
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 1.06s
                        Total time: 1097.28s
                               ETA: 2159.8s

################################################################################
                     [1m Learning iteration 1011/3000 [0m                     

                       Computation: 91582 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.1437
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5740
                     Learning rate: 0.0001
                       Mean reward: 68.46
               Mean episode length: 818.36
       Episode_Reward/keep_balance: 0.8331
     Episode_Reward/rew_lin_vel_xy: 2.9858
      Episode_Reward/rew_ang_vel_z: 2.4777
    Episode_Reward/pen_base_height: -0.3545
      Episode_Reward/pen_lin_vel_z: -0.0775
     Episode_Reward/pen_ang_vel_xy: -0.1241
   Episode_Reward/pen_joint_torque: -0.1645
    Episode_Reward/pen_joint_accel: -0.0759
    Episode_Reward/pen_action_rate: -0.2192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0317
   Episode_Reward/pen_joint_powers: -0.0579
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4915
Episode_Reward/pen_flat_orientation: -0.1377
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.2430
   Episode_Reward/foot_landing_vel: -0.1009
   Episode_Reward/test_gait_reward: -0.7994
Metrics/base_velocity/error_vel_xy: 2.1714
Metrics/base_velocity/error_vel_yaw: 0.7797
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 1.07s
                        Total time: 1098.35s
                               ETA: 2158.7s

################################################################################
                     [1m Learning iteration 1012/3000 [0m                     

                       Computation: 92022 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 1.0237
                    Surrogate loss: -0.0033
             Mean action noise std: 0.5740
                     Learning rate: 0.0003
                       Mean reward: 67.35
               Mean episode length: 844.99
       Episode_Reward/keep_balance: 0.8547
     Episode_Reward/rew_lin_vel_xy: 2.9132
      Episode_Reward/rew_ang_vel_z: 2.5495
    Episode_Reward/pen_base_height: -0.3389
      Episode_Reward/pen_lin_vel_z: -0.0782
     Episode_Reward/pen_ang_vel_xy: -0.1287
   Episode_Reward/pen_joint_torque: -0.1662
    Episode_Reward/pen_joint_accel: -0.0818
    Episode_Reward/pen_action_rate: -0.2265
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0322
   Episode_Reward/pen_joint_powers: -0.0583
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5087
Episode_Reward/pen_flat_orientation: -0.1358
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.2364
   Episode_Reward/foot_landing_vel: -0.1107
   Episode_Reward/test_gait_reward: -0.8112
Metrics/base_velocity/error_vel_xy: 2.2427
Metrics/base_velocity/error_vel_yaw: 0.7887
      Episode_Termination/time_out: 3.1250
  Episode_Termination/base_contact: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 1.07s
                        Total time: 1099.42s
                               ETA: 2157.6s

################################################################################
                     [1m Learning iteration 1013/3000 [0m                     

                       Computation: 91808 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 1.0134
                    Surrogate loss: -0.0036
             Mean action noise std: 0.5732
                     Learning rate: 0.0006
                       Mean reward: 62.50
               Mean episode length: 803.16
       Episode_Reward/keep_balance: 0.8017
     Episode_Reward/rew_lin_vel_xy: 2.7529
      Episode_Reward/rew_ang_vel_z: 2.3504
    Episode_Reward/pen_base_height: -0.3433
      Episode_Reward/pen_lin_vel_z: -0.0722
     Episode_Reward/pen_ang_vel_xy: -0.1200
   Episode_Reward/pen_joint_torque: -0.1543
    Episode_Reward/pen_joint_accel: -0.0697
    Episode_Reward/pen_action_rate: -0.2111
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0303
   Episode_Reward/pen_joint_powers: -0.0546
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.4755
Episode_Reward/pen_flat_orientation: -0.1447
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2274
   Episode_Reward/foot_landing_vel: -0.0955
   Episode_Reward/test_gait_reward: -0.7672
Metrics/base_velocity/error_vel_xy: 2.0939
Metrics/base_velocity/error_vel_yaw: 0.7718
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 1.07s
                        Total time: 1100.49s
                               ETA: 2156.5s

################################################################################
                     [1m Learning iteration 1014/3000 [0m                     

                       Computation: 92680 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 1.2207
                    Surrogate loss: -0.0028
             Mean action noise std: 0.5726
                     Learning rate: 0.0009
                       Mean reward: 64.78
               Mean episode length: 803.87
       Episode_Reward/keep_balance: 0.8102
     Episode_Reward/rew_lin_vel_xy: 2.8619
      Episode_Reward/rew_ang_vel_z: 2.4058
    Episode_Reward/pen_base_height: -0.3394
      Episode_Reward/pen_lin_vel_z: -0.0733
     Episode_Reward/pen_ang_vel_xy: -0.1226
   Episode_Reward/pen_joint_torque: -0.1579
    Episode_Reward/pen_joint_accel: -0.0725
    Episode_Reward/pen_action_rate: -0.2132
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0303
   Episode_Reward/pen_joint_powers: -0.0549
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4790
Episode_Reward/pen_flat_orientation: -0.1387
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.2326
   Episode_Reward/foot_landing_vel: -0.0936
   Episode_Reward/test_gait_reward: -0.7696
Metrics/base_velocity/error_vel_xy: 2.0842
Metrics/base_velocity/error_vel_yaw: 0.7589
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 1.06s
                        Total time: 1101.55s
                               ETA: 2155.4s

################################################################################
                     [1m Learning iteration 1015/3000 [0m                     

                       Computation: 92658 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 0.9488
                    Surrogate loss: 0.0033
             Mean action noise std: 0.5724
                     Learning rate: 0.0003
                       Mean reward: 68.51
               Mean episode length: 825.23
       Episode_Reward/keep_balance: 0.8148
     Episode_Reward/rew_lin_vel_xy: 2.9992
      Episode_Reward/rew_ang_vel_z: 2.4001
    Episode_Reward/pen_base_height: -0.3477
      Episode_Reward/pen_lin_vel_z: -0.0692
     Episode_Reward/pen_ang_vel_xy: -0.1173
   Episode_Reward/pen_joint_torque: -0.1538
    Episode_Reward/pen_joint_accel: -0.0719
    Episode_Reward/pen_action_rate: -0.2112
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0299
   Episode_Reward/pen_joint_powers: -0.0540
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4806
Episode_Reward/pen_flat_orientation: -0.1384
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.2258
   Episode_Reward/foot_landing_vel: -0.0900
   Episode_Reward/test_gait_reward: -0.7767
Metrics/base_velocity/error_vel_xy: 1.9798
Metrics/base_velocity/error_vel_yaw: 0.7797
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 1.06s
                        Total time: 1102.61s
                               ETA: 2154.2s

################################################################################
                     [1m Learning iteration 1016/3000 [0m                     

                       Computation: 88760 steps/s (collection: 0.982s, learning 0.125s)
               Value function loss: 0.9559
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5726
                     Learning rate: 0.0002
                       Mean reward: 74.47
               Mean episode length: 896.42
       Episode_Reward/keep_balance: 0.8841
     Episode_Reward/rew_lin_vel_xy: 3.2100
      Episode_Reward/rew_ang_vel_z: 2.6304
    Episode_Reward/pen_base_height: -0.3575
      Episode_Reward/pen_lin_vel_z: -0.0807
     Episode_Reward/pen_ang_vel_xy: -0.1334
   Episode_Reward/pen_joint_torque: -0.1695
    Episode_Reward/pen_joint_accel: -0.0800
    Episode_Reward/pen_action_rate: -0.2344
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0332
   Episode_Reward/pen_joint_powers: -0.0602
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5241
Episode_Reward/pen_flat_orientation: -0.1378
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.2570
   Episode_Reward/foot_landing_vel: -0.1025
   Episode_Reward/test_gait_reward: -0.8444
Metrics/base_velocity/error_vel_xy: 2.2462
Metrics/base_velocity/error_vel_yaw: 0.8235
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 1.11s
                        Total time: 1103.72s
                               ETA: 2153.2s

################################################################################
                     [1m Learning iteration 1017/3000 [0m                     

                       Computation: 86303 steps/s (collection: 1.013s, learning 0.126s)
               Value function loss: 1.0084
                    Surrogate loss: -0.0029
             Mean action noise std: 0.5727
                     Learning rate: 0.0003
                       Mean reward: 66.72
               Mean episode length: 843.16
       Episode_Reward/keep_balance: 0.8376
     Episode_Reward/rew_lin_vel_xy: 2.8810
      Episode_Reward/rew_ang_vel_z: 2.4719
    Episode_Reward/pen_base_height: -0.3440
      Episode_Reward/pen_lin_vel_z: -0.0748
     Episode_Reward/pen_ang_vel_xy: -0.1273
   Episode_Reward/pen_joint_torque: -0.1668
    Episode_Reward/pen_joint_accel: -0.0766
    Episode_Reward/pen_action_rate: -0.2209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0312
   Episode_Reward/pen_joint_powers: -0.0573
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4990
Episode_Reward/pen_flat_orientation: -0.1323
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.2309
   Episode_Reward/foot_landing_vel: -0.0959
   Episode_Reward/test_gait_reward: -0.7957
Metrics/base_velocity/error_vel_xy: 2.2232
Metrics/base_velocity/error_vel_yaw: 0.7995
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 1.14s
                        Total time: 1104.86s
                               ETA: 2152.2s

################################################################################
                     [1m Learning iteration 1018/3000 [0m                     

                       Computation: 89854 steps/s (collection: 0.968s, learning 0.126s)
               Value function loss: 0.9929
                    Surrogate loss: -0.0008
             Mean action noise std: 0.5726
                     Learning rate: 0.0001
                       Mean reward: 65.14
               Mean episode length: 813.88
       Episode_Reward/keep_balance: 0.8147
     Episode_Reward/rew_lin_vel_xy: 2.8238
      Episode_Reward/rew_ang_vel_z: 2.4048
    Episode_Reward/pen_base_height: -0.3506
      Episode_Reward/pen_lin_vel_z: -0.0690
     Episode_Reward/pen_ang_vel_xy: -0.1232
   Episode_Reward/pen_joint_torque: -0.1553
    Episode_Reward/pen_joint_accel: -0.0767
    Episode_Reward/pen_action_rate: -0.2130
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0304
   Episode_Reward/pen_joint_powers: -0.0545
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4852
Episode_Reward/pen_flat_orientation: -0.1391
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2212
   Episode_Reward/foot_landing_vel: -0.0913
   Episode_Reward/test_gait_reward: -0.7776
Metrics/base_velocity/error_vel_xy: 2.1111
Metrics/base_velocity/error_vel_yaw: 0.7795
      Episode_Termination/time_out: 2.8750
  Episode_Termination/base_contact: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 1.09s
                        Total time: 1105.95s
                               ETA: 2151.1s

################################################################################
                     [1m Learning iteration 1019/3000 [0m                     

                       Computation: 88851 steps/s (collection: 0.980s, learning 0.126s)
               Value function loss: 1.0899
                    Surrogate loss: 0.0070
             Mean action noise std: 0.5727
                     Learning rate: 0.0000
                       Mean reward: 73.25
               Mean episode length: 892.69
       Episode_Reward/keep_balance: 0.8704
     Episode_Reward/rew_lin_vel_xy: 3.0285
      Episode_Reward/rew_ang_vel_z: 2.5845
    Episode_Reward/pen_base_height: -0.3641
      Episode_Reward/pen_lin_vel_z: -0.0799
     Episode_Reward/pen_ang_vel_xy: -0.1312
   Episode_Reward/pen_joint_torque: -0.1703
    Episode_Reward/pen_joint_accel: -0.0731
    Episode_Reward/pen_action_rate: -0.2303
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0331
   Episode_Reward/pen_joint_powers: -0.0598
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5169
Episode_Reward/pen_flat_orientation: -0.1490
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.2613
   Episode_Reward/foot_landing_vel: -0.1060
   Episode_Reward/test_gait_reward: -0.8322
Metrics/base_velocity/error_vel_xy: 2.3131
Metrics/base_velocity/error_vel_yaw: 0.8186
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 1.11s
                        Total time: 1107.06s
                               ETA: 2150.1s

################################################################################
                     [1m Learning iteration 1020/3000 [0m                     

                       Computation: 91017 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 1.0458
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5725
                     Learning rate: 0.0001
                       Mean reward: 72.28
               Mean episode length: 882.99
       Episode_Reward/keep_balance: 0.8711
     Episode_Reward/rew_lin_vel_xy: 3.1905
      Episode_Reward/rew_ang_vel_z: 2.5674
    Episode_Reward/pen_base_height: -0.3538
      Episode_Reward/pen_lin_vel_z: -0.0786
     Episode_Reward/pen_ang_vel_xy: -0.1288
   Episode_Reward/pen_joint_torque: -0.1717
    Episode_Reward/pen_joint_accel: -0.0830
    Episode_Reward/pen_action_rate: -0.2313
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0329
   Episode_Reward/pen_joint_powers: -0.0598
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5193
Episode_Reward/pen_flat_orientation: -0.1359
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.2533
   Episode_Reward/foot_landing_vel: -0.1028
   Episode_Reward/test_gait_reward: -0.8292
Metrics/base_velocity/error_vel_xy: 2.1425
Metrics/base_velocity/error_vel_yaw: 0.8273
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 1.08s
                        Total time: 1108.14s
                               ETA: 2149.0s

################################################################################
                     [1m Learning iteration 1021/3000 [0m                     

                       Computation: 89650 steps/s (collection: 0.968s, learning 0.128s)
               Value function loss: 1.0223
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5723
                     Learning rate: 0.0001
                       Mean reward: 64.75
               Mean episode length: 826.51
       Episode_Reward/keep_balance: 0.8462
     Episode_Reward/rew_lin_vel_xy: 2.9834
      Episode_Reward/rew_ang_vel_z: 2.5116
    Episode_Reward/pen_base_height: -0.3478
      Episode_Reward/pen_lin_vel_z: -0.0752
     Episode_Reward/pen_ang_vel_xy: -0.1281
   Episode_Reward/pen_joint_torque: -0.1643
    Episode_Reward/pen_joint_accel: -0.0823
    Episode_Reward/pen_action_rate: -0.2245
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0329
   Episode_Reward/pen_joint_powers: -0.0578
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5071
Episode_Reward/pen_flat_orientation: -0.1440
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.2507
   Episode_Reward/foot_landing_vel: -0.1060
   Episode_Reward/test_gait_reward: -0.8055
Metrics/base_velocity/error_vel_xy: 2.1529
Metrics/base_velocity/error_vel_yaw: 0.7953
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 1.10s
                        Total time: 1109.24s
                               ETA: 2147.9s

################################################################################
                     [1m Learning iteration 1022/3000 [0m                     

                       Computation: 88990 steps/s (collection: 0.980s, learning 0.125s)
               Value function loss: 1.0727
                    Surrogate loss: -0.0031
             Mean action noise std: 0.5715
                     Learning rate: 0.0003
                       Mean reward: 68.13
               Mean episode length: 843.89
       Episode_Reward/keep_balance: 0.8437
     Episode_Reward/rew_lin_vel_xy: 2.8959
      Episode_Reward/rew_ang_vel_z: 2.5082
    Episode_Reward/pen_base_height: -0.3592
      Episode_Reward/pen_lin_vel_z: -0.0738
     Episode_Reward/pen_ang_vel_xy: -0.1307
   Episode_Reward/pen_joint_torque: -0.1648
    Episode_Reward/pen_joint_accel: -0.0821
    Episode_Reward/pen_action_rate: -0.2247
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0323
   Episode_Reward/pen_joint_powers: -0.0576
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5020
Episode_Reward/pen_flat_orientation: -0.1429
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.2456
   Episode_Reward/foot_landing_vel: -0.0972
   Episode_Reward/test_gait_reward: -0.8057
Metrics/base_velocity/error_vel_xy: 2.2058
Metrics/base_velocity/error_vel_yaw: 0.7890
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 1.10s
                        Total time: 1110.34s
                               ETA: 2146.9s

################################################################################
                     [1m Learning iteration 1023/3000 [0m                     

                       Computation: 87794 steps/s (collection: 0.995s, learning 0.125s)
               Value function loss: 1.1432
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5715
                     Learning rate: 0.0003
                       Mean reward: 59.63
               Mean episode length: 783.36
       Episode_Reward/keep_balance: 0.7777
     Episode_Reward/rew_lin_vel_xy: 2.5806
      Episode_Reward/rew_ang_vel_z: 2.3192
    Episode_Reward/pen_base_height: -0.3430
      Episode_Reward/pen_lin_vel_z: -0.0666
     Episode_Reward/pen_ang_vel_xy: -0.1163
   Episode_Reward/pen_joint_torque: -0.1524
    Episode_Reward/pen_joint_accel: -0.0751
    Episode_Reward/pen_action_rate: -0.2024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0293
   Episode_Reward/pen_joint_powers: -0.0525
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4564
Episode_Reward/pen_flat_orientation: -0.1355
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2149
   Episode_Reward/foot_landing_vel: -0.0925
   Episode_Reward/test_gait_reward: -0.7393
Metrics/base_velocity/error_vel_xy: 2.1043
Metrics/base_velocity/error_vel_yaw: 0.7237
      Episode_Termination/time_out: 3.0000
  Episode_Termination/base_contact: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 1.12s
                        Total time: 1111.46s
                               ETA: 2145.9s

################################################################################
                     [1m Learning iteration 1024/3000 [0m                     

                       Computation: 88690 steps/s (collection: 0.980s, learning 0.128s)
               Value function loss: 1.1063
                    Surrogate loss: -0.0036
             Mean action noise std: 0.5717
                     Learning rate: 0.0006
                       Mean reward: 66.13
               Mean episode length: 855.73
       Episode_Reward/keep_balance: 0.8694
     Episode_Reward/rew_lin_vel_xy: 2.9778
      Episode_Reward/rew_ang_vel_z: 2.5743
    Episode_Reward/pen_base_height: -0.3601
      Episode_Reward/pen_lin_vel_z: -0.0772
     Episode_Reward/pen_ang_vel_xy: -0.1312
   Episode_Reward/pen_joint_torque: -0.1705
    Episode_Reward/pen_joint_accel: -0.0801
    Episode_Reward/pen_action_rate: -0.2296
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0333
   Episode_Reward/pen_joint_powers: -0.0595
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5178
Episode_Reward/pen_flat_orientation: -0.1494
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.2558
   Episode_Reward/foot_landing_vel: -0.1056
   Episode_Reward/test_gait_reward: -0.8293
Metrics/base_velocity/error_vel_xy: 2.3028
Metrics/base_velocity/error_vel_yaw: 0.8225
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 1.11s
                        Total time: 1112.57s
                               ETA: 2144.8s

################################################################################
                     [1m Learning iteration 1025/3000 [0m                     

                       Computation: 85066 steps/s (collection: 1.031s, learning 0.125s)
               Value function loss: 1.0795
                    Surrogate loss: -0.0011
             Mean action noise std: 0.5721
                     Learning rate: 0.0003
                       Mean reward: 65.99
               Mean episode length: 799.40
       Episode_Reward/keep_balance: 0.7414
     Episode_Reward/rew_lin_vel_xy: 2.6649
      Episode_Reward/rew_ang_vel_z: 2.1944
    Episode_Reward/pen_base_height: -0.3298
      Episode_Reward/pen_lin_vel_z: -0.0620
     Episode_Reward/pen_ang_vel_xy: -0.1139
   Episode_Reward/pen_joint_torque: -0.1377
    Episode_Reward/pen_joint_accel: -0.0688
    Episode_Reward/pen_action_rate: -0.1927
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0281
   Episode_Reward/pen_joint_powers: -0.0489
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.4394
Episode_Reward/pen_flat_orientation: -0.1416
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.2068
   Episode_Reward/foot_landing_vel: -0.0840
   Episode_Reward/test_gait_reward: -0.7037
Metrics/base_velocity/error_vel_xy: 1.9102
Metrics/base_velocity/error_vel_yaw: 0.7033
      Episode_Termination/time_out: 2.7917
  Episode_Termination/base_contact: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 1.16s
                        Total time: 1113.73s
                               ETA: 2143.9s

################################################################################
                     [1m Learning iteration 1026/3000 [0m                     

                       Computation: 92729 steps/s (collection: 0.938s, learning 0.122s)
               Value function loss: 1.1069
                    Surrogate loss: -0.0032
             Mean action noise std: 0.5718
                     Learning rate: 0.0006
                       Mean reward: 66.61
               Mean episode length: 836.44
       Episode_Reward/keep_balance: 0.8533
     Episode_Reward/rew_lin_vel_xy: 2.9616
      Episode_Reward/rew_ang_vel_z: 2.5049
    Episode_Reward/pen_base_height: -0.3499
      Episode_Reward/pen_lin_vel_z: -0.0767
     Episode_Reward/pen_ang_vel_xy: -0.1313
   Episode_Reward/pen_joint_torque: -0.1646
    Episode_Reward/pen_joint_accel: -0.0749
    Episode_Reward/pen_action_rate: -0.2273
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0324
   Episode_Reward/pen_joint_powers: -0.0578
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5138
Episode_Reward/pen_flat_orientation: -0.1405
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.2427
   Episode_Reward/foot_landing_vel: -0.1094
   Episode_Reward/test_gait_reward: -0.8162
Metrics/base_velocity/error_vel_xy: 2.2541
Metrics/base_velocity/error_vel_yaw: 0.8221
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 1.06s
                        Total time: 1114.79s
                               ETA: 2142.7s

################################################################################
                     [1m Learning iteration 1027/3000 [0m                     

                       Computation: 92554 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 1.1473
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5717
                     Learning rate: 0.0003
                       Mean reward: 68.21
               Mean episode length: 872.37
       Episode_Reward/keep_balance: 0.8580
     Episode_Reward/rew_lin_vel_xy: 2.9481
      Episode_Reward/rew_ang_vel_z: 2.5484
    Episode_Reward/pen_base_height: -0.3645
      Episode_Reward/pen_lin_vel_z: -0.0724
     Episode_Reward/pen_ang_vel_xy: -0.1282
   Episode_Reward/pen_joint_torque: -0.1640
    Episode_Reward/pen_joint_accel: -0.0753
    Episode_Reward/pen_action_rate: -0.2247
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0319
   Episode_Reward/pen_joint_powers: -0.0569
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5078
Episode_Reward/pen_flat_orientation: -0.1374
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2352
   Episode_Reward/foot_landing_vel: -0.1009
   Episode_Reward/test_gait_reward: -0.8109
Metrics/base_velocity/error_vel_xy: 2.2534
Metrics/base_velocity/error_vel_yaw: 0.8020
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 1.06s
                        Total time: 1115.85s
                               ETA: 2141.6s

################################################################################
                     [1m Learning iteration 1028/3000 [0m                     

                       Computation: 91259 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 1.0965
                    Surrogate loss: 0.0026
             Mean action noise std: 0.5719
                     Learning rate: 0.0001
                       Mean reward: 65.26
               Mean episode length: 783.60
       Episode_Reward/keep_balance: 0.7698
     Episode_Reward/rew_lin_vel_xy: 2.8147
      Episode_Reward/rew_ang_vel_z: 2.2670
    Episode_Reward/pen_base_height: -0.3269
      Episode_Reward/pen_lin_vel_z: -0.0666
     Episode_Reward/pen_ang_vel_xy: -0.1206
   Episode_Reward/pen_joint_torque: -0.1460
    Episode_Reward/pen_joint_accel: -0.0704
    Episode_Reward/pen_action_rate: -0.2041
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0293
   Episode_Reward/pen_joint_powers: -0.0514
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4635
Episode_Reward/pen_flat_orientation: -0.1332
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2190
   Episode_Reward/foot_landing_vel: -0.0920
   Episode_Reward/test_gait_reward: -0.7288
Metrics/base_velocity/error_vel_xy: 1.8798
Metrics/base_velocity/error_vel_yaw: 0.7374
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 1.08s
                        Total time: 1116.93s
                               ETA: 2140.5s

################################################################################
                     [1m Learning iteration 1029/3000 [0m                     

                       Computation: 91863 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.9685
                    Surrogate loss: 0.0010
             Mean action noise std: 0.5720
                     Learning rate: 0.0001
                       Mean reward: 65.62
               Mean episode length: 829.90
       Episode_Reward/keep_balance: 0.8313
     Episode_Reward/rew_lin_vel_xy: 2.8572
      Episode_Reward/rew_ang_vel_z: 2.4399
    Episode_Reward/pen_base_height: -0.3454
      Episode_Reward/pen_lin_vel_z: -0.0656
     Episode_Reward/pen_ang_vel_xy: -0.1233
   Episode_Reward/pen_joint_torque: -0.1545
    Episode_Reward/pen_joint_accel: -0.0756
    Episode_Reward/pen_action_rate: -0.2158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0300
   Episode_Reward/pen_joint_powers: -0.0534
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4974
Episode_Reward/pen_flat_orientation: -0.1373
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.2111
   Episode_Reward/foot_landing_vel: -0.0900
   Episode_Reward/test_gait_reward: -0.7788
Metrics/base_velocity/error_vel_xy: 2.1892
Metrics/base_velocity/error_vel_yaw: 0.8017
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 1.07s
                        Total time: 1118.00s
                               ETA: 2139.4s

################################################################################
                     [1m Learning iteration 1030/3000 [0m                     

                       Computation: 91870 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 1.0507
                    Surrogate loss: -0.0042
             Mean action noise std: 0.5722
                     Learning rate: 0.0003
                       Mean reward: 65.79
               Mean episode length: 819.82
       Episode_Reward/keep_balance: 0.8306
     Episode_Reward/rew_lin_vel_xy: 2.9538
      Episode_Reward/rew_ang_vel_z: 2.4482
    Episode_Reward/pen_base_height: -0.3571
      Episode_Reward/pen_lin_vel_z: -0.0724
     Episode_Reward/pen_ang_vel_xy: -0.1279
   Episode_Reward/pen_joint_torque: -0.1644
    Episode_Reward/pen_joint_accel: -0.0806
    Episode_Reward/pen_action_rate: -0.2222
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0328
   Episode_Reward/pen_joint_powers: -0.0576
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5011
Episode_Reward/pen_flat_orientation: -0.1432
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.2465
   Episode_Reward/foot_landing_vel: -0.1088
   Episode_Reward/test_gait_reward: -0.7973
Metrics/base_velocity/error_vel_xy: 2.1783
Metrics/base_velocity/error_vel_yaw: 0.7954
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 1.07s
                        Total time: 1119.07s
                               ETA: 2138.3s

################################################################################
                     [1m Learning iteration 1031/3000 [0m                     

                       Computation: 91529 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 1.1208
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5727
                     Learning rate: 0.0004
                       Mean reward: 72.39
               Mean episode length: 867.74
       Episode_Reward/keep_balance: 0.8668
     Episode_Reward/rew_lin_vel_xy: 3.1113
      Episode_Reward/rew_ang_vel_z: 2.5278
    Episode_Reward/pen_base_height: -0.3707
      Episode_Reward/pen_lin_vel_z: -0.0707
     Episode_Reward/pen_ang_vel_xy: -0.1278
   Episode_Reward/pen_joint_torque: -0.1638
    Episode_Reward/pen_joint_accel: -0.0829
    Episode_Reward/pen_action_rate: -0.2289
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0326
   Episode_Reward/pen_joint_powers: -0.0569
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.5219
Episode_Reward/pen_flat_orientation: -0.1414
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2362
   Episode_Reward/foot_landing_vel: -0.1018
   Episode_Reward/test_gait_reward: -0.8189
Metrics/base_velocity/error_vel_xy: 2.1953
Metrics/base_velocity/error_vel_yaw: 0.8553
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 1.07s
                        Total time: 1120.14s
                               ETA: 2137.2s

################################################################################
                     [1m Learning iteration 1032/3000 [0m                     

                       Computation: 92173 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 1.1764
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5724
                     Learning rate: 0.0009
                       Mean reward: 73.65
               Mean episode length: 881.12
       Episode_Reward/keep_balance: 0.9022
     Episode_Reward/rew_lin_vel_xy: 3.2849
      Episode_Reward/rew_ang_vel_z: 2.6787
    Episode_Reward/pen_base_height: -0.3590
      Episode_Reward/pen_lin_vel_z: -0.0785
     Episode_Reward/pen_ang_vel_xy: -0.1360
   Episode_Reward/pen_joint_torque: -0.1749
    Episode_Reward/pen_joint_accel: -0.0870
    Episode_Reward/pen_action_rate: -0.2392
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0342
   Episode_Reward/pen_joint_powers: -0.0609
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.5427
Episode_Reward/pen_flat_orientation: -0.1346
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2515
   Episode_Reward/foot_landing_vel: -0.1106
   Episode_Reward/test_gait_reward: -0.8561
Metrics/base_velocity/error_vel_xy: 2.3452
Metrics/base_velocity/error_vel_yaw: 0.8453
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 1.07s
                        Total time: 1121.21s
                               ETA: 2136.0s

################################################################################
                     [1m Learning iteration 1033/3000 [0m                     

                       Computation: 92579 steps/s (collection: 0.937s, learning 0.125s)
               Value function loss: 1.2353
                    Surrogate loss: -0.0027
             Mean action noise std: 0.5719
                     Learning rate: 0.0006
                       Mean reward: 67.84
               Mean episode length: 828.30
       Episode_Reward/keep_balance: 0.8392
     Episode_Reward/rew_lin_vel_xy: 3.0250
      Episode_Reward/rew_ang_vel_z: 2.4840
    Episode_Reward/pen_base_height: -0.3587
      Episode_Reward/pen_lin_vel_z: -0.0733
     Episode_Reward/pen_ang_vel_xy: -0.1292
   Episode_Reward/pen_joint_torque: -0.1628
    Episode_Reward/pen_joint_accel: -0.0783
    Episode_Reward/pen_action_rate: -0.2223
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0319
   Episode_Reward/pen_joint_powers: -0.0565
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5045
Episode_Reward/pen_flat_orientation: -0.1359
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.2318
   Episode_Reward/foot_landing_vel: -0.1027
   Episode_Reward/test_gait_reward: -0.7945
Metrics/base_velocity/error_vel_xy: 2.2174
Metrics/base_velocity/error_vel_yaw: 0.7950
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 1.06s
                        Total time: 1122.27s
                               ETA: 2134.9s

################################################################################
                     [1m Learning iteration 1034/3000 [0m                     

                       Computation: 90945 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 1.1386
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5724
                     Learning rate: 0.0006
                       Mean reward: 68.15
               Mean episode length: 825.72
       Episode_Reward/keep_balance: 0.8298
     Episode_Reward/rew_lin_vel_xy: 2.9216
      Episode_Reward/rew_ang_vel_z: 2.4173
    Episode_Reward/pen_base_height: -0.3581
      Episode_Reward/pen_lin_vel_z: -0.0707
     Episode_Reward/pen_ang_vel_xy: -0.1229
   Episode_Reward/pen_joint_torque: -0.1637
    Episode_Reward/pen_joint_accel: -0.0743
    Episode_Reward/pen_action_rate: -0.2182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0310
   Episode_Reward/pen_joint_powers: -0.0556
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4972
Episode_Reward/pen_flat_orientation: -0.1385
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.2277
   Episode_Reward/foot_landing_vel: -0.0981
   Episode_Reward/test_gait_reward: -0.7879
Metrics/base_velocity/error_vel_xy: 2.2019
Metrics/base_velocity/error_vel_yaw: 0.8112
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 1.08s
                        Total time: 1123.35s
                               ETA: 2133.8s

################################################################################
                     [1m Learning iteration 1035/3000 [0m                     

                       Computation: 81413 steps/s (collection: 1.077s, learning 0.131s)
               Value function loss: 1.1731
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5736
                     Learning rate: 0.0009
                       Mean reward: 68.35
               Mean episode length: 823.94
       Episode_Reward/keep_balance: 0.8363
     Episode_Reward/rew_lin_vel_xy: 2.8899
      Episode_Reward/rew_ang_vel_z: 2.4835
    Episode_Reward/pen_base_height: -0.3595
      Episode_Reward/pen_lin_vel_z: -0.0697
     Episode_Reward/pen_ang_vel_xy: -0.1272
   Episode_Reward/pen_joint_torque: -0.1648
    Episode_Reward/pen_joint_accel: -0.0816
    Episode_Reward/pen_action_rate: -0.2196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0319
   Episode_Reward/pen_joint_powers: -0.0564
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.4997
Episode_Reward/pen_flat_orientation: -0.1465
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.2292
   Episode_Reward/foot_landing_vel: -0.1018
   Episode_Reward/test_gait_reward: -0.7950
Metrics/base_velocity/error_vel_xy: 2.2653
Metrics/base_velocity/error_vel_yaw: 0.7890
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 1.21s
                        Total time: 1124.56s
                               ETA: 2133.0s

################################################################################
                     [1m Learning iteration 1036/3000 [0m                     

                       Computation: 89237 steps/s (collection: 0.973s, learning 0.128s)
               Value function loss: 1.1466
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5745
                     Learning rate: 0.0009
                       Mean reward: 63.01
               Mean episode length: 793.84
       Episode_Reward/keep_balance: 0.7985
     Episode_Reward/rew_lin_vel_xy: 2.8345
      Episode_Reward/rew_ang_vel_z: 2.3411
    Episode_Reward/pen_base_height: -0.3595
      Episode_Reward/pen_lin_vel_z: -0.0708
     Episode_Reward/pen_ang_vel_xy: -0.1226
   Episode_Reward/pen_joint_torque: -0.1629
    Episode_Reward/pen_joint_accel: -0.0845
    Episode_Reward/pen_action_rate: -0.2137
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0321
   Episode_Reward/pen_joint_powers: -0.0559
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.4787
Episode_Reward/pen_flat_orientation: -0.1448
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.2461
   Episode_Reward/foot_landing_vel: -0.1050
   Episode_Reward/test_gait_reward: -0.7648
Metrics/base_velocity/error_vel_xy: 1.9887
Metrics/base_velocity/error_vel_yaw: 0.7781
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 1.10s
                        Total time: 1125.66s
                               ETA: 2131.9s

################################################################################
                     [1m Learning iteration 1037/3000 [0m                     

                       Computation: 91986 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 1.1498
                    Surrogate loss: 0.0057
             Mean action noise std: 0.5748
                     Learning rate: 0.0001
                       Mean reward: 65.78
               Mean episode length: 803.26
       Episode_Reward/keep_balance: 0.8069
     Episode_Reward/rew_lin_vel_xy: 2.9056
      Episode_Reward/rew_ang_vel_z: 2.3958
    Episode_Reward/pen_base_height: -0.3428
      Episode_Reward/pen_lin_vel_z: -0.0666
     Episode_Reward/pen_ang_vel_xy: -0.1223
   Episode_Reward/pen_joint_torque: -0.1527
    Episode_Reward/pen_joint_accel: -0.0698
    Episode_Reward/pen_action_rate: -0.2108
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0297
   Episode_Reward/pen_joint_powers: -0.0529
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4814
Episode_Reward/pen_flat_orientation: -0.1346
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.2125
   Episode_Reward/foot_landing_vel: -0.0928
   Episode_Reward/test_gait_reward: -0.7612
Metrics/base_velocity/error_vel_xy: 2.0685
Metrics/base_velocity/error_vel_yaw: 0.7598
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 1.07s
                        Total time: 1126.73s
                               ETA: 2130.8s

################################################################################
                     [1m Learning iteration 1038/3000 [0m                     

                       Computation: 91895 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 1.1254
                    Surrogate loss: -0.0029
             Mean action noise std: 0.5754
                     Learning rate: 0.0003
                       Mean reward: 61.94
               Mean episode length: 775.99
       Episode_Reward/keep_balance: 0.7361
     Episode_Reward/rew_lin_vel_xy: 2.6420
      Episode_Reward/rew_ang_vel_z: 2.1429
    Episode_Reward/pen_base_height: -0.3376
      Episode_Reward/pen_lin_vel_z: -0.0613
     Episode_Reward/pen_ang_vel_xy: -0.1158
   Episode_Reward/pen_joint_torque: -0.1399
    Episode_Reward/pen_joint_accel: -0.0731
    Episode_Reward/pen_action_rate: -0.1960
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0289
   Episode_Reward/pen_joint_powers: -0.0494
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.4448
Episode_Reward/pen_flat_orientation: -0.1354
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2094
   Episode_Reward/foot_landing_vel: -0.0941
   Episode_Reward/test_gait_reward: -0.7006
Metrics/base_velocity/error_vel_xy: 1.9037
Metrics/base_velocity/error_vel_yaw: 0.7284
      Episode_Termination/time_out: 3.2500
  Episode_Termination/base_contact: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 1.07s
                        Total time: 1127.80s
                               ETA: 2129.7s

################################################################################
                     [1m Learning iteration 1039/3000 [0m                     

                       Computation: 92649 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 1.0145
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5756
                     Learning rate: 0.0004
                       Mean reward: 71.31
               Mean episode length: 874.56
       Episode_Reward/keep_balance: 0.8721
     Episode_Reward/rew_lin_vel_xy: 3.1612
      Episode_Reward/rew_ang_vel_z: 2.5392
    Episode_Reward/pen_base_height: -0.3773
      Episode_Reward/pen_lin_vel_z: -0.0731
     Episode_Reward/pen_ang_vel_xy: -0.1324
   Episode_Reward/pen_joint_torque: -0.1720
    Episode_Reward/pen_joint_accel: -0.0825
    Episode_Reward/pen_action_rate: -0.2304
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0336
   Episode_Reward/pen_joint_powers: -0.0594
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5252
Episode_Reward/pen_flat_orientation: -0.1380
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.2423
   Episode_Reward/foot_landing_vel: -0.1064
   Episode_Reward/test_gait_reward: -0.8260
Metrics/base_velocity/error_vel_xy: 2.1886
Metrics/base_velocity/error_vel_yaw: 0.8545
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 1.06s
                        Total time: 1128.86s
                               ETA: 2128.5s

################################################################################
                     [1m Learning iteration 1040/3000 [0m                     

                       Computation: 90018 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 1.0719
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5756
                     Learning rate: 0.0003
                       Mean reward: 71.07
               Mean episode length: 846.44
       Episode_Reward/keep_balance: 0.8125
     Episode_Reward/rew_lin_vel_xy: 2.8654
      Episode_Reward/rew_ang_vel_z: 2.3810
    Episode_Reward/pen_base_height: -0.3508
      Episode_Reward/pen_lin_vel_z: -0.0672
     Episode_Reward/pen_ang_vel_xy: -0.1194
   Episode_Reward/pen_joint_torque: -0.1555
    Episode_Reward/pen_joint_accel: -0.0744
    Episode_Reward/pen_action_rate: -0.2134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0302
   Episode_Reward/pen_joint_powers: -0.0537
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4891
Episode_Reward/pen_flat_orientation: -0.1338
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2156
   Episode_Reward/foot_landing_vel: -0.0973
   Episode_Reward/test_gait_reward: -0.7674
Metrics/base_velocity/error_vel_xy: 2.1473
Metrics/base_velocity/error_vel_yaw: 0.7857
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 1.09s
                        Total time: 1129.95s
                               ETA: 2127.5s

################################################################################
                     [1m Learning iteration 1041/3000 [0m                     

                       Computation: 89341 steps/s (collection: 0.975s, learning 0.126s)
               Value function loss: 1.1090
                    Surrogate loss: -0.0034
             Mean action noise std: 0.5762
                     Learning rate: 0.0006
                       Mean reward: 74.76
               Mean episode length: 888.31
       Episode_Reward/keep_balance: 0.9028
     Episode_Reward/rew_lin_vel_xy: 3.2899
      Episode_Reward/rew_ang_vel_z: 2.6763
    Episode_Reward/pen_base_height: -0.3636
      Episode_Reward/pen_lin_vel_z: -0.0726
     Episode_Reward/pen_ang_vel_xy: -0.1330
   Episode_Reward/pen_joint_torque: -0.1734
    Episode_Reward/pen_joint_accel: -0.0809
    Episode_Reward/pen_action_rate: -0.2356
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0328
   Episode_Reward/pen_joint_powers: -0.0589
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5437
Episode_Reward/pen_flat_orientation: -0.1301
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2318
   Episode_Reward/foot_landing_vel: -0.1081
   Episode_Reward/test_gait_reward: -0.8545
Metrics/base_velocity/error_vel_xy: 2.2904
Metrics/base_velocity/error_vel_yaw: 0.8484
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 1.10s
                        Total time: 1131.05s
                               ETA: 2126.4s

################################################################################
                     [1m Learning iteration 1042/3000 [0m                     

                       Computation: 82287 steps/s (collection: 1.069s, learning 0.126s)
               Value function loss: 1.0561
                    Surrogate loss: -0.0035
             Mean action noise std: 0.5762
                     Learning rate: 0.0009
                       Mean reward: 66.01
               Mean episode length: 833.15
       Episode_Reward/keep_balance: 0.7795
     Episode_Reward/rew_lin_vel_xy: 2.6514
      Episode_Reward/rew_ang_vel_z: 2.2673
    Episode_Reward/pen_base_height: -0.3521
      Episode_Reward/pen_lin_vel_z: -0.0659
     Episode_Reward/pen_ang_vel_xy: -0.1193
   Episode_Reward/pen_joint_torque: -0.1484
    Episode_Reward/pen_joint_accel: -0.0762
    Episode_Reward/pen_action_rate: -0.2058
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0301
   Episode_Reward/pen_joint_powers: -0.0519
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.4702
Episode_Reward/pen_flat_orientation: -0.1465
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.2237
   Episode_Reward/foot_landing_vel: -0.0924
   Episode_Reward/test_gait_reward: -0.7332
Metrics/base_velocity/error_vel_xy: 2.1021
Metrics/base_velocity/error_vel_yaw: 0.7766
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 1.19s
                        Total time: 1132.24s
                               ETA: 2125.5s

################################################################################
                     [1m Learning iteration 1043/3000 [0m                     

                       Computation: 86152 steps/s (collection: 1.012s, learning 0.129s)
               Value function loss: 1.3605
                    Surrogate loss: -0.0029
             Mean action noise std: 0.5757
                     Learning rate: 0.0019
                       Mean reward: 70.26
               Mean episode length: 857.94
       Episode_Reward/keep_balance: 0.8619
     Episode_Reward/rew_lin_vel_xy: 3.0515
      Episode_Reward/rew_ang_vel_z: 2.5195
    Episode_Reward/pen_base_height: -0.3827
      Episode_Reward/pen_lin_vel_z: -0.0726
     Episode_Reward/pen_ang_vel_xy: -0.1397
   Episode_Reward/pen_joint_torque: -0.1689
    Episode_Reward/pen_joint_accel: -0.0815
    Episode_Reward/pen_action_rate: -0.2312
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0336
   Episode_Reward/pen_joint_powers: -0.0589
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5214
Episode_Reward/pen_flat_orientation: -0.1362
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.2444
   Episode_Reward/foot_landing_vel: -0.1027
   Episode_Reward/test_gait_reward: -0.8173
Metrics/base_velocity/error_vel_xy: 2.2012
Metrics/base_velocity/error_vel_yaw: 0.8414
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 1.14s
                        Total time: 1133.39s
                               ETA: 2124.6s

################################################################################
                     [1m Learning iteration 1044/3000 [0m                     

                       Computation: 88633 steps/s (collection: 0.981s, learning 0.128s)
               Value function loss: 1.3390
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5757
                     Learning rate: 0.0009
                       Mean reward: 69.53
               Mean episode length: 858.85
       Episode_Reward/keep_balance: 0.8440
     Episode_Reward/rew_lin_vel_xy: 3.0031
      Episode_Reward/rew_ang_vel_z: 2.4676
    Episode_Reward/pen_base_height: -0.3826
      Episode_Reward/pen_lin_vel_z: -0.0700
     Episode_Reward/pen_ang_vel_xy: -0.1250
   Episode_Reward/pen_joint_torque: -0.1651
    Episode_Reward/pen_joint_accel: -0.0701
    Episode_Reward/pen_action_rate: -0.2234
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0318
   Episode_Reward/pen_joint_powers: -0.0568
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5072
Episode_Reward/pen_flat_orientation: -0.1353
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.2410
   Episode_Reward/foot_landing_vel: -0.0973
   Episode_Reward/test_gait_reward: -0.8001
Metrics/base_velocity/error_vel_xy: 2.1714
Metrics/base_velocity/error_vel_yaw: 0.8244
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 1.11s
                        Total time: 1134.49s
                               ETA: 2123.5s

################################################################################
                     [1m Learning iteration 1045/3000 [0m                     

                       Computation: 89440 steps/s (collection: 0.973s, learning 0.127s)
               Value function loss: 1.0943
                    Surrogate loss: -0.0019
             Mean action noise std: 0.5763
                     Learning rate: 0.0006
                       Mean reward: 74.62
               Mean episode length: 870.84
       Episode_Reward/keep_balance: 0.8675
     Episode_Reward/rew_lin_vel_xy: 3.2215
      Episode_Reward/rew_ang_vel_z: 2.5688
    Episode_Reward/pen_base_height: -0.3717
      Episode_Reward/pen_lin_vel_z: -0.0710
     Episode_Reward/pen_ang_vel_xy: -0.1283
   Episode_Reward/pen_joint_torque: -0.1739
    Episode_Reward/pen_joint_accel: -0.0754
    Episode_Reward/pen_action_rate: -0.2253
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0323
   Episode_Reward/pen_joint_powers: -0.0585
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5149
Episode_Reward/pen_flat_orientation: -0.1352
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2364
   Episode_Reward/foot_landing_vel: -0.0984
   Episode_Reward/test_gait_reward: -0.8204
Metrics/base_velocity/error_vel_xy: 2.1832
Metrics/base_velocity/error_vel_yaw: 0.8199
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 1.10s
                        Total time: 1135.59s
                               ETA: 2122.5s

################################################################################
                     [1m Learning iteration 1046/3000 [0m                     

                       Computation: 89676 steps/s (collection: 0.969s, learning 0.127s)
               Value function loss: 1.1240
                    Surrogate loss: -0.0034
             Mean action noise std: 0.5778
                     Learning rate: 0.0009
                       Mean reward: 66.14
               Mean episode length: 791.39
       Episode_Reward/keep_balance: 0.8133
     Episode_Reward/rew_lin_vel_xy: 2.9047
      Episode_Reward/rew_ang_vel_z: 2.3844
    Episode_Reward/pen_base_height: -0.3478
      Episode_Reward/pen_lin_vel_z: -0.0651
     Episode_Reward/pen_ang_vel_xy: -0.1206
   Episode_Reward/pen_joint_torque: -0.1538
    Episode_Reward/pen_joint_accel: -0.0738
    Episode_Reward/pen_action_rate: -0.2120
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0303
   Episode_Reward/pen_joint_powers: -0.0533
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4841
Episode_Reward/pen_flat_orientation: -0.1317
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2137
   Episode_Reward/foot_landing_vel: -0.1017
   Episode_Reward/test_gait_reward: -0.7622
Metrics/base_velocity/error_vel_xy: 2.1155
Metrics/base_velocity/error_vel_yaw: 0.7904
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 1.10s
                        Total time: 1136.69s
                               ETA: 2121.4s

################################################################################
                     [1m Learning iteration 1047/3000 [0m                     

                       Computation: 91016 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 1.1344
                    Surrogate loss: 0.0002
             Mean action noise std: 0.5787
                     Learning rate: 0.0001
                       Mean reward: 74.28
               Mean episode length: 860.17
       Episode_Reward/keep_balance: 0.8495
     Episode_Reward/rew_lin_vel_xy: 3.1902
      Episode_Reward/rew_ang_vel_z: 2.5012
    Episode_Reward/pen_base_height: -0.3757
      Episode_Reward/pen_lin_vel_z: -0.0695
     Episode_Reward/pen_ang_vel_xy: -0.1246
   Episode_Reward/pen_joint_torque: -0.1649
    Episode_Reward/pen_joint_accel: -0.0836
    Episode_Reward/pen_action_rate: -0.2226
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0321
   Episode_Reward/pen_joint_powers: -0.0565
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5078
Episode_Reward/pen_flat_orientation: -0.1378
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2297
   Episode_Reward/foot_landing_vel: -0.1059
   Episode_Reward/test_gait_reward: -0.8078
Metrics/base_velocity/error_vel_xy: 2.0806
Metrics/base_velocity/error_vel_yaw: 0.8164
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 1.08s
                        Total time: 1137.77s
                               ETA: 2120.3s

################################################################################
                     [1m Learning iteration 1048/3000 [0m                     

                       Computation: 90877 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 1.1843
                    Surrogate loss: -0.0031
             Mean action noise std: 0.5793
                     Learning rate: 0.0003
                       Mean reward: 72.89
               Mean episode length: 877.40
       Episode_Reward/keep_balance: 0.8571
     Episode_Reward/rew_lin_vel_xy: 3.0805
      Episode_Reward/rew_ang_vel_z: 2.5110
    Episode_Reward/pen_base_height: -0.3679
      Episode_Reward/pen_lin_vel_z: -0.0705
     Episode_Reward/pen_ang_vel_xy: -0.1270
   Episode_Reward/pen_joint_torque: -0.1703
    Episode_Reward/pen_joint_accel: -0.0772
    Episode_Reward/pen_action_rate: -0.2254
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0323
   Episode_Reward/pen_joint_powers: -0.0577
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5117
Episode_Reward/pen_flat_orientation: -0.1349
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2352
   Episode_Reward/foot_landing_vel: -0.1109
   Episode_Reward/test_gait_reward: -0.8065
Metrics/base_velocity/error_vel_xy: 2.1728
Metrics/base_velocity/error_vel_yaw: 0.8355
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 1.08s
                        Total time: 1138.85s
                               ETA: 2119.2s

################################################################################
                     [1m Learning iteration 1049/3000 [0m                     

                       Computation: 86695 steps/s (collection: 1.009s, learning 0.125s)
               Value function loss: 1.1589
                    Surrogate loss: -0.0016
             Mean action noise std: 0.5812
                     Learning rate: 0.0006
                       Mean reward: 71.11
               Mean episode length: 837.88
       Episode_Reward/keep_balance: 0.8563
     Episode_Reward/rew_lin_vel_xy: 3.1615
      Episode_Reward/rew_ang_vel_z: 2.5281
    Episode_Reward/pen_base_height: -0.3560
      Episode_Reward/pen_lin_vel_z: -0.0714
     Episode_Reward/pen_ang_vel_xy: -0.1298
   Episode_Reward/pen_joint_torque: -0.1712
    Episode_Reward/pen_joint_accel: -0.0801
    Episode_Reward/pen_action_rate: -0.2268
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0331
   Episode_Reward/pen_joint_powers: -0.0586
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5127
Episode_Reward/pen_flat_orientation: -0.1330
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2449
   Episode_Reward/foot_landing_vel: -0.1047
   Episode_Reward/test_gait_reward: -0.8129
Metrics/base_velocity/error_vel_xy: 2.1747
Metrics/base_velocity/error_vel_yaw: 0.8184
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 1.13s
                        Total time: 1139.99s
                               ETA: 2118.2s

################################################################################
                     [1m Learning iteration 1050/3000 [0m                     

                       Computation: 88991 steps/s (collection: 0.980s, learning 0.125s)
               Value function loss: 1.1642
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5825
                     Learning rate: 0.0006
                       Mean reward: 71.45
               Mean episode length: 857.49
       Episode_Reward/keep_balance: 0.8490
     Episode_Reward/rew_lin_vel_xy: 3.0874
      Episode_Reward/rew_ang_vel_z: 2.5094
    Episode_Reward/pen_base_height: -0.3722
      Episode_Reward/pen_lin_vel_z: -0.0722
     Episode_Reward/pen_ang_vel_xy: -0.1273
   Episode_Reward/pen_joint_torque: -0.1708
    Episode_Reward/pen_joint_accel: -0.0780
    Episode_Reward/pen_action_rate: -0.2260
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0329
   Episode_Reward/pen_joint_powers: -0.0582
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5060
Episode_Reward/pen_flat_orientation: -0.1343
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.2537
   Episode_Reward/foot_landing_vel: -0.1042
   Episode_Reward/test_gait_reward: -0.8075
Metrics/base_velocity/error_vel_xy: 2.1530
Metrics/base_velocity/error_vel_yaw: 0.8087
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 1.10s
                        Total time: 1141.09s
                               ETA: 2117.2s

################################################################################
                     [1m Learning iteration 1051/3000 [0m                     

                       Computation: 86565 steps/s (collection: 1.008s, learning 0.128s)
               Value function loss: 1.1581
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5834
                     Learning rate: 0.0006
                       Mean reward: 68.43
               Mean episode length: 844.04
       Episode_Reward/keep_balance: 0.8253
     Episode_Reward/rew_lin_vel_xy: 2.8904
      Episode_Reward/rew_ang_vel_z: 2.4093
    Episode_Reward/pen_base_height: -0.3536
      Episode_Reward/pen_lin_vel_z: -0.0660
     Episode_Reward/pen_ang_vel_xy: -0.1232
   Episode_Reward/pen_joint_torque: -0.1596
    Episode_Reward/pen_joint_accel: -0.0777
    Episode_Reward/pen_action_rate: -0.2172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0312
   Episode_Reward/pen_joint_powers: -0.0545
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4978
Episode_Reward/pen_flat_orientation: -0.1291
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.2301
   Episode_Reward/foot_landing_vel: -0.0954
   Episode_Reward/test_gait_reward: -0.7756
Metrics/base_velocity/error_vel_xy: 2.1436
Metrics/base_velocity/error_vel_yaw: 0.8083
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 1.14s
                        Total time: 1142.23s
                               ETA: 2116.2s

################################################################################
                     [1m Learning iteration 1052/3000 [0m                     

                       Computation: 87986 steps/s (collection: 0.992s, learning 0.125s)
               Value function loss: 1.2246
                    Surrogate loss: -0.0034
             Mean action noise std: 0.5850
                     Learning rate: 0.0009
                       Mean reward: 66.12
               Mean episode length: 818.84
       Episode_Reward/keep_balance: 0.8142
     Episode_Reward/rew_lin_vel_xy: 2.8320
      Episode_Reward/rew_ang_vel_z: 2.4198
    Episode_Reward/pen_base_height: -0.3606
      Episode_Reward/pen_lin_vel_z: -0.0656
     Episode_Reward/pen_ang_vel_xy: -0.1216
   Episode_Reward/pen_joint_torque: -0.1660
    Episode_Reward/pen_joint_accel: -0.0695
    Episode_Reward/pen_action_rate: -0.2123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0302
   Episode_Reward/pen_joint_powers: -0.0554
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.4794
Episode_Reward/pen_flat_orientation: -0.1306
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2151
   Episode_Reward/foot_landing_vel: -0.0944
   Episode_Reward/test_gait_reward: -0.7679
Metrics/base_velocity/error_vel_xy: 2.1425
Metrics/base_velocity/error_vel_yaw: 0.7735
      Episode_Termination/time_out: 2.9583
  Episode_Termination/base_contact: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 1.12s
                        Total time: 1143.34s
                               ETA: 2115.1s

################################################################################
                     [1m Learning iteration 1053/3000 [0m                     

                       Computation: 89657 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 1.1057
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5859
                     Learning rate: 0.0006
                       Mean reward: 73.90
               Mean episode length: 880.67
       Episode_Reward/keep_balance: 0.9005
     Episode_Reward/rew_lin_vel_xy: 3.2938
      Episode_Reward/rew_ang_vel_z: 2.6393
    Episode_Reward/pen_base_height: -0.4076
      Episode_Reward/pen_lin_vel_z: -0.0746
     Episode_Reward/pen_ang_vel_xy: -0.1359
   Episode_Reward/pen_joint_torque: -0.1829
    Episode_Reward/pen_joint_accel: -0.0791
    Episode_Reward/pen_action_rate: -0.2412
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0352
   Episode_Reward/pen_joint_powers: -0.0623
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5398
Episode_Reward/pen_flat_orientation: -0.1354
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2624
   Episode_Reward/foot_landing_vel: -0.1158
   Episode_Reward/test_gait_reward: -0.8547
Metrics/base_velocity/error_vel_xy: 2.2606
Metrics/base_velocity/error_vel_yaw: 0.8775
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 1.10s
                        Total time: 1144.44s
                               ETA: 2114.1s

################################################################################
                     [1m Learning iteration 1054/3000 [0m                     

                       Computation: 90525 steps/s (collection: 0.959s, learning 0.127s)
               Value function loss: 1.0493
                    Surrogate loss: 0.0016
             Mean action noise std: 0.5863
                     Learning rate: 0.0001
                       Mean reward: 66.85
               Mean episode length: 846.75
       Episode_Reward/keep_balance: 0.8683
     Episode_Reward/rew_lin_vel_xy: 3.0988
      Episode_Reward/rew_ang_vel_z: 2.5282
    Episode_Reward/pen_base_height: -0.3748
      Episode_Reward/pen_lin_vel_z: -0.0720
     Episode_Reward/pen_ang_vel_xy: -0.1352
   Episode_Reward/pen_joint_torque: -0.1743
    Episode_Reward/pen_joint_accel: -0.0809
    Episode_Reward/pen_action_rate: -0.2337
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0342
   Episode_Reward/pen_joint_powers: -0.0598
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5249
Episode_Reward/pen_flat_orientation: -0.1351
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2512
   Episode_Reward/foot_landing_vel: -0.1123
   Episode_Reward/test_gait_reward: -0.8211
Metrics/base_velocity/error_vel_xy: 2.2278
Metrics/base_velocity/error_vel_yaw: 0.8568
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 1.09s
                        Total time: 1145.53s
                               ETA: 2113.0s

################################################################################
                     [1m Learning iteration 1055/3000 [0m                     

                       Computation: 90643 steps/s (collection: 0.957s, learning 0.127s)
               Value function loss: 1.1023
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5867
                     Learning rate: 0.0003
                       Mean reward: 77.28
               Mean episode length: 932.08
       Episode_Reward/keep_balance: 0.9150
     Episode_Reward/rew_lin_vel_xy: 3.2435
      Episode_Reward/rew_ang_vel_z: 2.6693
    Episode_Reward/pen_base_height: -0.3782
      Episode_Reward/pen_lin_vel_z: -0.0694
     Episode_Reward/pen_ang_vel_xy: -0.1349
   Episode_Reward/pen_joint_torque: -0.1731
    Episode_Reward/pen_joint_accel: -0.0835
    Episode_Reward/pen_action_rate: -0.2410
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0346
   Episode_Reward/pen_joint_powers: -0.0597
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5507
Episode_Reward/pen_flat_orientation: -0.1321
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.2442
   Episode_Reward/foot_landing_vel: -0.1092
   Episode_Reward/test_gait_reward: -0.8502
Metrics/base_velocity/error_vel_xy: 2.4359
Metrics/base_velocity/error_vel_yaw: 0.9025
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 1.08s
                        Total time: 1146.61s
                               ETA: 2111.9s

################################################################################
                     [1m Learning iteration 1056/3000 [0m                     

                       Computation: 89147 steps/s (collection: 0.976s, learning 0.127s)
               Value function loss: 0.9905
                    Surrogate loss: -0.0044
             Mean action noise std: 0.5870
                     Learning rate: 0.0004
                       Mean reward: 68.60
               Mean episode length: 849.84
       Episode_Reward/keep_balance: 0.8545
     Episode_Reward/rew_lin_vel_xy: 3.1480
      Episode_Reward/rew_ang_vel_z: 2.4987
    Episode_Reward/pen_base_height: -0.3665
      Episode_Reward/pen_lin_vel_z: -0.0679
     Episode_Reward/pen_ang_vel_xy: -0.1258
   Episode_Reward/pen_joint_torque: -0.1661
    Episode_Reward/pen_joint_accel: -0.0799
    Episode_Reward/pen_action_rate: -0.2264
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0324
   Episode_Reward/pen_joint_powers: -0.0568
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5191
Episode_Reward/pen_flat_orientation: -0.1381
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2332
   Episode_Reward/foot_landing_vel: -0.1034
   Episode_Reward/test_gait_reward: -0.8065
Metrics/base_velocity/error_vel_xy: 2.1776
Metrics/base_velocity/error_vel_yaw: 0.8355
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 1.10s
                        Total time: 1147.71s
                               ETA: 2110.8s

################################################################################
                     [1m Learning iteration 1057/3000 [0m                     

                       Computation: 88260 steps/s (collection: 0.989s, learning 0.125s)
               Value function loss: 1.0511
                    Surrogate loss: -0.0032
             Mean action noise std: 0.5873
                     Learning rate: 0.0006
                       Mean reward: 72.93
               Mean episode length: 867.43
       Episode_Reward/keep_balance: 0.8815
     Episode_Reward/rew_lin_vel_xy: 3.2608
      Episode_Reward/rew_ang_vel_z: 2.5888
    Episode_Reward/pen_base_height: -0.3774
      Episode_Reward/pen_lin_vel_z: -0.0670
     Episode_Reward/pen_ang_vel_xy: -0.1275
   Episode_Reward/pen_joint_torque: -0.1658
    Episode_Reward/pen_joint_accel: -0.0774
    Episode_Reward/pen_action_rate: -0.2307
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0318
   Episode_Reward/pen_joint_powers: -0.0564
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5276
Episode_Reward/pen_flat_orientation: -0.1349
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2271
   Episode_Reward/foot_landing_vel: -0.0992
   Episode_Reward/test_gait_reward: -0.8251
Metrics/base_velocity/error_vel_xy: 2.1554
Metrics/base_velocity/error_vel_yaw: 0.8526
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 1.11s
                        Total time: 1148.83s
                               ETA: 2109.8s

################################################################################
                     [1m Learning iteration 1058/3000 [0m                     

                       Computation: 83603 steps/s (collection: 1.050s, learning 0.126s)
               Value function loss: 1.0749
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5881
                     Learning rate: 0.0002
                       Mean reward: 74.97
               Mean episode length: 915.03
       Episode_Reward/keep_balance: 0.9116
     Episode_Reward/rew_lin_vel_xy: 3.3402
      Episode_Reward/rew_ang_vel_z: 2.6641
    Episode_Reward/pen_base_height: -0.3828
      Episode_Reward/pen_lin_vel_z: -0.0685
     Episode_Reward/pen_ang_vel_xy: -0.1344
   Episode_Reward/pen_joint_torque: -0.1725
    Episode_Reward/pen_joint_accel: -0.0779
    Episode_Reward/pen_action_rate: -0.2392
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0335
   Episode_Reward/pen_joint_powers: -0.0589
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5461
Episode_Reward/pen_flat_orientation: -0.1330
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.2340
   Episode_Reward/foot_landing_vel: -0.1026
   Episode_Reward/test_gait_reward: -0.8527
Metrics/base_velocity/error_vel_xy: 2.3255
Metrics/base_velocity/error_vel_yaw: 0.9016
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 1.18s
                        Total time: 1150.00s
                               ETA: 2108.9s

################################################################################
                     [1m Learning iteration 1059/3000 [0m                     

                       Computation: 91778 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 1.0275
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5879
                     Learning rate: 0.0003
                       Mean reward: 74.14
               Mean episode length: 868.60
       Episode_Reward/keep_balance: 0.8586
     Episode_Reward/rew_lin_vel_xy: 3.2428
      Episode_Reward/rew_ang_vel_z: 2.5130
    Episode_Reward/pen_base_height: -0.3670
      Episode_Reward/pen_lin_vel_z: -0.0665
     Episode_Reward/pen_ang_vel_xy: -0.1264
   Episode_Reward/pen_joint_torque: -0.1647
    Episode_Reward/pen_joint_accel: -0.0778
    Episode_Reward/pen_action_rate: -0.2261
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0323
   Episode_Reward/pen_joint_powers: -0.0565
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5202
Episode_Reward/pen_flat_orientation: -0.1294
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2323
   Episode_Reward/foot_landing_vel: -0.1018
   Episode_Reward/test_gait_reward: -0.8074
Metrics/base_velocity/error_vel_xy: 2.1412
Metrics/base_velocity/error_vel_yaw: 0.8373
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 1.07s
                        Total time: 1151.07s
                               ETA: 2107.8s

################################################################################
                     [1m Learning iteration 1060/3000 [0m                     

                       Computation: 92476 steps/s (collection: 0.939s, learning 0.124s)
               Value function loss: 1.1475
                    Surrogate loss: -0.0036
             Mean action noise std: 0.5897
                     Learning rate: 0.0006
                       Mean reward: 73.99
               Mean episode length: 848.81
       Episode_Reward/keep_balance: 0.8538
     Episode_Reward/rew_lin_vel_xy: 3.3088
      Episode_Reward/rew_ang_vel_z: 2.4968
    Episode_Reward/pen_base_height: -0.3751
      Episode_Reward/pen_lin_vel_z: -0.0701
     Episode_Reward/pen_ang_vel_xy: -0.1326
   Episode_Reward/pen_joint_torque: -0.1682
    Episode_Reward/pen_joint_accel: -0.0746
    Episode_Reward/pen_action_rate: -0.2291
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0334
   Episode_Reward/pen_joint_powers: -0.0584
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5173
Episode_Reward/pen_flat_orientation: -0.1373
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2430
   Episode_Reward/foot_landing_vel: -0.1087
   Episode_Reward/test_gait_reward: -0.8058
Metrics/base_velocity/error_vel_xy: 1.9956
Metrics/base_velocity/error_vel_yaw: 0.8408
      Episode_Termination/time_out: 2.9583
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 1.06s
                        Total time: 1152.14s
                               ETA: 2106.6s

################################################################################
                     [1m Learning iteration 1061/3000 [0m                     

                       Computation: 91960 steps/s (collection: 0.945s, learning 0.124s)
               Value function loss: 1.1495
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5918
                     Learning rate: 0.0013
                       Mean reward: 74.04
               Mean episode length: 872.17
       Episode_Reward/keep_balance: 0.8381
     Episode_Reward/rew_lin_vel_xy: 3.0774
      Episode_Reward/rew_ang_vel_z: 2.4668
    Episode_Reward/pen_base_height: -0.3664
      Episode_Reward/pen_lin_vel_z: -0.0641
     Episode_Reward/pen_ang_vel_xy: -0.1209
   Episode_Reward/pen_joint_torque: -0.1645
    Episode_Reward/pen_joint_accel: -0.0752
    Episode_Reward/pen_action_rate: -0.2196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0311
   Episode_Reward/pen_joint_powers: -0.0551
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.4996
Episode_Reward/pen_flat_orientation: -0.1268
  Episode_Reward/pen_feet_distance: -0.0025
Episode_Reward/pen_feet_regulation: -0.2254
   Episode_Reward/foot_landing_vel: -0.0987
   Episode_Reward/test_gait_reward: -0.7805
Metrics/base_velocity/error_vel_xy: 2.1012
Metrics/base_velocity/error_vel_yaw: 0.8102
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 1.07s
                        Total time: 1153.20s
                               ETA: 2105.5s

################################################################################
                     [1m Learning iteration 1062/3000 [0m                     

                       Computation: 92520 steps/s (collection: 0.937s, learning 0.125s)
               Value function loss: 1.1845
                    Surrogate loss: 0.0003
             Mean action noise std: 0.5925
                     Learning rate: 0.0004
                       Mean reward: 76.04
               Mean episode length: 910.25
       Episode_Reward/keep_balance: 0.9175
     Episode_Reward/rew_lin_vel_xy: 3.2324
      Episode_Reward/rew_ang_vel_z: 2.6936
    Episode_Reward/pen_base_height: -0.3768
      Episode_Reward/pen_lin_vel_z: -0.0710
     Episode_Reward/pen_ang_vel_xy: -0.1343
   Episode_Reward/pen_joint_torque: -0.1801
    Episode_Reward/pen_joint_accel: -0.0850
    Episode_Reward/pen_action_rate: -0.2446
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0336
   Episode_Reward/pen_joint_powers: -0.0599
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5533
Episode_Reward/pen_flat_orientation: -0.1230
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.2383
   Episode_Reward/foot_landing_vel: -0.1075
   Episode_Reward/test_gait_reward: -0.8496
Metrics/base_velocity/error_vel_xy: 2.4064
Metrics/base_velocity/error_vel_yaw: 0.8887
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 1.06s
                        Total time: 1154.27s
                               ETA: 2104.4s

################################################################################
                     [1m Learning iteration 1063/3000 [0m                     

                       Computation: 94485 steps/s (collection: 0.916s, learning 0.125s)
               Value function loss: 1.1185
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5928
                     Learning rate: 0.0002
                       Mean reward: 83.46
               Mean episode length: 918.02
       Episode_Reward/keep_balance: 0.8991
     Episode_Reward/rew_lin_vel_xy: 3.5394
      Episode_Reward/rew_ang_vel_z: 2.6586
    Episode_Reward/pen_base_height: -0.3765
      Episode_Reward/pen_lin_vel_z: -0.0702
     Episode_Reward/pen_ang_vel_xy: -0.1339
   Episode_Reward/pen_joint_torque: -0.1763
    Episode_Reward/pen_joint_accel: -0.0854
    Episode_Reward/pen_action_rate: -0.2399
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0340
   Episode_Reward/pen_joint_powers: -0.0596
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5432
Episode_Reward/pen_flat_orientation: -0.1236
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2487
   Episode_Reward/foot_landing_vel: -0.1092
   Episode_Reward/test_gait_reward: -0.8425
Metrics/base_velocity/error_vel_xy: 2.0625
Metrics/base_velocity/error_vel_yaw: 0.8544
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 1.04s
                        Total time: 1155.31s
                               ETA: 2103.2s

################################################################################
                     [1m Learning iteration 1064/3000 [0m                     

                       Computation: 92457 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 1.0784
                    Surrogate loss: -0.0032
             Mean action noise std: 0.5931
                     Learning rate: 0.0003
                       Mean reward: 77.66
               Mean episode length: 857.86
       Episode_Reward/keep_balance: 0.8657
     Episode_Reward/rew_lin_vel_xy: 3.3460
      Episode_Reward/rew_ang_vel_z: 2.5678
    Episode_Reward/pen_base_height: -0.3658
      Episode_Reward/pen_lin_vel_z: -0.0682
     Episode_Reward/pen_ang_vel_xy: -0.1272
   Episode_Reward/pen_joint_torque: -0.1691
    Episode_Reward/pen_joint_accel: -0.0837
    Episode_Reward/pen_action_rate: -0.2285
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0317
   Episode_Reward/pen_joint_powers: -0.0571
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5195
Episode_Reward/pen_flat_orientation: -0.1267
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.2238
   Episode_Reward/foot_landing_vel: -0.0975
   Episode_Reward/test_gait_reward: -0.8127
Metrics/base_velocity/error_vel_xy: 2.0260
Metrics/base_velocity/error_vel_yaw: 0.8230
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 1.06s
                        Total time: 1156.37s
                               ETA: 2102.1s

################################################################################
                     [1m Learning iteration 1065/3000 [0m                     

                       Computation: 93245 steps/s (collection: 0.931s, learning 0.124s)
               Value function loss: 1.1615
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5935
                     Learning rate: 0.0003
                       Mean reward: 81.52
               Mean episode length: 918.53
       Episode_Reward/keep_balance: 0.9127
     Episode_Reward/rew_lin_vel_xy: 3.5420
      Episode_Reward/rew_ang_vel_z: 2.6819
    Episode_Reward/pen_base_height: -0.3899
      Episode_Reward/pen_lin_vel_z: -0.0669
     Episode_Reward/pen_ang_vel_xy: -0.1319
   Episode_Reward/pen_joint_torque: -0.1742
    Episode_Reward/pen_joint_accel: -0.0801
    Episode_Reward/pen_action_rate: -0.2397
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0333
   Episode_Reward/pen_joint_powers: -0.0587
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.5514
Episode_Reward/pen_flat_orientation: -0.1225
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2347
   Episode_Reward/foot_landing_vel: -0.1033
   Episode_Reward/test_gait_reward: -0.8505
Metrics/base_velocity/error_vel_xy: 2.1280
Metrics/base_velocity/error_vel_yaw: 0.8790
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 1.05s
                        Total time: 1157.43s
                               ETA: 2101.0s

################################################################################
                     [1m Learning iteration 1066/3000 [0m                     

                       Computation: 92104 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 1.0941
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5947
                     Learning rate: 0.0002
                       Mean reward: 69.75
               Mean episode length: 853.51
       Episode_Reward/keep_balance: 0.8488
     Episode_Reward/rew_lin_vel_xy: 3.0554
      Episode_Reward/rew_ang_vel_z: 2.4964
    Episode_Reward/pen_base_height: -0.3596
      Episode_Reward/pen_lin_vel_z: -0.0656
     Episode_Reward/pen_ang_vel_xy: -0.1292
   Episode_Reward/pen_joint_torque: -0.1667
    Episode_Reward/pen_joint_accel: -0.0757
    Episode_Reward/pen_action_rate: -0.2269
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0315
   Episode_Reward/pen_joint_powers: -0.0557
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5188
Episode_Reward/pen_flat_orientation: -0.1256
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2184
   Episode_Reward/foot_landing_vel: -0.1011
   Episode_Reward/test_gait_reward: -0.7915
Metrics/base_velocity/error_vel_xy: 2.2172
Metrics/base_velocity/error_vel_yaw: 0.8254
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 1.07s
                        Total time: 1158.49s
                               ETA: 2099.8s

################################################################################
                     [1m Learning iteration 1067/3000 [0m                     

                       Computation: 91444 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 1.1406
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5951
                     Learning rate: 0.0002
                       Mean reward: 71.34
               Mean episode length: 861.32
       Episode_Reward/keep_balance: 0.8516
     Episode_Reward/rew_lin_vel_xy: 3.0492
      Episode_Reward/rew_ang_vel_z: 2.4922
    Episode_Reward/pen_base_height: -0.3630
      Episode_Reward/pen_lin_vel_z: -0.0648
     Episode_Reward/pen_ang_vel_xy: -0.1259
   Episode_Reward/pen_joint_torque: -0.1637
    Episode_Reward/pen_joint_accel: -0.0748
    Episode_Reward/pen_action_rate: -0.2263
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0318
   Episode_Reward/pen_joint_powers: -0.0557
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5156
Episode_Reward/pen_flat_orientation: -0.1278
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2290
   Episode_Reward/foot_landing_vel: -0.1024
   Episode_Reward/test_gait_reward: -0.8012
Metrics/base_velocity/error_vel_xy: 2.1953
Metrics/base_velocity/error_vel_yaw: 0.8379
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 1.08s
                        Total time: 1159.57s
                               ETA: 2098.7s

################################################################################
                     [1m Learning iteration 1068/3000 [0m                     

                       Computation: 92698 steps/s (collection: 0.937s, learning 0.124s)
               Value function loss: 1.0245
                    Surrogate loss: -0.0021
             Mean action noise std: 0.5951
                     Learning rate: 0.0003
                       Mean reward: 81.80
               Mean episode length: 946.35
       Episode_Reward/keep_balance: 0.9423
     Episode_Reward/rew_lin_vel_xy: 3.6072
      Episode_Reward/rew_ang_vel_z: 2.7495
    Episode_Reward/pen_base_height: -0.3738
      Episode_Reward/pen_lin_vel_z: -0.0690
     Episode_Reward/pen_ang_vel_xy: -0.1420
   Episode_Reward/pen_joint_torque: -0.1720
    Episode_Reward/pen_joint_accel: -0.0859
    Episode_Reward/pen_action_rate: -0.2500
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0351
   Episode_Reward/pen_joint_powers: -0.0603
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.5760
Episode_Reward/pen_flat_orientation: -0.1258
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.2446
   Episode_Reward/foot_landing_vel: -0.1124
   Episode_Reward/test_gait_reward: -0.8835
Metrics/base_velocity/error_vel_xy: 2.1673
Metrics/base_velocity/error_vel_yaw: 0.9208
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 1.06s
                        Total time: 1160.63s
                               ETA: 2097.6s

################################################################################
                     [1m Learning iteration 1069/3000 [0m                     

                       Computation: 92919 steps/s (collection: 0.933s, learning 0.125s)
               Value function loss: 1.1187
                    Surrogate loss: -0.0032
             Mean action noise std: 0.5947
                     Learning rate: 0.0004
                       Mean reward: 76.14
               Mean episode length: 911.85
       Episode_Reward/keep_balance: 0.9265
     Episode_Reward/rew_lin_vel_xy: 3.3668
      Episode_Reward/rew_ang_vel_z: 2.7169
    Episode_Reward/pen_base_height: -0.3845
      Episode_Reward/pen_lin_vel_z: -0.0693
     Episode_Reward/pen_ang_vel_xy: -0.1362
   Episode_Reward/pen_joint_torque: -0.1799
    Episode_Reward/pen_joint_accel: -0.0797
    Episode_Reward/pen_action_rate: -0.2455
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0344
   Episode_Reward/pen_joint_powers: -0.0605
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5634
Episode_Reward/pen_flat_orientation: -0.1244
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.2484
   Episode_Reward/foot_landing_vel: -0.1072
   Episode_Reward/test_gait_reward: -0.8647
Metrics/base_velocity/error_vel_xy: 2.4064
Metrics/base_velocity/error_vel_yaw: 0.8939
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 1.06s
                        Total time: 1161.69s
                               ETA: 2096.5s

################################################################################
                     [1m Learning iteration 1070/3000 [0m                     

                       Computation: 93329 steps/s (collection: 0.932s, learning 0.122s)
               Value function loss: 1.1334
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5950
                     Learning rate: 0.0003
                       Mean reward: 82.79
               Mean episode length: 921.60
       Episode_Reward/keep_balance: 0.9171
     Episode_Reward/rew_lin_vel_xy: 3.5626
      Episode_Reward/rew_ang_vel_z: 2.6714
    Episode_Reward/pen_base_height: -0.3931
      Episode_Reward/pen_lin_vel_z: -0.0661
     Episode_Reward/pen_ang_vel_xy: -0.1383
   Episode_Reward/pen_joint_torque: -0.1705
    Episode_Reward/pen_joint_accel: -0.0814
    Episode_Reward/pen_action_rate: -0.2440
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0340
   Episode_Reward/pen_joint_powers: -0.0587
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5571
Episode_Reward/pen_flat_orientation: -0.1306
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2410
   Episode_Reward/foot_landing_vel: -0.0987
   Episode_Reward/test_gait_reward: -0.8579
Metrics/base_velocity/error_vel_xy: 2.1219
Metrics/base_velocity/error_vel_yaw: 0.9020
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 1.05s
                        Total time: 1162.74s
                               ETA: 2095.3s

################################################################################
                     [1m Learning iteration 1071/3000 [0m                     

                       Computation: 91368 steps/s (collection: 0.951s, learning 0.125s)
               Value function loss: 1.0983
                    Surrogate loss: -0.0033
             Mean action noise std: 0.5965
                     Learning rate: 0.0006
                       Mean reward: 77.46
               Mean episode length: 886.64
       Episode_Reward/keep_balance: 0.8912
     Episode_Reward/rew_lin_vel_xy: 3.4453
      Episode_Reward/rew_ang_vel_z: 2.6029
    Episode_Reward/pen_base_height: -0.3667
      Episode_Reward/pen_lin_vel_z: -0.0663
     Episode_Reward/pen_ang_vel_xy: -0.1331
   Episode_Reward/pen_joint_torque: -0.1679
    Episode_Reward/pen_joint_accel: -0.0806
    Episode_Reward/pen_action_rate: -0.2391
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0335
   Episode_Reward/pen_joint_powers: -0.0579
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5475
Episode_Reward/pen_flat_orientation: -0.1258
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.2342
   Episode_Reward/foot_landing_vel: -0.1049
   Episode_Reward/test_gait_reward: -0.8394
Metrics/base_velocity/error_vel_xy: 2.0453
Metrics/base_velocity/error_vel_yaw: 0.8715
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 1.08s
                        Total time: 1163.82s
                               ETA: 2094.2s

################################################################################
                     [1m Learning iteration 1072/3000 [0m                     

                       Computation: 92490 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 1.1809
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5971
                     Learning rate: 0.0004
                       Mean reward: 73.37
               Mean episode length: 844.78
       Episode_Reward/keep_balance: 0.8722
     Episode_Reward/rew_lin_vel_xy: 3.3165
      Episode_Reward/rew_ang_vel_z: 2.5475
    Episode_Reward/pen_base_height: -0.3622
      Episode_Reward/pen_lin_vel_z: -0.0653
     Episode_Reward/pen_ang_vel_xy: -0.1243
   Episode_Reward/pen_joint_torque: -0.1639
    Episode_Reward/pen_joint_accel: -0.0891
    Episode_Reward/pen_action_rate: -0.2328
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0325
   Episode_Reward/pen_joint_powers: -0.0556
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5340
Episode_Reward/pen_flat_orientation: -0.1268
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.2343
   Episode_Reward/foot_landing_vel: -0.1040
   Episode_Reward/test_gait_reward: -0.8159
Metrics/base_velocity/error_vel_xy: 2.1828
Metrics/base_velocity/error_vel_yaw: 0.8551
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 1.06s
                        Total time: 1164.88s
                               ETA: 2093.1s

################################################################################
                     [1m Learning iteration 1073/3000 [0m                     

                       Computation: 92733 steps/s (collection: 0.935s, learning 0.125s)
               Value function loss: 1.1191
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5972
                     Learning rate: 0.0003
                       Mean reward: 81.10
               Mean episode length: 905.60
       Episode_Reward/keep_balance: 0.9264
     Episode_Reward/rew_lin_vel_xy: 3.5465
      Episode_Reward/rew_ang_vel_z: 2.6760
    Episode_Reward/pen_base_height: -0.3853
      Episode_Reward/pen_lin_vel_z: -0.0661
     Episode_Reward/pen_ang_vel_xy: -0.1317
   Episode_Reward/pen_joint_torque: -0.1730
    Episode_Reward/pen_joint_accel: -0.0842
    Episode_Reward/pen_action_rate: -0.2459
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0342
   Episode_Reward/pen_joint_powers: -0.0592
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.5673
Episode_Reward/pen_flat_orientation: -0.1263
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.2454
   Episode_Reward/foot_landing_vel: -0.1050
   Episode_Reward/test_gait_reward: -0.8644
Metrics/base_velocity/error_vel_xy: 2.1846
Metrics/base_velocity/error_vel_yaw: 0.9265
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 1.06s
                        Total time: 1165.94s
                               ETA: 2092.0s

################################################################################
                     [1m Learning iteration 1074/3000 [0m                     

                       Computation: 93437 steps/s (collection: 0.930s, learning 0.122s)
               Value function loss: 1.0022
                    Surrogate loss: -0.0021
             Mean action noise std: 0.5976
                     Learning rate: 0.0004
                       Mean reward: 80.19
               Mean episode length: 919.38
       Episode_Reward/keep_balance: 0.8919
     Episode_Reward/rew_lin_vel_xy: 3.3525
      Episode_Reward/rew_ang_vel_z: 2.6049
    Episode_Reward/pen_base_height: -0.3534
      Episode_Reward/pen_lin_vel_z: -0.0651
     Episode_Reward/pen_ang_vel_xy: -0.1315
   Episode_Reward/pen_joint_torque: -0.1656
    Episode_Reward/pen_joint_accel: -0.0817
    Episode_Reward/pen_action_rate: -0.2381
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0324
   Episode_Reward/pen_joint_powers: -0.0565
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5491
Episode_Reward/pen_flat_orientation: -0.1219
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2249
   Episode_Reward/foot_landing_vel: -0.1060
   Episode_Reward/test_gait_reward: -0.8313
Metrics/base_velocity/error_vel_xy: 2.1916
Metrics/base_velocity/error_vel_yaw: 0.8758
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 1.05s
                        Total time: 1166.99s
                               ETA: 2090.8s

################################################################################
                     [1m Learning iteration 1075/3000 [0m                     

                       Computation: 93568 steps/s (collection: 0.929s, learning 0.122s)
               Value function loss: 1.1627
                    Surrogate loss: 0.0014
             Mean action noise std: 0.5977
                     Learning rate: 0.0001
                       Mean reward: 79.14
               Mean episode length: 894.31
       Episode_Reward/keep_balance: 0.8750
     Episode_Reward/rew_lin_vel_xy: 3.3258
      Episode_Reward/rew_ang_vel_z: 2.5551
    Episode_Reward/pen_base_height: -0.3572
      Episode_Reward/pen_lin_vel_z: -0.0656
     Episode_Reward/pen_ang_vel_xy: -0.1305
   Episode_Reward/pen_joint_torque: -0.1678
    Episode_Reward/pen_joint_accel: -0.0746
    Episode_Reward/pen_action_rate: -0.2361
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0327
   Episode_Reward/pen_joint_powers: -0.0572
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5424
Episode_Reward/pen_flat_orientation: -0.1245
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.2345
   Episode_Reward/foot_landing_vel: -0.1035
   Episode_Reward/test_gait_reward: -0.8169
Metrics/base_velocity/error_vel_xy: 2.1308
Metrics/base_velocity/error_vel_yaw: 0.8564
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 1.05s
                        Total time: 1168.04s
                               ETA: 2089.7s

################################################################################
                     [1m Learning iteration 1076/3000 [0m                     

                       Computation: 92469 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 1.0965
                    Surrogate loss: -0.0030
             Mean action noise std: 0.5977
                     Learning rate: 0.0002
                       Mean reward: 80.75
               Mean episode length: 910.93
       Episode_Reward/keep_balance: 0.9291
     Episode_Reward/rew_lin_vel_xy: 3.5230
      Episode_Reward/rew_ang_vel_z: 2.7000
    Episode_Reward/pen_base_height: -0.3838
      Episode_Reward/pen_lin_vel_z: -0.0705
     Episode_Reward/pen_ang_vel_xy: -0.1336
   Episode_Reward/pen_joint_torque: -0.1819
    Episode_Reward/pen_joint_accel: -0.0797
    Episode_Reward/pen_action_rate: -0.2504
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0346
   Episode_Reward/pen_joint_powers: -0.0611
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.5688
Episode_Reward/pen_flat_orientation: -0.1305
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.2580
   Episode_Reward/foot_landing_vel: -0.1043
   Episode_Reward/test_gait_reward: -0.8666
Metrics/base_velocity/error_vel_xy: 2.3292
Metrics/base_velocity/error_vel_yaw: 0.9185
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 1.06s
                        Total time: 1169.10s
                               ETA: 2088.5s

################################################################################
                     [1m Learning iteration 1077/3000 [0m                     

                       Computation: 91919 steps/s (collection: 0.945s, learning 0.124s)
               Value function loss: 1.0570
                    Surrogate loss: -0.0035
             Mean action noise std: 0.5977
                     Learning rate: 0.0004
                       Mean reward: 73.85
               Mean episode length: 860.12
       Episode_Reward/keep_balance: 0.8528
     Episode_Reward/rew_lin_vel_xy: 3.2746
      Episode_Reward/rew_ang_vel_z: 2.4860
    Episode_Reward/pen_base_height: -0.3659
      Episode_Reward/pen_lin_vel_z: -0.0664
     Episode_Reward/pen_ang_vel_xy: -0.1303
   Episode_Reward/pen_joint_torque: -0.1671
    Episode_Reward/pen_joint_accel: -0.0884
    Episode_Reward/pen_action_rate: -0.2340
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0337
   Episode_Reward/pen_joint_powers: -0.0576
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5333
Episode_Reward/pen_flat_orientation: -0.1337
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.2486
   Episode_Reward/foot_landing_vel: -0.1067
   Episode_Reward/test_gait_reward: -0.8059
Metrics/base_velocity/error_vel_xy: 2.0191
Metrics/base_velocity/error_vel_yaw: 0.8436
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 1.07s
                        Total time: 1170.17s
                               ETA: 2087.4s

################################################################################
                     [1m Learning iteration 1078/3000 [0m                     

                       Computation: 92041 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 1.2155
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5984
                     Learning rate: 0.0002
                       Mean reward: 74.91
               Mean episode length: 905.99
       Episode_Reward/keep_balance: 0.8821
     Episode_Reward/rew_lin_vel_xy: 3.1351
      Episode_Reward/rew_ang_vel_z: 2.5265
    Episode_Reward/pen_base_height: -0.3829
      Episode_Reward/pen_lin_vel_z: -0.0673
     Episode_Reward/pen_ang_vel_xy: -0.1342
   Episode_Reward/pen_joint_torque: -0.1741
    Episode_Reward/pen_joint_accel: -0.0825
    Episode_Reward/pen_action_rate: -0.2432
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0342
   Episode_Reward/pen_joint_powers: -0.0589
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5519
Episode_Reward/pen_flat_orientation: -0.1241
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.2572
   Episode_Reward/foot_landing_vel: -0.1010
   Episode_Reward/test_gait_reward: -0.8257
Metrics/base_velocity/error_vel_xy: 2.2493
Metrics/base_velocity/error_vel_yaw: 0.9057
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 1.07s
                        Total time: 1171.24s
                               ETA: 2086.3s

################################################################################
                     [1m Learning iteration 1079/3000 [0m                     

                       Computation: 92310 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 1.0222
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5988
                     Learning rate: 0.0001
                       Mean reward: 70.07
               Mean episode length: 841.97
       Episode_Reward/keep_balance: 0.8303
     Episode_Reward/rew_lin_vel_xy: 3.0034
      Episode_Reward/rew_ang_vel_z: 2.4049
    Episode_Reward/pen_base_height: -0.3556
      Episode_Reward/pen_lin_vel_z: -0.0609
     Episode_Reward/pen_ang_vel_xy: -0.1261
   Episode_Reward/pen_joint_torque: -0.1559
    Episode_Reward/pen_joint_accel: -0.0735
    Episode_Reward/pen_action_rate: -0.2254
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0311
   Episode_Reward/pen_joint_powers: -0.0535
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5217
Episode_Reward/pen_flat_orientation: -0.1286
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.2189
   Episode_Reward/foot_landing_vel: -0.0952
   Episode_Reward/test_gait_reward: -0.7731
Metrics/base_velocity/error_vel_xy: 2.0250
Metrics/base_velocity/error_vel_yaw: 0.8336
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 1.06s
                        Total time: 1172.31s
                               ETA: 2085.2s

################################################################################
                     [1m Learning iteration 1080/3000 [0m                     

                       Computation: 93040 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 1.1519
                    Surrogate loss: -0.0019
             Mean action noise std: 0.5988
                     Learning rate: 0.0002
                       Mean reward: 75.72
               Mean episode length: 899.16
       Episode_Reward/keep_balance: 0.9002
     Episode_Reward/rew_lin_vel_xy: 3.3046
      Episode_Reward/rew_ang_vel_z: 2.6042
    Episode_Reward/pen_base_height: -0.3832
      Episode_Reward/pen_lin_vel_z: -0.0672
     Episode_Reward/pen_ang_vel_xy: -0.1375
   Episode_Reward/pen_joint_torque: -0.1720
    Episode_Reward/pen_joint_accel: -0.0836
    Episode_Reward/pen_action_rate: -0.2469
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0351
   Episode_Reward/pen_joint_powers: -0.0598
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5612
Episode_Reward/pen_flat_orientation: -0.1288
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2558
   Episode_Reward/foot_landing_vel: -0.1097
   Episode_Reward/test_gait_reward: -0.8414
Metrics/base_velocity/error_vel_xy: 2.2729
Metrics/base_velocity/error_vel_yaw: 0.9046
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 1.06s
                        Total time: 1173.36s
                               ETA: 2084.0s

################################################################################
                     [1m Learning iteration 1081/3000 [0m                     

                       Computation: 90885 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 1.1279
                    Surrogate loss: 0.0009
             Mean action noise std: 0.5991
                     Learning rate: 0.0001
                       Mean reward: 78.61
               Mean episode length: 888.05
       Episode_Reward/keep_balance: 0.8781
     Episode_Reward/rew_lin_vel_xy: 3.4029
      Episode_Reward/rew_ang_vel_z: 2.5240
    Episode_Reward/pen_base_height: -0.3588
      Episode_Reward/pen_lin_vel_z: -0.0615
     Episode_Reward/pen_ang_vel_xy: -0.1280
   Episode_Reward/pen_joint_torque: -0.1624
    Episode_Reward/pen_joint_accel: -0.0735
    Episode_Reward/pen_action_rate: -0.2358
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0321
   Episode_Reward/pen_joint_powers: -0.0552
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5456
Episode_Reward/pen_flat_orientation: -0.1229
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.2247
   Episode_Reward/foot_landing_vel: -0.0976
   Episode_Reward/test_gait_reward: -0.8120
Metrics/base_velocity/error_vel_xy: 2.1032
Metrics/base_velocity/error_vel_yaw: 0.8895
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 1.08s
                        Total time: 1174.44s
                               ETA: 2083.0s

################################################################################
                     [1m Learning iteration 1082/3000 [0m                     

                       Computation: 90638 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 1.1965
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5994
                     Learning rate: 0.0001
                       Mean reward: 75.88
               Mean episode length: 866.90
       Episode_Reward/keep_balance: 0.8703
     Episode_Reward/rew_lin_vel_xy: 3.3574
      Episode_Reward/rew_ang_vel_z: 2.5157
    Episode_Reward/pen_base_height: -0.3711
      Episode_Reward/pen_lin_vel_z: -0.0644
     Episode_Reward/pen_ang_vel_xy: -0.1300
   Episode_Reward/pen_joint_torque: -0.1679
    Episode_Reward/pen_joint_accel: -0.0712
    Episode_Reward/pen_action_rate: -0.2364
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0325
   Episode_Reward/pen_joint_powers: -0.0569
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5441
Episode_Reward/pen_flat_orientation: -0.1302
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.2317
   Episode_Reward/foot_landing_vel: -0.1017
   Episode_Reward/test_gait_reward: -0.8084
Metrics/base_velocity/error_vel_xy: 2.0801
Metrics/base_velocity/error_vel_yaw: 0.8738
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 1.08s
                        Total time: 1175.53s
                               ETA: 2081.9s

################################################################################
                     [1m Learning iteration 1083/3000 [0m                     

                       Computation: 91146 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 1.1646
                    Surrogate loss: -0.0039
             Mean action noise std: 0.5990
                     Learning rate: 0.0003
                       Mean reward: 73.55
               Mean episode length: 844.28
       Episode_Reward/keep_balance: 0.8408
     Episode_Reward/rew_lin_vel_xy: 3.1313
      Episode_Reward/rew_ang_vel_z: 2.4103
    Episode_Reward/pen_base_height: -0.3623
      Episode_Reward/pen_lin_vel_z: -0.0586
     Episode_Reward/pen_ang_vel_xy: -0.1292
   Episode_Reward/pen_joint_torque: -0.1524
    Episode_Reward/pen_joint_accel: -0.0723
    Episode_Reward/pen_action_rate: -0.2276
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0313
   Episode_Reward/pen_joint_powers: -0.0529
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.5247
Episode_Reward/pen_flat_orientation: -0.1251
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2155
   Episode_Reward/foot_landing_vel: -0.0945
   Episode_Reward/test_gait_reward: -0.7805
Metrics/base_velocity/error_vel_xy: 2.0381
Metrics/base_velocity/error_vel_yaw: 0.8637
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 1.08s
                        Total time: 1176.61s
                               ETA: 2080.8s

################################################################################
                     [1m Learning iteration 1084/3000 [0m                     

                       Computation: 89644 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 1.1744
                    Surrogate loss: -0.0024
             Mean action noise std: 0.5994
                     Learning rate: 0.0006
                       Mean reward: 67.74
               Mean episode length: 818.20
       Episode_Reward/keep_balance: 0.8060
     Episode_Reward/rew_lin_vel_xy: 3.0099
      Episode_Reward/rew_ang_vel_z: 2.3248
    Episode_Reward/pen_base_height: -0.3464
      Episode_Reward/pen_lin_vel_z: -0.0596
     Episode_Reward/pen_ang_vel_xy: -0.1243
   Episode_Reward/pen_joint_torque: -0.1577
    Episode_Reward/pen_joint_accel: -0.0796
    Episode_Reward/pen_action_rate: -0.2208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0308
   Episode_Reward/pen_joint_powers: -0.0534
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5035
Episode_Reward/pen_flat_orientation: -0.1279
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2241
   Episode_Reward/foot_landing_vel: -0.0944
   Episode_Reward/test_gait_reward: -0.7512
Metrics/base_velocity/error_vel_xy: 1.9605
Metrics/base_velocity/error_vel_yaw: 0.8143
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 1.10s
                        Total time: 1177.70s
                               ETA: 2079.7s

################################################################################
                     [1m Learning iteration 1085/3000 [0m                     

                       Computation: 88848 steps/s (collection: 0.982s, learning 0.124s)
               Value function loss: 1.1501
                    Surrogate loss: -0.0006
             Mean action noise std: 0.6001
                     Learning rate: 0.0004
                       Mean reward: 75.72
               Mean episode length: 885.73
       Episode_Reward/keep_balance: 0.8805
     Episode_Reward/rew_lin_vel_xy: 3.2307
      Episode_Reward/rew_ang_vel_z: 2.5449
    Episode_Reward/pen_base_height: -0.3792
      Episode_Reward/pen_lin_vel_z: -0.0693
     Episode_Reward/pen_ang_vel_xy: -0.1353
   Episode_Reward/pen_joint_torque: -0.1719
    Episode_Reward/pen_joint_accel: -0.0731
    Episode_Reward/pen_action_rate: -0.2430
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0337
   Episode_Reward/pen_joint_powers: -0.0592
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5540
Episode_Reward/pen_flat_orientation: -0.1275
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2527
   Episode_Reward/foot_landing_vel: -0.1017
   Episode_Reward/test_gait_reward: -0.8273
Metrics/base_velocity/error_vel_xy: 2.2225
Metrics/base_velocity/error_vel_yaw: 0.8814
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 1.11s
                        Total time: 1178.81s
                               ETA: 2078.7s

################################################################################
                     [1m Learning iteration 1086/3000 [0m                     

                       Computation: 90636 steps/s (collection: 0.960s, learning 0.125s)
               Value function loss: 1.0495
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6007
                     Learning rate: 0.0004
                       Mean reward: 73.99
               Mean episode length: 864.40
       Episode_Reward/keep_balance: 0.8839
     Episode_Reward/rew_lin_vel_xy: 3.3867
      Episode_Reward/rew_ang_vel_z: 2.5377
    Episode_Reward/pen_base_height: -0.3769
      Episode_Reward/pen_lin_vel_z: -0.0635
     Episode_Reward/pen_ang_vel_xy: -0.1321
   Episode_Reward/pen_joint_torque: -0.1672
    Episode_Reward/pen_joint_accel: -0.0747
    Episode_Reward/pen_action_rate: -0.2405
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0329
   Episode_Reward/pen_joint_powers: -0.0568
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5542
Episode_Reward/pen_flat_orientation: -0.1341
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2360
   Episode_Reward/foot_landing_vel: -0.0976
   Episode_Reward/test_gait_reward: -0.8254
Metrics/base_velocity/error_vel_xy: 2.0438
Metrics/base_velocity/error_vel_yaw: 0.9024
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 1.08s
                        Total time: 1179.90s
                               ETA: 2077.6s

################################################################################
                     [1m Learning iteration 1087/3000 [0m                     

                       Computation: 91503 steps/s (collection: 0.950s, learning 0.125s)
               Value function loss: 1.1161
                    Surrogate loss: -0.0036
             Mean action noise std: 0.6012
                     Learning rate: 0.0006
                       Mean reward: 71.36
               Mean episode length: 865.93
       Episode_Reward/keep_balance: 0.8434
     Episode_Reward/rew_lin_vel_xy: 3.0631
      Episode_Reward/rew_ang_vel_z: 2.4259
    Episode_Reward/pen_base_height: -0.3682
      Episode_Reward/pen_lin_vel_z: -0.0650
     Episode_Reward/pen_ang_vel_xy: -0.1345
   Episode_Reward/pen_joint_torque: -0.1682
    Episode_Reward/pen_joint_accel: -0.0712
    Episode_Reward/pen_action_rate: -0.2338
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0332
   Episode_Reward/pen_joint_powers: -0.0577
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5339
Episode_Reward/pen_flat_orientation: -0.1360
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2345
   Episode_Reward/foot_landing_vel: -0.1008
   Episode_Reward/test_gait_reward: -0.7917
Metrics/base_velocity/error_vel_xy: 2.0832
Metrics/base_velocity/error_vel_yaw: 0.8625
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 1.07s
                        Total time: 1180.97s
                               ETA: 2076.5s

################################################################################
                     [1m Learning iteration 1088/3000 [0m                     

                       Computation: 91748 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 1.1528
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6024
                     Learning rate: 0.0009
                       Mean reward: 79.06
               Mean episode length: 890.08
       Episode_Reward/keep_balance: 0.8987
     Episode_Reward/rew_lin_vel_xy: 3.6084
      Episode_Reward/rew_ang_vel_z: 2.5905
    Episode_Reward/pen_base_height: -0.3571
      Episode_Reward/pen_lin_vel_z: -0.0655
     Episode_Reward/pen_ang_vel_xy: -0.1340
   Episode_Reward/pen_joint_torque: -0.1685
    Episode_Reward/pen_joint_accel: -0.0778
    Episode_Reward/pen_action_rate: -0.2477
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0334
   Episode_Reward/pen_joint_powers: -0.0577
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5711
Episode_Reward/pen_flat_orientation: -0.1290
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2452
   Episode_Reward/foot_landing_vel: -0.1021
   Episode_Reward/test_gait_reward: -0.8358
Metrics/base_velocity/error_vel_xy: 1.9741
Metrics/base_velocity/error_vel_yaw: 0.9052
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 1.07s
                        Total time: 1182.04s
                               ETA: 2075.4s

################################################################################
                     [1m Learning iteration 1089/3000 [0m                     

                       Computation: 90141 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 1.1799
                    Surrogate loss: -0.0031
             Mean action noise std: 0.6025
                     Learning rate: 0.0009
                       Mean reward: 76.18
               Mean episode length: 902.80
       Episode_Reward/keep_balance: 0.8901
     Episode_Reward/rew_lin_vel_xy: 3.1755
      Episode_Reward/rew_ang_vel_z: 2.5584
    Episode_Reward/pen_base_height: -0.3704
      Episode_Reward/pen_lin_vel_z: -0.0638
     Episode_Reward/pen_ang_vel_xy: -0.1318
   Episode_Reward/pen_joint_torque: -0.1682
    Episode_Reward/pen_joint_accel: -0.0741
    Episode_Reward/pen_action_rate: -0.2446
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0333
   Episode_Reward/pen_joint_powers: -0.0575
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5662
Episode_Reward/pen_flat_orientation: -0.1265
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2414
   Episode_Reward/foot_landing_vel: -0.0985
   Episode_Reward/test_gait_reward: -0.8298
Metrics/base_velocity/error_vel_xy: 2.2929
Metrics/base_velocity/error_vel_yaw: 0.9048
      Episode_Termination/time_out: 3.1250
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 1.09s
                        Total time: 1183.13s
                               ETA: 2074.3s

################################################################################
                     [1m Learning iteration 1090/3000 [0m                     

                       Computation: 90306 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 1.1324
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6021
                     Learning rate: 0.0004
                       Mean reward: 75.98
               Mean episode length: 874.63
       Episode_Reward/keep_balance: 0.8888
     Episode_Reward/rew_lin_vel_xy: 3.6526
      Episode_Reward/rew_ang_vel_z: 2.5522
    Episode_Reward/pen_base_height: -0.3632
      Episode_Reward/pen_lin_vel_z: -0.0672
     Episode_Reward/pen_ang_vel_xy: -0.1356
   Episode_Reward/pen_joint_torque: -0.1735
    Episode_Reward/pen_joint_accel: -0.0837
    Episode_Reward/pen_action_rate: -0.2483
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0350
   Episode_Reward/pen_joint_powers: -0.0597
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5695
Episode_Reward/pen_flat_orientation: -0.1341
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2569
   Episode_Reward/foot_landing_vel: -0.1110
   Episode_Reward/test_gait_reward: -0.8297
Metrics/base_velocity/error_vel_xy: 1.9745
Metrics/base_velocity/error_vel_yaw: 0.9068
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 1.09s
                        Total time: 1184.22s
                               ETA: 2073.2s

################################################################################
                     [1m Learning iteration 1091/3000 [0m                     

                       Computation: 90997 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 1.0933
                    Surrogate loss: -0.0034
             Mean action noise std: 0.6023
                     Learning rate: 0.0006
                       Mean reward: 82.12
               Mean episode length: 912.81
       Episode_Reward/keep_balance: 0.9227
     Episode_Reward/rew_lin_vel_xy: 3.6290
      Episode_Reward/rew_ang_vel_z: 2.6834
    Episode_Reward/pen_base_height: -0.3711
      Episode_Reward/pen_lin_vel_z: -0.0661
     Episode_Reward/pen_ang_vel_xy: -0.1374
   Episode_Reward/pen_joint_torque: -0.1810
    Episode_Reward/pen_joint_accel: -0.0753
    Episode_Reward/pen_action_rate: -0.2534
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0336
   Episode_Reward/pen_joint_powers: -0.0601
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.5796
Episode_Reward/pen_flat_orientation: -0.1260
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.2420
   Episode_Reward/foot_landing_vel: -0.1000
   Episode_Reward/test_gait_reward: -0.8595
Metrics/base_velocity/error_vel_xy: 2.0953
Metrics/base_velocity/error_vel_yaw: 0.9105
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 1.08s
                        Total time: 1185.30s
                               ETA: 2072.1s

################################################################################
                     [1m Learning iteration 1092/3000 [0m                     

                       Computation: 91347 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 1.2637
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6037
                     Learning rate: 0.0009
                       Mean reward: 84.62
               Mean episode length: 932.25
       Episode_Reward/keep_balance: 0.9278
     Episode_Reward/rew_lin_vel_xy: 3.6999
      Episode_Reward/rew_ang_vel_z: 2.6626
    Episode_Reward/pen_base_height: -0.3707
      Episode_Reward/pen_lin_vel_z: -0.0699
     Episode_Reward/pen_ang_vel_xy: -0.1427
   Episode_Reward/pen_joint_torque: -0.1746
    Episode_Reward/pen_joint_accel: -0.0848
    Episode_Reward/pen_action_rate: -0.2605
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0365
   Episode_Reward/pen_joint_powers: -0.0614
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6007
Episode_Reward/pen_flat_orientation: -0.1336
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.2691
   Episode_Reward/foot_landing_vel: -0.1069
   Episode_Reward/test_gait_reward: -0.8692
Metrics/base_velocity/error_vel_xy: 2.1483
Metrics/base_velocity/error_vel_yaw: 0.9556
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 1.08s
                        Total time: 1186.38s
                               ETA: 2071.0s

################################################################################
                     [1m Learning iteration 1093/3000 [0m                     

                       Computation: 91167 steps/s (collection: 0.953s, learning 0.125s)
               Value function loss: 1.1137
                    Surrogate loss: -0.0029
             Mean action noise std: 0.6040
                     Learning rate: 0.0004
                       Mean reward: 83.74
               Mean episode length: 947.63
       Episode_Reward/keep_balance: 0.9339
     Episode_Reward/rew_lin_vel_xy: 3.6052
      Episode_Reward/rew_ang_vel_z: 2.6875
    Episode_Reward/pen_base_height: -0.3656
      Episode_Reward/pen_lin_vel_z: -0.0625
     Episode_Reward/pen_ang_vel_xy: -0.1351
   Episode_Reward/pen_joint_torque: -0.1729
    Episode_Reward/pen_joint_accel: -0.0755
    Episode_Reward/pen_action_rate: -0.2518
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0334
   Episode_Reward/pen_joint_powers: -0.0585
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.5895
Episode_Reward/pen_flat_orientation: -0.1225
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2322
   Episode_Reward/foot_landing_vel: -0.0952
   Episode_Reward/test_gait_reward: -0.8681
Metrics/base_velocity/error_vel_xy: 2.1867
Metrics/base_velocity/error_vel_yaw: 0.9404
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 1.08s
                        Total time: 1187.46s
                               ETA: 2069.9s

################################################################################
                     [1m Learning iteration 1094/3000 [0m                     

                       Computation: 91096 steps/s (collection: 0.953s, learning 0.126s)
               Value function loss: 1.1086
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6054
                     Learning rate: 0.0006
                       Mean reward: 77.54
               Mean episode length: 908.74
       Episode_Reward/keep_balance: 0.9087
     Episode_Reward/rew_lin_vel_xy: 3.4773
      Episode_Reward/rew_ang_vel_z: 2.6039
    Episode_Reward/pen_base_height: -0.3817
      Episode_Reward/pen_lin_vel_z: -0.0680
     Episode_Reward/pen_ang_vel_xy: -0.1387
   Episode_Reward/pen_joint_torque: -0.1800
    Episode_Reward/pen_joint_accel: -0.0734
    Episode_Reward/pen_action_rate: -0.2542
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0348
   Episode_Reward/pen_joint_powers: -0.0616
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5795
Episode_Reward/pen_flat_orientation: -0.1303
  Episode_Reward/pen_feet_distance: -0.0036
Episode_Reward/pen_feet_regulation: -0.2563
   Episode_Reward/foot_landing_vel: -0.1039
   Episode_Reward/test_gait_reward: -0.8556
Metrics/base_velocity/error_vel_xy: 2.0976
Metrics/base_velocity/error_vel_yaw: 0.9254
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 1.08s
                        Total time: 1188.53s
                               ETA: 2068.8s

################################################################################
                     [1m Learning iteration 1095/3000 [0m                     

                       Computation: 90588 steps/s (collection: 0.958s, learning 0.127s)
               Value function loss: 1.0946
                    Surrogate loss: -0.0035
             Mean action noise std: 0.6053
                     Learning rate: 0.0009
                       Mean reward: 79.60
               Mean episode length: 924.88
       Episode_Reward/keep_balance: 0.8991
     Episode_Reward/rew_lin_vel_xy: 3.3793
      Episode_Reward/rew_ang_vel_z: 2.6049
    Episode_Reward/pen_base_height: -0.3600
      Episode_Reward/pen_lin_vel_z: -0.0655
     Episode_Reward/pen_ang_vel_xy: -0.1354
   Episode_Reward/pen_joint_torque: -0.1716
    Episode_Reward/pen_joint_accel: -0.0798
    Episode_Reward/pen_action_rate: -0.2497
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0342
   Episode_Reward/pen_joint_powers: -0.0589
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5747
Episode_Reward/pen_flat_orientation: -0.1229
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2396
   Episode_Reward/foot_landing_vel: -0.1108
   Episode_Reward/test_gait_reward: -0.8347
Metrics/base_velocity/error_vel_xy: 2.1671
Metrics/base_velocity/error_vel_yaw: 0.8944
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 1.09s
                        Total time: 1189.62s
                               ETA: 2067.7s

################################################################################
                     [1m Learning iteration 1096/3000 [0m                     

                       Computation: 90897 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 1.1143
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6047
                     Learning rate: 0.0004
                       Mean reward: 75.74
               Mean episode length: 914.17
       Episode_Reward/keep_balance: 0.9080
     Episode_Reward/rew_lin_vel_xy: 3.3016
      Episode_Reward/rew_ang_vel_z: 2.6279
    Episode_Reward/pen_base_height: -0.3750
      Episode_Reward/pen_lin_vel_z: -0.0670
     Episode_Reward/pen_ang_vel_xy: -0.1377
   Episode_Reward/pen_joint_torque: -0.1770
    Episode_Reward/pen_joint_accel: -0.0723
    Episode_Reward/pen_action_rate: -0.2513
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0341
   Episode_Reward/pen_joint_powers: -0.0600
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5779
Episode_Reward/pen_flat_orientation: -0.1323
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2511
   Episode_Reward/foot_landing_vel: -0.1017
   Episode_Reward/test_gait_reward: -0.8468
Metrics/base_velocity/error_vel_xy: 2.3001
Metrics/base_velocity/error_vel_yaw: 0.9068
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 1.08s
                        Total time: 1190.70s
                               ETA: 2066.6s

################################################################################
                     [1m Learning iteration 1097/3000 [0m                     

                       Computation: 92085 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 1.1113
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6044
                     Learning rate: 0.0003
                       Mean reward: 75.16
               Mean episode length: 871.49
       Episode_Reward/keep_balance: 0.8751
     Episode_Reward/rew_lin_vel_xy: 3.3582
      Episode_Reward/rew_ang_vel_z: 2.4975
    Episode_Reward/pen_base_height: -0.3566
      Episode_Reward/pen_lin_vel_z: -0.0660
     Episode_Reward/pen_ang_vel_xy: -0.1356
   Episode_Reward/pen_joint_torque: -0.1672
    Episode_Reward/pen_joint_accel: -0.0703
    Episode_Reward/pen_action_rate: -0.2458
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0338
   Episode_Reward/pen_joint_powers: -0.0577
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5637
Episode_Reward/pen_flat_orientation: -0.1255
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.2464
   Episode_Reward/foot_landing_vel: -0.1017
   Episode_Reward/test_gait_reward: -0.8130
Metrics/base_velocity/error_vel_xy: 2.0498
Metrics/base_velocity/error_vel_yaw: 0.9093
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 1.07s
                        Total time: 1191.77s
                               ETA: 2065.5s

################################################################################
                     [1m Learning iteration 1098/3000 [0m                     

                       Computation: 90388 steps/s (collection: 0.960s, learning 0.128s)
               Value function loss: 1.0701
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6047
                     Learning rate: 0.0006
                       Mean reward: 79.79
               Mean episode length: 888.43
       Episode_Reward/keep_balance: 0.8888
     Episode_Reward/rew_lin_vel_xy: 3.6510
      Episode_Reward/rew_ang_vel_z: 2.5518
    Episode_Reward/pen_base_height: -0.3669
      Episode_Reward/pen_lin_vel_z: -0.0693
     Episode_Reward/pen_ang_vel_xy: -0.1370
   Episode_Reward/pen_joint_torque: -0.1768
    Episode_Reward/pen_joint_accel: -0.0820
    Episode_Reward/pen_action_rate: -0.2511
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0358
   Episode_Reward/pen_joint_powers: -0.0616
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5707
Episode_Reward/pen_flat_orientation: -0.1377
  Episode_Reward/pen_feet_distance: -0.0028
Episode_Reward/pen_feet_regulation: -0.2733
   Episode_Reward/foot_landing_vel: -0.1087
   Episode_Reward/test_gait_reward: -0.8356
Metrics/base_velocity/error_vel_xy: 2.0059
Metrics/base_velocity/error_vel_yaw: 0.9062
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 1.09s
                        Total time: 1192.86s
                               ETA: 2064.4s

################################################################################
                     [1m Learning iteration 1099/3000 [0m                     

                       Computation: 91688 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 1.2014
                    Surrogate loss: -0.0012
             Mean action noise std: 0.6061
                     Learning rate: 0.0009
                       Mean reward: 75.65
               Mean episode length: 892.36
       Episode_Reward/keep_balance: 0.8744
     Episode_Reward/rew_lin_vel_xy: 3.4143
      Episode_Reward/rew_ang_vel_z: 2.4873
    Episode_Reward/pen_base_height: -0.3653
      Episode_Reward/pen_lin_vel_z: -0.0656
     Episode_Reward/pen_ang_vel_xy: -0.1334
   Episode_Reward/pen_joint_torque: -0.1667
    Episode_Reward/pen_joint_accel: -0.0750
    Episode_Reward/pen_action_rate: -0.2456
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0339
   Episode_Reward/pen_joint_powers: -0.0578
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5619
Episode_Reward/pen_flat_orientation: -0.1342
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.2550
   Episode_Reward/foot_landing_vel: -0.0967
   Episode_Reward/test_gait_reward: -0.8184
Metrics/base_velocity/error_vel_xy: 2.0360
Metrics/base_velocity/error_vel_yaw: 0.9082
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 1.07s
                        Total time: 1193.93s
                               ETA: 2063.3s

################################################################################
                     [1m Learning iteration 1100/3000 [0m                     

                       Computation: 92262 steps/s (collection: 0.942s, learning 0.124s)
               Value function loss: 1.1609
                    Surrogate loss: 0.0008
             Mean action noise std: 0.6060
                     Learning rate: 0.0003
                       Mean reward: 80.05
               Mean episode length: 913.72
       Episode_Reward/keep_balance: 0.9171
     Episode_Reward/rew_lin_vel_xy: 3.5253
      Episode_Reward/rew_ang_vel_z: 2.6409
    Episode_Reward/pen_base_height: -0.3550
      Episode_Reward/pen_lin_vel_z: -0.0650
     Episode_Reward/pen_ang_vel_xy: -0.1345
   Episode_Reward/pen_joint_torque: -0.1732
    Episode_Reward/pen_joint_accel: -0.0774
    Episode_Reward/pen_action_rate: -0.2527
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0339
   Episode_Reward/pen_joint_powers: -0.0592
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.5881
Episode_Reward/pen_flat_orientation: -0.1205
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2413
   Episode_Reward/foot_landing_vel: -0.1020
   Episode_Reward/test_gait_reward: -0.8574
Metrics/base_velocity/error_vel_xy: 2.1957
Metrics/base_velocity/error_vel_yaw: 0.9244
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 1.07s
                        Total time: 1194.99s
                               ETA: 2062.2s

################################################################################
                     [1m Learning iteration 1101/3000 [0m                     

                       Computation: 91135 steps/s (collection: 0.953s, learning 0.126s)
               Value function loss: 1.0271
                    Surrogate loss: -0.0041
             Mean action noise std: 0.6064
                     Learning rate: 0.0006
                       Mean reward: 77.12
               Mean episode length: 902.83
       Episode_Reward/keep_balance: 0.9015
     Episode_Reward/rew_lin_vel_xy: 3.3950
      Episode_Reward/rew_ang_vel_z: 2.5750
    Episode_Reward/pen_base_height: -0.3624
      Episode_Reward/pen_lin_vel_z: -0.0635
     Episode_Reward/pen_ang_vel_xy: -0.1370
   Episode_Reward/pen_joint_torque: -0.1677
    Episode_Reward/pen_joint_accel: -0.0736
    Episode_Reward/pen_action_rate: -0.2494
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0344
   Episode_Reward/pen_joint_powers: -0.0586
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5785
Episode_Reward/pen_flat_orientation: -0.1270
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.2470
   Episode_Reward/foot_landing_vel: -0.0997
   Episode_Reward/test_gait_reward: -0.8365
Metrics/base_velocity/error_vel_xy: 2.2031
Metrics/base_velocity/error_vel_yaw: 0.9318
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 1.08s
                        Total time: 1196.07s
                               ETA: 2061.1s

################################################################################
                     [1m Learning iteration 1102/3000 [0m                     

                       Computation: 93377 steps/s (collection: 0.929s, learning 0.124s)
               Value function loss: 1.2094
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6061
                     Learning rate: 0.0004
                       Mean reward: 74.98
               Mean episode length: 886.61
       Episode_Reward/keep_balance: 0.9123
     Episode_Reward/rew_lin_vel_xy: 3.6166
      Episode_Reward/rew_ang_vel_z: 2.6241
    Episode_Reward/pen_base_height: -0.3585
      Episode_Reward/pen_lin_vel_z: -0.0689
     Episode_Reward/pen_ang_vel_xy: -0.1407
   Episode_Reward/pen_joint_torque: -0.1719
    Episode_Reward/pen_joint_accel: -0.0810
    Episode_Reward/pen_action_rate: -0.2550
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0350
   Episode_Reward/pen_joint_powers: -0.0603
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5947
Episode_Reward/pen_flat_orientation: -0.1281
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.2566
   Episode_Reward/foot_landing_vel: -0.1098
   Episode_Reward/test_gait_reward: -0.8507
Metrics/base_velocity/error_vel_xy: 2.0673
Metrics/base_velocity/error_vel_yaw: 0.9268
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 1.05s
                        Total time: 1197.12s
                               ETA: 2060.0s

################################################################################
                     [1m Learning iteration 1103/3000 [0m                     

                       Computation: 90113 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 1.1724
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6058
                     Learning rate: 0.0006
                       Mean reward: 81.06
               Mean episode length: 914.75
       Episode_Reward/keep_balance: 0.9313
     Episode_Reward/rew_lin_vel_xy: 3.7525
      Episode_Reward/rew_ang_vel_z: 2.6884
    Episode_Reward/pen_base_height: -0.3761
      Episode_Reward/pen_lin_vel_z: -0.0695
     Episode_Reward/pen_ang_vel_xy: -0.1399
   Episode_Reward/pen_joint_torque: -0.1785
    Episode_Reward/pen_joint_accel: -0.0792
    Episode_Reward/pen_action_rate: -0.2603
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0354
   Episode_Reward/pen_joint_powers: -0.0617
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6025
Episode_Reward/pen_flat_orientation: -0.1289
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2649
   Episode_Reward/foot_landing_vel: -0.0996
   Episode_Reward/test_gait_reward: -0.8724
Metrics/base_velocity/error_vel_xy: 2.1014
Metrics/base_velocity/error_vel_yaw: 0.9352
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 1.09s
                        Total time: 1198.22s
                               ETA: 2058.9s

################################################################################
                     [1m Learning iteration 1104/3000 [0m                     

                       Computation: 91113 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 1.0754
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6073
                     Learning rate: 0.0004
                       Mean reward: 74.68
               Mean episode length: 877.81
       Episode_Reward/keep_balance: 0.8574
     Episode_Reward/rew_lin_vel_xy: 3.2808
      Episode_Reward/rew_ang_vel_z: 2.4619
    Episode_Reward/pen_base_height: -0.3391
      Episode_Reward/pen_lin_vel_z: -0.0653
     Episode_Reward/pen_ang_vel_xy: -0.1302
   Episode_Reward/pen_joint_torque: -0.1704
    Episode_Reward/pen_joint_accel: -0.0781
    Episode_Reward/pen_action_rate: -0.2429
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0332
   Episode_Reward/pen_joint_powers: -0.0573
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5590
Episode_Reward/pen_flat_orientation: -0.1168
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2461
   Episode_Reward/foot_landing_vel: -0.1038
   Episode_Reward/test_gait_reward: -0.7997
Metrics/base_velocity/error_vel_xy: 1.9848
Metrics/base_velocity/error_vel_yaw: 0.8669
      Episode_Termination/time_out: 3.0833
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 1.08s
                        Total time: 1199.29s
                               ETA: 2057.8s

################################################################################
                     [1m Learning iteration 1105/3000 [0m                     

                       Computation: 91384 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 1.1113
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6084
                     Learning rate: 0.0006
                       Mean reward: 84.18
               Mean episode length: 925.62
       Episode_Reward/keep_balance: 0.9189
     Episode_Reward/rew_lin_vel_xy: 3.7167
      Episode_Reward/rew_ang_vel_z: 2.6618
    Episode_Reward/pen_base_height: -0.3658
      Episode_Reward/pen_lin_vel_z: -0.0661
     Episode_Reward/pen_ang_vel_xy: -0.1393
   Episode_Reward/pen_joint_torque: -0.1738
    Episode_Reward/pen_joint_accel: -0.0802
    Episode_Reward/pen_action_rate: -0.2565
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0341
   Episode_Reward/pen_joint_powers: -0.0595
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.5921
Episode_Reward/pen_flat_orientation: -0.1290
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2521
   Episode_Reward/foot_landing_vel: -0.1012
   Episode_Reward/test_gait_reward: -0.8614
Metrics/base_velocity/error_vel_xy: 2.0476
Metrics/base_velocity/error_vel_yaw: 0.9134
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 1.08s
                        Total time: 1200.37s
                               ETA: 2056.7s

################################################################################
                     [1m Learning iteration 1106/3000 [0m                     

                       Computation: 91696 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 1.1787
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6090
                     Learning rate: 0.0006
                       Mean reward: 76.85
               Mean episode length: 874.90
       Episode_Reward/keep_balance: 0.9000
     Episode_Reward/rew_lin_vel_xy: 3.5347
      Episode_Reward/rew_ang_vel_z: 2.6228
    Episode_Reward/pen_base_height: -0.3621
      Episode_Reward/pen_lin_vel_z: -0.0670
     Episode_Reward/pen_ang_vel_xy: -0.1333
   Episode_Reward/pen_joint_torque: -0.1748
    Episode_Reward/pen_joint_accel: -0.0783
    Episode_Reward/pen_action_rate: -0.2513
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0338
   Episode_Reward/pen_joint_powers: -0.0594
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.5771
Episode_Reward/pen_flat_orientation: -0.1213
  Episode_Reward/pen_feet_distance: -0.0035
Episode_Reward/pen_feet_regulation: -0.2528
   Episode_Reward/foot_landing_vel: -0.1050
   Episode_Reward/test_gait_reward: -0.8436
Metrics/base_velocity/error_vel_xy: 2.1005
Metrics/base_velocity/error_vel_yaw: 0.8850
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 1.07s
                        Total time: 1201.44s
                               ETA: 2055.6s

################################################################################
                     [1m Learning iteration 1107/3000 [0m                     

                       Computation: 91283 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 1.0006
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6097
                     Learning rate: 0.0004
                       Mean reward: 83.28
               Mean episode length: 927.78
       Episode_Reward/keep_balance: 0.9343
     Episode_Reward/rew_lin_vel_xy: 3.7079
      Episode_Reward/rew_ang_vel_z: 2.6648
    Episode_Reward/pen_base_height: -0.3652
      Episode_Reward/pen_lin_vel_z: -0.0640
     Episode_Reward/pen_ang_vel_xy: -0.1390
   Episode_Reward/pen_joint_torque: -0.1721
    Episode_Reward/pen_joint_accel: -0.0786
    Episode_Reward/pen_action_rate: -0.2597
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0347
   Episode_Reward/pen_joint_powers: -0.0598
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6091
Episode_Reward/pen_flat_orientation: -0.1210
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2458
   Episode_Reward/foot_landing_vel: -0.0965
   Episode_Reward/test_gait_reward: -0.8796
Metrics/base_velocity/error_vel_xy: 2.1149
Metrics/base_velocity/error_vel_yaw: 0.9575
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 1.08s
                        Total time: 1202.52s
                               ETA: 2054.5s

################################################################################
                     [1m Learning iteration 1108/3000 [0m                     

                       Computation: 92093 steps/s (collection: 0.943s, learning 0.124s)
               Value function loss: 1.1390
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6096
                     Learning rate: 0.0003
                       Mean reward: 87.71
               Mean episode length: 946.68
       Episode_Reward/keep_balance: 0.9528
     Episode_Reward/rew_lin_vel_xy: 3.8689
      Episode_Reward/rew_ang_vel_z: 2.7912
    Episode_Reward/pen_base_height: -0.3707
      Episode_Reward/pen_lin_vel_z: -0.0647
     Episode_Reward/pen_ang_vel_xy: -0.1414
   Episode_Reward/pen_joint_torque: -0.1764
    Episode_Reward/pen_joint_accel: -0.0736
    Episode_Reward/pen_action_rate: -0.2610
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0345
   Episode_Reward/pen_joint_powers: -0.0602
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6109
Episode_Reward/pen_flat_orientation: -0.1263
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.2486
   Episode_Reward/foot_landing_vel: -0.1023
   Episode_Reward/test_gait_reward: -0.8852
Metrics/base_velocity/error_vel_xy: 2.1137
Metrics/base_velocity/error_vel_yaw: 0.9221
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 1.07s
                        Total time: 1203.59s
                               ETA: 2053.4s

################################################################################
                     [1m Learning iteration 1109/3000 [0m                     

                       Computation: 91784 steps/s (collection: 0.947s, learning 0.124s)
               Value function loss: 1.1935
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6092
                     Learning rate: 0.0006
                       Mean reward: 76.41
               Mean episode length: 918.39
       Episode_Reward/keep_balance: 0.9143
     Episode_Reward/rew_lin_vel_xy: 3.4114
      Episode_Reward/rew_ang_vel_z: 2.6113
    Episode_Reward/pen_base_height: -0.3695
      Episode_Reward/pen_lin_vel_z: -0.0640
     Episode_Reward/pen_ang_vel_xy: -0.1385
   Episode_Reward/pen_joint_torque: -0.1698
    Episode_Reward/pen_joint_accel: -0.0793
    Episode_Reward/pen_action_rate: -0.2573
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0345
   Episode_Reward/pen_joint_powers: -0.0588
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5972
Episode_Reward/pen_flat_orientation: -0.1287
  Episode_Reward/pen_feet_distance: -0.0047
Episode_Reward/pen_feet_regulation: -0.2456
   Episode_Reward/foot_landing_vel: -0.1039
   Episode_Reward/test_gait_reward: -0.8531
Metrics/base_velocity/error_vel_xy: 2.2829
Metrics/base_velocity/error_vel_yaw: 0.9432
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 1.07s
                        Total time: 1204.66s
                               ETA: 2052.3s

################################################################################
                     [1m Learning iteration 1110/3000 [0m                     

                       Computation: 91194 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.3310
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6096
                     Learning rate: 0.0003
                       Mean reward: 75.12
               Mean episode length: 873.33
       Episode_Reward/keep_balance: 0.9029
     Episode_Reward/rew_lin_vel_xy: 3.6110
      Episode_Reward/rew_ang_vel_z: 2.5927
    Episode_Reward/pen_base_height: -0.3556
      Episode_Reward/pen_lin_vel_z: -0.0624
     Episode_Reward/pen_ang_vel_xy: -0.1409
   Episode_Reward/pen_joint_torque: -0.1676
    Episode_Reward/pen_joint_accel: -0.0802
    Episode_Reward/pen_action_rate: -0.2545
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0343
   Episode_Reward/pen_joint_powers: -0.0584
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5897
Episode_Reward/pen_flat_orientation: -0.1227
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.2399
   Episode_Reward/foot_landing_vel: -0.1001
   Episode_Reward/test_gait_reward: -0.8425
Metrics/base_velocity/error_vel_xy: 2.0351
Metrics/base_velocity/error_vel_yaw: 0.9201
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 1.08s
                        Total time: 1205.74s
                               ETA: 2051.2s

################################################################################
                     [1m Learning iteration 1111/3000 [0m                     

                       Computation: 91614 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 1.0605
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6103
                     Learning rate: 0.0006
                       Mean reward: 83.83
               Mean episode length: 925.52
       Episode_Reward/keep_balance: 0.9332
     Episode_Reward/rew_lin_vel_xy: 3.7620
      Episode_Reward/rew_ang_vel_z: 2.7114
    Episode_Reward/pen_base_height: -0.3480
      Episode_Reward/pen_lin_vel_z: -0.0612
     Episode_Reward/pen_ang_vel_xy: -0.1395
   Episode_Reward/pen_joint_torque: -0.1680
    Episode_Reward/pen_joint_accel: -0.0754
    Episode_Reward/pen_action_rate: -0.2566
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0339
   Episode_Reward/pen_joint_powers: -0.0584
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6040
Episode_Reward/pen_flat_orientation: -0.1256
  Episode_Reward/pen_feet_distance: -0.0027
Episode_Reward/pen_feet_regulation: -0.2342
   Episode_Reward/foot_landing_vel: -0.0948
   Episode_Reward/test_gait_reward: -0.8645
Metrics/base_velocity/error_vel_xy: 2.0873
Metrics/base_velocity/error_vel_yaw: 0.9241
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 1.07s
                        Total time: 1206.81s
                               ETA: 2050.1s

################################################################################
                     [1m Learning iteration 1112/3000 [0m                     

                       Computation: 92324 steps/s (collection: 0.941s, learning 0.124s)
               Value function loss: 1.2292
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6114
                     Learning rate: 0.0003
                       Mean reward: 79.86
               Mean episode length: 917.85
       Episode_Reward/keep_balance: 0.8991
     Episode_Reward/rew_lin_vel_xy: 3.4562
      Episode_Reward/rew_ang_vel_z: 2.5584
    Episode_Reward/pen_base_height: -0.3578
      Episode_Reward/pen_lin_vel_z: -0.0605
     Episode_Reward/pen_ang_vel_xy: -0.1374
   Episode_Reward/pen_joint_torque: -0.1671
    Episode_Reward/pen_joint_accel: -0.0799
    Episode_Reward/pen_action_rate: -0.2535
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0344
   Episode_Reward/pen_joint_powers: -0.0579
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5873
Episode_Reward/pen_flat_orientation: -0.1226
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.2458
   Episode_Reward/foot_landing_vel: -0.0977
   Episode_Reward/test_gait_reward: -0.8392
Metrics/base_velocity/error_vel_xy: 2.1616
Metrics/base_velocity/error_vel_yaw: 0.9316
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 1.06s
                        Total time: 1207.87s
                               ETA: 2048.9s

################################################################################
                     [1m Learning iteration 1113/3000 [0m                     

                       Computation: 90889 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 1.1305
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6119
                     Learning rate: 0.0004
                       Mean reward: 82.53
               Mean episode length: 893.07
       Episode_Reward/keep_balance: 0.8869
     Episode_Reward/rew_lin_vel_xy: 3.5740
      Episode_Reward/rew_ang_vel_z: 2.5359
    Episode_Reward/pen_base_height: -0.3514
      Episode_Reward/pen_lin_vel_z: -0.0592
     Episode_Reward/pen_ang_vel_xy: -0.1287
   Episode_Reward/pen_joint_torque: -0.1616
    Episode_Reward/pen_joint_accel: -0.0718
    Episode_Reward/pen_action_rate: -0.2465
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0325
   Episode_Reward/pen_joint_powers: -0.0559
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5829
Episode_Reward/pen_flat_orientation: -0.1221
  Episode_Reward/pen_feet_distance: -0.0029
Episode_Reward/pen_feet_regulation: -0.2265
   Episode_Reward/foot_landing_vel: -0.0946
   Episode_Reward/test_gait_reward: -0.8269
Metrics/base_velocity/error_vel_xy: 2.0011
Metrics/base_velocity/error_vel_yaw: 0.9118
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 1.08s
                        Total time: 1208.96s
                               ETA: 2047.8s

################################################################################
                     [1m Learning iteration 1114/3000 [0m                     

                       Computation: 92114 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 1.0738
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6125
                     Learning rate: 0.0009
                       Mean reward: 85.08
               Mean episode length: 934.27
       Episode_Reward/keep_balance: 0.9405
     Episode_Reward/rew_lin_vel_xy: 3.7797
      Episode_Reward/rew_ang_vel_z: 2.7185
    Episode_Reward/pen_base_height: -0.3642
      Episode_Reward/pen_lin_vel_z: -0.0663
     Episode_Reward/pen_ang_vel_xy: -0.1374
   Episode_Reward/pen_joint_torque: -0.1754
    Episode_Reward/pen_joint_accel: -0.0881
    Episode_Reward/pen_action_rate: -0.2660
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0357
   Episode_Reward/pen_joint_powers: -0.0605
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6151
Episode_Reward/pen_flat_orientation: -0.1200
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2593
   Episode_Reward/foot_landing_vel: -0.1077
   Episode_Reward/test_gait_reward: -0.8757
Metrics/base_velocity/error_vel_xy: 2.1283
Metrics/base_velocity/error_vel_yaw: 0.9437
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 1.07s
                        Total time: 1210.02s
                               ETA: 2046.7s

################################################################################
                     [1m Learning iteration 1115/3000 [0m                     

                       Computation: 91733 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 1.2383
                    Surrogate loss: 0.0029
             Mean action noise std: 0.6122
                     Learning rate: 0.0001
                       Mean reward: 81.14
               Mean episode length: 917.45
       Episode_Reward/keep_balance: 0.9210
     Episode_Reward/rew_lin_vel_xy: 3.6418
      Episode_Reward/rew_ang_vel_z: 2.6402
    Episode_Reward/pen_base_height: -0.3697
      Episode_Reward/pen_lin_vel_z: -0.0653
     Episode_Reward/pen_ang_vel_xy: -0.1371
   Episode_Reward/pen_joint_torque: -0.1763
    Episode_Reward/pen_joint_accel: -0.0773
    Episode_Reward/pen_action_rate: -0.2595
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0342
   Episode_Reward/pen_joint_powers: -0.0603
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.6003
Episode_Reward/pen_flat_orientation: -0.1283
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.2520
   Episode_Reward/foot_landing_vel: -0.0994
   Episode_Reward/test_gait_reward: -0.8617
Metrics/base_velocity/error_vel_xy: 2.0979
Metrics/base_velocity/error_vel_yaw: 0.9426
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 1.07s
                        Total time: 1211.09s
                               ETA: 2045.6s

################################################################################
                     [1m Learning iteration 1116/3000 [0m                     

                       Computation: 92775 steps/s (collection: 0.937s, learning 0.123s)
               Value function loss: 1.0855
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6117
                     Learning rate: 0.0004
                       Mean reward: 85.14
               Mean episode length: 947.57
       Episode_Reward/keep_balance: 0.9515
     Episode_Reward/rew_lin_vel_xy: 3.8669
      Episode_Reward/rew_ang_vel_z: 2.7362
    Episode_Reward/pen_base_height: -0.3678
      Episode_Reward/pen_lin_vel_z: -0.0654
     Episode_Reward/pen_ang_vel_xy: -0.1410
   Episode_Reward/pen_joint_torque: -0.1773
    Episode_Reward/pen_joint_accel: -0.0769
    Episode_Reward/pen_action_rate: -0.2674
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0345
   Episode_Reward/pen_joint_powers: -0.0601
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6247
Episode_Reward/pen_flat_orientation: -0.1234
  Episode_Reward/pen_feet_distance: -0.0027
Episode_Reward/pen_feet_regulation: -0.2486
   Episode_Reward/foot_landing_vel: -0.1041
   Episode_Reward/test_gait_reward: -0.8905
Metrics/base_velocity/error_vel_xy: 2.0839
Metrics/base_velocity/error_vel_yaw: 0.9606
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 1.06s
                        Total time: 1212.15s
                               ETA: 2044.5s

################################################################################
                     [1m Learning iteration 1117/3000 [0m                     

                       Computation: 91439 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 1.1320
                    Surrogate loss: 0.0013
             Mean action noise std: 0.6115
                     Learning rate: 0.0001
                       Mean reward: 84.63
               Mean episode length: 917.01
       Episode_Reward/keep_balance: 0.9073
     Episode_Reward/rew_lin_vel_xy: 3.7927
      Episode_Reward/rew_ang_vel_z: 2.6351
    Episode_Reward/pen_base_height: -0.3594
      Episode_Reward/pen_lin_vel_z: -0.0652
     Episode_Reward/pen_ang_vel_xy: -0.1367
   Episode_Reward/pen_joint_torque: -0.1718
    Episode_Reward/pen_joint_accel: -0.0756
    Episode_Reward/pen_action_rate: -0.2561
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0343
   Episode_Reward/pen_joint_powers: -0.0594
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.5918
Episode_Reward/pen_flat_orientation: -0.1251
  Episode_Reward/pen_feet_distance: -0.0029
Episode_Reward/pen_feet_regulation: -0.2551
   Episode_Reward/foot_landing_vel: -0.1037
   Episode_Reward/test_gait_reward: -0.8489
Metrics/base_velocity/error_vel_xy: 1.9896
Metrics/base_velocity/error_vel_yaw: 0.8995
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 1.08s
                        Total time: 1213.23s
                               ETA: 2043.4s

################################################################################
                     [1m Learning iteration 1118/3000 [0m                     

                       Computation: 91736 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 1.0874
                    Surrogate loss: -0.0040
             Mean action noise std: 0.6113
                     Learning rate: 0.0003
                       Mean reward: 81.58
               Mean episode length: 924.55
       Episode_Reward/keep_balance: 0.9453
     Episode_Reward/rew_lin_vel_xy: 3.7341
      Episode_Reward/rew_ang_vel_z: 2.6789
    Episode_Reward/pen_base_height: -0.3827
      Episode_Reward/pen_lin_vel_z: -0.0637
     Episode_Reward/pen_ang_vel_xy: -0.1403
   Episode_Reward/pen_joint_torque: -0.1802
    Episode_Reward/pen_joint_accel: -0.0827
    Episode_Reward/pen_action_rate: -0.2687
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0357
   Episode_Reward/pen_joint_powers: -0.0614
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6210
Episode_Reward/pen_flat_orientation: -0.1282
  Episode_Reward/pen_feet_distance: -0.0035
Episode_Reward/pen_feet_regulation: -0.2552
   Episode_Reward/foot_landing_vel: -0.1009
   Episode_Reward/test_gait_reward: -0.8867
Metrics/base_velocity/error_vel_xy: 2.0924
Metrics/base_velocity/error_vel_yaw: 0.9890
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 1.07s
                        Total time: 1214.30s
                               ETA: 2042.3s

################################################################################
                     [1m Learning iteration 1119/3000 [0m                     

                       Computation: 91904 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 1.1861
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6114
                     Learning rate: 0.0006
                       Mean reward: 77.59
               Mean episode length: 898.69
       Episode_Reward/keep_balance: 0.8840
     Episode_Reward/rew_lin_vel_xy: 3.4698
      Episode_Reward/rew_ang_vel_z: 2.5188
    Episode_Reward/pen_base_height: -0.3681
      Episode_Reward/pen_lin_vel_z: -0.0636
     Episode_Reward/pen_ang_vel_xy: -0.1349
   Episode_Reward/pen_joint_torque: -0.1733
    Episode_Reward/pen_joint_accel: -0.0855
    Episode_Reward/pen_action_rate: -0.2536
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0343
   Episode_Reward/pen_joint_powers: -0.0584
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.5840
Episode_Reward/pen_flat_orientation: -0.1356
  Episode_Reward/pen_feet_distance: -0.0038
Episode_Reward/pen_feet_regulation: -0.2511
   Episode_Reward/foot_landing_vel: -0.1035
   Episode_Reward/test_gait_reward: -0.8354
Metrics/base_velocity/error_vel_xy: 2.0367
Metrics/base_velocity/error_vel_yaw: 0.9271
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 1.07s
                        Total time: 1215.37s
                               ETA: 2041.2s

################################################################################
                     [1m Learning iteration 1120/3000 [0m                     

                       Computation: 91983 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 1.0623
                    Surrogate loss: -0.0039
             Mean action noise std: 0.6108
                     Learning rate: 0.0009
                       Mean reward: 71.00
               Mean episode length: 855.39
       Episode_Reward/keep_balance: 0.8477
     Episode_Reward/rew_lin_vel_xy: 3.2691
      Episode_Reward/rew_ang_vel_z: 2.4192
    Episode_Reward/pen_base_height: -0.3653
      Episode_Reward/pen_lin_vel_z: -0.0619
     Episode_Reward/pen_ang_vel_xy: -0.1326
   Episode_Reward/pen_joint_torque: -0.1662
    Episode_Reward/pen_joint_accel: -0.0744
    Episode_Reward/pen_action_rate: -0.2435
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0335
   Episode_Reward/pen_joint_powers: -0.0574
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5569
Episode_Reward/pen_flat_orientation: -0.1310
  Episode_Reward/pen_feet_distance: -0.0025
Episode_Reward/pen_feet_regulation: -0.2493
   Episode_Reward/foot_landing_vel: -0.0924
   Episode_Reward/test_gait_reward: -0.8007
Metrics/base_velocity/error_vel_xy: 1.9932
Metrics/base_velocity/error_vel_yaw: 0.8785
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 1.07s
                        Total time: 1216.44s
                               ETA: 2040.1s

################################################################################
                     [1m Learning iteration 1121/3000 [0m                     

                       Computation: 90790 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 1.1530
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6118
                     Learning rate: 0.0004
                       Mean reward: 75.58
               Mean episode length: 875.27
       Episode_Reward/keep_balance: 0.8967
     Episode_Reward/rew_lin_vel_xy: 3.5852
      Episode_Reward/rew_ang_vel_z: 2.5617
    Episode_Reward/pen_base_height: -0.3771
      Episode_Reward/pen_lin_vel_z: -0.0662
     Episode_Reward/pen_ang_vel_xy: -0.1419
   Episode_Reward/pen_joint_torque: -0.1720
    Episode_Reward/pen_joint_accel: -0.0811
    Episode_Reward/pen_action_rate: -0.2613
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0360
   Episode_Reward/pen_joint_powers: -0.0605
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5956
Episode_Reward/pen_flat_orientation: -0.1327
  Episode_Reward/pen_feet_distance: -0.0028
Episode_Reward/pen_feet_regulation: -0.2734
   Episode_Reward/foot_landing_vel: -0.1011
   Episode_Reward/test_gait_reward: -0.8456
Metrics/base_velocity/error_vel_xy: 2.0189
Metrics/base_velocity/error_vel_yaw: 0.9278
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 1.08s
                        Total time: 1217.52s
                               ETA: 2039.0s

################################################################################
                     [1m Learning iteration 1122/3000 [0m                     

                       Computation: 90722 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 1.1541
                    Surrogate loss: -0.0034
             Mean action noise std: 0.6143
                     Learning rate: 0.0006
                       Mean reward: 75.76
               Mean episode length: 893.53
       Episode_Reward/keep_balance: 0.8779
     Episode_Reward/rew_lin_vel_xy: 3.3597
      Episode_Reward/rew_ang_vel_z: 2.4857
    Episode_Reward/pen_base_height: -0.3626
      Episode_Reward/pen_lin_vel_z: -0.0588
     Episode_Reward/pen_ang_vel_xy: -0.1384
   Episode_Reward/pen_joint_torque: -0.1656
    Episode_Reward/pen_joint_accel: -0.0756
    Episode_Reward/pen_action_rate: -0.2518
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0334
   Episode_Reward/pen_joint_powers: -0.0567
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5829
Episode_Reward/pen_flat_orientation: -0.1226
  Episode_Reward/pen_feet_distance: -0.0043
Episode_Reward/pen_feet_regulation: -0.2315
   Episode_Reward/foot_landing_vel: -0.0990
   Episode_Reward/test_gait_reward: -0.8185
Metrics/base_velocity/error_vel_xy: 2.0545
Metrics/base_velocity/error_vel_yaw: 0.9241
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 1.08s
                        Total time: 1218.60s
                               ETA: 2037.9s

################################################################################
                     [1m Learning iteration 1123/3000 [0m                     

                       Computation: 91943 steps/s (collection: 0.945s, learning 0.124s)
               Value function loss: 1.1817
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6148
                     Learning rate: 0.0009
                       Mean reward: 83.75
               Mean episode length: 930.21
       Episode_Reward/keep_balance: 0.9335
     Episode_Reward/rew_lin_vel_xy: 3.7388
      Episode_Reward/rew_ang_vel_z: 2.6712
    Episode_Reward/pen_base_height: -0.3715
      Episode_Reward/pen_lin_vel_z: -0.0641
     Episode_Reward/pen_ang_vel_xy: -0.1393
   Episode_Reward/pen_joint_torque: -0.1758
    Episode_Reward/pen_joint_accel: -0.0740
    Episode_Reward/pen_action_rate: -0.2649
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0353
   Episode_Reward/pen_joint_powers: -0.0606
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6134
Episode_Reward/pen_flat_orientation: -0.1235
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2584
   Episode_Reward/foot_landing_vel: -0.1028
   Episode_Reward/test_gait_reward: -0.8716
Metrics/base_velocity/error_vel_xy: 2.1007
Metrics/base_velocity/error_vel_yaw: 0.9552
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 1.07s
                        Total time: 1219.67s
                               ETA: 2036.8s

################################################################################
                     [1m Learning iteration 1124/3000 [0m                     

                       Computation: 91583 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 1.1591
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6154
                     Learning rate: 0.0006
                       Mean reward: 84.56
               Mean episode length: 918.27
       Episode_Reward/keep_balance: 0.9203
     Episode_Reward/rew_lin_vel_xy: 3.6945
      Episode_Reward/rew_ang_vel_z: 2.6650
    Episode_Reward/pen_base_height: -0.3519
      Episode_Reward/pen_lin_vel_z: -0.0578
     Episode_Reward/pen_ang_vel_xy: -0.1331
   Episode_Reward/pen_joint_torque: -0.1664
    Episode_Reward/pen_joint_accel: -0.0725
    Episode_Reward/pen_action_rate: -0.2533
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0326
   Episode_Reward/pen_joint_powers: -0.0564
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6020
Episode_Reward/pen_flat_orientation: -0.1206
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.2231
   Episode_Reward/foot_landing_vel: -0.0970
   Episode_Reward/test_gait_reward: -0.8494
Metrics/base_velocity/error_vel_xy: 2.0301
Metrics/base_velocity/error_vel_yaw: 0.9160
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 1.07s
                        Total time: 1220.75s
                               ETA: 2035.7s

################################################################################
                     [1m Learning iteration 1125/3000 [0m                     

                       Computation: 92098 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 1.0594
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6159
                     Learning rate: 0.0009
                       Mean reward: 84.59
               Mean episode length: 934.55
       Episode_Reward/keep_balance: 0.9272
     Episode_Reward/rew_lin_vel_xy: 3.7118
      Episode_Reward/rew_ang_vel_z: 2.6529
    Episode_Reward/pen_base_height: -0.3730
      Episode_Reward/pen_lin_vel_z: -0.0620
     Episode_Reward/pen_ang_vel_xy: -0.1360
   Episode_Reward/pen_joint_torque: -0.1711
    Episode_Reward/pen_joint_accel: -0.0804
    Episode_Reward/pen_action_rate: -0.2626
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0348
   Episode_Reward/pen_joint_powers: -0.0587
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6133
Episode_Reward/pen_flat_orientation: -0.1300
  Episode_Reward/pen_feet_distance: -0.0061
Episode_Reward/pen_feet_regulation: -0.2559
   Episode_Reward/foot_landing_vel: -0.0995
   Episode_Reward/test_gait_reward: -0.8633
Metrics/base_velocity/error_vel_xy: 2.0774
Metrics/base_velocity/error_vel_yaw: 0.9560
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 1.07s
                        Total time: 1221.81s
                               ETA: 2034.5s

################################################################################
                     [1m Learning iteration 1126/3000 [0m                     

                       Computation: 91903 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.1946
                    Surrogate loss: 0.0005
             Mean action noise std: 0.6158
                     Learning rate: 0.0004
                       Mean reward: 77.55
               Mean episode length: 887.97
       Episode_Reward/keep_balance: 0.9064
     Episode_Reward/rew_lin_vel_xy: 3.6755
      Episode_Reward/rew_ang_vel_z: 2.5894
    Episode_Reward/pen_base_height: -0.3652
      Episode_Reward/pen_lin_vel_z: -0.0613
     Episode_Reward/pen_ang_vel_xy: -0.1378
   Episode_Reward/pen_joint_torque: -0.1698
    Episode_Reward/pen_joint_accel: -0.0764
    Episode_Reward/pen_action_rate: -0.2571
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0342
   Episode_Reward/pen_joint_powers: -0.0584
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.5974
Episode_Reward/pen_flat_orientation: -0.1288
  Episode_Reward/pen_feet_distance: -0.0028
Episode_Reward/pen_feet_regulation: -0.2499
   Episode_Reward/foot_landing_vel: -0.1010
   Episode_Reward/test_gait_reward: -0.8440
Metrics/base_velocity/error_vel_xy: 1.9910
Metrics/base_velocity/error_vel_yaw: 0.9343
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 1.07s
                        Total time: 1222.88s
                               ETA: 2033.4s

################################################################################
                     [1m Learning iteration 1127/3000 [0m                     

                       Computation: 91396 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 1.1142
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6160
                     Learning rate: 0.0006
                       Mean reward: 84.02
               Mean episode length: 916.35
       Episode_Reward/keep_balance: 0.9370
     Episode_Reward/rew_lin_vel_xy: 3.9984
      Episode_Reward/rew_ang_vel_z: 2.6803
    Episode_Reward/pen_base_height: -0.3814
      Episode_Reward/pen_lin_vel_z: -0.0698
     Episode_Reward/pen_ang_vel_xy: -0.1429
   Episode_Reward/pen_joint_torque: -0.1827
    Episode_Reward/pen_joint_accel: -0.0754
    Episode_Reward/pen_action_rate: -0.2720
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0359
   Episode_Reward/pen_joint_powers: -0.0625
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6204
Episode_Reward/pen_flat_orientation: -0.1294
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2751
   Episode_Reward/foot_landing_vel: -0.1032
   Episode_Reward/test_gait_reward: -0.8781
Metrics/base_velocity/error_vel_xy: 1.9599
Metrics/base_velocity/error_vel_yaw: 0.9592
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 1.08s
                        Total time: 1223.96s
                               ETA: 2032.3s

################################################################################
                     [1m Learning iteration 1128/3000 [0m                     

                       Computation: 92801 steps/s (collection: 0.937s, learning 0.123s)
               Value function loss: 1.0042
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6159
                     Learning rate: 0.0003
                       Mean reward: 86.27
               Mean episode length: 951.11
       Episode_Reward/keep_balance: 0.9455
     Episode_Reward/rew_lin_vel_xy: 3.7566
      Episode_Reward/rew_ang_vel_z: 2.7142
    Episode_Reward/pen_base_height: -0.3652
      Episode_Reward/pen_lin_vel_z: -0.0606
     Episode_Reward/pen_ang_vel_xy: -0.1384
   Episode_Reward/pen_joint_torque: -0.1804
    Episode_Reward/pen_joint_accel: -0.0774
    Episode_Reward/pen_action_rate: -0.2648
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0344
   Episode_Reward/pen_joint_powers: -0.0606
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6201
Episode_Reward/pen_flat_orientation: -0.1206
  Episode_Reward/pen_feet_distance: -0.0036
Episode_Reward/pen_feet_regulation: -0.2392
   Episode_Reward/foot_landing_vel: -0.0975
   Episode_Reward/test_gait_reward: -0.8762
Metrics/base_velocity/error_vel_xy: 2.1855
Metrics/base_velocity/error_vel_yaw: 0.9620
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 1.06s
                        Total time: 1225.02s
                               ETA: 2031.2s

################################################################################
                     [1m Learning iteration 1129/3000 [0m                     

                       Computation: 92147 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 1.1276
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6159
                     Learning rate: 0.0004
                       Mean reward: 79.10
               Mean episode length: 908.61
       Episode_Reward/keep_balance: 0.9175
     Episode_Reward/rew_lin_vel_xy: 3.5433
      Episode_Reward/rew_ang_vel_z: 2.6373
    Episode_Reward/pen_base_height: -0.3591
      Episode_Reward/pen_lin_vel_z: -0.0614
     Episode_Reward/pen_ang_vel_xy: -0.1425
   Episode_Reward/pen_joint_torque: -0.1720
    Episode_Reward/pen_joint_accel: -0.0761
    Episode_Reward/pen_action_rate: -0.2615
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0347
   Episode_Reward/pen_joint_powers: -0.0591
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6070
Episode_Reward/pen_flat_orientation: -0.1189
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.2440
   Episode_Reward/foot_landing_vel: -0.1008
   Episode_Reward/test_gait_reward: -0.8525
Metrics/base_velocity/error_vel_xy: 2.1361
Metrics/base_velocity/error_vel_yaw: 0.9317
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 1.07s
                        Total time: 1226.09s
                               ETA: 2030.1s

################################################################################
                     [1m Learning iteration 1130/3000 [0m                     

                       Computation: 90941 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.9975
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6160
                     Learning rate: 0.0006
                       Mean reward: 84.28
               Mean episode length: 958.37
       Episode_Reward/keep_balance: 0.9390
     Episode_Reward/rew_lin_vel_xy: 3.6107
      Episode_Reward/rew_ang_vel_z: 2.6996
    Episode_Reward/pen_base_height: -0.3758
      Episode_Reward/pen_lin_vel_z: -0.0650
     Episode_Reward/pen_ang_vel_xy: -0.1399
   Episode_Reward/pen_joint_torque: -0.1829
    Episode_Reward/pen_joint_accel: -0.0811
    Episode_Reward/pen_action_rate: -0.2684
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0354
   Episode_Reward/pen_joint_powers: -0.0615
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6161
Episode_Reward/pen_flat_orientation: -0.1282
  Episode_Reward/pen_feet_distance: -0.0029
Episode_Reward/pen_feet_regulation: -0.2605
   Episode_Reward/foot_landing_vel: -0.1059
   Episode_Reward/test_gait_reward: -0.8870
Metrics/base_velocity/error_vel_xy: 2.2241
Metrics/base_velocity/error_vel_yaw: 0.9502
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 1.08s
                        Total time: 1227.17s
                               ETA: 2029.0s

################################################################################
                     [1m Learning iteration 1131/3000 [0m                     

                       Computation: 91366 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 1.1181
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6154
                     Learning rate: 0.0006
                       Mean reward: 83.36
               Mean episode length: 938.32
       Episode_Reward/keep_balance: 0.9448
     Episode_Reward/rew_lin_vel_xy: 3.8950
      Episode_Reward/rew_ang_vel_z: 2.6920
    Episode_Reward/pen_base_height: -0.3652
      Episode_Reward/pen_lin_vel_z: -0.0626
     Episode_Reward/pen_ang_vel_xy: -0.1390
   Episode_Reward/pen_joint_torque: -0.1825
    Episode_Reward/pen_joint_accel: -0.0799
    Episode_Reward/pen_action_rate: -0.2697
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0357
   Episode_Reward/pen_joint_powers: -0.0615
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6293
Episode_Reward/pen_flat_orientation: -0.1236
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.2651
   Episode_Reward/foot_landing_vel: -0.0993
   Episode_Reward/test_gait_reward: -0.8921
Metrics/base_velocity/error_vel_xy: 2.0617
Metrics/base_velocity/error_vel_yaw: 0.9755
      Episode_Termination/time_out: 3.1250
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 1.08s
                        Total time: 1228.24s
                               ETA: 2027.9s

################################################################################
                     [1m Learning iteration 1132/3000 [0m                     

                       Computation: 91369 steps/s (collection: 0.951s, learning 0.125s)
               Value function loss: 1.0844
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6156
                     Learning rate: 0.0002
                       Mean reward: 82.72
               Mean episode length: 932.37
       Episode_Reward/keep_balance: 0.9515
     Episode_Reward/rew_lin_vel_xy: 3.7531
      Episode_Reward/rew_ang_vel_z: 2.7257
    Episode_Reward/pen_base_height: -0.3688
      Episode_Reward/pen_lin_vel_z: -0.0676
     Episode_Reward/pen_ang_vel_xy: -0.1479
   Episode_Reward/pen_joint_torque: -0.1848
    Episode_Reward/pen_joint_accel: -0.0918
    Episode_Reward/pen_action_rate: -0.2769
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0380
   Episode_Reward/pen_joint_powers: -0.0637
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6357
Episode_Reward/pen_flat_orientation: -0.1314
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.2834
   Episode_Reward/foot_landing_vel: -0.1127
   Episode_Reward/test_gait_reward: -0.8884
Metrics/base_velocity/error_vel_xy: 2.1877
Metrics/base_velocity/error_vel_yaw: 0.9825
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 1.08s
                        Total time: 1229.32s
                               ETA: 2026.8s

################################################################################
                     [1m Learning iteration 1133/3000 [0m                     

                       Computation: 92900 steps/s (collection: 0.935s, learning 0.123s)
               Value function loss: 0.9944
                    Surrogate loss: -0.0036
             Mean action noise std: 0.6158
                     Learning rate: 0.0004
                       Mean reward: 81.74
               Mean episode length: 938.13
       Episode_Reward/keep_balance: 0.9362
     Episode_Reward/rew_lin_vel_xy: 3.6190
      Episode_Reward/rew_ang_vel_z: 2.6936
    Episode_Reward/pen_base_height: -0.3685
      Episode_Reward/pen_lin_vel_z: -0.0658
     Episode_Reward/pen_ang_vel_xy: -0.1424
   Episode_Reward/pen_joint_torque: -0.1867
    Episode_Reward/pen_joint_accel: -0.0812
    Episode_Reward/pen_action_rate: -0.2699
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0356
   Episode_Reward/pen_joint_powers: -0.0625
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6156
Episode_Reward/pen_flat_orientation: -0.1250
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2688
   Episode_Reward/foot_landing_vel: -0.1034
   Episode_Reward/test_gait_reward: -0.8765
Metrics/base_velocity/error_vel_xy: 2.2650
Metrics/base_velocity/error_vel_yaw: 0.9414
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 1.06s
                        Total time: 1230.38s
                               ETA: 2025.7s

################################################################################
                     [1m Learning iteration 1134/3000 [0m                     

                       Computation: 90852 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 1.1162
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6165
                     Learning rate: 0.0004
                       Mean reward: 79.91
               Mean episode length: 928.29
       Episode_Reward/keep_balance: 0.9179
     Episode_Reward/rew_lin_vel_xy: 3.4850
      Episode_Reward/rew_ang_vel_z: 2.6141
    Episode_Reward/pen_base_height: -0.3663
      Episode_Reward/pen_lin_vel_z: -0.0635
     Episode_Reward/pen_ang_vel_xy: -0.1401
   Episode_Reward/pen_joint_torque: -0.1718
    Episode_Reward/pen_joint_accel: -0.0736
    Episode_Reward/pen_action_rate: -0.2660
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0344
   Episode_Reward/pen_joint_powers: -0.0591
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6151
Episode_Reward/pen_flat_orientation: -0.1269
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2550
   Episode_Reward/foot_landing_vel: -0.0992
   Episode_Reward/test_gait_reward: -0.8604
Metrics/base_velocity/error_vel_xy: 2.2062
Metrics/base_velocity/error_vel_yaw: 0.9604
      Episode_Termination/time_out: 3.1250
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 1.08s
                        Total time: 1231.46s
                               ETA: 2024.6s

################################################################################
                     [1m Learning iteration 1135/3000 [0m                     

                       Computation: 92781 steps/s (collection: 0.934s, learning 0.126s)
               Value function loss: 1.1170
                    Surrogate loss: -0.0034
             Mean action noise std: 0.6162
                     Learning rate: 0.0006
                       Mean reward: 78.29
               Mean episode length: 927.86
       Episode_Reward/keep_balance: 0.9445
     Episode_Reward/rew_lin_vel_xy: 3.4488
      Episode_Reward/rew_ang_vel_z: 2.7077
    Episode_Reward/pen_base_height: -0.3782
      Episode_Reward/pen_lin_vel_z: -0.0602
     Episode_Reward/pen_ang_vel_xy: -0.1393
   Episode_Reward/pen_joint_torque: -0.1799
    Episode_Reward/pen_joint_accel: -0.0728
    Episode_Reward/pen_action_rate: -0.2675
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0346
   Episode_Reward/pen_joint_powers: -0.0600
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6212
Episode_Reward/pen_flat_orientation: -0.1232
  Episode_Reward/pen_feet_distance: -0.0035
Episode_Reward/pen_feet_regulation: -0.2392
   Episode_Reward/foot_landing_vel: -0.0965
   Episode_Reward/test_gait_reward: -0.8751
Metrics/base_velocity/error_vel_xy: 2.3117
Metrics/base_velocity/error_vel_yaw: 0.9621
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 1.06s
                        Total time: 1232.52s
                               ETA: 2023.5s

################################################################################
                     [1m Learning iteration 1136/3000 [0m                     

                       Computation: 90290 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 1.1354
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6169
                     Learning rate: 0.0009
                       Mean reward: 80.57
               Mean episode length: 918.88
       Episode_Reward/keep_balance: 0.9051
     Episode_Reward/rew_lin_vel_xy: 3.6059
      Episode_Reward/rew_ang_vel_z: 2.5751
    Episode_Reward/pen_base_height: -0.3686
      Episode_Reward/pen_lin_vel_z: -0.0650
     Episode_Reward/pen_ang_vel_xy: -0.1389
   Episode_Reward/pen_joint_torque: -0.1831
    Episode_Reward/pen_joint_accel: -0.0800
    Episode_Reward/pen_action_rate: -0.2627
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0360
   Episode_Reward/pen_joint_powers: -0.0619
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5993
Episode_Reward/pen_flat_orientation: -0.1308
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.2701
   Episode_Reward/foot_landing_vel: -0.1055
   Episode_Reward/test_gait_reward: -0.8500
Metrics/base_velocity/error_vel_xy: 2.0892
Metrics/base_velocity/error_vel_yaw: 0.9401
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 1.09s
                        Total time: 1233.61s
                               ETA: 2022.4s

################################################################################
                     [1m Learning iteration 1137/3000 [0m                     

                       Computation: 91361 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 1.1205
                    Surrogate loss: -0.0029
             Mean action noise std: 0.6171
                     Learning rate: 0.0006
                       Mean reward: 83.77
               Mean episode length: 938.04
       Episode_Reward/keep_balance: 0.9493
     Episode_Reward/rew_lin_vel_xy: 3.7386
      Episode_Reward/rew_ang_vel_z: 2.7288
    Episode_Reward/pen_base_height: -0.3595
      Episode_Reward/pen_lin_vel_z: -0.0634
     Episode_Reward/pen_ang_vel_xy: -0.1429
   Episode_Reward/pen_joint_torque: -0.1835
    Episode_Reward/pen_joint_accel: -0.0815
    Episode_Reward/pen_action_rate: -0.2707
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0354
   Episode_Reward/pen_joint_powers: -0.0613
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6297
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0058
Episode_Reward/pen_feet_regulation: -0.2504
   Episode_Reward/foot_landing_vel: -0.1094
   Episode_Reward/test_gait_reward: -0.8784
Metrics/base_velocity/error_vel_xy: 2.1745
Metrics/base_velocity/error_vel_yaw: 0.9575
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 1.08s
                        Total time: 1234.68s
                               ETA: 2021.3s

################################################################################
                     [1m Learning iteration 1138/3000 [0m                     

                       Computation: 91366 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 1.0668
                    Surrogate loss: -0.0010
             Mean action noise std: 0.6168
                     Learning rate: 0.0004
                       Mean reward: 87.05
               Mean episode length: 929.20
       Episode_Reward/keep_balance: 0.9334
     Episode_Reward/rew_lin_vel_xy: 3.8056
      Episode_Reward/rew_ang_vel_z: 2.6814
    Episode_Reward/pen_base_height: -0.3668
      Episode_Reward/pen_lin_vel_z: -0.0587
     Episode_Reward/pen_ang_vel_xy: -0.1360
   Episode_Reward/pen_joint_torque: -0.1724
    Episode_Reward/pen_joint_accel: -0.0712
    Episode_Reward/pen_action_rate: -0.2615
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0328
   Episode_Reward/pen_joint_powers: -0.0577
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6139
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.2309
   Episode_Reward/foot_landing_vel: -0.0922
   Episode_Reward/test_gait_reward: -0.8662
Metrics/base_velocity/error_vel_xy: 2.0756
Metrics/base_velocity/error_vel_yaw: 0.9502
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 1.08s
                        Total time: 1235.76s
                               ETA: 2020.2s

################################################################################
                     [1m Learning iteration 1139/3000 [0m                     

                       Computation: 91115 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 1.1208
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6169
                     Learning rate: 0.0006
                       Mean reward: 80.38
               Mean episode length: 934.68
       Episode_Reward/keep_balance: 0.9255
     Episode_Reward/rew_lin_vel_xy: 3.5994
      Episode_Reward/rew_ang_vel_z: 2.6470
    Episode_Reward/pen_base_height: -0.3613
      Episode_Reward/pen_lin_vel_z: -0.0638
     Episode_Reward/pen_ang_vel_xy: -0.1414
   Episode_Reward/pen_joint_torque: -0.1806
    Episode_Reward/pen_joint_accel: -0.0774
    Episode_Reward/pen_action_rate: -0.2691
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0361
   Episode_Reward/pen_joint_powers: -0.0613
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6190
Episode_Reward/pen_flat_orientation: -0.1295
  Episode_Reward/pen_feet_distance: -0.0054
Episode_Reward/pen_feet_regulation: -0.2678
   Episode_Reward/foot_landing_vel: -0.1062
   Episode_Reward/test_gait_reward: -0.8669
Metrics/base_velocity/error_vel_xy: 2.1115
Metrics/base_velocity/error_vel_yaw: 0.9467
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 1.08s
                        Total time: 1236.84s
                               ETA: 2019.1s

################################################################################
                     [1m Learning iteration 1140/3000 [0m                     

                       Computation: 93315 steps/s (collection: 0.930s, learning 0.123s)
               Value function loss: 1.0818
                    Surrogate loss: -0.0010
             Mean action noise std: 0.6176
                     Learning rate: 0.0003
                       Mean reward: 85.31
               Mean episode length: 940.54
       Episode_Reward/keep_balance: 0.9501
     Episode_Reward/rew_lin_vel_xy: 3.8625
      Episode_Reward/rew_ang_vel_z: 2.7235
    Episode_Reward/pen_base_height: -0.3713
      Episode_Reward/pen_lin_vel_z: -0.0625
     Episode_Reward/pen_ang_vel_xy: -0.1363
   Episode_Reward/pen_joint_torque: -0.1781
    Episode_Reward/pen_joint_accel: -0.0762
    Episode_Reward/pen_action_rate: -0.2690
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0349
   Episode_Reward/pen_joint_powers: -0.0604
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6258
Episode_Reward/pen_flat_orientation: -0.1276
  Episode_Reward/pen_feet_distance: -0.0052
Episode_Reward/pen_feet_regulation: -0.2503
   Episode_Reward/foot_landing_vel: -0.1017
   Episode_Reward/test_gait_reward: -0.8885
Metrics/base_velocity/error_vel_xy: 2.0488
Metrics/base_velocity/error_vel_yaw: 0.9693
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 1.05s
                        Total time: 1237.89s
                               ETA: 2017.9s

################################################################################
                     [1m Learning iteration 1141/3000 [0m                     

                       Computation: 91381 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 1.1057
                    Surrogate loss: -0.0046
             Mean action noise std: 0.6186
                     Learning rate: 0.0004
                       Mean reward: 85.05
               Mean episode length: 941.83
       Episode_Reward/keep_balance: 0.9460
     Episode_Reward/rew_lin_vel_xy: 3.8735
      Episode_Reward/rew_ang_vel_z: 2.7144
    Episode_Reward/pen_base_height: -0.3495
      Episode_Reward/pen_lin_vel_z: -0.0630
     Episode_Reward/pen_ang_vel_xy: -0.1425
   Episode_Reward/pen_joint_torque: -0.1764
    Episode_Reward/pen_joint_accel: -0.0783
    Episode_Reward/pen_action_rate: -0.2727
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0351
   Episode_Reward/pen_joint_powers: -0.0603
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6306
Episode_Reward/pen_flat_orientation: -0.1223
  Episode_Reward/pen_feet_distance: -0.0043
Episode_Reward/pen_feet_regulation: -0.2470
   Episode_Reward/foot_landing_vel: -0.1036
   Episode_Reward/test_gait_reward: -0.8779
Metrics/base_velocity/error_vel_xy: 2.0554
Metrics/base_velocity/error_vel_yaw: 0.9613
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 1.08s
                        Total time: 1238.97s
                               ETA: 2016.8s

################################################################################
                     [1m Learning iteration 1142/3000 [0m                     

                       Computation: 91823 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.1724
                    Surrogate loss: -0.0037
             Mean action noise std: 0.6188
                     Learning rate: 0.0006
                       Mean reward: 90.20
               Mean episode length: 976.63
       Episode_Reward/keep_balance: 0.9796
     Episode_Reward/rew_lin_vel_xy: 4.2340
      Episode_Reward/rew_ang_vel_z: 2.8010
    Episode_Reward/pen_base_height: -0.3659
      Episode_Reward/pen_lin_vel_z: -0.0654
     Episode_Reward/pen_ang_vel_xy: -0.1450
   Episode_Reward/pen_joint_torque: -0.1925
    Episode_Reward/pen_joint_accel: -0.0820
    Episode_Reward/pen_action_rate: -0.2818
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0374
   Episode_Reward/pen_joint_powers: -0.0649
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6543
Episode_Reward/pen_flat_orientation: -0.1206
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.2728
   Episode_Reward/foot_landing_vel: -0.1067
   Episode_Reward/test_gait_reward: -0.9158
Metrics/base_velocity/error_vel_xy: 2.0297
Metrics/base_velocity/error_vel_yaw: 0.9973
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 1.07s
                        Total time: 1240.04s
                               ETA: 2015.7s

################################################################################
                     [1m Learning iteration 1143/3000 [0m                     

                       Computation: 92767 steps/s (collection: 0.936s, learning 0.123s)
               Value function loss: 1.0909
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6183
                     Learning rate: 0.0004
                       Mean reward: 82.32
               Mean episode length: 909.54
       Episode_Reward/keep_balance: 0.9215
     Episode_Reward/rew_lin_vel_xy: 3.7880
      Episode_Reward/rew_ang_vel_z: 2.5886
    Episode_Reward/pen_base_height: -0.3434
      Episode_Reward/pen_lin_vel_z: -0.0595
     Episode_Reward/pen_ang_vel_xy: -0.1432
   Episode_Reward/pen_joint_torque: -0.1682
    Episode_Reward/pen_joint_accel: -0.0840
    Episode_Reward/pen_action_rate: -0.2655
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0364
   Episode_Reward/pen_joint_powers: -0.0597
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6229
Episode_Reward/pen_flat_orientation: -0.1202
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.2547
   Episode_Reward/foot_landing_vel: -0.1052
   Episode_Reward/test_gait_reward: -0.8588
Metrics/base_velocity/error_vel_xy: 1.9621
Metrics/base_velocity/error_vel_yaw: 0.9803
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 1.06s
                        Total time: 1241.10s
                               ETA: 2014.6s

################################################################################
                     [1m Learning iteration 1144/3000 [0m                     

                       Computation: 90017 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 1.0413
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6179
                     Learning rate: 0.0009
                       Mean reward: 80.49
               Mean episode length: 930.10
       Episode_Reward/keep_balance: 0.9027
     Episode_Reward/rew_lin_vel_xy: 3.4514
      Episode_Reward/rew_ang_vel_z: 2.5916
    Episode_Reward/pen_base_height: -0.3576
      Episode_Reward/pen_lin_vel_z: -0.0606
     Episode_Reward/pen_ang_vel_xy: -0.1363
   Episode_Reward/pen_joint_torque: -0.1728
    Episode_Reward/pen_joint_accel: -0.0723
    Episode_Reward/pen_action_rate: -0.2590
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0338
   Episode_Reward/pen_joint_powers: -0.0583
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.5968
Episode_Reward/pen_flat_orientation: -0.1260
  Episode_Reward/pen_feet_distance: -0.0077
Episode_Reward/pen_feet_regulation: -0.2477
   Episode_Reward/foot_landing_vel: -0.1011
   Episode_Reward/test_gait_reward: -0.8394
Metrics/base_velocity/error_vel_xy: 2.0801
Metrics/base_velocity/error_vel_yaw: 0.9145
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 1.09s
                        Total time: 1242.19s
                               ETA: 2013.5s

################################################################################
                     [1m Learning iteration 1145/3000 [0m                     

                       Computation: 91784 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 1.0755
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6180
                     Learning rate: 0.0006
                       Mean reward: 86.46
               Mean episode length: 955.17
       Episode_Reward/keep_balance: 0.9502
     Episode_Reward/rew_lin_vel_xy: 3.9548
      Episode_Reward/rew_ang_vel_z: 2.7029
    Episode_Reward/pen_base_height: -0.3645
      Episode_Reward/pen_lin_vel_z: -0.0667
     Episode_Reward/pen_ang_vel_xy: -0.1451
   Episode_Reward/pen_joint_torque: -0.1844
    Episode_Reward/pen_joint_accel: -0.0844
    Episode_Reward/pen_action_rate: -0.2775
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0369
   Episode_Reward/pen_joint_powers: -0.0627
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6386
Episode_Reward/pen_flat_orientation: -0.1291
  Episode_Reward/pen_feet_distance: -0.0036
Episode_Reward/pen_feet_regulation: -0.2768
   Episode_Reward/foot_landing_vel: -0.1079
   Episode_Reward/test_gait_reward: -0.8869
Metrics/base_velocity/error_vel_xy: 2.0513
Metrics/base_velocity/error_vel_yaw: 0.9771
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 1.07s
                        Total time: 1243.26s
                               ETA: 2012.4s

################################################################################
                     [1m Learning iteration 1146/3000 [0m                     

                       Computation: 92374 steps/s (collection: 0.940s, learning 0.124s)
               Value function loss: 1.0598
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6187
                     Learning rate: 0.0004
                       Mean reward: 83.49
               Mean episode length: 966.39
       Episode_Reward/keep_balance: 0.9682
     Episode_Reward/rew_lin_vel_xy: 3.6839
      Episode_Reward/rew_ang_vel_z: 2.7693
    Episode_Reward/pen_base_height: -0.3526
      Episode_Reward/pen_lin_vel_z: -0.0616
     Episode_Reward/pen_ang_vel_xy: -0.1415
   Episode_Reward/pen_joint_torque: -0.1805
    Episode_Reward/pen_joint_accel: -0.0860
    Episode_Reward/pen_action_rate: -0.2785
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0360
   Episode_Reward/pen_joint_powers: -0.0611
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6474
Episode_Reward/pen_flat_orientation: -0.1169
  Episode_Reward/pen_feet_distance: -0.0049
Episode_Reward/pen_feet_regulation: -0.2537
   Episode_Reward/foot_landing_vel: -0.1093
   Episode_Reward/test_gait_reward: -0.8941
Metrics/base_velocity/error_vel_xy: 2.2647
Metrics/base_velocity/error_vel_yaw: 0.9866
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 1.06s
                        Total time: 1244.33s
                               ETA: 2011.3s

################################################################################
                     [1m Learning iteration 1147/3000 [0m                     

                       Computation: 92228 steps/s (collection: 0.941s, learning 0.125s)
               Value function loss: 1.1318
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6186
                     Learning rate: 0.0004
                       Mean reward: 87.66
               Mean episode length: 961.29
       Episode_Reward/keep_balance: 0.9458
     Episode_Reward/rew_lin_vel_xy: 3.8892
      Episode_Reward/rew_ang_vel_z: 2.6841
    Episode_Reward/pen_base_height: -0.3673
      Episode_Reward/pen_lin_vel_z: -0.0620
     Episode_Reward/pen_ang_vel_xy: -0.1395
   Episode_Reward/pen_joint_torque: -0.1830
    Episode_Reward/pen_joint_accel: -0.0779
    Episode_Reward/pen_action_rate: -0.2726
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0350
   Episode_Reward/pen_joint_powers: -0.0612
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6280
Episode_Reward/pen_flat_orientation: -0.1284
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.2540
   Episode_Reward/foot_landing_vel: -0.0994
   Episode_Reward/test_gait_reward: -0.8889
Metrics/base_velocity/error_vel_xy: 1.9825
Metrics/base_velocity/error_vel_yaw: 0.9803
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 1.07s
                        Total time: 1245.39s
                               ETA: 2010.2s

################################################################################
                     [1m Learning iteration 1148/3000 [0m                     

                       Computation: 91611 steps/s (collection: 0.947s, learning 0.126s)
               Value function loss: 1.0637
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6195
                     Learning rate: 0.0002
                       Mean reward: 84.28
               Mean episode length: 938.57
       Episode_Reward/keep_balance: 0.9372
     Episode_Reward/rew_lin_vel_xy: 3.5999
      Episode_Reward/rew_ang_vel_z: 2.7068
    Episode_Reward/pen_base_height: -0.3492
      Episode_Reward/pen_lin_vel_z: -0.0596
     Episode_Reward/pen_ang_vel_xy: -0.1374
   Episode_Reward/pen_joint_torque: -0.1753
    Episode_Reward/pen_joint_accel: -0.0820
    Episode_Reward/pen_action_rate: -0.2660
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0347
   Episode_Reward/pen_joint_powers: -0.0594
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6193
Episode_Reward/pen_flat_orientation: -0.1227
  Episode_Reward/pen_feet_distance: -0.0039
Episode_Reward/pen_feet_regulation: -0.2344
   Episode_Reward/foot_landing_vel: -0.1048
   Episode_Reward/test_gait_reward: -0.8569
Metrics/base_velocity/error_vel_xy: 2.2239
Metrics/base_velocity/error_vel_yaw: 0.9383
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 1.07s
                        Total time: 1246.46s
                               ETA: 2009.1s

################################################################################
                     [1m Learning iteration 1149/3000 [0m                     

                       Computation: 92237 steps/s (collection: 0.943s, learning 0.123s)
               Value function loss: 1.1499
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6196
                     Learning rate: 0.0003
                       Mean reward: 83.60
               Mean episode length: 947.95
       Episode_Reward/keep_balance: 0.9496
     Episode_Reward/rew_lin_vel_xy: 3.6340
      Episode_Reward/rew_ang_vel_z: 2.7123
    Episode_Reward/pen_base_height: -0.3530
      Episode_Reward/pen_lin_vel_z: -0.0615
     Episode_Reward/pen_ang_vel_xy: -0.1401
   Episode_Reward/pen_joint_torque: -0.1775
    Episode_Reward/pen_joint_accel: -0.0757
    Episode_Reward/pen_action_rate: -0.2700
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0344
   Episode_Reward/pen_joint_powers: -0.0595
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6336
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0036
Episode_Reward/pen_feet_regulation: -0.2427
   Episode_Reward/foot_landing_vel: -0.0994
   Episode_Reward/test_gait_reward: -0.8797
Metrics/base_velocity/error_vel_xy: 2.2847
Metrics/base_velocity/error_vel_yaw: 0.9654
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 1.07s
                        Total time: 1247.53s
                               ETA: 2008.0s

################################################################################
                     [1m Learning iteration 1150/3000 [0m                     

                       Computation: 93135 steps/s (collection: 0.933s, learning 0.123s)
               Value function loss: 1.1016
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6195
                     Learning rate: 0.0002
                       Mean reward: 83.78
               Mean episode length: 948.31
       Episode_Reward/keep_balance: 0.9674
     Episode_Reward/rew_lin_vel_xy: 3.8405
      Episode_Reward/rew_ang_vel_z: 2.7700
    Episode_Reward/pen_base_height: -0.3626
      Episode_Reward/pen_lin_vel_z: -0.0621
     Episode_Reward/pen_ang_vel_xy: -0.1502
   Episode_Reward/pen_joint_torque: -0.1770
    Episode_Reward/pen_joint_accel: -0.0839
    Episode_Reward/pen_action_rate: -0.2802
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0366
   Episode_Reward/pen_joint_powers: -0.0609
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6480
Episode_Reward/pen_flat_orientation: -0.1291
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2646
   Episode_Reward/foot_landing_vel: -0.1029
   Episode_Reward/test_gait_reward: -0.8943
Metrics/base_velocity/error_vel_xy: 2.1869
Metrics/base_velocity/error_vel_yaw: 0.9813
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 1.06s
                        Total time: 1248.59s
                               ETA: 2006.8s

################################################################################
                     [1m Learning iteration 1151/3000 [0m                     

                       Computation: 91910 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 1.0555
                    Surrogate loss: -0.0037
             Mean action noise std: 0.6208
                     Learning rate: 0.0004
                       Mean reward: 83.44
               Mean episode length: 958.92
       Episode_Reward/keep_balance: 0.9622
     Episode_Reward/rew_lin_vel_xy: 3.8386
      Episode_Reward/rew_ang_vel_z: 2.7040
    Episode_Reward/pen_base_height: -0.3616
      Episode_Reward/pen_lin_vel_z: -0.0657
     Episode_Reward/pen_ang_vel_xy: -0.1497
   Episode_Reward/pen_joint_torque: -0.1805
    Episode_Reward/pen_joint_accel: -0.0824
    Episode_Reward/pen_action_rate: -0.2805
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0373
   Episode_Reward/pen_joint_powers: -0.0626
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6480
Episode_Reward/pen_flat_orientation: -0.1259
  Episode_Reward/pen_feet_distance: -0.0037
Episode_Reward/pen_feet_regulation: -0.2680
   Episode_Reward/foot_landing_vel: -0.1162
   Episode_Reward/test_gait_reward: -0.8972
Metrics/base_velocity/error_vel_xy: 2.1827
Metrics/base_velocity/error_vel_yaw: 1.0182
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 1.07s
                        Total time: 1249.65s
                               ETA: 2005.7s

################################################################################
                     [1m Learning iteration 1152/3000 [0m                     

                       Computation: 92995 steps/s (collection: 0.933s, learning 0.124s)
               Value function loss: 1.0790
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6219
                     Learning rate: 0.0009
                       Mean reward: 85.48
               Mean episode length: 950.16
       Episode_Reward/keep_balance: 0.9517
     Episode_Reward/rew_lin_vel_xy: 3.7475
      Episode_Reward/rew_ang_vel_z: 2.7173
    Episode_Reward/pen_base_height: -0.3773
      Episode_Reward/pen_lin_vel_z: -0.0608
     Episode_Reward/pen_ang_vel_xy: -0.1465
   Episode_Reward/pen_joint_torque: -0.1790
    Episode_Reward/pen_joint_accel: -0.0833
    Episode_Reward/pen_action_rate: -0.2765
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0368
   Episode_Reward/pen_joint_powers: -0.0613
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6401
Episode_Reward/pen_flat_orientation: -0.1323
  Episode_Reward/pen_feet_distance: -0.0049
Episode_Reward/pen_feet_regulation: -0.2551
   Episode_Reward/foot_landing_vel: -0.1073
   Episode_Reward/test_gait_reward: -0.8817
Metrics/base_velocity/error_vel_xy: 2.1318
Metrics/base_velocity/error_vel_yaw: 0.9754
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 1.06s
                        Total time: 1250.71s
                               ETA: 2004.6s

################################################################################
                     [1m Learning iteration 1153/3000 [0m                     

                       Computation: 93729 steps/s (collection: 0.927s, learning 0.122s)
               Value function loss: 1.1837
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6217
                     Learning rate: 0.0006
                       Mean reward: 86.61
               Mean episode length: 975.09
       Episode_Reward/keep_balance: 0.9753
     Episode_Reward/rew_lin_vel_xy: 3.7091
      Episode_Reward/rew_ang_vel_z: 2.8001
    Episode_Reward/pen_base_height: -0.3416
      Episode_Reward/pen_lin_vel_z: -0.0620
     Episode_Reward/pen_ang_vel_xy: -0.1468
   Episode_Reward/pen_joint_torque: -0.1792
    Episode_Reward/pen_joint_accel: -0.0868
    Episode_Reward/pen_action_rate: -0.2785
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0361
   Episode_Reward/pen_joint_powers: -0.0610
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6509
Episode_Reward/pen_flat_orientation: -0.1207
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.2502
   Episode_Reward/foot_landing_vel: -0.1048
   Episode_Reward/test_gait_reward: -0.8930
Metrics/base_velocity/error_vel_xy: 2.3669
Metrics/base_velocity/error_vel_yaw: 0.9829
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 1.05s
                        Total time: 1251.76s
                               ETA: 2003.5s

################################################################################
                     [1m Learning iteration 1154/3000 [0m                     

                       Computation: 92361 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 1.0387
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6222
                     Learning rate: 0.0013
                       Mean reward: 80.66
               Mean episode length: 910.57
       Episode_Reward/keep_balance: 0.9162
     Episode_Reward/rew_lin_vel_xy: 3.7497
      Episode_Reward/rew_ang_vel_z: 2.5817
    Episode_Reward/pen_base_height: -0.3410
      Episode_Reward/pen_lin_vel_z: -0.0576
     Episode_Reward/pen_ang_vel_xy: -0.1390
   Episode_Reward/pen_joint_torque: -0.1685
    Episode_Reward/pen_joint_accel: -0.0787
    Episode_Reward/pen_action_rate: -0.2642
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0350
   Episode_Reward/pen_joint_powers: -0.0576
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6186
Episode_Reward/pen_flat_orientation: -0.1280
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.2433
   Episode_Reward/foot_landing_vel: -0.1011
   Episode_Reward/test_gait_reward: -0.8527
Metrics/base_velocity/error_vel_xy: 1.9659
Metrics/base_velocity/error_vel_yaw: 0.9677
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 1.06s
                        Total time: 1252.83s
                               ETA: 2002.4s

################################################################################
                     [1m Learning iteration 1155/3000 [0m                     

                       Computation: 92582 steps/s (collection: 0.936s, learning 0.126s)
               Value function loss: 1.1375
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6213
                     Learning rate: 0.0009
                       Mean reward: 86.85
               Mean episode length: 949.77
       Episode_Reward/keep_balance: 0.9450
     Episode_Reward/rew_lin_vel_xy: 3.7880
      Episode_Reward/rew_ang_vel_z: 2.6684
    Episode_Reward/pen_base_height: -0.3513
      Episode_Reward/pen_lin_vel_z: -0.0605
     Episode_Reward/pen_ang_vel_xy: -0.1406
   Episode_Reward/pen_joint_torque: -0.1698
    Episode_Reward/pen_joint_accel: -0.0880
    Episode_Reward/pen_action_rate: -0.2731
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0368
   Episode_Reward/pen_joint_powers: -0.0601
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6378
Episode_Reward/pen_flat_orientation: -0.1315
  Episode_Reward/pen_feet_distance: -0.0051
Episode_Reward/pen_feet_regulation: -0.2550
   Episode_Reward/foot_landing_vel: -0.1128
   Episode_Reward/test_gait_reward: -0.8742
Metrics/base_velocity/error_vel_xy: 2.1441
Metrics/base_velocity/error_vel_yaw: 0.9935
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 1.06s
                        Total time: 1253.89s
                               ETA: 2001.2s

################################################################################
                     [1m Learning iteration 1156/3000 [0m                     

                       Computation: 93047 steps/s (collection: 0.933s, learning 0.123s)
               Value function loss: 1.0289
                    Surrogate loss: -0.0035
             Mean action noise std: 0.6215
                     Learning rate: 0.0009
                       Mean reward: 87.89
               Mean episode length: 966.87
       Episode_Reward/keep_balance: 0.9616
     Episode_Reward/rew_lin_vel_xy: 3.9609
      Episode_Reward/rew_ang_vel_z: 2.7179
    Episode_Reward/pen_base_height: -0.3659
      Episode_Reward/pen_lin_vel_z: -0.0636
     Episode_Reward/pen_ang_vel_xy: -0.1440
   Episode_Reward/pen_joint_torque: -0.1829
    Episode_Reward/pen_joint_accel: -0.0883
    Episode_Reward/pen_action_rate: -0.2798
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0371
   Episode_Reward/pen_joint_powers: -0.0622
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6408
Episode_Reward/pen_flat_orientation: -0.1347
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.2691
   Episode_Reward/foot_landing_vel: -0.1091
   Episode_Reward/test_gait_reward: -0.8867
Metrics/base_velocity/error_vel_xy: 2.1161
Metrics/base_velocity/error_vel_yaw: 1.0094
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 1.06s
                        Total time: 1254.94s
                               ETA: 2000.1s

################################################################################
                     [1m Learning iteration 1157/3000 [0m                     

                       Computation: 92374 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 1.1067
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6220
                     Learning rate: 0.0006
                       Mean reward: 86.79
               Mean episode length: 947.68
       Episode_Reward/keep_balance: 0.9551
     Episode_Reward/rew_lin_vel_xy: 3.9662
      Episode_Reward/rew_ang_vel_z: 2.7089
    Episode_Reward/pen_base_height: -0.3569
      Episode_Reward/pen_lin_vel_z: -0.0615
     Episode_Reward/pen_ang_vel_xy: -0.1459
   Episode_Reward/pen_joint_torque: -0.1790
    Episode_Reward/pen_joint_accel: -0.0849
    Episode_Reward/pen_action_rate: -0.2780
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0365
   Episode_Reward/pen_joint_powers: -0.0612
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6437
Episode_Reward/pen_flat_orientation: -0.1277
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.2494
   Episode_Reward/foot_landing_vel: -0.1144
   Episode_Reward/test_gait_reward: -0.8783
Metrics/base_velocity/error_vel_xy: 1.9918
Metrics/base_velocity/error_vel_yaw: 0.9932
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 1.06s
                        Total time: 1256.01s
                               ETA: 1999.0s

################################################################################
                     [1m Learning iteration 1158/3000 [0m                     

                       Computation: 91526 steps/s (collection: 0.950s, learning 0.124s)
               Value function loss: 1.1017
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6224
                     Learning rate: 0.0006
                       Mean reward: 79.14
               Mean episode length: 900.86
       Episode_Reward/keep_balance: 0.9021
     Episode_Reward/rew_lin_vel_xy: 3.6422
      Episode_Reward/rew_ang_vel_z: 2.5561
    Episode_Reward/pen_base_height: -0.3534
      Episode_Reward/pen_lin_vel_z: -0.0596
     Episode_Reward/pen_ang_vel_xy: -0.1431
   Episode_Reward/pen_joint_torque: -0.1744
    Episode_Reward/pen_joint_accel: -0.0774
    Episode_Reward/pen_action_rate: -0.2637
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0362
   Episode_Reward/pen_joint_powers: -0.0602
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6057
Episode_Reward/pen_flat_orientation: -0.1282
  Episode_Reward/pen_feet_distance: -0.0038
Episode_Reward/pen_feet_regulation: -0.2502
   Episode_Reward/foot_landing_vel: -0.1060
   Episode_Reward/test_gait_reward: -0.8382
Metrics/base_velocity/error_vel_xy: 1.9516
Metrics/base_velocity/error_vel_yaw: 0.9394
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 1.07s
                        Total time: 1257.08s
                               ETA: 1997.9s

################################################################################
                     [1m Learning iteration 1159/3000 [0m                     

                       Computation: 90642 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 1.0097
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6230
                     Learning rate: 0.0003
                       Mean reward: 85.49
               Mean episode length: 974.95
       Episode_Reward/keep_balance: 0.9754
     Episode_Reward/rew_lin_vel_xy: 3.7323
      Episode_Reward/rew_ang_vel_z: 2.7505
    Episode_Reward/pen_base_height: -0.3623
      Episode_Reward/pen_lin_vel_z: -0.0612
     Episode_Reward/pen_ang_vel_xy: -0.1475
   Episode_Reward/pen_joint_torque: -0.1869
    Episode_Reward/pen_joint_accel: -0.0782
    Episode_Reward/pen_action_rate: -0.2812
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0368
   Episode_Reward/pen_joint_powers: -0.0629
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6500
Episode_Reward/pen_flat_orientation: -0.1263
  Episode_Reward/pen_feet_distance: -0.0039
Episode_Reward/pen_feet_regulation: -0.2593
   Episode_Reward/foot_landing_vel: -0.1083
   Episode_Reward/test_gait_reward: -0.9010
Metrics/base_velocity/error_vel_xy: 2.2899
Metrics/base_velocity/error_vel_yaw: 1.0211
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 1.08s
                        Total time: 1258.17s
                               ETA: 1996.8s

################################################################################
                     [1m Learning iteration 1160/3000 [0m                     

                       Computation: 91469 steps/s (collection: 0.950s, learning 0.125s)
               Value function loss: 1.0583
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6233
                     Learning rate: 0.0004
                       Mean reward: 83.05
               Mean episode length: 920.89
       Episode_Reward/keep_balance: 0.9262
     Episode_Reward/rew_lin_vel_xy: 3.7755
      Episode_Reward/rew_ang_vel_z: 2.6472
    Episode_Reward/pen_base_height: -0.3459
      Episode_Reward/pen_lin_vel_z: -0.0643
     Episode_Reward/pen_ang_vel_xy: -0.1414
   Episode_Reward/pen_joint_torque: -0.1840
    Episode_Reward/pen_joint_accel: -0.0837
    Episode_Reward/pen_action_rate: -0.2683
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0363
   Episode_Reward/pen_joint_powers: -0.0621
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6146
Episode_Reward/pen_flat_orientation: -0.1334
  Episode_Reward/pen_feet_distance: -0.0025
Episode_Reward/pen_feet_regulation: -0.2654
   Episode_Reward/foot_landing_vel: -0.1065
   Episode_Reward/test_gait_reward: -0.8664
Metrics/base_velocity/error_vel_xy: 2.0891
Metrics/base_velocity/error_vel_yaw: 0.9470
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 1.07s
                        Total time: 1259.24s
                               ETA: 1995.7s

################################################################################
                     [1m Learning iteration 1161/3000 [0m                     

                       Computation: 92047 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 1.1135
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6234
                     Learning rate: 0.0003
                       Mean reward: 85.91
               Mean episode length: 964.84
       Episode_Reward/keep_balance: 0.9583
     Episode_Reward/rew_lin_vel_xy: 3.9165
      Episode_Reward/rew_ang_vel_z: 2.6916
    Episode_Reward/pen_base_height: -0.3575
      Episode_Reward/pen_lin_vel_z: -0.0609
     Episode_Reward/pen_ang_vel_xy: -0.1418
   Episode_Reward/pen_joint_torque: -0.1824
    Episode_Reward/pen_joint_accel: -0.0904
    Episode_Reward/pen_action_rate: -0.2794
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0369
   Episode_Reward/pen_joint_powers: -0.0615
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6445
Episode_Reward/pen_flat_orientation: -0.1336
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.2645
   Episode_Reward/foot_landing_vel: -0.1094
   Episode_Reward/test_gait_reward: -0.8944
Metrics/base_velocity/error_vel_xy: 2.0601
Metrics/base_velocity/error_vel_yaw: 1.0131
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 1.07s
                        Total time: 1260.31s
                               ETA: 1994.6s

################################################################################
                     [1m Learning iteration 1162/3000 [0m                     

                       Computation: 92108 steps/s (collection: 0.943s, learning 0.124s)
               Value function loss: 1.0910
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6239
                     Learning rate: 0.0001
                       Mean reward: 85.72
               Mean episode length: 966.42
       Episode_Reward/keep_balance: 0.9541
     Episode_Reward/rew_lin_vel_xy: 3.8169
      Episode_Reward/rew_ang_vel_z: 2.7215
    Episode_Reward/pen_base_height: -0.3513
      Episode_Reward/pen_lin_vel_z: -0.0633
     Episode_Reward/pen_ang_vel_xy: -0.1457
   Episode_Reward/pen_joint_torque: -0.1862
    Episode_Reward/pen_joint_accel: -0.0861
    Episode_Reward/pen_action_rate: -0.2791
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0372
   Episode_Reward/pen_joint_powers: -0.0630
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6368
Episode_Reward/pen_flat_orientation: -0.1284
  Episode_Reward/pen_feet_distance: -0.0061
Episode_Reward/pen_feet_regulation: -0.2659
   Episode_Reward/foot_landing_vel: -0.1103
   Episode_Reward/test_gait_reward: -0.8850
Metrics/base_velocity/error_vel_xy: 2.1300
Metrics/base_velocity/error_vel_yaw: 0.9756
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 1.07s
                        Total time: 1261.38s
                               ETA: 1993.5s

################################################################################
                     [1m Learning iteration 1163/3000 [0m                     

                       Computation: 92116 steps/s (collection: 0.943s, learning 0.124s)
               Value function loss: 0.9904
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6248
                     Learning rate: 0.0003
                       Mean reward: 81.06
               Mean episode length: 918.96
       Episode_Reward/keep_balance: 0.9421
     Episode_Reward/rew_lin_vel_xy: 3.8182
      Episode_Reward/rew_ang_vel_z: 2.6535
    Episode_Reward/pen_base_height: -0.3597
      Episode_Reward/pen_lin_vel_z: -0.0627
     Episode_Reward/pen_ang_vel_xy: -0.1485
   Episode_Reward/pen_joint_torque: -0.1763
    Episode_Reward/pen_joint_accel: -0.0867
    Episode_Reward/pen_action_rate: -0.2759
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0377
   Episode_Reward/pen_joint_powers: -0.0617
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6340
Episode_Reward/pen_flat_orientation: -0.1329
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2685
   Episode_Reward/foot_landing_vel: -0.1147
   Episode_Reward/test_gait_reward: -0.8792
Metrics/base_velocity/error_vel_xy: 2.0721
Metrics/base_velocity/error_vel_yaw: 0.9971
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 1.07s
                        Total time: 1262.44s
                               ETA: 1992.4s

################################################################################
                     [1m Learning iteration 1164/3000 [0m                     

                       Computation: 92862 steps/s (collection: 0.936s, learning 0.122s)
               Value function loss: 0.9580
                    Surrogate loss: -0.0042
             Mean action noise std: 0.6254
                     Learning rate: 0.0004
                       Mean reward: 85.75
               Mean episode length: 944.46
       Episode_Reward/keep_balance: 0.9500
     Episode_Reward/rew_lin_vel_xy: 3.9180
      Episode_Reward/rew_ang_vel_z: 2.6623
    Episode_Reward/pen_base_height: -0.3484
      Episode_Reward/pen_lin_vel_z: -0.0614
     Episode_Reward/pen_ang_vel_xy: -0.1450
   Episode_Reward/pen_joint_torque: -0.1806
    Episode_Reward/pen_joint_accel: -0.0907
    Episode_Reward/pen_action_rate: -0.2793
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0379
   Episode_Reward/pen_joint_powers: -0.0621
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6424
Episode_Reward/pen_flat_orientation: -0.1264
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.2668
   Episode_Reward/foot_landing_vel: -0.1156
   Episode_Reward/test_gait_reward: -0.8724
Metrics/base_velocity/error_vel_xy: 2.0357
Metrics/base_velocity/error_vel_yaw: 1.0096
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 1.06s
                        Total time: 1263.50s
                               ETA: 1991.2s

################################################################################
                     [1m Learning iteration 1165/3000 [0m                     

                       Computation: 93419 steps/s (collection: 0.930s, learning 0.123s)
               Value function loss: 1.0475
                    Surrogate loss: -0.0012
             Mean action noise std: 0.6256
                     Learning rate: 0.0004
                       Mean reward: 89.57
               Mean episode length: 975.30
       Episode_Reward/keep_balance: 0.9814
     Episode_Reward/rew_lin_vel_xy: 3.9064
      Episode_Reward/rew_ang_vel_z: 2.7865
    Episode_Reward/pen_base_height: -0.3552
      Episode_Reward/pen_lin_vel_z: -0.0608
     Episode_Reward/pen_ang_vel_xy: -0.1430
   Episode_Reward/pen_joint_torque: -0.1785
    Episode_Reward/pen_joint_accel: -0.0785
    Episode_Reward/pen_action_rate: -0.2794
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0366
   Episode_Reward/pen_joint_powers: -0.0618
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6541
Episode_Reward/pen_flat_orientation: -0.1287
  Episode_Reward/pen_feet_distance: -0.0036
Episode_Reward/pen_feet_regulation: -0.2575
   Episode_Reward/foot_landing_vel: -0.1092
   Episode_Reward/test_gait_reward: -0.9023
Metrics/base_velocity/error_vel_xy: 2.1772
Metrics/base_velocity/error_vel_yaw: 1.0128
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 1.05s
                        Total time: 1264.55s
                               ETA: 1990.1s

################################################################################
                     [1m Learning iteration 1166/3000 [0m                     

                       Computation: 91888 steps/s (collection: 0.946s, learning 0.124s)
               Value function loss: 1.0517
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6256
                     Learning rate: 0.0006
                       Mean reward: 87.61
               Mean episode length: 946.02
       Episode_Reward/keep_balance: 0.9525
     Episode_Reward/rew_lin_vel_xy: 4.0746
      Episode_Reward/rew_ang_vel_z: 2.6857
    Episode_Reward/pen_base_height: -0.3406
      Episode_Reward/pen_lin_vel_z: -0.0613
     Episode_Reward/pen_ang_vel_xy: -0.1461
   Episode_Reward/pen_joint_torque: -0.1805
    Episode_Reward/pen_joint_accel: -0.0884
    Episode_Reward/pen_action_rate: -0.2792
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0380
   Episode_Reward/pen_joint_powers: -0.0621
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6480
Episode_Reward/pen_flat_orientation: -0.1284
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2606
   Episode_Reward/foot_landing_vel: -0.1131
   Episode_Reward/test_gait_reward: -0.8819
Metrics/base_velocity/error_vel_xy: 2.0091
Metrics/base_velocity/error_vel_yaw: 1.0048
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 1.07s
                        Total time: 1265.62s
                               ETA: 1989.0s

################################################################################
                     [1m Learning iteration 1167/3000 [0m                     

                       Computation: 92324 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 1.0051
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6261
                     Learning rate: 0.0002
                       Mean reward: 91.37
               Mean episode length: 984.45
       Episode_Reward/keep_balance: 0.9621
     Episode_Reward/rew_lin_vel_xy: 4.1191
      Episode_Reward/rew_ang_vel_z: 2.7298
    Episode_Reward/pen_base_height: -0.3628
      Episode_Reward/pen_lin_vel_z: -0.0620
     Episode_Reward/pen_ang_vel_xy: -0.1426
   Episode_Reward/pen_joint_torque: -0.1814
    Episode_Reward/pen_joint_accel: -0.0836
    Episode_Reward/pen_action_rate: -0.2779
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0370
   Episode_Reward/pen_joint_powers: -0.0617
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6399
Episode_Reward/pen_flat_orientation: -0.1328
  Episode_Reward/pen_feet_distance: -0.0037
Episode_Reward/pen_feet_regulation: -0.2740
   Episode_Reward/foot_landing_vel: -0.1102
   Episode_Reward/test_gait_reward: -0.8934
Metrics/base_velocity/error_vel_xy: 1.9334
Metrics/base_velocity/error_vel_yaw: 0.9949
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 1.06s
                        Total time: 1266.69s
                               ETA: 1987.9s

################################################################################
                     [1m Learning iteration 1168/3000 [0m                     

                       Computation: 91315 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.9409
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6261
                     Learning rate: 0.0002
                       Mean reward: 87.94
               Mean episode length: 963.25
       Episode_Reward/keep_balance: 0.9688
     Episode_Reward/rew_lin_vel_xy: 4.0272
      Episode_Reward/rew_ang_vel_z: 2.7447
    Episode_Reward/pen_base_height: -0.3502
      Episode_Reward/pen_lin_vel_z: -0.0620
     Episode_Reward/pen_ang_vel_xy: -0.1484
   Episode_Reward/pen_joint_torque: -0.1788
    Episode_Reward/pen_joint_accel: -0.0835
    Episode_Reward/pen_action_rate: -0.2797
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0368
   Episode_Reward/pen_joint_powers: -0.0612
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6500
Episode_Reward/pen_flat_orientation: -0.1244
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.2592
   Episode_Reward/foot_landing_vel: -0.1114
   Episode_Reward/test_gait_reward: -0.8917
Metrics/base_velocity/error_vel_xy: 2.0799
Metrics/base_velocity/error_vel_yaw: 1.0013
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 1.08s
                        Total time: 1267.77s
                               ETA: 1986.8s

################################################################################
                     [1m Learning iteration 1169/3000 [0m                     

                       Computation: 88598 steps/s (collection: 0.983s, learning 0.126s)
               Value function loss: 1.0365
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6260
                     Learning rate: 0.0003
                       Mean reward: 87.52
               Mean episode length: 973.41
       Episode_Reward/keep_balance: 0.9751
     Episode_Reward/rew_lin_vel_xy: 4.0635
      Episode_Reward/rew_ang_vel_z: 2.7443
    Episode_Reward/pen_base_height: -0.3703
      Episode_Reward/pen_lin_vel_z: -0.0660
     Episode_Reward/pen_ang_vel_xy: -0.1477
   Episode_Reward/pen_joint_torque: -0.1891
    Episode_Reward/pen_joint_accel: -0.0867
    Episode_Reward/pen_action_rate: -0.2864
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0387
   Episode_Reward/pen_joint_powers: -0.0649
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6537
Episode_Reward/pen_flat_orientation: -0.1350
  Episode_Reward/pen_feet_distance: -0.0037
Episode_Reward/pen_feet_regulation: -0.2929
   Episode_Reward/foot_landing_vel: -0.1138
   Episode_Reward/test_gait_reward: -0.9120
Metrics/base_velocity/error_vel_xy: 2.1123
Metrics/base_velocity/error_vel_yaw: 1.0302
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 1.11s
                        Total time: 1268.87s
                               ETA: 1985.7s

################################################################################
                     [1m Learning iteration 1170/3000 [0m                     

                       Computation: 90733 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 1.0920
                    Surrogate loss: -0.0038
             Mean action noise std: 0.6265
                     Learning rate: 0.0006
                       Mean reward: 87.26
               Mean episode length: 949.60
       Episode_Reward/keep_balance: 0.9533
     Episode_Reward/rew_lin_vel_xy: 3.9488
      Episode_Reward/rew_ang_vel_z: 2.6934
    Episode_Reward/pen_base_height: -0.3533
      Episode_Reward/pen_lin_vel_z: -0.0654
     Episode_Reward/pen_ang_vel_xy: -0.1498
   Episode_Reward/pen_joint_torque: -0.1887
    Episode_Reward/pen_joint_accel: -0.0900
    Episode_Reward/pen_action_rate: -0.2812
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0386
   Episode_Reward/pen_joint_powers: -0.0648
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6415
Episode_Reward/pen_flat_orientation: -0.1255
  Episode_Reward/pen_feet_distance: -0.0035
Episode_Reward/pen_feet_regulation: -0.2794
   Episode_Reward/foot_landing_vel: -0.1113
   Episode_Reward/test_gait_reward: -0.8873
Metrics/base_velocity/error_vel_xy: 2.1250
Metrics/base_velocity/error_vel_yaw: 0.9936
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 1.08s
                        Total time: 1269.96s
                               ETA: 1984.6s

################################################################################
                     [1m Learning iteration 1171/3000 [0m                     

                       Computation: 92435 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 1.1421
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6272
                     Learning rate: 0.0006
                       Mean reward: 86.03
               Mean episode length: 940.02
       Episode_Reward/keep_balance: 0.9545
     Episode_Reward/rew_lin_vel_xy: 3.8951
      Episode_Reward/rew_ang_vel_z: 2.7219
    Episode_Reward/pen_base_height: -0.3502
      Episode_Reward/pen_lin_vel_z: -0.0633
     Episode_Reward/pen_ang_vel_xy: -0.1460
   Episode_Reward/pen_joint_torque: -0.1790
    Episode_Reward/pen_joint_accel: -0.0884
    Episode_Reward/pen_action_rate: -0.2772
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0368
   Episode_Reward/pen_joint_powers: -0.0609
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6387
Episode_Reward/pen_flat_orientation: -0.1287
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.2596
   Episode_Reward/foot_landing_vel: -0.1154
   Episode_Reward/test_gait_reward: -0.8759
Metrics/base_velocity/error_vel_xy: 2.1249
Metrics/base_velocity/error_vel_yaw: 0.9793
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 1.06s
                        Total time: 1271.02s
                               ETA: 1983.5s

################################################################################
                     [1m Learning iteration 1172/3000 [0m                     

                       Computation: 92188 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 1.0655
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6267
                     Learning rate: 0.0009
                       Mean reward: 85.17
               Mean episode length: 940.06
       Episode_Reward/keep_balance: 0.9464
     Episode_Reward/rew_lin_vel_xy: 3.7214
      Episode_Reward/rew_ang_vel_z: 2.6819
    Episode_Reward/pen_base_height: -0.3428
      Episode_Reward/pen_lin_vel_z: -0.0602
     Episode_Reward/pen_ang_vel_xy: -0.1394
   Episode_Reward/pen_joint_torque: -0.1785
    Episode_Reward/pen_joint_accel: -0.0859
    Episode_Reward/pen_action_rate: -0.2739
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0361
   Episode_Reward/pen_joint_powers: -0.0604
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6322
Episode_Reward/pen_flat_orientation: -0.1195
  Episode_Reward/pen_feet_distance: -0.0047
Episode_Reward/pen_feet_regulation: -0.2553
   Episode_Reward/foot_landing_vel: -0.1078
   Episode_Reward/test_gait_reward: -0.8794
Metrics/base_velocity/error_vel_xy: 2.2005
Metrics/base_velocity/error_vel_yaw: 0.9813
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 1.07s
                        Total time: 1272.09s
                               ETA: 1982.4s

################################################################################
                     [1m Learning iteration 1173/3000 [0m                     

                       Computation: 91516 steps/s (collection: 0.951s, learning 0.124s)
               Value function loss: 1.1408
                    Surrogate loss: -0.0036
             Mean action noise std: 0.6255
                     Learning rate: 0.0013
                       Mean reward: 87.14
               Mean episode length: 956.77
       Episode_Reward/keep_balance: 0.9616
     Episode_Reward/rew_lin_vel_xy: 4.0797
      Episode_Reward/rew_ang_vel_z: 2.7041
    Episode_Reward/pen_base_height: -0.3425
      Episode_Reward/pen_lin_vel_z: -0.0628
     Episode_Reward/pen_ang_vel_xy: -0.1451
   Episode_Reward/pen_joint_torque: -0.1828
    Episode_Reward/pen_joint_accel: -0.0883
    Episode_Reward/pen_action_rate: -0.2815
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0374
   Episode_Reward/pen_joint_powers: -0.0622
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6521
Episode_Reward/pen_flat_orientation: -0.1261
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.2632
   Episode_Reward/foot_landing_vel: -0.1179
   Episode_Reward/test_gait_reward: -0.8850
Metrics/base_velocity/error_vel_xy: 2.0688
Metrics/base_velocity/error_vel_yaw: 1.0150
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 1.07s
                        Total time: 1273.16s
                               ETA: 1981.3s

################################################################################
                     [1m Learning iteration 1174/3000 [0m                     

                       Computation: 91445 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 1.1491
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6254
                     Learning rate: 0.0006
                       Mean reward: 86.89
               Mean episode length: 929.07
       Episode_Reward/keep_balance: 0.9482
     Episode_Reward/rew_lin_vel_xy: 3.9376
      Episode_Reward/rew_ang_vel_z: 2.7162
    Episode_Reward/pen_base_height: -0.3262
      Episode_Reward/pen_lin_vel_z: -0.0593
     Episode_Reward/pen_ang_vel_xy: -0.1428
   Episode_Reward/pen_joint_torque: -0.1820
    Episode_Reward/pen_joint_accel: -0.0824
    Episode_Reward/pen_action_rate: -0.2743
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0359
   Episode_Reward/pen_joint_powers: -0.0610
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6338
Episode_Reward/pen_flat_orientation: -0.1183
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.2481
   Episode_Reward/foot_landing_vel: -0.1039
   Episode_Reward/test_gait_reward: -0.8741
Metrics/base_velocity/error_vel_xy: 1.9494
Metrics/base_velocity/error_vel_yaw: 0.9599
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 1.07s
                        Total time: 1274.24s
                               ETA: 1980.2s

################################################################################
                     [1m Learning iteration 1175/3000 [0m                     

                       Computation: 91921 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 1.0808
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6260
                     Learning rate: 0.0002
                       Mean reward: 88.54
               Mean episode length: 952.18
       Episode_Reward/keep_balance: 0.9427
     Episode_Reward/rew_lin_vel_xy: 3.9543
      Episode_Reward/rew_ang_vel_z: 2.6854
    Episode_Reward/pen_base_height: -0.3391
      Episode_Reward/pen_lin_vel_z: -0.0628
     Episode_Reward/pen_ang_vel_xy: -0.1465
   Episode_Reward/pen_joint_torque: -0.1817
    Episode_Reward/pen_joint_accel: -0.0852
    Episode_Reward/pen_action_rate: -0.2771
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0373
   Episode_Reward/pen_joint_powers: -0.0621
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6325
Episode_Reward/pen_flat_orientation: -0.1265
  Episode_Reward/pen_feet_distance: -0.0046
Episode_Reward/pen_feet_regulation: -0.2794
   Episode_Reward/foot_landing_vel: -0.1101
   Episode_Reward/test_gait_reward: -0.8707
Metrics/base_velocity/error_vel_xy: 2.0115
Metrics/base_velocity/error_vel_yaw: 0.9676
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 1.07s
                        Total time: 1275.31s
                               ETA: 1979.1s

################################################################################
                     [1m Learning iteration 1176/3000 [0m                     

                       Computation: 89870 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 1.0933
                    Surrogate loss: -0.0045
             Mean action noise std: 0.6252
                     Learning rate: 0.0004
                       Mean reward: 82.12
               Mean episode length: 913.40
       Episode_Reward/keep_balance: 0.9259
     Episode_Reward/rew_lin_vel_xy: 3.8505
      Episode_Reward/rew_ang_vel_z: 2.6125
    Episode_Reward/pen_base_height: -0.3497
      Episode_Reward/pen_lin_vel_z: -0.0604
     Episode_Reward/pen_ang_vel_xy: -0.1431
   Episode_Reward/pen_joint_torque: -0.1752
    Episode_Reward/pen_joint_accel: -0.0790
    Episode_Reward/pen_action_rate: -0.2721
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0363
   Episode_Reward/pen_joint_powers: -0.0605
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6259
Episode_Reward/pen_flat_orientation: -0.1312
  Episode_Reward/pen_feet_distance: -0.0065
Episode_Reward/pen_feet_regulation: -0.2684
   Episode_Reward/foot_landing_vel: -0.1032
   Episode_Reward/test_gait_reward: -0.8547
Metrics/base_velocity/error_vel_xy: 2.0149
Metrics/base_velocity/error_vel_yaw: 0.9732
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 1.09s
                        Total time: 1276.40s
                               ETA: 1978.0s

################################################################################
                     [1m Learning iteration 1177/3000 [0m                     

                       Computation: 92485 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 0.9770
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6248
                     Learning rate: 0.0003
                       Mean reward: 87.08
               Mean episode length: 957.61
       Episode_Reward/keep_balance: 0.9605
     Episode_Reward/rew_lin_vel_xy: 3.9034
      Episode_Reward/rew_ang_vel_z: 2.7479
    Episode_Reward/pen_base_height: -0.3378
      Episode_Reward/pen_lin_vel_z: -0.0585
     Episode_Reward/pen_ang_vel_xy: -0.1433
   Episode_Reward/pen_joint_torque: -0.1805
    Episode_Reward/pen_joint_accel: -0.0859
    Episode_Reward/pen_action_rate: -0.2765
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0364
   Episode_Reward/pen_joint_powers: -0.0607
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6419
Episode_Reward/pen_flat_orientation: -0.1294
  Episode_Reward/pen_feet_distance: -0.0028
Episode_Reward/pen_feet_regulation: -0.2478
   Episode_Reward/foot_landing_vel: -0.1033
   Episode_Reward/test_gait_reward: -0.8830
Metrics/base_velocity/error_vel_xy: 2.1147
Metrics/base_velocity/error_vel_yaw: 0.9811
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 1.06s
                        Total time: 1277.46s
                               ETA: 1976.9s

################################################################################
                     [1m Learning iteration 1178/3000 [0m                     

                       Computation: 90885 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 1.0582
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6244
                     Learning rate: 0.0003
                       Mean reward: 83.36
               Mean episode length: 949.17
       Episode_Reward/keep_balance: 0.9564
     Episode_Reward/rew_lin_vel_xy: 3.8549
      Episode_Reward/rew_ang_vel_z: 2.7016
    Episode_Reward/pen_base_height: -0.3659
      Episode_Reward/pen_lin_vel_z: -0.0655
     Episode_Reward/pen_ang_vel_xy: -0.1461
   Episode_Reward/pen_joint_torque: -0.1857
    Episode_Reward/pen_joint_accel: -0.0883
    Episode_Reward/pen_action_rate: -0.2812
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0387
   Episode_Reward/pen_joint_powers: -0.0637
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6430
Episode_Reward/pen_flat_orientation: -0.1411
  Episode_Reward/pen_feet_distance: -0.0088
Episode_Reward/pen_feet_regulation: -0.2795
   Episode_Reward/foot_landing_vel: -0.1186
   Episode_Reward/test_gait_reward: -0.8857
Metrics/base_velocity/error_vel_xy: 2.1175
Metrics/base_velocity/error_vel_yaw: 0.9983
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 1.08s
                        Total time: 1278.54s
                               ETA: 1975.8s

################################################################################
                     [1m Learning iteration 1179/3000 [0m                     

                       Computation: 91640 steps/s (collection: 0.949s, learning 0.124s)
               Value function loss: 1.1120
                    Surrogate loss: -0.0042
             Mean action noise std: 0.6234
                     Learning rate: 0.0006
                       Mean reward: 90.27
               Mean episode length: 972.38
       Episode_Reward/keep_balance: 0.9761
     Episode_Reward/rew_lin_vel_xy: 4.1520
      Episode_Reward/rew_ang_vel_z: 2.7519
    Episode_Reward/pen_base_height: -0.3467
      Episode_Reward/pen_lin_vel_z: -0.0653
     Episode_Reward/pen_ang_vel_xy: -0.1530
   Episode_Reward/pen_joint_torque: -0.1848
    Episode_Reward/pen_joint_accel: -0.0882
    Episode_Reward/pen_action_rate: -0.2880
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0392
   Episode_Reward/pen_joint_powers: -0.0645
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6611
Episode_Reward/pen_flat_orientation: -0.1328
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.2928
   Episode_Reward/foot_landing_vel: -0.1185
   Episode_Reward/test_gait_reward: -0.9033
Metrics/base_velocity/error_vel_xy: 2.0791
Metrics/base_velocity/error_vel_yaw: 1.0269
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 1.07s
                        Total time: 1279.62s
                               ETA: 1974.7s

################################################################################
                     [1m Learning iteration 1180/3000 [0m                     

                       Computation: 92111 steps/s (collection: 0.943s, learning 0.124s)
               Value function loss: 1.1068
                    Surrogate loss: -0.0039
             Mean action noise std: 0.6234
                     Learning rate: 0.0009
                       Mean reward: 86.29
               Mean episode length: 951.81
       Episode_Reward/keep_balance: 0.9702
     Episode_Reward/rew_lin_vel_xy: 3.9944
      Episode_Reward/rew_ang_vel_z: 2.7417
    Episode_Reward/pen_base_height: -0.3471
      Episode_Reward/pen_lin_vel_z: -0.0642
     Episode_Reward/pen_ang_vel_xy: -0.1485
   Episode_Reward/pen_joint_torque: -0.1826
    Episode_Reward/pen_joint_accel: -0.0839
    Episode_Reward/pen_action_rate: -0.2826
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0379
   Episode_Reward/pen_joint_powers: -0.0627
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6555
Episode_Reward/pen_flat_orientation: -0.1340
  Episode_Reward/pen_feet_distance: -0.0039
Episode_Reward/pen_feet_regulation: -0.2711
   Episode_Reward/foot_landing_vel: -0.1105
   Episode_Reward/test_gait_reward: -0.8927
Metrics/base_velocity/error_vel_xy: 2.1102
Metrics/base_velocity/error_vel_yaw: 1.0159
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 1.07s
                        Total time: 1280.68s
                               ETA: 1973.6s

################################################################################
                     [1m Learning iteration 1181/3000 [0m                     

                       Computation: 92336 steps/s (collection: 0.940s, learning 0.125s)
               Value function loss: 1.1117
                    Surrogate loss: -0.0010
             Mean action noise std: 0.6245
                     Learning rate: 0.0006
                       Mean reward: 84.01
               Mean episode length: 928.60
       Episode_Reward/keep_balance: 0.9343
     Episode_Reward/rew_lin_vel_xy: 3.8330
      Episode_Reward/rew_ang_vel_z: 2.6435
    Episode_Reward/pen_base_height: -0.3364
      Episode_Reward/pen_lin_vel_z: -0.0587
     Episode_Reward/pen_ang_vel_xy: -0.1408
   Episode_Reward/pen_joint_torque: -0.1772
    Episode_Reward/pen_joint_accel: -0.0825
    Episode_Reward/pen_action_rate: -0.2746
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0366
   Episode_Reward/pen_joint_powers: -0.0607
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6326
Episode_Reward/pen_flat_orientation: -0.1302
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.2576
   Episode_Reward/foot_landing_vel: -0.1116
   Episode_Reward/test_gait_reward: -0.8613
Metrics/base_velocity/error_vel_xy: 2.0495
Metrics/base_velocity/error_vel_yaw: 0.9787
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 1.06s
                        Total time: 1281.75s
                               ETA: 1972.5s

################################################################################
                     [1m Learning iteration 1182/3000 [0m                     

                       Computation: 91582 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 1.0296
                    Surrogate loss: -0.0034
             Mean action noise std: 0.6247
                     Learning rate: 0.0009
                       Mean reward: 86.09
               Mean episode length: 931.15
       Episode_Reward/keep_balance: 0.9463
     Episode_Reward/rew_lin_vel_xy: 3.9292
      Episode_Reward/rew_ang_vel_z: 2.7095
    Episode_Reward/pen_base_height: -0.3373
      Episode_Reward/pen_lin_vel_z: -0.0618
     Episode_Reward/pen_ang_vel_xy: -0.1430
   Episode_Reward/pen_joint_torque: -0.1771
    Episode_Reward/pen_joint_accel: -0.0812
    Episode_Reward/pen_action_rate: -0.2766
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0362
   Episode_Reward/pen_joint_powers: -0.0606
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6334
Episode_Reward/pen_flat_orientation: -0.1283
  Episode_Reward/pen_feet_distance: -0.0043
Episode_Reward/pen_feet_regulation: -0.2659
   Episode_Reward/foot_landing_vel: -0.1079
   Episode_Reward/test_gait_reward: -0.8731
Metrics/base_velocity/error_vel_xy: 2.0880
Metrics/base_velocity/error_vel_yaw: 0.9578
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 1.07s
                        Total time: 1282.82s
                               ETA: 1971.4s

################################################################################
                     [1m Learning iteration 1183/3000 [0m                     

                       Computation: 92025 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 1.1184
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6258
                     Learning rate: 0.0006
                       Mean reward: 88.58
               Mean episode length: 948.54
       Episode_Reward/keep_balance: 0.9447
     Episode_Reward/rew_lin_vel_xy: 4.0244
      Episode_Reward/rew_ang_vel_z: 2.6552
    Episode_Reward/pen_base_height: -0.3366
      Episode_Reward/pen_lin_vel_z: -0.0615
     Episode_Reward/pen_ang_vel_xy: -0.1460
   Episode_Reward/pen_joint_torque: -0.1787
    Episode_Reward/pen_joint_accel: -0.0830
    Episode_Reward/pen_action_rate: -0.2784
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0371
   Episode_Reward/pen_joint_powers: -0.0614
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6432
Episode_Reward/pen_flat_orientation: -0.1266
  Episode_Reward/pen_feet_distance: -0.0046
Episode_Reward/pen_feet_regulation: -0.2582
   Episode_Reward/foot_landing_vel: -0.1080
   Episode_Reward/test_gait_reward: -0.8671
Metrics/base_velocity/error_vel_xy: 1.9886
Metrics/base_velocity/error_vel_yaw: 0.9997
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 1.07s
                        Total time: 1283.89s
                               ETA: 1970.3s

################################################################################
                     [1m Learning iteration 1184/3000 [0m                     

                       Computation: 91073 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 1.0488
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6256
                     Learning rate: 0.0004
                       Mean reward: 84.09
               Mean episode length: 916.36
       Episode_Reward/keep_balance: 0.9128
     Episode_Reward/rew_lin_vel_xy: 3.7823
      Episode_Reward/rew_ang_vel_z: 2.5701
    Episode_Reward/pen_base_height: -0.3269
      Episode_Reward/pen_lin_vel_z: -0.0555
     Episode_Reward/pen_ang_vel_xy: -0.1394
   Episode_Reward/pen_joint_torque: -0.1707
    Episode_Reward/pen_joint_accel: -0.0798
    Episode_Reward/pen_action_rate: -0.2655
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0355
   Episode_Reward/pen_joint_powers: -0.0584
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.6154
Episode_Reward/pen_flat_orientation: -0.1319
  Episode_Reward/pen_feet_distance: -0.0052
Episode_Reward/pen_feet_regulation: -0.2480
   Episode_Reward/foot_landing_vel: -0.1061
   Episode_Reward/test_gait_reward: -0.8313
Metrics/base_velocity/error_vel_xy: 1.9177
Metrics/base_velocity/error_vel_yaw: 0.9702
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 1.08s
                        Total time: 1284.97s
                               ETA: 1969.2s

################################################################################
                     [1m Learning iteration 1185/3000 [0m                     

                       Computation: 91080 steps/s (collection: 0.954s, learning 0.125s)
               Value function loss: 1.0344
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6249
                     Learning rate: 0.0004
                       Mean reward: 87.01
               Mean episode length: 961.78
       Episode_Reward/keep_balance: 0.9758
     Episode_Reward/rew_lin_vel_xy: 4.1578
      Episode_Reward/rew_ang_vel_z: 2.7445
    Episode_Reward/pen_base_height: -0.3377
      Episode_Reward/pen_lin_vel_z: -0.0619
     Episode_Reward/pen_ang_vel_xy: -0.1513
   Episode_Reward/pen_joint_torque: -0.1853
    Episode_Reward/pen_joint_accel: -0.0894
    Episode_Reward/pen_action_rate: -0.2872
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0385
   Episode_Reward/pen_joint_powers: -0.0633
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6633
Episode_Reward/pen_flat_orientation: -0.1366
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.2730
   Episode_Reward/foot_landing_vel: -0.1170
   Episode_Reward/test_gait_reward: -0.8957
Metrics/base_velocity/error_vel_xy: 2.0560
Metrics/base_velocity/error_vel_yaw: 1.0313
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 1.08s
                        Total time: 1286.05s
                               ETA: 1968.1s

################################################################################
                     [1m Learning iteration 1186/3000 [0m                     

                       Computation: 89834 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 1.1290
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6249
                     Learning rate: 0.0006
                       Mean reward: 90.61
               Mean episode length: 974.27
       Episode_Reward/keep_balance: 0.9724
     Episode_Reward/rew_lin_vel_xy: 3.9995
      Episode_Reward/rew_ang_vel_z: 2.7806
    Episode_Reward/pen_base_height: -0.3371
      Episode_Reward/pen_lin_vel_z: -0.0638
     Episode_Reward/pen_ang_vel_xy: -0.1483
   Episode_Reward/pen_joint_torque: -0.1861
    Episode_Reward/pen_joint_accel: -0.0816
    Episode_Reward/pen_action_rate: -0.2849
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0378
   Episode_Reward/pen_joint_powers: -0.0632
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6546
Episode_Reward/pen_flat_orientation: -0.1305
  Episode_Reward/pen_feet_distance: -0.0039
Episode_Reward/pen_feet_regulation: -0.2773
   Episode_Reward/foot_landing_vel: -0.1159
   Episode_Reward/test_gait_reward: -0.8935
Metrics/base_velocity/error_vel_xy: 2.1095
Metrics/base_velocity/error_vel_yaw: 0.9880
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 1.09s
                        Total time: 1287.14s
                               ETA: 1967.0s

################################################################################
                     [1m Learning iteration 1187/3000 [0m                     

                       Computation: 89640 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.9755
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6248
                     Learning rate: 0.0009
                       Mean reward: 83.09
               Mean episode length: 957.25
       Episode_Reward/keep_balance: 0.9688
     Episode_Reward/rew_lin_vel_xy: 3.7357
      Episode_Reward/rew_ang_vel_z: 2.7166
    Episode_Reward/pen_base_height: -0.3297
      Episode_Reward/pen_lin_vel_z: -0.0592
     Episode_Reward/pen_ang_vel_xy: -0.1420
   Episode_Reward/pen_joint_torque: -0.1794
    Episode_Reward/pen_joint_accel: -0.0888
    Episode_Reward/pen_action_rate: -0.2811
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0367
   Episode_Reward/pen_joint_powers: -0.0604
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6564
Episode_Reward/pen_flat_orientation: -0.1237
  Episode_Reward/pen_feet_distance: -0.0043
Episode_Reward/pen_feet_regulation: -0.2550
   Episode_Reward/foot_landing_vel: -0.1086
   Episode_Reward/test_gait_reward: -0.8804
Metrics/base_velocity/error_vel_xy: 2.2054
Metrics/base_velocity/error_vel_yaw: 1.0252
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 1.10s
                        Total time: 1288.24s
                               ETA: 1966.0s

################################################################################
                     [1m Learning iteration 1188/3000 [0m                     

                       Computation: 91564 steps/s (collection: 0.949s, learning 0.124s)
               Value function loss: 1.0272
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6258
                     Learning rate: 0.0009
                       Mean reward: 85.27
               Mean episode length: 960.50
       Episode_Reward/keep_balance: 0.9711
     Episode_Reward/rew_lin_vel_xy: 3.7419
      Episode_Reward/rew_ang_vel_z: 2.7821
    Episode_Reward/pen_base_height: -0.3298
      Episode_Reward/pen_lin_vel_z: -0.0614
     Episode_Reward/pen_ang_vel_xy: -0.1491
   Episode_Reward/pen_joint_torque: -0.1797
    Episode_Reward/pen_joint_accel: -0.0861
    Episode_Reward/pen_action_rate: -0.2845
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0371
   Episode_Reward/pen_joint_powers: -0.0610
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6555
Episode_Reward/pen_flat_orientation: -0.1256
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.2615
   Episode_Reward/foot_landing_vel: -0.1177
   Episode_Reward/test_gait_reward: -0.8783
Metrics/base_velocity/error_vel_xy: 2.4253
Metrics/base_velocity/error_vel_yaw: 0.9838
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 1.07s
                        Total time: 1289.31s
                               ETA: 1964.9s

################################################################################
                     [1m Learning iteration 1189/3000 [0m                     

                       Computation: 88524 steps/s (collection: 0.986s, learning 0.125s)
               Value function loss: 1.0728
                    Surrogate loss: -0.0038
             Mean action noise std: 0.6260
                     Learning rate: 0.0013
                       Mean reward: 89.20
               Mean episode length: 964.18
       Episode_Reward/keep_balance: 0.9663
     Episode_Reward/rew_lin_vel_xy: 3.9337
      Episode_Reward/rew_ang_vel_z: 2.7638
    Episode_Reward/pen_base_height: -0.3398
      Episode_Reward/pen_lin_vel_z: -0.0616
     Episode_Reward/pen_ang_vel_xy: -0.1454
   Episode_Reward/pen_joint_torque: -0.1894
    Episode_Reward/pen_joint_accel: -0.0875
    Episode_Reward/pen_action_rate: -0.2837
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0374
   Episode_Reward/pen_joint_powers: -0.0633
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6476
Episode_Reward/pen_flat_orientation: -0.1303
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.2716
   Episode_Reward/foot_landing_vel: -0.1108
   Episode_Reward/test_gait_reward: -0.8805
Metrics/base_velocity/error_vel_xy: 2.1493
Metrics/base_velocity/error_vel_yaw: 0.9840
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 1.11s
                        Total time: 1290.42s
                               ETA: 1963.8s

################################################################################
                     [1m Learning iteration 1190/3000 [0m                     

                       Computation: 90232 steps/s (collection: 0.965s, learning 0.125s)
               Value function loss: 1.1035
                    Surrogate loss: 0.0064
             Mean action noise std: 0.6261
                     Learning rate: 0.0001
                       Mean reward: 88.00
               Mean episode length: 956.09
       Episode_Reward/keep_balance: 0.9646
     Episode_Reward/rew_lin_vel_xy: 3.9681
      Episode_Reward/rew_ang_vel_z: 2.7107
    Episode_Reward/pen_base_height: -0.3458
      Episode_Reward/pen_lin_vel_z: -0.0626
     Episode_Reward/pen_ang_vel_xy: -0.1515
   Episode_Reward/pen_joint_torque: -0.1814
    Episode_Reward/pen_joint_accel: -0.0919
    Episode_Reward/pen_action_rate: -0.2845
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0394
   Episode_Reward/pen_joint_powers: -0.0635
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6583
Episode_Reward/pen_flat_orientation: -0.1245
  Episode_Reward/pen_feet_distance: -0.0028
Episode_Reward/pen_feet_regulation: -0.2786
   Episode_Reward/foot_landing_vel: -0.1187
   Episode_Reward/test_gait_reward: -0.8925
Metrics/base_velocity/error_vel_xy: 2.0812
Metrics/base_velocity/error_vel_yaw: 1.0124
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 1.09s
                        Total time: 1291.51s
                               ETA: 1962.8s

################################################################################
                     [1m Learning iteration 1191/3000 [0m                     

                       Computation: 90172 steps/s (collection: 0.966s, learning 0.125s)
               Value function loss: 1.0933
                    Surrogate loss: -0.0038
             Mean action noise std: 0.6263
                     Learning rate: 0.0003
                       Mean reward: 83.94
               Mean episode length: 955.47
       Episode_Reward/keep_balance: 0.9616
     Episode_Reward/rew_lin_vel_xy: 3.8050
      Episode_Reward/rew_ang_vel_z: 2.7362
    Episode_Reward/pen_base_height: -0.3391
      Episode_Reward/pen_lin_vel_z: -0.0624
     Episode_Reward/pen_ang_vel_xy: -0.1490
   Episode_Reward/pen_joint_torque: -0.1885
    Episode_Reward/pen_joint_accel: -0.0830
    Episode_Reward/pen_action_rate: -0.2849
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0374
   Episode_Reward/pen_joint_powers: -0.0633
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.6557
Episode_Reward/pen_flat_orientation: -0.1248
  Episode_Reward/pen_feet_distance: -0.0100
Episode_Reward/pen_feet_regulation: -0.2688
   Episode_Reward/foot_landing_vel: -0.1108
   Episode_Reward/test_gait_reward: -0.8891
Metrics/base_velocity/error_vel_xy: 2.2211
Metrics/base_velocity/error_vel_yaw: 0.9884
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 1.09s
                        Total time: 1292.60s
                               ETA: 1961.7s

################################################################################
                     [1m Learning iteration 1192/3000 [0m                     

                       Computation: 91829 steps/s (collection: 0.946s, learning 0.124s)
               Value function loss: 0.9527
                    Surrogate loss: -0.0034
             Mean action noise std: 0.6266
                     Learning rate: 0.0006
                       Mean reward: 87.44
               Mean episode length: 966.44
       Episode_Reward/keep_balance: 0.9679
     Episode_Reward/rew_lin_vel_xy: 4.0330
      Episode_Reward/rew_ang_vel_z: 2.7380
    Episode_Reward/pen_base_height: -0.3361
      Episode_Reward/pen_lin_vel_z: -0.0598
     Episode_Reward/pen_ang_vel_xy: -0.1496
   Episode_Reward/pen_joint_torque: -0.1808
    Episode_Reward/pen_joint_accel: -0.0891
    Episode_Reward/pen_action_rate: -0.2866
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0382
   Episode_Reward/pen_joint_powers: -0.0630
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6606
Episode_Reward/pen_flat_orientation: -0.1270
  Episode_Reward/pen_feet_distance: -0.0054
Episode_Reward/pen_feet_regulation: -0.2756
   Episode_Reward/foot_landing_vel: -0.1083
   Episode_Reward/test_gait_reward: -0.8922
Metrics/base_velocity/error_vel_xy: 2.0756
Metrics/base_velocity/error_vel_yaw: 1.0038
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 1.07s
                        Total time: 1293.68s
                               ETA: 1960.6s

################################################################################
                     [1m Learning iteration 1193/3000 [0m                     

                       Computation: 91019 steps/s (collection: 0.956s, learning 0.125s)
               Value function loss: 1.0267
                    Surrogate loss: -0.0029
             Mean action noise std: 0.6286
                     Learning rate: 0.0009
                       Mean reward: 88.08
               Mean episode length: 958.94
       Episode_Reward/keep_balance: 0.9414
     Episode_Reward/rew_lin_vel_xy: 3.9727
      Episode_Reward/rew_ang_vel_z: 2.6579
    Episode_Reward/pen_base_height: -0.3372
      Episode_Reward/pen_lin_vel_z: -0.0608
     Episode_Reward/pen_ang_vel_xy: -0.1485
   Episode_Reward/pen_joint_torque: -0.1736
    Episode_Reward/pen_joint_accel: -0.0894
    Episode_Reward/pen_action_rate: -0.2783
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0379
   Episode_Reward/pen_joint_powers: -0.0611
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6426
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0025
Episode_Reward/pen_feet_regulation: -0.2678
   Episode_Reward/foot_landing_vel: -0.1152
   Episode_Reward/test_gait_reward: -0.8671
Metrics/base_velocity/error_vel_xy: 1.9932
Metrics/base_velocity/error_vel_yaw: 0.9834
      Episode_Termination/time_out: 5.0417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 1.08s
                        Total time: 1294.76s
                               ETA: 1959.5s

################################################################################
                     [1m Learning iteration 1194/3000 [0m                     

                       Computation: 91224 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 1.0114
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6290
                     Learning rate: 0.0004
                       Mean reward: 89.78
               Mean episode length: 973.35
       Episode_Reward/keep_balance: 0.9792
     Episode_Reward/rew_lin_vel_xy: 3.8997
      Episode_Reward/rew_ang_vel_z: 2.7825
    Episode_Reward/pen_base_height: -0.3548
      Episode_Reward/pen_lin_vel_z: -0.0615
     Episode_Reward/pen_ang_vel_xy: -0.1461
   Episode_Reward/pen_joint_torque: -0.1860
    Episode_Reward/pen_joint_accel: -0.0876
    Episode_Reward/pen_action_rate: -0.2856
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0380
   Episode_Reward/pen_joint_powers: -0.0630
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6626
Episode_Reward/pen_flat_orientation: -0.1301
  Episode_Reward/pen_feet_distance: -0.0061
Episode_Reward/pen_feet_regulation: -0.2652
   Episode_Reward/foot_landing_vel: -0.1105
   Episode_Reward/test_gait_reward: -0.8952
Metrics/base_velocity/error_vel_xy: 2.2169
Metrics/base_velocity/error_vel_yaw: 1.0059
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 1.08s
                        Total time: 1295.83s
                               ETA: 1958.4s

################################################################################
                     [1m Learning iteration 1195/3000 [0m                     

                       Computation: 91941 steps/s (collection: 0.944s, learning 0.125s)
               Value function loss: 1.0857
                    Surrogate loss: 0.0094
             Mean action noise std: 0.6291
                     Learning rate: 0.0000
                       Mean reward: 88.16
               Mean episode length: 987.25
       Episode_Reward/keep_balance: 0.9695
     Episode_Reward/rew_lin_vel_xy: 3.7780
      Episode_Reward/rew_ang_vel_z: 2.7686
    Episode_Reward/pen_base_height: -0.3397
      Episode_Reward/pen_lin_vel_z: -0.0619
     Episode_Reward/pen_ang_vel_xy: -0.1467
   Episode_Reward/pen_joint_torque: -0.1872
    Episode_Reward/pen_joint_accel: -0.0887
    Episode_Reward/pen_action_rate: -0.2852
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0379
   Episode_Reward/pen_joint_powers: -0.0627
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6636
Episode_Reward/pen_flat_orientation: -0.1310
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.2790
   Episode_Reward/foot_landing_vel: -0.1131
   Episode_Reward/test_gait_reward: -0.8857
Metrics/base_velocity/error_vel_xy: 2.2523
Metrics/base_velocity/error_vel_yaw: 0.9878
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 1.07s
                        Total time: 1296.90s
                               ETA: 1957.3s

################################################################################
                     [1m Learning iteration 1196/3000 [0m                     

                       Computation: 91187 steps/s (collection: 0.953s, learning 0.125s)
               Value function loss: 1.0482
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6288
                     Learning rate: 0.0001
                       Mean reward: 91.07
               Mean episode length: 956.73
       Episode_Reward/keep_balance: 0.9538
     Episode_Reward/rew_lin_vel_xy: 4.1236
      Episode_Reward/rew_ang_vel_z: 2.6858
    Episode_Reward/pen_base_height: -0.3342
      Episode_Reward/pen_lin_vel_z: -0.0584
     Episode_Reward/pen_ang_vel_xy: -0.1453
   Episode_Reward/pen_joint_torque: -0.1730
    Episode_Reward/pen_joint_accel: -0.0843
    Episode_Reward/pen_action_rate: -0.2808
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0374
   Episode_Reward/pen_joint_powers: -0.0604
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.6588
Episode_Reward/pen_flat_orientation: -0.1263
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.2554
   Episode_Reward/foot_landing_vel: -0.1072
   Episode_Reward/test_gait_reward: -0.8772
Metrics/base_velocity/error_vel_xy: 1.9961
Metrics/base_velocity/error_vel_yaw: 1.0029
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 1.08s
                        Total time: 1297.98s
                               ETA: 1956.2s

################################################################################
                     [1m Learning iteration 1197/3000 [0m                     

                       Computation: 91459 steps/s (collection: 0.950s, learning 0.124s)
               Value function loss: 0.9601
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6278
                     Learning rate: 0.0001
                       Mean reward: 90.39
               Mean episode length: 967.13
       Episode_Reward/keep_balance: 0.9723
     Episode_Reward/rew_lin_vel_xy: 4.1608
      Episode_Reward/rew_ang_vel_z: 2.7573
    Episode_Reward/pen_base_height: -0.3328
      Episode_Reward/pen_lin_vel_z: -0.0610
     Episode_Reward/pen_ang_vel_xy: -0.1423
   Episode_Reward/pen_joint_torque: -0.1782
    Episode_Reward/pen_joint_accel: -0.1009
    Episode_Reward/pen_action_rate: -0.2869
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0383
   Episode_Reward/pen_joint_powers: -0.0618
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6682
Episode_Reward/pen_flat_orientation: -0.1195
  Episode_Reward/pen_feet_distance: -0.0047
Episode_Reward/pen_feet_regulation: -0.2716
   Episode_Reward/foot_landing_vel: -0.1183
   Episode_Reward/test_gait_reward: -0.8902
Metrics/base_velocity/error_vel_xy: 2.0296
Metrics/base_velocity/error_vel_yaw: 1.0079
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 1.07s
                        Total time: 1299.05s
                               ETA: 1955.1s

################################################################################
                     [1m Learning iteration 1198/3000 [0m                     

                       Computation: 91479 steps/s (collection: 0.948s, learning 0.126s)
               Value function loss: 1.0237
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6274
                     Learning rate: 0.0001
                       Mean reward: 89.86
               Mean episode length: 967.40
       Episode_Reward/keep_balance: 0.9584
     Episode_Reward/rew_lin_vel_xy: 4.0572
      Episode_Reward/rew_ang_vel_z: 2.7241
    Episode_Reward/pen_base_height: -0.3323
      Episode_Reward/pen_lin_vel_z: -0.0604
     Episode_Reward/pen_ang_vel_xy: -0.1414
   Episode_Reward/pen_joint_torque: -0.1808
    Episode_Reward/pen_joint_accel: -0.0927
    Episode_Reward/pen_action_rate: -0.2816
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0369
   Episode_Reward/pen_joint_powers: -0.0614
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6488
Episode_Reward/pen_flat_orientation: -0.1179
  Episode_Reward/pen_feet_distance: -0.0025
Episode_Reward/pen_feet_regulation: -0.2573
   Episode_Reward/foot_landing_vel: -0.1100
   Episode_Reward/test_gait_reward: -0.8785
Metrics/base_velocity/error_vel_xy: 2.0609
Metrics/base_velocity/error_vel_yaw: 0.9868
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 1.07s
                        Total time: 1300.13s
                               ETA: 1954.0s

################################################################################
                     [1m Learning iteration 1199/3000 [0m                     

                       Computation: 91263 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 1.0971
                    Surrogate loss: -0.0041
             Mean action noise std: 0.6278
                     Learning rate: 0.0003
                       Mean reward: 90.99
               Mean episode length: 969.55
       Episode_Reward/keep_balance: 0.9611
     Episode_Reward/rew_lin_vel_xy: 4.0350
      Episode_Reward/rew_ang_vel_z: 2.7375
    Episode_Reward/pen_base_height: -0.3347
      Episode_Reward/pen_lin_vel_z: -0.0640
     Episode_Reward/pen_ang_vel_xy: -0.1468
   Episode_Reward/pen_joint_torque: -0.1830
    Episode_Reward/pen_joint_accel: -0.0967
    Episode_Reward/pen_action_rate: -0.2883
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0386
   Episode_Reward/pen_joint_powers: -0.0630
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6653
Episode_Reward/pen_flat_orientation: -0.1207
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2796
   Episode_Reward/foot_landing_vel: -0.1226
   Episode_Reward/test_gait_reward: -0.8891
Metrics/base_velocity/error_vel_xy: 2.0616
Metrics/base_velocity/error_vel_yaw: 0.9807
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 1.08s
                        Total time: 1301.21s
                               ETA: 1952.9s

################################################################################
                     [1m Learning iteration 1200/3000 [0m                     

                       Computation: 91188 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.0186
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6280
                     Learning rate: 0.0004
                       Mean reward: 83.21
               Mean episode length: 925.50
       Episode_Reward/keep_balance: 0.9343
     Episode_Reward/rew_lin_vel_xy: 3.7998
      Episode_Reward/rew_ang_vel_z: 2.6660
    Episode_Reward/pen_base_height: -0.3181
      Episode_Reward/pen_lin_vel_z: -0.0579
     Episode_Reward/pen_ang_vel_xy: -0.1427
   Episode_Reward/pen_joint_torque: -0.1784
    Episode_Reward/pen_joint_accel: -0.0848
    Episode_Reward/pen_action_rate: -0.2761
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0365
   Episode_Reward/pen_joint_powers: -0.0603
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6365
Episode_Reward/pen_flat_orientation: -0.1200
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2553
   Episode_Reward/foot_landing_vel: -0.1088
   Episode_Reward/test_gait_reward: -0.8530
Metrics/base_velocity/error_vel_xy: 2.0794
Metrics/base_velocity/error_vel_yaw: 0.9545
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 1.08s
                        Total time: 1302.28s
                               ETA: 1951.8s

################################################################################
                     [1m Learning iteration 1201/3000 [0m                     

                       Computation: 93268 steps/s (collection: 0.931s, learning 0.123s)
               Value function loss: 0.9624
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6265
                     Learning rate: 0.0006
                       Mean reward: 87.73
               Mean episode length: 962.85
       Episode_Reward/keep_balance: 0.9660
     Episode_Reward/rew_lin_vel_xy: 4.0358
      Episode_Reward/rew_ang_vel_z: 2.7540
    Episode_Reward/pen_base_height: -0.3435
      Episode_Reward/pen_lin_vel_z: -0.0610
     Episode_Reward/pen_ang_vel_xy: -0.1435
   Episode_Reward/pen_joint_torque: -0.1846
    Episode_Reward/pen_joint_accel: -0.0766
    Episode_Reward/pen_action_rate: -0.2838
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0368
   Episode_Reward/pen_joint_powers: -0.0625
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6548
Episode_Reward/pen_flat_orientation: -0.1310
  Episode_Reward/pen_feet_distance: -0.0069
Episode_Reward/pen_feet_regulation: -0.2663
   Episode_Reward/foot_landing_vel: -0.1061
   Episode_Reward/test_gait_reward: -0.8841
Metrics/base_velocity/error_vel_xy: 2.1054
Metrics/base_velocity/error_vel_yaw: 0.9942
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 1.05s
                        Total time: 1303.34s
                               ETA: 1950.7s

################################################################################
                     [1m Learning iteration 1202/3000 [0m                     

                       Computation: 92086 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 1.0142
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6277
                     Learning rate: 0.0009
                       Mean reward: 91.39
               Mean episode length: 957.82
       Episode_Reward/keep_balance: 0.9489
     Episode_Reward/rew_lin_vel_xy: 4.0213
      Episode_Reward/rew_ang_vel_z: 2.7133
    Episode_Reward/pen_base_height: -0.3294
      Episode_Reward/pen_lin_vel_z: -0.0599
     Episode_Reward/pen_ang_vel_xy: -0.1398
   Episode_Reward/pen_joint_torque: -0.1870
    Episode_Reward/pen_joint_accel: -0.0938
    Episode_Reward/pen_action_rate: -0.2798
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0373
   Episode_Reward/pen_joint_powers: -0.0627
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6467
Episode_Reward/pen_flat_orientation: -0.1244
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.2756
   Episode_Reward/foot_landing_vel: -0.1106
   Episode_Reward/test_gait_reward: -0.8765
Metrics/base_velocity/error_vel_xy: 2.0192
Metrics/base_velocity/error_vel_yaw: 0.9671
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 1.07s
                        Total time: 1304.41s
                               ETA: 1949.6s

################################################################################
                     [1m Learning iteration 1203/3000 [0m                     

                       Computation: 91395 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 1.0528
                    Surrogate loss: 0.0005
             Mean action noise std: 0.6277
                     Learning rate: 0.0002
                       Mean reward: 88.59
               Mean episode length: 947.10
       Episode_Reward/keep_balance: 0.9537
     Episode_Reward/rew_lin_vel_xy: 3.9288
      Episode_Reward/rew_ang_vel_z: 2.7134
    Episode_Reward/pen_base_height: -0.3262
      Episode_Reward/pen_lin_vel_z: -0.0576
     Episode_Reward/pen_ang_vel_xy: -0.1426
   Episode_Reward/pen_joint_torque: -0.1859
    Episode_Reward/pen_joint_accel: -0.0880
    Episode_Reward/pen_action_rate: -0.2788
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0370
   Episode_Reward/pen_joint_powers: -0.0619
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6425
Episode_Reward/pen_flat_orientation: -0.1207
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.2533
   Episode_Reward/foot_landing_vel: -0.1081
   Episode_Reward/test_gait_reward: -0.8709
Metrics/base_velocity/error_vel_xy: 2.0812
Metrics/base_velocity/error_vel_yaw: 0.9804
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 1.08s
                        Total time: 1305.48s
                               ETA: 1948.5s

################################################################################
                     [1m Learning iteration 1204/3000 [0m                     

                       Computation: 91617 steps/s (collection: 0.949s, learning 0.124s)
               Value function loss: 1.0526
                    Surrogate loss: -0.0043
             Mean action noise std: 0.6273
                     Learning rate: 0.0003
                       Mean reward: 84.99
               Mean episode length: 961.40
       Episode_Reward/keep_balance: 0.9665
     Episode_Reward/rew_lin_vel_xy: 3.7905
      Episode_Reward/rew_ang_vel_z: 2.7366
    Episode_Reward/pen_base_height: -0.3392
      Episode_Reward/pen_lin_vel_z: -0.0611
     Episode_Reward/pen_ang_vel_xy: -0.1445
   Episode_Reward/pen_joint_torque: -0.1873
    Episode_Reward/pen_joint_accel: -0.0870
    Episode_Reward/pen_action_rate: -0.2878
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0380
   Episode_Reward/pen_joint_powers: -0.0634
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6617
Episode_Reward/pen_flat_orientation: -0.1261
  Episode_Reward/pen_feet_distance: -0.0054
Episode_Reward/pen_feet_regulation: -0.2712
   Episode_Reward/foot_landing_vel: -0.1085
   Episode_Reward/test_gait_reward: -0.8895
Metrics/base_velocity/error_vel_xy: 2.2018
Metrics/base_velocity/error_vel_yaw: 1.0112
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 1.07s
                        Total time: 1306.55s
                               ETA: 1947.4s

################################################################################
                     [1m Learning iteration 1205/3000 [0m                     

                       Computation: 92606 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 1.0724
                    Surrogate loss: -0.0036
             Mean action noise std: 0.6269
                     Learning rate: 0.0006
                       Mean reward: 89.26
               Mean episode length: 969.18
       Episode_Reward/keep_balance: 0.9678
     Episode_Reward/rew_lin_vel_xy: 4.0070
      Episode_Reward/rew_ang_vel_z: 2.7776
    Episode_Reward/pen_base_height: -0.3320
      Episode_Reward/pen_lin_vel_z: -0.0629
     Episode_Reward/pen_ang_vel_xy: -0.1482
   Episode_Reward/pen_joint_torque: -0.1858
    Episode_Reward/pen_joint_accel: -0.0995
    Episode_Reward/pen_action_rate: -0.2881
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0392
   Episode_Reward/pen_joint_powers: -0.0640
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6611
Episode_Reward/pen_flat_orientation: -0.1264
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.2810
   Episode_Reward/foot_landing_vel: -0.1199
   Episode_Reward/test_gait_reward: -0.8849
Metrics/base_velocity/error_vel_xy: 2.0966
Metrics/base_velocity/error_vel_yaw: 0.9793
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 1.06s
                        Total time: 1307.62s
                               ETA: 1946.2s

################################################################################
                     [1m Learning iteration 1206/3000 [0m                     

                       Computation: 93127 steps/s (collection: 0.934s, learning 0.122s)
               Value function loss: 1.0784
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6265
                     Learning rate: 0.0004
                       Mean reward: 90.14
               Mean episode length: 949.14
       Episode_Reward/keep_balance: 0.9591
     Episode_Reward/rew_lin_vel_xy: 4.1323
      Episode_Reward/rew_ang_vel_z: 2.7051
    Episode_Reward/pen_base_height: -0.3285
      Episode_Reward/pen_lin_vel_z: -0.0583
     Episode_Reward/pen_ang_vel_xy: -0.1423
   Episode_Reward/pen_joint_torque: -0.1771
    Episode_Reward/pen_joint_accel: -0.0830
    Episode_Reward/pen_action_rate: -0.2815
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0370
   Episode_Reward/pen_joint_powers: -0.0608
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6580
Episode_Reward/pen_flat_orientation: -0.1222
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.2613
   Episode_Reward/foot_landing_vel: -0.1120
   Episode_Reward/test_gait_reward: -0.8751
Metrics/base_velocity/error_vel_xy: 1.9355
Metrics/base_velocity/error_vel_yaw: 1.0071
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 1.06s
                        Total time: 1308.67s
                               ETA: 1945.1s

################################################################################
                     [1m Learning iteration 1207/3000 [0m                     

                       Computation: 92244 steps/s (collection: 0.942s, learning 0.124s)
               Value function loss: 0.9204
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6262
                     Learning rate: 0.0006
                       Mean reward: 91.13
               Mean episode length: 961.71
       Episode_Reward/keep_balance: 0.9605
     Episode_Reward/rew_lin_vel_xy: 4.1180
      Episode_Reward/rew_ang_vel_z: 2.7397
    Episode_Reward/pen_base_height: -0.3356
      Episode_Reward/pen_lin_vel_z: -0.0601
     Episode_Reward/pen_ang_vel_xy: -0.1410
   Episode_Reward/pen_joint_torque: -0.1856
    Episode_Reward/pen_joint_accel: -0.0822
    Episode_Reward/pen_action_rate: -0.2830
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0373
   Episode_Reward/pen_joint_powers: -0.0629
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6577
Episode_Reward/pen_flat_orientation: -0.1219
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2735
   Episode_Reward/foot_landing_vel: -0.1098
   Episode_Reward/test_gait_reward: -0.8805
Metrics/base_velocity/error_vel_xy: 2.0088
Metrics/base_velocity/error_vel_yaw: 0.9820
      Episode_Termination/time_out: 5.0417
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 1.07s
                        Total time: 1309.74s
                               ETA: 1944.0s

################################################################################
                     [1m Learning iteration 1208/3000 [0m                     

                       Computation: 91822 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 1.0638
                    Surrogate loss: -0.0039
             Mean action noise std: 0.6255
                     Learning rate: 0.0009
                       Mean reward: 88.55
               Mean episode length: 938.01
       Episode_Reward/keep_balance: 0.9522
     Episode_Reward/rew_lin_vel_xy: 4.0898
      Episode_Reward/rew_ang_vel_z: 2.6599
    Episode_Reward/pen_base_height: -0.3367
      Episode_Reward/pen_lin_vel_z: -0.0604
     Episode_Reward/pen_ang_vel_xy: -0.1445
   Episode_Reward/pen_joint_torque: -0.1825
    Episode_Reward/pen_joint_accel: -0.0867
    Episode_Reward/pen_action_rate: -0.2873
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0399
   Episode_Reward/pen_joint_powers: -0.0639
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.6614
Episode_Reward/pen_flat_orientation: -0.1304
  Episode_Reward/pen_feet_distance: -0.0073
Episode_Reward/pen_feet_regulation: -0.2924
   Episode_Reward/foot_landing_vel: -0.1173
   Episode_Reward/test_gait_reward: -0.8845
Metrics/base_velocity/error_vel_xy: 1.9131
Metrics/base_velocity/error_vel_yaw: 1.0209
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 1.07s
                        Total time: 1310.81s
                               ETA: 1942.9s

################################################################################
                     [1m Learning iteration 1209/3000 [0m                     

                       Computation: 92178 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 1.0968
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6257
                     Learning rate: 0.0009
                       Mean reward: 93.71
               Mean episode length: 977.85
       Episode_Reward/keep_balance: 0.9867
     Episode_Reward/rew_lin_vel_xy: 4.3141
      Episode_Reward/rew_ang_vel_z: 2.8579
    Episode_Reward/pen_base_height: -0.3263
      Episode_Reward/pen_lin_vel_z: -0.0569
     Episode_Reward/pen_ang_vel_xy: -0.1410
   Episode_Reward/pen_joint_torque: -0.1849
    Episode_Reward/pen_joint_accel: -0.0882
    Episode_Reward/pen_action_rate: -0.2842
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0360
   Episode_Reward/pen_joint_powers: -0.0614
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6619
Episode_Reward/pen_flat_orientation: -0.1168
  Episode_Reward/pen_feet_distance: -0.0058
Episode_Reward/pen_feet_regulation: -0.2480
   Episode_Reward/foot_landing_vel: -0.1073
   Episode_Reward/test_gait_reward: -0.8967
Metrics/base_velocity/error_vel_xy: 1.9741
Metrics/base_velocity/error_vel_yaw: 0.9728
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 1.07s
                        Total time: 1311.87s
                               ETA: 1941.8s

################################################################################
                     [1m Learning iteration 1210/3000 [0m                     

                       Computation: 92178 steps/s (collection: 0.942s, learning 0.125s)
               Value function loss: 1.0553
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6255
                     Learning rate: 0.0009
                       Mean reward: 89.99
               Mean episode length: 952.52
       Episode_Reward/keep_balance: 0.9474
     Episode_Reward/rew_lin_vel_xy: 4.0549
      Episode_Reward/rew_ang_vel_z: 2.7081
    Episode_Reward/pen_base_height: -0.3240
      Episode_Reward/pen_lin_vel_z: -0.0578
     Episode_Reward/pen_ang_vel_xy: -0.1405
   Episode_Reward/pen_joint_torque: -0.1754
    Episode_Reward/pen_joint_accel: -0.0800
    Episode_Reward/pen_action_rate: -0.2775
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0360
   Episode_Reward/pen_joint_powers: -0.0598
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6437
Episode_Reward/pen_flat_orientation: -0.1216
  Episode_Reward/pen_feet_distance: -0.0047
Episode_Reward/pen_feet_regulation: -0.2533
   Episode_Reward/foot_landing_vel: -0.1035
   Episode_Reward/test_gait_reward: -0.8658
Metrics/base_velocity/error_vel_xy: 1.9466
Metrics/base_velocity/error_vel_yaw: 0.9650
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 1.07s
                        Total time: 1312.94s
                               ETA: 1940.7s

################################################################################
                     [1m Learning iteration 1211/3000 [0m                     

                       Computation: 93327 steps/s (collection: 0.930s, learning 0.123s)
               Value function loss: 0.9895
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6265
                     Learning rate: 0.0002
                       Mean reward: 91.15
               Mean episode length: 966.36
       Episode_Reward/keep_balance: 0.9764
     Episode_Reward/rew_lin_vel_xy: 4.0563
      Episode_Reward/rew_ang_vel_z: 2.7914
    Episode_Reward/pen_base_height: -0.3280
      Episode_Reward/pen_lin_vel_z: -0.0590
     Episode_Reward/pen_ang_vel_xy: -0.1390
   Episode_Reward/pen_joint_torque: -0.1875
    Episode_Reward/pen_joint_accel: -0.0863
    Episode_Reward/pen_action_rate: -0.2846
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0372
   Episode_Reward/pen_joint_powers: -0.0624
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6591
Episode_Reward/pen_flat_orientation: -0.1190
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.2647
   Episode_Reward/foot_landing_vel: -0.1106
   Episode_Reward/test_gait_reward: -0.8841
Metrics/base_velocity/error_vel_xy: 2.1433
Metrics/base_velocity/error_vel_yaw: 0.9944
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 1.05s
                        Total time: 1313.99s
                               ETA: 1939.6s

################################################################################
                     [1m Learning iteration 1212/3000 [0m                     

                       Computation: 90759 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 1.0072
                    Surrogate loss: 0.0011
             Mean action noise std: 0.6266
                     Learning rate: 0.0001
                       Mean reward: 82.09
               Mean episode length: 932.27
       Episode_Reward/keep_balance: 0.9329
     Episode_Reward/rew_lin_vel_xy: 3.5952
      Episode_Reward/rew_ang_vel_z: 2.6780
    Episode_Reward/pen_base_height: -0.3256
      Episode_Reward/pen_lin_vel_z: -0.0603
     Episode_Reward/pen_ang_vel_xy: -0.1443
   Episode_Reward/pen_joint_torque: -0.1843
    Episode_Reward/pen_joint_accel: -0.0865
    Episode_Reward/pen_action_rate: -0.2785
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0373
   Episode_Reward/pen_joint_powers: -0.0627
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6387
Episode_Reward/pen_flat_orientation: -0.1187
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2637
   Episode_Reward/foot_landing_vel: -0.1118
   Episode_Reward/test_gait_reward: -0.8527
Metrics/base_velocity/error_vel_xy: 2.2192
Metrics/base_velocity/error_vel_yaw: 0.9448
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 1.08s
                        Total time: 1315.08s
                               ETA: 1938.5s

################################################################################
                     [1m Learning iteration 1213/3000 [0m                     

                       Computation: 91346 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 1.0748
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6259
                     Learning rate: 0.0002
                       Mean reward: 89.72
               Mean episode length: 959.45
       Episode_Reward/keep_balance: 0.9588
     Episode_Reward/rew_lin_vel_xy: 4.0779
      Episode_Reward/rew_ang_vel_z: 2.7473
    Episode_Reward/pen_base_height: -0.3405
      Episode_Reward/pen_lin_vel_z: -0.0647
     Episode_Reward/pen_ang_vel_xy: -0.1407
   Episode_Reward/pen_joint_torque: -0.1890
    Episode_Reward/pen_joint_accel: -0.0858
    Episode_Reward/pen_action_rate: -0.2865
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0383
   Episode_Reward/pen_joint_powers: -0.0644
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6578
Episode_Reward/pen_flat_orientation: -0.1264
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2919
   Episode_Reward/foot_landing_vel: -0.1158
   Episode_Reward/test_gait_reward: -0.8817
Metrics/base_velocity/error_vel_xy: 2.0689
Metrics/base_velocity/error_vel_yaw: 0.9757
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 1.08s
                        Total time: 1316.15s
                               ETA: 1937.4s

################################################################################
                     [1m Learning iteration 1214/3000 [0m                     

                       Computation: 91512 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 1.0570
                    Surrogate loss: -0.0039
             Mean action noise std: 0.6253
                     Learning rate: 0.0004
                       Mean reward: 88.97
               Mean episode length: 935.88
       Episode_Reward/keep_balance: 0.9482
     Episode_Reward/rew_lin_vel_xy: 4.1510
      Episode_Reward/rew_ang_vel_z: 2.7085
    Episode_Reward/pen_base_height: -0.3271
      Episode_Reward/pen_lin_vel_z: -0.0578
     Episode_Reward/pen_ang_vel_xy: -0.1387
   Episode_Reward/pen_joint_torque: -0.1782
    Episode_Reward/pen_joint_accel: -0.0784
    Episode_Reward/pen_action_rate: -0.2792
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0363
   Episode_Reward/pen_joint_powers: -0.0606
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6473
Episode_Reward/pen_flat_orientation: -0.1217
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.2562
   Episode_Reward/foot_landing_vel: -0.1054
   Episode_Reward/test_gait_reward: -0.8703
Metrics/base_velocity/error_vel_xy: 1.8927
Metrics/base_velocity/error_vel_yaw: 0.9708
      Episode_Termination/time_out: 3.1250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 1.07s
                        Total time: 1317.23s
                               ETA: 1936.3s

################################################################################
                     [1m Learning iteration 1215/3000 [0m                     

                       Computation: 91831 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 1.0481
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6259
                     Learning rate: 0.0006
                       Mean reward: 85.80
               Mean episode length: 926.97
       Episode_Reward/keep_balance: 0.9379
     Episode_Reward/rew_lin_vel_xy: 3.9231
      Episode_Reward/rew_ang_vel_z: 2.6472
    Episode_Reward/pen_base_height: -0.3384
      Episode_Reward/pen_lin_vel_z: -0.0607
     Episode_Reward/pen_ang_vel_xy: -0.1397
   Episode_Reward/pen_joint_torque: -0.1849
    Episode_Reward/pen_joint_accel: -0.0923
    Episode_Reward/pen_action_rate: -0.2809
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0384
   Episode_Reward/pen_joint_powers: -0.0630
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6519
Episode_Reward/pen_flat_orientation: -0.1329
  Episode_Reward/pen_feet_distance: -0.0058
Episode_Reward/pen_feet_regulation: -0.2850
   Episode_Reward/foot_landing_vel: -0.1181
   Episode_Reward/test_gait_reward: -0.8657
Metrics/base_velocity/error_vel_xy: 2.0365
Metrics/base_velocity/error_vel_yaw: 0.9853
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 1.07s
                        Total time: 1318.30s
                               ETA: 1935.2s

################################################################################
                     [1m Learning iteration 1216/3000 [0m                     

                       Computation: 91555 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 1.0224
                    Surrogate loss: -0.0036
             Mean action noise std: 0.6263
                     Learning rate: 0.0013
                       Mean reward: 84.56
               Mean episode length: 938.67
       Episode_Reward/keep_balance: 0.9476
     Episode_Reward/rew_lin_vel_xy: 3.7955
      Episode_Reward/rew_ang_vel_z: 2.7189
    Episode_Reward/pen_base_height: -0.3350
      Episode_Reward/pen_lin_vel_z: -0.0625
     Episode_Reward/pen_ang_vel_xy: -0.1431
   Episode_Reward/pen_joint_torque: -0.1864
    Episode_Reward/pen_joint_accel: -0.0895
    Episode_Reward/pen_action_rate: -0.2847
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0380
   Episode_Reward/pen_joint_powers: -0.0632
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6485
Episode_Reward/pen_flat_orientation: -0.1268
  Episode_Reward/pen_feet_distance: -0.0057
Episode_Reward/pen_feet_regulation: -0.2803
   Episode_Reward/foot_landing_vel: -0.1100
   Episode_Reward/test_gait_reward: -0.8668
Metrics/base_velocity/error_vel_xy: 2.2056
Metrics/base_velocity/error_vel_yaw: 0.9680
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 1.07s
                        Total time: 1319.37s
                               ETA: 1934.1s

################################################################################
                     [1m Learning iteration 1217/3000 [0m                     

                       Computation: 90070 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 1.0952
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6258
                     Learning rate: 0.0013
                       Mean reward: 89.81
               Mean episode length: 954.69
       Episode_Reward/keep_balance: 0.9371
     Episode_Reward/rew_lin_vel_xy: 4.0967
      Episode_Reward/rew_ang_vel_z: 2.6741
    Episode_Reward/pen_base_height: -0.3342
      Episode_Reward/pen_lin_vel_z: -0.0646
     Episode_Reward/pen_ang_vel_xy: -0.1466
   Episode_Reward/pen_joint_torque: -0.1850
    Episode_Reward/pen_joint_accel: -0.0899
    Episode_Reward/pen_action_rate: -0.2838
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0389
   Episode_Reward/pen_joint_powers: -0.0638
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6496
Episode_Reward/pen_flat_orientation: -0.1267
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.2928
   Episode_Reward/foot_landing_vel: -0.1165
   Episode_Reward/test_gait_reward: -0.8645
Metrics/base_velocity/error_vel_xy: 1.8728
Metrics/base_velocity/error_vel_yaw: 0.9709
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 1.09s
                        Total time: 1320.46s
                               ETA: 1933.0s

################################################################################
                     [1m Learning iteration 1218/3000 [0m                     

                       Computation: 90905 steps/s (collection: 0.956s, learning 0.125s)
               Value function loss: 1.0859
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6261
                     Learning rate: 0.0019
                       Mean reward: 86.18
               Mean episode length: 957.03
       Episode_Reward/keep_balance: 0.9524
     Episode_Reward/rew_lin_vel_xy: 3.9471
      Episode_Reward/rew_ang_vel_z: 2.6752
    Episode_Reward/pen_base_height: -0.3429
      Episode_Reward/pen_lin_vel_z: -0.0615
     Episode_Reward/pen_ang_vel_xy: -0.1432
   Episode_Reward/pen_joint_torque: -0.1900
    Episode_Reward/pen_joint_accel: -0.0866
    Episode_Reward/pen_action_rate: -0.2855
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0391
   Episode_Reward/pen_joint_powers: -0.0646
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6552
Episode_Reward/pen_flat_orientation: -0.1286
  Episode_Reward/pen_feet_distance: -0.0038
Episode_Reward/pen_feet_regulation: -0.2868
   Episode_Reward/foot_landing_vel: -0.1083
   Episode_Reward/test_gait_reward: -0.8839
Metrics/base_velocity/error_vel_xy: 2.0092
Metrics/base_velocity/error_vel_yaw: 1.0071
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 1.08s
                        Total time: 1321.54s
                               ETA: 1931.9s

################################################################################
                     [1m Learning iteration 1219/3000 [0m                     

                       Computation: 92681 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 1.2013
                    Surrogate loss: 0.0025
             Mean action noise std: 0.6271
                     Learning rate: 0.0003
                       Mean reward: 90.53
               Mean episode length: 981.14
       Episode_Reward/keep_balance: 0.9820
     Episode_Reward/rew_lin_vel_xy: 4.1660
      Episode_Reward/rew_ang_vel_z: 2.8466
    Episode_Reward/pen_base_height: -0.3264
      Episode_Reward/pen_lin_vel_z: -0.0606
     Episode_Reward/pen_ang_vel_xy: -0.1384
   Episode_Reward/pen_joint_torque: -0.1915
    Episode_Reward/pen_joint_accel: -0.0841
    Episode_Reward/pen_action_rate: -0.2879
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0371
   Episode_Reward/pen_joint_powers: -0.0638
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6671
Episode_Reward/pen_flat_orientation: -0.1110
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.2589
   Episode_Reward/foot_landing_vel: -0.1080
   Episode_Reward/test_gait_reward: -0.9011
Metrics/base_velocity/error_vel_xy: 2.1391
Metrics/base_velocity/error_vel_yaw: 0.9648
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 1.06s
                        Total time: 1322.61s
                               ETA: 1930.8s

################################################################################
                     [1m Learning iteration 1220/3000 [0m                     

                       Computation: 92689 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 1.0170
                    Surrogate loss: -0.0037
             Mean action noise std: 0.6272
                     Learning rate: 0.0006
                       Mean reward: 88.97
               Mean episode length: 960.67
       Episode_Reward/keep_balance: 0.9613
     Episode_Reward/rew_lin_vel_xy: 4.1546
      Episode_Reward/rew_ang_vel_z: 2.7341
    Episode_Reward/pen_base_height: -0.3440
      Episode_Reward/pen_lin_vel_z: -0.0636
     Episode_Reward/pen_ang_vel_xy: -0.1421
   Episode_Reward/pen_joint_torque: -0.1847
    Episode_Reward/pen_joint_accel: -0.0863
    Episode_Reward/pen_action_rate: -0.2866
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0386
   Episode_Reward/pen_joint_powers: -0.0637
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6647
Episode_Reward/pen_flat_orientation: -0.1306
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.2793
   Episode_Reward/foot_landing_vel: -0.1212
   Episode_Reward/test_gait_reward: -0.8775
Metrics/base_velocity/error_vel_xy: 2.0629
Metrics/base_velocity/error_vel_yaw: 0.9927
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 1.06s
                        Total time: 1323.67s
                               ETA: 1929.7s

################################################################################
                     [1m Learning iteration 1221/3000 [0m                     

                       Computation: 93496 steps/s (collection: 0.928s, learning 0.123s)
               Value function loss: 1.0462
                    Surrogate loss: -0.0037
             Mean action noise std: 0.6267
                     Learning rate: 0.0009
                       Mean reward: 90.31
               Mean episode length: 963.82
       Episode_Reward/keep_balance: 0.9631
     Episode_Reward/rew_lin_vel_xy: 4.0304
      Episode_Reward/rew_ang_vel_z: 2.7572
    Episode_Reward/pen_base_height: -0.3312
      Episode_Reward/pen_lin_vel_z: -0.0604
     Episode_Reward/pen_ang_vel_xy: -0.1438
   Episode_Reward/pen_joint_torque: -0.1925
    Episode_Reward/pen_joint_accel: -0.0794
    Episode_Reward/pen_action_rate: -0.2866
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0381
   Episode_Reward/pen_joint_powers: -0.0650
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6581
Episode_Reward/pen_flat_orientation: -0.1232
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.2805
   Episode_Reward/foot_landing_vel: -0.1064
   Episode_Reward/test_gait_reward: -0.8869
Metrics/base_velocity/error_vel_xy: 2.0732
Metrics/base_velocity/error_vel_yaw: 0.9787
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 1.05s
                        Total time: 1324.72s
                               ETA: 1928.5s

################################################################################
                     [1m Learning iteration 1222/3000 [0m                     

                       Computation: 92985 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 0.9600
                    Surrogate loss: 0.0017
             Mean action noise std: 0.6274
                     Learning rate: 0.0002
                       Mean reward: 91.66
               Mean episode length: 954.28
       Episode_Reward/keep_balance: 0.9640
     Episode_Reward/rew_lin_vel_xy: 4.1239
      Episode_Reward/rew_ang_vel_z: 2.7603
    Episode_Reward/pen_base_height: -0.3251
      Episode_Reward/pen_lin_vel_z: -0.0590
     Episode_Reward/pen_ang_vel_xy: -0.1383
   Episode_Reward/pen_joint_torque: -0.1836
    Episode_Reward/pen_joint_accel: -0.0790
    Episode_Reward/pen_action_rate: -0.2828
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0364
   Episode_Reward/pen_joint_powers: -0.0616
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6562
Episode_Reward/pen_flat_orientation: -0.1234
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.2648
   Episode_Reward/foot_landing_vel: -0.1041
   Episode_Reward/test_gait_reward: -0.8778
Metrics/base_velocity/error_vel_xy: 2.0494
Metrics/base_velocity/error_vel_yaw: 0.9778
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 1.06s
                        Total time: 1325.77s
                               ETA: 1927.4s

################################################################################
                     [1m Learning iteration 1223/3000 [0m                     

                       Computation: 92655 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 1.0060
                    Surrogate loss: 0.0003
             Mean action noise std: 0.6273
                     Learning rate: 0.0002
                       Mean reward: 91.74
               Mean episode length: 967.53
       Episode_Reward/keep_balance: 0.9564
     Episode_Reward/rew_lin_vel_xy: 4.2001
      Episode_Reward/rew_ang_vel_z: 2.7424
    Episode_Reward/pen_base_height: -0.3297
      Episode_Reward/pen_lin_vel_z: -0.0609
     Episode_Reward/pen_ang_vel_xy: -0.1416
   Episode_Reward/pen_joint_torque: -0.1833
    Episode_Reward/pen_joint_accel: -0.0889
    Episode_Reward/pen_action_rate: -0.2864
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0387
   Episode_Reward/pen_joint_powers: -0.0641
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6596
Episode_Reward/pen_flat_orientation: -0.1296
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.2860
   Episode_Reward/foot_landing_vel: -0.1164
   Episode_Reward/test_gait_reward: -0.8799
Metrics/base_velocity/error_vel_xy: 1.9003
Metrics/base_velocity/error_vel_yaw: 0.9733
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 1.06s
                        Total time: 1326.84s
                               ETA: 1926.3s

################################################################################
                     [1m Learning iteration 1224/3000 [0m                     

                       Computation: 90925 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 1.0279
                    Surrogate loss: -0.0043
             Mean action noise std: 0.6269
                     Learning rate: 0.0004
                       Mean reward: 86.51
               Mean episode length: 951.23
       Episode_Reward/keep_balance: 0.9312
     Episode_Reward/rew_lin_vel_xy: 3.8370
      Episode_Reward/rew_ang_vel_z: 2.6435
    Episode_Reward/pen_base_height: -0.3344
      Episode_Reward/pen_lin_vel_z: -0.0621
     Episode_Reward/pen_ang_vel_xy: -0.1417
   Episode_Reward/pen_joint_torque: -0.1880
    Episode_Reward/pen_joint_accel: -0.0860
    Episode_Reward/pen_action_rate: -0.2829
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0385
   Episode_Reward/pen_joint_powers: -0.0642
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6428
Episode_Reward/pen_flat_orientation: -0.1255
  Episode_Reward/pen_feet_distance: -0.0098
Episode_Reward/pen_feet_regulation: -0.2870
   Episode_Reward/foot_landing_vel: -0.1107
   Episode_Reward/test_gait_reward: -0.8614
Metrics/base_velocity/error_vel_xy: 2.0766
Metrics/base_velocity/error_vel_yaw: 0.9680
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 1.08s
                        Total time: 1327.92s
                               ETA: 1925.2s

################################################################################
                     [1m Learning iteration 1225/3000 [0m                     

                       Computation: 91170 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 1.0359
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6268
                     Learning rate: 0.0006
                       Mean reward: 94.77
               Mean episode length: 960.13
       Episode_Reward/keep_balance: 0.9777
     Episode_Reward/rew_lin_vel_xy: 4.2576
      Episode_Reward/rew_ang_vel_z: 2.8147
    Episode_Reward/pen_base_height: -0.3150
      Episode_Reward/pen_lin_vel_z: -0.0585
     Episode_Reward/pen_ang_vel_xy: -0.1374
   Episode_Reward/pen_joint_torque: -0.1825
    Episode_Reward/pen_joint_accel: -0.0831
    Episode_Reward/pen_action_rate: -0.2865
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0363
   Episode_Reward/pen_joint_powers: -0.0615
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6652
Episode_Reward/pen_flat_orientation: -0.1142
  Episode_Reward/pen_feet_distance: -0.0046
Episode_Reward/pen_feet_regulation: -0.2535
   Episode_Reward/foot_landing_vel: -0.1096
   Episode_Reward/test_gait_reward: -0.8906
Metrics/base_velocity/error_vel_xy: 2.0354
Metrics/base_velocity/error_vel_yaw: 0.9788
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 1.08s
                        Total time: 1328.99s
                               ETA: 1924.1s

################################################################################
                     [1m Learning iteration 1226/3000 [0m                     

                       Computation: 90958 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 1.0064
                    Surrogate loss: -0.0010
             Mean action noise std: 0.6274
                     Learning rate: 0.0006
                       Mean reward: 92.23
               Mean episode length: 978.72
       Episode_Reward/keep_balance: 0.9793
     Episode_Reward/rew_lin_vel_xy: 4.0888
      Episode_Reward/rew_ang_vel_z: 2.7721
    Episode_Reward/pen_base_height: -0.3304
      Episode_Reward/pen_lin_vel_z: -0.0584
     Episode_Reward/pen_ang_vel_xy: -0.1390
   Episode_Reward/pen_joint_torque: -0.1867
    Episode_Reward/pen_joint_accel: -0.0857
    Episode_Reward/pen_action_rate: -0.2901
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0381
   Episode_Reward/pen_joint_powers: -0.0631
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6753
Episode_Reward/pen_flat_orientation: -0.1216
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.2717
   Episode_Reward/foot_landing_vel: -0.1102
   Episode_Reward/test_gait_reward: -0.8946
Metrics/base_velocity/error_vel_xy: 2.1093
Metrics/base_velocity/error_vel_yaw: 1.0217
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 1.08s
                        Total time: 1330.08s
                               ETA: 1923.0s

################################################################################
                     [1m Learning iteration 1227/3000 [0m                     

                       Computation: 92453 steps/s (collection: 0.938s, learning 0.125s)
               Value function loss: 1.0052
                    Surrogate loss: -0.0029
             Mean action noise std: 0.6271
                     Learning rate: 0.0004
                       Mean reward: 91.40
               Mean episode length: 983.77
       Episode_Reward/keep_balance: 0.9837
     Episode_Reward/rew_lin_vel_xy: 4.0747
      Episode_Reward/rew_ang_vel_z: 2.8701
    Episode_Reward/pen_base_height: -0.3254
      Episode_Reward/pen_lin_vel_z: -0.0621
     Episode_Reward/pen_ang_vel_xy: -0.1378
   Episode_Reward/pen_joint_torque: -0.1912
    Episode_Reward/pen_joint_accel: -0.0840
    Episode_Reward/pen_action_rate: -0.2875
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0374
   Episode_Reward/pen_joint_powers: -0.0638
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6655
Episode_Reward/pen_flat_orientation: -0.1200
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.2698
   Episode_Reward/foot_landing_vel: -0.1207
   Episode_Reward/test_gait_reward: -0.8970
Metrics/base_velocity/error_vel_xy: 2.1810
Metrics/base_velocity/error_vel_yaw: 0.9574
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 1.06s
                        Total time: 1331.14s
                               ETA: 1921.9s

################################################################################
                     [1m Learning iteration 1228/3000 [0m                     

                       Computation: 89788 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.9482
                    Surrogate loss: -0.0037
             Mean action noise std: 0.6270
                     Learning rate: 0.0006
                       Mean reward: 89.32
               Mean episode length: 976.11
       Episode_Reward/keep_balance: 0.9737
     Episode_Reward/rew_lin_vel_xy: 4.0614
      Episode_Reward/rew_ang_vel_z: 2.7745
    Episode_Reward/pen_base_height: -0.3320
      Episode_Reward/pen_lin_vel_z: -0.0610
     Episode_Reward/pen_ang_vel_xy: -0.1460
   Episode_Reward/pen_joint_torque: -0.1868
    Episode_Reward/pen_joint_accel: -0.0881
    Episode_Reward/pen_action_rate: -0.2909
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0389
   Episode_Reward/pen_joint_powers: -0.0642
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6732
Episode_Reward/pen_flat_orientation: -0.1274
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.2840
   Episode_Reward/foot_landing_vel: -0.1117
   Episode_Reward/test_gait_reward: -0.8948
Metrics/base_velocity/error_vel_xy: 2.0746
Metrics/base_velocity/error_vel_yaw: 1.0019
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 1.09s
                        Total time: 1332.23s
                               ETA: 1920.8s

################################################################################
                     [1m Learning iteration 1229/3000 [0m                     

                       Computation: 91588 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 1.0988
                    Surrogate loss: 0.0045
             Mean action noise std: 0.6275
                     Learning rate: 0.0001
                       Mean reward: 88.73
               Mean episode length: 959.88
       Episode_Reward/keep_balance: 0.9374
     Episode_Reward/rew_lin_vel_xy: 3.8759
      Episode_Reward/rew_ang_vel_z: 2.6728
    Episode_Reward/pen_base_height: -0.3213
      Episode_Reward/pen_lin_vel_z: -0.0573
     Episode_Reward/pen_ang_vel_xy: -0.1341
   Episode_Reward/pen_joint_torque: -0.1805
    Episode_Reward/pen_joint_accel: -0.0887
    Episode_Reward/pen_action_rate: -0.2794
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0371
   Episode_Reward/pen_joint_powers: -0.0610
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.6496
Episode_Reward/pen_flat_orientation: -0.1247
  Episode_Reward/pen_feet_distance: -0.0046
Episode_Reward/pen_feet_regulation: -0.2670
   Episode_Reward/foot_landing_vel: -0.1110
   Episode_Reward/test_gait_reward: -0.8541
Metrics/base_velocity/error_vel_xy: 2.0385
Metrics/base_velocity/error_vel_yaw: 0.9762
      Episode_Termination/time_out: 3.0000
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 1.07s
                        Total time: 1333.31s
                               ETA: 1919.7s

################################################################################
                     [1m Learning iteration 1230/3000 [0m                     

                       Computation: 91390 steps/s (collection: 0.951s, learning 0.125s)
               Value function loss: 0.9750
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6274
                     Learning rate: 0.0002
                       Mean reward: 92.09
               Mean episode length: 951.14
       Episode_Reward/keep_balance: 0.9647
     Episode_Reward/rew_lin_vel_xy: 4.1474
      Episode_Reward/rew_ang_vel_z: 2.7876
    Episode_Reward/pen_base_height: -0.3193
      Episode_Reward/pen_lin_vel_z: -0.0584
     Episode_Reward/pen_ang_vel_xy: -0.1386
   Episode_Reward/pen_joint_torque: -0.1869
    Episode_Reward/pen_joint_accel: -0.0798
    Episode_Reward/pen_action_rate: -0.2845
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0362
   Episode_Reward/pen_joint_powers: -0.0619
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6552
Episode_Reward/pen_flat_orientation: -0.1174
  Episode_Reward/pen_feet_distance: -0.0054
Episode_Reward/pen_feet_regulation: -0.2619
   Episode_Reward/foot_landing_vel: -0.1081
   Episode_Reward/test_gait_reward: -0.8781
Metrics/base_velocity/error_vel_xy: 1.9901
Metrics/base_velocity/error_vel_yaw: 0.9619
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 1.08s
                        Total time: 1334.38s
                               ETA: 1918.6s

################################################################################
                     [1m Learning iteration 1231/3000 [0m                     

                       Computation: 91265 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 1.0647
                    Surrogate loss: -0.0049
             Mean action noise std: 0.6279
                     Learning rate: 0.0004
                       Mean reward: 94.50
               Mean episode length: 981.43
       Episode_Reward/keep_balance: 0.9737
     Episode_Reward/rew_lin_vel_xy: 4.1701
      Episode_Reward/rew_ang_vel_z: 2.8067
    Episode_Reward/pen_base_height: -0.3302
      Episode_Reward/pen_lin_vel_z: -0.0600
     Episode_Reward/pen_ang_vel_xy: -0.1398
   Episode_Reward/pen_joint_torque: -0.1904
    Episode_Reward/pen_joint_accel: -0.0891
    Episode_Reward/pen_action_rate: -0.2901
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0376
   Episode_Reward/pen_joint_powers: -0.0638
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6653
Episode_Reward/pen_flat_orientation: -0.1206
  Episode_Reward/pen_feet_distance: -0.0055
Episode_Reward/pen_feet_regulation: -0.2767
   Episode_Reward/foot_landing_vel: -0.1119
   Episode_Reward/test_gait_reward: -0.8957
Metrics/base_velocity/error_vel_xy: 2.0079
Metrics/base_velocity/error_vel_yaw: 0.9747
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 1.08s
                        Total time: 1335.46s
                               ETA: 1917.6s

################################################################################
                     [1m Learning iteration 1232/3000 [0m                     

                       Computation: 91924 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.0981
                    Surrogate loss: -0.0049
             Mean action noise std: 0.6288
                     Learning rate: 0.0009
                       Mean reward: 87.92
               Mean episode length: 945.64
       Episode_Reward/keep_balance: 0.9445
     Episode_Reward/rew_lin_vel_xy: 3.8847
      Episode_Reward/rew_ang_vel_z: 2.6869
    Episode_Reward/pen_base_height: -0.3278
      Episode_Reward/pen_lin_vel_z: -0.0581
     Episode_Reward/pen_ang_vel_xy: -0.1405
   Episode_Reward/pen_joint_torque: -0.1824
    Episode_Reward/pen_joint_accel: -0.0835
    Episode_Reward/pen_action_rate: -0.2824
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0381
   Episode_Reward/pen_joint_powers: -0.0628
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6522
Episode_Reward/pen_flat_orientation: -0.1277
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.2763
   Episode_Reward/foot_landing_vel: -0.1079
   Episode_Reward/test_gait_reward: -0.8672
Metrics/base_velocity/error_vel_xy: 2.1227
Metrics/base_velocity/error_vel_yaw: 0.9769
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 1.07s
                        Total time: 1336.53s
                               ETA: 1916.5s

################################################################################
                     [1m Learning iteration 1233/3000 [0m                     

                       Computation: 92826 steps/s (collection: 0.936s, learning 0.123s)
               Value function loss: 1.1595
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6292
                     Learning rate: 0.0006
                       Mean reward: 88.97
               Mean episode length: 929.62
       Episode_Reward/keep_balance: 0.9255
     Episode_Reward/rew_lin_vel_xy: 3.9889
      Episode_Reward/rew_ang_vel_z: 2.7045
    Episode_Reward/pen_base_height: -0.3151
      Episode_Reward/pen_lin_vel_z: -0.0558
     Episode_Reward/pen_ang_vel_xy: -0.1369
   Episode_Reward/pen_joint_torque: -0.1771
    Episode_Reward/pen_joint_accel: -0.0755
    Episode_Reward/pen_action_rate: -0.2709
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0352
   Episode_Reward/pen_joint_powers: -0.0599
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6269
Episode_Reward/pen_flat_orientation: -0.1233
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.2563
   Episode_Reward/foot_landing_vel: -0.0972
   Episode_Reward/test_gait_reward: -0.8474
Metrics/base_velocity/error_vel_xy: 1.9217
Metrics/base_velocity/error_vel_yaw: 0.9021
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 1.06s
                        Total time: 1337.59s
                               ETA: 1915.3s

################################################################################
                     [1m Learning iteration 1234/3000 [0m                     

                       Computation: 92535 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 0.9760
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6288
                     Learning rate: 0.0006
                       Mean reward: 91.54
               Mean episode length: 948.33
       Episode_Reward/keep_balance: 0.9288
     Episode_Reward/rew_lin_vel_xy: 4.1307
      Episode_Reward/rew_ang_vel_z: 2.6134
    Episode_Reward/pen_base_height: -0.3318
      Episode_Reward/pen_lin_vel_z: -0.0608
     Episode_Reward/pen_ang_vel_xy: -0.1397
   Episode_Reward/pen_joint_torque: -0.1780
    Episode_Reward/pen_joint_accel: -0.0790
    Episode_Reward/pen_action_rate: -0.2810
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0377
   Episode_Reward/pen_joint_powers: -0.0624
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6454
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.2797
   Episode_Reward/foot_landing_vel: -0.1137
   Episode_Reward/test_gait_reward: -0.8598
Metrics/base_velocity/error_vel_xy: 1.8772
Metrics/base_velocity/error_vel_yaw: 0.9812
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 1.06s
                        Total time: 1338.65s
                               ETA: 1914.2s

################################################################################
                     [1m Learning iteration 1235/3000 [0m                     

                       Computation: 92006 steps/s (collection: 0.944s, learning 0.124s)
               Value function loss: 0.9402
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6285
                     Learning rate: 0.0004
                       Mean reward: 93.82
               Mean episode length: 985.11
       Episode_Reward/keep_balance: 0.9821
     Episode_Reward/rew_lin_vel_xy: 4.2184
      Episode_Reward/rew_ang_vel_z: 2.8043
    Episode_Reward/pen_base_height: -0.3237
      Episode_Reward/pen_lin_vel_z: -0.0580
     Episode_Reward/pen_ang_vel_xy: -0.1463
   Episode_Reward/pen_joint_torque: -0.1849
    Episode_Reward/pen_joint_accel: -0.0915
    Episode_Reward/pen_action_rate: -0.2923
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0388
   Episode_Reward/pen_joint_powers: -0.0636
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.6761
Episode_Reward/pen_flat_orientation: -0.1272
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.2719
   Episode_Reward/foot_landing_vel: -0.1147
   Episode_Reward/test_gait_reward: -0.8993
Metrics/base_velocity/error_vel_xy: 2.0231
Metrics/base_velocity/error_vel_yaw: 1.0082
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 1.07s
                        Total time: 1339.72s
                               ETA: 1913.1s

################################################################################
                     [1m Learning iteration 1236/3000 [0m                     

                       Computation: 91876 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.1044
                    Surrogate loss: -0.0037
             Mean action noise std: 0.6300
                     Learning rate: 0.0009
                       Mean reward: 88.78
               Mean episode length: 966.55
       Episode_Reward/keep_balance: 0.9710
     Episode_Reward/rew_lin_vel_xy: 4.0822
      Episode_Reward/rew_ang_vel_z: 2.7410
    Episode_Reward/pen_base_height: -0.3375
      Episode_Reward/pen_lin_vel_z: -0.0588
     Episode_Reward/pen_ang_vel_xy: -0.1504
   Episode_Reward/pen_joint_torque: -0.1847
    Episode_Reward/pen_joint_accel: -0.0868
    Episode_Reward/pen_action_rate: -0.2924
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0402
   Episode_Reward/pen_joint_powers: -0.0651
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6791
Episode_Reward/pen_flat_orientation: -0.1340
  Episode_Reward/pen_feet_distance: -0.0072
Episode_Reward/pen_feet_regulation: -0.2888
   Episode_Reward/foot_landing_vel: -0.1162
   Episode_Reward/test_gait_reward: -0.8954
Metrics/base_velocity/error_vel_xy: 2.0232
Metrics/base_velocity/error_vel_yaw: 1.0217
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 1.07s
                        Total time: 1340.79s
                               ETA: 1912.0s

################################################################################
                     [1m Learning iteration 1237/3000 [0m                     

                       Computation: 93442 steps/s (collection: 0.930s, learning 0.122s)
               Value function loss: 0.9840
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6301
                     Learning rate: 0.0004
                       Mean reward: 94.28
               Mean episode length: 987.87
       Episode_Reward/keep_balance: 0.9898
     Episode_Reward/rew_lin_vel_xy: 4.1203
      Episode_Reward/rew_ang_vel_z: 2.8379
    Episode_Reward/pen_base_height: -0.3225
      Episode_Reward/pen_lin_vel_z: -0.0578
     Episode_Reward/pen_ang_vel_xy: -0.1420
   Episode_Reward/pen_joint_torque: -0.1886
    Episode_Reward/pen_joint_accel: -0.0904
    Episode_Reward/pen_action_rate: -0.2922
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0389
   Episode_Reward/pen_joint_powers: -0.0640
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6811
Episode_Reward/pen_flat_orientation: -0.1215
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.2797
   Episode_Reward/foot_landing_vel: -0.1133
   Episode_Reward/test_gait_reward: -0.9068
Metrics/base_velocity/error_vel_xy: 2.1143
Metrics/base_velocity/error_vel_yaw: 1.0025
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 1.05s
                        Total time: 1341.84s
                               ETA: 1910.9s

################################################################################
                     [1m Learning iteration 1238/3000 [0m                     

                       Computation: 91876 steps/s (collection: 0.945s, learning 0.125s)
               Value function loss: 1.0395
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6297
                     Learning rate: 0.0009
                       Mean reward: 94.75
               Mean episode length: 981.47
       Episode_Reward/keep_balance: 0.9875
     Episode_Reward/rew_lin_vel_xy: 4.3327
      Episode_Reward/rew_ang_vel_z: 2.8015
    Episode_Reward/pen_base_height: -0.3218
      Episode_Reward/pen_lin_vel_z: -0.0565
     Episode_Reward/pen_ang_vel_xy: -0.1374
   Episode_Reward/pen_joint_torque: -0.1812
    Episode_Reward/pen_joint_accel: -0.0863
    Episode_Reward/pen_action_rate: -0.2891
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0376
   Episode_Reward/pen_joint_powers: -0.0623
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6791
Episode_Reward/pen_flat_orientation: -0.1252
  Episode_Reward/pen_feet_distance: -0.0052
Episode_Reward/pen_feet_regulation: -0.2723
   Episode_Reward/foot_landing_vel: -0.1091
   Episode_Reward/test_gait_reward: -0.9009
Metrics/base_velocity/error_vel_xy: 1.9795
Metrics/base_velocity/error_vel_yaw: 1.0225
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 1.07s
                        Total time: 1342.91s
                               ETA: 1909.8s

################################################################################
                     [1m Learning iteration 1239/3000 [0m                     

                       Computation: 92154 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 1.0449
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6290
                     Learning rate: 0.0009
                       Mean reward: 94.27
               Mean episode length: 972.39
       Episode_Reward/keep_balance: 0.9544
     Episode_Reward/rew_lin_vel_xy: 4.2063
      Episode_Reward/rew_ang_vel_z: 2.7377
    Episode_Reward/pen_base_height: -0.3311
      Episode_Reward/pen_lin_vel_z: -0.0599
     Episode_Reward/pen_ang_vel_xy: -0.1355
   Episode_Reward/pen_joint_torque: -0.1832
    Episode_Reward/pen_joint_accel: -0.0901
    Episode_Reward/pen_action_rate: -0.2872
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0377
   Episode_Reward/pen_joint_powers: -0.0628
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6585
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0084
Episode_Reward/pen_feet_regulation: -0.2844
   Episode_Reward/foot_landing_vel: -0.1122
   Episode_Reward/test_gait_reward: -0.8786
Metrics/base_velocity/error_vel_xy: 1.9080
Metrics/base_velocity/error_vel_yaw: 0.9712
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 1.07s
                        Total time: 1343.98s
                               ETA: 1908.7s

################################################################################
                     [1m Learning iteration 1240/3000 [0m                     

                       Computation: 91705 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 1.0163
                    Surrogate loss: 0.0001
             Mean action noise std: 0.6287
                     Learning rate: 0.0003
                       Mean reward: 92.76
               Mean episode length: 957.56
       Episode_Reward/keep_balance: 0.9678
     Episode_Reward/rew_lin_vel_xy: 4.2848
      Episode_Reward/rew_ang_vel_z: 2.7724
    Episode_Reward/pen_base_height: -0.3315
      Episode_Reward/pen_lin_vel_z: -0.0628
     Episode_Reward/pen_ang_vel_xy: -0.1416
   Episode_Reward/pen_joint_torque: -0.1891
    Episode_Reward/pen_joint_accel: -0.0885
    Episode_Reward/pen_action_rate: -0.2914
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0385
   Episode_Reward/pen_joint_powers: -0.0653
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6680
Episode_Reward/pen_flat_orientation: -0.1220
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.2867
   Episode_Reward/foot_landing_vel: -0.1151
   Episode_Reward/test_gait_reward: -0.8881
Metrics/base_velocity/error_vel_xy: 1.9454
Metrics/base_velocity/error_vel_yaw: 0.9831
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 1.07s
                        Total time: 1345.05s
                               ETA: 1907.6s

################################################################################
                     [1m Learning iteration 1241/3000 [0m                     

                       Computation: 92258 steps/s (collection: 0.939s, learning 0.127s)
               Value function loss: 0.9676
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6289
                     Learning rate: 0.0006
                       Mean reward: 97.86
               Mean episode length: 983.80
       Episode_Reward/keep_balance: 0.9838
     Episode_Reward/rew_lin_vel_xy: 4.4391
      Episode_Reward/rew_ang_vel_z: 2.8068
    Episode_Reward/pen_base_height: -0.3294
      Episode_Reward/pen_lin_vel_z: -0.0581
     Episode_Reward/pen_ang_vel_xy: -0.1449
   Episode_Reward/pen_joint_torque: -0.1848
    Episode_Reward/pen_joint_accel: -0.0887
    Episode_Reward/pen_action_rate: -0.2942
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0386
   Episode_Reward/pen_joint_powers: -0.0635
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6844
Episode_Reward/pen_flat_orientation: -0.1234
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.2751
   Episode_Reward/foot_landing_vel: -0.1158
   Episode_Reward/test_gait_reward: -0.9013
Metrics/base_velocity/error_vel_xy: 1.8597
Metrics/base_velocity/error_vel_yaw: 1.0113
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 1.07s
                        Total time: 1346.12s
                               ETA: 1906.5s

################################################################################
                     [1m Learning iteration 1242/3000 [0m                     

                       Computation: 90976 steps/s (collection: 0.956s, learning 0.125s)
               Value function loss: 1.0483
                    Surrogate loss: -0.0037
             Mean action noise std: 0.6286
                     Learning rate: 0.0009
                       Mean reward: 93.79
               Mean episode length: 974.25
       Episode_Reward/keep_balance: 0.9723
     Episode_Reward/rew_lin_vel_xy: 4.1241
      Episode_Reward/rew_ang_vel_z: 2.8341
    Episode_Reward/pen_base_height: -0.3218
      Episode_Reward/pen_lin_vel_z: -0.0594
     Episode_Reward/pen_ang_vel_xy: -0.1378
   Episode_Reward/pen_joint_torque: -0.1862
    Episode_Reward/pen_joint_accel: -0.0814
    Episode_Reward/pen_action_rate: -0.2880
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0378
   Episode_Reward/pen_joint_powers: -0.0637
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6646
Episode_Reward/pen_flat_orientation: -0.1217
  Episode_Reward/pen_feet_distance: -0.0058
Episode_Reward/pen_feet_regulation: -0.2902
   Episode_Reward/foot_landing_vel: -0.1104
   Episode_Reward/test_gait_reward: -0.8883
Metrics/base_velocity/error_vel_xy: 2.0788
Metrics/base_velocity/error_vel_yaw: 0.9507
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 1.08s
                        Total time: 1347.20s
                               ETA: 1905.4s

################################################################################
                     [1m Learning iteration 1243/3000 [0m                     

                       Computation: 91271 steps/s (collection: 0.950s, learning 0.127s)
               Value function loss: 1.0664
                    Surrogate loss: -0.0036
             Mean action noise std: 0.6272
                     Learning rate: 0.0013
                       Mean reward: 89.57
               Mean episode length: 958.31
       Episode_Reward/keep_balance: 0.9472
     Episode_Reward/rew_lin_vel_xy: 3.9333
      Episode_Reward/rew_ang_vel_z: 2.7171
    Episode_Reward/pen_base_height: -0.3257
      Episode_Reward/pen_lin_vel_z: -0.0592
     Episode_Reward/pen_ang_vel_xy: -0.1360
   Episode_Reward/pen_joint_torque: -0.1834
    Episode_Reward/pen_joint_accel: -0.0811
    Episode_Reward/pen_action_rate: -0.2868
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0373
   Episode_Reward/pen_joint_powers: -0.0629
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6556
Episode_Reward/pen_flat_orientation: -0.1276
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.2730
   Episode_Reward/foot_landing_vel: -0.1072
   Episode_Reward/test_gait_reward: -0.8693
Metrics/base_velocity/error_vel_xy: 2.0292
Metrics/base_velocity/error_vel_yaw: 0.9721
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 1.08s
                        Total time: 1348.27s
                               ETA: 1904.3s

################################################################################
                     [1m Learning iteration 1244/3000 [0m                     

                       Computation: 91958 steps/s (collection: 0.945s, learning 0.124s)
               Value function loss: 1.1094
                    Surrogate loss: -0.0012
             Mean action noise std: 0.6277
                     Learning rate: 0.0009
                       Mean reward: 90.90
               Mean episode length: 965.22
       Episode_Reward/keep_balance: 0.9753
     Episode_Reward/rew_lin_vel_xy: 4.2288
      Episode_Reward/rew_ang_vel_z: 2.7982
    Episode_Reward/pen_base_height: -0.3224
      Episode_Reward/pen_lin_vel_z: -0.0567
     Episode_Reward/pen_ang_vel_xy: -0.1354
   Episode_Reward/pen_joint_torque: -0.1906
    Episode_Reward/pen_joint_accel: -0.0912
    Episode_Reward/pen_action_rate: -0.2887
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0370
   Episode_Reward/pen_joint_powers: -0.0632
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6709
Episode_Reward/pen_flat_orientation: -0.1196
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.2742
   Episode_Reward/foot_landing_vel: -0.1077
   Episode_Reward/test_gait_reward: -0.8938
Metrics/base_velocity/error_vel_xy: 2.0200
Metrics/base_velocity/error_vel_yaw: 0.9857
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 1.07s
                        Total time: 1349.34s
                               ETA: 1903.2s

################################################################################
                     [1m Learning iteration 1245/3000 [0m                     

                       Computation: 90425 steps/s (collection: 0.960s, learning 0.127s)
               Value function loss: 1.0533
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6278
                     Learning rate: 0.0006
                       Mean reward: 84.62
               Mean episode length: 935.95
       Episode_Reward/keep_balance: 0.9451
     Episode_Reward/rew_lin_vel_xy: 3.8778
      Episode_Reward/rew_ang_vel_z: 2.7132
    Episode_Reward/pen_base_height: -0.3296
      Episode_Reward/pen_lin_vel_z: -0.0597
     Episode_Reward/pen_ang_vel_xy: -0.1368
   Episode_Reward/pen_joint_torque: -0.1896
    Episode_Reward/pen_joint_accel: -0.0819
    Episode_Reward/pen_action_rate: -0.2857
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0381
   Episode_Reward/pen_joint_powers: -0.0641
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6517
Episode_Reward/pen_flat_orientation: -0.1231
  Episode_Reward/pen_feet_distance: -0.0082
Episode_Reward/pen_feet_regulation: -0.2826
   Episode_Reward/foot_landing_vel: -0.1096
   Episode_Reward/test_gait_reward: -0.8667
Metrics/base_velocity/error_vel_xy: 2.1432
Metrics/base_velocity/error_vel_yaw: 0.9538
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 1.09s
                        Total time: 1350.43s
                               ETA: 1902.1s

################################################################################
                     [1m Learning iteration 1246/3000 [0m                     

                       Computation: 92876 steps/s (collection: 0.936s, learning 0.123s)
               Value function loss: 1.0173
                    Surrogate loss: -0.0031
             Mean action noise std: 0.6277
                     Learning rate: 0.0013
                       Mean reward: 94.98
               Mean episode length: 995.28
       Episode_Reward/keep_balance: 0.9928
     Episode_Reward/rew_lin_vel_xy: 4.3018
      Episode_Reward/rew_ang_vel_z: 2.8293
    Episode_Reward/pen_base_height: -0.3359
      Episode_Reward/pen_lin_vel_z: -0.0618
     Episode_Reward/pen_ang_vel_xy: -0.1490
   Episode_Reward/pen_joint_torque: -0.1912
    Episode_Reward/pen_joint_accel: -0.0904
    Episode_Reward/pen_action_rate: -0.3023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0401
   Episode_Reward/pen_joint_powers: -0.0666
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6937
Episode_Reward/pen_flat_orientation: -0.1279
  Episode_Reward/pen_feet_distance: -0.0077
Episode_Reward/pen_feet_regulation: -0.3019
   Episode_Reward/foot_landing_vel: -0.1104
   Episode_Reward/test_gait_reward: -0.9146
Metrics/base_velocity/error_vel_xy: 2.0534
Metrics/base_velocity/error_vel_yaw: 1.0195
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 1.06s
                        Total time: 1351.49s
                               ETA: 1901.0s

################################################################################
                     [1m Learning iteration 1247/3000 [0m                     

                       Computation: 90054 steps/s (collection: 0.967s, learning 0.125s)
               Value function loss: 1.0207
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6283
                     Learning rate: 0.0013
                       Mean reward: 94.34
               Mean episode length: 980.58
       Episode_Reward/keep_balance: 0.9892
     Episode_Reward/rew_lin_vel_xy: 4.2142
      Episode_Reward/rew_ang_vel_z: 2.8231
    Episode_Reward/pen_base_height: -0.3158
      Episode_Reward/pen_lin_vel_z: -0.0587
     Episode_Reward/pen_ang_vel_xy: -0.1424
   Episode_Reward/pen_joint_torque: -0.1882
    Episode_Reward/pen_joint_accel: -0.0988
    Episode_Reward/pen_action_rate: -0.2963
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0391
   Episode_Reward/pen_joint_powers: -0.0646
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6867
Episode_Reward/pen_flat_orientation: -0.1213
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.2779
   Episode_Reward/foot_landing_vel: -0.1191
   Episode_Reward/test_gait_reward: -0.8969
Metrics/base_velocity/error_vel_xy: 2.0817
Metrics/base_velocity/error_vel_yaw: 1.0130
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 1.09s
                        Total time: 1352.58s
                               ETA: 1899.9s

################################################################################
                     [1m Learning iteration 1248/3000 [0m                     

                       Computation: 90351 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 1.2013
                    Surrogate loss: -0.0035
             Mean action noise std: 0.6284
                     Learning rate: 0.0019
                       Mean reward: 89.48
               Mean episode length: 970.88
       Episode_Reward/keep_balance: 0.9721
     Episode_Reward/rew_lin_vel_xy: 4.0498
      Episode_Reward/rew_ang_vel_z: 2.7671
    Episode_Reward/pen_base_height: -0.3345
      Episode_Reward/pen_lin_vel_z: -0.0563
     Episode_Reward/pen_ang_vel_xy: -0.1413
   Episode_Reward/pen_joint_torque: -0.1859
    Episode_Reward/pen_joint_accel: -0.0775
    Episode_Reward/pen_action_rate: -0.2915
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0381
   Episode_Reward/pen_joint_powers: -0.0635
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6704
Episode_Reward/pen_flat_orientation: -0.1351
  Episode_Reward/pen_feet_distance: -0.0084
Episode_Reward/pen_feet_regulation: -0.2844
   Episode_Reward/foot_landing_vel: -0.1082
   Episode_Reward/test_gait_reward: -0.8836
Metrics/base_velocity/error_vel_xy: 2.0349
Metrics/base_velocity/error_vel_yaw: 1.0023
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 1.09s
                        Total time: 1353.67s
                               ETA: 1898.8s

################################################################################
                     [1m Learning iteration 1249/3000 [0m                     

                       Computation: 88456 steps/s (collection: 0.986s, learning 0.125s)
               Value function loss: 1.1122
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6287
                     Learning rate: 0.0006
                       Mean reward: 92.81
               Mean episode length: 949.00
       Episode_Reward/keep_balance: 0.8834
     Episode_Reward/rew_lin_vel_xy: 3.9113
      Episode_Reward/rew_ang_vel_z: 2.5156
    Episode_Reward/pen_base_height: -0.3104
      Episode_Reward/pen_lin_vel_z: -0.0530
     Episode_Reward/pen_ang_vel_xy: -0.1309
   Episode_Reward/pen_joint_torque: -0.1692
    Episode_Reward/pen_joint_accel: -0.0775
    Episode_Reward/pen_action_rate: -0.2687
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0354
   Episode_Reward/pen_joint_powers: -0.0587
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6221
Episode_Reward/pen_flat_orientation: -0.1277
  Episode_Reward/pen_feet_distance: -0.0075
Episode_Reward/pen_feet_regulation: -0.2639
   Episode_Reward/foot_landing_vel: -0.1001
   Episode_Reward/test_gait_reward: -0.8116
Metrics/base_velocity/error_vel_xy: 1.7477
Metrics/base_velocity/error_vel_yaw: 0.9145
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 1.11s
                        Total time: 1354.78s
                               ETA: 1897.8s

################################################################################
                     [1m Learning iteration 1250/3000 [0m                     

                       Computation: 90830 steps/s (collection: 0.958s, learning 0.125s)
               Value function loss: 0.9952
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6297
                     Learning rate: 0.0006
                       Mean reward: 98.35
               Mean episode length: 974.41
       Episode_Reward/keep_balance: 0.9861
     Episode_Reward/rew_lin_vel_xy: 4.4508
      Episode_Reward/rew_ang_vel_z: 2.8103
    Episode_Reward/pen_base_height: -0.3142
      Episode_Reward/pen_lin_vel_z: -0.0548
     Episode_Reward/pen_ang_vel_xy: -0.1326
   Episode_Reward/pen_joint_torque: -0.1810
    Episode_Reward/pen_joint_accel: -0.0824
    Episode_Reward/pen_action_rate: -0.2919
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0375
   Episode_Reward/pen_joint_powers: -0.0624
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6866
Episode_Reward/pen_flat_orientation: -0.1193
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.2826
   Episode_Reward/foot_landing_vel: -0.1023
   Episode_Reward/test_gait_reward: -0.8999
Metrics/base_velocity/error_vel_xy: 1.9155
Metrics/base_velocity/error_vel_yaw: 1.0120
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 1.08s
                        Total time: 1355.86s
                               ETA: 1896.7s

################################################################################
                     [1m Learning iteration 1251/3000 [0m                     

                       Computation: 91413 steps/s (collection: 0.950s, learning 0.125s)
               Value function loss: 0.9791
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6293
                     Learning rate: 0.0006
                       Mean reward: 97.38
               Mean episode length: 963.26
       Episode_Reward/keep_balance: 0.9690
     Episode_Reward/rew_lin_vel_xy: 4.2215
      Episode_Reward/rew_ang_vel_z: 2.7742
    Episode_Reward/pen_base_height: -0.3246
      Episode_Reward/pen_lin_vel_z: -0.0565
     Episode_Reward/pen_ang_vel_xy: -0.1382
   Episode_Reward/pen_joint_torque: -0.1829
    Episode_Reward/pen_joint_accel: -0.0848
    Episode_Reward/pen_action_rate: -0.2896
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0371
   Episode_Reward/pen_joint_powers: -0.0623
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6669
Episode_Reward/pen_flat_orientation: -0.1281
  Episode_Reward/pen_feet_distance: -0.0130
Episode_Reward/pen_feet_regulation: -0.2736
   Episode_Reward/foot_landing_vel: -0.1068
   Episode_Reward/test_gait_reward: -0.8831
Metrics/base_velocity/error_vel_xy: 1.9765
Metrics/base_velocity/error_vel_yaw: 0.9895
      Episode_Termination/time_out: 5.0417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 1.08s
                        Total time: 1356.94s
                               ETA: 1895.6s

################################################################################
                     [1m Learning iteration 1252/3000 [0m                     

                       Computation: 90963 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 1.0411
                    Surrogate loss: -0.0010
             Mean action noise std: 0.6290
                     Learning rate: 0.0004
                       Mean reward: 93.66
               Mean episode length: 978.28
       Episode_Reward/keep_balance: 0.9774
     Episode_Reward/rew_lin_vel_xy: 4.2422
      Episode_Reward/rew_ang_vel_z: 2.8021
    Episode_Reward/pen_base_height: -0.3148
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1391
   Episode_Reward/pen_joint_torque: -0.1834
    Episode_Reward/pen_joint_accel: -0.0816
    Episode_Reward/pen_action_rate: -0.2921
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0371
   Episode_Reward/pen_joint_powers: -0.0624
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6745
Episode_Reward/pen_flat_orientation: -0.1176
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.2690
   Episode_Reward/foot_landing_vel: -0.1070
   Episode_Reward/test_gait_reward: -0.8910
Metrics/base_velocity/error_vel_xy: 1.9849
Metrics/base_velocity/error_vel_yaw: 0.9887
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 1.08s
                        Total time: 1358.02s
                               ETA: 1894.5s

################################################################################
                     [1m Learning iteration 1253/3000 [0m                     

                       Computation: 92950 steps/s (collection: 0.933s, learning 0.125s)
               Value function loss: 0.9841
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6295
                     Learning rate: 0.0009
                       Mean reward: 92.88
               Mean episode length: 973.52
       Episode_Reward/keep_balance: 0.9799
     Episode_Reward/rew_lin_vel_xy: 4.1888
      Episode_Reward/rew_ang_vel_z: 2.7718
    Episode_Reward/pen_base_height: -0.3282
      Episode_Reward/pen_lin_vel_z: -0.0564
     Episode_Reward/pen_ang_vel_xy: -0.1372
   Episode_Reward/pen_joint_torque: -0.1890
    Episode_Reward/pen_joint_accel: -0.0852
    Episode_Reward/pen_action_rate: -0.2913
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0379
   Episode_Reward/pen_joint_powers: -0.0643
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6777
Episode_Reward/pen_flat_orientation: -0.1209
  Episode_Reward/pen_feet_distance: -0.0054
Episode_Reward/pen_feet_regulation: -0.2841
   Episode_Reward/foot_landing_vel: -0.1045
   Episode_Reward/test_gait_reward: -0.8915
Metrics/base_velocity/error_vel_xy: 2.0380
Metrics/base_velocity/error_vel_yaw: 1.0180
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 1.06s
                        Total time: 1359.07s
                               ETA: 1893.4s

################################################################################
                     [1m Learning iteration 1254/3000 [0m                     

                       Computation: 90774 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 1.0198
                    Surrogate loss: -0.0042
             Mean action noise std: 0.6294
                     Learning rate: 0.0006
                       Mean reward: 92.65
               Mean episode length: 971.35
       Episode_Reward/keep_balance: 0.9744
     Episode_Reward/rew_lin_vel_xy: 4.1895
      Episode_Reward/rew_ang_vel_z: 2.7813
    Episode_Reward/pen_base_height: -0.3220
      Episode_Reward/pen_lin_vel_z: -0.0581
     Episode_Reward/pen_ang_vel_xy: -0.1413
   Episode_Reward/pen_joint_torque: -0.1834
    Episode_Reward/pen_joint_accel: -0.0861
    Episode_Reward/pen_action_rate: -0.2966
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0386
   Episode_Reward/pen_joint_powers: -0.0638
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6843
Episode_Reward/pen_flat_orientation: -0.1233
  Episode_Reward/pen_feet_distance: -0.0065
Episode_Reward/pen_feet_regulation: -0.2921
   Episode_Reward/foot_landing_vel: -0.1105
   Episode_Reward/test_gait_reward: -0.8973
Metrics/base_velocity/error_vel_xy: 1.9743
Metrics/base_velocity/error_vel_yaw: 0.9962
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 1.08s
                        Total time: 1360.16s
                               ETA: 1892.3s

################################################################################
                     [1m Learning iteration 1255/3000 [0m                     

                       Computation: 91710 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 1.0789
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6294
                     Learning rate: 0.0006
                       Mean reward: 95.20
               Mean episode length: 946.20
       Episode_Reward/keep_balance: 0.9210
     Episode_Reward/rew_lin_vel_xy: 4.2388
      Episode_Reward/rew_ang_vel_z: 2.6489
    Episode_Reward/pen_base_height: -0.3221
      Episode_Reward/pen_lin_vel_z: -0.0558
     Episode_Reward/pen_ang_vel_xy: -0.1320
   Episode_Reward/pen_joint_torque: -0.1804
    Episode_Reward/pen_joint_accel: -0.0829
    Episode_Reward/pen_action_rate: -0.2776
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0359
   Episode_Reward/pen_joint_powers: -0.0611
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6368
Episode_Reward/pen_flat_orientation: -0.1230
  Episode_Reward/pen_feet_distance: -0.0113
Episode_Reward/pen_feet_regulation: -0.2699
   Episode_Reward/foot_landing_vel: -0.1006
   Episode_Reward/test_gait_reward: -0.8450
Metrics/base_velocity/error_vel_xy: 1.7324
Metrics/base_velocity/error_vel_yaw: 0.9322
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 1.07s
                        Total time: 1361.23s
                               ETA: 1891.2s

################################################################################
                     [1m Learning iteration 1256/3000 [0m                     

                       Computation: 87684 steps/s (collection: 0.996s, learning 0.125s)
               Value function loss: 1.0027
                    Surrogate loss: -0.0044
             Mean action noise std: 0.6286
                     Learning rate: 0.0013
                       Mean reward: 92.35
               Mean episode length: 947.02
       Episode_Reward/keep_balance: 0.9169
     Episode_Reward/rew_lin_vel_xy: 4.0113
      Episode_Reward/rew_ang_vel_z: 2.5789
    Episode_Reward/pen_base_height: -0.3166
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1411
   Episode_Reward/pen_joint_torque: -0.1769
    Episode_Reward/pen_joint_accel: -0.0783
    Episode_Reward/pen_action_rate: -0.2824
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0376
   Episode_Reward/pen_joint_powers: -0.0623
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6514
Episode_Reward/pen_flat_orientation: -0.1241
  Episode_Reward/pen_feet_distance: -0.0096
Episode_Reward/pen_feet_regulation: -0.2849
   Episode_Reward/foot_landing_vel: -0.1011
   Episode_Reward/test_gait_reward: -0.8408
Metrics/base_velocity/error_vel_xy: 1.8853
Metrics/base_velocity/error_vel_yaw: 0.9761
      Episode_Termination/time_out: 3.1250
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 1.12s
                        Total time: 1362.35s
                               ETA: 1890.2s

################################################################################
                     [1m Learning iteration 1257/3000 [0m                     

                       Computation: 91238 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 1.1332
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6285
                     Learning rate: 0.0003
                       Mean reward: 95.79
               Mean episode length: 961.70
       Episode_Reward/keep_balance: 0.9757
     Episode_Reward/rew_lin_vel_xy: 4.2435
      Episode_Reward/rew_ang_vel_z: 2.7967
    Episode_Reward/pen_base_height: -0.3179
      Episode_Reward/pen_lin_vel_z: -0.0569
     Episode_Reward/pen_ang_vel_xy: -0.1380
   Episode_Reward/pen_joint_torque: -0.1847
    Episode_Reward/pen_joint_accel: -0.0804
    Episode_Reward/pen_action_rate: -0.2924
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0377
   Episode_Reward/pen_joint_powers: -0.0630
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6764
Episode_Reward/pen_flat_orientation: -0.1250
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.2810
   Episode_Reward/foot_landing_vel: -0.1082
   Episode_Reward/test_gait_reward: -0.8879
Metrics/base_velocity/error_vel_xy: 2.0238
Metrics/base_velocity/error_vel_yaw: 0.9896
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 1.08s
                        Total time: 1363.43s
                               ETA: 1889.1s

################################################################################
                     [1m Learning iteration 1258/3000 [0m                     

                       Computation: 91776 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 1.0011
                    Surrogate loss: -0.0036
             Mean action noise std: 0.6286
                     Learning rate: 0.0004
                       Mean reward: 87.93
               Mean episode length: 945.46
       Episode_Reward/keep_balance: 0.9424
     Episode_Reward/rew_lin_vel_xy: 3.9564
      Episode_Reward/rew_ang_vel_z: 2.6810
    Episode_Reward/pen_base_height: -0.3222
      Episode_Reward/pen_lin_vel_z: -0.0559
     Episode_Reward/pen_ang_vel_xy: -0.1396
   Episode_Reward/pen_joint_torque: -0.1849
    Episode_Reward/pen_joint_accel: -0.0823
    Episode_Reward/pen_action_rate: -0.2906
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0379
   Episode_Reward/pen_joint_powers: -0.0633
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6601
Episode_Reward/pen_flat_orientation: -0.1207
  Episode_Reward/pen_feet_distance: -0.0084
Episode_Reward/pen_feet_regulation: -0.2825
   Episode_Reward/foot_landing_vel: -0.1090
   Episode_Reward/test_gait_reward: -0.8620
Metrics/base_velocity/error_vel_xy: 2.0311
Metrics/base_velocity/error_vel_yaw: 0.9730
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 1.07s
                        Total time: 1364.50s
                               ETA: 1888.0s

################################################################################
                     [1m Learning iteration 1259/3000 [0m                     

                       Computation: 90192 steps/s (collection: 0.964s, learning 0.126s)
               Value function loss: 1.0023
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6286
                     Learning rate: 0.0003
                       Mean reward: 93.72
               Mean episode length: 990.77
       Episode_Reward/keep_balance: 0.9935
     Episode_Reward/rew_lin_vel_xy: 4.1770
      Episode_Reward/rew_ang_vel_z: 2.8135
    Episode_Reward/pen_base_height: -0.3204
      Episode_Reward/pen_lin_vel_z: -0.0588
     Episode_Reward/pen_ang_vel_xy: -0.1462
   Episode_Reward/pen_joint_torque: -0.1860
    Episode_Reward/pen_joint_accel: -0.0911
    Episode_Reward/pen_action_rate: -0.3017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0389
   Episode_Reward/pen_joint_powers: -0.0644
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7063
Episode_Reward/pen_flat_orientation: -0.1225
  Episode_Reward/pen_feet_distance: -0.0079
Episode_Reward/pen_feet_regulation: -0.2924
   Episode_Reward/foot_landing_vel: -0.1125
   Episode_Reward/test_gait_reward: -0.9041
Metrics/base_velocity/error_vel_xy: 2.1592
Metrics/base_velocity/error_vel_yaw: 1.0339
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 1.09s
                        Total time: 1365.59s
                               ETA: 1886.9s

################################################################################
                     [1m Learning iteration 1260/3000 [0m                     

                       Computation: 90185 steps/s (collection: 0.965s, learning 0.125s)
               Value function loss: 0.9784
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6293
                     Learning rate: 0.0006
                       Mean reward: 94.55
               Mean episode length: 963.24
       Episode_Reward/keep_balance: 0.9459
     Episode_Reward/rew_lin_vel_xy: 4.0450
      Episode_Reward/rew_ang_vel_z: 2.7002
    Episode_Reward/pen_base_height: -0.3123
      Episode_Reward/pen_lin_vel_z: -0.0543
     Episode_Reward/pen_ang_vel_xy: -0.1346
   Episode_Reward/pen_joint_torque: -0.1810
    Episode_Reward/pen_joint_accel: -0.0749
    Episode_Reward/pen_action_rate: -0.2861
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0358
   Episode_Reward/pen_joint_powers: -0.0608
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6644
Episode_Reward/pen_flat_orientation: -0.1193
  Episode_Reward/pen_feet_distance: -0.0064
Episode_Reward/pen_feet_regulation: -0.2583
   Episode_Reward/foot_landing_vel: -0.0969
   Episode_Reward/test_gait_reward: -0.8594
Metrics/base_velocity/error_vel_xy: 1.9790
Metrics/base_velocity/error_vel_yaw: 0.9717
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 1.09s
                        Total time: 1366.68s
                               ETA: 1885.8s

################################################################################
                     [1m Learning iteration 1261/3000 [0m                     

                       Computation: 91182 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.9932
                    Surrogate loss: -0.0039
             Mean action noise std: 0.6315
                     Learning rate: 0.0009
                       Mean reward: 92.50
               Mean episode length: 966.61
       Episode_Reward/keep_balance: 0.9620
     Episode_Reward/rew_lin_vel_xy: 4.2971
      Episode_Reward/rew_ang_vel_z: 2.7281
    Episode_Reward/pen_base_height: -0.3252
      Episode_Reward/pen_lin_vel_z: -0.0598
     Episode_Reward/pen_ang_vel_xy: -0.1384
   Episode_Reward/pen_joint_torque: -0.1907
    Episode_Reward/pen_joint_accel: -0.0926
    Episode_Reward/pen_action_rate: -0.2940
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0395
   Episode_Reward/pen_joint_powers: -0.0656
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6746
Episode_Reward/pen_flat_orientation: -0.1225
  Episode_Reward/pen_feet_distance: -0.0064
Episode_Reward/pen_feet_regulation: -0.2951
   Episode_Reward/foot_landing_vel: -0.1117
   Episode_Reward/test_gait_reward: -0.8857
Metrics/base_velocity/error_vel_xy: 1.8907
Metrics/base_velocity/error_vel_yaw: 1.0058
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 1.08s
                        Total time: 1367.76s
                               ETA: 1884.7s

################################################################################
                     [1m Learning iteration 1262/3000 [0m                     

                       Computation: 90262 steps/s (collection: 0.962s, learning 0.127s)
               Value function loss: 0.9942
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6319
                     Learning rate: 0.0004
                       Mean reward: 95.54
               Mean episode length: 974.31
       Episode_Reward/keep_balance: 0.9662
     Episode_Reward/rew_lin_vel_xy: 4.1600
      Episode_Reward/rew_ang_vel_z: 2.7641
    Episode_Reward/pen_base_height: -0.3088
      Episode_Reward/pen_lin_vel_z: -0.0555
     Episode_Reward/pen_ang_vel_xy: -0.1346
   Episode_Reward/pen_joint_torque: -0.1874
    Episode_Reward/pen_joint_accel: -0.0815
    Episode_Reward/pen_action_rate: -0.2888
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0369
   Episode_Reward/pen_joint_powers: -0.0631
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6692
Episode_Reward/pen_flat_orientation: -0.1144
  Episode_Reward/pen_feet_distance: -0.0110
Episode_Reward/pen_feet_regulation: -0.2697
   Episode_Reward/foot_landing_vel: -0.1076
   Episode_Reward/test_gait_reward: -0.8716
Metrics/base_velocity/error_vel_xy: 2.0581
Metrics/base_velocity/error_vel_yaw: 0.9796
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 1.09s
                        Total time: 1368.85s
                               ETA: 1883.7s

################################################################################
                     [1m Learning iteration 1263/3000 [0m                     

                       Computation: 90803 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 1.0347
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6319
                     Learning rate: 0.0002
                       Mean reward: 94.09
               Mean episode length: 953.26
       Episode_Reward/keep_balance: 0.9577
     Episode_Reward/rew_lin_vel_xy: 4.2819
      Episode_Reward/rew_ang_vel_z: 2.7133
    Episode_Reward/pen_base_height: -0.3031
      Episode_Reward/pen_lin_vel_z: -0.0531
     Episode_Reward/pen_ang_vel_xy: -0.1351
   Episode_Reward/pen_joint_torque: -0.1777
    Episode_Reward/pen_joint_accel: -0.0804
    Episode_Reward/pen_action_rate: -0.2857
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0362
   Episode_Reward/pen_joint_powers: -0.0611
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6679
Episode_Reward/pen_flat_orientation: -0.1153
  Episode_Reward/pen_feet_distance: -0.0084
Episode_Reward/pen_feet_regulation: -0.2627
   Episode_Reward/foot_landing_vel: -0.0976
   Episode_Reward/test_gait_reward: -0.8686
Metrics/base_velocity/error_vel_xy: 1.9606
Metrics/base_velocity/error_vel_yaw: 1.0005
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 1.08s
                        Total time: 1369.93s
                               ETA: 1882.6s

################################################################################
                     [1m Learning iteration 1264/3000 [0m                     

                       Computation: 90941 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 1.0403
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6319
                     Learning rate: 0.0002
                       Mean reward: 95.65
               Mean episode length: 970.97
       Episode_Reward/keep_balance: 0.9665
     Episode_Reward/rew_lin_vel_xy: 4.3183
      Episode_Reward/rew_ang_vel_z: 2.7573
    Episode_Reward/pen_base_height: -0.3175
      Episode_Reward/pen_lin_vel_z: -0.0558
     Episode_Reward/pen_ang_vel_xy: -0.1382
   Episode_Reward/pen_joint_torque: -0.1845
    Episode_Reward/pen_joint_accel: -0.0851
    Episode_Reward/pen_action_rate: -0.2973
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0388
   Episode_Reward/pen_joint_powers: -0.0637
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6878
Episode_Reward/pen_flat_orientation: -0.1159
  Episode_Reward/pen_feet_distance: -0.0117
Episode_Reward/pen_feet_regulation: -0.2910
   Episode_Reward/foot_landing_vel: -0.1102
   Episode_Reward/test_gait_reward: -0.8885
Metrics/base_velocity/error_vel_xy: 1.9254
Metrics/base_velocity/error_vel_yaw: 0.9876
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 1.08s
                        Total time: 1371.01s
                               ETA: 1881.5s

################################################################################
                     [1m Learning iteration 1265/3000 [0m                     

                       Computation: 90466 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.9907
                    Surrogate loss: -0.0038
             Mean action noise std: 0.6325
                     Learning rate: 0.0004
                       Mean reward: 89.91
               Mean episode length: 960.90
       Episode_Reward/keep_balance: 0.9790
     Episode_Reward/rew_lin_vel_xy: 4.0046
      Episode_Reward/rew_ang_vel_z: 2.7930
    Episode_Reward/pen_base_height: -0.3145
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1388
   Episode_Reward/pen_joint_torque: -0.1820
    Episode_Reward/pen_joint_accel: -0.0813
    Episode_Reward/pen_action_rate: -0.2935
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0375
   Episode_Reward/pen_joint_powers: -0.0631
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6822
Episode_Reward/pen_flat_orientation: -0.1238
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.2715
   Episode_Reward/foot_landing_vel: -0.1098
   Episode_Reward/test_gait_reward: -0.8865
Metrics/base_velocity/error_vel_xy: 2.0956
Metrics/base_velocity/error_vel_yaw: 1.0031
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 1.09s
                        Total time: 1372.10s
                               ETA: 1880.4s

################################################################################
                     [1m Learning iteration 1266/3000 [0m                     

                       Computation: 90632 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.9808
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6317
                     Learning rate: 0.0006
                       Mean reward: 96.18
               Mean episode length: 962.64
       Episode_Reward/keep_balance: 0.9664
     Episode_Reward/rew_lin_vel_xy: 4.3804
      Episode_Reward/rew_ang_vel_z: 2.7885
    Episode_Reward/pen_base_height: -0.3125
      Episode_Reward/pen_lin_vel_z: -0.0564
     Episode_Reward/pen_ang_vel_xy: -0.1409
   Episode_Reward/pen_joint_torque: -0.1826
    Episode_Reward/pen_joint_accel: -0.0802
    Episode_Reward/pen_action_rate: -0.2946
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0376
   Episode_Reward/pen_joint_powers: -0.0637
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6802
Episode_Reward/pen_flat_orientation: -0.1122
  Episode_Reward/pen_feet_distance: -0.0061
Episode_Reward/pen_feet_regulation: -0.2730
   Episode_Reward/foot_landing_vel: -0.1067
   Episode_Reward/test_gait_reward: -0.8884
Metrics/base_velocity/error_vel_xy: 1.8894
Metrics/base_velocity/error_vel_yaw: 0.9680
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 1.08s
                        Total time: 1373.18s
                               ETA: 1879.3s

################################################################################
                     [1m Learning iteration 1267/3000 [0m                     

                       Computation: 91606 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 1.1028
                    Surrogate loss: -0.0031
             Mean action noise std: 0.6315
                     Learning rate: 0.0009
                       Mean reward: 91.49
               Mean episode length: 976.45
       Episode_Reward/keep_balance: 0.9720
     Episode_Reward/rew_lin_vel_xy: 4.0737
      Episode_Reward/rew_ang_vel_z: 2.7470
    Episode_Reward/pen_base_height: -0.3164
      Episode_Reward/pen_lin_vel_z: -0.0546
     Episode_Reward/pen_ang_vel_xy: -0.1381
   Episode_Reward/pen_joint_torque: -0.1853
    Episode_Reward/pen_joint_accel: -0.0823
    Episode_Reward/pen_action_rate: -0.2959
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0380
   Episode_Reward/pen_joint_powers: -0.0633
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6887
Episode_Reward/pen_flat_orientation: -0.1154
  Episode_Reward/pen_feet_distance: -0.0113
Episode_Reward/pen_feet_regulation: -0.2714
   Episode_Reward/foot_landing_vel: -0.1078
   Episode_Reward/test_gait_reward: -0.8813
Metrics/base_velocity/error_vel_xy: 2.0716
Metrics/base_velocity/error_vel_yaw: 1.0179
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 1.07s
                        Total time: 1374.25s
                               ETA: 1878.2s

################################################################################
                     [1m Learning iteration 1268/3000 [0m                     

                       Computation: 93177 steps/s (collection: 0.933s, learning 0.122s)
               Value function loss: 1.0251
                    Surrogate loss: -0.0031
             Mean action noise std: 0.6311
                     Learning rate: 0.0006
                       Mean reward: 92.99
               Mean episode length: 972.35
       Episode_Reward/keep_balance: 0.9833
     Episode_Reward/rew_lin_vel_xy: 4.3746
      Episode_Reward/rew_ang_vel_z: 2.7883
    Episode_Reward/pen_base_height: -0.3138
      Episode_Reward/pen_lin_vel_z: -0.0583
     Episode_Reward/pen_ang_vel_xy: -0.1377
   Episode_Reward/pen_joint_torque: -0.1889
    Episode_Reward/pen_joint_accel: -0.0863
    Episode_Reward/pen_action_rate: -0.3022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0398
   Episode_Reward/pen_joint_powers: -0.0657
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6961
Episode_Reward/pen_flat_orientation: -0.1171
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.2979
   Episode_Reward/foot_landing_vel: -0.1189
   Episode_Reward/test_gait_reward: -0.9036
Metrics/base_velocity/error_vel_xy: 1.9702
Metrics/base_velocity/error_vel_yaw: 1.0179
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 1.06s
                        Total time: 1375.31s
                               ETA: 1877.1s

################################################################################
                     [1m Learning iteration 1269/3000 [0m                     

                       Computation: 92675 steps/s (collection: 0.937s, learning 0.124s)
               Value function loss: 1.0820
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6313
                     Learning rate: 0.0006
                       Mean reward: 96.18
               Mean episode length: 976.90
       Episode_Reward/keep_balance: 0.9871
     Episode_Reward/rew_lin_vel_xy: 4.3683
      Episode_Reward/rew_ang_vel_z: 2.8480
    Episode_Reward/pen_base_height: -0.3283
      Episode_Reward/pen_lin_vel_z: -0.0587
     Episode_Reward/pen_ang_vel_xy: -0.1453
   Episode_Reward/pen_joint_torque: -0.1878
    Episode_Reward/pen_joint_accel: -0.0826
    Episode_Reward/pen_action_rate: -0.3005
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0390
   Episode_Reward/pen_joint_powers: -0.0650
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6927
Episode_Reward/pen_flat_orientation: -0.1235
  Episode_Reward/pen_feet_distance: -0.0066
Episode_Reward/pen_feet_regulation: -0.2971
   Episode_Reward/foot_landing_vel: -0.1096
   Episode_Reward/test_gait_reward: -0.9048
Metrics/base_velocity/error_vel_xy: 1.9798
Metrics/base_velocity/error_vel_yaw: 0.9911
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 1.06s
                        Total time: 1376.37s
                               ETA: 1876.0s

################################################################################
                     [1m Learning iteration 1270/3000 [0m                     

                       Computation: 92428 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 0.9299
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6318
                     Learning rate: 0.0006
                       Mean reward: 95.95
               Mean episode length: 977.31
       Episode_Reward/keep_balance: 0.9798
     Episode_Reward/rew_lin_vel_xy: 4.3510
      Episode_Reward/rew_ang_vel_z: 2.7832
    Episode_Reward/pen_base_height: -0.3006
      Episode_Reward/pen_lin_vel_z: -0.0526
     Episode_Reward/pen_ang_vel_xy: -0.1381
   Episode_Reward/pen_joint_torque: -0.1782
    Episode_Reward/pen_joint_accel: -0.0826
    Episode_Reward/pen_action_rate: -0.2960
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0372
   Episode_Reward/pen_joint_powers: -0.0616
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6932
Episode_Reward/pen_flat_orientation: -0.1136
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.2605
   Episode_Reward/foot_landing_vel: -0.1058
   Episode_Reward/test_gait_reward: -0.8868
Metrics/base_velocity/error_vel_xy: 1.9362
Metrics/base_velocity/error_vel_yaw: 1.0138
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 1.06s
                        Total time: 1377.43s
                               ETA: 1874.9s

################################################################################
                     [1m Learning iteration 1271/3000 [0m                     

                       Computation: 92979 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 1.0302
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6317
                     Learning rate: 0.0001
                       Mean reward: 97.29
               Mean episode length: 984.08
       Episode_Reward/keep_balance: 0.9763
     Episode_Reward/rew_lin_vel_xy: 4.2867
      Episode_Reward/rew_ang_vel_z: 2.7995
    Episode_Reward/pen_base_height: -0.3210
      Episode_Reward/pen_lin_vel_z: -0.0567
     Episode_Reward/pen_ang_vel_xy: -0.1393
   Episode_Reward/pen_joint_torque: -0.1919
    Episode_Reward/pen_joint_accel: -0.0899
    Episode_Reward/pen_action_rate: -0.3005
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0381
   Episode_Reward/pen_joint_powers: -0.0641
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6916
Episode_Reward/pen_flat_orientation: -0.1141
  Episode_Reward/pen_feet_distance: -0.0078
Episode_Reward/pen_feet_regulation: -0.2744
   Episode_Reward/foot_landing_vel: -0.1098
   Episode_Reward/test_gait_reward: -0.8902
Metrics/base_velocity/error_vel_xy: 1.9806
Metrics/base_velocity/error_vel_yaw: 0.9906
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 1.06s
                        Total time: 1378.49s
                               ETA: 1873.8s

################################################################################
                     [1m Learning iteration 1272/3000 [0m                     

                       Computation: 93326 steps/s (collection: 0.932s, learning 0.122s)
               Value function loss: 1.0050
                    Surrogate loss: 0.0003
             Mean action noise std: 0.6315
                     Learning rate: 0.0001
                       Mean reward: 94.96
               Mean episode length: 943.71
       Episode_Reward/keep_balance: 0.9405
     Episode_Reward/rew_lin_vel_xy: 4.3082
      Episode_Reward/rew_ang_vel_z: 2.6911
    Episode_Reward/pen_base_height: -0.3170
      Episode_Reward/pen_lin_vel_z: -0.0552
     Episode_Reward/pen_ang_vel_xy: -0.1354
   Episode_Reward/pen_joint_torque: -0.1831
    Episode_Reward/pen_joint_accel: -0.0791
    Episode_Reward/pen_action_rate: -0.2887
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0371
   Episode_Reward/pen_joint_powers: -0.0625
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6601
Episode_Reward/pen_flat_orientation: -0.1182
  Episode_Reward/pen_feet_distance: -0.0122
Episode_Reward/pen_feet_regulation: -0.2810
   Episode_Reward/foot_landing_vel: -0.1022
   Episode_Reward/test_gait_reward: -0.8626
Metrics/base_velocity/error_vel_xy: 1.7968
Metrics/base_velocity/error_vel_yaw: 0.9640
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 1.05s
                        Total time: 1379.54s
                               ETA: 1872.6s

################################################################################
                     [1m Learning iteration 1273/3000 [0m                     

                       Computation: 94294 steps/s (collection: 0.921s, learning 0.122s)
               Value function loss: 1.0200
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6316
                     Learning rate: 0.0002
                       Mean reward: 94.04
               Mean episode length: 974.58
       Episode_Reward/keep_balance: 0.9843
     Episode_Reward/rew_lin_vel_xy: 4.2958
      Episode_Reward/rew_ang_vel_z: 2.8137
    Episode_Reward/pen_base_height: -0.3189
      Episode_Reward/pen_lin_vel_z: -0.0575
     Episode_Reward/pen_ang_vel_xy: -0.1392
   Episode_Reward/pen_joint_torque: -0.1861
    Episode_Reward/pen_joint_accel: -0.0914
    Episode_Reward/pen_action_rate: -0.2998
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0393
   Episode_Reward/pen_joint_powers: -0.0646
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6941
Episode_Reward/pen_flat_orientation: -0.1142
  Episode_Reward/pen_feet_distance: -0.0064
Episode_Reward/pen_feet_regulation: -0.2836
   Episode_Reward/foot_landing_vel: -0.1108
   Episode_Reward/test_gait_reward: -0.8980
Metrics/base_velocity/error_vel_xy: 1.9697
Metrics/base_velocity/error_vel_yaw: 1.0041
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 1.04s
                        Total time: 1380.59s
                               ETA: 1871.5s

################################################################################
                     [1m Learning iteration 1274/3000 [0m                     

                       Computation: 92728 steps/s (collection: 0.937s, learning 0.123s)
               Value function loss: 0.8782
                    Surrogate loss: -0.0034
             Mean action noise std: 0.6332
                     Learning rate: 0.0004
                       Mean reward: 92.96
               Mean episode length: 953.91
       Episode_Reward/keep_balance: 0.9521
     Episode_Reward/rew_lin_vel_xy: 4.2670
      Episode_Reward/rew_ang_vel_z: 2.7216
    Episode_Reward/pen_base_height: -0.3163
      Episode_Reward/pen_lin_vel_z: -0.0584
     Episode_Reward/pen_ang_vel_xy: -0.1411
   Episode_Reward/pen_joint_torque: -0.1831
    Episode_Reward/pen_joint_accel: -0.0815
    Episode_Reward/pen_action_rate: -0.2929
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0385
   Episode_Reward/pen_joint_powers: -0.0639
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6784
Episode_Reward/pen_flat_orientation: -0.1193
  Episode_Reward/pen_feet_distance: -0.0065
Episode_Reward/pen_feet_regulation: -0.2893
   Episode_Reward/foot_landing_vel: -0.1093
   Episode_Reward/test_gait_reward: -0.8777
Metrics/base_velocity/error_vel_xy: 1.8805
Metrics/base_velocity/error_vel_yaw: 0.9723
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 1.06s
                        Total time: 1381.65s
                               ETA: 1870.4s

################################################################################
                     [1m Learning iteration 1275/3000 [0m                     

                       Computation: 93945 steps/s (collection: 0.923s, learning 0.123s)
               Value function loss: 0.9822
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6327
                     Learning rate: 0.0006
                       Mean reward: 92.78
               Mean episode length: 968.23
       Episode_Reward/keep_balance: 0.9421
     Episode_Reward/rew_lin_vel_xy: 4.1828
      Episode_Reward/rew_ang_vel_z: 2.6949
    Episode_Reward/pen_base_height: -0.3023
      Episode_Reward/pen_lin_vel_z: -0.0540
     Episode_Reward/pen_ang_vel_xy: -0.1392
   Episode_Reward/pen_joint_torque: -0.1777
    Episode_Reward/pen_joint_accel: -0.0806
    Episode_Reward/pen_action_rate: -0.2888
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0372
   Episode_Reward/pen_joint_powers: -0.0618
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6656
Episode_Reward/pen_flat_orientation: -0.1137
  Episode_Reward/pen_feet_distance: -0.0084
Episode_Reward/pen_feet_regulation: -0.2751
   Episode_Reward/foot_landing_vel: -0.0979
   Episode_Reward/test_gait_reward: -0.8618
Metrics/base_velocity/error_vel_xy: 1.8622
Metrics/base_velocity/error_vel_yaw: 0.9611
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 1.05s
                        Total time: 1382.69s
                               ETA: 1869.2s

################################################################################
                     [1m Learning iteration 1276/3000 [0m                     

                       Computation: 86570 steps/s (collection: 1.014s, learning 0.122s)
               Value function loss: 1.0422
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6319
                     Learning rate: 0.0004
                       Mean reward: 93.70
               Mean episode length: 968.07
       Episode_Reward/keep_balance: 0.9650
     Episode_Reward/rew_lin_vel_xy: 4.2072
      Episode_Reward/rew_ang_vel_z: 2.7248
    Episode_Reward/pen_base_height: -0.3175
      Episode_Reward/pen_lin_vel_z: -0.0592
     Episode_Reward/pen_ang_vel_xy: -0.1398
   Episode_Reward/pen_joint_torque: -0.1819
    Episode_Reward/pen_joint_accel: -0.0787
    Episode_Reward/pen_action_rate: -0.2968
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0381
   Episode_Reward/pen_joint_powers: -0.0635
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6865
Episode_Reward/pen_flat_orientation: -0.1114
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.2812
   Episode_Reward/foot_landing_vel: -0.1158
   Episode_Reward/test_gait_reward: -0.8768
Metrics/base_velocity/error_vel_xy: 1.9699
Metrics/base_velocity/error_vel_yaw: 1.0096
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 1.14s
                        Total time: 1383.83s
                               ETA: 1868.2s

################################################################################
                     [1m Learning iteration 1277/3000 [0m                     

                       Computation: 90495 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 1.0003
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6319
                     Learning rate: 0.0006
                       Mean reward: 93.55
               Mean episode length: 967.52
       Episode_Reward/keep_balance: 0.9756
     Episode_Reward/rew_lin_vel_xy: 4.2153
      Episode_Reward/rew_ang_vel_z: 2.7630
    Episode_Reward/pen_base_height: -0.3301
      Episode_Reward/pen_lin_vel_z: -0.0537
     Episode_Reward/pen_ang_vel_xy: -0.1421
   Episode_Reward/pen_joint_torque: -0.1818
    Episode_Reward/pen_joint_accel: -0.0866
    Episode_Reward/pen_action_rate: -0.2974
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0384
   Episode_Reward/pen_joint_powers: -0.0627
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6912
Episode_Reward/pen_flat_orientation: -0.1264
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.2635
   Episode_Reward/foot_landing_vel: -0.1079
   Episode_Reward/test_gait_reward: -0.8849
Metrics/base_velocity/error_vel_xy: 2.0486
Metrics/base_velocity/error_vel_yaw: 1.0192
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 1.09s
                        Total time: 1384.91s
                               ETA: 1867.1s

################################################################################
                     [1m Learning iteration 1278/3000 [0m                     

                       Computation: 93486 steps/s (collection: 0.928s, learning 0.123s)
               Value function loss: 1.0098
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6318
                     Learning rate: 0.0006
                       Mean reward: 93.44
               Mean episode length: 959.47
       Episode_Reward/keep_balance: 0.9530
     Episode_Reward/rew_lin_vel_xy: 4.2255
      Episode_Reward/rew_ang_vel_z: 2.7247
    Episode_Reward/pen_base_height: -0.3119
      Episode_Reward/pen_lin_vel_z: -0.0564
     Episode_Reward/pen_ang_vel_xy: -0.1406
   Episode_Reward/pen_joint_torque: -0.1794
    Episode_Reward/pen_joint_accel: -0.0862
    Episode_Reward/pen_action_rate: -0.2941
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0386
   Episode_Reward/pen_joint_powers: -0.0630
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6810
Episode_Reward/pen_flat_orientation: -0.1213
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.2874
   Episode_Reward/foot_landing_vel: -0.1081
   Episode_Reward/test_gait_reward: -0.8712
Metrics/base_velocity/error_vel_xy: 1.9409
Metrics/base_velocity/error_vel_yaw: 0.9764
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 1.05s
                        Total time: 1385.97s
                               ETA: 1866.0s

################################################################################
                     [1m Learning iteration 1279/3000 [0m                     

                       Computation: 91651 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 1.0343
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6316
                     Learning rate: 0.0004
                       Mean reward: 92.08
               Mean episode length: 953.19
       Episode_Reward/keep_balance: 0.9550
     Episode_Reward/rew_lin_vel_xy: 4.0497
      Episode_Reward/rew_ang_vel_z: 2.7382
    Episode_Reward/pen_base_height: -0.3024
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1334
   Episode_Reward/pen_joint_torque: -0.1825
    Episode_Reward/pen_joint_accel: -0.0824
    Episode_Reward/pen_action_rate: -0.2906
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0373
   Episode_Reward/pen_joint_powers: -0.0619
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6766
Episode_Reward/pen_flat_orientation: -0.1125
  Episode_Reward/pen_feet_distance: -0.0086
Episode_Reward/pen_feet_regulation: -0.2694
   Episode_Reward/foot_landing_vel: -0.1075
   Episode_Reward/test_gait_reward: -0.8668
Metrics/base_velocity/error_vel_xy: 2.0537
Metrics/base_velocity/error_vel_yaw: 0.9708
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 1.07s
                        Total time: 1387.04s
                               ETA: 1864.9s

################################################################################
                     [1m Learning iteration 1280/3000 [0m                     

                       Computation: 92157 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 1.0435
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6312
                     Learning rate: 0.0004
                       Mean reward: 96.34
               Mean episode length: 972.01
       Episode_Reward/keep_balance: 0.9910
     Episode_Reward/rew_lin_vel_xy: 4.3994
      Episode_Reward/rew_ang_vel_z: 2.8147
    Episode_Reward/pen_base_height: -0.3386
      Episode_Reward/pen_lin_vel_z: -0.0573
     Episode_Reward/pen_ang_vel_xy: -0.1390
   Episode_Reward/pen_joint_torque: -0.1873
    Episode_Reward/pen_joint_accel: -0.0974
    Episode_Reward/pen_action_rate: -0.3048
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0397
   Episode_Reward/pen_joint_powers: -0.0648
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7054
Episode_Reward/pen_flat_orientation: -0.1213
  Episode_Reward/pen_feet_distance: -0.0098
Episode_Reward/pen_feet_regulation: -0.2859
   Episode_Reward/foot_landing_vel: -0.1182
   Episode_Reward/test_gait_reward: -0.9110
Metrics/base_velocity/error_vel_xy: 2.0410
Metrics/base_velocity/error_vel_yaw: 1.0240
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 1.07s
                        Total time: 1388.11s
                               ETA: 1863.8s

################################################################################
                     [1m Learning iteration 1281/3000 [0m                     

                       Computation: 92622 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 1.0135
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6311
                     Learning rate: 0.0006
                       Mean reward: 86.67
               Mean episode length: 935.46
       Episode_Reward/keep_balance: 0.9475
     Episode_Reward/rew_lin_vel_xy: 3.9867
      Episode_Reward/rew_ang_vel_z: 2.6810
    Episode_Reward/pen_base_height: -0.3152
      Episode_Reward/pen_lin_vel_z: -0.0557
     Episode_Reward/pen_ang_vel_xy: -0.1332
   Episode_Reward/pen_joint_torque: -0.1813
    Episode_Reward/pen_joint_accel: -0.0898
    Episode_Reward/pen_action_rate: -0.2921
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0377
   Episode_Reward/pen_joint_powers: -0.0619
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6692
Episode_Reward/pen_flat_orientation: -0.1113
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.2779
   Episode_Reward/foot_landing_vel: -0.1089
   Episode_Reward/test_gait_reward: -0.8643
Metrics/base_velocity/error_vel_xy: 2.0780
Metrics/base_velocity/error_vel_yaw: 0.9917
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 1.06s
                        Total time: 1389.17s
                               ETA: 1862.7s

################################################################################
                     [1m Learning iteration 1282/3000 [0m                     

                       Computation: 92664 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 0.9459
                    Surrogate loss: -0.0034
             Mean action noise std: 0.6315
                     Learning rate: 0.0009
                       Mean reward: 92.91
               Mean episode length: 968.75
       Episode_Reward/keep_balance: 0.9783
     Episode_Reward/rew_lin_vel_xy: 4.2825
      Episode_Reward/rew_ang_vel_z: 2.7860
    Episode_Reward/pen_base_height: -0.3217
      Episode_Reward/pen_lin_vel_z: -0.0604
     Episode_Reward/pen_ang_vel_xy: -0.1400
   Episode_Reward/pen_joint_torque: -0.1881
    Episode_Reward/pen_joint_accel: -0.0910
    Episode_Reward/pen_action_rate: -0.3022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0384
   Episode_Reward/pen_joint_powers: -0.0646
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6978
Episode_Reward/pen_flat_orientation: -0.1102
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.2774
   Episode_Reward/foot_landing_vel: -0.1162
   Episode_Reward/test_gait_reward: -0.8920
Metrics/base_velocity/error_vel_xy: 2.0552
Metrics/base_velocity/error_vel_yaw: 1.0044
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 1.06s
                        Total time: 1390.23s
                               ETA: 1861.6s

################################################################################
                     [1m Learning iteration 1283/3000 [0m                     

                       Computation: 93276 steps/s (collection: 0.932s, learning 0.122s)
               Value function loss: 1.0529
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6313
                     Learning rate: 0.0013
                       Mean reward: 93.88
               Mean episode length: 966.04
       Episode_Reward/keep_balance: 0.9677
     Episode_Reward/rew_lin_vel_xy: 4.2022
      Episode_Reward/rew_ang_vel_z: 2.7656
    Episode_Reward/pen_base_height: -0.3297
      Episode_Reward/pen_lin_vel_z: -0.0586
     Episode_Reward/pen_ang_vel_xy: -0.1429
   Episode_Reward/pen_joint_torque: -0.1881
    Episode_Reward/pen_joint_accel: -0.0878
    Episode_Reward/pen_action_rate: -0.2981
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0398
   Episode_Reward/pen_joint_powers: -0.0650
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6869
Episode_Reward/pen_flat_orientation: -0.1209
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.2944
   Episode_Reward/foot_landing_vel: -0.1125
   Episode_Reward/test_gait_reward: -0.8779
Metrics/base_velocity/error_vel_xy: 2.0463
Metrics/base_velocity/error_vel_yaw: 0.9930
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 1.05s
                        Total time: 1391.28s
                               ETA: 1860.5s

################################################################################
                     [1m Learning iteration 1284/3000 [0m                     

                       Computation: 92337 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 1.0610
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6317
                     Learning rate: 0.0006
                       Mean reward: 92.90
               Mean episode length: 969.22
       Episode_Reward/keep_balance: 0.9584
     Episode_Reward/rew_lin_vel_xy: 4.1588
      Episode_Reward/rew_ang_vel_z: 2.7245
    Episode_Reward/pen_base_height: -0.3294
      Episode_Reward/pen_lin_vel_z: -0.0598
     Episode_Reward/pen_ang_vel_xy: -0.1425
   Episode_Reward/pen_joint_torque: -0.1892
    Episode_Reward/pen_joint_accel: -0.0828
    Episode_Reward/pen_action_rate: -0.2979
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0395
   Episode_Reward/pen_joint_powers: -0.0652
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6811
Episode_Reward/pen_flat_orientation: -0.1197
  Episode_Reward/pen_feet_distance: -0.0075
Episode_Reward/pen_feet_regulation: -0.3037
   Episode_Reward/foot_landing_vel: -0.1149
   Episode_Reward/test_gait_reward: -0.8801
Metrics/base_velocity/error_vel_xy: 1.9947
Metrics/base_velocity/error_vel_yaw: 0.9890
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 1.06s
                        Total time: 1392.35s
                               ETA: 1859.4s

################################################################################
                     [1m Learning iteration 1285/3000 [0m                     

                       Computation: 91918 steps/s (collection: 0.946s, learning 0.124s)
               Value function loss: 0.9915
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6318
                     Learning rate: 0.0004
                       Mean reward: 93.57
               Mean episode length: 951.06
       Episode_Reward/keep_balance: 0.9580
     Episode_Reward/rew_lin_vel_xy: 4.3940
      Episode_Reward/rew_ang_vel_z: 2.7765
    Episode_Reward/pen_base_height: -0.3214
      Episode_Reward/pen_lin_vel_z: -0.0614
     Episode_Reward/pen_ang_vel_xy: -0.1372
   Episode_Reward/pen_joint_torque: -0.1909
    Episode_Reward/pen_joint_accel: -0.0820
    Episode_Reward/pen_action_rate: -0.2960
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0385
   Episode_Reward/pen_joint_powers: -0.0654
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6734
Episode_Reward/pen_flat_orientation: -0.1127
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.2948
   Episode_Reward/foot_landing_vel: -0.1124
   Episode_Reward/test_gait_reward: -0.8913
Metrics/base_velocity/error_vel_xy: 1.9004
Metrics/base_velocity/error_vel_yaw: 0.9458
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 1.07s
                        Total time: 1393.42s
                               ETA: 1858.2s

################################################################################
                     [1m Learning iteration 1286/3000 [0m                     

                       Computation: 92545 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 1.1213
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6314
                     Learning rate: 0.0009
                       Mean reward: 96.35
               Mean episode length: 975.93
       Episode_Reward/keep_balance: 0.9848
     Episode_Reward/rew_lin_vel_xy: 4.4508
      Episode_Reward/rew_ang_vel_z: 2.7904
    Episode_Reward/pen_base_height: -0.3265
      Episode_Reward/pen_lin_vel_z: -0.0595
     Episode_Reward/pen_ang_vel_xy: -0.1398
   Episode_Reward/pen_joint_torque: -0.1911
    Episode_Reward/pen_joint_accel: -0.0982
    Episode_Reward/pen_action_rate: -0.3046
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0402
   Episode_Reward/pen_joint_powers: -0.0656
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6971
Episode_Reward/pen_flat_orientation: -0.1219
  Episode_Reward/pen_feet_distance: -0.0073
Episode_Reward/pen_feet_regulation: -0.2967
   Episode_Reward/foot_landing_vel: -0.1177
   Episode_Reward/test_gait_reward: -0.9021
Metrics/base_velocity/error_vel_xy: 1.8988
Metrics/base_velocity/error_vel_yaw: 1.0271
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 1.06s
                        Total time: 1394.48s
                               ETA: 1857.1s

################################################################################
                     [1m Learning iteration 1287/3000 [0m                     

                       Computation: 93063 steps/s (collection: 0.935s, learning 0.121s)
               Value function loss: 1.0820
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6313
                     Learning rate: 0.0004
                       Mean reward: 95.34
               Mean episode length: 979.56
       Episode_Reward/keep_balance: 0.9860
     Episode_Reward/rew_lin_vel_xy: 4.3547
      Episode_Reward/rew_ang_vel_z: 2.8120
    Episode_Reward/pen_base_height: -0.3332
      Episode_Reward/pen_lin_vel_z: -0.0597
     Episode_Reward/pen_ang_vel_xy: -0.1387
   Episode_Reward/pen_joint_torque: -0.1950
    Episode_Reward/pen_joint_accel: -0.0897
    Episode_Reward/pen_action_rate: -0.3068
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0402
   Episode_Reward/pen_joint_powers: -0.0665
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6975
Episode_Reward/pen_flat_orientation: -0.1140
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.2990
   Episode_Reward/foot_landing_vel: -0.1132
   Episode_Reward/test_gait_reward: -0.9020
Metrics/base_velocity/error_vel_xy: 1.9520
Metrics/base_velocity/error_vel_yaw: 1.0105
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 1.06s
                        Total time: 1395.53s
                               ETA: 1856.0s

################################################################################
                     [1m Learning iteration 1288/3000 [0m                     

                       Computation: 92148 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 1.1271
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6320
                     Learning rate: 0.0003
                       Mean reward: 95.69
               Mean episode length: 960.01
       Episode_Reward/keep_balance: 0.9627
     Episode_Reward/rew_lin_vel_xy: 4.3546
      Episode_Reward/rew_ang_vel_z: 2.7572
    Episode_Reward/pen_base_height: -0.3188
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1388
   Episode_Reward/pen_joint_torque: -0.1841
    Episode_Reward/pen_joint_accel: -0.0910
    Episode_Reward/pen_action_rate: -0.2949
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0381
   Episode_Reward/pen_joint_powers: -0.0633
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6794
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.2742
   Episode_Reward/foot_landing_vel: -0.1094
   Episode_Reward/test_gait_reward: -0.8757
Metrics/base_velocity/error_vel_xy: 1.9072
Metrics/base_velocity/error_vel_yaw: 0.9821
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 1.07s
                        Total time: 1396.60s
                               ETA: 1854.9s

################################################################################
                     [1m Learning iteration 1289/3000 [0m                     

                       Computation: 92243 steps/s (collection: 0.943s, learning 0.123s)
               Value function loss: 1.0153
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6320
                     Learning rate: 0.0001
                       Mean reward: 98.15
               Mean episode length: 972.64
       Episode_Reward/keep_balance: 0.9683
     Episode_Reward/rew_lin_vel_xy: 4.4521
      Episode_Reward/rew_ang_vel_z: 2.7354
    Episode_Reward/pen_base_height: -0.3101
      Episode_Reward/pen_lin_vel_z: -0.0551
     Episode_Reward/pen_ang_vel_xy: -0.1353
   Episode_Reward/pen_joint_torque: -0.1835
    Episode_Reward/pen_joint_accel: -0.0910
    Episode_Reward/pen_action_rate: -0.2982
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0382
   Episode_Reward/pen_joint_powers: -0.0628
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6897
Episode_Reward/pen_flat_orientation: -0.1128
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.2726
   Episode_Reward/foot_landing_vel: -0.1119
   Episode_Reward/test_gait_reward: -0.8755
Metrics/base_velocity/error_vel_xy: 1.8243
Metrics/base_velocity/error_vel_yaw: 1.0110
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 1.07s
                        Total time: 1397.67s
                               ETA: 1853.8s

################################################################################
                     [1m Learning iteration 1290/3000 [0m                     

                       Computation: 93260 steps/s (collection: 0.932s, learning 0.122s)
               Value function loss: 0.9412
                    Surrogate loss: -0.0042
             Mean action noise std: 0.6319
                     Learning rate: 0.0003
                       Mean reward: 97.92
               Mean episode length: 981.89
       Episode_Reward/keep_balance: 0.9824
     Episode_Reward/rew_lin_vel_xy: 4.4630
      Episode_Reward/rew_ang_vel_z: 2.7939
    Episode_Reward/pen_base_height: -0.3367
      Episode_Reward/pen_lin_vel_z: -0.0577
     Episode_Reward/pen_ang_vel_xy: -0.1404
   Episode_Reward/pen_joint_torque: -0.1888
    Episode_Reward/pen_joint_accel: -0.0804
    Episode_Reward/pen_action_rate: -0.3034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0391
   Episode_Reward/pen_joint_powers: -0.0647
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6998
Episode_Reward/pen_flat_orientation: -0.1172
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.2919
   Episode_Reward/foot_landing_vel: -0.1097
   Episode_Reward/test_gait_reward: -0.8945
Metrics/base_velocity/error_vel_xy: 1.9133
Metrics/base_velocity/error_vel_yaw: 1.0131
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 1.05s
                        Total time: 1398.72s
                               ETA: 1852.7s

################################################################################
                     [1m Learning iteration 1291/3000 [0m                     

                       Computation: 91667 steps/s (collection: 0.949s, learning 0.124s)
               Value function loss: 0.9929
                    Surrogate loss: -0.0038
             Mean action noise std: 0.6317
                     Learning rate: 0.0006
                       Mean reward: 95.15
               Mean episode length: 971.07
       Episode_Reward/keep_balance: 0.9826
     Episode_Reward/rew_lin_vel_xy: 4.2934
      Episode_Reward/rew_ang_vel_z: 2.7902
    Episode_Reward/pen_base_height: -0.3185
      Episode_Reward/pen_lin_vel_z: -0.0583
     Episode_Reward/pen_ang_vel_xy: -0.1334
   Episode_Reward/pen_joint_torque: -0.1842
    Episode_Reward/pen_joint_accel: -0.0860
    Episode_Reward/pen_action_rate: -0.2955
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0382
   Episode_Reward/pen_joint_powers: -0.0632
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6944
Episode_Reward/pen_flat_orientation: -0.1118
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.2785
   Episode_Reward/foot_landing_vel: -0.1137
   Episode_Reward/test_gait_reward: -0.8874
Metrics/base_velocity/error_vel_xy: 2.0215
Metrics/base_velocity/error_vel_yaw: 1.0176
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 1.07s
                        Total time: 1399.79s
                               ETA: 1851.6s

################################################################################
                     [1m Learning iteration 1292/3000 [0m                     

                       Computation: 88875 steps/s (collection: 0.980s, learning 0.126s)
               Value function loss: 0.9726
                    Surrogate loss: 0.0002
             Mean action noise std: 0.6318
                     Learning rate: 0.0001
                       Mean reward: 93.56
               Mean episode length: 944.59
       Episode_Reward/keep_balance: 0.9391
     Episode_Reward/rew_lin_vel_xy: 4.1232
      Episode_Reward/rew_ang_vel_z: 2.6714
    Episode_Reward/pen_base_height: -0.3211
      Episode_Reward/pen_lin_vel_z: -0.0548
     Episode_Reward/pen_ang_vel_xy: -0.1312
   Episode_Reward/pen_joint_torque: -0.1819
    Episode_Reward/pen_joint_accel: -0.0835
    Episode_Reward/pen_action_rate: -0.2873
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0373
   Episode_Reward/pen_joint_powers: -0.0619
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.6616
Episode_Reward/pen_flat_orientation: -0.1194
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.2718
   Episode_Reward/foot_landing_vel: -0.1018
   Episode_Reward/test_gait_reward: -0.8532
Metrics/base_velocity/error_vel_xy: 1.8454
Metrics/base_velocity/error_vel_yaw: 0.9732
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 1.11s
                        Total time: 1400.90s
                               ETA: 1850.5s

################################################################################
                     [1m Learning iteration 1293/3000 [0m                     

                       Computation: 91002 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.9026
                    Surrogate loss: -0.0043
             Mean action noise std: 0.6313
                     Learning rate: 0.0003
                       Mean reward: 97.26
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 0.9970
     Episode_Reward/rew_lin_vel_xy: 4.3008
      Episode_Reward/rew_ang_vel_z: 2.8151
    Episode_Reward/pen_base_height: -0.3290
      Episode_Reward/pen_lin_vel_z: -0.0569
     Episode_Reward/pen_ang_vel_xy: -0.1439
   Episode_Reward/pen_joint_torque: -0.1912
    Episode_Reward/pen_joint_accel: -0.0838
    Episode_Reward/pen_action_rate: -0.3078
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0395
   Episode_Reward/pen_joint_powers: -0.0653
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7077
Episode_Reward/pen_flat_orientation: -0.1161
  Episode_Reward/pen_feet_distance: -0.0077
Episode_Reward/pen_feet_regulation: -0.2891
   Episode_Reward/foot_landing_vel: -0.1104
   Episode_Reward/test_gait_reward: -0.9026
Metrics/base_velocity/error_vel_xy: 2.0902
Metrics/base_velocity/error_vel_yaw: 1.0433
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 1.08s
                        Total time: 1401.98s
                               ETA: 1849.4s

################################################################################
                     [1m Learning iteration 1294/3000 [0m                     

                       Computation: 91903 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 0.9486
                    Surrogate loss: -0.0042
             Mean action noise std: 0.6302
                     Learning rate: 0.0004
                       Mean reward: 92.91
               Mean episode length: 958.61
       Episode_Reward/keep_balance: 0.9725
     Episode_Reward/rew_lin_vel_xy: 4.3020
      Episode_Reward/rew_ang_vel_z: 2.7000
    Episode_Reward/pen_base_height: -0.3329
      Episode_Reward/pen_lin_vel_z: -0.0564
     Episode_Reward/pen_ang_vel_xy: -0.1380
   Episode_Reward/pen_joint_torque: -0.1894
    Episode_Reward/pen_joint_accel: -0.0858
    Episode_Reward/pen_action_rate: -0.3033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0394
   Episode_Reward/pen_joint_powers: -0.0647
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6939
Episode_Reward/pen_flat_orientation: -0.1127
  Episode_Reward/pen_feet_distance: -0.0078
Episode_Reward/pen_feet_regulation: -0.2930
   Episode_Reward/foot_landing_vel: -0.1113
   Episode_Reward/test_gait_reward: -0.8903
Metrics/base_velocity/error_vel_xy: 1.9237
Metrics/base_velocity/error_vel_yaw: 1.0575
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 1.07s
                        Total time: 1403.05s
                               ETA: 1848.3s

################################################################################
                     [1m Learning iteration 1295/3000 [0m                     

                       Computation: 93481 steps/s (collection: 0.928s, learning 0.123s)
               Value function loss: 0.9206
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6311
                     Learning rate: 0.0006
                       Mean reward: 93.99
               Mean episode length: 948.32
       Episode_Reward/keep_balance: 0.9595
     Episode_Reward/rew_lin_vel_xy: 4.2533
      Episode_Reward/rew_ang_vel_z: 2.7494
    Episode_Reward/pen_base_height: -0.3213
      Episode_Reward/pen_lin_vel_z: -0.0565
     Episode_Reward/pen_ang_vel_xy: -0.1379
   Episode_Reward/pen_joint_torque: -0.1875
    Episode_Reward/pen_joint_accel: -0.0823
    Episode_Reward/pen_action_rate: -0.2928
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0380
   Episode_Reward/pen_joint_powers: -0.0637
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6744
Episode_Reward/pen_flat_orientation: -0.1129
  Episode_Reward/pen_feet_distance: -0.0093
Episode_Reward/pen_feet_regulation: -0.2699
   Episode_Reward/foot_landing_vel: -0.1039
   Episode_Reward/test_gait_reward: -0.8692
Metrics/base_velocity/error_vel_xy: 1.9566
Metrics/base_velocity/error_vel_yaw: 0.9765
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 1.05s
                        Total time: 1404.10s
                               ETA: 1847.2s

################################################################################
                     [1m Learning iteration 1296/3000 [0m                     

                       Computation: 91507 steps/s (collection: 0.950s, learning 0.124s)
               Value function loss: 0.9755
                    Surrogate loss: -0.0031
             Mean action noise std: 0.6319
                     Learning rate: 0.0009
                       Mean reward: 97.00
               Mean episode length: 988.52
       Episode_Reward/keep_balance: 0.9939
     Episode_Reward/rew_lin_vel_xy: 4.3627
      Episode_Reward/rew_ang_vel_z: 2.8184
    Episode_Reward/pen_base_height: -0.3188
      Episode_Reward/pen_lin_vel_z: -0.0568
     Episode_Reward/pen_ang_vel_xy: -0.1394
   Episode_Reward/pen_joint_torque: -0.1876
    Episode_Reward/pen_joint_accel: -0.0841
    Episode_Reward/pen_action_rate: -0.3056
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0395
   Episode_Reward/pen_joint_powers: -0.0645
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7064
Episode_Reward/pen_flat_orientation: -0.1124
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.2878
   Episode_Reward/foot_landing_vel: -0.1191
   Episode_Reward/test_gait_reward: -0.8989
Metrics/base_velocity/error_vel_xy: 2.0037
Metrics/base_velocity/error_vel_yaw: 1.0321
      Episode_Termination/time_out: 4.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 1.07s
                        Total time: 1405.17s
                               ETA: 1846.1s

################################################################################
                     [1m Learning iteration 1297/3000 [0m                     

                       Computation: 91300 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 1.0951
                    Surrogate loss: -0.0010
             Mean action noise std: 0.6321
                     Learning rate: 0.0003
                       Mean reward: 100.76
               Mean episode length: 962.54
       Episode_Reward/keep_balance: 0.9695
     Episode_Reward/rew_lin_vel_xy: 4.6888
      Episode_Reward/rew_ang_vel_z: 2.7622
    Episode_Reward/pen_base_height: -0.3229
      Episode_Reward/pen_lin_vel_z: -0.0563
     Episode_Reward/pen_ang_vel_xy: -0.1384
   Episode_Reward/pen_joint_torque: -0.1885
    Episode_Reward/pen_joint_accel: -0.0912
    Episode_Reward/pen_action_rate: -0.2995
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0387
   Episode_Reward/pen_joint_powers: -0.0644
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6889
Episode_Reward/pen_flat_orientation: -0.1166
  Episode_Reward/pen_feet_distance: -0.0073
Episode_Reward/pen_feet_regulation: -0.2783
   Episode_Reward/foot_landing_vel: -0.1083
   Episode_Reward/test_gait_reward: -0.8911
Metrics/base_velocity/error_vel_xy: 1.7174
Metrics/base_velocity/error_vel_yaw: 1.0017
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 1.08s
                        Total time: 1406.25s
                               ETA: 1845.0s

################################################################################
                     [1m Learning iteration 1298/3000 [0m                     

                       Computation: 93340 steps/s (collection: 0.930s, learning 0.123s)
               Value function loss: 1.1364
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6319
                     Learning rate: 0.0004
                       Mean reward: 94.16
               Mean episode length: 967.76
       Episode_Reward/keep_balance: 0.9734
     Episode_Reward/rew_lin_vel_xy: 4.2386
      Episode_Reward/rew_ang_vel_z: 2.7534
    Episode_Reward/pen_base_height: -0.3315
      Episode_Reward/pen_lin_vel_z: -0.0624
     Episode_Reward/pen_ang_vel_xy: -0.1407
   Episode_Reward/pen_joint_torque: -0.1970
    Episode_Reward/pen_joint_accel: -0.0833
    Episode_Reward/pen_action_rate: -0.3026
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0397
   Episode_Reward/pen_joint_powers: -0.0664
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6897
Episode_Reward/pen_flat_orientation: -0.1151
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.3080
   Episode_Reward/foot_landing_vel: -0.1178
   Episode_Reward/test_gait_reward: -0.8826
Metrics/base_velocity/error_vel_xy: 2.0046
Metrics/base_velocity/error_vel_yaw: 1.0141
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 1.05s
                        Total time: 1407.30s
                               ETA: 1843.9s

################################################################################
                     [1m Learning iteration 1299/3000 [0m                     

                       Computation: 92721 steps/s (collection: 0.937s, learning 0.123s)
               Value function loss: 0.9601
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6317
                     Learning rate: 0.0004
                       Mean reward: 99.78
               Mean episode length: 975.20
       Episode_Reward/keep_balance: 0.9698
     Episode_Reward/rew_lin_vel_xy: 4.5698
      Episode_Reward/rew_ang_vel_z: 2.7722
    Episode_Reward/pen_base_height: -0.3250
      Episode_Reward/pen_lin_vel_z: -0.0553
     Episode_Reward/pen_ang_vel_xy: -0.1359
   Episode_Reward/pen_joint_torque: -0.1882
    Episode_Reward/pen_joint_accel: -0.0866
    Episode_Reward/pen_action_rate: -0.2993
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0388
   Episode_Reward/pen_joint_powers: -0.0641
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6878
Episode_Reward/pen_flat_orientation: -0.1164
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.2849
   Episode_Reward/foot_landing_vel: -0.1074
   Episode_Reward/test_gait_reward: -0.8893
Metrics/base_velocity/error_vel_xy: 1.7741
Metrics/base_velocity/error_vel_yaw: 0.9912
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 1.06s
                        Total time: 1408.37s
                               ETA: 1842.8s

################################################################################
                     [1m Learning iteration 1300/3000 [0m                     

                       Computation: 92145 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 1.0069
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6317
                     Learning rate: 0.0009
                       Mean reward: 93.13
               Mean episode length: 961.74
       Episode_Reward/keep_balance: 0.9483
     Episode_Reward/rew_lin_vel_xy: 4.1700
      Episode_Reward/rew_ang_vel_z: 2.6894
    Episode_Reward/pen_base_height: -0.3224
      Episode_Reward/pen_lin_vel_z: -0.0568
     Episode_Reward/pen_ang_vel_xy: -0.1412
   Episode_Reward/pen_joint_torque: -0.1819
    Episode_Reward/pen_joint_accel: -0.0853
    Episode_Reward/pen_action_rate: -0.2937
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0391
   Episode_Reward/pen_joint_powers: -0.0636
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.6737
Episode_Reward/pen_flat_orientation: -0.1175
  Episode_Reward/pen_feet_distance: -0.0077
Episode_Reward/pen_feet_regulation: -0.2895
   Episode_Reward/foot_landing_vel: -0.1092
   Episode_Reward/test_gait_reward: -0.8620
Metrics/base_velocity/error_vel_xy: 1.9623
Metrics/base_velocity/error_vel_yaw: 0.9886
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 1.07s
                        Total time: 1409.43s
                               ETA: 1841.7s

################################################################################
                     [1m Learning iteration 1301/3000 [0m                     

                       Computation: 91256 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 0.9597
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6323
                     Learning rate: 0.0004
                       Mean reward: 96.84
               Mean episode length: 982.97
       Episode_Reward/keep_balance: 0.9858
     Episode_Reward/rew_lin_vel_xy: 4.4135
      Episode_Reward/rew_ang_vel_z: 2.7873
    Episode_Reward/pen_base_height: -0.3371
      Episode_Reward/pen_lin_vel_z: -0.0597
     Episode_Reward/pen_ang_vel_xy: -0.1399
   Episode_Reward/pen_joint_torque: -0.1922
    Episode_Reward/pen_joint_accel: -0.0890
    Episode_Reward/pen_action_rate: -0.3039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0397
   Episode_Reward/pen_joint_powers: -0.0658
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7028
Episode_Reward/pen_flat_orientation: -0.1152
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.2939
   Episode_Reward/foot_landing_vel: -0.1145
   Episode_Reward/test_gait_reward: -0.9001
Metrics/base_velocity/error_vel_xy: 2.0059
Metrics/base_velocity/error_vel_yaw: 1.0312
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 1.08s
                        Total time: 1410.51s
                               ETA: 1840.6s

################################################################################
                     [1m Learning iteration 1302/3000 [0m                     

                       Computation: 92378 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 1.0840
                    Surrogate loss: -0.0031
             Mean action noise std: 0.6318
                     Learning rate: 0.0009
                       Mean reward: 96.91
               Mean episode length: 978.41
       Episode_Reward/keep_balance: 0.9724
     Episode_Reward/rew_lin_vel_xy: 4.4297
      Episode_Reward/rew_ang_vel_z: 2.7656
    Episode_Reward/pen_base_height: -0.3265
      Episode_Reward/pen_lin_vel_z: -0.0557
     Episode_Reward/pen_ang_vel_xy: -0.1376
   Episode_Reward/pen_joint_torque: -0.1901
    Episode_Reward/pen_joint_accel: -0.0854
    Episode_Reward/pen_action_rate: -0.2991
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0388
   Episode_Reward/pen_joint_powers: -0.0640
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6902
Episode_Reward/pen_flat_orientation: -0.1166
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.2769
   Episode_Reward/foot_landing_vel: -0.1113
   Episode_Reward/test_gait_reward: -0.8753
Metrics/base_velocity/error_vel_xy: 1.8690
Metrics/base_velocity/error_vel_yaw: 1.0108
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 1.06s
                        Total time: 1411.57s
                               ETA: 1839.5s

################################################################################
                     [1m Learning iteration 1303/3000 [0m                     

                       Computation: 92354 steps/s (collection: 0.941s, learning 0.124s)
               Value function loss: 1.0189
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6327
                     Learning rate: 0.0006
                       Mean reward: 93.45
               Mean episode length: 961.73
       Episode_Reward/keep_balance: 0.9546
     Episode_Reward/rew_lin_vel_xy: 4.1299
      Episode_Reward/rew_ang_vel_z: 2.7049
    Episode_Reward/pen_base_height: -0.3227
      Episode_Reward/pen_lin_vel_z: -0.0589
     Episode_Reward/pen_ang_vel_xy: -0.1383
   Episode_Reward/pen_joint_torque: -0.1894
    Episode_Reward/pen_joint_accel: -0.0853
    Episode_Reward/pen_action_rate: -0.2937
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0394
   Episode_Reward/pen_joint_powers: -0.0651
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6716
Episode_Reward/pen_flat_orientation: -0.1135
  Episode_Reward/pen_feet_distance: -0.0100
Episode_Reward/pen_feet_regulation: -0.2945
   Episode_Reward/foot_landing_vel: -0.1156
   Episode_Reward/test_gait_reward: -0.8693
Metrics/base_velocity/error_vel_xy: 1.9875
Metrics/base_velocity/error_vel_yaw: 0.9930
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 1.06s
                        Total time: 1412.64s
                               ETA: 1838.4s

################################################################################
                     [1m Learning iteration 1304/3000 [0m                     

                       Computation: 93633 steps/s (collection: 0.928s, learning 0.122s)
               Value function loss: 1.0037
                    Surrogate loss: -0.0031
             Mean action noise std: 0.6334
                     Learning rate: 0.0006
                       Mean reward: 93.29
               Mean episode length: 932.47
       Episode_Reward/keep_balance: 0.9335
     Episode_Reward/rew_lin_vel_xy: 4.2430
      Episode_Reward/rew_ang_vel_z: 2.6458
    Episode_Reward/pen_base_height: -0.3165
      Episode_Reward/pen_lin_vel_z: -0.0545
     Episode_Reward/pen_ang_vel_xy: -0.1366
   Episode_Reward/pen_joint_torque: -0.1816
    Episode_Reward/pen_joint_accel: -0.0741
    Episode_Reward/pen_action_rate: -0.2856
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0372
   Episode_Reward/pen_joint_powers: -0.0619
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6609
Episode_Reward/pen_flat_orientation: -0.1161
  Episode_Reward/pen_feet_distance: -0.0054
Episode_Reward/pen_feet_regulation: -0.2739
   Episode_Reward/foot_landing_vel: -0.1079
   Episode_Reward/test_gait_reward: -0.8394
Metrics/base_velocity/error_vel_xy: 1.7710
Metrics/base_velocity/error_vel_yaw: 0.9744
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 1.05s
                        Total time: 1413.69s
                               ETA: 1837.3s

################################################################################
                     [1m Learning iteration 1305/3000 [0m                     

                       Computation: 92555 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 1.0690
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6339
                     Learning rate: 0.0006
                       Mean reward: 92.72
               Mean episode length: 953.05
       Episode_Reward/keep_balance: 0.9272
     Episode_Reward/rew_lin_vel_xy: 4.1893
      Episode_Reward/rew_ang_vel_z: 2.5971
    Episode_Reward/pen_base_height: -0.3191
      Episode_Reward/pen_lin_vel_z: -0.0566
     Episode_Reward/pen_ang_vel_xy: -0.1379
   Episode_Reward/pen_joint_torque: -0.1819
    Episode_Reward/pen_joint_accel: -0.0803
    Episode_Reward/pen_action_rate: -0.2883
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0387
   Episode_Reward/pen_joint_powers: -0.0630
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6635
Episode_Reward/pen_flat_orientation: -0.1170
  Episode_Reward/pen_feet_distance: -0.0075
Episode_Reward/pen_feet_regulation: -0.2817
   Episode_Reward/foot_landing_vel: -0.1106
   Episode_Reward/test_gait_reward: -0.8447
Metrics/base_velocity/error_vel_xy: 1.8231
Metrics/base_velocity/error_vel_yaw: 0.9909
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 1.06s
                        Total time: 1414.75s
                               ETA: 1836.1s

################################################################################
                     [1m Learning iteration 1306/3000 [0m                     

                       Computation: 91787 steps/s (collection: 0.944s, learning 0.127s)
               Value function loss: 1.0572
                    Surrogate loss: 0.0011
             Mean action noise std: 0.6346
                     Learning rate: 0.0001
                       Mean reward: 95.80
               Mean episode length: 937.87
       Episode_Reward/keep_balance: 0.9570
     Episode_Reward/rew_lin_vel_xy: 4.5525
      Episode_Reward/rew_ang_vel_z: 2.7168
    Episode_Reward/pen_base_height: -0.3180
      Episode_Reward/pen_lin_vel_z: -0.0561
     Episode_Reward/pen_ang_vel_xy: -0.1409
   Episode_Reward/pen_joint_torque: -0.1817
    Episode_Reward/pen_joint_accel: -0.0833
    Episode_Reward/pen_action_rate: -0.2933
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0392
   Episode_Reward/pen_joint_powers: -0.0636
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6820
Episode_Reward/pen_flat_orientation: -0.1112
  Episode_Reward/pen_feet_distance: -0.0065
Episode_Reward/pen_feet_regulation: -0.2914
   Episode_Reward/foot_landing_vel: -0.1165
   Episode_Reward/test_gait_reward: -0.8686
Metrics/base_velocity/error_vel_xy: 1.7372
Metrics/base_velocity/error_vel_yaw: 0.9933
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 1.07s
                        Total time: 1415.82s
                               ETA: 1835.0s

################################################################################
                     [1m Learning iteration 1307/3000 [0m                     

                       Computation: 90763 steps/s (collection: 0.958s, learning 0.125s)
               Value function loss: 1.0800
                    Surrogate loss: 0.0024
             Mean action noise std: 0.6346
                     Learning rate: 0.0000
                       Mean reward: 100.63
               Mean episode length: 985.91
       Episode_Reward/keep_balance: 0.9873
     Episode_Reward/rew_lin_vel_xy: 4.5222
      Episode_Reward/rew_ang_vel_z: 2.8353
    Episode_Reward/pen_base_height: -0.3284
      Episode_Reward/pen_lin_vel_z: -0.0572
     Episode_Reward/pen_ang_vel_xy: -0.1350
   Episode_Reward/pen_joint_torque: -0.1920
    Episode_Reward/pen_joint_accel: -0.0863
    Episode_Reward/pen_action_rate: -0.2999
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0387
   Episode_Reward/pen_joint_powers: -0.0649
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6920
Episode_Reward/pen_flat_orientation: -0.1100
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.2857
   Episode_Reward/foot_landing_vel: -0.1126
   Episode_Reward/test_gait_reward: -0.8913
Metrics/base_velocity/error_vel_xy: 1.9662
Metrics/base_velocity/error_vel_yaw: 0.9972
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 1.08s
                        Total time: 1416.90s
                               ETA: 1834.0s

################################################################################
                     [1m Learning iteration 1308/3000 [0m                     

                       Computation: 89801 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 1.0170
                    Surrogate loss: 0.0022
             Mean action noise std: 0.6346
                     Learning rate: 0.0000
                       Mean reward: 97.32
               Mean episode length: 978.01
       Episode_Reward/keep_balance: 0.9829
     Episode_Reward/rew_lin_vel_xy: 4.4842
      Episode_Reward/rew_ang_vel_z: 2.7608
    Episode_Reward/pen_base_height: -0.3281
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1428
   Episode_Reward/pen_joint_torque: -0.1949
    Episode_Reward/pen_joint_accel: -0.0842
    Episode_Reward/pen_action_rate: -0.3044
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0395
   Episode_Reward/pen_joint_powers: -0.0658
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7004
Episode_Reward/pen_flat_orientation: -0.1177
  Episode_Reward/pen_feet_distance: -0.0097
Episode_Reward/pen_feet_regulation: -0.2829
   Episode_Reward/foot_landing_vel: -0.1074
   Episode_Reward/test_gait_reward: -0.8936
Metrics/base_velocity/error_vel_xy: 1.8857
Metrics/base_velocity/error_vel_yaw: 1.0451
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 1.09s
                        Total time: 1418.00s
                               ETA: 1832.9s

################################################################################
                     [1m Learning iteration 1309/3000 [0m                     

                       Computation: 90319 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.9675
                    Surrogate loss: 0.0032
             Mean action noise std: 0.6346
                     Learning rate: 0.0000
                       Mean reward: 99.47
               Mean episode length: 970.64
       Episode_Reward/keep_balance: 0.9816
     Episode_Reward/rew_lin_vel_xy: 4.6817
      Episode_Reward/rew_ang_vel_z: 2.7586
    Episode_Reward/pen_base_height: -0.3280
      Episode_Reward/pen_lin_vel_z: -0.0574
     Episode_Reward/pen_ang_vel_xy: -0.1396
   Episode_Reward/pen_joint_torque: -0.1897
    Episode_Reward/pen_joint_accel: -0.0828
    Episode_Reward/pen_action_rate: -0.3042
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0408
   Episode_Reward/pen_joint_powers: -0.0664
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6997
Episode_Reward/pen_flat_orientation: -0.1140
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.3048
   Episode_Reward/foot_landing_vel: -0.1192
   Episode_Reward/test_gait_reward: -0.8987
Metrics/base_velocity/error_vel_xy: 1.7827
Metrics/base_velocity/error_vel_yaw: 1.0371
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 1.09s
                        Total time: 1419.09s
                               ETA: 1831.8s

################################################################################
                     [1m Learning iteration 1310/3000 [0m                     

                       Computation: 90019 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.9326
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6347
                     Learning rate: 0.0002
                       Mean reward: 90.71
               Mean episode length: 940.70
       Episode_Reward/keep_balance: 0.9209
     Episode_Reward/rew_lin_vel_xy: 4.0808
      Episode_Reward/rew_ang_vel_z: 2.5835
    Episode_Reward/pen_base_height: -0.3267
      Episode_Reward/pen_lin_vel_z: -0.0575
     Episode_Reward/pen_ang_vel_xy: -0.1337
   Episode_Reward/pen_joint_torque: -0.1866
    Episode_Reward/pen_joint_accel: -0.0821
    Episode_Reward/pen_action_rate: -0.2884
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0395
   Episode_Reward/pen_joint_powers: -0.0642
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.6530
Episode_Reward/pen_flat_orientation: -0.1137
  Episode_Reward/pen_feet_distance: -0.0122
Episode_Reward/pen_feet_regulation: -0.2993
   Episode_Reward/foot_landing_vel: -0.1211
   Episode_Reward/test_gait_reward: -0.8400
Metrics/base_velocity/error_vel_xy: 1.8609
Metrics/base_velocity/error_vel_yaw: 0.9866
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 1.09s
                        Total time: 1420.18s
                               ETA: 1830.7s

################################################################################
                     [1m Learning iteration 1311/3000 [0m                     

                       Computation: 90275 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.9870
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6350
                     Learning rate: 0.0004
                       Mean reward: 98.90
               Mean episode length: 986.16
       Episode_Reward/keep_balance: 0.9825
     Episode_Reward/rew_lin_vel_xy: 4.5645
      Episode_Reward/rew_ang_vel_z: 2.8004
    Episode_Reward/pen_base_height: -0.3259
      Episode_Reward/pen_lin_vel_z: -0.0569
     Episode_Reward/pen_ang_vel_xy: -0.1426
   Episode_Reward/pen_joint_torque: -0.1858
    Episode_Reward/pen_joint_accel: -0.0896
    Episode_Reward/pen_action_rate: -0.3024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0397
   Episode_Reward/pen_joint_powers: -0.0644
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6993
Episode_Reward/pen_flat_orientation: -0.1227
  Episode_Reward/pen_feet_distance: -0.0094
Episode_Reward/pen_feet_regulation: -0.2919
   Episode_Reward/foot_landing_vel: -0.1165
   Episode_Reward/test_gait_reward: -0.8935
Metrics/base_velocity/error_vel_xy: 1.8256
Metrics/base_velocity/error_vel_yaw: 1.0094
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 1.09s
                        Total time: 1421.27s
                               ETA: 1829.7s

################################################################################
                     [1m Learning iteration 1312/3000 [0m                     

                       Computation: 90829 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 0.9915
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6355
                     Learning rate: 0.0009
                       Mean reward: 97.17
               Mean episode length: 980.60
       Episode_Reward/keep_balance: 0.9712
     Episode_Reward/rew_lin_vel_xy: 4.3039
      Episode_Reward/rew_ang_vel_z: 2.7078
    Episode_Reward/pen_base_height: -0.3227
      Episode_Reward/pen_lin_vel_z: -0.0541
     Episode_Reward/pen_ang_vel_xy: -0.1384
   Episode_Reward/pen_joint_torque: -0.1855
    Episode_Reward/pen_joint_accel: -0.0832
    Episode_Reward/pen_action_rate: -0.3000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0394
   Episode_Reward/pen_joint_powers: -0.0639
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6978
Episode_Reward/pen_flat_orientation: -0.1135
  Episode_Reward/pen_feet_distance: -0.0082
Episode_Reward/pen_feet_regulation: -0.2849
   Episode_Reward/foot_landing_vel: -0.1127
   Episode_Reward/test_gait_reward: -0.8791
Metrics/base_velocity/error_vel_xy: 1.9121
Metrics/base_velocity/error_vel_yaw: 1.0493
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 1.08s
                        Total time: 1422.35s
                               ETA: 1828.6s

################################################################################
                     [1m Learning iteration 1313/3000 [0m                     

                       Computation: 92602 steps/s (collection: 0.938s, learning 0.124s)
               Value function loss: 1.0390
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6353
                     Learning rate: 0.0004
                       Mean reward: 92.07
               Mean episode length: 976.84
       Episode_Reward/keep_balance: 0.9745
     Episode_Reward/rew_lin_vel_xy: 4.1700
      Episode_Reward/rew_ang_vel_z: 2.7402
    Episode_Reward/pen_base_height: -0.3322
      Episode_Reward/pen_lin_vel_z: -0.0538
     Episode_Reward/pen_ang_vel_xy: -0.1442
   Episode_Reward/pen_joint_torque: -0.1873
    Episode_Reward/pen_joint_accel: -0.0826
    Episode_Reward/pen_action_rate: -0.3015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0397
   Episode_Reward/pen_joint_powers: -0.0641
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6945
Episode_Reward/pen_flat_orientation: -0.1164
  Episode_Reward/pen_feet_distance: -0.0093
Episode_Reward/pen_feet_regulation: -0.2813
   Episode_Reward/foot_landing_vel: -0.1153
   Episode_Reward/test_gait_reward: -0.8726
Metrics/base_velocity/error_vel_xy: 2.0250
Metrics/base_velocity/error_vel_yaw: 1.0355
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 1.06s
                        Total time: 1423.41s
                               ETA: 1827.5s

################################################################################
                     [1m Learning iteration 1314/3000 [0m                     

                       Computation: 91819 steps/s (collection: 0.947s, learning 0.124s)
               Value function loss: 0.9973
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6354
                     Learning rate: 0.0004
                       Mean reward: 97.40
               Mean episode length: 973.70
       Episode_Reward/keep_balance: 0.9787
     Episode_Reward/rew_lin_vel_xy: 4.5085
      Episode_Reward/rew_ang_vel_z: 2.7544
    Episode_Reward/pen_base_height: -0.3375
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1370
   Episode_Reward/pen_joint_torque: -0.1914
    Episode_Reward/pen_joint_accel: -0.0849
    Episode_Reward/pen_action_rate: -0.3008
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0395
   Episode_Reward/pen_joint_powers: -0.0658
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6907
Episode_Reward/pen_flat_orientation: -0.1171
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.2976
   Episode_Reward/foot_landing_vel: -0.1092
   Episode_Reward/test_gait_reward: -0.8870
Metrics/base_velocity/error_vel_xy: 1.9008
Metrics/base_velocity/error_vel_yaw: 1.0324
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 1.07s
                        Total time: 1424.48s
                               ETA: 1826.4s

################################################################################
                     [1m Learning iteration 1315/3000 [0m                     

                       Computation: 92193 steps/s (collection: 0.941s, learning 0.125s)
               Value function loss: 1.0510
                    Surrogate loss: -0.0029
             Mean action noise std: 0.6354
                     Learning rate: 0.0009
                       Mean reward: 100.37
               Mean episode length: 978.85
       Episode_Reward/keep_balance: 0.9815
     Episode_Reward/rew_lin_vel_xy: 4.7367
      Episode_Reward/rew_ang_vel_z: 2.7779
    Episode_Reward/pen_base_height: -0.3335
      Episode_Reward/pen_lin_vel_z: -0.0540
     Episode_Reward/pen_ang_vel_xy: -0.1358
   Episode_Reward/pen_joint_torque: -0.1882
    Episode_Reward/pen_joint_accel: -0.0875
    Episode_Reward/pen_action_rate: -0.2999
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0390
   Episode_Reward/pen_joint_powers: -0.0641
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6959
Episode_Reward/pen_flat_orientation: -0.1098
  Episode_Reward/pen_feet_distance: -0.0066
Episode_Reward/pen_feet_regulation: -0.2871
   Episode_Reward/foot_landing_vel: -0.1097
   Episode_Reward/test_gait_reward: -0.8859
Metrics/base_velocity/error_vel_xy: 1.7449
Metrics/base_velocity/error_vel_yaw: 1.0243
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 1.07s
                        Total time: 1425.55s
                               ETA: 1825.3s

################################################################################
                     [1m Learning iteration 1316/3000 [0m                     

                       Computation: 92945 steps/s (collection: 0.934s, learning 0.123s)
               Value function loss: 0.9984
                    Surrogate loss: 0.0014
             Mean action noise std: 0.6353
                     Learning rate: 0.0001
                       Mean reward: 97.04
               Mean episode length: 982.14
       Episode_Reward/keep_balance: 0.9878
     Episode_Reward/rew_lin_vel_xy: 4.3768
      Episode_Reward/rew_ang_vel_z: 2.7943
    Episode_Reward/pen_base_height: -0.3288
      Episode_Reward/pen_lin_vel_z: -0.0582
     Episode_Reward/pen_ang_vel_xy: -0.1451
   Episode_Reward/pen_joint_torque: -0.1947
    Episode_Reward/pen_joint_accel: -0.0922
    Episode_Reward/pen_action_rate: -0.3048
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0412
   Episode_Reward/pen_joint_powers: -0.0672
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7046
Episode_Reward/pen_flat_orientation: -0.1176
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.2980
   Episode_Reward/foot_landing_vel: -0.1162
   Episode_Reward/test_gait_reward: -0.9051
Metrics/base_velocity/error_vel_xy: 1.9694
Metrics/base_velocity/error_vel_yaw: 1.0301
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 1.06s
                        Total time: 1426.61s
                               ETA: 1824.1s

################################################################################
                     [1m Learning iteration 1317/3000 [0m                     

                       Computation: 92540 steps/s (collection: 0.938s, learning 0.125s)
               Value function loss: 0.9027
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6354
                     Learning rate: 0.0002
                       Mean reward: 95.71
               Mean episode length: 966.21
       Episode_Reward/keep_balance: 0.9291
     Episode_Reward/rew_lin_vel_xy: 4.2716
      Episode_Reward/rew_ang_vel_z: 2.6019
    Episode_Reward/pen_base_height: -0.3279
      Episode_Reward/pen_lin_vel_z: -0.0551
     Episode_Reward/pen_ang_vel_xy: -0.1387
   Episode_Reward/pen_joint_torque: -0.1794
    Episode_Reward/pen_joint_accel: -0.0786
    Episode_Reward/pen_action_rate: -0.2895
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0391
   Episode_Reward/pen_joint_powers: -0.0633
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6668
Episode_Reward/pen_flat_orientation: -0.1171
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.2982
   Episode_Reward/foot_landing_vel: -0.1078
   Episode_Reward/test_gait_reward: -0.8511
Metrics/base_velocity/error_vel_xy: 1.8217
Metrics/base_velocity/error_vel_yaw: 0.9918
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 1.06s
                        Total time: 1427.67s
                               ETA: 1823.0s

################################################################################
                     [1m Learning iteration 1318/3000 [0m                     

                       Computation: 92027 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.9071
                    Surrogate loss: -0.0037
             Mean action noise std: 0.6342
                     Learning rate: 0.0004
                       Mean reward: 99.13
               Mean episode length: 981.84
       Episode_Reward/keep_balance: 0.9829
     Episode_Reward/rew_lin_vel_xy: 4.6615
      Episode_Reward/rew_ang_vel_z: 2.7399
    Episode_Reward/pen_base_height: -0.3286
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1470
   Episode_Reward/pen_joint_torque: -0.1859
    Episode_Reward/pen_joint_accel: -0.0897
    Episode_Reward/pen_action_rate: -0.3085
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0410
   Episode_Reward/pen_joint_powers: -0.0656
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7106
Episode_Reward/pen_flat_orientation: -0.1140
  Episode_Reward/pen_feet_distance: -0.0055
Episode_Reward/pen_feet_regulation: -0.2979
   Episode_Reward/foot_landing_vel: -0.1235
   Episode_Reward/test_gait_reward: -0.8969
Metrics/base_velocity/error_vel_xy: 1.7585
Metrics/base_velocity/error_vel_yaw: 1.0595
      Episode_Termination/time_out: 5.1250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 1.07s
                        Total time: 1428.74s
                               ETA: 1821.9s

################################################################################
                     [1m Learning iteration 1319/3000 [0m                     

                       Computation: 91377 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 1.0652
                    Surrogate loss: -0.0001
             Mean action noise std: 0.6333
                     Learning rate: 0.0003
                       Mean reward: 100.88
               Mean episode length: 978.98
       Episode_Reward/keep_balance: 0.9838
     Episode_Reward/rew_lin_vel_xy: 4.5583
      Episode_Reward/rew_ang_vel_z: 2.7902
    Episode_Reward/pen_base_height: -0.3381
      Episode_Reward/pen_lin_vel_z: -0.0563
     Episode_Reward/pen_ang_vel_xy: -0.1389
   Episode_Reward/pen_joint_torque: -0.1884
    Episode_Reward/pen_joint_accel: -0.0824
    Episode_Reward/pen_action_rate: -0.3009
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0397
   Episode_Reward/pen_joint_powers: -0.0647
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6990
Episode_Reward/pen_flat_orientation: -0.1161
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.2928
   Episode_Reward/foot_landing_vel: -0.1162
   Episode_Reward/test_gait_reward: -0.8880
Metrics/base_velocity/error_vel_xy: 1.8956
Metrics/base_velocity/error_vel_yaw: 1.0235
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 1.08s
                        Total time: 1429.81s
                               ETA: 1820.8s

################################################################################
                     [1m Learning iteration 1320/3000 [0m                     

                       Computation: 92504 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 1.0114
                    Surrogate loss: -0.0039
             Mean action noise std: 0.6331
                     Learning rate: 0.0004
                       Mean reward: 96.89
               Mean episode length: 980.98
       Episode_Reward/keep_balance: 0.9900
     Episode_Reward/rew_lin_vel_xy: 4.4661
      Episode_Reward/rew_ang_vel_z: 2.7852
    Episode_Reward/pen_base_height: -0.3312
      Episode_Reward/pen_lin_vel_z: -0.0577
     Episode_Reward/pen_ang_vel_xy: -0.1453
   Episode_Reward/pen_joint_torque: -0.1965
    Episode_Reward/pen_joint_accel: -0.0894
    Episode_Reward/pen_action_rate: -0.3078
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0409
   Episode_Reward/pen_joint_powers: -0.0670
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7094
Episode_Reward/pen_flat_orientation: -0.1190
  Episode_Reward/pen_feet_distance: -0.0109
Episode_Reward/pen_feet_regulation: -0.3102
   Episode_Reward/foot_landing_vel: -0.1140
   Episode_Reward/test_gait_reward: -0.8965
Metrics/base_velocity/error_vel_xy: 1.9999
Metrics/base_velocity/error_vel_yaw: 1.0410
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 1.06s
                        Total time: 1430.88s
                               ETA: 1819.7s

################################################################################
                     [1m Learning iteration 1321/3000 [0m                     

                       Computation: 92149 steps/s (collection: 0.943s, learning 0.124s)
               Value function loss: 0.9094
                    Surrogate loss: -0.0029
             Mean action noise std: 0.6337
                     Learning rate: 0.0009
                       Mean reward: 100.41
               Mean episode length: 988.90
       Episode_Reward/keep_balance: 0.9906
     Episode_Reward/rew_lin_vel_xy: 4.5693
      Episode_Reward/rew_ang_vel_z: 2.8040
    Episode_Reward/pen_base_height: -0.3256
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1425
   Episode_Reward/pen_joint_torque: -0.1891
    Episode_Reward/pen_joint_accel: -0.0880
    Episode_Reward/pen_action_rate: -0.3031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0400
   Episode_Reward/pen_joint_powers: -0.0654
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7066
Episode_Reward/pen_flat_orientation: -0.1106
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.2848
   Episode_Reward/foot_landing_vel: -0.1157
   Episode_Reward/test_gait_reward: -0.8874
Metrics/base_velocity/error_vel_xy: 1.8326
Metrics/base_velocity/error_vel_yaw: 1.0324
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 1.07s
                        Total time: 1431.94s
                               ETA: 1818.6s

################################################################################
                     [1m Learning iteration 1322/3000 [0m                     

                       Computation: 90276 steps/s (collection: 0.964s, learning 0.125s)
               Value function loss: 0.9882
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6339
                     Learning rate: 0.0006
                       Mean reward: 98.53
               Mean episode length: 991.64
       Episode_Reward/keep_balance: 0.9917
     Episode_Reward/rew_lin_vel_xy: 4.4210
      Episode_Reward/rew_ang_vel_z: 2.7582
    Episode_Reward/pen_base_height: -0.3329
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1407
   Episode_Reward/pen_joint_torque: -0.1918
    Episode_Reward/pen_joint_accel: -0.0937
    Episode_Reward/pen_action_rate: -0.3101
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0407
   Episode_Reward/pen_joint_powers: -0.0655
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7153
Episode_Reward/pen_flat_orientation: -0.1158
  Episode_Reward/pen_feet_distance: -0.0072
Episode_Reward/pen_feet_regulation: -0.3027
   Episode_Reward/foot_landing_vel: -0.1228
   Episode_Reward/test_gait_reward: -0.8966
Metrics/base_velocity/error_vel_xy: 2.0087
Metrics/base_velocity/error_vel_yaw: 1.0768
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 1.09s
                        Total time: 1433.03s
                               ETA: 1817.6s

################################################################################
                     [1m Learning iteration 1323/3000 [0m                     

                       Computation: 89724 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 1.0112
                    Surrogate loss: -0.0031
             Mean action noise std: 0.6333
                     Learning rate: 0.0009
                       Mean reward: 96.23
               Mean episode length: 986.60
       Episode_Reward/keep_balance: 0.9879
     Episode_Reward/rew_lin_vel_xy: 4.4139
      Episode_Reward/rew_ang_vel_z: 2.7656
    Episode_Reward/pen_base_height: -0.3266
      Episode_Reward/pen_lin_vel_z: -0.0529
     Episode_Reward/pen_ang_vel_xy: -0.1383
   Episode_Reward/pen_joint_torque: -0.1871
    Episode_Reward/pen_joint_accel: -0.0897
    Episode_Reward/pen_action_rate: -0.3027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0390
   Episode_Reward/pen_joint_powers: -0.0640
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6996
Episode_Reward/pen_flat_orientation: -0.1090
  Episode_Reward/pen_feet_distance: -0.0108
Episode_Reward/pen_feet_regulation: -0.2742
   Episode_Reward/foot_landing_vel: -0.1107
   Episode_Reward/test_gait_reward: -0.8917
Metrics/base_velocity/error_vel_xy: 1.9211
Metrics/base_velocity/error_vel_yaw: 1.0533
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 1.10s
                        Total time: 1434.13s
                               ETA: 1816.5s

################################################################################
                     [1m Learning iteration 1324/3000 [0m                     

                       Computation: 90240 steps/s (collection: 0.964s, learning 0.125s)
               Value function loss: 1.0673
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6331
                     Learning rate: 0.0002
                       Mean reward: 93.81
               Mean episode length: 943.69
       Episode_Reward/keep_balance: 0.9559
     Episode_Reward/rew_lin_vel_xy: 4.5144
      Episode_Reward/rew_ang_vel_z: 2.6999
    Episode_Reward/pen_base_height: -0.3261
      Episode_Reward/pen_lin_vel_z: -0.0591
     Episode_Reward/pen_ang_vel_xy: -0.1427
   Episode_Reward/pen_joint_torque: -0.1840
    Episode_Reward/pen_joint_accel: -0.0909
    Episode_Reward/pen_action_rate: -0.3017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0410
   Episode_Reward/pen_joint_powers: -0.0650
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6920
Episode_Reward/pen_flat_orientation: -0.1137
  Episode_Reward/pen_feet_distance: -0.0052
Episode_Reward/pen_feet_regulation: -0.3044
   Episode_Reward/foot_landing_vel: -0.1293
   Episode_Reward/test_gait_reward: -0.8708
Metrics/base_velocity/error_vel_xy: 1.7848
Metrics/base_velocity/error_vel_yaw: 1.0012
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 1.09s
                        Total time: 1435.22s
                               ETA: 1815.4s

################################################################################
                     [1m Learning iteration 1325/3000 [0m                     

                       Computation: 92622 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 1.0490
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6334
                     Learning rate: 0.0002
                       Mean reward: 90.06
               Mean episode length: 914.77
       Episode_Reward/keep_balance: 0.9282
     Episode_Reward/rew_lin_vel_xy: 4.2312
      Episode_Reward/rew_ang_vel_z: 2.6259
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0550
     Episode_Reward/pen_ang_vel_xy: -0.1411
   Episode_Reward/pen_joint_torque: -0.1826
    Episode_Reward/pen_joint_accel: -0.0819
    Episode_Reward/pen_action_rate: -0.2890
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0392
   Episode_Reward/pen_joint_powers: -0.0640
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6615
Episode_Reward/pen_flat_orientation: -0.1172
  Episode_Reward/pen_feet_distance: -0.0084
Episode_Reward/pen_feet_regulation: -0.2879
   Episode_Reward/foot_landing_vel: -0.1120
   Episode_Reward/test_gait_reward: -0.8370
Metrics/base_velocity/error_vel_xy: 1.8239
Metrics/base_velocity/error_vel_yaw: 0.9776
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 1.06s
                        Total time: 1436.28s
                               ETA: 1814.3s

################################################################################
                     [1m Learning iteration 1326/3000 [0m                     

                       Computation: 92020 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.9954
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6342
                     Learning rate: 0.0003
                       Mean reward: 94.88
               Mean episode length: 962.29
       Episode_Reward/keep_balance: 0.9662
     Episode_Reward/rew_lin_vel_xy: 4.4652
      Episode_Reward/rew_ang_vel_z: 2.7207
    Episode_Reward/pen_base_height: -0.3350
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1418
   Episode_Reward/pen_joint_torque: -0.1952
    Episode_Reward/pen_joint_accel: -0.0851
    Episode_Reward/pen_action_rate: -0.3018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0407
   Episode_Reward/pen_joint_powers: -0.0670
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6875
Episode_Reward/pen_flat_orientation: -0.1203
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3056
   Episode_Reward/foot_landing_vel: -0.1138
   Episode_Reward/test_gait_reward: -0.8850
Metrics/base_velocity/error_vel_xy: 1.8284
Metrics/base_velocity/error_vel_yaw: 1.0158
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 1.07s
                        Total time: 1437.35s
                               ETA: 1813.2s

################################################################################
                     [1m Learning iteration 1327/3000 [0m                     

                       Computation: 91939 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 1.0141
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6351
                     Learning rate: 0.0003
                       Mean reward: 100.09
               Mean episode length: 974.57
       Episode_Reward/keep_balance: 0.9782
     Episode_Reward/rew_lin_vel_xy: 4.6946
      Episode_Reward/rew_ang_vel_z: 2.7817
    Episode_Reward/pen_base_height: -0.3342
      Episode_Reward/pen_lin_vel_z: -0.0552
     Episode_Reward/pen_ang_vel_xy: -0.1386
   Episode_Reward/pen_joint_torque: -0.1922
    Episode_Reward/pen_joint_accel: -0.0891
    Episode_Reward/pen_action_rate: -0.3010
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0401
   Episode_Reward/pen_joint_powers: -0.0662
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6920
Episode_Reward/pen_flat_orientation: -0.1157
  Episode_Reward/pen_feet_distance: -0.0069
Episode_Reward/pen_feet_regulation: -0.3048
   Episode_Reward/foot_landing_vel: -0.1134
   Episode_Reward/test_gait_reward: -0.8889
Metrics/base_velocity/error_vel_xy: 1.7723
Metrics/base_velocity/error_vel_yaw: 1.0117
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 1.07s
                        Total time: 1438.41s
                               ETA: 1812.1s

################################################################################
                     [1m Learning iteration 1328/3000 [0m                     

                       Computation: 90840 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 0.8650
                    Surrogate loss: -0.0040
             Mean action noise std: 0.6351
                     Learning rate: 0.0006
                       Mean reward: 94.44
               Mean episode length: 974.69
       Episode_Reward/keep_balance: 0.9808
     Episode_Reward/rew_lin_vel_xy: 4.4399
      Episode_Reward/rew_ang_vel_z: 2.7583
    Episode_Reward/pen_base_height: -0.3261
      Episode_Reward/pen_lin_vel_z: -0.0576
     Episode_Reward/pen_ang_vel_xy: -0.1457
   Episode_Reward/pen_joint_torque: -0.1968
    Episode_Reward/pen_joint_accel: -0.0931
    Episode_Reward/pen_action_rate: -0.3093
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0421
   Episode_Reward/pen_joint_powers: -0.0675
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7037
Episode_Reward/pen_flat_orientation: -0.1182
  Episode_Reward/pen_feet_distance: -0.0109
Episode_Reward/pen_feet_regulation: -0.3097
   Episode_Reward/foot_landing_vel: -0.1227
   Episode_Reward/test_gait_reward: -0.8922
Metrics/base_velocity/error_vel_xy: 1.9028
Metrics/base_velocity/error_vel_yaw: 1.0389
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 1.08s
                        Total time: 1439.50s
                               ETA: 1811.0s

################################################################################
                     [1m Learning iteration 1329/3000 [0m                     

                       Computation: 91703 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 0.9850
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6338
                     Learning rate: 0.0003
                       Mean reward: 97.11
               Mean episode length: 990.45
       Episode_Reward/keep_balance: 0.9904
     Episode_Reward/rew_lin_vel_xy: 4.5853
      Episode_Reward/rew_ang_vel_z: 2.7726
    Episode_Reward/pen_base_height: -0.3293
      Episode_Reward/pen_lin_vel_z: -0.0547
     Episode_Reward/pen_ang_vel_xy: -0.1413
   Episode_Reward/pen_joint_torque: -0.1909
    Episode_Reward/pen_joint_accel: -0.0873
    Episode_Reward/pen_action_rate: -0.3096
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0406
   Episode_Reward/pen_joint_powers: -0.0656
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7130
Episode_Reward/pen_flat_orientation: -0.1175
  Episode_Reward/pen_feet_distance: -0.0065
Episode_Reward/pen_feet_regulation: -0.2907
   Episode_Reward/foot_landing_vel: -0.1144
   Episode_Reward/test_gait_reward: -0.9003
Metrics/base_velocity/error_vel_xy: 1.8790
Metrics/base_velocity/error_vel_yaw: 1.0576
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 1.07s
                        Total time: 1440.57s
                               ETA: 1809.9s

################################################################################
                     [1m Learning iteration 1330/3000 [0m                     

                       Computation: 91569 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.9157
                    Surrogate loss: -0.0042
             Mean action noise std: 0.6347
                     Learning rate: 0.0006
                       Mean reward: 93.47
               Mean episode length: 965.88
       Episode_Reward/keep_balance: 0.9681
     Episode_Reward/rew_lin_vel_xy: 4.2879
      Episode_Reward/rew_ang_vel_z: 2.7261
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0543
     Episode_Reward/pen_ang_vel_xy: -0.1433
   Episode_Reward/pen_joint_torque: -0.1839
    Episode_Reward/pen_joint_accel: -0.0901
    Episode_Reward/pen_action_rate: -0.2998
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0403
   Episode_Reward/pen_joint_powers: -0.0648
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6931
Episode_Reward/pen_flat_orientation: -0.1128
  Episode_Reward/pen_feet_distance: -0.0082
Episode_Reward/pen_feet_regulation: -0.2929
   Episode_Reward/foot_landing_vel: -0.1168
   Episode_Reward/test_gait_reward: -0.8678
Metrics/base_velocity/error_vel_xy: 2.0024
Metrics/base_velocity/error_vel_yaw: 1.0173
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 1.07s
                        Total time: 1441.64s
                               ETA: 1808.8s

################################################################################
                     [1m Learning iteration 1331/3000 [0m                     

                       Computation: 92798 steps/s (collection: 0.936s, learning 0.123s)
               Value function loss: 0.9770
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6358
                     Learning rate: 0.0009
                       Mean reward: 95.95
               Mean episode length: 965.71
       Episode_Reward/keep_balance: 0.9774
     Episode_Reward/rew_lin_vel_xy: 4.6851
      Episode_Reward/rew_ang_vel_z: 2.7000
    Episode_Reward/pen_base_height: -0.3285
      Episode_Reward/pen_lin_vel_z: -0.0561
     Episode_Reward/pen_ang_vel_xy: -0.1441
   Episode_Reward/pen_joint_torque: -0.1917
    Episode_Reward/pen_joint_accel: -0.0925
    Episode_Reward/pen_action_rate: -0.3106
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0430
   Episode_Reward/pen_joint_powers: -0.0673
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7092
Episode_Reward/pen_flat_orientation: -0.1119
  Episode_Reward/pen_feet_distance: -0.0086
Episode_Reward/pen_feet_regulation: -0.3326
   Episode_Reward/foot_landing_vel: -0.1249
   Episode_Reward/test_gait_reward: -0.8868
Metrics/base_velocity/error_vel_xy: 1.6972
Metrics/base_velocity/error_vel_yaw: 1.0685
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 1.06s
                        Total time: 1442.70s
                               ETA: 1807.7s

################################################################################
                     [1m Learning iteration 1332/3000 [0m                     

                       Computation: 89432 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.9820
                    Surrogate loss: -0.0006
             Mean action noise std: 0.6363
                     Learning rate: 0.0001
                       Mean reward: 98.82
               Mean episode length: 965.26
       Episode_Reward/keep_balance: 0.9681
     Episode_Reward/rew_lin_vel_xy: 4.4033
      Episode_Reward/rew_ang_vel_z: 2.6994
    Episode_Reward/pen_base_height: -0.3290
      Episode_Reward/pen_lin_vel_z: -0.0527
     Episode_Reward/pen_ang_vel_xy: -0.1434
   Episode_Reward/pen_joint_torque: -0.1846
    Episode_Reward/pen_joint_accel: -0.0857
    Episode_Reward/pen_action_rate: -0.3015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0403
   Episode_Reward/pen_joint_powers: -0.0649
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6994
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.2933
   Episode_Reward/foot_landing_vel: -0.1149
   Episode_Reward/test_gait_reward: -0.8687
Metrics/base_velocity/error_vel_xy: 1.8374
Metrics/base_velocity/error_vel_yaw: 1.0368
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 1.10s
                        Total time: 1443.80s
                               ETA: 1806.6s

################################################################################
                     [1m Learning iteration 1333/3000 [0m                     

                       Computation: 91358 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 1.0058
                    Surrogate loss: -0.0051
             Mean action noise std: 0.6362
                     Learning rate: 0.0003
                       Mean reward: 101.14
               Mean episode length: 994.55
       Episode_Reward/keep_balance: 0.9951
     Episode_Reward/rew_lin_vel_xy: 4.4934
      Episode_Reward/rew_ang_vel_z: 2.8026
    Episode_Reward/pen_base_height: -0.3218
      Episode_Reward/pen_lin_vel_z: -0.0536
     Episode_Reward/pen_ang_vel_xy: -0.1419
   Episode_Reward/pen_joint_torque: -0.1868
    Episode_Reward/pen_joint_accel: -0.0826
    Episode_Reward/pen_action_rate: -0.3078
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0401
   Episode_Reward/pen_joint_powers: -0.0645
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.7178
Episode_Reward/pen_flat_orientation: -0.1163
  Episode_Reward/pen_feet_distance: -0.0108
Episode_Reward/pen_feet_regulation: -0.2882
   Episode_Reward/foot_landing_vel: -0.1114
   Episode_Reward/test_gait_reward: -0.8934
Metrics/base_velocity/error_vel_xy: 1.9506
Metrics/base_velocity/error_vel_yaw: 1.0491
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 1.08s
                        Total time: 1444.88s
                               ETA: 1805.6s

################################################################################
                     [1m Learning iteration 1334/3000 [0m                     

                       Computation: 90455 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.9519
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6358
                     Learning rate: 0.0006
                       Mean reward: 96.68
               Mean episode length: 965.99
       Episode_Reward/keep_balance: 0.9707
     Episode_Reward/rew_lin_vel_xy: 4.5920
      Episode_Reward/rew_ang_vel_z: 2.7239
    Episode_Reward/pen_base_height: -0.3311
      Episode_Reward/pen_lin_vel_z: -0.0546
     Episode_Reward/pen_ang_vel_xy: -0.1442
   Episode_Reward/pen_joint_torque: -0.1904
    Episode_Reward/pen_joint_accel: -0.0958
    Episode_Reward/pen_action_rate: -0.3035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0409
   Episode_Reward/pen_joint_powers: -0.0660
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6938
Episode_Reward/pen_flat_orientation: -0.1242
  Episode_Reward/pen_feet_distance: -0.0124
Episode_Reward/pen_feet_regulation: -0.2987
   Episode_Reward/foot_landing_vel: -0.1162
   Episode_Reward/test_gait_reward: -0.8796
Metrics/base_velocity/error_vel_xy: 1.7826
Metrics/base_velocity/error_vel_yaw: 1.0290
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 1.09s
                        Total time: 1445.96s
                               ETA: 1804.5s

################################################################################
                     [1m Learning iteration 1335/3000 [0m                     

                       Computation: 90710 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.9911
                    Surrogate loss: 0.0000
             Mean action noise std: 0.6363
                     Learning rate: 0.0003
                       Mean reward: 103.32
               Mean episode length: 989.33
       Episode_Reward/keep_balance: 0.9920
     Episode_Reward/rew_lin_vel_xy: 4.7456
      Episode_Reward/rew_ang_vel_z: 2.8012
    Episode_Reward/pen_base_height: -0.3262
      Episode_Reward/pen_lin_vel_z: -0.0547
     Episode_Reward/pen_ang_vel_xy: -0.1449
   Episode_Reward/pen_joint_torque: -0.1888
    Episode_Reward/pen_joint_accel: -0.0853
    Episode_Reward/pen_action_rate: -0.3062
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0403
   Episode_Reward/pen_joint_powers: -0.0656
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7066
Episode_Reward/pen_flat_orientation: -0.1159
  Episode_Reward/pen_feet_distance: -0.0073
Episode_Reward/pen_feet_regulation: -0.2980
   Episode_Reward/foot_landing_vel: -0.1147
   Episode_Reward/test_gait_reward: -0.8950
Metrics/base_velocity/error_vel_xy: 1.7470
Metrics/base_velocity/error_vel_yaw: 1.0391
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 1.08s
                        Total time: 1447.05s
                               ETA: 1803.4s

################################################################################
                     [1m Learning iteration 1336/3000 [0m                     

                       Computation: 91457 steps/s (collection: 0.948s, learning 0.127s)
               Value function loss: 1.0088
                    Surrogate loss: 0.0008
             Mean action noise std: 0.6365
                     Learning rate: 0.0002
                       Mean reward: 97.22
               Mean episode length: 981.11
       Episode_Reward/keep_balance: 0.9866
     Episode_Reward/rew_lin_vel_xy: 4.5099
      Episode_Reward/rew_ang_vel_z: 2.7656
    Episode_Reward/pen_base_height: -0.3234
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.1417
   Episode_Reward/pen_joint_torque: -0.1880
    Episode_Reward/pen_joint_accel: -0.0875
    Episode_Reward/pen_action_rate: -0.3074
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0404
   Episode_Reward/pen_joint_powers: -0.0650
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.7115
Episode_Reward/pen_flat_orientation: -0.1164
  Episode_Reward/pen_feet_distance: -0.0097
Episode_Reward/pen_feet_regulation: -0.2882
   Episode_Reward/foot_landing_vel: -0.1172
   Episode_Reward/test_gait_reward: -0.8858
Metrics/base_velocity/error_vel_xy: 1.9143
Metrics/base_velocity/error_vel_yaw: 1.0515
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 1.07s
                        Total time: 1448.12s
                               ETA: 1802.3s

################################################################################
                     [1m Learning iteration 1337/3000 [0m                     

                       Computation: 90297 steps/s (collection: 0.963s, learning 0.126s)
               Value function loss: 1.0129
                    Surrogate loss: -0.0051
             Mean action noise std: 0.6371
                     Learning rate: 0.0004
                       Mean reward: 98.74
               Mean episode length: 979.19
       Episode_Reward/keep_balance: 0.9754
     Episode_Reward/rew_lin_vel_xy: 4.5448
      Episode_Reward/rew_ang_vel_z: 2.7308
    Episode_Reward/pen_base_height: -0.3381
      Episode_Reward/pen_lin_vel_z: -0.0550
     Episode_Reward/pen_ang_vel_xy: -0.1463
   Episode_Reward/pen_joint_torque: -0.1940
    Episode_Reward/pen_joint_accel: -0.0874
    Episode_Reward/pen_action_rate: -0.3058
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0676
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7018
Episode_Reward/pen_flat_orientation: -0.1199
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.2916
   Episode_Reward/foot_landing_vel: -0.1156
   Episode_Reward/test_gait_reward: -0.8856
Metrics/base_velocity/error_vel_xy: 1.7902
Metrics/base_velocity/error_vel_yaw: 1.0441
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 1.09s
                        Total time: 1449.21s
                               ETA: 1801.2s

################################################################################
                     [1m Learning iteration 1338/3000 [0m                     

                       Computation: 90267 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 1.0164
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6376
                     Learning rate: 0.0006
                       Mean reward: 93.94
               Mean episode length: 947.33
       Episode_Reward/keep_balance: 0.9516
     Episode_Reward/rew_lin_vel_xy: 4.3636
      Episode_Reward/rew_ang_vel_z: 2.6923
    Episode_Reward/pen_base_height: -0.3162
      Episode_Reward/pen_lin_vel_z: -0.0531
     Episode_Reward/pen_ang_vel_xy: -0.1356
   Episode_Reward/pen_joint_torque: -0.1855
    Episode_Reward/pen_joint_accel: -0.0809
    Episode_Reward/pen_action_rate: -0.2935
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0387
   Episode_Reward/pen_joint_powers: -0.0633
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6737
Episode_Reward/pen_flat_orientation: -0.1166
  Episode_Reward/pen_feet_distance: -0.0087
Episode_Reward/pen_feet_regulation: -0.2918
   Episode_Reward/foot_landing_vel: -0.1117
   Episode_Reward/test_gait_reward: -0.8565
Metrics/base_velocity/error_vel_xy: 1.7955
Metrics/base_velocity/error_vel_yaw: 0.9968
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 1.09s
                        Total time: 1450.30s
                               ETA: 1800.1s

################################################################################
                     [1m Learning iteration 1339/3000 [0m                     

                       Computation: 90250 steps/s (collection: 0.963s, learning 0.127s)
               Value function loss: 0.9792
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6397
                     Learning rate: 0.0013
                       Mean reward: 94.44
               Mean episode length: 970.94
       Episode_Reward/keep_balance: 0.9780
     Episode_Reward/rew_lin_vel_xy: 4.3468
      Episode_Reward/rew_ang_vel_z: 2.7473
    Episode_Reward/pen_base_height: -0.3418
      Episode_Reward/pen_lin_vel_z: -0.0600
     Episode_Reward/pen_ang_vel_xy: -0.1458
   Episode_Reward/pen_joint_torque: -0.1895
    Episode_Reward/pen_joint_accel: -0.0917
    Episode_Reward/pen_action_rate: -0.3065
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0421
   Episode_Reward/pen_joint_powers: -0.0670
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7009
Episode_Reward/pen_flat_orientation: -0.1199
  Episode_Reward/pen_feet_distance: -0.0137
Episode_Reward/pen_feet_regulation: -0.3166
   Episode_Reward/foot_landing_vel: -0.1235
   Episode_Reward/test_gait_reward: -0.8856
Metrics/base_velocity/error_vel_xy: 2.0716
Metrics/base_velocity/error_vel_yaw: 1.0359
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 1.09s
                        Total time: 1451.39s
                               ETA: 1799.1s

################################################################################
                     [1m Learning iteration 1340/3000 [0m                     

                       Computation: 91203 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.9635
                    Surrogate loss: 0.0009
             Mean action noise std: 0.6396
                     Learning rate: 0.0003
                       Mean reward: 98.76
               Mean episode length: 991.01
       Episode_Reward/keep_balance: 0.9873
     Episode_Reward/rew_lin_vel_xy: 4.5901
      Episode_Reward/rew_ang_vel_z: 2.7151
    Episode_Reward/pen_base_height: -0.3312
      Episode_Reward/pen_lin_vel_z: -0.0579
     Episode_Reward/pen_ang_vel_xy: -0.1505
   Episode_Reward/pen_joint_torque: -0.1969
    Episode_Reward/pen_joint_accel: -0.0892
    Episode_Reward/pen_action_rate: -0.3166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0437
   Episode_Reward/pen_joint_powers: -0.0690
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.7252
Episode_Reward/pen_flat_orientation: -0.1213
  Episode_Reward/pen_feet_distance: -0.0101
Episode_Reward/pen_feet_regulation: -0.3353
   Episode_Reward/foot_landing_vel: -0.1256
   Episode_Reward/test_gait_reward: -0.9055
Metrics/base_velocity/error_vel_xy: 1.8156
Metrics/base_velocity/error_vel_yaw: 1.0933
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 1.08s
                        Total time: 1452.47s
                               ETA: 1798.0s

################################################################################
                     [1m Learning iteration 1341/3000 [0m                     

                       Computation: 90437 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 1.1009
                    Surrogate loss: -0.0037
             Mean action noise std: 0.6392
                     Learning rate: 0.0006
                       Mean reward: 99.01
               Mean episode length: 980.65
       Episode_Reward/keep_balance: 0.9676
     Episode_Reward/rew_lin_vel_xy: 4.6111
      Episode_Reward/rew_ang_vel_z: 2.6993
    Episode_Reward/pen_base_height: -0.3258
      Episode_Reward/pen_lin_vel_z: -0.0521
     Episode_Reward/pen_ang_vel_xy: -0.1430
   Episode_Reward/pen_joint_torque: -0.1864
    Episode_Reward/pen_joint_accel: -0.0794
    Episode_Reward/pen_action_rate: -0.3062
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0402
   Episode_Reward/pen_joint_powers: -0.0652
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7017
Episode_Reward/pen_flat_orientation: -0.1228
  Episode_Reward/pen_feet_distance: -0.0115
Episode_Reward/pen_feet_regulation: -0.3022
   Episode_Reward/foot_landing_vel: -0.1087
   Episode_Reward/test_gait_reward: -0.8798
Metrics/base_velocity/error_vel_xy: 1.7166
Metrics/base_velocity/error_vel_yaw: 1.0477
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 1.09s
                        Total time: 1453.55s
                               ETA: 1796.9s

################################################################################
                     [1m Learning iteration 1342/3000 [0m                     

                       Computation: 91981 steps/s (collection: 0.943s, learning 0.125s)
               Value function loss: 1.0211
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6393
                     Learning rate: 0.0004
                       Mean reward: 105.95
               Mean episode length: 987.36
       Episode_Reward/keep_balance: 0.9868
     Episode_Reward/rew_lin_vel_xy: 4.8524
      Episode_Reward/rew_ang_vel_z: 2.7770
    Episode_Reward/pen_base_height: -0.3083
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1500
   Episode_Reward/pen_joint_torque: -0.1900
    Episode_Reward/pen_joint_accel: -0.0956
    Episode_Reward/pen_action_rate: -0.3096
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0672
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7121
Episode_Reward/pen_flat_orientation: -0.1093
  Episode_Reward/pen_feet_distance: -0.0098
Episode_Reward/pen_feet_regulation: -0.3012
   Episode_Reward/foot_landing_vel: -0.1229
   Episode_Reward/test_gait_reward: -0.8950
Metrics/base_velocity/error_vel_xy: 1.7198
Metrics/base_velocity/error_vel_yaw: 1.0361
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 1.07s
                        Total time: 1454.62s
                               ETA: 1795.8s

################################################################################
                     [1m Learning iteration 1343/3000 [0m                     

                       Computation: 91422 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.9825
                    Surrogate loss: -0.0031
             Mean action noise std: 0.6377
                     Learning rate: 0.0006
                       Mean reward: 97.42
               Mean episode length: 979.65
       Episode_Reward/keep_balance: 0.9843
     Episode_Reward/rew_lin_vel_xy: 4.6228
      Episode_Reward/rew_ang_vel_z: 2.7237
    Episode_Reward/pen_base_height: -0.3238
      Episode_Reward/pen_lin_vel_z: -0.0537
     Episode_Reward/pen_ang_vel_xy: -0.1464
   Episode_Reward/pen_joint_torque: -0.1922
    Episode_Reward/pen_joint_accel: -0.0849
    Episode_Reward/pen_action_rate: -0.3104
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0417
   Episode_Reward/pen_joint_powers: -0.0670
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7110
Episode_Reward/pen_flat_orientation: -0.1192
  Episode_Reward/pen_feet_distance: -0.0099
Episode_Reward/pen_feet_regulation: -0.3082
   Episode_Reward/foot_landing_vel: -0.1148
   Episode_Reward/test_gait_reward: -0.8923
Metrics/base_velocity/error_vel_xy: 1.8059
Metrics/base_velocity/error_vel_yaw: 1.0776
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 1.08s
                        Total time: 1455.70s
                               ETA: 1794.7s

################################################################################
                     [1m Learning iteration 1344/3000 [0m                     

                       Computation: 92612 steps/s (collection: 0.937s, learning 0.125s)
               Value function loss: 0.8941
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6368
                     Learning rate: 0.0004
                       Mean reward: 98.79
               Mean episode length: 988.92
       Episode_Reward/keep_balance: 0.9923
     Episode_Reward/rew_lin_vel_xy: 4.6531
      Episode_Reward/rew_ang_vel_z: 2.8064
    Episode_Reward/pen_base_height: -0.3280
      Episode_Reward/pen_lin_vel_z: -0.0571
     Episode_Reward/pen_ang_vel_xy: -0.1471
   Episode_Reward/pen_joint_torque: -0.1942
    Episode_Reward/pen_joint_accel: -0.0936
    Episode_Reward/pen_action_rate: -0.3125
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0428
   Episode_Reward/pen_joint_powers: -0.0688
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7177
Episode_Reward/pen_flat_orientation: -0.1135
  Episode_Reward/pen_feet_distance: -0.0108
Episode_Reward/pen_feet_regulation: -0.3190
   Episode_Reward/foot_landing_vel: -0.1240
   Episode_Reward/test_gait_reward: -0.9112
Metrics/base_velocity/error_vel_xy: 1.8253
Metrics/base_velocity/error_vel_yaw: 1.0308
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 1.06s
                        Total time: 1456.76s
                               ETA: 1793.6s

################################################################################
                     [1m Learning iteration 1345/3000 [0m                     

                       Computation: 91307 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.9752
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6363
                     Learning rate: 0.0006
                       Mean reward: 100.81
               Mean episode length: 984.48
       Episode_Reward/keep_balance: 0.9892
     Episode_Reward/rew_lin_vel_xy: 4.7448
      Episode_Reward/rew_ang_vel_z: 2.7789
    Episode_Reward/pen_base_height: -0.3195
      Episode_Reward/pen_lin_vel_z: -0.0538
     Episode_Reward/pen_ang_vel_xy: -0.1440
   Episode_Reward/pen_joint_torque: -0.1870
    Episode_Reward/pen_joint_accel: -0.0818
    Episode_Reward/pen_action_rate: -0.3049
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0400
   Episode_Reward/pen_joint_powers: -0.0648
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7114
Episode_Reward/pen_flat_orientation: -0.1111
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.2890
   Episode_Reward/foot_landing_vel: -0.1208
   Episode_Reward/test_gait_reward: -0.8912
Metrics/base_velocity/error_vel_xy: 1.8428
Metrics/base_velocity/error_vel_yaw: 1.0478
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 1.08s
                        Total time: 1457.84s
                               ETA: 1792.5s

################################################################################
                     [1m Learning iteration 1346/3000 [0m                     

                       Computation: 92223 steps/s (collection: 0.942s, learning 0.124s)
               Value function loss: 0.9710
                    Surrogate loss: -0.0037
             Mean action noise std: 0.6368
                     Learning rate: 0.0009
                       Mean reward: 93.05
               Mean episode length: 946.00
       Episode_Reward/keep_balance: 0.9627
     Episode_Reward/rew_lin_vel_xy: 4.3786
      Episode_Reward/rew_ang_vel_z: 2.6974
    Episode_Reward/pen_base_height: -0.3236
      Episode_Reward/pen_lin_vel_z: -0.0538
     Episode_Reward/pen_ang_vel_xy: -0.1438
   Episode_Reward/pen_joint_torque: -0.1931
    Episode_Reward/pen_joint_accel: -0.0808
    Episode_Reward/pen_action_rate: -0.3013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0402
   Episode_Reward/pen_joint_powers: -0.0664
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6895
Episode_Reward/pen_flat_orientation: -0.1119
  Episode_Reward/pen_feet_distance: -0.0105
Episode_Reward/pen_feet_regulation: -0.3037
   Episode_Reward/foot_landing_vel: -0.1117
   Episode_Reward/test_gait_reward: -0.8701
Metrics/base_velocity/error_vel_xy: 1.8865
Metrics/base_velocity/error_vel_yaw: 1.0243
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 1.07s
                        Total time: 1458.90s
                               ETA: 1791.4s

################################################################################
                     [1m Learning iteration 1347/3000 [0m                     

                       Computation: 89648 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 1.0517
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6362
                     Learning rate: 0.0006
                       Mean reward: 96.24
               Mean episode length: 971.61
       Episode_Reward/keep_balance: 0.9731
     Episode_Reward/rew_lin_vel_xy: 4.4892
      Episode_Reward/rew_ang_vel_z: 2.7048
    Episode_Reward/pen_base_height: -0.3198
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1467
   Episode_Reward/pen_joint_torque: -0.1865
    Episode_Reward/pen_joint_accel: -0.0835
    Episode_Reward/pen_action_rate: -0.3049
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0409
   Episode_Reward/pen_joint_powers: -0.0658
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7070
Episode_Reward/pen_flat_orientation: -0.1153
  Episode_Reward/pen_feet_distance: -0.0097
Episode_Reward/pen_feet_regulation: -0.3067
   Episode_Reward/foot_landing_vel: -0.1162
   Episode_Reward/test_gait_reward: -0.8824
Metrics/base_velocity/error_vel_xy: 1.8927
Metrics/base_velocity/error_vel_yaw: 1.0554
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 1.10s
                        Total time: 1460.00s
                               ETA: 1790.3s

################################################################################
                     [1m Learning iteration 1348/3000 [0m                     

                       Computation: 91757 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 1.0787
                    Surrogate loss: 0.0000
             Mean action noise std: 0.6358
                     Learning rate: 0.0003
                       Mean reward: 96.70
               Mean episode length: 964.26
       Episode_Reward/keep_balance: 0.9676
     Episode_Reward/rew_lin_vel_xy: 4.5690
      Episode_Reward/rew_ang_vel_z: 2.7215
    Episode_Reward/pen_base_height: -0.3167
      Episode_Reward/pen_lin_vel_z: -0.0540
     Episode_Reward/pen_ang_vel_xy: -0.1445
   Episode_Reward/pen_joint_torque: -0.1828
    Episode_Reward/pen_joint_accel: -0.0878
    Episode_Reward/pen_action_rate: -0.3046
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0410
   Episode_Reward/pen_joint_powers: -0.0654
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7010
Episode_Reward/pen_flat_orientation: -0.1231
  Episode_Reward/pen_feet_distance: -0.0088
Episode_Reward/pen_feet_regulation: -0.3056
   Episode_Reward/foot_landing_vel: -0.1210
   Episode_Reward/test_gait_reward: -0.8810
Metrics/base_velocity/error_vel_xy: 1.8151
Metrics/base_velocity/error_vel_yaw: 1.0295
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 1.07s
                        Total time: 1461.07s
                               ETA: 1789.2s

################################################################################
                     [1m Learning iteration 1349/3000 [0m                     

                       Computation: 91856 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 1.0737
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6358
                     Learning rate: 0.0002
                       Mean reward: 95.46
               Mean episode length: 979.12
       Episode_Reward/keep_balance: 0.9859
     Episode_Reward/rew_lin_vel_xy: 4.5573
      Episode_Reward/rew_ang_vel_z: 2.7384
    Episode_Reward/pen_base_height: -0.3298
      Episode_Reward/pen_lin_vel_z: -0.0587
     Episode_Reward/pen_ang_vel_xy: -0.1481
   Episode_Reward/pen_joint_torque: -0.1979
    Episode_Reward/pen_joint_accel: -0.0906
    Episode_Reward/pen_action_rate: -0.3159
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0426
   Episode_Reward/pen_joint_powers: -0.0686
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7195
Episode_Reward/pen_flat_orientation: -0.1228
  Episode_Reward/pen_feet_distance: -0.0087
Episode_Reward/pen_feet_regulation: -0.3256
   Episode_Reward/foot_landing_vel: -0.1252
   Episode_Reward/test_gait_reward: -0.9053
Metrics/base_velocity/error_vel_xy: 1.9397
Metrics/base_velocity/error_vel_yaw: 1.0694
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 1.07s
                        Total time: 1462.14s
                               ETA: 1788.1s

################################################################################
                     [1m Learning iteration 1350/3000 [0m                     

                       Computation: 93029 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 0.9754
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6357
                     Learning rate: 0.0004
                       Mean reward: 100.34
               Mean episode length: 975.34
       Episode_Reward/keep_balance: 0.9802
     Episode_Reward/rew_lin_vel_xy: 4.6469
      Episode_Reward/rew_ang_vel_z: 2.7623
    Episode_Reward/pen_base_height: -0.3126
      Episode_Reward/pen_lin_vel_z: -0.0547
     Episode_Reward/pen_ang_vel_xy: -0.1448
   Episode_Reward/pen_joint_torque: -0.1918
    Episode_Reward/pen_joint_accel: -0.0847
    Episode_Reward/pen_action_rate: -0.3063
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0397
   Episode_Reward/pen_joint_powers: -0.0657
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7050
Episode_Reward/pen_flat_orientation: -0.1101
  Episode_Reward/pen_feet_distance: -0.0079
Episode_Reward/pen_feet_regulation: -0.2818
   Episode_Reward/foot_landing_vel: -0.1161
   Episode_Reward/test_gait_reward: -0.8861
Metrics/base_velocity/error_vel_xy: 1.8784
Metrics/base_velocity/error_vel_yaw: 1.0300
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 1.06s
                        Total time: 1463.20s
                               ETA: 1787.0s

################################################################################
                     [1m Learning iteration 1351/3000 [0m                     

                       Computation: 92392 steps/s (collection: 0.935s, learning 0.129s)
               Value function loss: 1.0647
                    Surrogate loss: -0.0043
             Mean action noise std: 0.6353
                     Learning rate: 0.0006
                       Mean reward: 100.15
               Mean episode length: 971.64
       Episode_Reward/keep_balance: 0.9777
     Episode_Reward/rew_lin_vel_xy: 4.7061
      Episode_Reward/rew_ang_vel_z: 2.7285
    Episode_Reward/pen_base_height: -0.3050
      Episode_Reward/pen_lin_vel_z: -0.0504
     Episode_Reward/pen_ang_vel_xy: -0.1399
   Episode_Reward/pen_joint_torque: -0.1848
    Episode_Reward/pen_joint_accel: -0.0806
    Episode_Reward/pen_action_rate: -0.3023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0392
   Episode_Reward/pen_joint_powers: -0.0636
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7006
Episode_Reward/pen_flat_orientation: -0.1155
  Episode_Reward/pen_feet_distance: -0.0089
Episode_Reward/pen_feet_regulation: -0.2858
   Episode_Reward/foot_landing_vel: -0.1118
   Episode_Reward/test_gait_reward: -0.8816
Metrics/base_velocity/error_vel_xy: 1.7108
Metrics/base_velocity/error_vel_yaw: 1.0492
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 1.06s
                        Total time: 1464.26s
                               ETA: 1785.9s

################################################################################
                     [1m Learning iteration 1352/3000 [0m                     

                       Computation: 92858 steps/s (collection: 0.936s, learning 0.122s)
               Value function loss: 1.0120
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6357
                     Learning rate: 0.0006
                       Mean reward: 93.48
               Mean episode length: 945.00
       Episode_Reward/keep_balance: 0.9610
     Episode_Reward/rew_lin_vel_xy: 4.4774
      Episode_Reward/rew_ang_vel_z: 2.7247
    Episode_Reward/pen_base_height: -0.3175
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1434
   Episode_Reward/pen_joint_torque: -0.1904
    Episode_Reward/pen_joint_accel: -0.0888
    Episode_Reward/pen_action_rate: -0.3040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0418
   Episode_Reward/pen_joint_powers: -0.0668
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6927
Episode_Reward/pen_flat_orientation: -0.1209
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.3132
   Episode_Reward/foot_landing_vel: -0.1300
   Episode_Reward/test_gait_reward: -0.8754
Metrics/base_velocity/error_vel_xy: 1.8205
Metrics/base_velocity/error_vel_yaw: 0.9992
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 1.06s
                        Total time: 1465.32s
                               ETA: 1784.8s

################################################################################
                     [1m Learning iteration 1353/3000 [0m                     

                       Computation: 92455 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 0.8915
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6353
                     Learning rate: 0.0004
                       Mean reward: 102.29
               Mean episode length: 990.99
       Episode_Reward/keep_balance: 0.9881
     Episode_Reward/rew_lin_vel_xy: 4.7225
      Episode_Reward/rew_ang_vel_z: 2.7940
    Episode_Reward/pen_base_height: -0.3215
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1517
   Episode_Reward/pen_joint_torque: -0.1878
    Episode_Reward/pen_joint_accel: -0.0954
    Episode_Reward/pen_action_rate: -0.3129
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0417
   Episode_Reward/pen_joint_powers: -0.0666
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7198
Episode_Reward/pen_flat_orientation: -0.1200
  Episode_Reward/pen_feet_distance: -0.0093
Episode_Reward/pen_feet_regulation: -0.3125
   Episode_Reward/foot_landing_vel: -0.1174
   Episode_Reward/test_gait_reward: -0.9051
Metrics/base_velocity/error_vel_xy: 1.8143
Metrics/base_velocity/error_vel_yaw: 1.0320
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 1.06s
                        Total time: 1466.38s
                               ETA: 1783.7s

################################################################################
                     [1m Learning iteration 1354/3000 [0m                     

                       Computation: 93032 steps/s (collection: 0.933s, learning 0.124s)
               Value function loss: 1.0090
                    Surrogate loss: -0.0039
             Mean action noise std: 0.6361
                     Learning rate: 0.0006
                       Mean reward: 99.86
               Mean episode length: 985.50
       Episode_Reward/keep_balance: 0.9792
     Episode_Reward/rew_lin_vel_xy: 4.6041
      Episode_Reward/rew_ang_vel_z: 2.7236
    Episode_Reward/pen_base_height: -0.3134
      Episode_Reward/pen_lin_vel_z: -0.0531
     Episode_Reward/pen_ang_vel_xy: -0.1419
   Episode_Reward/pen_joint_torque: -0.1852
    Episode_Reward/pen_joint_accel: -0.0903
    Episode_Reward/pen_action_rate: -0.3050
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0405
   Episode_Reward/pen_joint_powers: -0.0649
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7066
Episode_Reward/pen_flat_orientation: -0.1112
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.2918
   Episode_Reward/foot_landing_vel: -0.1195
   Episode_Reward/test_gait_reward: -0.8868
Metrics/base_velocity/error_vel_xy: 1.8281
Metrics/base_velocity/error_vel_yaw: 1.0569
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 1.06s
                        Total time: 1467.44s
                               ETA: 1782.6s

################################################################################
                     [1m Learning iteration 1355/3000 [0m                     

                       Computation: 91715 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 1.0036
                    Surrogate loss: -0.0040
             Mean action noise std: 0.6373
                     Learning rate: 0.0009
                       Mean reward: 101.86
               Mean episode length: 987.39
       Episode_Reward/keep_balance: 0.9863
     Episode_Reward/rew_lin_vel_xy: 4.6755
      Episode_Reward/rew_ang_vel_z: 2.7670
    Episode_Reward/pen_base_height: -0.3276
      Episode_Reward/pen_lin_vel_z: -0.0541
     Episode_Reward/pen_ang_vel_xy: -0.1480
   Episode_Reward/pen_joint_torque: -0.1926
    Episode_Reward/pen_joint_accel: -0.0826
    Episode_Reward/pen_action_rate: -0.3077
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0405
   Episode_Reward/pen_joint_powers: -0.0663
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7100
Episode_Reward/pen_flat_orientation: -0.1157
  Episode_Reward/pen_feet_distance: -0.0078
Episode_Reward/pen_feet_regulation: -0.2995
   Episode_Reward/foot_landing_vel: -0.1182
   Episode_Reward/test_gait_reward: -0.8904
Metrics/base_velocity/error_vel_xy: 1.8022
Metrics/base_velocity/error_vel_yaw: 1.0449
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 1.07s
                        Total time: 1468.51s
                               ETA: 1781.5s

################################################################################
                     [1m Learning iteration 1356/3000 [0m                     

                       Computation: 92604 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 1.0296
                    Surrogate loss: -0.0042
             Mean action noise std: 0.6374
                     Learning rate: 0.0013
                       Mean reward: 103.46
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 0.9951
     Episode_Reward/rew_lin_vel_xy: 4.7774
      Episode_Reward/rew_ang_vel_z: 2.8072
    Episode_Reward/pen_base_height: -0.3249
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1445
   Episode_Reward/pen_joint_torque: -0.1947
    Episode_Reward/pen_joint_accel: -0.0920
    Episode_Reward/pen_action_rate: -0.3131
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0412
   Episode_Reward/pen_joint_powers: -0.0673
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7138
Episode_Reward/pen_flat_orientation: -0.1133
  Episode_Reward/pen_feet_distance: -0.0069
Episode_Reward/pen_feet_regulation: -0.3123
   Episode_Reward/foot_landing_vel: -0.1208
   Episode_Reward/test_gait_reward: -0.9098
Metrics/base_velocity/error_vel_xy: 1.7906
Metrics/base_velocity/error_vel_yaw: 1.0454
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 1.06s
                        Total time: 1469.57s
                               ETA: 1780.4s

################################################################################
                     [1m Learning iteration 1357/3000 [0m                     

                       Computation: 92663 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 0.9839
                    Surrogate loss: -0.0040
             Mean action noise std: 0.6374
                     Learning rate: 0.0013
                       Mean reward: 100.06
               Mean episode length: 980.28
       Episode_Reward/keep_balance: 0.9830
     Episode_Reward/rew_lin_vel_xy: 4.5756
      Episode_Reward/rew_ang_vel_z: 2.7717
    Episode_Reward/pen_base_height: -0.3320
      Episode_Reward/pen_lin_vel_z: -0.0564
     Episode_Reward/pen_ang_vel_xy: -0.1421
   Episode_Reward/pen_joint_torque: -0.1915
    Episode_Reward/pen_joint_accel: -0.0848
    Episode_Reward/pen_action_rate: -0.3023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0399
   Episode_Reward/pen_joint_powers: -0.0659
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6964
Episode_Reward/pen_flat_orientation: -0.1151
  Episode_Reward/pen_feet_distance: -0.0079
Episode_Reward/pen_feet_regulation: -0.2992
   Episode_Reward/foot_landing_vel: -0.1116
   Episode_Reward/test_gait_reward: -0.8975
Metrics/base_velocity/error_vel_xy: 1.9455
Metrics/base_velocity/error_vel_yaw: 1.0340
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 1.06s
                        Total time: 1470.63s
                               ETA: 1779.3s

################################################################################
                     [1m Learning iteration 1358/3000 [0m                     

                       Computation: 93664 steps/s (collection: 0.928s, learning 0.122s)
               Value function loss: 1.1063
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6377
                     Learning rate: 0.0009
                       Mean reward: 93.60
               Mean episode length: 948.56
       Episode_Reward/keep_balance: 0.9480
     Episode_Reward/rew_lin_vel_xy: 4.2737
      Episode_Reward/rew_ang_vel_z: 2.6810
    Episode_Reward/pen_base_height: -0.3298
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1481
   Episode_Reward/pen_joint_torque: -0.1879
    Episode_Reward/pen_joint_accel: -0.0868
    Episode_Reward/pen_action_rate: -0.2991
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0413
   Episode_Reward/pen_joint_powers: -0.0660
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6867
Episode_Reward/pen_flat_orientation: -0.1275
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.3142
   Episode_Reward/foot_landing_vel: -0.1101
   Episode_Reward/test_gait_reward: -0.8660
Metrics/base_velocity/error_vel_xy: 1.8985
Metrics/base_velocity/error_vel_yaw: 0.9920
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 1.05s
                        Total time: 1471.68s
                               ETA: 1778.1s

################################################################################
                     [1m Learning iteration 1359/3000 [0m                     

                       Computation: 93026 steps/s (collection: 0.934s, learning 0.122s)
               Value function loss: 0.9515
                    Surrogate loss: 0.0014
             Mean action noise std: 0.6378
                     Learning rate: 0.0002
                       Mean reward: 98.29
               Mean episode length: 963.77
       Episode_Reward/keep_balance: 0.9632
     Episode_Reward/rew_lin_vel_xy: 4.6485
      Episode_Reward/rew_ang_vel_z: 2.6921
    Episode_Reward/pen_base_height: -0.3203
      Episode_Reward/pen_lin_vel_z: -0.0561
     Episode_Reward/pen_ang_vel_xy: -0.1435
   Episode_Reward/pen_joint_torque: -0.1862
    Episode_Reward/pen_joint_accel: -0.0860
    Episode_Reward/pen_action_rate: -0.3031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0402
   Episode_Reward/pen_joint_powers: -0.0656
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.6970
Episode_Reward/pen_flat_orientation: -0.1128
  Episode_Reward/pen_feet_distance: -0.0089
Episode_Reward/pen_feet_regulation: -0.3076
   Episode_Reward/foot_landing_vel: -0.1181
   Episode_Reward/test_gait_reward: -0.8806
Metrics/base_velocity/error_vel_xy: 1.7481
Metrics/base_velocity/error_vel_yaw: 1.0335
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 1.06s
                        Total time: 1472.74s
                               ETA: 1777.0s

################################################################################
                     [1m Learning iteration 1360/3000 [0m                     

                       Computation: 91032 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.9291
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6369
                     Learning rate: 0.0004
                       Mean reward: 99.14
               Mean episode length: 976.39
       Episode_Reward/keep_balance: 0.9790
     Episode_Reward/rew_lin_vel_xy: 4.5235
      Episode_Reward/rew_ang_vel_z: 2.7380
    Episode_Reward/pen_base_height: -0.3209
      Episode_Reward/pen_lin_vel_z: -0.0561
     Episode_Reward/pen_ang_vel_xy: -0.1522
   Episode_Reward/pen_joint_torque: -0.1884
    Episode_Reward/pen_joint_accel: -0.0934
    Episode_Reward/pen_action_rate: -0.3081
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0415
   Episode_Reward/pen_joint_powers: -0.0664
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7102
Episode_Reward/pen_flat_orientation: -0.1163
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.3030
   Episode_Reward/foot_landing_vel: -0.1213
   Episode_Reward/test_gait_reward: -0.8881
Metrics/base_velocity/error_vel_xy: 1.8982
Metrics/base_velocity/error_vel_yaw: 1.0539
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 1.08s
                        Total time: 1473.82s
                               ETA: 1775.9s

################################################################################
                     [1m Learning iteration 1361/3000 [0m                     

                       Computation: 92121 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 1.0153
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6363
                     Learning rate: 0.0004
                       Mean reward: 97.67
               Mean episode length: 983.48
       Episode_Reward/keep_balance: 0.9761
     Episode_Reward/rew_lin_vel_xy: 4.5154
      Episode_Reward/rew_ang_vel_z: 2.7047
    Episode_Reward/pen_base_height: -0.3430
      Episode_Reward/pen_lin_vel_z: -0.0553
     Episode_Reward/pen_ang_vel_xy: -0.1509
   Episode_Reward/pen_joint_torque: -0.1892
    Episode_Reward/pen_joint_accel: -0.0876
    Episode_Reward/pen_action_rate: -0.3099
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0424
   Episode_Reward/pen_joint_powers: -0.0674
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.7154
Episode_Reward/pen_flat_orientation: -0.1287
  Episode_Reward/pen_feet_distance: -0.0104
Episode_Reward/pen_feet_regulation: -0.3164
   Episode_Reward/foot_landing_vel: -0.1172
   Episode_Reward/test_gait_reward: -0.8888
Metrics/base_velocity/error_vel_xy: 1.8724
Metrics/base_velocity/error_vel_yaw: 1.0656
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 1.07s
                        Total time: 1474.89s
                               ETA: 1774.8s

################################################################################
                     [1m Learning iteration 1362/3000 [0m                     

                       Computation: 93447 steps/s (collection: 0.930s, learning 0.122s)
               Value function loss: 1.0309
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6365
                     Learning rate: 0.0003
                       Mean reward: 98.81
               Mean episode length: 977.88
       Episode_Reward/keep_balance: 0.9872
     Episode_Reward/rew_lin_vel_xy: 4.7010
      Episode_Reward/rew_ang_vel_z: 2.7616
    Episode_Reward/pen_base_height: -0.3189
      Episode_Reward/pen_lin_vel_z: -0.0546
     Episode_Reward/pen_ang_vel_xy: -0.1481
   Episode_Reward/pen_joint_torque: -0.1935
    Episode_Reward/pen_joint_accel: -0.0899
    Episode_Reward/pen_action_rate: -0.3123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0415
   Episode_Reward/pen_joint_powers: -0.0669
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7207
Episode_Reward/pen_flat_orientation: -0.1164
  Episode_Reward/pen_feet_distance: -0.0104
Episode_Reward/pen_feet_regulation: -0.3048
   Episode_Reward/foot_landing_vel: -0.1188
   Episode_Reward/test_gait_reward: -0.9089
Metrics/base_velocity/error_vel_xy: 1.8091
Metrics/base_velocity/error_vel_yaw: 1.0558
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 1.05s
                        Total time: 1475.94s
                               ETA: 1773.7s

################################################################################
                     [1m Learning iteration 1363/3000 [0m                     

                       Computation: 91904 steps/s (collection: 0.946s, learning 0.124s)
               Value function loss: 0.9760
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6373
                     Learning rate: 0.0006
                       Mean reward: 100.18
               Mean episode length: 973.03
       Episode_Reward/keep_balance: 0.9749
     Episode_Reward/rew_lin_vel_xy: 4.6307
      Episode_Reward/rew_ang_vel_z: 2.7369
    Episode_Reward/pen_base_height: -0.3347
      Episode_Reward/pen_lin_vel_z: -0.0543
     Episode_Reward/pen_ang_vel_xy: -0.1446
   Episode_Reward/pen_joint_torque: -0.1899
    Episode_Reward/pen_joint_accel: -0.0914
    Episode_Reward/pen_action_rate: -0.3053
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0409
   Episode_Reward/pen_joint_powers: -0.0660
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7010
Episode_Reward/pen_flat_orientation: -0.1144
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.3017
   Episode_Reward/foot_landing_vel: -0.1191
   Episode_Reward/test_gait_reward: -0.8902
Metrics/base_velocity/error_vel_xy: 1.7464
Metrics/base_velocity/error_vel_yaw: 1.0356
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 1.07s
                        Total time: 1477.01s
                               ETA: 1772.6s

################################################################################
                     [1m Learning iteration 1364/3000 [0m                     

                       Computation: 92053 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.8383
                    Surrogate loss: -0.0006
             Mean action noise std: 0.6373
                     Learning rate: 0.0002
                       Mean reward: 98.45
               Mean episode length: 973.05
       Episode_Reward/keep_balance: 0.9761
     Episode_Reward/rew_lin_vel_xy: 4.6671
      Episode_Reward/rew_ang_vel_z: 2.7333
    Episode_Reward/pen_base_height: -0.3318
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.1422
   Episode_Reward/pen_joint_torque: -0.1882
    Episode_Reward/pen_joint_accel: -0.0930
    Episode_Reward/pen_action_rate: -0.3052
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0401
   Episode_Reward/pen_joint_powers: -0.0652
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7044
Episode_Reward/pen_flat_orientation: -0.1099
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3019
   Episode_Reward/foot_landing_vel: -0.1153
   Episode_Reward/test_gait_reward: -0.8935
Metrics/base_velocity/error_vel_xy: 1.8024
Metrics/base_velocity/error_vel_yaw: 1.0404
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 1.07s
                        Total time: 1478.08s
                               ETA: 1771.5s

################################################################################
                     [1m Learning iteration 1365/3000 [0m                     

                       Computation: 91564 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.0963
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6373
                     Learning rate: 0.0004
                       Mean reward: 98.56
               Mean episode length: 988.99
       Episode_Reward/keep_balance: 0.9893
     Episode_Reward/rew_lin_vel_xy: 4.6954
      Episode_Reward/rew_ang_vel_z: 2.7469
    Episode_Reward/pen_base_height: -0.3343
      Episode_Reward/pen_lin_vel_z: -0.0578
     Episode_Reward/pen_ang_vel_xy: -0.1508
   Episode_Reward/pen_joint_torque: -0.1958
    Episode_Reward/pen_joint_accel: -0.0934
    Episode_Reward/pen_action_rate: -0.3154
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0425
   Episode_Reward/pen_joint_powers: -0.0688
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7200
Episode_Reward/pen_flat_orientation: -0.1213
  Episode_Reward/pen_feet_distance: -0.0099
Episode_Reward/pen_feet_regulation: -0.3264
   Episode_Reward/foot_landing_vel: -0.1249
   Episode_Reward/test_gait_reward: -0.9128
Metrics/base_velocity/error_vel_xy: 1.8433
Metrics/base_velocity/error_vel_yaw: 1.0771
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 1.07s
                        Total time: 1479.15s
                               ETA: 1770.4s

################################################################################
                     [1m Learning iteration 1366/3000 [0m                     

                       Computation: 92658 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 0.9900
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6377
                     Learning rate: 0.0004
                       Mean reward: 92.67
               Mean episode length: 939.49
       Episode_Reward/keep_balance: 0.9416
     Episode_Reward/rew_lin_vel_xy: 4.2807
      Episode_Reward/rew_ang_vel_z: 2.6383
    Episode_Reward/pen_base_height: -0.3168
      Episode_Reward/pen_lin_vel_z: -0.0521
     Episode_Reward/pen_ang_vel_xy: -0.1444
   Episode_Reward/pen_joint_torque: -0.1799
    Episode_Reward/pen_joint_accel: -0.0855
    Episode_Reward/pen_action_rate: -0.2962
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0396
   Episode_Reward/pen_joint_powers: -0.0635
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6824
Episode_Reward/pen_flat_orientation: -0.1209
  Episode_Reward/pen_feet_distance: -0.0079
Episode_Reward/pen_feet_regulation: -0.2915
   Episode_Reward/foot_landing_vel: -0.1138
   Episode_Reward/test_gait_reward: -0.8532
Metrics/base_velocity/error_vel_xy: 1.8378
Metrics/base_velocity/error_vel_yaw: 1.0097
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 1.06s
                        Total time: 1480.21s
                               ETA: 1769.3s

################################################################################
                     [1m Learning iteration 1367/3000 [0m                     

                       Computation: 92380 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 0.9725
                    Surrogate loss: -0.0036
             Mean action noise std: 0.6382
                     Learning rate: 0.0003
                       Mean reward: 98.21
               Mean episode length: 979.24
       Episode_Reward/keep_balance: 0.9799
     Episode_Reward/rew_lin_vel_xy: 4.6513
      Episode_Reward/rew_ang_vel_z: 2.7617
    Episode_Reward/pen_base_height: -0.3261
      Episode_Reward/pen_lin_vel_z: -0.0567
     Episode_Reward/pen_ang_vel_xy: -0.1531
   Episode_Reward/pen_joint_torque: -0.1975
    Episode_Reward/pen_joint_accel: -0.0869
    Episode_Reward/pen_action_rate: -0.3107
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0420
   Episode_Reward/pen_joint_powers: -0.0690
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7092
Episode_Reward/pen_flat_orientation: -0.1149
  Episode_Reward/pen_feet_distance: -0.0106
Episode_Reward/pen_feet_regulation: -0.3252
   Episode_Reward/foot_landing_vel: -0.1186
   Episode_Reward/test_gait_reward: -0.9049
Metrics/base_velocity/error_vel_xy: 1.7772
Metrics/base_velocity/error_vel_yaw: 1.0289
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 1.06s
                        Total time: 1481.28s
                               ETA: 1768.2s

################################################################################
                     [1m Learning iteration 1368/3000 [0m                     

                       Computation: 93667 steps/s (collection: 0.926s, learning 0.123s)
               Value function loss: 0.9836
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6382
                     Learning rate: 0.0004
                       Mean reward: 89.39
               Mean episode length: 968.33
       Episode_Reward/keep_balance: 0.9713
     Episode_Reward/rew_lin_vel_xy: 4.2386
      Episode_Reward/rew_ang_vel_z: 2.6941
    Episode_Reward/pen_base_height: -0.3427
      Episode_Reward/pen_lin_vel_z: -0.0555
     Episode_Reward/pen_ang_vel_xy: -0.1454
   Episode_Reward/pen_joint_torque: -0.1944
    Episode_Reward/pen_joint_accel: -0.0848
    Episode_Reward/pen_action_rate: -0.3078
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0409
   Episode_Reward/pen_joint_powers: -0.0673
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7025
Episode_Reward/pen_flat_orientation: -0.1208
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.3182
   Episode_Reward/foot_landing_vel: -0.1139
   Episode_Reward/test_gait_reward: -0.8934
Metrics/base_velocity/error_vel_xy: 2.0304
Metrics/base_velocity/error_vel_yaw: 1.0594
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 1.05s
                        Total time: 1482.32s
                               ETA: 1767.1s

################################################################################
                     [1m Learning iteration 1369/3000 [0m                     

                       Computation: 93067 steps/s (collection: 0.929s, learning 0.127s)
               Value function loss: 0.9865
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6390
                     Learning rate: 0.0003
                       Mean reward: 97.17
               Mean episode length: 965.63
       Episode_Reward/keep_balance: 0.9697
     Episode_Reward/rew_lin_vel_xy: 4.5161
      Episode_Reward/rew_ang_vel_z: 2.6892
    Episode_Reward/pen_base_height: -0.3325
      Episode_Reward/pen_lin_vel_z: -0.0547
     Episode_Reward/pen_ang_vel_xy: -0.1459
   Episode_Reward/pen_joint_torque: -0.1959
    Episode_Reward/pen_joint_accel: -0.0882
    Episode_Reward/pen_action_rate: -0.3062
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0406
   Episode_Reward/pen_joint_powers: -0.0675
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7034
Episode_Reward/pen_flat_orientation: -0.1218
  Episode_Reward/pen_feet_distance: -0.0098
Episode_Reward/pen_feet_regulation: -0.3068
   Episode_Reward/foot_landing_vel: -0.1134
   Episode_Reward/test_gait_reward: -0.8952
Metrics/base_velocity/error_vel_xy: 1.7783
Metrics/base_velocity/error_vel_yaw: 1.0584
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 1.06s
                        Total time: 1483.38s
                               ETA: 1766.0s

################################################################################
                     [1m Learning iteration 1370/3000 [0m                     

                       Computation: 92436 steps/s (collection: 0.939s, learning 0.124s)
               Value function loss: 1.0146
                    Surrogate loss: -0.0048
             Mean action noise std: 0.6397
                     Learning rate: 0.0006
                       Mean reward: 100.70
               Mean episode length: 988.86
       Episode_Reward/keep_balance: 0.9991
     Episode_Reward/rew_lin_vel_xy: 4.7871
      Episode_Reward/rew_ang_vel_z: 2.8095
    Episode_Reward/pen_base_height: -0.3240
      Episode_Reward/pen_lin_vel_z: -0.0533
     Episode_Reward/pen_ang_vel_xy: -0.1429
   Episode_Reward/pen_joint_torque: -0.1964
    Episode_Reward/pen_joint_accel: -0.0878
    Episode_Reward/pen_action_rate: -0.3119
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0404
   Episode_Reward/pen_joint_powers: -0.0670
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7167
Episode_Reward/pen_flat_orientation: -0.1080
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.2971
   Episode_Reward/foot_landing_vel: -0.1119
   Episode_Reward/test_gait_reward: -0.9152
Metrics/base_velocity/error_vel_xy: 1.7954
Metrics/base_velocity/error_vel_yaw: 1.0545
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 1.06s
                        Total time: 1484.44s
                               ETA: 1764.9s

################################################################################
                     [1m Learning iteration 1371/3000 [0m                     

                       Computation: 89293 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 1.0051
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6403
                     Learning rate: 0.0004
                       Mean reward: 96.38
               Mean episode length: 969.62
       Episode_Reward/keep_balance: 0.9834
     Episode_Reward/rew_lin_vel_xy: 4.4994
      Episode_Reward/rew_ang_vel_z: 2.7509
    Episode_Reward/pen_base_height: -0.3213
      Episode_Reward/pen_lin_vel_z: -0.0536
     Episode_Reward/pen_ang_vel_xy: -0.1484
   Episode_Reward/pen_joint_torque: -0.1874
    Episode_Reward/pen_joint_accel: -0.0879
    Episode_Reward/pen_action_rate: -0.3100
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0403
   Episode_Reward/pen_joint_powers: -0.0657
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7147
Episode_Reward/pen_flat_orientation: -0.1122
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.2995
   Episode_Reward/foot_landing_vel: -0.1136
   Episode_Reward/test_gait_reward: -0.8972
Metrics/base_velocity/error_vel_xy: 1.9463
Metrics/base_velocity/error_vel_yaw: 1.0527
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 1.10s
                        Total time: 1485.55s
                               ETA: 1763.8s

################################################################################
                     [1m Learning iteration 1372/3000 [0m                     

                       Computation: 90775 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 1.0865
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6401
                     Learning rate: 0.0006
                       Mean reward: 94.58
               Mean episode length: 954.09
       Episode_Reward/keep_balance: 0.9663
     Episode_Reward/rew_lin_vel_xy: 4.5502
      Episode_Reward/rew_ang_vel_z: 2.6913
    Episode_Reward/pen_base_height: -0.3159
      Episode_Reward/pen_lin_vel_z: -0.0556
     Episode_Reward/pen_ang_vel_xy: -0.1521
   Episode_Reward/pen_joint_torque: -0.1921
    Episode_Reward/pen_joint_accel: -0.0968
    Episode_Reward/pen_action_rate: -0.3083
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0418
   Episode_Reward/pen_joint_powers: -0.0678
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.7100
Episode_Reward/pen_flat_orientation: -0.1218
  Episode_Reward/pen_feet_distance: -0.0098
Episode_Reward/pen_feet_regulation: -0.3084
   Episode_Reward/foot_landing_vel: -0.1204
   Episode_Reward/test_gait_reward: -0.8760
Metrics/base_velocity/error_vel_xy: 1.8186
Metrics/base_velocity/error_vel_yaw: 1.0453
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 1.08s
                        Total time: 1486.63s
                               ETA: 1762.7s

################################################################################
                     [1m Learning iteration 1373/3000 [0m                     

                       Computation: 91304 steps/s (collection: 0.949s, learning 0.128s)
               Value function loss: 1.0398
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6409
                     Learning rate: 0.0006
                       Mean reward: 98.56
               Mean episode length: 965.53
       Episode_Reward/keep_balance: 0.9510
     Episode_Reward/rew_lin_vel_xy: 4.5425
      Episode_Reward/rew_ang_vel_z: 2.6361
    Episode_Reward/pen_base_height: -0.3244
      Episode_Reward/pen_lin_vel_z: -0.0534
     Episode_Reward/pen_ang_vel_xy: -0.1472
   Episode_Reward/pen_joint_torque: -0.1853
    Episode_Reward/pen_joint_accel: -0.0812
    Episode_Reward/pen_action_rate: -0.3017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0407
   Episode_Reward/pen_joint_powers: -0.0656
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6953
Episode_Reward/pen_flat_orientation: -0.1184
  Episode_Reward/pen_feet_distance: -0.0100
Episode_Reward/pen_feet_regulation: -0.3114
   Episode_Reward/foot_landing_vel: -0.1124
   Episode_Reward/test_gait_reward: -0.8719
Metrics/base_velocity/error_vel_xy: 1.7000
Metrics/base_velocity/error_vel_yaw: 1.0483
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 1.08s
                        Total time: 1487.70s
                               ETA: 1761.6s

################################################################################
                     [1m Learning iteration 1374/3000 [0m                     

                       Computation: 88909 steps/s (collection: 0.977s, learning 0.128s)
               Value function loss: 0.9394
                    Surrogate loss: -0.0035
             Mean action noise std: 0.6399
                     Learning rate: 0.0009
                       Mean reward: 101.50
               Mean episode length: 996.48
       Episode_Reward/keep_balance: 0.9972
     Episode_Reward/rew_lin_vel_xy: 4.7639
      Episode_Reward/rew_ang_vel_z: 2.7982
    Episode_Reward/pen_base_height: -0.3378
      Episode_Reward/pen_lin_vel_z: -0.0565
     Episode_Reward/pen_ang_vel_xy: -0.1542
   Episode_Reward/pen_joint_torque: -0.1925
    Episode_Reward/pen_joint_accel: -0.0937
    Episode_Reward/pen_action_rate: -0.3139
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0418
   Episode_Reward/pen_joint_powers: -0.0677
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7292
Episode_Reward/pen_flat_orientation: -0.1185
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.3213
   Episode_Reward/foot_landing_vel: -0.1156
   Episode_Reward/test_gait_reward: -0.9185
Metrics/base_velocity/error_vel_xy: 1.7844
Metrics/base_velocity/error_vel_yaw: 1.0644
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 1.11s
                        Total time: 1488.81s
                               ETA: 1760.6s

################################################################################
                     [1m Learning iteration 1375/3000 [0m                     

                       Computation: 88457 steps/s (collection: 0.983s, learning 0.128s)
               Value function loss: 1.0854
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6398
                     Learning rate: 0.0009
                       Mean reward: 100.85
               Mean episode length: 962.57
       Episode_Reward/keep_balance: 0.9512
     Episode_Reward/rew_lin_vel_xy: 4.7586
      Episode_Reward/rew_ang_vel_z: 2.6652
    Episode_Reward/pen_base_height: -0.3288
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1433
   Episode_Reward/pen_joint_torque: -0.1880
    Episode_Reward/pen_joint_accel: -0.0845
    Episode_Reward/pen_action_rate: -0.2979
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0400
   Episode_Reward/pen_joint_powers: -0.0655
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6885
Episode_Reward/pen_flat_orientation: -0.1219
  Episode_Reward/pen_feet_distance: -0.0057
Episode_Reward/pen_feet_regulation: -0.3032
   Episode_Reward/foot_landing_vel: -0.1073
   Episode_Reward/test_gait_reward: -0.8762
Metrics/base_velocity/error_vel_xy: 1.6175
Metrics/base_velocity/error_vel_yaw: 1.0211
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 1.11s
                        Total time: 1489.92s
                               ETA: 1759.5s

################################################################################
                     [1m Learning iteration 1376/3000 [0m                     

                       Computation: 84936 steps/s (collection: 1.024s, learning 0.134s)
               Value function loss: 0.9401
                    Surrogate loss: -0.0029
             Mean action noise std: 0.6407
                     Learning rate: 0.0006
                       Mean reward: 98.40
               Mean episode length: 973.28
       Episode_Reward/keep_balance: 0.9776
     Episode_Reward/rew_lin_vel_xy: 4.5507
      Episode_Reward/rew_ang_vel_z: 2.7246
    Episode_Reward/pen_base_height: -0.3315
      Episode_Reward/pen_lin_vel_z: -0.0549
     Episode_Reward/pen_ang_vel_xy: -0.1485
   Episode_Reward/pen_joint_torque: -0.1931
    Episode_Reward/pen_joint_accel: -0.0885
    Episode_Reward/pen_action_rate: -0.3074
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0403
   Episode_Reward/pen_joint_powers: -0.0664
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.7045
Episode_Reward/pen_flat_orientation: -0.1196
  Episode_Reward/pen_feet_distance: -0.0111
Episode_Reward/pen_feet_regulation: -0.3065
   Episode_Reward/foot_landing_vel: -0.1126
   Episode_Reward/test_gait_reward: -0.9003
Metrics/base_velocity/error_vel_xy: 1.8700
Metrics/base_velocity/error_vel_yaw: 1.0549
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 1.16s
                        Total time: 1491.08s
                               ETA: 1758.5s

################################################################################
                     [1m Learning iteration 1377/3000 [0m                     

                       Computation: 90647 steps/s (collection: 0.958s, learning 0.126s)
               Value function loss: 1.0245
                    Surrogate loss: 0.0008
             Mean action noise std: 0.6404
                     Learning rate: 0.0002
                       Mean reward: 99.63
               Mean episode length: 981.98
       Episode_Reward/keep_balance: 0.9806
     Episode_Reward/rew_lin_vel_xy: 4.5700
      Episode_Reward/rew_ang_vel_z: 2.7385
    Episode_Reward/pen_base_height: -0.3226
      Episode_Reward/pen_lin_vel_z: -0.0527
     Episode_Reward/pen_ang_vel_xy: -0.1455
   Episode_Reward/pen_joint_torque: -0.1845
    Episode_Reward/pen_joint_accel: -0.0826
    Episode_Reward/pen_action_rate: -0.3055
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0397
   Episode_Reward/pen_joint_powers: -0.0652
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7088
Episode_Reward/pen_flat_orientation: -0.1129
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.2907
   Episode_Reward/foot_landing_vel: -0.1103
   Episode_Reward/test_gait_reward: -0.8971
Metrics/base_velocity/error_vel_xy: 1.8326
Metrics/base_velocity/error_vel_yaw: 1.0537
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 1.08s
                        Total time: 1492.16s
                               ETA: 1757.5s

################################################################################
                     [1m Learning iteration 1378/3000 [0m                     

                       Computation: 90255 steps/s (collection: 0.963s, learning 0.127s)
               Value function loss: 0.8437
                    Surrogate loss: -0.0042
             Mean action noise std: 0.6404
                     Learning rate: 0.0004
                       Mean reward: 100.63
               Mean episode length: 968.46
       Episode_Reward/keep_balance: 0.9455
     Episode_Reward/rew_lin_vel_xy: 4.6969
      Episode_Reward/rew_ang_vel_z: 2.6226
    Episode_Reward/pen_base_height: -0.3311
      Episode_Reward/pen_lin_vel_z: -0.0545
     Episode_Reward/pen_ang_vel_xy: -0.1506
   Episode_Reward/pen_joint_torque: -0.1858
    Episode_Reward/pen_joint_accel: -0.0874
    Episode_Reward/pen_action_rate: -0.3012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0407
   Episode_Reward/pen_joint_powers: -0.0661
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6912
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.3094
   Episode_Reward/foot_landing_vel: -0.1141
   Episode_Reward/test_gait_reward: -0.8706
Metrics/base_velocity/error_vel_xy: 1.5987
Metrics/base_velocity/error_vel_yaw: 1.0296
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 1.09s
                        Total time: 1493.25s
                               ETA: 1756.4s

################################################################################
                     [1m Learning iteration 1379/3000 [0m                     

                       Computation: 90934 steps/s (collection: 0.956s, learning 0.125s)
               Value function loss: 0.9893
                    Surrogate loss: -0.0031
             Mean action noise std: 0.6417
                     Learning rate: 0.0004
                       Mean reward: 101.89
               Mean episode length: 988.70
       Episode_Reward/keep_balance: 0.9940
     Episode_Reward/rew_lin_vel_xy: 4.8483
      Episode_Reward/rew_ang_vel_z: 2.7980
    Episode_Reward/pen_base_height: -0.3305
      Episode_Reward/pen_lin_vel_z: -0.0581
     Episode_Reward/pen_ang_vel_xy: -0.1508
   Episode_Reward/pen_joint_torque: -0.1934
    Episode_Reward/pen_joint_accel: -0.0839
    Episode_Reward/pen_action_rate: -0.3121
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0416
   Episode_Reward/pen_joint_powers: -0.0684
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7202
Episode_Reward/pen_flat_orientation: -0.1166
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3186
   Episode_Reward/foot_landing_vel: -0.1210
   Episode_Reward/test_gait_reward: -0.9105
Metrics/base_velocity/error_vel_xy: 1.8028
Metrics/base_velocity/error_vel_yaw: 1.0489
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 1.08s
                        Total time: 1494.33s
                               ETA: 1755.3s

################################################################################
                     [1m Learning iteration 1380/3000 [0m                     

                       Computation: 91661 steps/s (collection: 0.949s, learning 0.124s)
               Value function loss: 0.9897
                    Surrogate loss: -0.0039
             Mean action noise std: 0.6429
                     Learning rate: 0.0006
                       Mean reward: 96.54
               Mean episode length: 945.42
       Episode_Reward/keep_balance: 0.9458
     Episode_Reward/rew_lin_vel_xy: 4.6764
      Episode_Reward/rew_ang_vel_z: 2.6278
    Episode_Reward/pen_base_height: -0.3254
      Episode_Reward/pen_lin_vel_z: -0.0543
     Episode_Reward/pen_ang_vel_xy: -0.1435
   Episode_Reward/pen_joint_torque: -0.1896
    Episode_Reward/pen_joint_accel: -0.0866
    Episode_Reward/pen_action_rate: -0.2993
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0395
   Episode_Reward/pen_joint_powers: -0.0663
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.6867
Episode_Reward/pen_flat_orientation: -0.1144
  Episode_Reward/pen_feet_distance: -0.0064
Episode_Reward/pen_feet_regulation: -0.2941
   Episode_Reward/foot_landing_vel: -0.1105
   Episode_Reward/test_gait_reward: -0.8699
Metrics/base_velocity/error_vel_xy: 1.6235
Metrics/base_velocity/error_vel_yaw: 1.0305
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 1.07s
                        Total time: 1495.41s
                               ETA: 1754.2s

################################################################################
                     [1m Learning iteration 1381/3000 [0m                     

                       Computation: 92274 steps/s (collection: 0.943s, learning 0.123s)
               Value function loss: 0.9636
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6424
                     Learning rate: 0.0009
                       Mean reward: 97.40
               Mean episode length: 972.48
       Episode_Reward/keep_balance: 0.9892
     Episode_Reward/rew_lin_vel_xy: 4.4510
      Episode_Reward/rew_ang_vel_z: 2.7496
    Episode_Reward/pen_base_height: -0.3226
      Episode_Reward/pen_lin_vel_z: -0.0557
     Episode_Reward/pen_ang_vel_xy: -0.1540
   Episode_Reward/pen_joint_torque: -0.1926
    Episode_Reward/pen_joint_accel: -0.0861
    Episode_Reward/pen_action_rate: -0.3113
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0412
   Episode_Reward/pen_joint_powers: -0.0677
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7263
Episode_Reward/pen_flat_orientation: -0.1144
  Episode_Reward/pen_feet_distance: -0.0064
Episode_Reward/pen_feet_regulation: -0.3094
   Episode_Reward/foot_landing_vel: -0.1131
   Episode_Reward/test_gait_reward: -0.9038
Metrics/base_velocity/error_vel_xy: 1.9341
Metrics/base_velocity/error_vel_yaw: 1.0727
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 1.07s
                        Total time: 1496.47s
                               ETA: 1753.1s

################################################################################
                     [1m Learning iteration 1382/3000 [0m                     

                       Computation: 91954 steps/s (collection: 0.942s, learning 0.127s)
               Value function loss: 1.0224
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6418
                     Learning rate: 0.0009
                       Mean reward: 101.72
               Mean episode length: 990.94
       Episode_Reward/keep_balance: 0.9922
     Episode_Reward/rew_lin_vel_xy: 4.7221
      Episode_Reward/rew_ang_vel_z: 2.7706
    Episode_Reward/pen_base_height: -0.3267
      Episode_Reward/pen_lin_vel_z: -0.0552
     Episode_Reward/pen_ang_vel_xy: -0.1482
   Episode_Reward/pen_joint_torque: -0.1920
    Episode_Reward/pen_joint_accel: -0.0871
    Episode_Reward/pen_action_rate: -0.3121
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0411
   Episode_Reward/pen_joint_powers: -0.0675
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7223
Episode_Reward/pen_flat_orientation: -0.1138
  Episode_Reward/pen_feet_distance: -0.0088
Episode_Reward/pen_feet_regulation: -0.3173
   Episode_Reward/foot_landing_vel: -0.1160
   Episode_Reward/test_gait_reward: -0.9091
Metrics/base_velocity/error_vel_xy: 1.8307
Metrics/base_velocity/error_vel_yaw: 1.0647
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 1.07s
                        Total time: 1497.54s
                               ETA: 1752.0s

################################################################################
                     [1m Learning iteration 1383/3000 [0m                     

                       Computation: 88539 steps/s (collection: 0.981s, learning 0.129s)
               Value function loss: 0.9322
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6412
                     Learning rate: 0.0006
                       Mean reward: 96.78
               Mean episode length: 956.92
       Episode_Reward/keep_balance: 0.9633
     Episode_Reward/rew_lin_vel_xy: 4.5741
      Episode_Reward/rew_ang_vel_z: 2.6852
    Episode_Reward/pen_base_height: -0.3181
      Episode_Reward/pen_lin_vel_z: -0.0523
     Episode_Reward/pen_ang_vel_xy: -0.1442
   Episode_Reward/pen_joint_torque: -0.1891
    Episode_Reward/pen_joint_accel: -0.0805
    Episode_Reward/pen_action_rate: -0.3028
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0389
   Episode_Reward/pen_joint_powers: -0.0654
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6967
Episode_Reward/pen_flat_orientation: -0.1133
  Episode_Reward/pen_feet_distance: -0.0075
Episode_Reward/pen_feet_regulation: -0.2891
   Episode_Reward/foot_landing_vel: -0.1066
   Episode_Reward/test_gait_reward: -0.8884
Metrics/base_velocity/error_vel_xy: 1.7575
Metrics/base_velocity/error_vel_yaw: 1.0435
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 1.11s
                        Total time: 1498.65s
                               ETA: 1751.0s

################################################################################
                     [1m Learning iteration 1384/3000 [0m                     

                       Computation: 92050 steps/s (collection: 0.944s, learning 0.124s)
               Value function loss: 1.0046
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6412
                     Learning rate: 0.0004
                       Mean reward: 102.39
               Mean episode length: 985.34
       Episode_Reward/keep_balance: 0.9796
     Episode_Reward/rew_lin_vel_xy: 4.5339
      Episode_Reward/rew_ang_vel_z: 2.6977
    Episode_Reward/pen_base_height: -0.3029
      Episode_Reward/pen_lin_vel_z: -0.0522
     Episode_Reward/pen_ang_vel_xy: -0.1493
   Episode_Reward/pen_joint_torque: -0.1802
    Episode_Reward/pen_joint_accel: -0.0823
    Episode_Reward/pen_action_rate: -0.3030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0398
   Episode_Reward/pen_joint_powers: -0.0648
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7144
Episode_Reward/pen_flat_orientation: -0.1159
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.2974
   Episode_Reward/foot_landing_vel: -0.1112
   Episode_Reward/test_gait_reward: -0.8817
Metrics/base_velocity/error_vel_xy: 1.9025
Metrics/base_velocity/error_vel_yaw: 1.0801
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 1.07s
                        Total time: 1499.72s
                               ETA: 1749.9s

################################################################################
                     [1m Learning iteration 1385/3000 [0m                     

                       Computation: 92760 steps/s (collection: 0.935s, learning 0.124s)
               Value function loss: 1.0032
                    Surrogate loss: -0.0035
             Mean action noise std: 0.6414
                     Learning rate: 0.0003
                       Mean reward: 97.79
               Mean episode length: 971.53
       Episode_Reward/keep_balance: 0.9741
     Episode_Reward/rew_lin_vel_xy: 4.4868
      Episode_Reward/rew_ang_vel_z: 2.7108
    Episode_Reward/pen_base_height: -0.3112
      Episode_Reward/pen_lin_vel_z: -0.0507
     Episode_Reward/pen_ang_vel_xy: -0.1457
   Episode_Reward/pen_joint_torque: -0.1882
    Episode_Reward/pen_joint_accel: -0.0784
    Episode_Reward/pen_action_rate: -0.3019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0398
   Episode_Reward/pen_joint_powers: -0.0657
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7051
Episode_Reward/pen_flat_orientation: -0.1125
  Episode_Reward/pen_feet_distance: -0.0113
Episode_Reward/pen_feet_regulation: -0.2902
   Episode_Reward/foot_landing_vel: -0.1052
   Episode_Reward/test_gait_reward: -0.8841
Metrics/base_velocity/error_vel_xy: 1.8691
Metrics/base_velocity/error_vel_yaw: 1.0582
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 1.06s
                        Total time: 1500.78s
                               ETA: 1748.7s

################################################################################
                     [1m Learning iteration 1386/3000 [0m                     

                       Computation: 91797 steps/s (collection: 0.947s, learning 0.124s)
               Value function loss: 1.0171
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6405
                     Learning rate: 0.0006
                       Mean reward: 97.59
               Mean episode length: 970.11
       Episode_Reward/keep_balance: 0.9638
     Episode_Reward/rew_lin_vel_xy: 4.4527
      Episode_Reward/rew_ang_vel_z: 2.6898
    Episode_Reward/pen_base_height: -0.3268
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1538
   Episode_Reward/pen_joint_torque: -0.1977
    Episode_Reward/pen_joint_accel: -0.0847
    Episode_Reward/pen_action_rate: -0.3053
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0412
   Episode_Reward/pen_joint_powers: -0.0690
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7000
Episode_Reward/pen_flat_orientation: -0.1144
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.3015
   Episode_Reward/foot_landing_vel: -0.1135
   Episode_Reward/test_gait_reward: -0.8862
Metrics/base_velocity/error_vel_xy: 1.8863
Metrics/base_velocity/error_vel_yaw: 1.0479
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 1.07s
                        Total time: 1501.85s
                               ETA: 1747.6s

################################################################################
                     [1m Learning iteration 1387/3000 [0m                     

                       Computation: 88226 steps/s (collection: 0.986s, learning 0.128s)
               Value function loss: 0.9344
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6410
                     Learning rate: 0.0009
                       Mean reward: 97.87
               Mean episode length: 977.54
       Episode_Reward/keep_balance: 0.9786
     Episode_Reward/rew_lin_vel_xy: 4.6020
      Episode_Reward/rew_ang_vel_z: 2.7015
    Episode_Reward/pen_base_height: -0.3195
      Episode_Reward/pen_lin_vel_z: -0.0532
     Episode_Reward/pen_ang_vel_xy: -0.1521
   Episode_Reward/pen_joint_torque: -0.1955
    Episode_Reward/pen_joint_accel: -0.0817
    Episode_Reward/pen_action_rate: -0.3111
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0415
   Episode_Reward/pen_joint_powers: -0.0683
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7171
Episode_Reward/pen_flat_orientation: -0.1175
  Episode_Reward/pen_feet_distance: -0.0073
Episode_Reward/pen_feet_regulation: -0.3097
   Episode_Reward/foot_landing_vel: -0.1175
   Episode_Reward/test_gait_reward: -0.8920
Metrics/base_velocity/error_vel_xy: 1.8077
Metrics/base_velocity/error_vel_yaw: 1.0794
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 1.11s
                        Total time: 1502.96s
                               ETA: 1746.6s

################################################################################
                     [1m Learning iteration 1388/3000 [0m                     

                       Computation: 87516 steps/s (collection: 0.995s, learning 0.129s)
               Value function loss: 0.8870
                    Surrogate loss: 0.0038
             Mean action noise std: 0.6410
                     Learning rate: 0.0001
                       Mean reward: 100.39
               Mean episode length: 990.08
       Episode_Reward/keep_balance: 0.9940
     Episode_Reward/rew_lin_vel_xy: 4.7123
      Episode_Reward/rew_ang_vel_z: 2.7220
    Episode_Reward/pen_base_height: -0.3240
      Episode_Reward/pen_lin_vel_z: -0.0530
     Episode_Reward/pen_ang_vel_xy: -0.1541
   Episode_Reward/pen_joint_torque: -0.1898
    Episode_Reward/pen_joint_accel: -0.0840
    Episode_Reward/pen_action_rate: -0.3135
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0415
   Episode_Reward/pen_joint_powers: -0.0677
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7243
Episode_Reward/pen_flat_orientation: -0.1172
  Episode_Reward/pen_feet_distance: -0.0104
Episode_Reward/pen_feet_regulation: -0.3108
   Episode_Reward/foot_landing_vel: -0.1121
   Episode_Reward/test_gait_reward: -0.9107
Metrics/base_velocity/error_vel_xy: 1.7807
Metrics/base_velocity/error_vel_yaw: 1.1143
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 1.12s
                        Total time: 1504.09s
                               ETA: 1745.6s

################################################################################
                     [1m Learning iteration 1389/3000 [0m                     

                       Computation: 88350 steps/s (collection: 0.988s, learning 0.125s)
               Value function loss: 0.9276
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6407
                     Learning rate: 0.0002
                       Mean reward: 99.72
               Mean episode length: 968.23
       Episode_Reward/keep_balance: 0.9735
     Episode_Reward/rew_lin_vel_xy: 4.7101
      Episode_Reward/rew_ang_vel_z: 2.6895
    Episode_Reward/pen_base_height: -0.3240
      Episode_Reward/pen_lin_vel_z: -0.0542
     Episode_Reward/pen_ang_vel_xy: -0.1520
   Episode_Reward/pen_joint_torque: -0.1883
    Episode_Reward/pen_joint_accel: -0.0864
    Episode_Reward/pen_action_rate: -0.3105
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0419
   Episode_Reward/pen_joint_powers: -0.0671
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7157
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3155
   Episode_Reward/foot_landing_vel: -0.1158
   Episode_Reward/test_gait_reward: -0.8956
Metrics/base_velocity/error_vel_xy: 1.7014
Metrics/base_velocity/error_vel_yaw: 1.0763
      Episode_Termination/time_out: 5.0417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 1.11s
                        Total time: 1505.20s
                               ETA: 1744.5s

################################################################################
                     [1m Learning iteration 1390/3000 [0m                     

                       Computation: 86959 steps/s (collection: 1.004s, learning 0.126s)
               Value function loss: 0.9154
                    Surrogate loss: -0.0035
             Mean action noise std: 0.6409
                     Learning rate: 0.0006
                       Mean reward: 105.47
               Mean episode length: 982.49
       Episode_Reward/keep_balance: 0.9827
     Episode_Reward/rew_lin_vel_xy: 4.7932
      Episode_Reward/rew_ang_vel_z: 2.7487
    Episode_Reward/pen_base_height: -0.3118
      Episode_Reward/pen_lin_vel_z: -0.0526
     Episode_Reward/pen_ang_vel_xy: -0.1409
   Episode_Reward/pen_joint_torque: -0.1824
    Episode_Reward/pen_joint_accel: -0.0778
    Episode_Reward/pen_action_rate: -0.3008
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0383
   Episode_Reward/pen_joint_powers: -0.0640
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7040
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0061
Episode_Reward/pen_feet_regulation: -0.2789
   Episode_Reward/foot_landing_vel: -0.1084
   Episode_Reward/test_gait_reward: -0.8901
Metrics/base_velocity/error_vel_xy: 1.7108
Metrics/base_velocity/error_vel_yaw: 1.0579
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 1.13s
                        Total time: 1506.33s
                               ETA: 1743.5s

################################################################################
                     [1m Learning iteration 1391/3000 [0m                     

                       Computation: 85865 steps/s (collection: 1.015s, learning 0.130s)
               Value function loss: 0.9795
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6409
                     Learning rate: 0.0000
                       Mean reward: 98.30
               Mean episode length: 970.64
       Episode_Reward/keep_balance: 0.9823
     Episode_Reward/rew_lin_vel_xy: 4.8159
      Episode_Reward/rew_ang_vel_z: 2.7280
    Episode_Reward/pen_base_height: -0.3186
      Episode_Reward/pen_lin_vel_z: -0.0569
     Episode_Reward/pen_ang_vel_xy: -0.1591
   Episode_Reward/pen_joint_torque: -0.1925
    Episode_Reward/pen_joint_accel: -0.0837
    Episode_Reward/pen_action_rate: -0.3155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0419
   Episode_Reward/pen_joint_powers: -0.0683
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.7216
Episode_Reward/pen_flat_orientation: -0.1153
  Episode_Reward/pen_feet_distance: -0.0058
Episode_Reward/pen_feet_regulation: -0.3124
   Episode_Reward/foot_landing_vel: -0.1213
   Episode_Reward/test_gait_reward: -0.9018
Metrics/base_velocity/error_vel_xy: 1.6876
Metrics/base_velocity/error_vel_yaw: 1.0742
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 1.14s
                        Total time: 1507.48s
                               ETA: 1742.5s

################################################################################
                     [1m Learning iteration 1392/3000 [0m                     

                       Computation: 92739 steps/s (collection: 0.937s, learning 0.123s)
               Value function loss: 0.9877
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6404
                     Learning rate: 0.0002
                       Mean reward: 105.81
               Mean episode length: 993.77
       Episode_Reward/keep_balance: 0.9951
     Episode_Reward/rew_lin_vel_xy: 5.0433
      Episode_Reward/rew_ang_vel_z: 2.7567
    Episode_Reward/pen_base_height: -0.3184
      Episode_Reward/pen_lin_vel_z: -0.0558
     Episode_Reward/pen_ang_vel_xy: -0.1514
   Episode_Reward/pen_joint_torque: -0.1992
    Episode_Reward/pen_joint_accel: -0.0866
    Episode_Reward/pen_action_rate: -0.3151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0412
   Episode_Reward/pen_joint_powers: -0.0691
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7258
Episode_Reward/pen_flat_orientation: -0.1117
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.3060
   Episode_Reward/foot_landing_vel: -0.1113
   Episode_Reward/test_gait_reward: -0.9141
Metrics/base_velocity/error_vel_xy: 1.6800
Metrics/base_velocity/error_vel_yaw: 1.0887
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 1.06s
                        Total time: 1508.54s
                               ETA: 1741.4s

################################################################################
                     [1m Learning iteration 1393/3000 [0m                     

                       Computation: 93503 steps/s (collection: 0.929s, learning 0.123s)
               Value function loss: 0.9244
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6392
                     Learning rate: 0.0002
                       Mean reward: 100.58
               Mean episode length: 965.08
       Episode_Reward/keep_balance: 0.9538
     Episode_Reward/rew_lin_vel_xy: 4.5824
      Episode_Reward/rew_ang_vel_z: 2.6472
    Episode_Reward/pen_base_height: -0.3164
      Episode_Reward/pen_lin_vel_z: -0.0558
     Episode_Reward/pen_ang_vel_xy: -0.1429
   Episode_Reward/pen_joint_torque: -0.1890
    Episode_Reward/pen_joint_accel: -0.0833
    Episode_Reward/pen_action_rate: -0.3015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0409
   Episode_Reward/pen_joint_powers: -0.0670
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6965
Episode_Reward/pen_flat_orientation: -0.1147
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3040
   Episode_Reward/foot_landing_vel: -0.1183
   Episode_Reward/test_gait_reward: -0.8720
Metrics/base_velocity/error_vel_xy: 1.7397
Metrics/base_velocity/error_vel_yaw: 1.0419
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 1.05s
                        Total time: 1509.59s
                               ETA: 1740.2s

################################################################################
                     [1m Learning iteration 1394/3000 [0m                     

                       Computation: 89774 steps/s (collection: 0.967s, learning 0.128s)
               Value function loss: 1.0122
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6393
                     Learning rate: 0.0002
                       Mean reward: 96.98
               Mean episode length: 983.49
       Episode_Reward/keep_balance: 0.9858
     Episode_Reward/rew_lin_vel_xy: 4.5294
      Episode_Reward/rew_ang_vel_z: 2.7291
    Episode_Reward/pen_base_height: -0.3301
      Episode_Reward/pen_lin_vel_z: -0.0542
     Episode_Reward/pen_ang_vel_xy: -0.1569
   Episode_Reward/pen_joint_torque: -0.1938
    Episode_Reward/pen_joint_accel: -0.0860
    Episode_Reward/pen_action_rate: -0.3190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0416
   Episode_Reward/pen_joint_powers: -0.0681
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7260
Episode_Reward/pen_flat_orientation: -0.1168
  Episode_Reward/pen_feet_distance: -0.0028
Episode_Reward/pen_feet_regulation: -0.3214
   Episode_Reward/foot_landing_vel: -0.1146
   Episode_Reward/test_gait_reward: -0.9064
Metrics/base_velocity/error_vel_xy: 1.9285
Metrics/base_velocity/error_vel_yaw: 1.0771
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 1.10s
                        Total time: 1510.68s
                               ETA: 1739.2s

################################################################################
                     [1m Learning iteration 1395/3000 [0m                     

                       Computation: 90202 steps/s (collection: 0.962s, learning 0.128s)
               Value function loss: 1.0127
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6397
                     Learning rate: 0.0004
                       Mean reward: 96.61
               Mean episode length: 955.24
       Episode_Reward/keep_balance: 0.9652
     Episode_Reward/rew_lin_vel_xy: 4.6975
      Episode_Reward/rew_ang_vel_z: 2.6661
    Episode_Reward/pen_base_height: -0.3060
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.1511
   Episode_Reward/pen_joint_torque: -0.1809
    Episode_Reward/pen_joint_accel: -0.0875
    Episode_Reward/pen_action_rate: -0.3065
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0406
   Episode_Reward/pen_joint_powers: -0.0652
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7159
Episode_Reward/pen_flat_orientation: -0.1114
  Episode_Reward/pen_feet_distance: -0.0043
Episode_Reward/pen_feet_regulation: -0.3009
   Episode_Reward/foot_landing_vel: -0.1154
   Episode_Reward/test_gait_reward: -0.8780
Metrics/base_velocity/error_vel_xy: 1.7142
Metrics/base_velocity/error_vel_yaw: 1.0614
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 1.09s
                        Total time: 1511.77s
                               ETA: 1738.1s

################################################################################
                     [1m Learning iteration 1396/3000 [0m                     

                       Computation: 88269 steps/s (collection: 0.986s, learning 0.128s)
               Value function loss: 0.9433
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6394
                     Learning rate: 0.0002
                       Mean reward: 95.79
               Mean episode length: 928.04
       Episode_Reward/keep_balance: 0.9303
     Episode_Reward/rew_lin_vel_xy: 4.5607
      Episode_Reward/rew_ang_vel_z: 2.5772
    Episode_Reward/pen_base_height: -0.3114
      Episode_Reward/pen_lin_vel_z: -0.0509
     Episode_Reward/pen_ang_vel_xy: -0.1470
   Episode_Reward/pen_joint_torque: -0.1797
    Episode_Reward/pen_joint_accel: -0.0855
    Episode_Reward/pen_action_rate: -0.2974
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0395
   Episode_Reward/pen_joint_powers: -0.0645
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6861
Episode_Reward/pen_flat_orientation: -0.1146
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.2800
   Episode_Reward/foot_landing_vel: -0.1079
   Episode_Reward/test_gait_reward: -0.8452
Metrics/base_velocity/error_vel_xy: 1.6403
Metrics/base_velocity/error_vel_yaw: 1.0225
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 1.11s
                        Total time: 1512.88s
                               ETA: 1737.1s

################################################################################
                     [1m Learning iteration 1397/3000 [0m                     

                       Computation: 87968 steps/s (collection: 0.993s, learning 0.124s)
               Value function loss: 0.9880
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6392
                     Learning rate: 0.0004
                       Mean reward: 101.53
               Mean episode length: 974.26
       Episode_Reward/keep_balance: 0.9823
     Episode_Reward/rew_lin_vel_xy: 4.7804
      Episode_Reward/rew_ang_vel_z: 2.6962
    Episode_Reward/pen_base_height: -0.3339
      Episode_Reward/pen_lin_vel_z: -0.0546
     Episode_Reward/pen_ang_vel_xy: -0.1535
   Episode_Reward/pen_joint_torque: -0.1960
    Episode_Reward/pen_joint_accel: -0.0798
    Episode_Reward/pen_action_rate: -0.3153
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0417
   Episode_Reward/pen_joint_powers: -0.0692
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7203
Episode_Reward/pen_flat_orientation: -0.1204
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3236
   Episode_Reward/foot_landing_vel: -0.1084
   Episode_Reward/test_gait_reward: -0.9065
Metrics/base_velocity/error_vel_xy: 1.6979
Metrics/base_velocity/error_vel_yaw: 1.0947
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 1.12s
                        Total time: 1514.00s
                               ETA: 1736.0s

################################################################################
                     [1m Learning iteration 1398/3000 [0m                     

                       Computation: 90424 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.9275
                    Surrogate loss: 0.0003
             Mean action noise std: 0.6393
                     Learning rate: 0.0001
                       Mean reward: 99.02
               Mean episode length: 982.51
       Episode_Reward/keep_balance: 0.9891
     Episode_Reward/rew_lin_vel_xy: 4.7274
      Episode_Reward/rew_ang_vel_z: 2.7227
    Episode_Reward/pen_base_height: -0.3281
      Episode_Reward/pen_lin_vel_z: -0.0565
     Episode_Reward/pen_ang_vel_xy: -0.1493
   Episode_Reward/pen_joint_torque: -0.1904
    Episode_Reward/pen_joint_accel: -0.0858
    Episode_Reward/pen_action_rate: -0.3144
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0416
   Episode_Reward/pen_joint_powers: -0.0681
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7238
Episode_Reward/pen_flat_orientation: -0.1104
  Episode_Reward/pen_feet_distance: -0.0046
Episode_Reward/pen_feet_regulation: -0.3131
   Episode_Reward/foot_landing_vel: -0.1193
   Episode_Reward/test_gait_reward: -0.9097
Metrics/base_velocity/error_vel_xy: 1.7278
Metrics/base_velocity/error_vel_yaw: 1.1010
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 1.09s
                        Total time: 1515.09s
                               ETA: 1734.9s

################################################################################
                     [1m Learning iteration 1399/3000 [0m                     

                       Computation: 88741 steps/s (collection: 0.982s, learning 0.126s)
               Value function loss: 0.9701
                    Surrogate loss: -0.0035
             Mean action noise std: 0.6381
                     Learning rate: 0.0003
                       Mean reward: 100.90
               Mean episode length: 991.03
       Episode_Reward/keep_balance: 0.9964
     Episode_Reward/rew_lin_vel_xy: 4.8075
      Episode_Reward/rew_ang_vel_z: 2.7405
    Episode_Reward/pen_base_height: -0.3355
      Episode_Reward/pen_lin_vel_z: -0.0556
     Episode_Reward/pen_ang_vel_xy: -0.1576
   Episode_Reward/pen_joint_torque: -0.1978
    Episode_Reward/pen_joint_accel: -0.0829
    Episode_Reward/pen_action_rate: -0.3171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0425
   Episode_Reward/pen_joint_powers: -0.0701
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7307
Episode_Reward/pen_flat_orientation: -0.1207
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.3184
   Episode_Reward/foot_landing_vel: -0.1100
   Episode_Reward/test_gait_reward: -0.9171
Metrics/base_velocity/error_vel_xy: 1.7833
Metrics/base_velocity/error_vel_yaw: 1.1083
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 1.11s
                        Total time: 1516.20s
                               ETA: 1733.9s

################################################################################
                     [1m Learning iteration 1400/3000 [0m                     

                       Computation: 90502 steps/s (collection: 0.955s, learning 0.131s)
               Value function loss: 0.9755
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6381
                     Learning rate: 0.0006
                       Mean reward: 101.07
               Mean episode length: 944.86
       Episode_Reward/keep_balance: 0.9423
     Episode_Reward/rew_lin_vel_xy: 4.9148
      Episode_Reward/rew_ang_vel_z: 2.6171
    Episode_Reward/pen_base_height: -0.3310
      Episode_Reward/pen_lin_vel_z: -0.0566
     Episode_Reward/pen_ang_vel_xy: -0.1566
   Episode_Reward/pen_joint_torque: -0.1852
    Episode_Reward/pen_joint_accel: -0.0899
    Episode_Reward/pen_action_rate: -0.3034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0426
   Episode_Reward/pen_joint_powers: -0.0683
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6934
Episode_Reward/pen_flat_orientation: -0.1192
  Episode_Reward/pen_feet_distance: -0.0055
Episode_Reward/pen_feet_regulation: -0.3392
   Episode_Reward/foot_landing_vel: -0.1066
   Episode_Reward/test_gait_reward: -0.8839
Metrics/base_velocity/error_vel_xy: 1.4103
Metrics/base_velocity/error_vel_yaw: 1.0283
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 1.09s
                        Total time: 1517.28s
                               ETA: 1732.8s

################################################################################
                     [1m Learning iteration 1401/3000 [0m                     

                       Computation: 88272 steps/s (collection: 0.986s, learning 0.128s)
               Value function loss: 1.0405
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6386
                     Learning rate: 0.0003
                       Mean reward: 100.92
               Mean episode length: 971.80
       Episode_Reward/keep_balance: 0.9797
     Episode_Reward/rew_lin_vel_xy: 4.8396
      Episode_Reward/rew_ang_vel_z: 2.6905
    Episode_Reward/pen_base_height: -0.3242
      Episode_Reward/pen_lin_vel_z: -0.0565
     Episode_Reward/pen_ang_vel_xy: -0.1585
   Episode_Reward/pen_joint_torque: -0.1881
    Episode_Reward/pen_joint_accel: -0.0838
    Episode_Reward/pen_action_rate: -0.3144
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0421
   Episode_Reward/pen_joint_powers: -0.0682
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7240
Episode_Reward/pen_flat_orientation: -0.1126
  Episode_Reward/pen_feet_distance: -0.0052
Episode_Reward/pen_feet_regulation: -0.3160
   Episode_Reward/foot_landing_vel: -0.1178
   Episode_Reward/test_gait_reward: -0.9007
Metrics/base_velocity/error_vel_xy: 1.6885
Metrics/base_velocity/error_vel_yaw: 1.0932
      Episode_Termination/time_out: 4.9167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 1.11s
                        Total time: 1518.40s
                               ETA: 1731.8s

################################################################################
                     [1m Learning iteration 1402/3000 [0m                     

                       Computation: 88849 steps/s (collection: 0.981s, learning 0.125s)
               Value function loss: 0.8703
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6381
                     Learning rate: 0.0002
                       Mean reward: 95.63
               Mean episode length: 963.93
       Episode_Reward/keep_balance: 0.9693
     Episode_Reward/rew_lin_vel_xy: 4.6222
      Episode_Reward/rew_ang_vel_z: 2.6708
    Episode_Reward/pen_base_height: -0.3325
      Episode_Reward/pen_lin_vel_z: -0.0536
     Episode_Reward/pen_ang_vel_xy: -0.1525
   Episode_Reward/pen_joint_torque: -0.1905
    Episode_Reward/pen_joint_accel: -0.0846
    Episode_Reward/pen_action_rate: -0.3128
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0415
   Episode_Reward/pen_joint_powers: -0.0673
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7146
Episode_Reward/pen_flat_orientation: -0.1173
  Episode_Reward/pen_feet_distance: -0.0085
Episode_Reward/pen_feet_regulation: -0.3101
   Episode_Reward/foot_landing_vel: -0.1103
   Episode_Reward/test_gait_reward: -0.8938
Metrics/base_velocity/error_vel_xy: 1.7603
Metrics/base_velocity/error_vel_yaw: 1.0811
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 1.11s
                        Total time: 1519.50s
                               ETA: 1730.7s

################################################################################
                     [1m Learning iteration 1403/3000 [0m                     

                       Computation: 89644 steps/s (collection: 0.970s, learning 0.127s)
               Value function loss: 0.9442
                    Surrogate loss: -0.0038
             Mean action noise std: 0.6373
                     Learning rate: 0.0004
                       Mean reward: 101.75
               Mean episode length: 972.84
       Episode_Reward/keep_balance: 0.9675
     Episode_Reward/rew_lin_vel_xy: 4.8133
      Episode_Reward/rew_ang_vel_z: 2.6970
    Episode_Reward/pen_base_height: -0.3197
      Episode_Reward/pen_lin_vel_z: -0.0563
     Episode_Reward/pen_ang_vel_xy: -0.1548
   Episode_Reward/pen_joint_torque: -0.1886
    Episode_Reward/pen_joint_accel: -0.0881
    Episode_Reward/pen_action_rate: -0.3068
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0416
   Episode_Reward/pen_joint_powers: -0.0679
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7072
Episode_Reward/pen_flat_orientation: -0.1205
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.3143
   Episode_Reward/foot_landing_vel: -0.1120
   Episode_Reward/test_gait_reward: -0.8890
Metrics/base_velocity/error_vel_xy: 1.6008
Metrics/base_velocity/error_vel_yaw: 1.0499
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 1.10s
                        Total time: 1520.60s
                               ETA: 1729.6s

################################################################################
                     [1m Learning iteration 1404/3000 [0m                     

                       Computation: 89728 steps/s (collection: 0.968s, learning 0.128s)
               Value function loss: 0.9192
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6372
                     Learning rate: 0.0000
                       Mean reward: 101.62
               Mean episode length: 973.69
       Episode_Reward/keep_balance: 0.9753
     Episode_Reward/rew_lin_vel_xy: 4.8126
      Episode_Reward/rew_ang_vel_z: 2.6981
    Episode_Reward/pen_base_height: -0.3176
      Episode_Reward/pen_lin_vel_z: -0.0541
     Episode_Reward/pen_ang_vel_xy: -0.1490
   Episode_Reward/pen_joint_torque: -0.1942
    Episode_Reward/pen_joint_accel: -0.0877
    Episode_Reward/pen_action_rate: -0.3109
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0411
   Episode_Reward/pen_joint_powers: -0.0675
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.7186
Episode_Reward/pen_flat_orientation: -0.1180
  Episode_Reward/pen_feet_distance: -0.0050
Episode_Reward/pen_feet_regulation: -0.3014
   Episode_Reward/foot_landing_vel: -0.1105
   Episode_Reward/test_gait_reward: -0.8922
Metrics/base_velocity/error_vel_xy: 1.7353
Metrics/base_velocity/error_vel_yaw: 1.0768
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 1.10s
                        Total time: 1521.70s
                               ETA: 1728.6s

################################################################################
                     [1m Learning iteration 1405/3000 [0m                     

                       Computation: 90443 steps/s (collection: 0.958s, learning 0.129s)
               Value function loss: 0.9768
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6374
                     Learning rate: 0.0001
                       Mean reward: 101.81
               Mean episode length: 981.49
       Episode_Reward/keep_balance: 0.9783
     Episode_Reward/rew_lin_vel_xy: 4.8059
      Episode_Reward/rew_ang_vel_z: 2.7194
    Episode_Reward/pen_base_height: -0.3443
      Episode_Reward/pen_lin_vel_z: -0.0551
     Episode_Reward/pen_ang_vel_xy: -0.1513
   Episode_Reward/pen_joint_torque: -0.1896
    Episode_Reward/pen_joint_accel: -0.0859
    Episode_Reward/pen_action_rate: -0.3125
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0418
   Episode_Reward/pen_joint_powers: -0.0682
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7184
Episode_Reward/pen_flat_orientation: -0.1215
  Episode_Reward/pen_feet_distance: -0.0072
Episode_Reward/pen_feet_regulation: -0.3124
   Episode_Reward/foot_landing_vel: -0.1156
   Episode_Reward/test_gait_reward: -0.9042
Metrics/base_velocity/error_vel_xy: 1.6900
Metrics/base_velocity/error_vel_yaw: 1.0712
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 1.09s
                        Total time: 1522.78s
                               ETA: 1727.5s

################################################################################
                     [1m Learning iteration 1406/3000 [0m                     

                       Computation: 80936 steps/s (collection: 1.082s, learning 0.133s)
               Value function loss: 0.8494
                    Surrogate loss: -0.0036
             Mean action noise std: 0.6374
                     Learning rate: 0.0003
                       Mean reward: 100.81
               Mean episode length: 978.18
       Episode_Reward/keep_balance: 0.9821
     Episode_Reward/rew_lin_vel_xy: 4.8269
      Episode_Reward/rew_ang_vel_z: 2.6744
    Episode_Reward/pen_base_height: -0.3357
      Episode_Reward/pen_lin_vel_z: -0.0557
     Episode_Reward/pen_ang_vel_xy: -0.1530
   Episode_Reward/pen_joint_torque: -0.1920
    Episode_Reward/pen_joint_accel: -0.0901
    Episode_Reward/pen_action_rate: -0.3208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0425
   Episode_Reward/pen_joint_powers: -0.0690
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7322
Episode_Reward/pen_flat_orientation: -0.1200
  Episode_Reward/pen_feet_distance: -0.0044
Episode_Reward/pen_feet_regulation: -0.3285
   Episode_Reward/foot_landing_vel: -0.1113
   Episode_Reward/test_gait_reward: -0.9131
Metrics/base_velocity/error_vel_xy: 1.7095
Metrics/base_velocity/error_vel_yaw: 1.1115
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 1.21s
                        Total time: 1524.00s
                               ETA: 1726.5s

################################################################################
                     [1m Learning iteration 1407/3000 [0m                     

                       Computation: 89138 steps/s (collection: 0.977s, learning 0.126s)
               Value function loss: 0.9083
                    Surrogate loss: -0.0046
             Mean action noise std: 0.6380
                     Learning rate: 0.0006
                       Mean reward: 98.05
               Mean episode length: 975.65
       Episode_Reward/keep_balance: 0.9693
     Episode_Reward/rew_lin_vel_xy: 4.5887
      Episode_Reward/rew_ang_vel_z: 2.6821
    Episode_Reward/pen_base_height: -0.3314
      Episode_Reward/pen_lin_vel_z: -0.0580
     Episode_Reward/pen_ang_vel_xy: -0.1567
   Episode_Reward/pen_joint_torque: -0.1950
    Episode_Reward/pen_joint_accel: -0.0931
    Episode_Reward/pen_action_rate: -0.3141
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0429
   Episode_Reward/pen_joint_powers: -0.0701
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7139
Episode_Reward/pen_flat_orientation: -0.1179
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.3307
   Episode_Reward/foot_landing_vel: -0.1217
   Episode_Reward/test_gait_reward: -0.8899
Metrics/base_velocity/error_vel_xy: 1.8484
Metrics/base_velocity/error_vel_yaw: 1.0687
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 1.10s
                        Total time: 1525.10s
                               ETA: 1725.5s

################################################################################
                     [1m Learning iteration 1408/3000 [0m                     

                       Computation: 90070 steps/s (collection: 0.965s, learning 0.126s)
               Value function loss: 0.9833
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6391
                     Learning rate: 0.0003
                       Mean reward: 102.92
               Mean episode length: 987.40
       Episode_Reward/keep_balance: 0.9890
     Episode_Reward/rew_lin_vel_xy: 4.8477
      Episode_Reward/rew_ang_vel_z: 2.7666
    Episode_Reward/pen_base_height: -0.3249
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1575
   Episode_Reward/pen_joint_torque: -0.1880
    Episode_Reward/pen_joint_accel: -0.0872
    Episode_Reward/pen_action_rate: -0.3134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0422
   Episode_Reward/pen_joint_powers: -0.0679
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7249
Episode_Reward/pen_flat_orientation: -0.1207
  Episode_Reward/pen_feet_distance: -0.0058
Episode_Reward/pen_feet_regulation: -0.3150
   Episode_Reward/foot_landing_vel: -0.1142
   Episode_Reward/test_gait_reward: -0.9068
Metrics/base_velocity/error_vel_xy: 1.7312
Metrics/base_velocity/error_vel_yaw: 1.0606
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 1.09s
                        Total time: 1526.19s
                               ETA: 1724.4s

################################################################################
                     [1m Learning iteration 1409/3000 [0m                     

                       Computation: 84110 steps/s (collection: 1.041s, learning 0.127s)
               Value function loss: 0.8962
                    Surrogate loss: -0.0035
             Mean action noise std: 0.6386
                     Learning rate: 0.0004
                       Mean reward: 102.55
               Mean episode length: 995.06
       Episode_Reward/keep_balance: 0.9945
     Episode_Reward/rew_lin_vel_xy: 4.8614
      Episode_Reward/rew_ang_vel_z: 2.7479
    Episode_Reward/pen_base_height: -0.3284
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.1611
   Episode_Reward/pen_joint_torque: -0.1987
    Episode_Reward/pen_joint_accel: -0.0805
    Episode_Reward/pen_action_rate: -0.3202
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0418
   Episode_Reward/pen_joint_powers: -0.0698
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7361
Episode_Reward/pen_flat_orientation: -0.1179
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.3172
   Episode_Reward/foot_landing_vel: -0.1096
   Episode_Reward/test_gait_reward: -0.9121
Metrics/base_velocity/error_vel_xy: 1.7058
Metrics/base_velocity/error_vel_yaw: 1.0923
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 1.17s
                        Total time: 1527.36s
                               ETA: 1723.4s

################################################################################
                     [1m Learning iteration 1410/3000 [0m                     

                       Computation: 90781 steps/s (collection: 0.955s, learning 0.127s)
               Value function loss: 0.9354
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6382
                     Learning rate: 0.0003
                       Mean reward: 100.46
               Mean episode length: 972.53
       Episode_Reward/keep_balance: 0.9724
     Episode_Reward/rew_lin_vel_xy: 4.6261
      Episode_Reward/rew_ang_vel_z: 2.7385
    Episode_Reward/pen_base_height: -0.3288
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1461
   Episode_Reward/pen_joint_torque: -0.1951
    Episode_Reward/pen_joint_accel: -0.0786
    Episode_Reward/pen_action_rate: -0.3066
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0395
   Episode_Reward/pen_joint_powers: -0.0675
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6995
Episode_Reward/pen_flat_orientation: -0.1149
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.3029
   Episode_Reward/foot_landing_vel: -0.1042
   Episode_Reward/test_gait_reward: -0.8882
Metrics/base_velocity/error_vel_xy: 1.8297
Metrics/base_velocity/error_vel_yaw: 1.0412
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 1.08s
                        Total time: 1528.44s
                               ETA: 1722.3s

################################################################################
                     [1m Learning iteration 1411/3000 [0m                     

                       Computation: 90157 steps/s (collection: 0.965s, learning 0.125s)
               Value function loss: 0.8795
                    Surrogate loss: -0.0042
             Mean action noise std: 0.6387
                     Learning rate: 0.0006
                       Mean reward: 102.24
               Mean episode length: 987.08
       Episode_Reward/keep_balance: 0.9944
     Episode_Reward/rew_lin_vel_xy: 4.8028
      Episode_Reward/rew_ang_vel_z: 2.7562
    Episode_Reward/pen_base_height: -0.3348
      Episode_Reward/pen_lin_vel_z: -0.0557
     Episode_Reward/pen_ang_vel_xy: -0.1521
   Episode_Reward/pen_joint_torque: -0.1966
    Episode_Reward/pen_joint_accel: -0.0933
    Episode_Reward/pen_action_rate: -0.3194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0426
   Episode_Reward/pen_joint_powers: -0.0692
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7315
Episode_Reward/pen_flat_orientation: -0.1194
  Episode_Reward/pen_feet_distance: -0.0078
Episode_Reward/pen_feet_regulation: -0.3232
   Episode_Reward/foot_landing_vel: -0.1168
   Episode_Reward/test_gait_reward: -0.9212
Metrics/base_velocity/error_vel_xy: 1.7465
Metrics/base_velocity/error_vel_yaw: 1.0902
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 1.09s
                        Total time: 1529.53s
                               ETA: 1721.3s

################################################################################
                     [1m Learning iteration 1412/3000 [0m                     

                       Computation: 89044 steps/s (collection: 0.977s, learning 0.127s)
               Value function loss: 1.0555
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6389
                     Learning rate: 0.0002
                       Mean reward: 99.48
               Mean episode length: 979.66
       Episode_Reward/keep_balance: 0.9822
     Episode_Reward/rew_lin_vel_xy: 4.7637
      Episode_Reward/rew_ang_vel_z: 2.7066
    Episode_Reward/pen_base_height: -0.3306
      Episode_Reward/pen_lin_vel_z: -0.0576
     Episode_Reward/pen_ang_vel_xy: -0.1530
   Episode_Reward/pen_joint_torque: -0.2010
    Episode_Reward/pen_joint_accel: -0.0838
    Episode_Reward/pen_action_rate: -0.3213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0429
   Episode_Reward/pen_joint_powers: -0.0707
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7278
Episode_Reward/pen_flat_orientation: -0.1168
  Episode_Reward/pen_feet_distance: -0.0066
Episode_Reward/pen_feet_regulation: -0.3399
   Episode_Reward/foot_landing_vel: -0.1136
   Episode_Reward/test_gait_reward: -0.9123
Metrics/base_velocity/error_vel_xy: 1.7404
Metrics/base_velocity/error_vel_yaw: 1.0865
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 1.10s
                        Total time: 1530.64s
                               ETA: 1720.2s

################################################################################
                     [1m Learning iteration 1413/3000 [0m                     

                       Computation: 84830 steps/s (collection: 1.031s, learning 0.127s)
               Value function loss: 0.9628
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6387
                     Learning rate: 0.0003
                       Mean reward: 107.58
               Mean episode length: 982.14
       Episode_Reward/keep_balance: 0.9856
     Episode_Reward/rew_lin_vel_xy: 5.0252
      Episode_Reward/rew_ang_vel_z: 2.7520
    Episode_Reward/pen_base_height: -0.3241
      Episode_Reward/pen_lin_vel_z: -0.0552
     Episode_Reward/pen_ang_vel_xy: -0.1560
   Episode_Reward/pen_joint_torque: -0.1902
    Episode_Reward/pen_joint_accel: -0.0868
    Episode_Reward/pen_action_rate: -0.3139
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0416
   Episode_Reward/pen_joint_powers: -0.0683
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7202
Episode_Reward/pen_flat_orientation: -0.1138
  Episode_Reward/pen_feet_distance: -0.0049
Episode_Reward/pen_feet_regulation: -0.3096
   Episode_Reward/foot_landing_vel: -0.1162
   Episode_Reward/test_gait_reward: -0.9063
Metrics/base_velocity/error_vel_xy: 1.6309
Metrics/base_velocity/error_vel_yaw: 1.0640
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 1.16s
                        Total time: 1531.80s
                               ETA: 1719.2s

################################################################################
                     [1m Learning iteration 1414/3000 [0m                     

                       Computation: 87428 steps/s (collection: 0.999s, learning 0.125s)
               Value function loss: 0.9717
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6390
                     Learning rate: 0.0004
                       Mean reward: 104.12
               Mean episode length: 986.59
       Episode_Reward/keep_balance: 0.9904
     Episode_Reward/rew_lin_vel_xy: 4.9677
      Episode_Reward/rew_ang_vel_z: 2.7107
    Episode_Reward/pen_base_height: -0.3261
      Episode_Reward/pen_lin_vel_z: -0.0537
     Episode_Reward/pen_ang_vel_xy: -0.1565
   Episode_Reward/pen_joint_torque: -0.1881
    Episode_Reward/pen_joint_accel: -0.0913
    Episode_Reward/pen_action_rate: -0.3173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0429
   Episode_Reward/pen_joint_powers: -0.0688
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7334
Episode_Reward/pen_flat_orientation: -0.1179
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.3187
   Episode_Reward/foot_landing_vel: -0.1157
   Episode_Reward/test_gait_reward: -0.9059
Metrics/base_velocity/error_vel_xy: 1.5905
Metrics/base_velocity/error_vel_yaw: 1.1177
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 1.12s
                        Total time: 1532.92s
                               ETA: 1718.2s

################################################################################
                     [1m Learning iteration 1415/3000 [0m                     

                       Computation: 90882 steps/s (collection: 0.956s, learning 0.126s)
               Value function loss: 1.0100
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6394
                     Learning rate: 0.0002
                       Mean reward: 103.29
               Mean episode length: 988.19
       Episode_Reward/keep_balance: 0.9913
     Episode_Reward/rew_lin_vel_xy: 4.9696
      Episode_Reward/rew_ang_vel_z: 2.7351
    Episode_Reward/pen_base_height: -0.3328
      Episode_Reward/pen_lin_vel_z: -0.0557
     Episode_Reward/pen_ang_vel_xy: -0.1575
   Episode_Reward/pen_joint_torque: -0.1913
    Episode_Reward/pen_joint_accel: -0.0865
    Episode_Reward/pen_action_rate: -0.3195
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0426
   Episode_Reward/pen_joint_powers: -0.0691
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7343
Episode_Reward/pen_flat_orientation: -0.1167
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3324
   Episode_Reward/foot_landing_vel: -0.1108
   Episode_Reward/test_gait_reward: -0.9175
Metrics/base_velocity/error_vel_xy: 1.6381
Metrics/base_velocity/error_vel_yaw: 1.0982
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 1.08s
                        Total time: 1534.00s
                               ETA: 1717.1s

################################################################################
                     [1m Learning iteration 1416/3000 [0m                     

                       Computation: 87961 steps/s (collection: 0.992s, learning 0.126s)
               Value function loss: 0.9573
                    Surrogate loss: -0.0045
             Mean action noise std: 0.6394
                     Learning rate: 0.0004
                       Mean reward: 103.16
               Mean episode length: 982.63
       Episode_Reward/keep_balance: 0.9555
     Episode_Reward/rew_lin_vel_xy: 4.8072
      Episode_Reward/rew_ang_vel_z: 2.5998
    Episode_Reward/pen_base_height: -0.3222
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.1518
   Episode_Reward/pen_joint_torque: -0.1845
    Episode_Reward/pen_joint_accel: -0.0791
    Episode_Reward/pen_action_rate: -0.3092
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0419
   Episode_Reward/pen_joint_powers: -0.0672
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7167
Episode_Reward/pen_flat_orientation: -0.1184
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.3218
   Episode_Reward/foot_landing_vel: -0.1113
   Episode_Reward/test_gait_reward: -0.8831
Metrics/base_velocity/error_vel_xy: 1.5525
Metrics/base_velocity/error_vel_yaw: 1.0859
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 1.12s
                        Total time: 1535.12s
                               ETA: 1716.0s

################################################################################
                     [1m Learning iteration 1417/3000 [0m                     

                       Computation: 89626 steps/s (collection: 0.971s, learning 0.126s)
               Value function loss: 0.9823
                    Surrogate loss: -0.0029
             Mean action noise std: 0.6401
                     Learning rate: 0.0006
                       Mean reward: 92.89
               Mean episode length: 934.81
       Episode_Reward/keep_balance: 0.9371
     Episode_Reward/rew_lin_vel_xy: 4.5191
      Episode_Reward/rew_ang_vel_z: 2.5507
    Episode_Reward/pen_base_height: -0.3247
      Episode_Reward/pen_lin_vel_z: -0.0543
     Episode_Reward/pen_ang_vel_xy: -0.1482
   Episode_Reward/pen_joint_torque: -0.1874
    Episode_Reward/pen_joint_accel: -0.0892
    Episode_Reward/pen_action_rate: -0.3107
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0417
   Episode_Reward/pen_joint_powers: -0.0670
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.6991
Episode_Reward/pen_flat_orientation: -0.1173
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.3269
   Episode_Reward/foot_landing_vel: -0.1112
   Episode_Reward/test_gait_reward: -0.8643
Metrics/base_velocity/error_vel_xy: 1.5736
Metrics/base_velocity/error_vel_yaw: 1.0762
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 1.10s
                        Total time: 1536.22s
                               ETA: 1715.0s

################################################################################
                     [1m Learning iteration 1418/3000 [0m                     

                       Computation: 89123 steps/s (collection: 0.977s, learning 0.126s)
               Value function loss: 1.0162
                    Surrogate loss: -0.0040
             Mean action noise std: 0.6404
                     Learning rate: 0.0009
                       Mean reward: 99.30
               Mean episode length: 966.71
       Episode_Reward/keep_balance: 0.9638
     Episode_Reward/rew_lin_vel_xy: 4.7327
      Episode_Reward/rew_ang_vel_z: 2.6687
    Episode_Reward/pen_base_height: -0.3430
      Episode_Reward/pen_lin_vel_z: -0.0564
     Episode_Reward/pen_ang_vel_xy: -0.1576
   Episode_Reward/pen_joint_torque: -0.1897
    Episode_Reward/pen_joint_accel: -0.0861
    Episode_Reward/pen_action_rate: -0.3121
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0419
   Episode_Reward/pen_joint_powers: -0.0683
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7123
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.3236
   Episode_Reward/foot_landing_vel: -0.1101
   Episode_Reward/test_gait_reward: -0.8900
Metrics/base_velocity/error_vel_xy: 1.6549
Metrics/base_velocity/error_vel_yaw: 1.0607
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 1.10s
                        Total time: 1537.32s
                               ETA: 1713.9s

################################################################################
                     [1m Learning iteration 1419/3000 [0m                     

                       Computation: 86326 steps/s (collection: 1.007s, learning 0.132s)
               Value function loss: 0.8883
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6409
                     Learning rate: 0.0006
                       Mean reward: 104.90
               Mean episode length: 981.81
       Episode_Reward/keep_balance: 0.9827
     Episode_Reward/rew_lin_vel_xy: 5.0714
      Episode_Reward/rew_ang_vel_z: 2.7155
    Episode_Reward/pen_base_height: -0.3357
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1565
   Episode_Reward/pen_joint_torque: -0.1902
    Episode_Reward/pen_joint_accel: -0.0919
    Episode_Reward/pen_action_rate: -0.3175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0436
   Episode_Reward/pen_joint_powers: -0.0700
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7233
Episode_Reward/pen_flat_orientation: -0.1184
  Episode_Reward/pen_feet_distance: -0.0061
Episode_Reward/pen_feet_regulation: -0.3367
   Episode_Reward/foot_landing_vel: -0.1173
   Episode_Reward/test_gait_reward: -0.9130
Metrics/base_velocity/error_vel_xy: 1.5263
Metrics/base_velocity/error_vel_yaw: 1.0869
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 1.14s
                        Total time: 1538.46s
                               ETA: 1712.9s

################################################################################
                     [1m Learning iteration 1420/3000 [0m                     

                       Computation: 88017 steps/s (collection: 0.989s, learning 0.128s)
               Value function loss: 1.0458
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6415
                     Learning rate: 0.0004
                       Mean reward: 106.60
               Mean episode length: 992.71
       Episode_Reward/keep_balance: 0.9926
     Episode_Reward/rew_lin_vel_xy: 5.0631
      Episode_Reward/rew_ang_vel_z: 2.7600
    Episode_Reward/pen_base_height: -0.3358
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1592
   Episode_Reward/pen_joint_torque: -0.1986
    Episode_Reward/pen_joint_accel: -0.0894
    Episode_Reward/pen_action_rate: -0.3202
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0426
   Episode_Reward/pen_joint_powers: -0.0704
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7312
Episode_Reward/pen_flat_orientation: -0.1144
  Episode_Reward/pen_feet_distance: -0.0046
Episode_Reward/pen_feet_regulation: -0.3111
   Episode_Reward/foot_landing_vel: -0.1127
   Episode_Reward/test_gait_reward: -0.9187
Metrics/base_velocity/error_vel_xy: 1.6170
Metrics/base_velocity/error_vel_yaw: 1.0795
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 1.12s
                        Total time: 1539.58s
                               ETA: 1711.8s

################################################################################
                     [1m Learning iteration 1421/3000 [0m                     

                       Computation: 89143 steps/s (collection: 0.976s, learning 0.126s)
               Value function loss: 1.0349
                    Surrogate loss: -0.0048
             Mean action noise std: 0.6411
                     Learning rate: 0.0006
                       Mean reward: 100.00
               Mean episode length: 961.97
       Episode_Reward/keep_balance: 0.9669
     Episode_Reward/rew_lin_vel_xy: 4.6990
      Episode_Reward/rew_ang_vel_z: 2.6753
    Episode_Reward/pen_base_height: -0.3241
      Episode_Reward/pen_lin_vel_z: -0.0549
     Episode_Reward/pen_ang_vel_xy: -0.1500
   Episode_Reward/pen_joint_torque: -0.1849
    Episode_Reward/pen_joint_accel: -0.0846
    Episode_Reward/pen_action_rate: -0.3118
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0672
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7157
Episode_Reward/pen_flat_orientation: -0.1146
  Episode_Reward/pen_feet_distance: -0.0065
Episode_Reward/pen_feet_regulation: -0.3259
   Episode_Reward/foot_landing_vel: -0.1174
   Episode_Reward/test_gait_reward: -0.8873
Metrics/base_velocity/error_vel_xy: 1.6654
Metrics/base_velocity/error_vel_yaw: 1.0606
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 1.10s
                        Total time: 1540.68s
                               ETA: 1710.8s

################################################################################
                     [1m Learning iteration 1422/3000 [0m                     

                       Computation: 86647 steps/s (collection: 1.010s, learning 0.125s)
               Value function loss: 1.0046
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6422
                     Learning rate: 0.0006
                       Mean reward: 98.16
               Mean episode length: 959.00
       Episode_Reward/keep_balance: 0.9639
     Episode_Reward/rew_lin_vel_xy: 4.7295
      Episode_Reward/rew_ang_vel_z: 2.6170
    Episode_Reward/pen_base_height: -0.3412
      Episode_Reward/pen_lin_vel_z: -0.0536
     Episode_Reward/pen_ang_vel_xy: -0.1515
   Episode_Reward/pen_joint_torque: -0.1871
    Episode_Reward/pen_joint_accel: -0.0862
    Episode_Reward/pen_action_rate: -0.3116
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0421
   Episode_Reward/pen_joint_powers: -0.0678
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.7147
Episode_Reward/pen_flat_orientation: -0.1218
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.3255
   Episode_Reward/foot_landing_vel: -0.1056
   Episode_Reward/test_gait_reward: -0.8873
Metrics/base_velocity/error_vel_xy: 1.6454
Metrics/base_velocity/error_vel_yaw: 1.1076
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 1.13s
                        Total time: 1541.81s
                               ETA: 1709.8s

################################################################################
                     [1m Learning iteration 1423/3000 [0m                     

                       Computation: 91087 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.9187
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6423
                     Learning rate: 0.0004
                       Mean reward: 95.45
               Mean episode length: 947.71
       Episode_Reward/keep_balance: 0.9592
     Episode_Reward/rew_lin_vel_xy: 4.6769
      Episode_Reward/rew_ang_vel_z: 2.6126
    Episode_Reward/pen_base_height: -0.3283
      Episode_Reward/pen_lin_vel_z: -0.0525
     Episode_Reward/pen_ang_vel_xy: -0.1578
   Episode_Reward/pen_joint_torque: -0.1865
    Episode_Reward/pen_joint_accel: -0.0782
    Episode_Reward/pen_action_rate: -0.3149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0416
   Episode_Reward/pen_joint_powers: -0.0674
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7203
Episode_Reward/pen_flat_orientation: -0.1220
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.3205
   Episode_Reward/foot_landing_vel: -0.1095
   Episode_Reward/test_gait_reward: -0.8847
Metrics/base_velocity/error_vel_xy: 1.6628
Metrics/base_velocity/error_vel_yaw: 1.0888
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 1.08s
                        Total time: 1542.89s
                               ETA: 1708.7s

################################################################################
                     [1m Learning iteration 1424/3000 [0m                     

                       Computation: 89476 steps/s (collection: 0.973s, learning 0.126s)
               Value function loss: 0.9078
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6413
                     Learning rate: 0.0002
                       Mean reward: 96.78
               Mean episode length: 965.64
       Episode_Reward/keep_balance: 0.9630
     Episode_Reward/rew_lin_vel_xy: 4.7138
      Episode_Reward/rew_ang_vel_z: 2.6209
    Episode_Reward/pen_base_height: -0.3219
      Episode_Reward/pen_lin_vel_z: -0.0532
     Episode_Reward/pen_ang_vel_xy: -0.1498
   Episode_Reward/pen_joint_torque: -0.1890
    Episode_Reward/pen_joint_accel: -0.0896
    Episode_Reward/pen_action_rate: -0.3119
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0422
   Episode_Reward/pen_joint_powers: -0.0677
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7139
Episode_Reward/pen_flat_orientation: -0.1150
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3209
   Episode_Reward/foot_landing_vel: -0.1102
   Episode_Reward/test_gait_reward: -0.8860
Metrics/base_velocity/error_vel_xy: 1.6824
Metrics/base_velocity/error_vel_yaw: 1.0985
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 1.10s
                        Total time: 1543.99s
                               ETA: 1707.6s

################################################################################
                     [1m Learning iteration 1425/3000 [0m                     

                       Computation: 89376 steps/s (collection: 0.975s, learning 0.125s)
               Value function loss: 1.0629
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6414
                     Learning rate: 0.0002
                       Mean reward: 101.33
               Mean episode length: 987.28
       Episode_Reward/keep_balance: 0.9775
     Episode_Reward/rew_lin_vel_xy: 4.7426
      Episode_Reward/rew_ang_vel_z: 2.6931
    Episode_Reward/pen_base_height: -0.3419
      Episode_Reward/pen_lin_vel_z: -0.0590
     Episode_Reward/pen_ang_vel_xy: -0.1655
   Episode_Reward/pen_joint_torque: -0.1902
    Episode_Reward/pen_joint_accel: -0.0866
    Episode_Reward/pen_action_rate: -0.3179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0440
   Episode_Reward/pen_joint_powers: -0.0708
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7250
Episode_Reward/pen_flat_orientation: -0.1192
  Episode_Reward/pen_feet_distance: -0.0087
Episode_Reward/pen_feet_regulation: -0.3386
   Episode_Reward/foot_landing_vel: -0.1218
   Episode_Reward/test_gait_reward: -0.9046
Metrics/base_velocity/error_vel_xy: 1.7400
Metrics/base_velocity/error_vel_yaw: 1.0798
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 1.10s
                        Total time: 1545.09s
                               ETA: 1706.5s

################################################################################
                     [1m Learning iteration 1426/3000 [0m                     

                       Computation: 86889 steps/s (collection: 1.004s, learning 0.128s)
               Value function loss: 0.9952
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6412
                     Learning rate: 0.0000
                       Mean reward: 101.55
               Mean episode length: 988.94
       Episode_Reward/keep_balance: 0.9778
     Episode_Reward/rew_lin_vel_xy: 4.9188
      Episode_Reward/rew_ang_vel_z: 2.6637
    Episode_Reward/pen_base_height: -0.3196
      Episode_Reward/pen_lin_vel_z: -0.0540
     Episode_Reward/pen_ang_vel_xy: -0.1574
   Episode_Reward/pen_joint_torque: -0.1915
    Episode_Reward/pen_joint_accel: -0.0889
    Episode_Reward/pen_action_rate: -0.3191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0432
   Episode_Reward/pen_joint_powers: -0.0696
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7312
Episode_Reward/pen_flat_orientation: -0.1186
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3305
   Episode_Reward/foot_landing_vel: -0.1146
   Episode_Reward/test_gait_reward: -0.8976
Metrics/base_velocity/error_vel_xy: 1.5901
Metrics/base_velocity/error_vel_yaw: 1.1193
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 1.13s
                        Total time: 1546.22s
                               ETA: 1705.5s

################################################################################
                     [1m Learning iteration 1427/3000 [0m                     

                       Computation: 85485 steps/s (collection: 1.027s, learning 0.123s)
               Value function loss: 1.2712
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6411
                     Learning rate: 0.0000
                       Mean reward: 101.73
               Mean episode length: 966.49
       Episode_Reward/keep_balance: 0.9802
     Episode_Reward/rew_lin_vel_xy: 5.0625
      Episode_Reward/rew_ang_vel_z: 2.7289
    Episode_Reward/pen_base_height: -0.3299
      Episode_Reward/pen_lin_vel_z: -0.0550
     Episode_Reward/pen_ang_vel_xy: -0.1549
   Episode_Reward/pen_joint_torque: -0.2000
    Episode_Reward/pen_joint_accel: -0.0863
    Episode_Reward/pen_action_rate: -0.3364
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0422
   Episode_Reward/pen_joint_powers: -0.0700
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7223
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0048
Episode_Reward/pen_feet_regulation: -0.3240
   Episode_Reward/foot_landing_vel: -0.1076
   Episode_Reward/test_gait_reward: -0.9028
Metrics/base_velocity/error_vel_xy: 1.5385
Metrics/base_velocity/error_vel_yaw: 1.0712
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 1.15s
                        Total time: 1547.37s
                               ETA: 1704.5s

################################################################################
                     [1m Learning iteration 1428/3000 [0m                     

                       Computation: 88926 steps/s (collection: 0.980s, learning 0.125s)
               Value function loss: 1.6535
                    Surrogate loss: 0.0027
             Mean action noise std: 0.6410
                     Learning rate: 0.0001
                       Mean reward: 104.18
               Mean episode length: 981.43
       Episode_Reward/keep_balance: 0.9809
     Episode_Reward/rew_lin_vel_xy: 4.6659
      Episode_Reward/rew_ang_vel_z: 2.7159
    Episode_Reward/pen_base_height: -0.3333
      Episode_Reward/pen_lin_vel_z: -0.0573
     Episode_Reward/pen_ang_vel_xy: -0.1508
   Episode_Reward/pen_joint_torque: -0.1975
    Episode_Reward/pen_joint_accel: -0.0793
    Episode_Reward/pen_action_rate: -0.3155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0427
   Episode_Reward/pen_joint_powers: -0.0706
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7232
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0086
Episode_Reward/pen_feet_regulation: -0.3409
   Episode_Reward/foot_landing_vel: -0.1163
   Episode_Reward/test_gait_reward: -0.9078
Metrics/base_velocity/error_vel_xy: 1.7670
Metrics/base_velocity/error_vel_yaw: 1.0769
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 1.11s
                        Total time: 1548.48s
                               ETA: 1703.4s

################################################################################
                     [1m Learning iteration 1429/3000 [0m                     

                       Computation: 89725 steps/s (collection: 0.970s, learning 0.126s)
               Value function loss: 1.2287
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6411
                     Learning rate: 0.0004
                       Mean reward: 86.21
               Mean episode length: 877.51
       Episode_Reward/keep_balance: 0.8985
     Episode_Reward/rew_lin_vel_xy: 4.4687
      Episode_Reward/rew_ang_vel_z: 2.4679
    Episode_Reward/pen_base_height: -0.3386
      Episode_Reward/pen_lin_vel_z: -0.0572
     Episode_Reward/pen_ang_vel_xy: -0.1592
   Episode_Reward/pen_joint_torque: -0.1896
    Episode_Reward/pen_joint_accel: -0.0785
    Episode_Reward/pen_action_rate: -0.3008
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0424
   Episode_Reward/pen_joint_powers: -0.0683
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.6750
Episode_Reward/pen_flat_orientation: -0.1310
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.3296
   Episode_Reward/foot_landing_vel: -0.1137
   Episode_Reward/test_gait_reward: -0.8284
Metrics/base_velocity/error_vel_xy: 1.5207
Metrics/base_velocity/error_vel_yaw: 1.0132
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 1.10s
                        Total time: 1549.57s
                               ETA: 1702.4s

################################################################################
                     [1m Learning iteration 1430/3000 [0m                     

                       Computation: 83116 steps/s (collection: 1.057s, learning 0.125s)
               Value function loss: 1.1921
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6412
                     Learning rate: 0.0000
                       Mean reward: 95.52
               Mean episode length: 950.27
       Episode_Reward/keep_balance: 0.9545
     Episode_Reward/rew_lin_vel_xy: 4.7617
      Episode_Reward/rew_ang_vel_z: 2.5807
    Episode_Reward/pen_base_height: -0.3345
      Episode_Reward/pen_lin_vel_z: -0.0566
     Episode_Reward/pen_ang_vel_xy: -0.1583
   Episode_Reward/pen_joint_torque: -0.1886
    Episode_Reward/pen_joint_accel: -0.0830
    Episode_Reward/pen_action_rate: -0.3167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0430
   Episode_Reward/pen_joint_powers: -0.0686
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.7122
Episode_Reward/pen_flat_orientation: -0.1289
  Episode_Reward/pen_feet_distance: -0.0094
Episode_Reward/pen_feet_regulation: -0.3289
   Episode_Reward/foot_landing_vel: -0.1138
   Episode_Reward/test_gait_reward: -0.8890
Metrics/base_velocity/error_vel_xy: 1.5937
Metrics/base_velocity/error_vel_yaw: 1.1149
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 1.18s
                        Total time: 1550.76s
                               ETA: 1701.4s

################################################################################
                     [1m Learning iteration 1431/3000 [0m                     

                       Computation: 92071 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.8593
                    Surrogate loss: -0.0038
             Mean action noise std: 0.6410
                     Learning rate: 0.0001
                       Mean reward: 95.63
               Mean episode length: 933.90
       Episode_Reward/keep_balance: 0.9261
     Episode_Reward/rew_lin_vel_xy: 4.5909
      Episode_Reward/rew_ang_vel_z: 2.5354
    Episode_Reward/pen_base_height: -0.3375
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1565
   Episode_Reward/pen_joint_torque: -0.1853
    Episode_Reward/pen_joint_accel: -0.0836
    Episode_Reward/pen_action_rate: -0.3093
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0435
   Episode_Reward/pen_joint_powers: -0.0690
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.6995
Episode_Reward/pen_flat_orientation: -0.1332
  Episode_Reward/pen_feet_distance: -0.0104
Episode_Reward/pen_feet_regulation: -0.3337
   Episode_Reward/foot_landing_vel: -0.1133
   Episode_Reward/test_gait_reward: -0.8570
Metrics/base_velocity/error_vel_xy: 1.5862
Metrics/base_velocity/error_vel_yaw: 1.0588
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 1.07s
                        Total time: 1551.82s
                               ETA: 1700.3s

################################################################################
                     [1m Learning iteration 1432/3000 [0m                     

                       Computation: 94477 steps/s (collection: 0.916s, learning 0.124s)
               Value function loss: 1.0005
                    Surrogate loss: -0.0038
             Mean action noise std: 0.6401
                     Learning rate: 0.0003
                       Mean reward: 96.70
               Mean episode length: 971.13
       Episode_Reward/keep_balance: 0.9864
     Episode_Reward/rew_lin_vel_xy: 4.9158
      Episode_Reward/rew_ang_vel_z: 2.7391
    Episode_Reward/pen_base_height: -0.3543
      Episode_Reward/pen_lin_vel_z: -0.0578
     Episode_Reward/pen_ang_vel_xy: -0.1604
   Episode_Reward/pen_joint_torque: -0.1914
    Episode_Reward/pen_joint_accel: -0.0834
    Episode_Reward/pen_action_rate: -0.3237
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0438
   Episode_Reward/pen_joint_powers: -0.0704
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7368
Episode_Reward/pen_flat_orientation: -0.1241
  Episode_Reward/pen_feet_distance: -0.0087
Episode_Reward/pen_feet_regulation: -0.3522
   Episode_Reward/foot_landing_vel: -0.1208
   Episode_Reward/test_gait_reward: -0.9142
Metrics/base_velocity/error_vel_xy: 1.6166
Metrics/base_velocity/error_vel_yaw: 1.0873
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 1.04s
                        Total time: 1552.86s
                               ETA: 1699.2s

################################################################################
                     [1m Learning iteration 1433/3000 [0m                     

                       Computation: 90519 steps/s (collection: 0.961s, learning 0.125s)
               Value function loss: 0.9465
                    Surrogate loss: -0.0038
             Mean action noise std: 0.6394
                     Learning rate: 0.0006
                       Mean reward: 99.06
               Mean episode length: 969.24
       Episode_Reward/keep_balance: 0.9651
     Episode_Reward/rew_lin_vel_xy: 4.7393
      Episode_Reward/rew_ang_vel_z: 2.6230
    Episode_Reward/pen_base_height: -0.3368
      Episode_Reward/pen_lin_vel_z: -0.0568
     Episode_Reward/pen_ang_vel_xy: -0.1596
   Episode_Reward/pen_joint_torque: -0.1968
    Episode_Reward/pen_joint_accel: -0.0840
    Episode_Reward/pen_action_rate: -0.3216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0436
   Episode_Reward/pen_joint_powers: -0.0708
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7282
Episode_Reward/pen_flat_orientation: -0.1245
  Episode_Reward/pen_feet_distance: -0.0077
Episode_Reward/pen_feet_regulation: -0.3275
   Episode_Reward/foot_landing_vel: -0.1187
   Episode_Reward/test_gait_reward: -0.8928
Metrics/base_velocity/error_vel_xy: 1.6867
Metrics/base_velocity/error_vel_yaw: 1.1162
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 1.09s
                        Total time: 1553.95s
                               ETA: 1698.1s

################################################################################
                     [1m Learning iteration 1434/3000 [0m                     

                       Computation: 90396 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.8311
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6396
                     Learning rate: 0.0006
                       Mean reward: 99.01
               Mean episode length: 969.39
       Episode_Reward/keep_balance: 0.9817
     Episode_Reward/rew_lin_vel_xy: 4.7912
      Episode_Reward/rew_ang_vel_z: 2.7064
    Episode_Reward/pen_base_height: -0.3327
      Episode_Reward/pen_lin_vel_z: -0.0555
     Episode_Reward/pen_ang_vel_xy: -0.1520
   Episode_Reward/pen_joint_torque: -0.1957
    Episode_Reward/pen_joint_accel: -0.0874
    Episode_Reward/pen_action_rate: -0.3201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0424
   Episode_Reward/pen_joint_powers: -0.0694
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7334
Episode_Reward/pen_flat_orientation: -0.1179
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.3249
   Episode_Reward/foot_landing_vel: -0.1176
   Episode_Reward/test_gait_reward: -0.9010
Metrics/base_velocity/error_vel_xy: 1.7211
Metrics/base_velocity/error_vel_yaw: 1.0925
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 1.09s
                        Total time: 1555.04s
                               ETA: 1697.0s

################################################################################
                     [1m Learning iteration 1435/3000 [0m                     

                       Computation: 94473 steps/s (collection: 0.918s, learning 0.122s)
               Value function loss: 0.9365
                    Surrogate loss: -0.0031
             Mean action noise std: 0.6401
                     Learning rate: 0.0009
                       Mean reward: 100.48
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 4.8337
      Episode_Reward/rew_ang_vel_z: 2.7355
    Episode_Reward/pen_base_height: -0.3418
      Episode_Reward/pen_lin_vel_z: -0.0583
     Episode_Reward/pen_ang_vel_xy: -0.1572
   Episode_Reward/pen_joint_torque: -0.2014
    Episode_Reward/pen_joint_accel: -0.0791
    Episode_Reward/pen_action_rate: -0.3293
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0444
   Episode_Reward/pen_joint_powers: -0.0718
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7476
Episode_Reward/pen_flat_orientation: -0.1160
  Episode_Reward/pen_feet_distance: -0.0088
Episode_Reward/pen_feet_regulation: -0.3483
   Episode_Reward/foot_landing_vel: -0.1227
   Episode_Reward/test_gait_reward: -0.9297
Metrics/base_velocity/error_vel_xy: 1.7020
Metrics/base_velocity/error_vel_yaw: 1.1231
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 1.04s
                        Total time: 1556.08s
                               ETA: 1695.9s

################################################################################
                     [1m Learning iteration 1436/3000 [0m                     

                       Computation: 92302 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.9468
                    Surrogate loss: -0.0036
             Mean action noise std: 0.6403
                     Learning rate: 0.0013
                       Mean reward: 99.88
               Mean episode length: 987.18
       Episode_Reward/keep_balance: 0.9880
     Episode_Reward/rew_lin_vel_xy: 4.8082
      Episode_Reward/rew_ang_vel_z: 2.7139
    Episode_Reward/pen_base_height: -0.3424
      Episode_Reward/pen_lin_vel_z: -0.0577
     Episode_Reward/pen_ang_vel_xy: -0.1665
   Episode_Reward/pen_joint_torque: -0.1956
    Episode_Reward/pen_joint_accel: -0.0972
    Episode_Reward/pen_action_rate: -0.3295
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0449
   Episode_Reward/pen_joint_powers: -0.0713
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7499
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0082
Episode_Reward/pen_feet_regulation: -0.3452
   Episode_Reward/foot_landing_vel: -0.1240
   Episode_Reward/test_gait_reward: -0.9153
Metrics/base_velocity/error_vel_xy: 1.7177
Metrics/base_velocity/error_vel_yaw: 1.1076
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 1.07s
                        Total time: 1557.14s
                               ETA: 1694.8s

################################################################################
                     [1m Learning iteration 1437/3000 [0m                     

                       Computation: 89190 steps/s (collection: 0.977s, learning 0.125s)
               Value function loss: 1.0383
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6404
                     Learning rate: 0.0013
                       Mean reward: 101.23
               Mean episode length: 977.18
       Episode_Reward/keep_balance: 0.9784
     Episode_Reward/rew_lin_vel_xy: 4.9125
      Episode_Reward/rew_ang_vel_z: 2.6890
    Episode_Reward/pen_base_height: -0.3293
      Episode_Reward/pen_lin_vel_z: -0.0574
     Episode_Reward/pen_ang_vel_xy: -0.1582
   Episode_Reward/pen_joint_torque: -0.1907
    Episode_Reward/pen_joint_accel: -0.0945
    Episode_Reward/pen_action_rate: -0.3242
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0448
   Episode_Reward/pen_joint_powers: -0.0702
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7400
Episode_Reward/pen_flat_orientation: -0.1184
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.3498
   Episode_Reward/foot_landing_vel: -0.1201
   Episode_Reward/test_gait_reward: -0.9062
Metrics/base_velocity/error_vel_xy: 1.5702
Metrics/base_velocity/error_vel_yaw: 1.0885
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 1.10s
                        Total time: 1558.24s
                               ETA: 1693.7s

################################################################################
                     [1m Learning iteration 1438/3000 [0m                     

                       Computation: 90695 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.9716
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6410
                     Learning rate: 0.0019
                       Mean reward: 101.57
               Mean episode length: 988.75
       Episode_Reward/keep_balance: 0.9888
     Episode_Reward/rew_lin_vel_xy: 4.9379
      Episode_Reward/rew_ang_vel_z: 2.7290
    Episode_Reward/pen_base_height: -0.3478
      Episode_Reward/pen_lin_vel_z: -0.0577
     Episode_Reward/pen_ang_vel_xy: -0.1640
   Episode_Reward/pen_joint_torque: -0.1971
    Episode_Reward/pen_joint_accel: -0.0894
    Episode_Reward/pen_action_rate: -0.3293
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0451
   Episode_Reward/pen_joint_powers: -0.0714
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7454
Episode_Reward/pen_flat_orientation: -0.1232
  Episode_Reward/pen_feet_distance: -0.0113
Episode_Reward/pen_feet_regulation: -0.3445
   Episode_Reward/foot_landing_vel: -0.1242
   Episode_Reward/test_gait_reward: -0.9162
Metrics/base_velocity/error_vel_xy: 1.6648
Metrics/base_velocity/error_vel_yaw: 1.0905
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 1.08s
                        Total time: 1559.33s
                               ETA: 1692.6s

################################################################################
                     [1m Learning iteration 1439/3000 [0m                     

                       Computation: 90309 steps/s (collection: 0.962s, learning 0.126s)
               Value function loss: 1.0867
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6417
                     Learning rate: 0.0019
                       Mean reward: 101.41
               Mean episode length: 985.45
       Episode_Reward/keep_balance: 0.9844
     Episode_Reward/rew_lin_vel_xy: 5.0220
      Episode_Reward/rew_ang_vel_z: 2.7264
    Episode_Reward/pen_base_height: -0.3539
      Episode_Reward/pen_lin_vel_z: -0.0579
     Episode_Reward/pen_ang_vel_xy: -0.1581
   Episode_Reward/pen_joint_torque: -0.2000
    Episode_Reward/pen_joint_accel: -0.0931
    Episode_Reward/pen_action_rate: -0.3285
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0445
   Episode_Reward/pen_joint_powers: -0.0722
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7385
Episode_Reward/pen_flat_orientation: -0.1236
  Episode_Reward/pen_feet_distance: -0.0104
Episode_Reward/pen_feet_regulation: -0.3568
   Episode_Reward/foot_landing_vel: -0.1194
   Episode_Reward/test_gait_reward: -0.9161
Metrics/base_velocity/error_vel_xy: 1.5961
Metrics/base_velocity/error_vel_yaw: 1.0857
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 1.09s
                        Total time: 1560.42s
                               ETA: 1691.5s

################################################################################
                     [1m Learning iteration 1440/3000 [0m                     

                       Computation: 91064 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 1.0299
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6414
                     Learning rate: 0.0013
                       Mean reward: 97.65
               Mean episode length: 956.56
       Episode_Reward/keep_balance: 0.9634
     Episode_Reward/rew_lin_vel_xy: 4.9004
      Episode_Reward/rew_ang_vel_z: 2.6347
    Episode_Reward/pen_base_height: -0.3413
      Episode_Reward/pen_lin_vel_z: -0.0525
     Episode_Reward/pen_ang_vel_xy: -0.1541
   Episode_Reward/pen_joint_torque: -0.1898
    Episode_Reward/pen_joint_accel: -0.0861
    Episode_Reward/pen_action_rate: -0.3201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0424
   Episode_Reward/pen_joint_powers: -0.0680
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7291
Episode_Reward/pen_flat_orientation: -0.1114
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.3291
   Episode_Reward/foot_landing_vel: -0.1160
   Episode_Reward/test_gait_reward: -0.8939
Metrics/base_velocity/error_vel_xy: 1.5249
Metrics/base_velocity/error_vel_yaw: 1.0856
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 1.08s
                        Total time: 1561.50s
                               ETA: 1690.4s

################################################################################
                     [1m Learning iteration 1441/3000 [0m                     

                       Computation: 91482 steps/s (collection: 0.949s, learning 0.126s)
               Value function loss: 0.9630
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6414
                     Learning rate: 0.0003
                       Mean reward: 99.79
               Mean episode length: 972.70
       Episode_Reward/keep_balance: 0.9723
     Episode_Reward/rew_lin_vel_xy: 4.8154
      Episode_Reward/rew_ang_vel_z: 2.7138
    Episode_Reward/pen_base_height: -0.3362
      Episode_Reward/pen_lin_vel_z: -0.0587
     Episode_Reward/pen_ang_vel_xy: -0.1575
   Episode_Reward/pen_joint_torque: -0.1993
    Episode_Reward/pen_joint_accel: -0.0883
    Episode_Reward/pen_action_rate: -0.3224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0433
   Episode_Reward/pen_joint_powers: -0.0710
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7314
Episode_Reward/pen_flat_orientation: -0.1166
  Episode_Reward/pen_feet_distance: -0.0108
Episode_Reward/pen_feet_regulation: -0.3388
   Episode_Reward/foot_landing_vel: -0.1174
   Episode_Reward/test_gait_reward: -0.9057
Metrics/base_velocity/error_vel_xy: 1.6924
Metrics/base_velocity/error_vel_yaw: 1.0572
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 1.07s
                        Total time: 1562.57s
                               ETA: 1689.4s

################################################################################
                     [1m Learning iteration 1442/3000 [0m                     

                       Computation: 90370 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.9834
                    Surrogate loss: -0.0035
             Mean action noise std: 0.6414
                     Learning rate: 0.0006
                       Mean reward: 98.39
               Mean episode length: 991.44
       Episode_Reward/keep_balance: 0.9912
     Episode_Reward/rew_lin_vel_xy: 4.8353
      Episode_Reward/rew_ang_vel_z: 2.7264
    Episode_Reward/pen_base_height: -0.3461
      Episode_Reward/pen_lin_vel_z: -0.0583
     Episode_Reward/pen_ang_vel_xy: -0.1598
   Episode_Reward/pen_joint_torque: -0.1967
    Episode_Reward/pen_joint_accel: -0.0857
    Episode_Reward/pen_action_rate: -0.3252
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0443
   Episode_Reward/pen_joint_powers: -0.0716
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7437
Episode_Reward/pen_flat_orientation: -0.1219
  Episode_Reward/pen_feet_distance: -0.0122
Episode_Reward/pen_feet_regulation: -0.3524
   Episode_Reward/foot_landing_vel: -0.1183
   Episode_Reward/test_gait_reward: -0.9210
Metrics/base_velocity/error_vel_xy: 1.7501
Metrics/base_velocity/error_vel_yaw: 1.1002
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 1.09s
                        Total time: 1563.66s
                               ETA: 1688.3s

################################################################################
                     [1m Learning iteration 1443/3000 [0m                     

                       Computation: 89571 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 1.0260
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6415
                     Learning rate: 0.0013
                       Mean reward: 97.73
               Mean episode length: 982.63
       Episode_Reward/keep_balance: 0.9906
     Episode_Reward/rew_lin_vel_xy: 4.8379
      Episode_Reward/rew_ang_vel_z: 2.7122
    Episode_Reward/pen_base_height: -0.3350
      Episode_Reward/pen_lin_vel_z: -0.0580
     Episode_Reward/pen_ang_vel_xy: -0.1670
   Episode_Reward/pen_joint_torque: -0.1935
    Episode_Reward/pen_joint_accel: -0.0965
    Episode_Reward/pen_action_rate: -0.3311
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0460
   Episode_Reward/pen_joint_powers: -0.0718
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7509
Episode_Reward/pen_flat_orientation: -0.1193
  Episode_Reward/pen_feet_distance: -0.0113
Episode_Reward/pen_feet_regulation: -0.3512
   Episode_Reward/foot_landing_vel: -0.1300
   Episode_Reward/test_gait_reward: -0.9192
Metrics/base_velocity/error_vel_xy: 1.7164
Metrics/base_velocity/error_vel_yaw: 1.1129
      Episode_Termination/time_out: 5.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 1.10s
                        Total time: 1564.76s
                               ETA: 1687.2s

################################################################################
                     [1m Learning iteration 1444/3000 [0m                     

                       Computation: 89259 steps/s (collection: 0.977s, learning 0.124s)
               Value function loss: 0.9188
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6414
                     Learning rate: 0.0000
                       Mean reward: 98.44
               Mean episode length: 969.47
       Episode_Reward/keep_balance: 0.9770
     Episode_Reward/rew_lin_vel_xy: 4.8440
      Episode_Reward/rew_ang_vel_z: 2.6730
    Episode_Reward/pen_base_height: -0.3626
      Episode_Reward/pen_lin_vel_z: -0.0593
     Episode_Reward/pen_ang_vel_xy: -0.1602
   Episode_Reward/pen_joint_torque: -0.2005
    Episode_Reward/pen_joint_accel: -0.0871
    Episode_Reward/pen_action_rate: -0.3288
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0449
   Episode_Reward/pen_joint_powers: -0.0715
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7408
Episode_Reward/pen_flat_orientation: -0.1247
  Episode_Reward/pen_feet_distance: -0.0147
Episode_Reward/pen_feet_regulation: -0.3491
   Episode_Reward/foot_landing_vel: -0.1196
   Episode_Reward/test_gait_reward: -0.9124
Metrics/base_velocity/error_vel_xy: 1.6985
Metrics/base_velocity/error_vel_yaw: 1.1058
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 1.10s
                        Total time: 1565.86s
                               ETA: 1686.1s

################################################################################
                     [1m Learning iteration 1445/3000 [0m                     

                       Computation: 89850 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 1.0205
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6412
                     Learning rate: 0.0003
                       Mean reward: 101.39
               Mean episode length: 975.80
       Episode_Reward/keep_balance: 0.9816
     Episode_Reward/rew_lin_vel_xy: 4.9687
      Episode_Reward/rew_ang_vel_z: 2.7351
    Episode_Reward/pen_base_height: -0.3324
      Episode_Reward/pen_lin_vel_z: -0.0578
     Episode_Reward/pen_ang_vel_xy: -0.1575
   Episode_Reward/pen_joint_torque: -0.2034
    Episode_Reward/pen_joint_accel: -0.0880
    Episode_Reward/pen_action_rate: -0.3226
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0432
   Episode_Reward/pen_joint_powers: -0.0707
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7347
Episode_Reward/pen_flat_orientation: -0.1140
  Episode_Reward/pen_feet_distance: -0.0094
Episode_Reward/pen_feet_regulation: -0.3316
   Episode_Reward/foot_landing_vel: -0.1191
   Episode_Reward/test_gait_reward: -0.9110
Metrics/base_velocity/error_vel_xy: 1.6284
Metrics/base_velocity/error_vel_yaw: 1.0613
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 1.09s
                        Total time: 1566.95s
                               ETA: 1685.1s

################################################################################
                     [1m Learning iteration 1446/3000 [0m                     

                       Computation: 93304 steps/s (collection: 0.928s, learning 0.126s)
               Value function loss: 0.9456
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6407
                     Learning rate: 0.0006
                       Mean reward: 102.89
               Mean episode length: 963.36
       Episode_Reward/keep_balance: 0.9747
     Episode_Reward/rew_lin_vel_xy: 5.0111
      Episode_Reward/rew_ang_vel_z: 2.6843
    Episode_Reward/pen_base_height: -0.3244
      Episode_Reward/pen_lin_vel_z: -0.0507
     Episode_Reward/pen_ang_vel_xy: -0.1569
   Episode_Reward/pen_joint_torque: -0.1876
    Episode_Reward/pen_joint_accel: -0.0887
    Episode_Reward/pen_action_rate: -0.3211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0420
   Episode_Reward/pen_joint_powers: -0.0681
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7326
Episode_Reward/pen_flat_orientation: -0.1075
  Episode_Reward/pen_feet_distance: -0.0093
Episode_Reward/pen_feet_regulation: -0.3076
   Episode_Reward/foot_landing_vel: -0.1112
   Episode_Reward/test_gait_reward: -0.8971
Metrics/base_velocity/error_vel_xy: 1.5183
Metrics/base_velocity/error_vel_yaw: 1.0811
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 1.05s
                        Total time: 1568.01s
                               ETA: 1684.0s

################################################################################
                     [1m Learning iteration 1447/3000 [0m                     

                       Computation: 93576 steps/s (collection: 0.927s, learning 0.123s)
               Value function loss: 0.9686
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6406
                     Learning rate: 0.0002
                       Mean reward: 100.59
               Mean episode length: 989.73
       Episode_Reward/keep_balance: 0.9865
     Episode_Reward/rew_lin_vel_xy: 4.9411
      Episode_Reward/rew_ang_vel_z: 2.7300
    Episode_Reward/pen_base_height: -0.3324
      Episode_Reward/pen_lin_vel_z: -0.0569
     Episode_Reward/pen_ang_vel_xy: -0.1517
   Episode_Reward/pen_joint_torque: -0.1939
    Episode_Reward/pen_joint_accel: -0.0963
    Episode_Reward/pen_action_rate: -0.3246
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0437
   Episode_Reward/pen_joint_powers: -0.0700
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7421
Episode_Reward/pen_flat_orientation: -0.1140
  Episode_Reward/pen_feet_distance: -0.0116
Episode_Reward/pen_feet_regulation: -0.3410
   Episode_Reward/foot_landing_vel: -0.1264
   Episode_Reward/test_gait_reward: -0.9100
Metrics/base_velocity/error_vel_xy: 1.6376
Metrics/base_velocity/error_vel_yaw: 1.0827
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 1.05s
                        Total time: 1569.06s
                               ETA: 1682.8s

################################################################################
                     [1m Learning iteration 1448/3000 [0m                     

                       Computation: 90239 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.9179
                    Surrogate loss: -0.0035
             Mean action noise std: 0.6410
                     Learning rate: 0.0004
                       Mean reward: 102.19
               Mean episode length: 985.36
       Episode_Reward/keep_balance: 0.9781
     Episode_Reward/rew_lin_vel_xy: 4.9526
      Episode_Reward/rew_ang_vel_z: 2.6614
    Episode_Reward/pen_base_height: -0.3540
      Episode_Reward/pen_lin_vel_z: -0.0580
     Episode_Reward/pen_ang_vel_xy: -0.1575
   Episode_Reward/pen_joint_torque: -0.2002
    Episode_Reward/pen_joint_accel: -0.0875
    Episode_Reward/pen_action_rate: -0.3335
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0445
   Episode_Reward/pen_joint_powers: -0.0718
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7425
Episode_Reward/pen_flat_orientation: -0.1203
  Episode_Reward/pen_feet_distance: -0.0106
Episode_Reward/pen_feet_regulation: -0.3534
   Episode_Reward/foot_landing_vel: -0.1200
   Episode_Reward/test_gait_reward: -0.9166
Metrics/base_velocity/error_vel_xy: 1.6119
Metrics/base_velocity/error_vel_yaw: 1.1256
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 1.09s
                        Total time: 1570.15s
                               ETA: 1681.8s

################################################################################
                     [1m Learning iteration 1449/3000 [0m                     

                       Computation: 89433 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.9089
                    Surrogate loss: -0.0034
             Mean action noise std: 0.6400
                     Learning rate: 0.0006
                       Mean reward: 100.23
               Mean episode length: 986.91
       Episode_Reward/keep_balance: 0.9904
     Episode_Reward/rew_lin_vel_xy: 4.9597
      Episode_Reward/rew_ang_vel_z: 2.7077
    Episode_Reward/pen_base_height: -0.3469
      Episode_Reward/pen_lin_vel_z: -0.0594
     Episode_Reward/pen_ang_vel_xy: -0.1629
   Episode_Reward/pen_joint_torque: -0.1958
    Episode_Reward/pen_joint_accel: -0.0965
    Episode_Reward/pen_action_rate: -0.3294
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0456
   Episode_Reward/pen_joint_powers: -0.0713
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7495
Episode_Reward/pen_flat_orientation: -0.1250
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.3472
   Episode_Reward/foot_landing_vel: -0.1349
   Episode_Reward/test_gait_reward: -0.9161
Metrics/base_velocity/error_vel_xy: 1.6448
Metrics/base_velocity/error_vel_yaw: 1.1228
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 1.10s
                        Total time: 1571.24s
                               ETA: 1680.7s

################################################################################
                     [1m Learning iteration 1450/3000 [0m                     

                       Computation: 91465 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.9262
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6395
                     Learning rate: 0.0009
                       Mean reward: 97.92
               Mean episode length: 989.03
       Episode_Reward/keep_balance: 0.9912
     Episode_Reward/rew_lin_vel_xy: 4.7856
      Episode_Reward/rew_ang_vel_z: 2.7404
    Episode_Reward/pen_base_height: -0.3360
      Episode_Reward/pen_lin_vel_z: -0.0565
     Episode_Reward/pen_ang_vel_xy: -0.1620
   Episode_Reward/pen_joint_torque: -0.1983
    Episode_Reward/pen_joint_accel: -0.0867
    Episode_Reward/pen_action_rate: -0.3309
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0456
   Episode_Reward/pen_joint_powers: -0.0723
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7481
Episode_Reward/pen_flat_orientation: -0.1170
  Episode_Reward/pen_feet_distance: -0.0119
Episode_Reward/pen_feet_regulation: -0.3610
   Episode_Reward/foot_landing_vel: -0.1244
   Episode_Reward/test_gait_reward: -0.9189
Metrics/base_velocity/error_vel_xy: 1.7024
Metrics/base_velocity/error_vel_yaw: 1.0924
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 1.07s
                        Total time: 1572.32s
                               ETA: 1679.6s

################################################################################
                     [1m Learning iteration 1451/3000 [0m                     

                       Computation: 91440 steps/s (collection: 0.951s, learning 0.124s)
               Value function loss: 25.7046
                    Surrogate loss: 0.0024
             Mean action noise std: 0.6400
                     Learning rate: 0.0000
                       Mean reward: 96.73
               Mean episode length: 968.98
       Episode_Reward/keep_balance: 0.9725
     Episode_Reward/rew_lin_vel_xy: 4.8191
      Episode_Reward/rew_ang_vel_z: 2.6922
    Episode_Reward/pen_base_height: -0.3558
      Episode_Reward/pen_lin_vel_z: -0.0584
     Episode_Reward/pen_ang_vel_xy: -0.1570
   Episode_Reward/pen_joint_torque: -0.2085
    Episode_Reward/pen_joint_accel: -0.0882
    Episode_Reward/pen_action_rate: -0.3304
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0452
   Episode_Reward/pen_joint_powers: -0.0735
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7353
Episode_Reward/pen_flat_orientation: -0.1191
  Episode_Reward/pen_feet_distance: -0.0109
Episode_Reward/pen_feet_regulation: -0.3709
   Episode_Reward/foot_landing_vel: -0.1254
   Episode_Reward/test_gait_reward: -0.9080
Metrics/base_velocity/error_vel_xy: 1.6804
Metrics/base_velocity/error_vel_yaw: 1.0695
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 1.08s
                        Total time: 1573.39s
                               ETA: 1678.5s

################################################################################
                     [1m Learning iteration 1452/3000 [0m                     

                       Computation: 90961 steps/s (collection: 0.953s, learning 0.128s)
               Value function loss: 2141311.0125
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6403
                     Learning rate: 0.0000
                       Mean reward: 101.80
               Mean episode length: 962.91
       Episode_Reward/keep_balance: 0.9737
     Episode_Reward/rew_lin_vel_xy: 5.1032
      Episode_Reward/rew_ang_vel_z: 2.7138
    Episode_Reward/pen_base_height: -0.3399
      Episode_Reward/pen_lin_vel_z: -0.0573
     Episode_Reward/pen_ang_vel_xy: -0.1516
   Episode_Reward/pen_joint_torque: -0.1974
    Episode_Reward/pen_joint_accel: -0.0884
    Episode_Reward/pen_action_rate: -0.3191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0431
   Episode_Reward/pen_joint_powers: -0.0707
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7261
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0085
Episode_Reward/pen_feet_regulation: -0.3439
   Episode_Reward/foot_landing_vel: -0.1193
   Episode_Reward/test_gait_reward: -0.9055
Metrics/base_velocity/error_vel_xy: 1.4846
Metrics/base_velocity/error_vel_yaw: 1.0572
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 1.08s
                        Total time: 1574.48s
                               ETA: 1677.4s

################################################################################
                     [1m Learning iteration 1453/3000 [0m                     

                       Computation: 89431 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 1472181232.0000
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6406
                     Learning rate: 0.0000
                       Mean reward: -57410.62
               Mean episode length: 980.17
       Episode_Reward/keep_balance: 0.9872
     Episode_Reward/rew_lin_vel_xy: 4.9407
      Episode_Reward/rew_ang_vel_z: 2.7140
    Episode_Reward/pen_base_height: -0.3467
      Episode_Reward/pen_lin_vel_z: -0.0603
     Episode_Reward/pen_ang_vel_xy: -0.1631
   Episode_Reward/pen_joint_torque: -0.2255
    Episode_Reward/pen_joint_accel: -0.0961
    Episode_Reward/pen_action_rate: -2345.6392
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0462
   Episode_Reward/pen_joint_powers: -0.0745
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -51.6910
Episode_Reward/pen_flat_orientation: -0.1189
  Episode_Reward/pen_feet_distance: -0.0110
Episode_Reward/pen_feet_regulation: -0.3572
   Episode_Reward/foot_landing_vel: -0.1327
   Episode_Reward/test_gait_reward: -0.9233
Metrics/base_velocity/error_vel_xy: 1.6414
Metrics/base_velocity/error_vel_yaw: 1.1124
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 1.10s
                        Total time: 1575.57s
                               ETA: 1676.4s

################################################################################
                     [1m Learning iteration 1454/3000 [0m                     

                       Computation: 90351 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.9197
                    Surrogate loss: -0.0034
             Mean action noise std: 0.6414
                     Learning rate: 0.0002
                       Mean reward: 102.92
               Mean episode length: 981.79
       Episode_Reward/keep_balance: 0.9863
     Episode_Reward/rew_lin_vel_xy: 5.1039
      Episode_Reward/rew_ang_vel_z: 2.6977
    Episode_Reward/pen_base_height: -0.3423
      Episode_Reward/pen_lin_vel_z: -0.0580
     Episode_Reward/pen_ang_vel_xy: -0.1574
   Episode_Reward/pen_joint_torque: -0.2036
    Episode_Reward/pen_joint_accel: -0.0882
    Episode_Reward/pen_action_rate: -0.3290
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0443
   Episode_Reward/pen_joint_powers: -0.0725
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7407
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0099
Episode_Reward/pen_feet_regulation: -0.3419
   Episode_Reward/foot_landing_vel: -0.1241
   Episode_Reward/test_gait_reward: -0.9222
Metrics/base_velocity/error_vel_xy: 1.5287
Metrics/base_velocity/error_vel_yaw: 1.1093
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 1.09s
                        Total time: 1576.66s
                               ETA: 1675.3s

################################################################################
                     [1m Learning iteration 1455/3000 [0m                     

                       Computation: 90324 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.9430
                    Surrogate loss: -0.0048
             Mean action noise std: 0.6410
                     Learning rate: 0.0004
                       Mean reward: 103.07
               Mean episode length: 969.54
       Episode_Reward/keep_balance: 0.9710
     Episode_Reward/rew_lin_vel_xy: 5.0001
      Episode_Reward/rew_ang_vel_z: 2.7022
    Episode_Reward/pen_base_height: -0.3235
      Episode_Reward/pen_lin_vel_z: -0.0563
     Episode_Reward/pen_ang_vel_xy: -0.1591
   Episode_Reward/pen_joint_torque: -0.1932
    Episode_Reward/pen_joint_accel: -0.0972
    Episode_Reward/pen_action_rate: -0.3243
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0443
   Episode_Reward/pen_joint_powers: -0.0706
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7302
Episode_Reward/pen_flat_orientation: -0.1155
  Episode_Reward/pen_feet_distance: -0.0120
Episode_Reward/pen_feet_regulation: -0.3351
   Episode_Reward/foot_landing_vel: -0.1259
   Episode_Reward/test_gait_reward: -0.8951
Metrics/base_velocity/error_vel_xy: 1.4937
Metrics/base_velocity/error_vel_yaw: 1.0565
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 1.09s
                        Total time: 1577.75s
                               ETA: 1674.2s

################################################################################
                     [1m Learning iteration 1456/3000 [0m                     

                       Computation: 90545 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.9553
                    Surrogate loss: -0.0038
             Mean action noise std: 0.6422
                     Learning rate: 0.0006
                       Mean reward: 98.48
               Mean episode length: 959.41
       Episode_Reward/keep_balance: 0.9610
     Episode_Reward/rew_lin_vel_xy: 4.8951
      Episode_Reward/rew_ang_vel_z: 2.6033
    Episode_Reward/pen_base_height: -0.3606
      Episode_Reward/pen_lin_vel_z: -0.0571
     Episode_Reward/pen_ang_vel_xy: -0.1655
   Episode_Reward/pen_joint_torque: -0.2012
    Episode_Reward/pen_joint_accel: -0.0925
    Episode_Reward/pen_action_rate: -0.3317
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0464
   Episode_Reward/pen_joint_powers: -0.0736
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7413
Episode_Reward/pen_flat_orientation: -0.1286
  Episode_Reward/pen_feet_distance: -0.0106
Episode_Reward/pen_feet_regulation: -0.3606
   Episode_Reward/foot_landing_vel: -0.1207
   Episode_Reward/test_gait_reward: -0.9036
Metrics/base_velocity/error_vel_xy: 1.5070
Metrics/base_velocity/error_vel_yaw: 1.1152
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 1.09s
                        Total time: 1578.84s
                               ETA: 1673.1s

################################################################################
                     [1m Learning iteration 1457/3000 [0m                     

                       Computation: 90544 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.8776
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6430
                     Learning rate: 0.0003
                       Mean reward: 98.73
               Mean episode length: 973.97
       Episode_Reward/keep_balance: 0.9697
     Episode_Reward/rew_lin_vel_xy: 4.8555
      Episode_Reward/rew_ang_vel_z: 2.6327
    Episode_Reward/pen_base_height: -0.3329
      Episode_Reward/pen_lin_vel_z: -0.0537
     Episode_Reward/pen_ang_vel_xy: -0.1598
   Episode_Reward/pen_joint_torque: -0.1948
    Episode_Reward/pen_joint_accel: -0.0904
    Episode_Reward/pen_action_rate: -0.3278
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0705
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7436
Episode_Reward/pen_flat_orientation: -0.1190
  Episode_Reward/pen_feet_distance: -0.0106
Episode_Reward/pen_feet_regulation: -0.3406
   Episode_Reward/foot_landing_vel: -0.1216
   Episode_Reward/test_gait_reward: -0.9033
Metrics/base_velocity/error_vel_xy: 1.5862
Metrics/base_velocity/error_vel_yaw: 1.1118
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 1.09s
                        Total time: 1579.92s
                               ETA: 1672.0s

################################################################################
                     [1m Learning iteration 1458/3000 [0m                     

                       Computation: 90548 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.9541
                    Surrogate loss: -0.0038
             Mean action noise std: 0.6434
                     Learning rate: 0.0006
                       Mean reward: 98.16
               Mean episode length: 969.88
       Episode_Reward/keep_balance: 0.9577
     Episode_Reward/rew_lin_vel_xy: 4.7317
      Episode_Reward/rew_ang_vel_z: 2.6131
    Episode_Reward/pen_base_height: -0.3262
      Episode_Reward/pen_lin_vel_z: -0.0529
     Episode_Reward/pen_ang_vel_xy: -0.1529
   Episode_Reward/pen_joint_torque: -0.1884
    Episode_Reward/pen_joint_accel: -0.0839
    Episode_Reward/pen_action_rate: -0.3183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0428
   Episode_Reward/pen_joint_powers: -0.0679
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7275
Episode_Reward/pen_flat_orientation: -0.1164
  Episode_Reward/pen_feet_distance: -0.0113
Episode_Reward/pen_feet_regulation: -0.3433
   Episode_Reward/foot_landing_vel: -0.1112
   Episode_Reward/test_gait_reward: -0.8913
Metrics/base_velocity/error_vel_xy: 1.6483
Metrics/base_velocity/error_vel_yaw: 1.0893
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 1.09s
                        Total time: 1581.01s
                               ETA: 1670.9s

################################################################################
                     [1m Learning iteration 1459/3000 [0m                     

                       Computation: 90238 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.9356
                    Surrogate loss: -0.0038
             Mean action noise std: 0.6435
                     Learning rate: 0.0009
                       Mean reward: 104.25
               Mean episode length: 963.32
       Episode_Reward/keep_balance: 0.9634
     Episode_Reward/rew_lin_vel_xy: 5.0349
      Episode_Reward/rew_ang_vel_z: 2.6716
    Episode_Reward/pen_base_height: -0.3359
      Episode_Reward/pen_lin_vel_z: -0.0561
     Episode_Reward/pen_ang_vel_xy: -0.1531
   Episode_Reward/pen_joint_torque: -0.1961
    Episode_Reward/pen_joint_accel: -0.0920
    Episode_Reward/pen_action_rate: -0.3231
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0430
   Episode_Reward/pen_joint_powers: -0.0699
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7246
Episode_Reward/pen_flat_orientation: -0.1151
  Episode_Reward/pen_feet_distance: -0.0117
Episode_Reward/pen_feet_regulation: -0.3373
   Episode_Reward/foot_landing_vel: -0.1219
   Episode_Reward/test_gait_reward: -0.9020
Metrics/base_velocity/error_vel_xy: 1.4605
Metrics/base_velocity/error_vel_yaw: 1.0556
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 1.09s
                        Total time: 1582.10s
                               ETA: 1669.9s

################################################################################
                     [1m Learning iteration 1460/3000 [0m                     

                       Computation: 89871 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.9678
                    Surrogate loss: -0.0012
             Mean action noise std: 0.6438
                     Learning rate: 0.0004
                       Mean reward: 105.73
               Mean episode length: 982.96
       Episode_Reward/keep_balance: 0.9874
     Episode_Reward/rew_lin_vel_xy: 5.0825
      Episode_Reward/rew_ang_vel_z: 2.7288
    Episode_Reward/pen_base_height: -0.3302
      Episode_Reward/pen_lin_vel_z: -0.0557
     Episode_Reward/pen_ang_vel_xy: -0.1612
   Episode_Reward/pen_joint_torque: -0.1947
    Episode_Reward/pen_joint_accel: -0.0878
    Episode_Reward/pen_action_rate: -0.3297
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0438
   Episode_Reward/pen_joint_powers: -0.0701
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7412
Episode_Reward/pen_flat_orientation: -0.1169
  Episode_Reward/pen_feet_distance: -0.0100
Episode_Reward/pen_feet_regulation: -0.3345
   Episode_Reward/foot_landing_vel: -0.1195
   Episode_Reward/test_gait_reward: -0.9121
Metrics/base_velocity/error_vel_xy: 1.5744
Metrics/base_velocity/error_vel_yaw: 1.0885
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 1.09s
                        Total time: 1583.19s
                               ETA: 1668.8s

################################################################################
                     [1m Learning iteration 1461/3000 [0m                     

                       Computation: 89277 steps/s (collection: 0.974s, learning 0.127s)
               Value function loss: 0.9071
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6439
                     Learning rate: 0.0003
                       Mean reward: 99.99
               Mean episode length: 984.50
       Episode_Reward/keep_balance: 0.9833
     Episode_Reward/rew_lin_vel_xy: 4.9170
      Episode_Reward/rew_ang_vel_z: 2.6740
    Episode_Reward/pen_base_height: -0.3383
      Episode_Reward/pen_lin_vel_z: -0.0555
     Episode_Reward/pen_ang_vel_xy: -0.1606
   Episode_Reward/pen_joint_torque: -0.1957
    Episode_Reward/pen_joint_accel: -0.0919
    Episode_Reward/pen_action_rate: -0.3331
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0461
   Episode_Reward/pen_joint_powers: -0.0717
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7508
Episode_Reward/pen_flat_orientation: -0.1218
  Episode_Reward/pen_feet_distance: -0.0115
Episode_Reward/pen_feet_regulation: -0.3575
   Episode_Reward/foot_landing_vel: -0.1294
   Episode_Reward/test_gait_reward: -0.9147
Metrics/base_velocity/error_vel_xy: 1.5818
Metrics/base_velocity/error_vel_yaw: 1.1206
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 1.10s
                        Total time: 1584.29s
                               ETA: 1667.7s

################################################################################
                     [1m Learning iteration 1462/3000 [0m                     

                       Computation: 90570 steps/s (collection: 0.960s, learning 0.126s)
               Value function loss: 0.9373
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6442
                     Learning rate: 0.0003
                       Mean reward: 102.81
               Mean episode length: 984.36
       Episode_Reward/keep_balance: 0.9859
     Episode_Reward/rew_lin_vel_xy: 4.9885
      Episode_Reward/rew_ang_vel_z: 2.6914
    Episode_Reward/pen_base_height: -0.3526
      Episode_Reward/pen_lin_vel_z: -0.0600
     Episode_Reward/pen_ang_vel_xy: -0.1636
   Episode_Reward/pen_joint_torque: -0.2047
    Episode_Reward/pen_joint_accel: -0.0935
    Episode_Reward/pen_action_rate: -0.3377
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0477
   Episode_Reward/pen_joint_powers: -0.0756
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7588
Episode_Reward/pen_flat_orientation: -0.1193
  Episode_Reward/pen_feet_distance: -0.0138
Episode_Reward/pen_feet_regulation: -0.3761
   Episode_Reward/foot_landing_vel: -0.1275
   Episode_Reward/test_gait_reward: -0.9261
Metrics/base_velocity/error_vel_xy: 1.6173
Metrics/base_velocity/error_vel_yaw: 1.1115
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 1.09s
                        Total time: 1585.38s
                               ETA: 1666.7s

################################################################################
                     [1m Learning iteration 1463/3000 [0m                     

                       Computation: 90501 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.9265
                    Surrogate loss: -0.0045
             Mean action noise std: 0.6440
                     Learning rate: 0.0006
                       Mean reward: 101.19
               Mean episode length: 992.98
       Episode_Reward/keep_balance: 0.9964
     Episode_Reward/rew_lin_vel_xy: 4.8970
      Episode_Reward/rew_ang_vel_z: 2.7303
    Episode_Reward/pen_base_height: -0.3385
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1576
   Episode_Reward/pen_joint_torque: -0.1973
    Episode_Reward/pen_joint_accel: -0.0889
    Episode_Reward/pen_action_rate: -0.3317
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0451
   Episode_Reward/pen_joint_powers: -0.0710
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7528
Episode_Reward/pen_flat_orientation: -0.1173
  Episode_Reward/pen_feet_distance: -0.0123
Episode_Reward/pen_feet_regulation: -0.3597
   Episode_Reward/foot_landing_vel: -0.1289
   Episode_Reward/test_gait_reward: -0.9187
Metrics/base_velocity/error_vel_xy: 1.7083
Metrics/base_velocity/error_vel_yaw: 1.1200
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 1.09s
                        Total time: 1586.46s
                               ETA: 1665.6s

################################################################################
                     [1m Learning iteration 1464/3000 [0m                     

                       Computation: 89863 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.9671
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6439
                     Learning rate: 0.0001
                       Mean reward: 98.07
               Mean episode length: 957.18
       Episode_Reward/keep_balance: 0.9661
     Episode_Reward/rew_lin_vel_xy: 4.7399
      Episode_Reward/rew_ang_vel_z: 2.6469
    Episode_Reward/pen_base_height: -0.3450
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1647
   Episode_Reward/pen_joint_torque: -0.1882
    Episode_Reward/pen_joint_accel: -0.0842
    Episode_Reward/pen_action_rate: -0.3264
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0457
   Episode_Reward/pen_joint_powers: -0.0705
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7416
Episode_Reward/pen_flat_orientation: -0.1300
  Episode_Reward/pen_feet_distance: -0.0139
Episode_Reward/pen_feet_regulation: -0.3616
   Episode_Reward/foot_landing_vel: -0.1246
   Episode_Reward/test_gait_reward: -0.8973
Metrics/base_velocity/error_vel_xy: 1.6303
Metrics/base_velocity/error_vel_yaw: 1.0953
      Episode_Termination/time_out: 2.9583
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 1.09s
                        Total time: 1587.56s
                               ETA: 1664.5s

################################################################################
                     [1m Learning iteration 1465/3000 [0m                     

                       Computation: 91658 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.9489
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6443
                     Learning rate: 0.0001
                       Mean reward: 101.56
               Mean episode length: 996.05
       Episode_Reward/keep_balance: 0.9843
     Episode_Reward/rew_lin_vel_xy: 4.9075
      Episode_Reward/rew_ang_vel_z: 2.7037
    Episode_Reward/pen_base_height: -0.3369
      Episode_Reward/pen_lin_vel_z: -0.0568
     Episode_Reward/pen_ang_vel_xy: -0.1561
   Episode_Reward/pen_joint_torque: -0.2022
    Episode_Reward/pen_joint_accel: -0.0921
    Episode_Reward/pen_action_rate: -0.3294
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0439
   Episode_Reward/pen_joint_powers: -0.0707
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7437
Episode_Reward/pen_flat_orientation: -0.1149
  Episode_Reward/pen_feet_distance: -0.0145
Episode_Reward/pen_feet_regulation: -0.3383
   Episode_Reward/foot_landing_vel: -0.1252
   Episode_Reward/test_gait_reward: -0.9149
Metrics/base_velocity/error_vel_xy: 1.6788
Metrics/base_velocity/error_vel_yaw: 1.0970
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 1.07s
                        Total time: 1588.63s
                               ETA: 1663.4s

################################################################################
                     [1m Learning iteration 1466/3000 [0m                     

                       Computation: 90693 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.9661
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6444
                     Learning rate: 0.0001
                       Mean reward: 95.32
               Mean episode length: 975.72
       Episode_Reward/keep_balance: 0.9830
     Episode_Reward/rew_lin_vel_xy: 4.8104
      Episode_Reward/rew_ang_vel_z: 2.6796
    Episode_Reward/pen_base_height: -0.3472
      Episode_Reward/pen_lin_vel_z: -0.0593
     Episode_Reward/pen_ang_vel_xy: -0.1630
   Episode_Reward/pen_joint_torque: -0.1996
    Episode_Reward/pen_joint_accel: -0.0957
    Episode_Reward/pen_action_rate: -0.3390
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0468
   Episode_Reward/pen_joint_powers: -0.0733
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7575
Episode_Reward/pen_flat_orientation: -0.1277
  Episode_Reward/pen_feet_distance: -0.0107
Episode_Reward/pen_feet_regulation: -0.3738
   Episode_Reward/foot_landing_vel: -0.1296
   Episode_Reward/test_gait_reward: -0.9231
Metrics/base_velocity/error_vel_xy: 1.6890
Metrics/base_velocity/error_vel_yaw: 1.1275
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 1.08s
                        Total time: 1589.71s
                               ETA: 1662.3s

################################################################################
                     [1m Learning iteration 1467/3000 [0m                     

                       Computation: 92161 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 0.9886
                    Surrogate loss: 0.0020
             Mean action noise std: 0.6445
                     Learning rate: 0.0000
                       Mean reward: 100.03
               Mean episode length: 965.55
       Episode_Reward/keep_balance: 0.9575
     Episode_Reward/rew_lin_vel_xy: 4.8795
      Episode_Reward/rew_ang_vel_z: 2.6336
    Episode_Reward/pen_base_height: -0.3186
      Episode_Reward/pen_lin_vel_z: -0.0559
     Episode_Reward/pen_ang_vel_xy: -0.1620
   Episode_Reward/pen_joint_torque: -0.1921
    Episode_Reward/pen_joint_accel: -0.0910
    Episode_Reward/pen_action_rate: -0.3227
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0442
   Episode_Reward/pen_joint_powers: -0.0704
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.7299
Episode_Reward/pen_flat_orientation: -0.1176
  Episode_Reward/pen_feet_distance: -0.0133
Episode_Reward/pen_feet_regulation: -0.3371
   Episode_Reward/foot_landing_vel: -0.1228
   Episode_Reward/test_gait_reward: -0.8851
Metrics/base_velocity/error_vel_xy: 1.5561
Metrics/base_velocity/error_vel_yaw: 1.0650
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 1.07s
                        Total time: 1590.78s
                               ETA: 1661.2s

################################################################################
                     [1m Learning iteration 1468/3000 [0m                     

                       Computation: 91448 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.8448
                    Surrogate loss: 0.0020
             Mean action noise std: 0.6446
                     Learning rate: 0.0000
                       Mean reward: 99.69
               Mean episode length: 990.24
       Episode_Reward/keep_balance: 0.9865
     Episode_Reward/rew_lin_vel_xy: 4.9153
      Episode_Reward/rew_ang_vel_z: 2.6888
    Episode_Reward/pen_base_height: -0.3256
      Episode_Reward/pen_lin_vel_z: -0.0538
     Episode_Reward/pen_ang_vel_xy: -0.1563
   Episode_Reward/pen_joint_torque: -0.2009
    Episode_Reward/pen_joint_accel: -0.0870
    Episode_Reward/pen_action_rate: -0.3284
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0714
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7409
Episode_Reward/pen_flat_orientation: -0.1164
  Episode_Reward/pen_feet_distance: -0.0123
Episode_Reward/pen_feet_regulation: -0.3463
   Episode_Reward/foot_landing_vel: -0.1166
   Episode_Reward/test_gait_reward: -0.9110
Metrics/base_velocity/error_vel_xy: 1.6558
Metrics/base_velocity/error_vel_yaw: 1.1190
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 1.07s
                        Total time: 1591.86s
                               ETA: 1660.1s

################################################################################
                     [1m Learning iteration 1469/3000 [0m                     

                       Computation: 93399 steps/s (collection: 0.930s, learning 0.123s)
               Value function loss: 0.8944
                    Surrogate loss: 0.0007
             Mean action noise std: 0.6443
                     Learning rate: 0.0001
                       Mean reward: 103.19
               Mean episode length: 998.43
       Episode_Reward/keep_balance: 0.9984
     Episode_Reward/rew_lin_vel_xy: 5.0356
      Episode_Reward/rew_ang_vel_z: 2.7469
    Episode_Reward/pen_base_height: -0.3491
      Episode_Reward/pen_lin_vel_z: -0.0592
     Episode_Reward/pen_ang_vel_xy: -0.1599
   Episode_Reward/pen_joint_torque: -0.2070
    Episode_Reward/pen_joint_accel: -0.0863
    Episode_Reward/pen_action_rate: -0.3378
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0463
   Episode_Reward/pen_joint_powers: -0.0741
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7543
Episode_Reward/pen_flat_orientation: -0.1181
  Episode_Reward/pen_feet_distance: -0.0094
Episode_Reward/pen_feet_regulation: -0.3578
   Episode_Reward/foot_landing_vel: -0.1362
   Episode_Reward/test_gait_reward: -0.9328
Metrics/base_velocity/error_vel_xy: 1.6904
Metrics/base_velocity/error_vel_yaw: 1.1117
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 1.05s
                        Total time: 1592.91s
                               ETA: 1659.0s

################################################################################
                     [1m Learning iteration 1470/3000 [0m                     

                       Computation: 92700 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 0.8738
                    Surrogate loss: 0.0004
             Mean action noise std: 0.6440
                     Learning rate: 0.0001
                       Mean reward: 100.56
               Mean episode length: 970.90
       Episode_Reward/keep_balance: 0.9760
     Episode_Reward/rew_lin_vel_xy: 4.9706
      Episode_Reward/rew_ang_vel_z: 2.6901
    Episode_Reward/pen_base_height: -0.3242
      Episode_Reward/pen_lin_vel_z: -0.0566
     Episode_Reward/pen_ang_vel_xy: -0.1535
   Episode_Reward/pen_joint_torque: -0.1954
    Episode_Reward/pen_joint_accel: -0.0900
    Episode_Reward/pen_action_rate: -0.3252
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0446
   Episode_Reward/pen_joint_powers: -0.0708
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7379
Episode_Reward/pen_flat_orientation: -0.1158
  Episode_Reward/pen_feet_distance: -0.0100
Episode_Reward/pen_feet_regulation: -0.3437
   Episode_Reward/foot_landing_vel: -0.1316
   Episode_Reward/test_gait_reward: -0.9025
Metrics/base_velocity/error_vel_xy: 1.6421
Metrics/base_velocity/error_vel_yaw: 1.0844
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 1.06s
                        Total time: 1593.97s
                               ETA: 1657.9s

################################################################################
                     [1m Learning iteration 1471/3000 [0m                     

                       Computation: 92568 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 0.8265
                    Surrogate loss: 0.0027
             Mean action noise std: 0.6438
                     Learning rate: 0.0000
                       Mean reward: 101.79
               Mean episode length: 985.47
       Episode_Reward/keep_balance: 0.9901
     Episode_Reward/rew_lin_vel_xy: 4.9783
      Episode_Reward/rew_ang_vel_z: 2.7190
    Episode_Reward/pen_base_height: -0.3365
      Episode_Reward/pen_lin_vel_z: -0.0569
     Episode_Reward/pen_ang_vel_xy: -0.1615
   Episode_Reward/pen_joint_torque: -0.2060
    Episode_Reward/pen_joint_accel: -0.0853
    Episode_Reward/pen_action_rate: -0.3342
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0452
   Episode_Reward/pen_joint_powers: -0.0734
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7431
Episode_Reward/pen_flat_orientation: -0.1160
  Episode_Reward/pen_feet_distance: -0.0136
Episode_Reward/pen_feet_regulation: -0.3550
   Episode_Reward/foot_landing_vel: -0.1238
   Episode_Reward/test_gait_reward: -0.9230
Metrics/base_velocity/error_vel_xy: 1.6478
Metrics/base_velocity/error_vel_yaw: 1.1099
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 1.06s
                        Total time: 1595.03s
                               ETA: 1656.8s

################################################################################
                     [1m Learning iteration 1472/3000 [0m                     

                       Computation: 90661 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.9078
                    Surrogate loss: 0.0053
             Mean action noise std: 0.6436
                     Learning rate: 0.0000
                       Mean reward: 101.39
               Mean episode length: 983.79
       Episode_Reward/keep_balance: 0.9731
     Episode_Reward/rew_lin_vel_xy: 4.9105
      Episode_Reward/rew_ang_vel_z: 2.6562
    Episode_Reward/pen_base_height: -0.3247
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1583
   Episode_Reward/pen_joint_torque: -0.1986
    Episode_Reward/pen_joint_accel: -0.0884
    Episode_Reward/pen_action_rate: -0.3327
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0710
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7398
Episode_Reward/pen_flat_orientation: -0.1182
  Episode_Reward/pen_feet_distance: -0.0130
Episode_Reward/pen_feet_regulation: -0.3592
   Episode_Reward/foot_landing_vel: -0.1248
   Episode_Reward/test_gait_reward: -0.9007
Metrics/base_velocity/error_vel_xy: 1.6040
Metrics/base_velocity/error_vel_yaw: 1.1057
      Episode_Termination/time_out: 4.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 1.08s
                        Total time: 1596.11s
                               ETA: 1655.7s

################################################################################
                     [1m Learning iteration 1473/3000 [0m                     

                       Computation: 91093 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.9581
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6432
                     Learning rate: 0.0001
                       Mean reward: 100.86
               Mean episode length: 964.32
       Episode_Reward/keep_balance: 0.9614
     Episode_Reward/rew_lin_vel_xy: 4.8927
      Episode_Reward/rew_ang_vel_z: 2.6360
    Episode_Reward/pen_base_height: -0.3163
      Episode_Reward/pen_lin_vel_z: -0.0534
     Episode_Reward/pen_ang_vel_xy: -0.1566
   Episode_Reward/pen_joint_torque: -0.1886
    Episode_Reward/pen_joint_accel: -0.0895
    Episode_Reward/pen_action_rate: -0.3251
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0707
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7311
Episode_Reward/pen_flat_orientation: -0.1198
  Episode_Reward/pen_feet_distance: -0.0114
Episode_Reward/pen_feet_regulation: -0.3712
   Episode_Reward/foot_landing_vel: -0.1318
   Episode_Reward/test_gait_reward: -0.8888
Metrics/base_velocity/error_vel_xy: 1.5298
Metrics/base_velocity/error_vel_yaw: 1.0785
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 1.08s
                        Total time: 1597.19s
                               ETA: 1654.6s

################################################################################
                     [1m Learning iteration 1474/3000 [0m                     

                       Computation: 93519 steps/s (collection: 0.930s, learning 0.121s)
               Value function loss: 0.8508
                    Surrogate loss: -0.0035
             Mean action noise std: 0.6426
                     Learning rate: 0.0003
                       Mean reward: 97.19
               Mean episode length: 951.23
       Episode_Reward/keep_balance: 0.9259
     Episode_Reward/rew_lin_vel_xy: 4.5696
      Episode_Reward/rew_ang_vel_z: 2.5548
    Episode_Reward/pen_base_height: -0.3112
      Episode_Reward/pen_lin_vel_z: -0.0505
     Episode_Reward/pen_ang_vel_xy: -0.1490
   Episode_Reward/pen_joint_torque: -0.1863
    Episode_Reward/pen_joint_accel: -0.0821
    Episode_Reward/pen_action_rate: -0.3069
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0405
   Episode_Reward/pen_joint_powers: -0.0654
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.6956
Episode_Reward/pen_flat_orientation: -0.1085
  Episode_Reward/pen_feet_distance: -0.0144
Episode_Reward/pen_feet_regulation: -0.3136
   Episode_Reward/foot_landing_vel: -0.1161
   Episode_Reward/test_gait_reward: -0.8505
Metrics/base_velocity/error_vel_xy: 1.5982
Metrics/base_velocity/error_vel_yaw: 1.0335
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 1.05s
                        Total time: 1598.25s
                               ETA: 1653.5s

################################################################################
                     [1m Learning iteration 1475/3000 [0m                     

                       Computation: 91835 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 0.9020
                    Surrogate loss: -0.0034
             Mean action noise std: 0.6413
                     Learning rate: 0.0006
                       Mean reward: 99.91
               Mean episode length: 977.60
       Episode_Reward/keep_balance: 0.9752
     Episode_Reward/rew_lin_vel_xy: 4.8746
      Episode_Reward/rew_ang_vel_z: 2.6662
    Episode_Reward/pen_base_height: -0.3227
      Episode_Reward/pen_lin_vel_z: -0.0552
     Episode_Reward/pen_ang_vel_xy: -0.1573
   Episode_Reward/pen_joint_torque: -0.2011
    Episode_Reward/pen_joint_accel: -0.0897
    Episode_Reward/pen_action_rate: -0.3281
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0446
   Episode_Reward/pen_joint_powers: -0.0715
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7328
Episode_Reward/pen_flat_orientation: -0.1129
  Episode_Reward/pen_feet_distance: -0.0146
Episode_Reward/pen_feet_regulation: -0.3396
   Episode_Reward/foot_landing_vel: -0.1263
   Episode_Reward/test_gait_reward: -0.9018
Metrics/base_velocity/error_vel_xy: 1.6365
Metrics/base_velocity/error_vel_yaw: 1.1064
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 1.07s
                        Total time: 1599.32s
                               ETA: 1652.4s

################################################################################
                     [1m Learning iteration 1476/3000 [0m                     

                       Computation: 93552 steps/s (collection: 0.928s, learning 0.123s)
               Value function loss: 0.8719
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6400
                     Learning rate: 0.0009
                       Mean reward: 104.82
               Mean episode length: 978.21
       Episode_Reward/keep_balance: 0.9892
     Episode_Reward/rew_lin_vel_xy: 5.0292
      Episode_Reward/rew_ang_vel_z: 2.7233
    Episode_Reward/pen_base_height: -0.3265
      Episode_Reward/pen_lin_vel_z: -0.0542
     Episode_Reward/pen_ang_vel_xy: -0.1507
   Episode_Reward/pen_joint_torque: -0.1989
    Episode_Reward/pen_joint_accel: -0.0871
    Episode_Reward/pen_action_rate: -0.3239
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0435
   Episode_Reward/pen_joint_powers: -0.0709
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7357
Episode_Reward/pen_flat_orientation: -0.1106
  Episode_Reward/pen_feet_distance: -0.0135
Episode_Reward/pen_feet_regulation: -0.3327
   Episode_Reward/foot_landing_vel: -0.1175
   Episode_Reward/test_gait_reward: -0.9117
Metrics/base_velocity/error_vel_xy: 1.6218
Metrics/base_velocity/error_vel_yaw: 1.1079
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 1.05s
                        Total time: 1600.37s
                               ETA: 1651.3s

################################################################################
                     [1m Learning iteration 1477/3000 [0m                     

                       Computation: 92164 steps/s (collection: 0.943s, learning 0.123s)
               Value function loss: 0.8811
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6398
                     Learning rate: 0.0009
                       Mean reward: 101.24
               Mean episode length: 969.96
       Episode_Reward/keep_balance: 0.9734
     Episode_Reward/rew_lin_vel_xy: 4.8341
      Episode_Reward/rew_ang_vel_z: 2.7097
    Episode_Reward/pen_base_height: -0.3221
      Episode_Reward/pen_lin_vel_z: -0.0546
     Episode_Reward/pen_ang_vel_xy: -0.1568
   Episode_Reward/pen_joint_torque: -0.1975
    Episode_Reward/pen_joint_accel: -0.0925
    Episode_Reward/pen_action_rate: -0.3276
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0443
   Episode_Reward/pen_joint_powers: -0.0704
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7296
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0133
Episode_Reward/pen_feet_regulation: -0.3406
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.8969
Metrics/base_velocity/error_vel_xy: 1.6200
Metrics/base_velocity/error_vel_yaw: 1.0590
      Episode_Termination/time_out: 3.2500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 1.07s
                        Total time: 1601.43s
                               ETA: 1650.2s

################################################################################
                     [1m Learning iteration 1478/3000 [0m                     

                       Computation: 92666 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 0.9031
                    Surrogate loss: -0.0040
             Mean action noise std: 0.6402
                     Learning rate: 0.0019
                       Mean reward: 102.68
               Mean episode length: 986.49
       Episode_Reward/keep_balance: 0.9762
     Episode_Reward/rew_lin_vel_xy: 4.9001
      Episode_Reward/rew_ang_vel_z: 2.6664
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0523
     Episode_Reward/pen_ang_vel_xy: -0.1645
   Episode_Reward/pen_joint_torque: -0.1892
    Episode_Reward/pen_joint_accel: -0.0962
    Episode_Reward/pen_action_rate: -0.3264
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0454
   Episode_Reward/pen_joint_powers: -0.0698
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7373
Episode_Reward/pen_flat_orientation: -0.1171
  Episode_Reward/pen_feet_distance: -0.0128
Episode_Reward/pen_feet_regulation: -0.3468
   Episode_Reward/foot_landing_vel: -0.1233
   Episode_Reward/test_gait_reward: -0.8990
Metrics/base_velocity/error_vel_xy: 1.6052
Metrics/base_velocity/error_vel_yaw: 1.0980
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 1.06s
                        Total time: 1602.49s
                               ETA: 1649.1s

################################################################################
                     [1m Learning iteration 1479/3000 [0m                     

                       Computation: 92846 steps/s (collection: 0.935s, learning 0.124s)
               Value function loss: 0.9080
                    Surrogate loss: 0.0008
             Mean action noise std: 0.6402
                     Learning rate: 0.0004
                       Mean reward: 100.86
               Mean episode length: 985.09
       Episode_Reward/keep_balance: 0.9885
     Episode_Reward/rew_lin_vel_xy: 4.8248
      Episode_Reward/rew_ang_vel_z: 2.7204
    Episode_Reward/pen_base_height: -0.3304
      Episode_Reward/pen_lin_vel_z: -0.0574
     Episode_Reward/pen_ang_vel_xy: -0.1551
   Episode_Reward/pen_joint_torque: -0.1954
    Episode_Reward/pen_joint_accel: -0.1010
    Episode_Reward/pen_action_rate: -0.3282
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0460
   Episode_Reward/pen_joint_powers: -0.0715
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7429
Episode_Reward/pen_flat_orientation: -0.1143
  Episode_Reward/pen_feet_distance: -0.0109
Episode_Reward/pen_feet_regulation: -0.3536
   Episode_Reward/foot_landing_vel: -0.1340
   Episode_Reward/test_gait_reward: -0.9142
Metrics/base_velocity/error_vel_xy: 1.7538
Metrics/base_velocity/error_vel_yaw: 1.0944
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 1.06s
                        Total time: 1603.55s
                               ETA: 1648.0s

################################################################################
                     [1m Learning iteration 1480/3000 [0m                     

                       Computation: 91397 steps/s (collection: 0.951s, learning 0.125s)
               Value function loss: 0.8447
                    Surrogate loss: -0.0041
             Mean action noise std: 0.6395
                     Learning rate: 0.0009
                       Mean reward: 102.42
               Mean episode length: 983.06
       Episode_Reward/keep_balance: 0.9854
     Episode_Reward/rew_lin_vel_xy: 5.0575
      Episode_Reward/rew_ang_vel_z: 2.6923
    Episode_Reward/pen_base_height: -0.3309
      Episode_Reward/pen_lin_vel_z: -0.0553
     Episode_Reward/pen_ang_vel_xy: -0.1625
   Episode_Reward/pen_joint_torque: -0.2002
    Episode_Reward/pen_joint_accel: -0.0876
    Episode_Reward/pen_action_rate: -0.3315
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0462
   Episode_Reward/pen_joint_powers: -0.0728
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7431
Episode_Reward/pen_flat_orientation: -0.1225
  Episode_Reward/pen_feet_distance: -0.0146
Episode_Reward/pen_feet_regulation: -0.3732
   Episode_Reward/foot_landing_vel: -0.1298
   Episode_Reward/test_gait_reward: -0.9193
Metrics/base_velocity/error_vel_xy: 1.5662
Metrics/base_velocity/error_vel_yaw: 1.1116
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 1.08s
                        Total time: 1604.63s
                               ETA: 1646.9s

################################################################################
                     [1m Learning iteration 1481/3000 [0m                     

                       Computation: 93206 steps/s (collection: 0.932s, learning 0.123s)
               Value function loss: 0.8851
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6390
                     Learning rate: 0.0013
                       Mean reward: 104.91
               Mean episode length: 991.87
       Episode_Reward/keep_balance: 0.9952
     Episode_Reward/rew_lin_vel_xy: 5.1021
      Episode_Reward/rew_ang_vel_z: 2.7497
    Episode_Reward/pen_base_height: -0.3275
      Episode_Reward/pen_lin_vel_z: -0.0568
     Episode_Reward/pen_ang_vel_xy: -0.1573
   Episode_Reward/pen_joint_torque: -0.1987
    Episode_Reward/pen_joint_accel: -0.0947
    Episode_Reward/pen_action_rate: -0.3326
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0719
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7406
Episode_Reward/pen_flat_orientation: -0.1113
  Episode_Reward/pen_feet_distance: -0.0139
Episode_Reward/pen_feet_regulation: -0.3623
   Episode_Reward/foot_landing_vel: -0.1349
   Episode_Reward/test_gait_reward: -0.9208
Metrics/base_velocity/error_vel_xy: 1.5889
Metrics/base_velocity/error_vel_yaw: 1.0976
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 1.05s
                        Total time: 1605.68s
                               ETA: 1645.8s

################################################################################
                     [1m Learning iteration 1482/3000 [0m                     

                       Computation: 92224 steps/s (collection: 0.943s, learning 0.123s)
               Value function loss: 0.8485
                    Surrogate loss: -0.0036
             Mean action noise std: 0.6383
                     Learning rate: 0.0013
                       Mean reward: 105.63
               Mean episode length: 998.27
       Episode_Reward/keep_balance: 0.9986
     Episode_Reward/rew_lin_vel_xy: 5.2812
      Episode_Reward/rew_ang_vel_z: 2.7021
    Episode_Reward/pen_base_height: -0.3435
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.1594
   Episode_Reward/pen_joint_torque: -0.1994
    Episode_Reward/pen_joint_accel: -0.0847
    Episode_Reward/pen_action_rate: -0.3348
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0454
   Episode_Reward/pen_joint_powers: -0.0725
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7526
Episode_Reward/pen_flat_orientation: -0.1194
  Episode_Reward/pen_feet_distance: -0.0123
Episode_Reward/pen_feet_regulation: -0.3585
   Episode_Reward/foot_landing_vel: -0.1215
   Episode_Reward/test_gait_reward: -0.9355
Metrics/base_velocity/error_vel_xy: 1.4786
Metrics/base_velocity/error_vel_yaw: 1.1501
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 1.07s
                        Total time: 1606.75s
                               ETA: 1644.7s

################################################################################
                     [1m Learning iteration 1483/3000 [0m                     

                       Computation: 93858 steps/s (collection: 0.924s, learning 0.124s)
               Value function loss: 0.9314
                    Surrogate loss: 0.0001
             Mean action noise std: 0.6378
                     Learning rate: 0.0003
                       Mean reward: 102.53
               Mean episode length: 980.17
       Episode_Reward/keep_balance: 0.9753
     Episode_Reward/rew_lin_vel_xy: 4.9839
      Episode_Reward/rew_ang_vel_z: 2.7227
    Episode_Reward/pen_base_height: -0.3482
      Episode_Reward/pen_lin_vel_z: -0.0615
     Episode_Reward/pen_ang_vel_xy: -0.1632
   Episode_Reward/pen_joint_torque: -0.2097
    Episode_Reward/pen_joint_accel: -0.0984
    Episode_Reward/pen_action_rate: -0.3296
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0469
   Episode_Reward/pen_joint_powers: -0.0758
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7299
Episode_Reward/pen_flat_orientation: -0.1223
  Episode_Reward/pen_feet_distance: -0.0161
Episode_Reward/pen_feet_regulation: -0.3759
   Episode_Reward/foot_landing_vel: -0.1269
   Episode_Reward/test_gait_reward: -0.9074
Metrics/base_velocity/error_vel_xy: 1.6132
Metrics/base_velocity/error_vel_yaw: 1.0585
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 1.05s
                        Total time: 1607.80s
                               ETA: 1643.5s

################################################################################
                     [1m Learning iteration 1484/3000 [0m                     

                       Computation: 92889 steps/s (collection: 0.936s, learning 0.123s)
               Value function loss: 0.9120
                    Surrogate loss: -0.0037
             Mean action noise std: 0.6374
                     Learning rate: 0.0006
                       Mean reward: 104.38
               Mean episode length: 993.59
       Episode_Reward/keep_balance: 0.9933
     Episode_Reward/rew_lin_vel_xy: 5.0591
      Episode_Reward/rew_ang_vel_z: 2.7142
    Episode_Reward/pen_base_height: -0.3356
      Episode_Reward/pen_lin_vel_z: -0.0579
     Episode_Reward/pen_ang_vel_xy: -0.1584
   Episode_Reward/pen_joint_torque: -0.1991
    Episode_Reward/pen_joint_accel: -0.0920
    Episode_Reward/pen_action_rate: -0.3313
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0462
   Episode_Reward/pen_joint_powers: -0.0733
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7463
Episode_Reward/pen_flat_orientation: -0.1196
  Episode_Reward/pen_feet_distance: -0.0130
Episode_Reward/pen_feet_regulation: -0.3720
   Episode_Reward/foot_landing_vel: -0.1315
   Episode_Reward/test_gait_reward: -0.9240
Metrics/base_velocity/error_vel_xy: 1.6238
Metrics/base_velocity/error_vel_yaw: 1.1242
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 1.06s
                        Total time: 1608.85s
                               ETA: 1642.4s

################################################################################
                     [1m Learning iteration 1485/3000 [0m                     

                       Computation: 92084 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 0.9456
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6362
                     Learning rate: 0.0003
                       Mean reward: 103.48
               Mean episode length: 983.00
       Episode_Reward/keep_balance: 0.9895
     Episode_Reward/rew_lin_vel_xy: 5.0484
      Episode_Reward/rew_ang_vel_z: 2.7326
    Episode_Reward/pen_base_height: -0.3326
      Episode_Reward/pen_lin_vel_z: -0.0574
     Episode_Reward/pen_ang_vel_xy: -0.1637
   Episode_Reward/pen_joint_torque: -0.1992
    Episode_Reward/pen_joint_accel: -0.0935
    Episode_Reward/pen_action_rate: -0.3296
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0724
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7366
Episode_Reward/pen_flat_orientation: -0.1184
  Episode_Reward/pen_feet_distance: -0.0125
Episode_Reward/pen_feet_regulation: -0.3584
   Episode_Reward/foot_landing_vel: -0.1319
   Episode_Reward/test_gait_reward: -0.9211
Metrics/base_velocity/error_vel_xy: 1.6079
Metrics/base_velocity/error_vel_yaw: 1.0971
      Episode_Termination/time_out: 4.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 1.07s
                        Total time: 1609.92s
                               ETA: 1641.3s

################################################################################
                     [1m Learning iteration 1486/3000 [0m                     

                       Computation: 90522 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.8548
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6353
                     Learning rate: 0.0004
                       Mean reward: 104.48
               Mean episode length: 977.48
       Episode_Reward/keep_balance: 0.9851
     Episode_Reward/rew_lin_vel_xy: 5.1869
      Episode_Reward/rew_ang_vel_z: 2.7027
    Episode_Reward/pen_base_height: -0.3373
      Episode_Reward/pen_lin_vel_z: -0.0551
     Episode_Reward/pen_ang_vel_xy: -0.1612
   Episode_Reward/pen_joint_torque: -0.2056
    Episode_Reward/pen_joint_accel: -0.0881
    Episode_Reward/pen_action_rate: -0.3314
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0452
   Episode_Reward/pen_joint_powers: -0.0727
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7422
Episode_Reward/pen_flat_orientation: -0.1160
  Episode_Reward/pen_feet_distance: -0.0139
Episode_Reward/pen_feet_regulation: -0.3562
   Episode_Reward/foot_landing_vel: -0.1200
   Episode_Reward/test_gait_reward: -0.9187
Metrics/base_velocity/error_vel_xy: 1.5140
Metrics/base_velocity/error_vel_yaw: 1.1022
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 1.09s
                        Total time: 1611.01s
                               ETA: 1640.3s

################################################################################
                     [1m Learning iteration 1487/3000 [0m                     

                       Computation: 93088 steps/s (collection: 0.933s, learning 0.124s)
               Value function loss: 0.8414
                    Surrogate loss: -0.0042
             Mean action noise std: 0.6345
                     Learning rate: 0.0006
                       Mean reward: 105.13
               Mean episode length: 981.43
       Episode_Reward/keep_balance: 0.9936
     Episode_Reward/rew_lin_vel_xy: 5.1196
      Episode_Reward/rew_ang_vel_z: 2.7753
    Episode_Reward/pen_base_height: -0.3110
      Episode_Reward/pen_lin_vel_z: -0.0555
     Episode_Reward/pen_ang_vel_xy: -0.1533
   Episode_Reward/pen_joint_torque: -0.2004
    Episode_Reward/pen_joint_accel: -0.0906
    Episode_Reward/pen_action_rate: -0.3250
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0435
   Episode_Reward/pen_joint_powers: -0.0704
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7371
Episode_Reward/pen_flat_orientation: -0.1087
  Episode_Reward/pen_feet_distance: -0.0141
Episode_Reward/pen_feet_regulation: -0.3458
   Episode_Reward/foot_landing_vel: -0.1237
   Episode_Reward/test_gait_reward: -0.9207
Metrics/base_velocity/error_vel_xy: 1.5640
Metrics/base_velocity/error_vel_yaw: 1.0674
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 1.06s
                        Total time: 1612.06s
                               ETA: 1639.1s

################################################################################
                     [1m Learning iteration 1488/3000 [0m                     

                       Computation: 92548 steps/s (collection: 0.939s, learning 0.124s)
               Value function loss: 0.9357
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6345
                     Learning rate: 0.0006
                       Mean reward: 96.98
               Mean episode length: 971.11
       Episode_Reward/keep_balance: 0.9672
     Episode_Reward/rew_lin_vel_xy: 4.7594
      Episode_Reward/rew_ang_vel_z: 2.6494
    Episode_Reward/pen_base_height: -0.3496
      Episode_Reward/pen_lin_vel_z: -0.0545
     Episode_Reward/pen_ang_vel_xy: -0.1618
   Episode_Reward/pen_joint_torque: -0.1948
    Episode_Reward/pen_joint_accel: -0.0858
    Episode_Reward/pen_action_rate: -0.3243
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0456
   Episode_Reward/pen_joint_powers: -0.0724
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.7262
Episode_Reward/pen_flat_orientation: -0.1236
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.3648
   Episode_Reward/foot_landing_vel: -0.1230
   Episode_Reward/test_gait_reward: -0.8986
Metrics/base_velocity/error_vel_xy: 1.6579
Metrics/base_velocity/error_vel_yaw: 1.0928
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 1.06s
                        Total time: 1613.13s
                               ETA: 1638.0s

################################################################################
                     [1m Learning iteration 1489/3000 [0m                     

                       Computation: 87839 steps/s (collection: 0.988s, learning 0.131s)
               Value function loss: 0.8795
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6350
                     Learning rate: 0.0004
                       Mean reward: 105.05
               Mean episode length: 988.16
       Episode_Reward/keep_balance: 0.9824
     Episode_Reward/rew_lin_vel_xy: 5.0946
      Episode_Reward/rew_ang_vel_z: 2.6917
    Episode_Reward/pen_base_height: -0.3251
      Episode_Reward/pen_lin_vel_z: -0.0563
     Episode_Reward/pen_ang_vel_xy: -0.1548
   Episode_Reward/pen_joint_torque: -0.1983
    Episode_Reward/pen_joint_accel: -0.0932
    Episode_Reward/pen_action_rate: -0.3305
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0717
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7321
Episode_Reward/pen_flat_orientation: -0.1163
  Episode_Reward/pen_feet_distance: -0.0131
Episode_Reward/pen_feet_regulation: -0.3589
   Episode_Reward/foot_landing_vel: -0.1236
   Episode_Reward/test_gait_reward: -0.9141
Metrics/base_velocity/error_vel_xy: 1.5339
Metrics/base_velocity/error_vel_yaw: 1.1111
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 1.12s
                        Total time: 1614.25s
                               ETA: 1637.0s

################################################################################
                     [1m Learning iteration 1490/3000 [0m                     

                       Computation: 91668 steps/s (collection: 0.949s, learning 0.124s)
               Value function loss: 0.8261
                    Surrogate loss: -0.0031
             Mean action noise std: 0.6353
                     Learning rate: 0.0009
                       Mean reward: 95.68
               Mean episode length: 965.52
       Episode_Reward/keep_balance: 0.9606
     Episode_Reward/rew_lin_vel_xy: 4.6845
      Episode_Reward/rew_ang_vel_z: 2.6185
    Episode_Reward/pen_base_height: -0.3314
      Episode_Reward/pen_lin_vel_z: -0.0585
     Episode_Reward/pen_ang_vel_xy: -0.1595
   Episode_Reward/pen_joint_torque: -0.1969
    Episode_Reward/pen_joint_accel: -0.0945
    Episode_Reward/pen_action_rate: -0.3250
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0453
   Episode_Reward/pen_joint_powers: -0.0716
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.7236
Episode_Reward/pen_flat_orientation: -0.1198
  Episode_Reward/pen_feet_distance: -0.0146
Episode_Reward/pen_feet_regulation: -0.3630
   Episode_Reward/foot_landing_vel: -0.1296
   Episode_Reward/test_gait_reward: -0.8948
Metrics/base_velocity/error_vel_xy: 1.6807
Metrics/base_velocity/error_vel_yaw: 1.0970
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 1.07s
                        Total time: 1615.32s
                               ETA: 1635.9s

################################################################################
                     [1m Learning iteration 1491/3000 [0m                     

                       Computation: 93012 steps/s (collection: 0.933s, learning 0.124s)
               Value function loss: 0.9629
                    Surrogate loss: -0.0038
             Mean action noise std: 0.6357
                     Learning rate: 0.0013
                       Mean reward: 108.27
               Mean episode length: 993.85
       Episode_Reward/keep_balance: 0.9957
     Episode_Reward/rew_lin_vel_xy: 5.3039
      Episode_Reward/rew_ang_vel_z: 2.7602
    Episode_Reward/pen_base_height: -0.3284
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1575
   Episode_Reward/pen_joint_torque: -0.1959
    Episode_Reward/pen_joint_accel: -0.0922
    Episode_Reward/pen_action_rate: -0.3272
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0708
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7415
Episode_Reward/pen_flat_orientation: -0.1157
  Episode_Reward/pen_feet_distance: -0.0115
Episode_Reward/pen_feet_regulation: -0.3549
   Episode_Reward/foot_landing_vel: -0.1223
   Episode_Reward/test_gait_reward: -0.9214
Metrics/base_velocity/error_vel_xy: 1.4802
Metrics/base_velocity/error_vel_yaw: 1.0890
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 1.06s
                        Total time: 1616.37s
                               ETA: 1634.8s

################################################################################
                     [1m Learning iteration 1492/3000 [0m                     

                       Computation: 92201 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 0.8514
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6352
                     Learning rate: 0.0009
                       Mean reward: 97.87
               Mean episode length: 956.58
       Episode_Reward/keep_balance: 0.9644
     Episode_Reward/rew_lin_vel_xy: 4.8624
      Episode_Reward/rew_ang_vel_z: 2.6930
    Episode_Reward/pen_base_height: -0.3266
      Episode_Reward/pen_lin_vel_z: -0.0561
     Episode_Reward/pen_ang_vel_xy: -0.1605
   Episode_Reward/pen_joint_torque: -0.2015
    Episode_Reward/pen_joint_accel: -0.0862
    Episode_Reward/pen_action_rate: -0.3192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0723
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.7087
Episode_Reward/pen_flat_orientation: -0.1185
  Episode_Reward/pen_feet_distance: -0.0149
Episode_Reward/pen_feet_regulation: -0.3637
   Episode_Reward/foot_landing_vel: -0.1226
   Episode_Reward/test_gait_reward: -0.8945
Metrics/base_velocity/error_vel_xy: 1.5852
Metrics/base_velocity/error_vel_yaw: 1.0463
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 1.07s
                        Total time: 1617.44s
                               ETA: 1633.7s

################################################################################
                     [1m Learning iteration 1493/3000 [0m                     

                       Computation: 93168 steps/s (collection: 0.931s, learning 0.124s)
               Value function loss: 0.9154
                    Surrogate loss: -0.0034
             Mean action noise std: 0.6354
                     Learning rate: 0.0013
                       Mean reward: 101.83
               Mean episode length: 997.14
       Episode_Reward/keep_balance: 0.9960
     Episode_Reward/rew_lin_vel_xy: 4.9567
      Episode_Reward/rew_ang_vel_z: 2.7514
    Episode_Reward/pen_base_height: -0.3398
      Episode_Reward/pen_lin_vel_z: -0.0588
     Episode_Reward/pen_ang_vel_xy: -0.1583
   Episode_Reward/pen_joint_torque: -0.2109
    Episode_Reward/pen_joint_accel: -0.0938
    Episode_Reward/pen_action_rate: -0.3299
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0454
   Episode_Reward/pen_joint_powers: -0.0742
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7373
Episode_Reward/pen_flat_orientation: -0.1130
  Episode_Reward/pen_feet_distance: -0.0127
Episode_Reward/pen_feet_regulation: -0.3638
   Episode_Reward/foot_landing_vel: -0.1232
   Episode_Reward/test_gait_reward: -0.9285
Metrics/base_velocity/error_vel_xy: 1.7088
Metrics/base_velocity/error_vel_yaw: 1.0923
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 1.06s
                        Total time: 1618.50s
                               ETA: 1632.6s

################################################################################
                     [1m Learning iteration 1494/3000 [0m                     

                       Computation: 92429 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 0.9241
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6356
                     Learning rate: 0.0006
                       Mean reward: 99.99
               Mean episode length: 976.22
       Episode_Reward/keep_balance: 0.9728
     Episode_Reward/rew_lin_vel_xy: 4.9724
      Episode_Reward/rew_ang_vel_z: 2.6612
    Episode_Reward/pen_base_height: -0.3474
      Episode_Reward/pen_lin_vel_z: -0.0603
     Episode_Reward/pen_ang_vel_xy: -0.1625
   Episode_Reward/pen_joint_torque: -0.2128
    Episode_Reward/pen_joint_accel: -0.0987
    Episode_Reward/pen_action_rate: -0.3299
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0474
   Episode_Reward/pen_joint_powers: -0.0758
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7273
Episode_Reward/pen_flat_orientation: -0.1235
  Episode_Reward/pen_feet_distance: -0.0120
Episode_Reward/pen_feet_regulation: -0.3929
   Episode_Reward/foot_landing_vel: -0.1337
   Episode_Reward/test_gait_reward: -0.9121
Metrics/base_velocity/error_vel_xy: 1.5851
Metrics/base_velocity/error_vel_yaw: 1.1079
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 1.06s
                        Total time: 1619.56s
                               ETA: 1631.5s

################################################################################
                     [1m Learning iteration 1495/3000 [0m                     

                       Computation: 92184 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 0.9442
                    Surrogate loss: -0.0037
             Mean action noise std: 0.6359
                     Learning rate: 0.0001
                       Mean reward: 101.19
               Mean episode length: 988.58
       Episode_Reward/keep_balance: 0.9960
     Episode_Reward/rew_lin_vel_xy: 4.9674
      Episode_Reward/rew_ang_vel_z: 2.7599
    Episode_Reward/pen_base_height: -0.3309
      Episode_Reward/pen_lin_vel_z: -0.0559
     Episode_Reward/pen_ang_vel_xy: -0.1506
   Episode_Reward/pen_joint_torque: -0.2056
    Episode_Reward/pen_joint_accel: -0.0868
    Episode_Reward/pen_action_rate: -0.3250
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0439
   Episode_Reward/pen_joint_powers: -0.0720
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7258
Episode_Reward/pen_flat_orientation: -0.1063
  Episode_Reward/pen_feet_distance: -0.0137
Episode_Reward/pen_feet_regulation: -0.3559
   Episode_Reward/foot_landing_vel: -0.1188
   Episode_Reward/test_gait_reward: -0.9201
Metrics/base_velocity/error_vel_xy: 1.6686
Metrics/base_velocity/error_vel_yaw: 1.0939
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 1.07s
                        Total time: 1620.63s
                               ETA: 1630.4s

################################################################################
                     [1m Learning iteration 1496/3000 [0m                     

                       Computation: 91324 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.8333
                    Surrogate loss: -0.0031
             Mean action noise std: 0.6359
                     Learning rate: 0.0000
                       Mean reward: 99.06
               Mean episode length: 961.91
       Episode_Reward/keep_balance: 0.9744
     Episode_Reward/rew_lin_vel_xy: 4.9398
      Episode_Reward/rew_ang_vel_z: 2.6800
    Episode_Reward/pen_base_height: -0.3384
      Episode_Reward/pen_lin_vel_z: -0.0581
     Episode_Reward/pen_ang_vel_xy: -0.1647
   Episode_Reward/pen_joint_torque: -0.2041
    Episode_Reward/pen_joint_accel: -0.0896
    Episode_Reward/pen_action_rate: -0.3301
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0456
   Episode_Reward/pen_joint_powers: -0.0739
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7244
Episode_Reward/pen_flat_orientation: -0.1169
  Episode_Reward/pen_feet_distance: -0.0157
Episode_Reward/pen_feet_regulation: -0.3635
   Episode_Reward/foot_landing_vel: -0.1274
   Episode_Reward/test_gait_reward: -0.9107
Metrics/base_velocity/error_vel_xy: 1.6245
Metrics/base_velocity/error_vel_yaw: 1.0931
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 1.08s
                        Total time: 1621.70s
                               ETA: 1629.3s

################################################################################
                     [1m Learning iteration 1497/3000 [0m                     

                       Computation: 90801 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.7879
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6360
                     Learning rate: 0.0001
                       Mean reward: 104.74
               Mean episode length: 969.59
       Episode_Reward/keep_balance: 0.9634
     Episode_Reward/rew_lin_vel_xy: 5.0571
      Episode_Reward/rew_ang_vel_z: 2.6675
    Episode_Reward/pen_base_height: -0.3235
      Episode_Reward/pen_lin_vel_z: -0.0542
     Episode_Reward/pen_ang_vel_xy: -0.1567
   Episode_Reward/pen_joint_torque: -0.1987
    Episode_Reward/pen_joint_accel: -0.0949
    Episode_Reward/pen_action_rate: -0.3178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0442
   Episode_Reward/pen_joint_powers: -0.0711
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7122
Episode_Reward/pen_flat_orientation: -0.1129
  Episode_Reward/pen_feet_distance: -0.0136
Episode_Reward/pen_feet_regulation: -0.3536
   Episode_Reward/foot_landing_vel: -0.1196
   Episode_Reward/test_gait_reward: -0.8965
Metrics/base_velocity/error_vel_xy: 1.4589
Metrics/base_velocity/error_vel_yaw: 1.0545
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 1.08s
                        Total time: 1622.78s
                               ETA: 1628.2s

################################################################################
                     [1m Learning iteration 1498/3000 [0m                     

                       Computation: 91748 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.9513
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6359
                     Learning rate: 0.0003
                       Mean reward: 106.18
               Mean episode length: 990.38
       Episode_Reward/keep_balance: 0.9956
     Episode_Reward/rew_lin_vel_xy: 5.0555
      Episode_Reward/rew_ang_vel_z: 2.7142
    Episode_Reward/pen_base_height: -0.3414
      Episode_Reward/pen_lin_vel_z: -0.0530
     Episode_Reward/pen_ang_vel_xy: -0.1596
   Episode_Reward/pen_joint_torque: -0.2073
    Episode_Reward/pen_joint_accel: -0.0839
    Episode_Reward/pen_action_rate: -0.3288
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0448
   Episode_Reward/pen_joint_powers: -0.0732
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7382
Episode_Reward/pen_flat_orientation: -0.1134
  Episode_Reward/pen_feet_distance: -0.0140
Episode_Reward/pen_feet_regulation: -0.3570
   Episode_Reward/foot_landing_vel: -0.1155
   Episode_Reward/test_gait_reward: -0.9242
Metrics/base_velocity/error_vel_xy: 1.6039
Metrics/base_velocity/error_vel_yaw: 1.1322
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 1.07s
                        Total time: 1623.86s
                               ETA: 1627.1s

################################################################################
                     [1m Learning iteration 1499/3000 [0m                     

                       Computation: 91622 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.9379
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6357
                     Learning rate: 0.0000
                       Mean reward: 103.58
               Mean episode length: 974.21
       Episode_Reward/keep_balance: 0.9782
     Episode_Reward/rew_lin_vel_xy: 5.0442
      Episode_Reward/rew_ang_vel_z: 2.6638
    Episode_Reward/pen_base_height: -0.3387
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.1603
   Episode_Reward/pen_joint_torque: -0.2013
    Episode_Reward/pen_joint_accel: -0.0809
    Episode_Reward/pen_action_rate: -0.3247
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0718
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7280
Episode_Reward/pen_flat_orientation: -0.1210
  Episode_Reward/pen_feet_distance: -0.0113
Episode_Reward/pen_feet_regulation: -0.3695
   Episode_Reward/foot_landing_vel: -0.1195
   Episode_Reward/test_gait_reward: -0.9018
Metrics/base_velocity/error_vel_xy: 1.5466
Metrics/base_velocity/error_vel_yaw: 1.1148
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 1.07s
                        Total time: 1624.93s
                               ETA: 1626.0s

################################################################################
                     [1m Learning iteration 1500/3000 [0m                     

                       Computation: 91496 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.9777
                    Surrogate loss: -0.0034
             Mean action noise std: 0.6354
                     Learning rate: 0.0003
                       Mean reward: 106.18
               Mean episode length: 961.78
       Episode_Reward/keep_balance: 0.9593
     Episode_Reward/rew_lin_vel_xy: 5.2040
      Episode_Reward/rew_ang_vel_z: 2.6427
    Episode_Reward/pen_base_height: -0.3231
      Episode_Reward/pen_lin_vel_z: -0.0531
     Episode_Reward/pen_ang_vel_xy: -0.1509
   Episode_Reward/pen_joint_torque: -0.1934
    Episode_Reward/pen_joint_accel: -0.0871
    Episode_Reward/pen_action_rate: -0.3167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0428
   Episode_Reward/pen_joint_powers: -0.0688
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7086
Episode_Reward/pen_flat_orientation: -0.1116
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.3477
   Episode_Reward/foot_landing_vel: -0.1100
   Episode_Reward/test_gait_reward: -0.8977
Metrics/base_velocity/error_vel_xy: 1.3821
Metrics/base_velocity/error_vel_yaw: 1.0672
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 147554304
                    Iteration time: 1.07s
                        Total time: 1626.00s
                               ETA: 1624.9s

################################################################################
                     [1m Learning iteration 1501/3000 [0m                     

                       Computation: 90313 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.8753
                    Surrogate loss: -0.0047
             Mean action noise std: 0.6343
                     Learning rate: 0.0006
                       Mean reward: 104.08
               Mean episode length: 976.23
       Episode_Reward/keep_balance: 0.9773
     Episode_Reward/rew_lin_vel_xy: 5.1020
      Episode_Reward/rew_ang_vel_z: 2.6879
    Episode_Reward/pen_base_height: -0.3415
      Episode_Reward/pen_lin_vel_z: -0.0541
     Episode_Reward/pen_ang_vel_xy: -0.1584
   Episode_Reward/pen_joint_torque: -0.1984
    Episode_Reward/pen_joint_accel: -0.0900
    Episode_Reward/pen_action_rate: -0.3212
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0445
   Episode_Reward/pen_joint_powers: -0.0709
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7212
Episode_Reward/pen_flat_orientation: -0.1150
  Episode_Reward/pen_feet_distance: -0.0137
Episode_Reward/pen_feet_regulation: -0.3635
   Episode_Reward/foot_landing_vel: -0.1187
   Episode_Reward/test_gait_reward: -0.9075
Metrics/base_velocity/error_vel_xy: 1.4963
Metrics/base_velocity/error_vel_yaw: 1.0928
      Episode_Termination/time_out: 5.0833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147652608
                    Iteration time: 1.09s
                        Total time: 1627.09s
                               ETA: 1623.8s

################################################################################
                     [1m Learning iteration 1502/3000 [0m                     

                       Computation: 89667 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.9256
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6335
                     Learning rate: 0.0004
                       Mean reward: 104.37
               Mean episode length: 972.59
       Episode_Reward/keep_balance: 0.9724
     Episode_Reward/rew_lin_vel_xy: 5.1550
      Episode_Reward/rew_ang_vel_z: 2.6570
    Episode_Reward/pen_base_height: -0.3318
      Episode_Reward/pen_lin_vel_z: -0.0549
     Episode_Reward/pen_ang_vel_xy: -0.1620
   Episode_Reward/pen_joint_torque: -0.1936
    Episode_Reward/pen_joint_accel: -0.0932
    Episode_Reward/pen_action_rate: -0.3258
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0455
   Episode_Reward/pen_joint_powers: -0.0714
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7231
Episode_Reward/pen_flat_orientation: -0.1191
  Episode_Reward/pen_feet_distance: -0.0121
Episode_Reward/pen_feet_regulation: -0.3599
   Episode_Reward/foot_landing_vel: -0.1250
   Episode_Reward/test_gait_reward: -0.9059
Metrics/base_velocity/error_vel_xy: 1.4511
Metrics/base_velocity/error_vel_yaw: 1.1086
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 147750912
                    Iteration time: 1.10s
                        Total time: 1628.19s
                               ETA: 1622.8s

################################################################################
                     [1m Learning iteration 1503/3000 [0m                     

                       Computation: 90487 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 1323640.5000
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6337
                     Learning rate: 0.0000
                       Mean reward: -1225.46
               Mean episode length: 978.07
       Episode_Reward/keep_balance: 0.9795
     Episode_Reward/rew_lin_vel_xy: 5.2741
      Episode_Reward/rew_ang_vel_z: 2.6863
    Episode_Reward/pen_base_height: -0.3515
      Episode_Reward/pen_lin_vel_z: -0.0568
     Episode_Reward/pen_ang_vel_xy: -0.1642
   Episode_Reward/pen_joint_torque: -0.2052
    Episode_Reward/pen_joint_accel: -0.1050
    Episode_Reward/pen_action_rate: -85.2411
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0465
   Episode_Reward/pen_joint_powers: -0.0724
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -8.3793
Episode_Reward/pen_flat_orientation: -0.1176
  Episode_Reward/pen_feet_distance: -0.0144
Episode_Reward/pen_feet_regulation: -0.3665
   Episode_Reward/foot_landing_vel: -0.1352
   Episode_Reward/test_gait_reward: -0.9087
Metrics/base_velocity/error_vel_xy: 1.3956
Metrics/base_velocity/error_vel_yaw: 1.0953
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 147849216
                    Iteration time: 1.09s
                        Total time: 1629.27s
                               ETA: 1621.7s

################################################################################
                     [1m Learning iteration 1504/3000 [0m                     

                       Computation: 90449 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.9358
                    Surrogate loss: -0.0035
             Mean action noise std: 0.6347
                     Learning rate: 0.0002
                       Mean reward: 103.05
               Mean episode length: 979.96
       Episode_Reward/keep_balance: 0.9818
     Episode_Reward/rew_lin_vel_xy: 4.9782
      Episode_Reward/rew_ang_vel_z: 2.6792
    Episode_Reward/pen_base_height: -0.3390
      Episode_Reward/pen_lin_vel_z: -0.0565
     Episode_Reward/pen_ang_vel_xy: -0.1571
   Episode_Reward/pen_joint_torque: -0.2034
    Episode_Reward/pen_joint_accel: -0.0877
    Episode_Reward/pen_action_rate: -0.3276
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0461
   Episode_Reward/pen_joint_powers: -0.0737
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7268
Episode_Reward/pen_flat_orientation: -0.1156
  Episode_Reward/pen_feet_distance: -0.0144
Episode_Reward/pen_feet_regulation: -0.3773
   Episode_Reward/foot_landing_vel: -0.1227
   Episode_Reward/test_gait_reward: -0.9178
Metrics/base_velocity/error_vel_xy: 1.5473
Metrics/base_velocity/error_vel_yaw: 1.1104
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 147947520
                    Iteration time: 1.09s
                        Total time: 1630.36s
                               ETA: 1620.6s

################################################################################
                     [1m Learning iteration 1505/3000 [0m                     

                       Computation: 87654 steps/s (collection: 0.993s, learning 0.129s)
               Value function loss: 1.0582
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6349
                     Learning rate: 0.0000
                       Mean reward: 102.57
               Mean episode length: 974.66
       Episode_Reward/keep_balance: 0.9725
     Episode_Reward/rew_lin_vel_xy: 5.0487
      Episode_Reward/rew_ang_vel_z: 2.6740
    Episode_Reward/pen_base_height: -0.3467
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.1556
   Episode_Reward/pen_joint_torque: -0.2045
    Episode_Reward/pen_joint_accel: -0.0819
    Episode_Reward/pen_action_rate: -0.3514
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0433
   Episode_Reward/pen_joint_powers: -0.0709
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7158
Episode_Reward/pen_flat_orientation: -0.1175
  Episode_Reward/pen_feet_distance: -0.0143
Episode_Reward/pen_feet_regulation: -0.3409
   Episode_Reward/foot_landing_vel: -0.1163
   Episode_Reward/test_gait_reward: -0.9003
Metrics/base_velocity/error_vel_xy: 1.5408
Metrics/base_velocity/error_vel_yaw: 1.0874
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 148045824
                    Iteration time: 1.12s
                        Total time: 1631.48s
                               ETA: 1619.6s

################################################################################
                     [1m Learning iteration 1506/3000 [0m                     

                       Computation: 90732 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.8697
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6348
                     Learning rate: 0.0001
                       Mean reward: 104.13
               Mean episode length: 959.48
       Episode_Reward/keep_balance: 0.9668
     Episode_Reward/rew_lin_vel_xy: 5.1440
      Episode_Reward/rew_ang_vel_z: 2.6098
    Episode_Reward/pen_base_height: -0.3280
      Episode_Reward/pen_lin_vel_z: -0.0518
     Episode_Reward/pen_ang_vel_xy: -0.1643
   Episode_Reward/pen_joint_torque: -0.1970
    Episode_Reward/pen_joint_accel: -0.0928
    Episode_Reward/pen_action_rate: -0.3303
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0459
   Episode_Reward/pen_joint_powers: -0.0716
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.7198
Episode_Reward/pen_flat_orientation: -0.1206
  Episode_Reward/pen_feet_distance: -0.0231
Episode_Reward/pen_feet_regulation: -0.3674
   Episode_Reward/foot_landing_vel: -0.1187
   Episode_Reward/test_gait_reward: -0.9042
Metrics/base_velocity/error_vel_xy: 1.3971
Metrics/base_velocity/error_vel_yaw: 1.1389
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 148144128
                    Iteration time: 1.08s
                        Total time: 1632.57s
                               ETA: 1618.5s

################################################################################
                     [1m Learning iteration 1507/3000 [0m                     

                       Computation: 90774 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.9092
                    Surrogate loss: -0.0035
             Mean action noise std: 0.6346
                     Learning rate: 0.0004
                       Mean reward: 105.95
               Mean episode length: 985.90
       Episode_Reward/keep_balance: 0.9826
     Episode_Reward/rew_lin_vel_xy: 5.2364
      Episode_Reward/rew_ang_vel_z: 2.6956
    Episode_Reward/pen_base_height: -0.3322
      Episode_Reward/pen_lin_vel_z: -0.0541
     Episode_Reward/pen_ang_vel_xy: -0.1553
   Episode_Reward/pen_joint_torque: -0.1979
    Episode_Reward/pen_joint_accel: -0.0909
    Episode_Reward/pen_action_rate: -0.3260
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0455
   Episode_Reward/pen_joint_powers: -0.0715
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.7212
Episode_Reward/pen_flat_orientation: -0.1153
  Episode_Reward/pen_feet_distance: -0.0139
Episode_Reward/pen_feet_regulation: -0.3717
   Episode_Reward/foot_landing_vel: -0.1248
   Episode_Reward/test_gait_reward: -0.9167
Metrics/base_velocity/error_vel_xy: 1.4309
Metrics/base_velocity/error_vel_yaw: 1.0999
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 148242432
                    Iteration time: 1.08s
                        Total time: 1633.65s
                               ETA: 1617.4s

################################################################################
                     [1m Learning iteration 1508/3000 [0m                     

                       Computation: 87832 steps/s (collection: 0.995s, learning 0.124s)
               Value function loss: 0.9758
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6349
                     Learning rate: 0.0000
                       Mean reward: 106.36
               Mean episode length: 977.32
       Episode_Reward/keep_balance: 0.9837
     Episode_Reward/rew_lin_vel_xy: 5.1340
      Episode_Reward/rew_ang_vel_z: 2.7105
    Episode_Reward/pen_base_height: -0.3422
      Episode_Reward/pen_lin_vel_z: -0.0555
     Episode_Reward/pen_ang_vel_xy: -0.1550
   Episode_Reward/pen_joint_torque: -0.2020
    Episode_Reward/pen_joint_accel: -0.0904
    Episode_Reward/pen_action_rate: -0.3323
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0442
   Episode_Reward/pen_joint_powers: -0.0718
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7192
Episode_Reward/pen_flat_orientation: -0.1114
  Episode_Reward/pen_feet_distance: -0.0147
Episode_Reward/pen_feet_regulation: -0.3633
   Episode_Reward/foot_landing_vel: -0.1178
   Episode_Reward/test_gait_reward: -0.9213
Metrics/base_velocity/error_vel_xy: 1.5315
Metrics/base_velocity/error_vel_yaw: 1.0893
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 148340736
                    Iteration time: 1.12s
                        Total time: 1634.77s
                               ETA: 1616.4s

################################################################################
                     [1m Learning iteration 1509/3000 [0m                     

                       Computation: 90705 steps/s (collection: 0.957s, learning 0.126s)
               Value function loss: 0.9095
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6346
                     Learning rate: 0.0000
                       Mean reward: 104.86
               Mean episode length: 970.72
       Episode_Reward/keep_balance: 0.9742
     Episode_Reward/rew_lin_vel_xy: 5.1717
      Episode_Reward/rew_ang_vel_z: 2.6499
    Episode_Reward/pen_base_height: -0.3209
      Episode_Reward/pen_lin_vel_z: -0.0548
     Episode_Reward/pen_ang_vel_xy: -0.1640
   Episode_Reward/pen_joint_torque: -0.1903
    Episode_Reward/pen_joint_accel: -0.0918
    Episode_Reward/pen_action_rate: -0.3200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0456
   Episode_Reward/pen_joint_powers: -0.0716
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7227
Episode_Reward/pen_flat_orientation: -0.1148
  Episode_Reward/pen_feet_distance: -0.0126
Episode_Reward/pen_feet_regulation: -0.3681
   Episode_Reward/foot_landing_vel: -0.1255
   Episode_Reward/test_gait_reward: -0.8959
Metrics/base_velocity/error_vel_xy: 1.4452
Metrics/base_velocity/error_vel_yaw: 1.1102
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 148439040
                    Iteration time: 1.08s
                        Total time: 1635.85s
                               ETA: 1615.3s

################################################################################
                     [1m Learning iteration 1510/3000 [0m                     

                       Computation: 91041 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 2.0383
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6345
                     Learning rate: 0.0000
                       Mean reward: 101.89
               Mean episode length: 989.13
       Episode_Reward/keep_balance: 0.9786
     Episode_Reward/rew_lin_vel_xy: 5.0360
      Episode_Reward/rew_ang_vel_z: 2.6625
    Episode_Reward/pen_base_height: -0.3470
      Episode_Reward/pen_lin_vel_z: -0.0542
     Episode_Reward/pen_ang_vel_xy: -0.1606
   Episode_Reward/pen_joint_torque: -0.2149
    Episode_Reward/pen_joint_accel: -0.0794
    Episode_Reward/pen_action_rate: -0.4833
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0460
   Episode_Reward/pen_joint_powers: -0.0749
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7499
Episode_Reward/pen_flat_orientation: -0.1136
  Episode_Reward/pen_feet_distance: -0.0174
Episode_Reward/pen_feet_regulation: -0.3833
   Episode_Reward/foot_landing_vel: -0.1161
   Episode_Reward/test_gait_reward: -0.9209
Metrics/base_velocity/error_vel_xy: 1.5290
Metrics/base_velocity/error_vel_yaw: 1.1301
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 148537344
                    Iteration time: 1.08s
                        Total time: 1636.93s
                               ETA: 1614.2s

################################################################################
                     [1m Learning iteration 1511/3000 [0m                     

                       Computation: 89339 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 258.4837
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6347
                     Learning rate: 0.0000
                       Mean reward: 92.28
               Mean episode length: 987.53
       Episode_Reward/keep_balance: 0.9775
     Episode_Reward/rew_lin_vel_xy: 5.1628
      Episode_Reward/rew_ang_vel_z: 2.7378
    Episode_Reward/pen_base_height: -0.3367
      Episode_Reward/pen_lin_vel_z: -0.0573
     Episode_Reward/pen_ang_vel_xy: -0.1542
   Episode_Reward/pen_joint_torque: -0.2135
    Episode_Reward/pen_joint_accel: -0.0890
    Episode_Reward/pen_action_rate: -1.0289
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0448
   Episode_Reward/pen_joint_powers: -0.0743
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.8578
Episode_Reward/pen_flat_orientation: -0.1125
  Episode_Reward/pen_feet_distance: -0.0155
Episode_Reward/pen_feet_regulation: -0.3570
   Episode_Reward/foot_landing_vel: -0.1233
   Episode_Reward/test_gait_reward: -0.9136
Metrics/base_velocity/error_vel_xy: 1.5080
Metrics/base_velocity/error_vel_yaw: 1.0538
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 148635648
                    Iteration time: 1.10s
                        Total time: 1638.03s
                               ETA: 1613.1s

################################################################################
                     [1m Learning iteration 1512/3000 [0m                     

                       Computation: 89523 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 957712227.2000
                    Surrogate loss: 0.0044
             Mean action noise std: 0.6348
                     Learning rate: 0.0000
                       Mean reward: -46637.92
               Mean episode length: 973.95
       Episode_Reward/keep_balance: 0.9689
     Episode_Reward/rew_lin_vel_xy: 5.0415
      Episode_Reward/rew_ang_vel_z: 2.6356
    Episode_Reward/pen_base_height: -0.3364
      Episode_Reward/pen_lin_vel_z: -0.0555
     Episode_Reward/pen_ang_vel_xy: -0.1596
   Episode_Reward/pen_joint_torque: -0.2122
    Episode_Reward/pen_joint_accel: -0.0884
    Episode_Reward/pen_action_rate: -1271.8733
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0459
   Episode_Reward/pen_joint_powers: -0.0732
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -279.0722
Episode_Reward/pen_flat_orientation: -0.1215
  Episode_Reward/pen_feet_distance: -0.0176
Episode_Reward/pen_feet_regulation: -0.3665
   Episode_Reward/foot_landing_vel: -0.1289
   Episode_Reward/test_gait_reward: -0.9030
Metrics/base_velocity/error_vel_xy: 1.4656
Metrics/base_velocity/error_vel_yaw: 1.1070
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 148733952
                    Iteration time: 1.10s
                        Total time: 1639.13s
                               ETA: 1612.0s

################################################################################
                     [1m Learning iteration 1513/3000 [0m                     

                       Computation: 90394 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 107947417898726594665512960.0000
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6348
                     Learning rate: 0.0000
                       Mean reward: -11787551165548.94
               Mean episode length: 980.70
       Episode_Reward/keep_balance: 0.9818
     Episode_Reward/rew_lin_vel_xy: 5.1191
      Episode_Reward/rew_ang_vel_z: 2.6750
    Episode_Reward/pen_base_height: -0.3390
      Episode_Reward/pen_lin_vel_z: -0.0553
     Episode_Reward/pen_ang_vel_xy: -0.1621
   Episode_Reward/pen_joint_torque: -0.2133
    Episode_Reward/pen_joint_accel: -0.0836
    Episode_Reward/pen_action_rate: -502433120256.0000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0454
   Episode_Reward/pen_joint_powers: -0.0724
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -111501934592.0000
Episode_Reward/pen_flat_orientation: -0.1183
  Episode_Reward/pen_feet_distance: -0.0124
Episode_Reward/pen_feet_regulation: -0.3701
   Episode_Reward/foot_landing_vel: -0.1195
   Episode_Reward/test_gait_reward: -0.9185
Metrics/base_velocity/error_vel_xy: 1.5176
Metrics/base_velocity/error_vel_yaw: 1.1222
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 148832256
                    Iteration time: 1.09s
                        Total time: 1640.22s
                               ETA: 1611.0s

################################################################################
                     [1m Learning iteration 1514/3000 [0m                     

                       Computation: 88925 steps/s (collection: 0.982s, learning 0.124s)
               Value function loss: 1.4480
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6349
                     Learning rate: 0.0000
                       Mean reward: 107.18
               Mean episode length: 977.77
       Episode_Reward/keep_balance: 0.9744
     Episode_Reward/rew_lin_vel_xy: 5.1697
      Episode_Reward/rew_ang_vel_z: 2.6654
    Episode_Reward/pen_base_height: -0.3325
      Episode_Reward/pen_lin_vel_z: -0.0573
     Episode_Reward/pen_ang_vel_xy: -0.1628
   Episode_Reward/pen_joint_torque: -0.2007
    Episode_Reward/pen_joint_accel: -0.0906
    Episode_Reward/pen_action_rate: -0.3555
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0474
   Episode_Reward/pen_joint_powers: -0.0739
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7300
Episode_Reward/pen_flat_orientation: -0.1184
  Episode_Reward/pen_feet_distance: -0.0157
Episode_Reward/pen_feet_regulation: -0.3905
   Episode_Reward/foot_landing_vel: -0.1275
   Episode_Reward/test_gait_reward: -0.9108
Metrics/base_velocity/error_vel_xy: 1.4494
Metrics/base_velocity/error_vel_yaw: 1.0985
      Episode_Termination/time_out: 5.1667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 148930560
                    Iteration time: 1.11s
                        Total time: 1641.32s
                               ETA: 1609.9s

################################################################################
                     [1m Learning iteration 1515/3000 [0m                     

                       Computation: 90709 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 821601452032.0000
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6349
                     Learning rate: 0.0000
                       Mean reward: -1032299.64
               Mean episode length: 923.71
       Episode_Reward/keep_balance: 0.9029
     Episode_Reward/rew_lin_vel_xy: 4.6788
      Episode_Reward/rew_ang_vel_z: 2.4561
    Episode_Reward/pen_base_height: -0.3202
      Episode_Reward/pen_lin_vel_z: -0.0512
     Episode_Reward/pen_ang_vel_xy: -0.1499
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.0805
    Episode_Reward/pen_action_rate: -57962.1172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0424
   Episode_Reward/pen_joint_powers: -0.0691
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -13741.5039
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0155
Episode_Reward/pen_feet_regulation: -0.3411
   Episode_Reward/foot_landing_vel: -0.1179
   Episode_Reward/test_gait_reward: -0.8375
Metrics/base_velocity/error_vel_xy: 1.4101
Metrics/base_velocity/error_vel_yaw: 1.0477
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 149028864
                    Iteration time: 1.08s
                        Total time: 1642.41s
                               ETA: 1608.8s

################################################################################
                     [1m Learning iteration 1516/3000 [0m                     

                       Computation: 91671 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 6219405910343680.0000
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6349
                     Learning rate: 0.0000
                       Mean reward: -97914599.65
               Mean episode length: 927.68
       Episode_Reward/keep_balance: 0.9160
     Episode_Reward/rew_lin_vel_xy: 4.7277
      Episode_Reward/rew_ang_vel_z: 2.4830
    Episode_Reward/pen_base_height: -0.3339
      Episode_Reward/pen_lin_vel_z: -0.0533
     Episode_Reward/pen_ang_vel_xy: -0.1562
   Episode_Reward/pen_joint_torque: -0.2243
    Episode_Reward/pen_joint_accel: -0.0856
    Episode_Reward/pen_action_rate: -1832717.7500
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0431
   Episode_Reward/pen_joint_powers: -0.0705
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -433965.1875
Episode_Reward/pen_flat_orientation: -0.1170
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.3428
   Episode_Reward/foot_landing_vel: -0.1206
   Episode_Reward/test_gait_reward: -0.8531
Metrics/base_velocity/error_vel_xy: 1.4453
Metrics/base_velocity/error_vel_yaw: 1.0595
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 149127168
                    Iteration time: 1.07s
                        Total time: 1643.48s
                               ETA: 1607.7s

################################################################################
                     [1m Learning iteration 1517/3000 [0m                     

                       Computation: 91006 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 1251795229736960.0000
                    Surrogate loss: 0.0004
             Mean action noise std: 0.6350
                     Learning rate: 0.0000
                       Mean reward: -42491189.58
               Mean episode length: 950.65
       Episode_Reward/keep_balance: 0.9559
     Episode_Reward/rew_lin_vel_xy: 4.9277
      Episode_Reward/rew_ang_vel_z: 2.5884
    Episode_Reward/pen_base_height: -0.3437
      Episode_Reward/pen_lin_vel_z: -0.0556
     Episode_Reward/pen_ang_vel_xy: -0.1564
   Episode_Reward/pen_joint_torque: -0.2183
    Episode_Reward/pen_joint_accel: -0.0843
    Episode_Reward/pen_action_rate: -1789785.0000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0451
   Episode_Reward/pen_joint_powers: -0.0730
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -423300.2188
Episode_Reward/pen_flat_orientation: -0.1184
  Episode_Reward/pen_feet_distance: -0.0136
Episode_Reward/pen_feet_regulation: -0.3618
   Episode_Reward/foot_landing_vel: -0.1194
   Episode_Reward/test_gait_reward: -0.8944
Metrics/base_velocity/error_vel_xy: 1.4806
Metrics/base_velocity/error_vel_yaw: 1.1100
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 149225472
                    Iteration time: 1.08s
                        Total time: 1644.56s
                               ETA: 1606.6s

################################################################################
                     [1m Learning iteration 1518/3000 [0m                     

                       Computation: 92457 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 302689117265723392.0000
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6350
                     Learning rate: 0.0000
                       Mean reward: -755531519.24
               Mean episode length: 973.75
       Episode_Reward/keep_balance: 0.9816
     Episode_Reward/rew_lin_vel_xy: 5.1670
      Episode_Reward/rew_ang_vel_z: 2.6906
    Episode_Reward/pen_base_height: -0.3237
      Episode_Reward/pen_lin_vel_z: -0.0529
     Episode_Reward/pen_ang_vel_xy: -0.1521
   Episode_Reward/pen_joint_torque: -0.2052
    Episode_Reward/pen_joint_accel: -0.0841
    Episode_Reward/pen_action_rate: -21269650.0000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0442
   Episode_Reward/pen_joint_powers: -0.0707
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -4964088.0000
Episode_Reward/pen_flat_orientation: -0.1128
  Episode_Reward/pen_feet_distance: -0.0111
Episode_Reward/pen_feet_regulation: -0.3386
   Episode_Reward/foot_landing_vel: -0.1258
   Episode_Reward/test_gait_reward: -0.9055
Metrics/base_velocity/error_vel_xy: 1.4486
Metrics/base_velocity/error_vel_yaw: 1.1092
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 149323776
                    Iteration time: 1.06s
                        Total time: 1645.62s
                               ETA: 1605.5s

################################################################################
                     [1m Learning iteration 1519/3000 [0m                     

                       Computation: 89444 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 2836260921.6000
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6351
                     Learning rate: 0.0000
                       Mean reward: -68929.45
               Mean episode length: 977.24
       Episode_Reward/keep_balance: 0.9832
     Episode_Reward/rew_lin_vel_xy: 5.1185
      Episode_Reward/rew_ang_vel_z: 2.6613
    Episode_Reward/pen_base_height: -0.3360
      Episode_Reward/pen_lin_vel_z: -0.0521
     Episode_Reward/pen_ang_vel_xy: -0.1621
   Episode_Reward/pen_joint_torque: -0.2045
    Episode_Reward/pen_joint_accel: -0.0886
    Episode_Reward/pen_action_rate: -1955.8589
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0719
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -442.1725
Episode_Reward/pen_flat_orientation: -0.1160
  Episode_Reward/pen_feet_distance: -0.0157
Episode_Reward/pen_feet_regulation: -0.3680
   Episode_Reward/foot_landing_vel: -0.1245
   Episode_Reward/test_gait_reward: -0.9142
Metrics/base_velocity/error_vel_xy: 1.4563
Metrics/base_velocity/error_vel_yaw: 1.1383
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 149422080
                    Iteration time: 1.10s
                        Total time: 1646.72s
                               ETA: 1604.5s

################################################################################
                     [1m Learning iteration 1520/3000 [0m                     

                       Computation: 90674 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 518891230.4000
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6352
                     Learning rate: 0.0000
                       Mean reward: 92.64
               Mean episode length: 959.88
       Episode_Reward/keep_balance: 0.9551
     Episode_Reward/rew_lin_vel_xy: 5.0087
      Episode_Reward/rew_ang_vel_z: 2.5744
    Episode_Reward/pen_base_height: -0.3291
      Episode_Reward/pen_lin_vel_z: -0.0538
     Episode_Reward/pen_ang_vel_xy: -0.1594
   Episode_Reward/pen_joint_torque: -0.1961
    Episode_Reward/pen_joint_accel: -0.0900
    Episode_Reward/pen_action_rate: -54.4592
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0459
   Episode_Reward/pen_joint_powers: -0.0710
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -12.8802
Episode_Reward/pen_flat_orientation: -0.1241
  Episode_Reward/pen_feet_distance: -0.0115
Episode_Reward/pen_feet_regulation: -0.3644
   Episode_Reward/foot_landing_vel: -0.1262
   Episode_Reward/test_gait_reward: -0.8889
Metrics/base_velocity/error_vel_xy: 1.4054
Metrics/base_velocity/error_vel_yaw: 1.1194
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 149520384
                    Iteration time: 1.08s
                        Total time: 1647.81s
                               ETA: 1603.4s

################################################################################
                     [1m Learning iteration 1521/3000 [0m                     

                       Computation: 92856 steps/s (collection: 0.936s, learning 0.123s)
               Value function loss: 91863788814364.4219
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6353
                     Learning rate: 0.0000
                       Mean reward: -15348724.88
               Mean episode length: 962.00
       Episode_Reward/keep_balance: 0.9595
     Episode_Reward/rew_lin_vel_xy: 5.1212
      Episode_Reward/rew_ang_vel_z: 2.6320
    Episode_Reward/pen_base_height: -0.3260
      Episode_Reward/pen_lin_vel_z: -0.0531
     Episode_Reward/pen_ang_vel_xy: -0.1553
   Episode_Reward/pen_joint_torque: -0.2109
    Episode_Reward/pen_joint_accel: -0.0932
    Episode_Reward/pen_action_rate: -868070.9375
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0455
   Episode_Reward/pen_joint_powers: -0.0714
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -197820.2812
Episode_Reward/pen_flat_orientation: -0.1151
  Episode_Reward/pen_feet_distance: -0.0153
Episode_Reward/pen_feet_regulation: -0.3588
   Episode_Reward/foot_landing_vel: -0.1307
   Episode_Reward/test_gait_reward: -0.8946
Metrics/base_velocity/error_vel_xy: 1.3823
Metrics/base_velocity/error_vel_yaw: 1.0823
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 149618688
                    Iteration time: 1.06s
                        Total time: 1648.87s
                               ETA: 1602.3s

################################################################################
                     [1m Learning iteration 1522/3000 [0m                     

                       Computation: 90348 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.9459
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6354
                     Learning rate: 0.0000
                       Mean reward: 105.19
               Mean episode length: 967.69
       Episode_Reward/keep_balance: 0.9626
     Episode_Reward/rew_lin_vel_xy: 5.0149
      Episode_Reward/rew_ang_vel_z: 2.6401
    Episode_Reward/pen_base_height: -0.3466
      Episode_Reward/pen_lin_vel_z: -0.0541
     Episode_Reward/pen_ang_vel_xy: -0.1541
   Episode_Reward/pen_joint_torque: -0.2025
    Episode_Reward/pen_joint_accel: -0.0813
    Episode_Reward/pen_action_rate: -0.3469
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0445
   Episode_Reward/pen_joint_powers: -0.0721
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7073
Episode_Reward/pen_flat_orientation: -0.1163
  Episode_Reward/pen_feet_distance: -0.0176
Episode_Reward/pen_feet_regulation: -0.3677
   Episode_Reward/foot_landing_vel: -0.1196
   Episode_Reward/test_gait_reward: -0.8960
Metrics/base_velocity/error_vel_xy: 1.4842
Metrics/base_velocity/error_vel_yaw: 1.0820
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 149716992
                    Iteration time: 1.09s
                        Total time: 1649.95s
                               ETA: 1601.2s

################################################################################
                     [1m Learning iteration 1523/3000 [0m                     

                       Computation: 91058 steps/s (collection: 0.955s, learning 0.125s)
               Value function loss: 727.3672
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6355
                     Learning rate: 0.0000
                       Mean reward: 74.37
               Mean episode length: 985.66
       Episode_Reward/keep_balance: 0.9866
     Episode_Reward/rew_lin_vel_xy: 5.3522
      Episode_Reward/rew_ang_vel_z: 2.7041
    Episode_Reward/pen_base_height: -0.3341
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.1558
   Episode_Reward/pen_joint_torque: -0.1946
    Episode_Reward/pen_joint_accel: -0.0976
    Episode_Reward/pen_action_rate: -1.3994
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0453
   Episode_Reward/pen_joint_powers: -0.0709
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.9678
Episode_Reward/pen_flat_orientation: -0.1094
  Episode_Reward/pen_feet_distance: -0.0128
Episode_Reward/pen_feet_regulation: -0.3597
   Episode_Reward/foot_landing_vel: -0.1320
   Episode_Reward/test_gait_reward: -0.9264
Metrics/base_velocity/error_vel_xy: 1.3666
Metrics/base_velocity/error_vel_yaw: 1.1153
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 149815296
                    Iteration time: 1.08s
                        Total time: 1651.03s
                               ETA: 1600.1s

################################################################################
                     [1m Learning iteration 1524/3000 [0m                     

                       Computation: 91824 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 5153334414540.7998
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6356
                     Learning rate: 0.0000
                       Mean reward: -2774646.93
               Mean episode length: 940.99
       Episode_Reward/keep_balance: 0.9352
     Episode_Reward/rew_lin_vel_xy: 4.7646
      Episode_Reward/rew_ang_vel_z: 2.5106
    Episode_Reward/pen_base_height: -0.3408
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.1614
   Episode_Reward/pen_joint_torque: -0.2135
    Episode_Reward/pen_joint_accel: -0.0848
    Episode_Reward/pen_action_rate: -95131.9609
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0468
   Episode_Reward/pen_joint_powers: -0.0732
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -20483.5391
Episode_Reward/pen_flat_orientation: -0.1181
  Episode_Reward/pen_feet_distance: -0.0216
Episode_Reward/pen_feet_regulation: -0.3748
   Episode_Reward/foot_landing_vel: -0.1280
   Episode_Reward/test_gait_reward: -0.8794
Metrics/base_velocity/error_vel_xy: 1.4689
Metrics/base_velocity/error_vel_yaw: 1.1053
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 149913600
                    Iteration time: 1.07s
                        Total time: 1652.10s
                               ETA: 1599.0s

################################################################################
                     [1m Learning iteration 1525/3000 [0m                     

                       Computation: 92620 steps/s (collection: 0.938s, learning 0.124s)
               Value function loss: 43317.4826
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6357
                     Learning rate: 0.0000
                       Mean reward: -152.99
               Mean episode length: 982.10
       Episode_Reward/keep_balance: 0.9790
     Episode_Reward/rew_lin_vel_xy: 5.2316
      Episode_Reward/rew_ang_vel_z: 2.6823
    Episode_Reward/pen_base_height: -0.3519
      Episode_Reward/pen_lin_vel_z: -0.0549
     Episode_Reward/pen_ang_vel_xy: -0.1578
   Episode_Reward/pen_joint_torque: -0.2122
    Episode_Reward/pen_joint_accel: -0.0921
    Episode_Reward/pen_action_rate: -9.5255
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0460
   Episode_Reward/pen_joint_powers: -0.0739
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -2.7057
Episode_Reward/pen_flat_orientation: -0.1194
  Episode_Reward/pen_feet_distance: -0.0195
Episode_Reward/pen_feet_regulation: -0.3719
   Episode_Reward/foot_landing_vel: -0.1225
   Episode_Reward/test_gait_reward: -0.9142
Metrics/base_velocity/error_vel_xy: 1.4081
Metrics/base_velocity/error_vel_yaw: 1.1064
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 150011904
                    Iteration time: 1.06s
                        Total time: 1653.16s
                               ETA: 1597.9s

################################################################################
                     [1m Learning iteration 1526/3000 [0m                     

                       Computation: 92133 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 1115926.7344
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6358
                     Learning rate: 0.0000
                       Mean reward: -1120.56
               Mean episode length: 954.83
       Episode_Reward/keep_balance: 0.9654
     Episode_Reward/rew_lin_vel_xy: 5.1112
      Episode_Reward/rew_ang_vel_z: 2.6291
    Episode_Reward/pen_base_height: -0.3417
      Episode_Reward/pen_lin_vel_z: -0.0569
     Episode_Reward/pen_ang_vel_xy: -0.1622
   Episode_Reward/pen_joint_torque: -0.2023
    Episode_Reward/pen_joint_accel: -0.0915
    Episode_Reward/pen_action_rate: -24.1249
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0466
   Episode_Reward/pen_joint_powers: -0.0730
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -5.8498
Episode_Reward/pen_flat_orientation: -0.1154
  Episode_Reward/pen_feet_distance: -0.0130
Episode_Reward/pen_feet_regulation: -0.3804
   Episode_Reward/foot_landing_vel: -0.1307
   Episode_Reward/test_gait_reward: -0.9031
Metrics/base_velocity/error_vel_xy: 1.4395
Metrics/base_velocity/error_vel_yaw: 1.0996
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 150110208
                    Iteration time: 1.07s
                        Total time: 1654.23s
                               ETA: 1596.8s

################################################################################
                     [1m Learning iteration 1527/3000 [0m                     

                       Computation: 91041 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 4004932818567168.0000
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6359
                     Learning rate: 0.0000
                       Mean reward: -444.89
               Mean episode length: 959.82
       Episode_Reward/keep_balance: 0.9662
     Episode_Reward/rew_lin_vel_xy: 4.9532
      Episode_Reward/rew_ang_vel_z: 2.6486
    Episode_Reward/pen_base_height: -0.3437
      Episode_Reward/pen_lin_vel_z: -0.0529
     Episode_Reward/pen_ang_vel_xy: -0.1559
   Episode_Reward/pen_joint_torque: -0.2050
    Episode_Reward/pen_joint_accel: -0.0943
    Episode_Reward/pen_action_rate: -19.0906
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0453
   Episode_Reward/pen_joint_powers: -0.0713
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -4.7742
Episode_Reward/pen_flat_orientation: -0.1135
  Episode_Reward/pen_feet_distance: -0.0164
Episode_Reward/pen_feet_regulation: -0.3526
   Episode_Reward/foot_landing_vel: -0.1266
   Episode_Reward/test_gait_reward: -0.8955
Metrics/base_velocity/error_vel_xy: 1.5351
Metrics/base_velocity/error_vel_yaw: 1.0878
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 150208512
                    Iteration time: 1.08s
                        Total time: 1655.31s
                               ETA: 1595.7s

################################################################################
                     [1m Learning iteration 1528/3000 [0m                     

                       Computation: 93039 steps/s (collection: 0.933s, learning 0.123s)
               Value function loss: 1696425511599542.7500
                    Surrogate loss: -0.0006
             Mean action noise std: 0.6362
                     Learning rate: 0.0000
                       Mean reward: -200348796.03
               Mean episode length: 967.44
       Episode_Reward/keep_balance: 0.9665
     Episode_Reward/rew_lin_vel_xy: 4.9759
      Episode_Reward/rew_ang_vel_z: 2.6196
    Episode_Reward/pen_base_height: -0.3382
      Episode_Reward/pen_lin_vel_z: -0.0555
     Episode_Reward/pen_ang_vel_xy: -0.1666
   Episode_Reward/pen_joint_torque: -0.2157
    Episode_Reward/pen_joint_accel: -0.0945
    Episode_Reward/pen_action_rate: -6857225.0000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0476
   Episode_Reward/pen_joint_powers: -0.0748
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -1490648.2500
Episode_Reward/pen_flat_orientation: -0.1261
  Episode_Reward/pen_feet_distance: -0.0162
Episode_Reward/pen_feet_regulation: -0.3740
   Episode_Reward/foot_landing_vel: -0.1290
   Episode_Reward/test_gait_reward: -0.9045
Metrics/base_velocity/error_vel_xy: 1.5265
Metrics/base_velocity/error_vel_yaw: 1.1182
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 150306816
                    Iteration time: 1.06s
                        Total time: 1656.37s
                               ETA: 1594.6s

################################################################################
                     [1m Learning iteration 1529/3000 [0m                     

                       Computation: 93706 steps/s (collection: 0.927s, learning 0.122s)
               Value function loss: 83335.4358
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6380
                     Learning rate: 0.0000
                       Mean reward: -592.00
               Mean episode length: 977.74
       Episode_Reward/keep_balance: 0.9704
     Episode_Reward/rew_lin_vel_xy: 5.0898
      Episode_Reward/rew_ang_vel_z: 2.6474
    Episode_Reward/pen_base_height: -0.3363
      Episode_Reward/pen_lin_vel_z: -0.0531
     Episode_Reward/pen_ang_vel_xy: -0.1568
   Episode_Reward/pen_joint_torque: -0.2056
    Episode_Reward/pen_joint_accel: -0.0910
    Episode_Reward/pen_action_rate: -40.0555
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0723
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -9.3418
Episode_Reward/pen_flat_orientation: -0.1122
  Episode_Reward/pen_feet_distance: -0.0128
Episode_Reward/pen_feet_regulation: -0.3567
   Episode_Reward/foot_landing_vel: -0.1299
   Episode_Reward/test_gait_reward: -0.9035
Metrics/base_velocity/error_vel_xy: 1.4635
Metrics/base_velocity/error_vel_yaw: 1.1102
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 150405120
                    Iteration time: 1.05s
                        Total time: 1657.42s
                               ETA: 1593.5s

################################################################################
                     [1m Learning iteration 1530/3000 [0m                     

                       Computation: 93282 steps/s (collection: 0.932s, learning 0.122s)
               Value function loss: 12629.9267
                    Surrogate loss: -0.0012
             Mean action noise std: 0.6383
                     Learning rate: 0.0000
                       Mean reward: -86.38
               Mean episode length: 977.83
       Episode_Reward/keep_balance: 0.9870
     Episode_Reward/rew_lin_vel_xy: 5.1731
      Episode_Reward/rew_ang_vel_z: 2.6900
    Episode_Reward/pen_base_height: -0.3567
      Episode_Reward/pen_lin_vel_z: -0.0547
     Episode_Reward/pen_ang_vel_xy: -0.1622
   Episode_Reward/pen_joint_torque: -0.1951
    Episode_Reward/pen_joint_accel: -0.0888
    Episode_Reward/pen_action_rate: -4.9826
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0467
   Episode_Reward/pen_joint_powers: -0.0724
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -1.7396
Episode_Reward/pen_flat_orientation: -0.1177
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.3747
   Episode_Reward/foot_landing_vel: -0.1282
   Episode_Reward/test_gait_reward: -0.9219
Metrics/base_velocity/error_vel_xy: 1.4976
Metrics/base_velocity/error_vel_yaw: 1.1226
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 150503424
                    Iteration time: 1.05s
                        Total time: 1658.47s
                               ETA: 1592.4s

################################################################################
                     [1m Learning iteration 1531/3000 [0m                     

                       Computation: 92775 steps/s (collection: 0.935s, learning 0.124s)
               Value function loss: 8345740132745216.0000
                    Surrogate loss: -0.0006
             Mean action noise std: 0.6384
                     Learning rate: 0.0000
                       Mean reward: -106018571.15
               Mean episode length: 952.92
       Episode_Reward/keep_balance: 0.9667
     Episode_Reward/rew_lin_vel_xy: 4.9253
      Episode_Reward/rew_ang_vel_z: 2.6129
    Episode_Reward/pen_base_height: -0.3456
      Episode_Reward/pen_lin_vel_z: -0.0551
     Episode_Reward/pen_ang_vel_xy: -0.1575
   Episode_Reward/pen_joint_torque: -0.2080
    Episode_Reward/pen_joint_accel: -0.0962
    Episode_Reward/pen_action_rate: -2980647.7500
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0468
   Episode_Reward/pen_joint_powers: -0.0729
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -700557.4375
Episode_Reward/pen_flat_orientation: -0.1169
  Episode_Reward/pen_feet_distance: -0.0141
Episode_Reward/pen_feet_regulation: -0.3758
   Episode_Reward/foot_landing_vel: -0.1263
   Episode_Reward/test_gait_reward: -0.9089
Metrics/base_velocity/error_vel_xy: 1.5182
Metrics/base_velocity/error_vel_yaw: 1.1254
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 150601728
                    Iteration time: 1.06s
                        Total time: 1659.53s
                               ETA: 1591.3s

################################################################################
                     [1m Learning iteration 1532/3000 [0m                     

                       Computation: 90921 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 110814.5996
                    Surrogate loss: 0.0006
             Mean action noise std: 0.6384
                     Learning rate: 0.0000
                       Mean reward: -492.80
               Mean episode length: 966.41
       Episode_Reward/keep_balance: 0.9628
     Episode_Reward/rew_lin_vel_xy: 4.9602
      Episode_Reward/rew_ang_vel_z: 2.6233
    Episode_Reward/pen_base_height: -0.3211
      Episode_Reward/pen_lin_vel_z: -0.0524
     Episode_Reward/pen_ang_vel_xy: -0.1539
   Episode_Reward/pen_joint_torque: -0.2069
    Episode_Reward/pen_joint_accel: -0.0901
    Episode_Reward/pen_action_rate: -18.3935
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0444
   Episode_Reward/pen_joint_powers: -0.0712
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -4.9738
Episode_Reward/pen_flat_orientation: -0.1089
  Episode_Reward/pen_feet_distance: -0.0123
Episode_Reward/pen_feet_regulation: -0.3515
   Episode_Reward/foot_landing_vel: -0.1235
   Episode_Reward/test_gait_reward: -0.8868
Metrics/base_velocity/error_vel_xy: 1.4744
Metrics/base_velocity/error_vel_yaw: 1.0999
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 150700032
                    Iteration time: 1.08s
                        Total time: 1660.61s
                               ETA: 1590.2s

################################################################################
                     [1m Learning iteration 1533/3000 [0m                     

                       Computation: 91896 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 51215.1265
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6385
                     Learning rate: 0.0000
                       Mean reward: -308.93
               Mean episode length: 982.17
       Episode_Reward/keep_balance: 0.9815
     Episode_Reward/rew_lin_vel_xy: 5.1829
      Episode_Reward/rew_ang_vel_z: 2.6753
    Episode_Reward/pen_base_height: -0.3386
      Episode_Reward/pen_lin_vel_z: -0.0521
     Episode_Reward/pen_ang_vel_xy: -0.1579
   Episode_Reward/pen_joint_torque: -0.2071
    Episode_Reward/pen_joint_accel: -0.0890
    Episode_Reward/pen_action_rate: -24.6440
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0463
   Episode_Reward/pen_joint_powers: -0.0716
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -6.4136
Episode_Reward/pen_flat_orientation: -0.1239
  Episode_Reward/pen_feet_distance: -0.0174
Episode_Reward/pen_feet_regulation: -0.3787
   Episode_Reward/foot_landing_vel: -0.1202
   Episode_Reward/test_gait_reward: -0.9159
Metrics/base_velocity/error_vel_xy: 1.4355
Metrics/base_velocity/error_vel_yaw: 1.1235
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 150798336
                    Iteration time: 1.07s
                        Total time: 1661.68s
                               ETA: 1589.1s

################################################################################
                     [1m Learning iteration 1534/3000 [0m                     

                       Computation: 90731 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 78.5945
                    Surrogate loss: -0.0012
             Mean action noise std: 0.6390
                     Learning rate: 0.0001
                       Mean reward: 68.83
               Mean episode length: 942.76
       Episode_Reward/keep_balance: 0.9545
     Episode_Reward/rew_lin_vel_xy: 4.9285
      Episode_Reward/rew_ang_vel_z: 2.6133
    Episode_Reward/pen_base_height: -0.3363
      Episode_Reward/pen_lin_vel_z: -0.0518
     Episode_Reward/pen_ang_vel_xy: -0.1577
   Episode_Reward/pen_joint_torque: -0.2148
    Episode_Reward/pen_joint_accel: -0.0808
    Episode_Reward/pen_action_rate: -1.4929
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0448
   Episode_Reward/pen_joint_powers: -0.0727
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.9696
Episode_Reward/pen_flat_orientation: -0.1157
  Episode_Reward/pen_feet_distance: -0.0179
Episode_Reward/pen_feet_regulation: -0.3627
   Episode_Reward/foot_landing_vel: -0.1237
   Episode_Reward/test_gait_reward: -0.8905
Metrics/base_velocity/error_vel_xy: 1.4923
Metrics/base_velocity/error_vel_yaw: 1.0835
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 150896640
                    Iteration time: 1.08s
                        Total time: 1662.76s
                               ETA: 1588.0s

################################################################################
                     [1m Learning iteration 1535/3000 [0m                     

                       Computation: 91702 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 6.7795
                    Surrogate loss: 0.0001
             Mean action noise std: 0.6394
                     Learning rate: 0.0000
                       Mean reward: 101.63
               Mean episode length: 958.93
       Episode_Reward/keep_balance: 0.9524
     Episode_Reward/rew_lin_vel_xy: 5.0855
      Episode_Reward/rew_ang_vel_z: 2.6339
    Episode_Reward/pen_base_height: -0.3328
      Episode_Reward/pen_lin_vel_z: -0.0547
     Episode_Reward/pen_ang_vel_xy: -0.1489
   Episode_Reward/pen_joint_torque: -0.2047
    Episode_Reward/pen_joint_accel: -0.0886
    Episode_Reward/pen_action_rate: -0.4478
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0449
   Episode_Reward/pen_joint_powers: -0.0724
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.7253
Episode_Reward/pen_flat_orientation: -0.1159
  Episode_Reward/pen_feet_distance: -0.0189
Episode_Reward/pen_feet_regulation: -0.3551
   Episode_Reward/foot_landing_vel: -0.1241
   Episode_Reward/test_gait_reward: -0.8928
Metrics/base_velocity/error_vel_xy: 1.3825
Metrics/base_velocity/error_vel_yaw: 1.0606
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 150994944
                    Iteration time: 1.07s
                        Total time: 1663.84s
                               ETA: 1586.9s

################################################################################
                     [1m Learning iteration 1536/3000 [0m                     

                       Computation: 91253 steps/s (collection: 0.956s, learning 0.121s)
               Value function loss: 55815472320007112753152.0000
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6394
                     Learning rate: 0.0000
                       Mean reward: -264613272587.57
               Mean episode length: 952.13
       Episode_Reward/keep_balance: 0.9607
     Episode_Reward/rew_lin_vel_xy: 5.0172
      Episode_Reward/rew_ang_vel_z: 2.6160
    Episode_Reward/pen_base_height: -0.3474
      Episode_Reward/pen_lin_vel_z: -0.0550
     Episode_Reward/pen_ang_vel_xy: -0.1543
   Episode_Reward/pen_joint_torque: -0.2200
    Episode_Reward/pen_joint_accel: -0.0912
    Episode_Reward/pen_action_rate: -14543125504.0000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0456
   Episode_Reward/pen_joint_powers: -0.0724
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -3832797696.0000
Episode_Reward/pen_flat_orientation: -0.1178
  Episode_Reward/pen_feet_distance: -0.0179
Episode_Reward/pen_feet_regulation: -0.3680
   Episode_Reward/foot_landing_vel: -0.1258
   Episode_Reward/test_gait_reward: -0.9060
Metrics/base_velocity/error_vel_xy: 1.4602
Metrics/base_velocity/error_vel_yaw: 1.1031
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 151093248
                    Iteration time: 1.08s
                        Total time: 1664.91s
                               ETA: 1585.8s

################################################################################
                     [1m Learning iteration 1537/3000 [0m                     

                       Computation: 91220 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 288593812315.2000
                    Surrogate loss: -0.0006
             Mean action noise std: 0.6395
                     Learning rate: 0.0000
                       Mean reward: -264615725928.66
               Mean episode length: 951.26
       Episode_Reward/keep_balance: 0.9575
     Episode_Reward/rew_lin_vel_xy: 5.1456
      Episode_Reward/rew_ang_vel_z: 2.6119
    Episode_Reward/pen_base_height: -0.3368
      Episode_Reward/pen_lin_vel_z: -0.0526
     Episode_Reward/pen_ang_vel_xy: -0.1478
   Episode_Reward/pen_joint_torque: -0.2164
    Episode_Reward/pen_joint_accel: -0.0873
    Episode_Reward/pen_action_rate: -67958.0625
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0719
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -17947.7461
Episode_Reward/pen_flat_orientation: -0.1081
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.3582
   Episode_Reward/foot_landing_vel: -0.1271
   Episode_Reward/test_gait_reward: -0.9018
Metrics/base_velocity/error_vel_xy: 1.4046
Metrics/base_velocity/error_vel_yaw: 1.0922
      Episode_Termination/time_out: 3.1250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 151191552
                    Iteration time: 1.08s
                        Total time: 1665.99s
                               ETA: 1584.8s

################################################################################
                     [1m Learning iteration 1538/3000 [0m                     

                       Computation: 92136 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 22.8613
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6408
                     Learning rate: 0.0001
                       Mean reward: 108.76
               Mean episode length: 996.51
       Episode_Reward/keep_balance: 0.9970
     Episode_Reward/rew_lin_vel_xy: 5.3319
      Episode_Reward/rew_ang_vel_z: 2.7261
    Episode_Reward/pen_base_height: -0.3213
      Episode_Reward/pen_lin_vel_z: -0.0517
     Episode_Reward/pen_ang_vel_xy: -0.1616
   Episode_Reward/pen_joint_torque: -0.1972
    Episode_Reward/pen_joint_accel: -0.0934
    Episode_Reward/pen_action_rate: -0.3286
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0460
   Episode_Reward/pen_joint_powers: -0.0726
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7332
Episode_Reward/pen_flat_orientation: -0.1099
  Episode_Reward/pen_feet_distance: -0.0159
Episode_Reward/pen_feet_regulation: -0.3580
   Episode_Reward/foot_landing_vel: -0.1240
   Episode_Reward/test_gait_reward: -0.9305
Metrics/base_velocity/error_vel_xy: 1.4300
Metrics/base_velocity/error_vel_yaw: 1.1251
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 151289856
                    Iteration time: 1.07s
                        Total time: 1667.06s
                               ETA: 1583.7s

################################################################################
                     [1m Learning iteration 1539/3000 [0m                     

                       Computation: 90409 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 144.8672
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6416
                     Learning rate: 0.0000
                       Mean reward: 68.33
               Mean episode length: 984.29
       Episode_Reward/keep_balance: 0.9848
     Episode_Reward/rew_lin_vel_xy: 5.0738
      Episode_Reward/rew_ang_vel_z: 2.6700
    Episode_Reward/pen_base_height: -0.3472
      Episode_Reward/pen_lin_vel_z: -0.0543
     Episode_Reward/pen_ang_vel_xy: -0.1620
   Episode_Reward/pen_joint_torque: -0.2054
    Episode_Reward/pen_joint_accel: -0.0936
    Episode_Reward/pen_action_rate: -1.8113
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0474
   Episode_Reward/pen_joint_powers: -0.0738
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -1.0969
Episode_Reward/pen_flat_orientation: -0.1186
  Episode_Reward/pen_feet_distance: -0.0188
Episode_Reward/pen_feet_regulation: -0.3746
   Episode_Reward/foot_landing_vel: -0.1302
   Episode_Reward/test_gait_reward: -0.9176
Metrics/base_velocity/error_vel_xy: 1.5306
Metrics/base_velocity/error_vel_yaw: 1.1292
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 151388160
                    Iteration time: 1.09s
                        Total time: 1668.15s
                               ETA: 1582.6s

################################################################################
                     [1m Learning iteration 1540/3000 [0m                     

                       Computation: 90863 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 35191266406.4000
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6417
                     Learning rate: 0.0000
                       Mean reward: -219966.72
               Mean episode length: 965.22
       Episode_Reward/keep_balance: 0.9609
     Episode_Reward/rew_lin_vel_xy: 5.0056
      Episode_Reward/rew_ang_vel_z: 2.5856
    Episode_Reward/pen_base_height: -0.3508
      Episode_Reward/pen_lin_vel_z: -0.0549
     Episode_Reward/pen_ang_vel_xy: -0.1643
   Episode_Reward/pen_joint_torque: -0.2253
    Episode_Reward/pen_joint_accel: -0.0897
    Episode_Reward/pen_action_rate: -9189.9180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0484
   Episode_Reward/pen_joint_powers: -0.0759
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -2273.2351
Episode_Reward/pen_flat_orientation: -0.1216
  Episode_Reward/pen_feet_distance: -0.0131
Episode_Reward/pen_feet_regulation: -0.3994
   Episode_Reward/foot_landing_vel: -0.1293
   Episode_Reward/test_gait_reward: -0.9074
Metrics/base_velocity/error_vel_xy: 1.4460
Metrics/base_velocity/error_vel_yaw: 1.1308
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 151486464
                    Iteration time: 1.08s
                        Total time: 1669.23s
                               ETA: 1581.5s

################################################################################
                     [1m Learning iteration 1541/3000 [0m                     

                       Computation: 91339 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 11690797107.9498
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6417
                     Learning rate: 0.0000
                       Mean reward: -172468.28
               Mean episode length: 975.79
       Episode_Reward/keep_balance: 0.9833
     Episode_Reward/rew_lin_vel_xy: 5.2936
      Episode_Reward/rew_ang_vel_z: 2.6463
    Episode_Reward/pen_base_height: -0.3379
      Episode_Reward/pen_lin_vel_z: -0.0515
     Episode_Reward/pen_ang_vel_xy: -0.1563
   Episode_Reward/pen_joint_torque: -0.2032
    Episode_Reward/pen_joint_accel: -0.0894
    Episode_Reward/pen_action_rate: -9646.8623
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0461
   Episode_Reward/pen_joint_powers: -0.0716
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -2338.3745
Episode_Reward/pen_flat_orientation: -0.1185
  Episode_Reward/pen_feet_distance: -0.0151
Episode_Reward/pen_feet_regulation: -0.3806
   Episode_Reward/foot_landing_vel: -0.1196
   Episode_Reward/test_gait_reward: -0.9221
Metrics/base_velocity/error_vel_xy: 1.3762
Metrics/base_velocity/error_vel_yaw: 1.1483
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 151584768
                    Iteration time: 1.08s
                        Total time: 1670.30s
                               ETA: 1580.4s

################################################################################
                     [1m Learning iteration 1542/3000 [0m                     

                       Computation: 91745 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 26.4271
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6423
                     Learning rate: 0.0000
                       Mean reward: 105.74
               Mean episode length: 985.76
       Episode_Reward/keep_balance: 0.9872
     Episode_Reward/rew_lin_vel_xy: 5.2590
      Episode_Reward/rew_ang_vel_z: 2.6813
    Episode_Reward/pen_base_height: -0.3357
      Episode_Reward/pen_lin_vel_z: -0.0523
     Episode_Reward/pen_ang_vel_xy: -0.1560
   Episode_Reward/pen_joint_torque: -0.1966
    Episode_Reward/pen_joint_accel: -0.0914
    Episode_Reward/pen_action_rate: -0.4299
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0459
   Episode_Reward/pen_joint_powers: -0.0714
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7580
Episode_Reward/pen_flat_orientation: -0.1155
  Episode_Reward/pen_feet_distance: -0.0167
Episode_Reward/pen_feet_regulation: -0.3713
   Episode_Reward/foot_landing_vel: -0.1223
   Episode_Reward/test_gait_reward: -0.9191
Metrics/base_velocity/error_vel_xy: 1.4056
Metrics/base_velocity/error_vel_yaw: 1.1288
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 151683072
                    Iteration time: 1.07s
                        Total time: 1671.38s
                               ETA: 1579.3s

################################################################################
                     [1m Learning iteration 1543/3000 [0m                     

                       Computation: 89608 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 2852229456.0000
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6424
                     Learning rate: 0.0000
                       Mean reward: -97551.14
               Mean episode length: 927.83
       Episode_Reward/keep_balance: 0.9395
     Episode_Reward/rew_lin_vel_xy: 5.1147
      Episode_Reward/rew_ang_vel_z: 2.5562
    Episode_Reward/pen_base_height: -0.3323
      Episode_Reward/pen_lin_vel_z: -0.0501
     Episode_Reward/pen_ang_vel_xy: -0.1572
   Episode_Reward/pen_joint_torque: -0.2022
    Episode_Reward/pen_joint_accel: -0.0838
    Episode_Reward/pen_action_rate: -1681.8909
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0442
   Episode_Reward/pen_joint_powers: -0.0706
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -424.8346
Episode_Reward/pen_flat_orientation: -0.1153
  Episode_Reward/pen_feet_distance: -0.0172
Episode_Reward/pen_feet_regulation: -0.3434
   Episode_Reward/foot_landing_vel: -0.1191
   Episode_Reward/test_gait_reward: -0.8810
Metrics/base_velocity/error_vel_xy: 1.3124
Metrics/base_velocity/error_vel_yaw: 1.0862
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 151781376
                    Iteration time: 1.10s
                        Total time: 1672.47s
                               ETA: 1578.2s

################################################################################
                     [1m Learning iteration 1544/3000 [0m                     

                       Computation: 91568 steps/s (collection: 0.950s, learning 0.124s)
               Value function loss: 211074.7387
                    Surrogate loss: -0.0010
             Mean action noise std: 0.6424
                     Learning rate: 0.0000
                       Mean reward: 103.89
               Mean episode length: 972.02
       Episode_Reward/keep_balance: 0.9816
     Episode_Reward/rew_lin_vel_xy: 5.3247
      Episode_Reward/rew_ang_vel_z: 2.6896
    Episode_Reward/pen_base_height: -0.3312
      Episode_Reward/pen_lin_vel_z: -0.0555
     Episode_Reward/pen_ang_vel_xy: -0.1565
   Episode_Reward/pen_joint_torque: -0.1949
    Episode_Reward/pen_joint_accel: -0.0935
    Episode_Reward/pen_action_rate: -0.3906
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0460
   Episode_Reward/pen_joint_powers: -0.0714
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7468
Episode_Reward/pen_flat_orientation: -0.1143
  Episode_Reward/pen_feet_distance: -0.0121
Episode_Reward/pen_feet_regulation: -0.3733
   Episode_Reward/foot_landing_vel: -0.1298
   Episode_Reward/test_gait_reward: -0.9221
Metrics/base_velocity/error_vel_xy: 1.3960
Metrics/base_velocity/error_vel_yaw: 1.1059
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 151879680
                    Iteration time: 1.07s
                        Total time: 1673.55s
                               ETA: 1577.1s

################################################################################
                     [1m Learning iteration 1545/3000 [0m                     

                       Computation: 91857 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 6188408998.4000
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6425
                     Learning rate: 0.0000
                       Mean reward: -95299.72
               Mean episode length: 950.22
       Episode_Reward/keep_balance: 0.9298
     Episode_Reward/rew_lin_vel_xy: 5.0575
      Episode_Reward/rew_ang_vel_z: 2.5336
    Episode_Reward/pen_base_height: -0.3344
      Episode_Reward/pen_lin_vel_z: -0.0524
     Episode_Reward/pen_ang_vel_xy: -0.1574
   Episode_Reward/pen_joint_torque: -0.2282
    Episode_Reward/pen_joint_accel: -0.0938
    Episode_Reward/pen_action_rate: -3931.2341
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0459
   Episode_Reward/pen_joint_powers: -0.0732
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -1021.2577
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0156
Episode_Reward/pen_feet_regulation: -0.3558
   Episode_Reward/foot_landing_vel: -0.1251
   Episode_Reward/test_gait_reward: -0.8775
Metrics/base_velocity/error_vel_xy: 1.2638
Metrics/base_velocity/error_vel_yaw: 1.0602
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 151977984
                    Iteration time: 1.07s
                        Total time: 1674.62s
                               ETA: 1576.0s

################################################################################
                     [1m Learning iteration 1546/3000 [0m                     

                       Computation: 90533 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 2102.7714
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6425
                     Learning rate: 0.0000
                       Mean reward: 82.02
               Mean episode length: 971.75
       Episode_Reward/keep_balance: 0.9740
     Episode_Reward/rew_lin_vel_xy: 5.2677
      Episode_Reward/rew_ang_vel_z: 2.6743
    Episode_Reward/pen_base_height: -0.3267
      Episode_Reward/pen_lin_vel_z: -0.0534
     Episode_Reward/pen_ang_vel_xy: -0.1499
   Episode_Reward/pen_joint_torque: -0.1975
    Episode_Reward/pen_joint_accel: -0.0884
    Episode_Reward/pen_action_rate: -1.3421
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0445
   Episode_Reward/pen_joint_powers: -0.0701
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.9815
Episode_Reward/pen_flat_orientation: -0.1132
  Episode_Reward/pen_feet_distance: -0.0147
Episode_Reward/pen_feet_regulation: -0.3599
   Episode_Reward/foot_landing_vel: -0.1257
   Episode_Reward/test_gait_reward: -0.9077
Metrics/base_velocity/error_vel_xy: 1.3709
Metrics/base_velocity/error_vel_yaw: 1.0901
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 152076288
                    Iteration time: 1.09s
                        Total time: 1675.70s
                               ETA: 1575.0s

################################################################################
                     [1m Learning iteration 1547/3000 [0m                     

                       Computation: 90137 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 14900195229696.0000
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6425
                     Learning rate: 0.0000
                       Mean reward: -5093763.25
               Mean episode length: 961.83
       Episode_Reward/keep_balance: 0.9674
     Episode_Reward/rew_lin_vel_xy: 5.2238
      Episode_Reward/rew_ang_vel_z: 2.6239
    Episode_Reward/pen_base_height: -0.3487
      Episode_Reward/pen_lin_vel_z: -0.0532
     Episode_Reward/pen_ang_vel_xy: -0.1530
   Episode_Reward/pen_joint_torque: -0.2027
    Episode_Reward/pen_joint_accel: -0.0869
    Episode_Reward/pen_action_rate: -92626.2500
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0455
   Episode_Reward/pen_joint_powers: -0.0722
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -25288.4414
Episode_Reward/pen_flat_orientation: -0.1141
  Episode_Reward/pen_feet_distance: -0.0173
Episode_Reward/pen_feet_regulation: -0.3665
   Episode_Reward/foot_landing_vel: -0.1168
   Episode_Reward/test_gait_reward: -0.9063
Metrics/base_velocity/error_vel_xy: 1.3670
Metrics/base_velocity/error_vel_yaw: 1.1149
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 152174592
                    Iteration time: 1.09s
                        Total time: 1676.79s
                               ETA: 1573.9s

################################################################################
                     [1m Learning iteration 1548/3000 [0m                     

                       Computation: 91793 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 11183634304.0000
                    Surrogate loss: 0.0001
             Mean action noise std: 0.6426
                     Learning rate: 0.0000
                       Mean reward: -13343.87
               Mean episode length: 967.38
       Episode_Reward/keep_balance: 0.9714
     Episode_Reward/rew_lin_vel_xy: 5.0767
      Episode_Reward/rew_ang_vel_z: 2.6487
    Episode_Reward/pen_base_height: -0.3533
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.1583
   Episode_Reward/pen_joint_torque: -0.2063
    Episode_Reward/pen_joint_accel: -0.0937
    Episode_Reward/pen_action_rate: -366.7339
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0465
   Episode_Reward/pen_joint_powers: -0.0730
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -101.5845
Episode_Reward/pen_flat_orientation: -0.1228
  Episode_Reward/pen_feet_distance: -0.0185
Episode_Reward/pen_feet_regulation: -0.3786
   Episode_Reward/foot_landing_vel: -0.1238
   Episode_Reward/test_gait_reward: -0.9132
Metrics/base_velocity/error_vel_xy: 1.4624
Metrics/base_velocity/error_vel_yaw: 1.1071
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 152272896
                    Iteration time: 1.07s
                        Total time: 1677.86s
                               ETA: 1572.8s

################################################################################
                     [1m Learning iteration 1549/3000 [0m                     

                       Computation: 91124 steps/s (collection: 0.954s, learning 0.125s)
               Value function loss: 11106107166220615680.0000
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6426
                     Learning rate: 0.0000
                       Mean reward: -3985817471.11
               Mean episode length: 940.05
       Episode_Reward/keep_balance: 0.9463
     Episode_Reward/rew_lin_vel_xy: 5.0614
      Episode_Reward/rew_ang_vel_z: 2.5548
    Episode_Reward/pen_base_height: -0.3190
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.1477
   Episode_Reward/pen_joint_torque: -0.2052
    Episode_Reward/pen_joint_accel: -0.0924
    Episode_Reward/pen_action_rate: -81571960.0000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0446
   Episode_Reward/pen_joint_powers: -0.0697
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -22236548.0000
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0092
Episode_Reward/pen_feet_regulation: -0.3628
   Episode_Reward/foot_landing_vel: -0.1172
   Episode_Reward/test_gait_reward: -0.8927
Metrics/base_velocity/error_vel_xy: 1.3679
Metrics/base_velocity/error_vel_yaw: 1.0988
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 152371200
                    Iteration time: 1.08s
                        Total time: 1678.94s
                               ETA: 1571.7s

################################################################################
                     [1m Learning iteration 1550/3000 [0m                     

                       Computation: 89657 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 125182733363.2000
                    Surrogate loss: -0.0012
             Mean action noise std: 0.6426
                     Learning rate: 0.0000
                       Mean reward: -107922.96
               Mean episode length: 963.04
       Episode_Reward/keep_balance: 0.9609
     Episode_Reward/rew_lin_vel_xy: 5.0986
      Episode_Reward/rew_ang_vel_z: 2.5994
    Episode_Reward/pen_base_height: -0.3302
      Episode_Reward/pen_lin_vel_z: -0.0530
     Episode_Reward/pen_ang_vel_xy: -0.1616
   Episode_Reward/pen_joint_torque: -0.2005
    Episode_Reward/pen_joint_accel: -0.0872
    Episode_Reward/pen_action_rate: -35294.1172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0461
   Episode_Reward/pen_joint_powers: -0.0716
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -9454.2051
Episode_Reward/pen_flat_orientation: -0.1182
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.3753
   Episode_Reward/foot_landing_vel: -0.1232
   Episode_Reward/test_gait_reward: -0.9036
Metrics/base_velocity/error_vel_xy: 1.3849
Metrics/base_velocity/error_vel_yaw: 1.1058
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 152469504
                    Iteration time: 1.10s
                        Total time: 1680.04s
                               ETA: 1570.6s

################################################################################
                     [1m Learning iteration 1551/3000 [0m                     

                       Computation: 88462 steps/s (collection: 0.985s, learning 0.127s)
               Value function loss: 13685.2369
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6435
                     Learning rate: 0.0001
                       Mean reward: -107.69
               Mean episode length: 960.65
       Episode_Reward/keep_balance: 0.9696
     Episode_Reward/rew_lin_vel_xy: 5.0985
      Episode_Reward/rew_ang_vel_z: 2.5913
    Episode_Reward/pen_base_height: -0.3322
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.1562
   Episode_Reward/pen_joint_torque: -0.2011
    Episode_Reward/pen_joint_accel: -0.0939
    Episode_Reward/pen_action_rate: -11.0710
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0473
   Episode_Reward/pen_joint_powers: -0.0728
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -3.6161
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0162
Episode_Reward/pen_feet_regulation: -0.3833
   Episode_Reward/foot_landing_vel: -0.1291
   Episode_Reward/test_gait_reward: -0.9057
Metrics/base_velocity/error_vel_xy: 1.4691
Metrics/base_velocity/error_vel_yaw: 1.1486
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 152567808
                    Iteration time: 1.11s
                        Total time: 1681.15s
                               ETA: 1569.6s

################################################################################
                     [1m Learning iteration 1552/3000 [0m                     

                       Computation: 89080 steps/s (collection: 0.977s, learning 0.127s)
               Value function loss: 266611.0527
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6439
                     Learning rate: 0.0000
                       Mean reward: -514.96
               Mean episode length: 975.47
       Episode_Reward/keep_balance: 0.9645
     Episode_Reward/rew_lin_vel_xy: 5.1758
      Episode_Reward/rew_ang_vel_z: 2.6513
    Episode_Reward/pen_base_height: -0.3291
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.1523
   Episode_Reward/pen_joint_torque: -0.2155
    Episode_Reward/pen_joint_accel: -0.0842
    Episode_Reward/pen_action_rate: -17.6669
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0442
   Episode_Reward/pen_joint_powers: -0.0724
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -5.3324
Episode_Reward/pen_flat_orientation: -0.1074
  Episode_Reward/pen_feet_distance: -0.0169
Episode_Reward/pen_feet_regulation: -0.3497
   Episode_Reward/foot_landing_vel: -0.1142
   Episode_Reward/test_gait_reward: -0.8977
Metrics/base_velocity/error_vel_xy: 1.3667
Metrics/base_velocity/error_vel_yaw: 1.0849
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 152666112
                    Iteration time: 1.10s
                        Total time: 1682.25s
                               ETA: 1568.5s

################################################################################
                     [1m Learning iteration 1553/3000 [0m                     

                       Computation: 91428 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 15.4033
                    Surrogate loss: -0.0003
             Mean action noise std: 0.6444
                     Learning rate: 0.0001
                       Mean reward: 60.68
               Mean episode length: 964.17
       Episode_Reward/keep_balance: 0.9338
     Episode_Reward/rew_lin_vel_xy: 4.9342
      Episode_Reward/rew_ang_vel_z: 2.5283
    Episode_Reward/pen_base_height: -0.3089
      Episode_Reward/pen_lin_vel_z: -0.0512
     Episode_Reward/pen_ang_vel_xy: -0.1533
   Episode_Reward/pen_joint_torque: -0.2017
    Episode_Reward/pen_joint_accel: -0.0834
    Episode_Reward/pen_action_rate: -7.8734
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0453
   Episode_Reward/pen_joint_powers: -0.0718
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -2.4988
Episode_Reward/pen_flat_orientation: -0.1140
  Episode_Reward/pen_feet_distance: -0.0152
Episode_Reward/pen_feet_regulation: -0.3575
   Episode_Reward/foot_landing_vel: -0.1275
   Episode_Reward/test_gait_reward: -0.8647
Metrics/base_velocity/error_vel_xy: 1.3395
Metrics/base_velocity/error_vel_yaw: 1.0899
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 152764416
                    Iteration time: 1.08s
                        Total time: 1683.33s
                               ETA: 1567.4s

################################################################################
                     [1m Learning iteration 1554/3000 [0m                     

                       Computation: 90647 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 9730.8339
                    Surrogate loss: -0.0006
             Mean action noise std: 0.6447
                     Learning rate: 0.0000
                       Mean reward: -15.23
               Mean episode length: 993.04
       Episode_Reward/keep_balance: 0.9906
     Episode_Reward/rew_lin_vel_xy: 5.3253
      Episode_Reward/rew_ang_vel_z: 2.7066
    Episode_Reward/pen_base_height: -0.3368
      Episode_Reward/pen_lin_vel_z: -0.0571
     Episode_Reward/pen_ang_vel_xy: -0.1638
   Episode_Reward/pen_joint_torque: -0.2122
    Episode_Reward/pen_joint_accel: -0.0886
    Episode_Reward/pen_action_rate: -3.2501
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0475
   Episode_Reward/pen_joint_powers: -0.0753
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -1.4733
Episode_Reward/pen_flat_orientation: -0.1188
  Episode_Reward/pen_feet_distance: -0.0140
Episode_Reward/pen_feet_regulation: -0.3821
   Episode_Reward/foot_landing_vel: -0.1290
   Episode_Reward/test_gait_reward: -0.9278
Metrics/base_velocity/error_vel_xy: 1.3822
Metrics/base_velocity/error_vel_yaw: 1.1250
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 152862720
                    Iteration time: 1.08s
                        Total time: 1684.41s
                               ETA: 1566.3s

################################################################################
                     [1m Learning iteration 1555/3000 [0m                     

                       Computation: 90636 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 87640405494988.7969
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6448
                     Learning rate: 0.0000
                       Mean reward: -14083.38
               Mean episode length: 970.98
       Episode_Reward/keep_balance: 0.9734
     Episode_Reward/rew_lin_vel_xy: 5.1574
      Episode_Reward/rew_ang_vel_z: 2.6136
    Episode_Reward/pen_base_height: -0.3441
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1644
   Episode_Reward/pen_joint_torque: -0.2032
    Episode_Reward/pen_joint_accel: -0.0938
    Episode_Reward/pen_action_rate: -458.5405
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0484
   Episode_Reward/pen_joint_powers: -0.0740
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -133.8398
Episode_Reward/pen_flat_orientation: -0.1210
  Episode_Reward/pen_feet_distance: -0.0148
Episode_Reward/pen_feet_regulation: -0.3972
   Episode_Reward/foot_landing_vel: -0.1331
   Episode_Reward/test_gait_reward: -0.9154
Metrics/base_velocity/error_vel_xy: 1.4061
Metrics/base_velocity/error_vel_yaw: 1.1477
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 152961024
                    Iteration time: 1.08s
                        Total time: 1685.50s
                               ETA: 1565.3s

################################################################################
                     [1m Learning iteration 1556/3000 [0m                     

                       Computation: 91319 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 738839369691271936.0000
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6448
                     Learning rate: 0.0000
                       Mean reward: -1617391219.80
               Mean episode length: 977.58
       Episode_Reward/keep_balance: 0.9819
     Episode_Reward/rew_lin_vel_xy: 5.1318
      Episode_Reward/rew_ang_vel_z: 2.6639
    Episode_Reward/pen_base_height: -0.3289
      Episode_Reward/pen_lin_vel_z: -0.0516
     Episode_Reward/pen_ang_vel_xy: -0.1604
   Episode_Reward/pen_joint_torque: -0.2124
    Episode_Reward/pen_joint_accel: -0.0887
    Episode_Reward/pen_action_rate: -52193400.0000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0485
   Episode_Reward/pen_joint_powers: -0.0738
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -15197928.0000
Episode_Reward/pen_flat_orientation: -0.1198
  Episode_Reward/pen_feet_distance: -0.0135
Episode_Reward/pen_feet_regulation: -0.3968
   Episode_Reward/foot_landing_vel: -0.1342
   Episode_Reward/test_gait_reward: -0.9098
Metrics/base_velocity/error_vel_xy: 1.4591
Metrics/base_velocity/error_vel_yaw: 1.1318
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 153059328
                    Iteration time: 1.08s
                        Total time: 1686.57s
                               ETA: 1564.2s

################################################################################
                     [1m Learning iteration 1557/3000 [0m                     

                       Computation: 91151 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 9976135841.1992
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6452
                     Learning rate: 0.0000
                       Mean reward: -219403.25
               Mean episode length: 967.42
       Episode_Reward/keep_balance: 0.9668
     Episode_Reward/rew_lin_vel_xy: 4.9962
      Episode_Reward/rew_ang_vel_z: 2.6232
    Episode_Reward/pen_base_height: -0.3536
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1575
   Episode_Reward/pen_joint_torque: -0.2136
    Episode_Reward/pen_joint_accel: -0.0864
    Episode_Reward/pen_action_rate: -4428.9268
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0464
   Episode_Reward/pen_joint_powers: -0.0741
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -1291.3934
Episode_Reward/pen_flat_orientation: -0.1177
  Episode_Reward/pen_feet_distance: -0.0169
Episode_Reward/pen_feet_regulation: -0.3869
   Episode_Reward/foot_landing_vel: -0.1299
   Episode_Reward/test_gait_reward: -0.9140
Metrics/base_velocity/error_vel_xy: 1.5221
Metrics/base_velocity/error_vel_yaw: 1.1189
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 153157632
                    Iteration time: 1.08s
                        Total time: 1687.65s
                               ETA: 1563.1s

################################################################################
                     [1m Learning iteration 1558/3000 [0m                     

                       Computation: 90722 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 1.3825
                    Surrogate loss: -0.0037
             Mean action noise std: 0.6465
                     Learning rate: 0.0002
                       Mean reward: 106.49
               Mean episode length: 984.72
       Episode_Reward/keep_balance: 0.9896
     Episode_Reward/rew_lin_vel_xy: 5.2691
      Episode_Reward/rew_ang_vel_z: 2.6735
    Episode_Reward/pen_base_height: -0.3336
      Episode_Reward/pen_lin_vel_z: -0.0566
     Episode_Reward/pen_ang_vel_xy: -0.1635
   Episode_Reward/pen_joint_torque: -0.2055
    Episode_Reward/pen_joint_accel: -0.0917
    Episode_Reward/pen_action_rate: -0.3356
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0476
   Episode_Reward/pen_joint_powers: -0.0747
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.7436
Episode_Reward/pen_flat_orientation: -0.1118
  Episode_Reward/pen_feet_distance: -0.0177
Episode_Reward/pen_feet_regulation: -0.3790
   Episode_Reward/foot_landing_vel: -0.1364
   Episode_Reward/test_gait_reward: -0.9303
Metrics/base_velocity/error_vel_xy: 1.4746
Metrics/base_velocity/error_vel_yaw: 1.1434
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 153255936
                    Iteration time: 1.08s
                        Total time: 1688.74s
                               ETA: 1562.0s

################################################################################
                     [1m Learning iteration 1559/3000 [0m                     

                       Computation: 91233 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 246229559736249876480.0000
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6466
                     Learning rate: 0.0000
                       Mean reward: -17610891490.47
               Mean episode length: 987.84
       Episode_Reward/keep_balance: 0.9806
     Episode_Reward/rew_lin_vel_xy: 5.1168
      Episode_Reward/rew_ang_vel_z: 2.6362
    Episode_Reward/pen_base_height: -0.3391
      Episode_Reward/pen_lin_vel_z: -0.0559
     Episode_Reward/pen_ang_vel_xy: -0.1563
   Episode_Reward/pen_joint_torque: -0.2235
    Episode_Reward/pen_joint_accel: -0.0912
    Episode_Reward/pen_action_rate: -1424026112.0000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0483
   Episode_Reward/pen_joint_powers: -0.0753
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -410441984.0000
Episode_Reward/pen_flat_orientation: -0.1149
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.3964
   Episode_Reward/foot_landing_vel: -0.1352
   Episode_Reward/test_gait_reward: -0.9218
Metrics/base_velocity/error_vel_xy: 1.4738
Metrics/base_velocity/error_vel_yaw: 1.1494
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 153354240
                    Iteration time: 1.08s
                        Total time: 1689.81s
                               ETA: 1560.9s

################################################################################
                     [1m Learning iteration 1560/3000 [0m                     

                       Computation: 89415 steps/s (collection: 0.977s, learning 0.122s)
               Value function loss: 414170552.0000
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6467
                     Learning rate: 0.0000
                       Mean reward: -17610916375.57
               Mean episode length: 948.95
       Episode_Reward/keep_balance: 0.9194
     Episode_Reward/rew_lin_vel_xy: 4.7566
      Episode_Reward/rew_ang_vel_z: 2.5084
    Episode_Reward/pen_base_height: -0.3274
      Episode_Reward/pen_lin_vel_z: -0.0525
     Episode_Reward/pen_ang_vel_xy: -0.1514
   Episode_Reward/pen_joint_torque: -0.2063
    Episode_Reward/pen_joint_accel: -0.0859
    Episode_Reward/pen_action_rate: -892.9562
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0456
   Episode_Reward/pen_joint_powers: -0.0708
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -257.5630
Episode_Reward/pen_flat_orientation: -0.1229
  Episode_Reward/pen_feet_distance: -0.0160
Episode_Reward/pen_feet_regulation: -0.3610
   Episode_Reward/foot_landing_vel: -0.1263
   Episode_Reward/test_gait_reward: -0.8609
Metrics/base_velocity/error_vel_xy: 1.3920
Metrics/base_velocity/error_vel_yaw: 1.0662
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 153452544
                    Iteration time: 1.10s
                        Total time: 1690.91s
                               ETA: 1559.8s

################################################################################
                     [1m Learning iteration 1561/3000 [0m                     

                       Computation: 92007 steps/s (collection: 0.945s, learning 0.124s)
               Value function loss: 122.2399
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6472
                     Learning rate: 0.0000
                       Mean reward: 97.84
               Mean episode length: 966.14
       Episode_Reward/keep_balance: 0.9702
     Episode_Reward/rew_lin_vel_xy: 5.1587
      Episode_Reward/rew_ang_vel_z: 2.6334
    Episode_Reward/pen_base_height: -0.3255
      Episode_Reward/pen_lin_vel_z: -0.0527
     Episode_Reward/pen_ang_vel_xy: -0.1592
   Episode_Reward/pen_joint_torque: -0.2010
    Episode_Reward/pen_joint_accel: -0.0924
    Episode_Reward/pen_action_rate: -0.5931
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0463
   Episode_Reward/pen_joint_powers: -0.0721
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.8071
Episode_Reward/pen_flat_orientation: -0.1118
  Episode_Reward/pen_feet_distance: -0.0148
Episode_Reward/pen_feet_regulation: -0.3665
   Episode_Reward/foot_landing_vel: -0.1317
   Episode_Reward/test_gait_reward: -0.9066
Metrics/base_velocity/error_vel_xy: 1.4136
Metrics/base_velocity/error_vel_yaw: 1.1116
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 153550848
                    Iteration time: 1.07s
                        Total time: 1691.98s
                               ETA: 1558.7s

################################################################################
                     [1m Learning iteration 1562/3000 [0m                     

                       Computation: 92957 steps/s (collection: 0.935s, learning 0.123s)
               Value function loss: 24196472635392.0000
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6473
                     Learning rate: 0.0000
                       Mean reward: -6039335.00
               Mean episode length: 973.48
       Episode_Reward/keep_balance: 0.9755
     Episode_Reward/rew_lin_vel_xy: 5.2028
      Episode_Reward/rew_ang_vel_z: 2.6280
    Episode_Reward/pen_base_height: -0.3199
      Episode_Reward/pen_lin_vel_z: -0.0517
     Episode_Reward/pen_ang_vel_xy: -0.1574
   Episode_Reward/pen_joint_torque: -0.2103
    Episode_Reward/pen_joint_accel: -0.0934
    Episode_Reward/pen_action_rate: -481349.8125
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0465
   Episode_Reward/pen_joint_powers: -0.0716
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -147755.6406
Episode_Reward/pen_flat_orientation: -0.1130
  Episode_Reward/pen_feet_distance: -0.0132
Episode_Reward/pen_feet_regulation: -0.3701
   Episode_Reward/foot_landing_vel: -0.1287
   Episode_Reward/test_gait_reward: -0.9093
Metrics/base_velocity/error_vel_xy: 1.3862
Metrics/base_velocity/error_vel_yaw: 1.1342
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 153649152
                    Iteration time: 1.06s
                        Total time: 1693.04s
                               ETA: 1557.6s

################################################################################
                     [1m Learning iteration 1563/3000 [0m                     

                       Computation: 91434 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 15804387150976512.0000
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6473
                     Learning rate: 0.0000
                       Mean reward: -145455915.30
               Mean episode length: 964.35
       Episode_Reward/keep_balance: 0.9655
     Episode_Reward/rew_lin_vel_xy: 5.1938
      Episode_Reward/rew_ang_vel_z: 2.6264
    Episode_Reward/pen_base_height: -0.3351
      Episode_Reward/pen_lin_vel_z: -0.0551
     Episode_Reward/pen_ang_vel_xy: -0.1595
   Episode_Reward/pen_joint_torque: -0.2130
    Episode_Reward/pen_joint_accel: -0.1002
    Episode_Reward/pen_action_rate: -4639398.5000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0486
   Episode_Reward/pen_joint_powers: -0.0740
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -1423839.5000
Episode_Reward/pen_flat_orientation: -0.1170
  Episode_Reward/pen_feet_distance: -0.0148
Episode_Reward/pen_feet_regulation: -0.3939
   Episode_Reward/foot_landing_vel: -0.1411
   Episode_Reward/test_gait_reward: -0.9078
Metrics/base_velocity/error_vel_xy: 1.4041
Metrics/base_velocity/error_vel_yaw: 1.1044
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 153747456
                    Iteration time: 1.08s
                        Total time: 1694.11s
                               ETA: 1556.5s

################################################################################
                     [1m Learning iteration 1564/3000 [0m                     

                       Computation: 92216 steps/s (collection: 0.941s, learning 0.125s)
               Value function loss: 68929506.7000
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6474
                     Learning rate: 0.0000
                       Mean reward: -12408.03
               Mean episode length: 986.48
       Episode_Reward/keep_balance: 0.9891
     Episode_Reward/rew_lin_vel_xy: 5.2344
      Episode_Reward/rew_ang_vel_z: 2.7147
    Episode_Reward/pen_base_height: -0.3356
      Episode_Reward/pen_lin_vel_z: -0.0522
     Episode_Reward/pen_ang_vel_xy: -0.1496
   Episode_Reward/pen_joint_torque: -0.2074
    Episode_Reward/pen_joint_accel: -0.0896
    Episode_Reward/pen_action_rate: -382.9267
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0452
   Episode_Reward/pen_joint_powers: -0.0720
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -118.2019
Episode_Reward/pen_flat_orientation: -0.1128
  Episode_Reward/pen_feet_distance: -0.0201
Episode_Reward/pen_feet_regulation: -0.3596
   Episode_Reward/foot_landing_vel: -0.1290
   Episode_Reward/test_gait_reward: -0.9219
Metrics/base_velocity/error_vel_xy: 1.5114
Metrics/base_velocity/error_vel_yaw: 1.1074
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 153845760
                    Iteration time: 1.07s
                        Total time: 1695.18s
                               ETA: 1555.5s

################################################################################
                     [1m Learning iteration 1565/3000 [0m                     

                       Computation: 92290 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 137140000260096.0000
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6474
                     Learning rate: 0.0000
                       Mean reward: -14988868.97
               Mean episode length: 976.02
       Episode_Reward/keep_balance: 0.9756
     Episode_Reward/rew_lin_vel_xy: 5.2241
      Episode_Reward/rew_ang_vel_z: 2.6204
    Episode_Reward/pen_base_height: -0.3557
      Episode_Reward/pen_lin_vel_z: -0.0529
     Episode_Reward/pen_ang_vel_xy: -0.1641
   Episode_Reward/pen_joint_torque: -0.2135
    Episode_Reward/pen_joint_accel: -0.0919
    Episode_Reward/pen_action_rate: -600041.7500
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0475
   Episode_Reward/pen_joint_powers: -0.0737
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -180639.0625
Episode_Reward/pen_flat_orientation: -0.1213
  Episode_Reward/pen_feet_distance: -0.0156
Episode_Reward/pen_feet_regulation: -0.3877
   Episode_Reward/foot_landing_vel: -0.1280
   Episode_Reward/test_gait_reward: -0.9223
Metrics/base_velocity/error_vel_xy: 1.4354
Metrics/base_velocity/error_vel_yaw: 1.1545
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 153944064
                    Iteration time: 1.07s
                        Total time: 1696.25s
                               ETA: 1554.4s

################################################################################
                     [1m Learning iteration 1566/3000 [0m                     

                       Computation: 91783 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 857706546810385858560.0000
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6474
                     Learning rate: 0.0000
                       Mean reward: -33354841166.37
               Mean episode length: 983.01
       Episode_Reward/keep_balance: 0.9541
     Episode_Reward/rew_lin_vel_xy: 5.1087
      Episode_Reward/rew_ang_vel_z: 2.6428
    Episode_Reward/pen_base_height: -0.3321
      Episode_Reward/pen_lin_vel_z: -0.0549
     Episode_Reward/pen_ang_vel_xy: -0.1513
   Episode_Reward/pen_joint_torque: -0.2513
    Episode_Reward/pen_joint_accel: -0.0978
    Episode_Reward/pen_action_rate: -5341509120.0000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0460
   Episode_Reward/pen_joint_powers: -0.0734
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -1607416576.0000
Episode_Reward/pen_flat_orientation: -0.1104
  Episode_Reward/pen_feet_distance: -0.0142
Episode_Reward/pen_feet_regulation: -0.3502
   Episode_Reward/foot_landing_vel: -0.1326
   Episode_Reward/test_gait_reward: -0.8917
Metrics/base_velocity/error_vel_xy: 1.4027
Metrics/base_velocity/error_vel_yaw: 1.0609
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 154042368
                    Iteration time: 1.07s
                        Total time: 1697.32s
                               ETA: 1553.3s

################################################################################
                     [1m Learning iteration 1567/3000 [0m                     

                       Computation: 90737 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 1588582428657.3406
                    Surrogate loss: -0.0006
             Mean action noise std: 0.6476
                     Learning rate: 0.0003
                       Mean reward: -1953.14
               Mean episode length: 945.06
       Episode_Reward/keep_balance: 0.9254
     Episode_Reward/rew_lin_vel_xy: 4.9561
      Episode_Reward/rew_ang_vel_z: 2.5095
    Episode_Reward/pen_base_height: -0.3253
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.1546
   Episode_Reward/pen_joint_torque: -0.2194
    Episode_Reward/pen_joint_accel: -0.0901
    Episode_Reward/pen_action_rate: -437794.8125
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0448
   Episode_Reward/pen_joint_powers: -0.0704
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -131673.6562
Episode_Reward/pen_flat_orientation: -0.1137
  Episode_Reward/pen_feet_distance: -0.0142
Episode_Reward/pen_feet_regulation: -0.3614
   Episode_Reward/foot_landing_vel: -0.1246
   Episode_Reward/test_gait_reward: -0.8722
Metrics/base_velocity/error_vel_xy: 1.3397
Metrics/base_velocity/error_vel_yaw: 1.0642
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 154140672
                    Iteration time: 1.08s
                        Total time: 1698.40s
                               ETA: 1552.2s

################################################################################
                     [1m Learning iteration 1568/3000 [0m                     

                       Computation: 91658 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 1162995908476928.0000
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6477
                     Learning rate: 0.0000
                       Mean reward: -3692081.23
               Mean episode length: 980.73
       Episode_Reward/keep_balance: 0.9809
     Episode_Reward/rew_lin_vel_xy: 5.2521
      Episode_Reward/rew_ang_vel_z: 2.6426
    Episode_Reward/pen_base_height: -0.3397
      Episode_Reward/pen_lin_vel_z: -0.0540
     Episode_Reward/pen_ang_vel_xy: -0.1640
   Episode_Reward/pen_joint_torque: -0.2003
    Episode_Reward/pen_joint_accel: -0.0932
    Episode_Reward/pen_action_rate: -84467.1094
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0479
   Episode_Reward/pen_joint_powers: -0.0725
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -25423.1309
Episode_Reward/pen_flat_orientation: -0.1139
  Episode_Reward/pen_feet_distance: -0.0155
Episode_Reward/pen_feet_regulation: -0.3820
   Episode_Reward/foot_landing_vel: -0.1393
   Episode_Reward/test_gait_reward: -0.9123
Metrics/base_velocity/error_vel_xy: 1.4002
Metrics/base_velocity/error_vel_yaw: 1.1331
      Episode_Termination/time_out: 4.8750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 154238976
                    Iteration time: 1.07s
                        Total time: 1699.47s
                               ETA: 1551.1s

################################################################################
                     [1m Learning iteration 1569/3000 [0m                     

                       Computation: 90904 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: inf
                    Surrogate loss: 0.0000
             Mean action noise std: 0.6477
                     Learning rate: 0.0000
                       Mean reward: -553683160989.46
               Mean episode length: 983.75
       Episode_Reward/keep_balance: 0.9915
     Episode_Reward/rew_lin_vel_xy: 5.3752
      Episode_Reward/rew_ang_vel_z: 2.6992
    Episode_Reward/pen_base_height: -0.3363
      Episode_Reward/pen_lin_vel_z: -0.0537
     Episode_Reward/pen_ang_vel_xy: -0.1582
   Episode_Reward/pen_joint_torque: -0.2084
    Episode_Reward/pen_joint_accel: -0.0912
    Episode_Reward/pen_action_rate: -11082665984.0000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0469
   Episode_Reward/pen_joint_powers: -0.0729
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -3336166912.0000
Episode_Reward/pen_flat_orientation: -0.1119
  Episode_Reward/pen_feet_distance: -0.0145
Episode_Reward/pen_feet_regulation: -0.3706
   Episode_Reward/foot_landing_vel: -0.1272
   Episode_Reward/test_gait_reward: -0.9359
Metrics/base_velocity/error_vel_xy: 1.3586
Metrics/base_velocity/error_vel_yaw: 1.1332
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 154337280
                    Iteration time: 1.08s
                        Total time: 1700.55s
                               ETA: 1550.0s

Traceback (most recent call last):
  File "/personal/limxtron1lab-main/scripts/rsl_rl/train.py", line 154, in <module>
    main()
  File "/personal/limxtron1lab-main/scripts/rsl_rl/train.py", line 146, in main
    runner.learn(num_learning_iterations=agent_cfg.max_iterations, init_at_random_ep_len=True)
  File "/personal/limxtron1lab-main/rsl_rl/rsl_rl/runner/on_policy_runner.py", line 269, in learn
    ) = self.alg.update()
  File "/personal/limxtron1lab-main/rsl_rl/rsl_rl/algorithm/ppo.py", line 241, in update
    self.actor_critic.act(
  File "/personal/limxtron1lab-main/rsl_rl/rsl_rl/modules/actor_critic.py", line 180, in act
    self.update_distribution(observations)
  File "/personal/limxtron1lab-main/rsl_rl/rsl_rl/modules/actor_critic.py", line 169, in update_distribution
    self.distribution = Normal(mean, mean * 0.0 + torch.exp(self.logstd))
  File "/isaac-sim/extscache/omni.isaac.ml_archive-2.1.2+106.5.0.lx64.cp310/pip_prebundle/torch/distributions/normal.py", line 59, in __init__
    super().__init__(batch_shape, validate_args=validate_args)
  File "/isaac-sim/extscache/omni.isaac.ml_archive-2.1.2+106.5.0.lx64.cp310/pip_prebundle/torch/distributions/distribution.py", line 71, in __init__
    raise ValueError(
ValueError: Expected parameter loc (Tensor of shape (24576, 6)) of distribution Normal(loc: torch.Size([24576, 6]), scale: torch.Size([24576, 6])) to satisfy the constraint Real(), but found invalid values:
tensor([[nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan],
        ...,
        [nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
2026-01-04 12:19:36 [4,719,724ms] [Warning] [omni.fabric.plugin] gFabricState->gUsdStageToSimStageWithHistoryMap had 1 outstanding SimStageWithHistory(s) at shutdown
2026-01-04 12:19:36 [4,719,879ms] [Warning] [carb] Recursive unloadAllPlugins() detected!
