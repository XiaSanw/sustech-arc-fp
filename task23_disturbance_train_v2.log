nohup: ignoring input
/isaac-sim/extscache/omni.isaac.ml_archive-2.1.2+106.5.0.lx64.cp310/pip_prebundle/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: '/isaac-sim/extscache/omni.isaac.ml_archive-2.1.2+106.5.0.lx64.cp310/pip_prebundle/torchvision/image.so: ELF load command address/offset not page-aligned'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Loading user config located at: '/isaac-sim/kit/data/Kit/Isaac-Sim/4.5/user.config.json'
[Info] [carb] Logging to file: /isaac-sim/kit/logs/Kit/Isaac-Sim/4.5/kit_20260104_210927.log
2026-01-04 13:09:27 [0ms] [Warning] [omni.kit.app.plugin] No crash reporter present, dumps uploading isn't available.
2026-01-04 13:09:27 [4ms] [Warning] [omni.ext.plugin] [ext: rendering_modes] Extensions config 'extension.toml' doesn't exist '/workspace/isaaclab/apps/rendering_modes' or '/workspace/isaaclab/apps/rendering_modes/config'
2026-01-04 13:09:31 [3,375ms] [Warning] [omni.usd_config.extension] Enable omni.materialx.libs extension to use MaterialX
2026-01-04 13:09:34 [6,231ms] [Warning] [omni.datastore] OmniHub is inaccessible
2026-01-04 13:09:38 [10,708ms] [Warning] [omni.platforminfo.plugin] failed to open the default display.  Can't verify X Server version.
2026-01-04 13:09:40 [12,240ms] [Warning] [omni.isaac.dynamic_control] omni.isaac.dynamic_control is deprecated as of Isaac Sim 4.5. No action is needed from end-users.

|---------------------------------------------------------------------------------------------|
| Driver Version: 535.154.05    | Graphics API: Vulkan
|=============================================================================================|
| GPU | Name                             | Active | LDA | GPU Memory | Vendor-ID | LUID       |
|     |                                  |        |     |            | Device-ID | UUID       |
|     |                                  |        |     |            | Bus-ID    |            |
|---------------------------------------------------------------------------------------------|
| 0   | NVIDIA GeForce RTX 4090 D        | Yes: 0 |     | 24810   MB | 10de      | 0          |
|     |                                  |        |     |            | 2685      | 91c4a5c2.. |
|     |                                  |        |     |            | 65        |            |
|=============================================================================================|
| OS: 22.04.5 LTS (Jammy Jellyfish) ubuntu, Version: 22.04.5, Kernel: 5.4.250-9-velinux1u1-amd64
| Processor: Intel(R) Xeon(R) Platinum 8457C
| Cores: 22 | Logical Cores: 44
|---------------------------------------------------------------------------------------------|
| Total Memory (MB): 180751 | Free Memory: 79099
| Total Page/Swap (MB): 0 | Free Page/Swap: 0
|---------------------------------------------------------------------------------------------|
2026-01-04 13:10:10 [42,654ms] [Warning] [isaaclab.terrains.terrain_importer] Visual material specified for ground plane but no diffuse color found. Using default color: (0.0, 0.0, 0.0)
2026-01-04 13:10:13 [45,369ms] [Warning] [isaaclab.actuators.actuator_pd] The <ImplicitActuatorCfg> object has a value for 'effort_limit'. This parameter will be removed in the future. To set the effort limit, please use 'effort_limit_sim' instead.
2026-01-04 13:10:13 [45,369ms] [Warning] [isaaclab.actuators.actuator_pd] The <ImplicitActuatorCfg> object has a value for 'velocity_limit'. Previously, although this value was specified, it was not getting used by implicit actuators. Since this parameter affects the simulation behavior, we continue to not use it. This parameter will be removed in the future. To set the velocity limit, please use 'velocity_limit_sim' instead.
2026-01-04 13:10:15 [47,827ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPreviewSurface.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 13:10:15 [47,865ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdUVTexture.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 13:10:15 [47,905ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_float.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 13:10:15 [47,935ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_float2.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 13:10:15 [47,965ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_float3.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 13:10:15 [47,995ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_float4.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 13:10:15 [48,028ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_int.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 13:10:15 [48,058ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_string.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 13:10:15 [48,087ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_normal.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 13:10:15 [48,120ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_point.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 13:10:16 [48,150ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_vector.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 13:10:16 [48,180ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_matrix.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-04 13:10:16 [48,209ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdTransform2d.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

[INFO][AppLauncher]: Using device: cuda:0
[INFO][AppLauncher]: Loading experience file: /workspace/isaaclab/apps/isaaclab.python.headless.kit
[INFO]: Parsing configuration from: <class 'bipedal_locomotion.tasks.locomotion.robots.limx_pointfoot_env_cfg.PFBlindFlatEnvCfg'>
[INFO]: Parsing configuration from: PF_TRON1AFlatPPORunnerCfg(seed=42, device='cuda:0', num_steps_per_env=24, max_iterations=3000, empirical_normalization=False, policy=RslRlPpoActorCriticCfg(class_name='ActorCritic', init_noise_std=1.0, noise_std_type='scalar', actor_hidden_dims=[512, 256, 128], critic_hidden_dims=[512, 256, 128], activation='elu'), algorithm=RslRlPpoAlgorithmMlpCfg(class_name='PPO', num_learning_epochs=5, num_mini_batches=4, learning_rate=0.001, schedule='adaptive', gamma=0.99, lam=0.95, entropy_coef=0.01, desired_kl=0.01, max_grad_norm=1.0, value_loss_coef=1.0, use_clipped_value_loss=True, clip_param=0.2, normalize_advantage_per_mini_batch=False, symmetry_cfg=None, rnd_cfg=None, obs_history_len=10), clip_actions=None, save_interval=200, experiment_name='pf_tron_1a_flat', run_name='', logger='tensorboard', neptune_project='isaaclab', wandb_project='isaaclab', resume=False, load_run='.*', load_checkpoint='model_.*.pt', encoder=EncoderCfg(output_detach=True, num_input_dim=<dataclasses._MISSING_TYPE object at 0x7fa783b08130>, num_output_dim=3, hidden_dims=[256, 128], activation='elu', orthogonal_init=False))
[INFO] Logging experiment in directory: /personal/limxtron1lab-main/logs/rsl_rl/pf_tron_1a_flat
Setting seed: 42
[INFO]: Base environment:
	Environment device    : cuda:0
	Environment seed      : 42
	Physics step-size     : 0.005
	Rendering step-size   : 0.04
	Environment step-size : 0.02
[INFO]: Time taken for scene creation : 2.178031 seconds
[INFO]: Scene manager:  <class InteractiveScene>
	Number of environments: 4096
	Environment spacing   : 2.5
	Source prim name      : /World/envs/env_0
	Global prim paths     : ['/World/ground']
	Replicate physics     : True
[INFO]: Starting the simulation. This may take a few seconds. Please wait...
[INFO]: Time taken for simulation start : 3.539902 seconds
[INFO] Command Manager:  <CommandManager> contains 2 active terms.
+------------------------------------------------+
|              Active Command Terms              |
+-------+---------------+------------------------+
| Index | Name          |          Type          |
+-------+---------------+------------------------+
|   0   | base_velocity | UniformVelocityCommand |
|   1   | gait_command  |      GaitCommand       |
+-------+---------------+------------------------+

[INFO] Event Manager:  <EventManager> contains 3 active terms.
+-------------------------------------------+
|   Active Event Terms in Mode: 'startup'   |
+-------+-----------------------------------+
| Index | Name                              |
+-------+-----------------------------------+
|   0   | add_base_mass                     |
|   1   | add_link_mass                     |
|   2   | radomize_rigid_body_mass_inertia  |
|   3   | robot_physics_material            |
|   4   | robot_joint_stiffness_and_damping |
|   5   | robot_center_of_mass              |
+-------+-----------------------------------+
+-------------------------------------+
| Active Event Terms in Mode: 'reset' |
+---------+---------------------------+
|  Index  | Name                      |
+---------+---------------------------+
|    0    | reset_robot_base          |
|    1    | reset_robot_joints        |
+---------+---------------------------+
+----------------------------------------------+
|    Active Event Terms in Mode: 'interval'    |
+-------+------------+-------------------------+
| Index | Name       | Interval time range (s) |
+-------+------------+-------------------------+
|   0   | push_robot |       (5.0, 10.0)       |
+-------+------------+-------------------------+

[INFO] Recorder Manager:  <RecorderManager> contains 0 active terms.
+---------------------+
| Active Recorder Terms |
+-----------+---------+
|   Index   | Name    |
+-----------+---------+
+-----------+---------+

[INFO] Action Manager:  <ActionManager> contains 1 active terms.
+----------------------------------+
|  Active Action Terms (shape: 6)  |
+--------+------------+------------+
| Index  | Name       |  Dimension |
+--------+------------+------------+
|   0    | joint_pos  |          6 |
+--------+------------+------------+

[INFO] Observation Manager: <ObservationManager> contains 4 groups.
+-------------------------------------------------------+
| Active Observation Terms in Group: 'policy' (shape: (30,)) |
+-------------+---------------------------+-------------+
|    Index    | Name                      |    Shape    |
+-------------+---------------------------+-------------+
|      0      | base_ang_vel              |     (3,)    |
|      1      | proj_gravity              |     (3,)    |
|      2      | joint_pos                 |     (6,)    |
|      3      | joint_vel                 |     (6,)    |
|      4      | last_action               |     (6,)    |
|      5      | gait_phase                |     (2,)    |
|      6      | gait_command              |     (4,)    |
+-------------+---------------------------+-------------+
+-------------------------------------------------------------+
| Active Observation Terms in Group: 'critic' (shape: (360,)) |
+----------+--------------------------------------+-----------+
|  Index   | Name                                 |   Shape   |
+----------+--------------------------------------+-----------+
|    0     | base_lin_vel                         |    (3,)   |
|    1     | base_ang_vel                         |    (3,)   |
|    2     | proj_gravity                         |    (3,)   |
|    3     | joint_pos                            |    (6,)   |
|    4     | joint_vel                            |    (6,)   |
|    5     | last_action                          |    (6,)   |
|    6     | gait_phase                           |    (2,)   |
|    7     | gait_command                         |    (4,)   |
|    8     | robot_joint_torque                   |    (6,)   |
|    9     | robot_joint_acc                      |    (6,)   |
|    10    | robot_feet_contact_force             |   (144,)  |
|    11    | robot_mass                           |   (12,)   |
|    12    | robot_inertia                        |   (108,)  |
|    13    | robot_joint_stiffness                |    (6,)   |
|    14    | robot_joint_damping                  |    (6,)   |
|    15    | robot_pos                            |    (3,)   |
|    16    | robot_vel                            |    (6,)   |
|    17    | robot_material_propertirs            |   (27,)   |
|    18    | robot_base_pose                      |    (3,)   |
+----------+--------------------------------------+-----------+
+---------------------------------------------------------+
| Active Observation Terms in Group: 'commands' (shape: (3,)) |
+-----------+---------------------------------+-----------+
|   Index   | Name                            |   Shape   |
+-----------+---------------------------------+-----------+
|     0     | velocity_commands               |    (3,)   |
+-----------+---------------------------------+-----------+
+-------------------------------------------------------------+
| Active Observation Terms in Group: 'obsHistory' (shape: (70, 30)) |
+-------------+----------------------------+------------------+
|    Index    | Name                       |      Shape       |
+-------------+----------------------------+------------------+
|      0      | base_ang_vel               |     (10, 3)      |
|      1      | proj_gravity               |     (10, 3)      |
|      2      | joint_pos                  |     (10, 6)      |
|      3      | joint_vel                  |     (10, 6)      |
|      4      | last_action                |     (10, 6)      |
|      5      | gait_phase                 |     (10, 2)      |
|      6      | gait_command               |     (10, 4)      |
+-------------+----------------------------+------------------+

[INFO] Termination Manager:  <TerminationManager> contains 2 active terms.
+---------------------------------+
|     Active Termination Terms    |
+-------+--------------+----------+
| Index | Name         | Time Out |
+-------+--------------+----------+
|   0   | time_out     |   True   |
|   1   | base_contact |  False   |
+-------+--------------+----------+

[INFO] Reward Manager:  <RewardManager> contains 19 active terms.
+-------------------------------------------+
|            Active Reward Terms            |
+-------+------------------------+----------+
| Index | Name                   |   Weight |
+-------+------------------------+----------+
|   0   | keep_balance           |      1.0 |
|   1   | rew_lin_vel_xy         |      8.0 |
|   2   | rew_ang_vel_z          |      4.0 |
|   3   | pen_base_height        |    -20.0 |
|   4   | pen_lin_vel_z          |     -0.5 |
|   5   | pen_ang_vel_xy         |    -0.05 |
|   6   | pen_joint_torque       |   -8e-05 |
|   7   | pen_joint_accel        | -2.5e-07 |
|   8   | pen_action_rate        |   -0.005 |
|   9   | pen_joint_pos_limits   |     -2.0 |
|   10  | pen_joint_vel_l2       |   -0.001 |
|   11  | pen_joint_powers       |  -0.0005 |
|   12  | pen_undesired_contacts |     -0.5 |
|   13  | pen_action_smoothness  |   -0.005 |
|   14  | pen_flat_orientation   |    -10.0 |
|   15  | pen_feet_distance      |     -100 |
|   16  | pen_feet_regulation    |     -0.1 |
|   17  | foot_landing_vel       |     -0.5 |
|   18  | test_gait_reward       |      1.0 |
+-------+------------------------+----------+

[INFO] Curriculum Manager:  <CurriculumManager> contains 0 active terms.
+----------------------+
| Active Curriculum Terms |
+-----------+----------+
|   Index   | Name     |
+-----------+----------+
+-----------+----------+

[INFO]: Completed setting up the environment...
encoder cfg: dict_keys(['seed', 'device', 'num_steps_per_env', 'max_iterations', 'empirical_normalization', 'policy', 'algorithm', 'clip_actions', 'save_interval', 'experiment_name', 'run_name', 'logger', 'neptune_project', 'wandb_project', 'resume', 'load_run', 'load_checkpoint', 'encoder'])
Encoder MLP: Sequential(
  (0): Linear(in_features=300, out_features=256, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=256, out_features=128, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=128, out_features=3, bias=True)
)
ActorCritic.__init__ got unexpected arguments, which will be ignored: ['class_name', 'noise_std_type']
Actor MLP: Sequential(
  (0): Linear(in_features=36, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=6, bias=True)
)
Critic MLP: Sequential(
  (0): Linear(in_features=363, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=1, bias=True)
)
Setting seed: 42
################################################################################
                      [1m Learning iteration 0/3000 [0m                       

                       Computation: 32229 steps/s (collection: 2.862s, learning 0.188s)
               Value function loss: 6.5784
                    Surrogate loss: 0.0122
             Mean action noise std: 1.0046
                     Learning rate: 0.0004
                       Mean reward: -4.15
               Mean episode length: 23.91
       Episode_Reward/keep_balance: 0.0125
     Episode_Reward/rew_lin_vel_xy: 0.0107
      Episode_Reward/rew_ang_vel_z: 0.0210
    Episode_Reward/pen_base_height: -0.0408
      Episode_Reward/pen_lin_vel_z: -0.0090
     Episode_Reward/pen_ang_vel_xy: -0.0075
   Episode_Reward/pen_joint_torque: -0.0013
    Episode_Reward/pen_joint_accel: -0.0020
    Episode_Reward/pen_action_rate: -0.0007
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0008
   Episode_Reward/pen_joint_powers: -0.0010
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.0019
Episode_Reward/pen_flat_orientation: -0.0164
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0021
   Episode_Reward/foot_landing_vel: -0.0048
   Episode_Reward/test_gait_reward: -0.0134
Metrics/base_velocity/error_vel_xy: 0.0539
Metrics/base_velocity/error_vel_yaw: 0.0274
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 3.05s
                        Total time: 3.05s
                               ETA: 9150.5s

################################################################################
                      [1m Learning iteration 1/3000 [0m                       

                       Computation: 87276 steps/s (collection: 1.001s, learning 0.126s)
               Value function loss: 4.5519
                    Surrogate loss: 0.0043
             Mean action noise std: 1.0081
                     Learning rate: 0.0004
                       Mean reward: -7.12
               Mean episode length: 42.06
       Episode_Reward/keep_balance: 0.0358
     Episode_Reward/rew_lin_vel_xy: 0.0296
      Episode_Reward/rew_ang_vel_z: 0.0456
    Episode_Reward/pen_base_height: -0.1794
      Episode_Reward/pen_lin_vel_z: -0.0195
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0062
Episode_Reward/pen_flat_orientation: -0.1287
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0401
Metrics/base_velocity/error_vel_xy: 0.1703
Metrics/base_velocity/error_vel_yaw: 0.1233
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 137.7917
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 1.13s
                        Total time: 4.18s
                               ETA: 6262.7s

################################################################################
                      [1m Learning iteration 2/3000 [0m                       

                       Computation: 88428 steps/s (collection: 0.992s, learning 0.119s)
               Value function loss: 1.9426
                    Surrogate loss: 0.0022
             Mean action noise std: 1.0069
                     Learning rate: 0.0015
                       Mean reward: -6.49
               Mean episode length: 34.96
       Episode_Reward/keep_balance: 0.0362
     Episode_Reward/rew_lin_vel_xy: 0.0327
      Episode_Reward/rew_ang_vel_z: 0.0462
    Episode_Reward/pen_base_height: -0.1783
      Episode_Reward/pen_lin_vel_z: -0.0193
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0063
Episode_Reward/pen_flat_orientation: -0.1293
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0404
Metrics/base_velocity/error_vel_xy: 0.1719
Metrics/base_velocity/error_vel_yaw: 0.1258
      Episode_Termination/time_out: 0.2083
  Episode_Termination/base_contact: 104.5833
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 1.11s
                        Total time: 5.29s
                               ETA: 5284.7s

################################################################################
                      [1m Learning iteration 3/3000 [0m                       

                       Computation: 88076 steps/s (collection: 0.994s, learning 0.122s)
               Value function loss: 1.8016
                    Surrogate loss: 0.0015
             Mean action noise std: 1.0067
                     Learning rate: 0.0051
                       Mean reward: -6.71
               Mean episode length: 37.82
       Episode_Reward/keep_balance: 0.0370
     Episode_Reward/rew_lin_vel_xy: 0.0328
      Episode_Reward/rew_ang_vel_z: 0.0457
    Episode_Reward/pen_base_height: -0.1838
      Episode_Reward/pen_lin_vel_z: -0.0197
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0065
Episode_Reward/pen_flat_orientation: -0.1321
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0414
Metrics/base_velocity/error_vel_xy: 0.1787
Metrics/base_velocity/error_vel_yaw: 0.1344
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 118.3333
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 1.12s
                        Total time: 6.40s
                               ETA: 4798.4s

################################################################################
                      [1m Learning iteration 4/3000 [0m                       

                       Computation: 88758 steps/s (collection: 0.984s, learning 0.124s)
               Value function loss: 1.6148
                    Surrogate loss: 0.0077
             Mean action noise std: 1.0093
                     Learning rate: 0.0022
                       Mean reward: -6.80
               Mean episode length: 37.35
       Episode_Reward/keep_balance: 0.0366
     Episode_Reward/rew_lin_vel_xy: 0.0314
      Episode_Reward/rew_ang_vel_z: 0.0462
    Episode_Reward/pen_base_height: -0.1813
      Episode_Reward/pen_lin_vel_z: -0.0195
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0064
Episode_Reward/pen_flat_orientation: -0.1300
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0410
Metrics/base_velocity/error_vel_xy: 0.1775
Metrics/base_velocity/error_vel_yaw: 0.1299
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 106.9167
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 1.11s
                        Total time: 7.51s
                               ETA: 4501.1s

################################################################################
                      [1m Learning iteration 5/3000 [0m                       

                       Computation: 88663 steps/s (collection: 0.987s, learning 0.122s)
               Value function loss: 1.4459
                    Surrogate loss: 0.0130
             Mean action noise std: 1.0127
                     Learning rate: 0.0004
                       Mean reward: -6.60
               Mean episode length: 36.18
       Episode_Reward/keep_balance: 0.0375
     Episode_Reward/rew_lin_vel_xy: 0.0317
      Episode_Reward/rew_ang_vel_z: 0.0474
    Episode_Reward/pen_base_height: -0.1846
      Episode_Reward/pen_lin_vel_z: -0.0198
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0058
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0066
Episode_Reward/pen_flat_orientation: -0.1313
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0417
Metrics/base_velocity/error_vel_xy: 0.1830
Metrics/base_velocity/error_vel_yaw: 0.1321
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 108.9583
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 1.11s
                        Total time: 8.62s
                               ETA: 4303.1s

################################################################################
                      [1m Learning iteration 6/3000 [0m                       

                       Computation: 89121 steps/s (collection: 0.981s, learning 0.122s)
               Value function loss: 1.1551
                    Surrogate loss: 0.0027
             Mean action noise std: 1.0159
                     Learning rate: 0.0022
                       Mean reward: -6.72
               Mean episode length: 38.22
       Episode_Reward/keep_balance: 0.0371
     Episode_Reward/rew_lin_vel_xy: 0.0311
      Episode_Reward/rew_ang_vel_z: 0.0467
    Episode_Reward/pen_base_height: -0.1814
      Episode_Reward/pen_lin_vel_z: -0.0195
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0067
Episode_Reward/pen_flat_orientation: -0.1301
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0414
Metrics/base_velocity/error_vel_xy: 0.1824
Metrics/base_velocity/error_vel_yaw: 0.1288
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 110.5833
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 1.10s
                        Total time: 9.72s
                               ETA: 4158.9s

################################################################################
                      [1m Learning iteration 7/3000 [0m                       

                       Computation: 89305 steps/s (collection: 0.979s, learning 0.122s)
               Value function loss: 1.0753
                    Surrogate loss: 0.0046
             Mean action noise std: 1.0228
                     Learning rate: 0.0034
                       Mean reward: -6.26
               Mean episode length: 36.05
       Episode_Reward/keep_balance: 0.0370
     Episode_Reward/rew_lin_vel_xy: 0.0326
      Episode_Reward/rew_ang_vel_z: 0.0476
    Episode_Reward/pen_base_height: -0.1806
      Episode_Reward/pen_lin_vel_z: -0.0193
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0067
Episode_Reward/pen_flat_orientation: -0.1294
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0413
Metrics/base_velocity/error_vel_xy: 0.1766
Metrics/base_velocity/error_vel_yaw: 0.1280
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 111.1250
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 1.10s
                        Total time: 10.82s
                               ETA: 4049.7s

################################################################################
                      [1m Learning iteration 8/3000 [0m                       

                       Computation: 89424 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.9832
                    Surrogate loss: 0.0105
             Mean action noise std: 1.0263
                     Learning rate: 0.0004
                       Mean reward: -6.15
               Mean episode length: 35.41
       Episode_Reward/keep_balance: 0.0369
     Episode_Reward/rew_lin_vel_xy: 0.0309
      Episode_Reward/rew_ang_vel_z: 0.0479
    Episode_Reward/pen_base_height: -0.1796
      Episode_Reward/pen_lin_vel_z: -0.0189
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0067
Episode_Reward/pen_flat_orientation: -0.1277
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0411
Metrics/base_velocity/error_vel_xy: 0.1814
Metrics/base_velocity/error_vel_yaw: 0.1265
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 112.1667
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 1.10s
                        Total time: 11.92s
                               ETA: 3964.0s

################################################################################
                      [1m Learning iteration 9/3000 [0m                       

                       Computation: 89778 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.8602
                    Surrogate loss: 0.0065
             Mean action noise std: 1.0296
                     Learning rate: 0.0010
                       Mean reward: -6.75
               Mean episode length: 37.53
       Episode_Reward/keep_balance: 0.0367
     Episode_Reward/rew_lin_vel_xy: 0.0309
      Episode_Reward/rew_ang_vel_z: 0.0470
    Episode_Reward/pen_base_height: -0.1790
      Episode_Reward/pen_lin_vel_z: -0.0189
     Episode_Reward/pen_ang_vel_xy: -0.0221
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0068
Episode_Reward/pen_flat_orientation: -0.1275
  Episode_Reward/pen_feet_distance: -0.0050
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0411
Metrics/base_velocity/error_vel_xy: 0.1781
Metrics/base_velocity/error_vel_yaw: 0.1271
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 111.3333
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.09s
                        Total time: 13.02s
                               ETA: 3893.9s

################################################################################
                      [1m Learning iteration 10/3000 [0m                      

                       Computation: 90331 steps/s (collection: 0.968s, learning 0.120s)
               Value function loss: 0.8072
                    Surrogate loss: 0.0016
             Mean action noise std: 1.0296
                     Learning rate: 0.0051
                       Mean reward: -6.38
               Mean episode length: 36.08
       Episode_Reward/keep_balance: 0.0368
     Episode_Reward/rew_lin_vel_xy: 0.0325
      Episode_Reward/rew_ang_vel_z: 0.0472
    Episode_Reward/pen_base_height: -0.1790
      Episode_Reward/pen_lin_vel_z: -0.0189
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0068
Episode_Reward/pen_flat_orientation: -0.1278
  Episode_Reward/pen_feet_distance: -0.0044
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0411
Metrics/base_velocity/error_vel_xy: 0.1778
Metrics/base_velocity/error_vel_yaw: 0.1263
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 113.8750
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.09s
                        Total time: 14.11s
                               ETA: 3834.5s

################################################################################
                      [1m Learning iteration 11/3000 [0m                      

                       Computation: 89359 steps/s (collection: 0.981s, learning 0.119s)
               Value function loss: 0.8867
                    Surrogate loss: 0.0008
             Mean action noise std: 1.0337
                     Learning rate: 0.0100
                       Mean reward: -5.97
               Mean episode length: 34.23
       Episode_Reward/keep_balance: 0.0365
     Episode_Reward/rew_lin_vel_xy: 0.0317
      Episode_Reward/rew_ang_vel_z: 0.0463
    Episode_Reward/pen_base_height: -0.1774
      Episode_Reward/pen_lin_vel_z: -0.0187
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0068
Episode_Reward/pen_flat_orientation: -0.1272
  Episode_Reward/pen_feet_distance: -0.0047
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0408
Metrics/base_velocity/error_vel_xy: 0.1774
Metrics/base_velocity/error_vel_yaw: 0.1264
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 110.0833
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.10s
                        Total time: 15.21s
                               ETA: 3787.8s

################################################################################
                      [1m Learning iteration 12/3000 [0m                      

                       Computation: 88646 steps/s (collection: 0.988s, learning 0.121s)
               Value function loss: 0.7762
                    Surrogate loss: -0.0001
             Mean action noise std: 1.0374
                     Learning rate: 0.0100
                       Mean reward: -6.18
               Mean episode length: 36.80
       Episode_Reward/keep_balance: 0.0365
     Episode_Reward/rew_lin_vel_xy: 0.0311
      Episode_Reward/rew_ang_vel_z: 0.0474
    Episode_Reward/pen_base_height: -0.1775
      Episode_Reward/pen_lin_vel_z: -0.0186
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0069
Episode_Reward/pen_flat_orientation: -0.1261
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0408
Metrics/base_velocity/error_vel_xy: 0.1776
Metrics/base_velocity/error_vel_yaw: 0.1242
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 112.3750
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.11s
                        Total time: 16.32s
                               ETA: 3750.2s

################################################################################
                      [1m Learning iteration 13/3000 [0m                      

                       Computation: 87899 steps/s (collection: 0.996s, learning 0.122s)
               Value function loss: 0.7932
                    Surrogate loss: 0.0027
             Mean action noise std: 1.0445
                     Learning rate: 0.0044
                       Mean reward: -5.99
               Mean episode length: 36.04
       Episode_Reward/keep_balance: 0.0363
     Episode_Reward/rew_lin_vel_xy: 0.0322
      Episode_Reward/rew_ang_vel_z: 0.0472
    Episode_Reward/pen_base_height: -0.1749
      Episode_Reward/pen_lin_vel_z: -0.0182
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0069
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0043
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0404
Metrics/base_velocity/error_vel_xy: 0.1754
Metrics/base_velocity/error_vel_yaw: 0.1222
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 114.8333
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.12s
                        Total time: 17.43s
                               ETA: 3719.7s

################################################################################
                      [1m Learning iteration 14/3000 [0m                      

                       Computation: 88702 steps/s (collection: 0.986s, learning 0.122s)
               Value function loss: 0.7321
                    Surrogate loss: 0.0005
             Mean action noise std: 1.0515
                     Learning rate: 0.0100
                       Mean reward: -6.23
               Mean episode length: 36.17
       Episode_Reward/keep_balance: 0.0359
     Episode_Reward/rew_lin_vel_xy: 0.0309
      Episode_Reward/rew_ang_vel_z: 0.0470
    Episode_Reward/pen_base_height: -0.1724
      Episode_Reward/pen_lin_vel_z: -0.0178
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0069
Episode_Reward/pen_flat_orientation: -0.1234
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0401
Metrics/base_velocity/error_vel_xy: 0.1771
Metrics/base_velocity/error_vel_yaw: 0.1194
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 112.2500
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.11s
                        Total time: 18.54s
                               ETA: 3691.2s

################################################################################
                      [1m Learning iteration 15/3000 [0m                      

                       Computation: 87520 steps/s (collection: 0.999s, learning 0.124s)
               Value function loss: 0.8095
                    Surrogate loss: 0.0024
             Mean action noise std: 1.0529
                     Learning rate: 0.0067
                       Mean reward: -6.25
               Mean episode length: 35.90
       Episode_Reward/keep_balance: 0.0361
     Episode_Reward/rew_lin_vel_xy: 0.0306
      Episode_Reward/rew_ang_vel_z: 0.0473
    Episode_Reward/pen_base_height: -0.1726
      Episode_Reward/pen_lin_vel_z: -0.0176
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0070
Episode_Reward/pen_flat_orientation: -0.1235
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.0063
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0403
Metrics/base_velocity/error_vel_xy: 0.1769
Metrics/base_velocity/error_vel_yaw: 0.1205
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.4167
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.12s
                        Total time: 19.67s
                               ETA: 3668.9s

################################################################################
                      [1m Learning iteration 16/3000 [0m                      

                       Computation: 88682 steps/s (collection: 0.986s, learning 0.122s)
               Value function loss: 0.5658
                    Surrogate loss: 0.0013
             Mean action noise std: 1.0599
                     Learning rate: 0.0067
                       Mean reward: -6.12
               Mean episode length: 36.91
       Episode_Reward/keep_balance: 0.0356
     Episode_Reward/rew_lin_vel_xy: 0.0315
      Episode_Reward/rew_ang_vel_z: 0.0467
    Episode_Reward/pen_base_height: -0.1685
      Episode_Reward/pen_lin_vel_z: -0.0172
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0070
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0037
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0398
Metrics/base_velocity/error_vel_xy: 0.1729
Metrics/base_velocity/error_vel_yaw: 0.1164
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.8750
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.11s
                        Total time: 20.77s
                               ETA: 3646.5s

################################################################################
                      [1m Learning iteration 17/3000 [0m                      

                       Computation: 89015 steps/s (collection: 0.983s, learning 0.121s)
               Value function loss: 0.6609
                    Surrogate loss: 0.0032
             Mean action noise std: 1.0650
                     Learning rate: 0.0067
                       Mean reward: -5.77
               Mean episode length: 35.26
       Episode_Reward/keep_balance: 0.0355
     Episode_Reward/rew_lin_vel_xy: 0.0304
      Episode_Reward/rew_ang_vel_z: 0.0478
    Episode_Reward/pen_base_height: -0.1668
      Episode_Reward/pen_lin_vel_z: -0.0166
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0042
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0071
Episode_Reward/pen_flat_orientation: -0.1191
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0396
Metrics/base_velocity/error_vel_xy: 0.1748
Metrics/base_velocity/error_vel_yaw: 0.1126
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.9583
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.10s
                        Total time: 21.88s
                               ETA: 3625.8s

################################################################################
                      [1m Learning iteration 18/3000 [0m                      

                       Computation: 88467 steps/s (collection: 0.988s, learning 0.123s)
               Value function loss: 0.4154
                    Surrogate loss: 0.0017
             Mean action noise std: 1.0646
                     Learning rate: 0.0044
                       Mean reward: -6.07
               Mean episode length: 37.90
       Episode_Reward/keep_balance: 0.0353
     Episode_Reward/rew_lin_vel_xy: 0.0306
      Episode_Reward/rew_ang_vel_z: 0.0484
    Episode_Reward/pen_base_height: -0.1649
      Episode_Reward/pen_lin_vel_z: -0.0163
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0072
Episode_Reward/pen_flat_orientation: -0.1182
  Episode_Reward/pen_feet_distance: -0.0035
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0393
Metrics/base_velocity/error_vel_xy: 0.1733
Metrics/base_velocity/error_vel_yaw: 0.1089
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 113.1667
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.11s
                        Total time: 22.99s
                               ETA: 3608.2s

################################################################################
                      [1m Learning iteration 19/3000 [0m                      

                       Computation: 88036 steps/s (collection: 0.994s, learning 0.123s)
               Value function loss: 0.3460
                    Surrogate loss: 0.0065
             Mean action noise std: 1.0673
                     Learning rate: 0.0020
                       Mean reward: -5.99
               Mean episode length: 36.02
       Episode_Reward/keep_balance: 0.0358
     Episode_Reward/rew_lin_vel_xy: 0.0313
      Episode_Reward/rew_ang_vel_z: 0.0498
    Episode_Reward/pen_base_height: -0.1671
      Episode_Reward/pen_lin_vel_z: -0.0164
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0042
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0074
Episode_Reward/pen_flat_orientation: -0.1188
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0400
Metrics/base_velocity/error_vel_xy: 0.1757
Metrics/base_velocity/error_vel_yaw: 0.1089
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 117.5833
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.12s
                        Total time: 24.11s
                               ETA: 3593.1s

################################################################################
                      [1m Learning iteration 20/3000 [0m                      

                       Computation: 88423 steps/s (collection: 0.988s, learning 0.123s)
               Value function loss: 0.3207
                    Surrogate loss: -0.0001
             Mean action noise std: 1.0694
                     Learning rate: 0.0044
                       Mean reward: -5.35
               Mean episode length: 33.95
       Episode_Reward/keep_balance: 0.0353
     Episode_Reward/rew_lin_vel_xy: 0.0307
      Episode_Reward/rew_ang_vel_z: 0.0503
    Episode_Reward/pen_base_height: -0.1644
      Episode_Reward/pen_lin_vel_z: -0.0161
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0073
Episode_Reward/pen_flat_orientation: -0.1171
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0392
Metrics/base_velocity/error_vel_xy: 0.1745
Metrics/base_velocity/error_vel_yaw: 0.1048
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.0833
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.11s
                        Total time: 25.22s
                               ETA: 3578.6s

################################################################################
                      [1m Learning iteration 21/3000 [0m                      

                       Computation: 89325 steps/s (collection: 0.980s, learning 0.120s)
               Value function loss: 0.5221
                    Surrogate loss: 0.0049
             Mean action noise std: 1.0731
                     Learning rate: 0.0013
                       Mean reward: -5.92
               Mean episode length: 37.61
       Episode_Reward/keep_balance: 0.0352
     Episode_Reward/rew_lin_vel_xy: 0.0305
      Episode_Reward/rew_ang_vel_z: 0.0506
    Episode_Reward/pen_base_height: -0.1629
      Episode_Reward/pen_lin_vel_z: -0.0159
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0042
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0073
Episode_Reward/pen_flat_orientation: -0.1161
  Episode_Reward/pen_feet_distance: -0.0027
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0391
Metrics/base_velocity/error_vel_xy: 0.1735
Metrics/base_velocity/error_vel_yaw: 0.1021
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 117.6250
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.10s
                        Total time: 26.32s
                               ETA: 3563.8s

################################################################################
                      [1m Learning iteration 22/3000 [0m                      

                       Computation: 89619 steps/s (collection: 0.976s, learning 0.121s)
               Value function loss: 0.4719
                    Surrogate loss: 0.0099
             Mean action noise std: 1.0717
                     Learning rate: 0.0000
                       Mean reward: -5.64
               Mean episode length: 35.44
       Episode_Reward/keep_balance: 0.0348
     Episode_Reward/rew_lin_vel_xy: 0.0312
      Episode_Reward/rew_ang_vel_z: 0.0514
    Episode_Reward/pen_base_height: -0.1609
      Episode_Reward/pen_lin_vel_z: -0.0156
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0073
Episode_Reward/pen_flat_orientation: -0.1152
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0387
Metrics/base_velocity/error_vel_xy: 0.1704
Metrics/base_velocity/error_vel_yaw: 0.0974
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 119.5833
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.10s
                        Total time: 27.42s
                               ETA: 3549.7s

################################################################################
                      [1m Learning iteration 23/3000 [0m                      

                       Computation: 89652 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.4258
                    Surrogate loss: -0.0007
             Mean action noise std: 1.0755
                     Learning rate: 0.0013
                       Mean reward: -5.02
               Mean episode length: 33.05
       Episode_Reward/keep_balance: 0.0343
     Episode_Reward/rew_lin_vel_xy: 0.0299
      Episode_Reward/rew_ang_vel_z: 0.0508
    Episode_Reward/pen_base_height: -0.1558
      Episode_Reward/pen_lin_vel_z: -0.0147
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0047
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0072
Episode_Reward/pen_flat_orientation: -0.1109
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0382
Metrics/base_velocity/error_vel_xy: 0.1703
Metrics/base_velocity/error_vel_yaw: 0.0957
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 122.2500
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 1.10s
                        Total time: 28.51s
                               ETA: 3536.7s

################################################################################
                      [1m Learning iteration 24/3000 [0m                      

                       Computation: 90284 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.2917
                    Surrogate loss: -0.0011
             Mean action noise std: 1.0760
                     Learning rate: 0.0019
                       Mean reward: -5.18
               Mean episode length: 32.83
       Episode_Reward/keep_balance: 0.0335
     Episode_Reward/rew_lin_vel_xy: 0.0294
      Episode_Reward/rew_ang_vel_z: 0.0507
    Episode_Reward/pen_base_height: -0.1505
      Episode_Reward/pen_lin_vel_z: -0.0142
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0071
Episode_Reward/pen_flat_orientation: -0.1072
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0371
Metrics/base_velocity/error_vel_xy: 0.1660
Metrics/base_velocity/error_vel_yaw: 0.0907
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 123.3333
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 1.09s
                        Total time: 29.60s
                               ETA: 3523.7s

################################################################################
                      [1m Learning iteration 25/3000 [0m                      

                       Computation: 89125 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 0.2478
                    Surrogate loss: -0.0020
             Mean action noise std: 1.0746
                     Learning rate: 0.0029
                       Mean reward: -5.17
               Mean episode length: 32.86
       Episode_Reward/keep_balance: 0.0331
     Episode_Reward/rew_lin_vel_xy: 0.0282
      Episode_Reward/rew_ang_vel_z: 0.0509
    Episode_Reward/pen_base_height: -0.1484
      Episode_Reward/pen_lin_vel_z: -0.0140
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0070
Episode_Reward/pen_flat_orientation: -0.1050
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0367
Metrics/base_velocity/error_vel_xy: 0.1647
Metrics/base_velocity/error_vel_yaw: 0.0871
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 125.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 1.10s
                        Total time: 30.70s
                               ETA: 3513.2s

################################################################################
                      [1m Learning iteration 26/3000 [0m                      

                       Computation: 89365 steps/s (collection: 0.981s, learning 0.119s)
               Value function loss: 0.2781
                    Surrogate loss: 0.0029
             Mean action noise std: 1.0758
                     Learning rate: 0.0009
                       Mean reward: -4.83
               Mean episode length: 32.28
       Episode_Reward/keep_balance: 0.0329
     Episode_Reward/rew_lin_vel_xy: 0.0280
      Episode_Reward/rew_ang_vel_z: 0.0517
    Episode_Reward/pen_base_height: -0.1455
      Episode_Reward/pen_lin_vel_z: -0.0137
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0070
Episode_Reward/pen_flat_orientation: -0.1022
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0364
Metrics/base_velocity/error_vel_xy: 0.1639
Metrics/base_velocity/error_vel_yaw: 0.0843
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 124.7917
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 1.10s
                        Total time: 31.80s
                               ETA: 3503.1s

################################################################################
                      [1m Learning iteration 27/3000 [0m                      

                       Computation: 91025 steps/s (collection: 0.961s, learning 0.119s)
               Value function loss: 0.2449
                    Surrogate loss: 0.0002
             Mean action noise std: 1.0790
                     Learning rate: 0.0013
                       Mean reward: -4.71
               Mean episode length: 32.75
       Episode_Reward/keep_balance: 0.0325
     Episode_Reward/rew_lin_vel_xy: 0.0280
      Episode_Reward/rew_ang_vel_z: 0.0523
    Episode_Reward/pen_base_height: -0.1416
      Episode_Reward/pen_lin_vel_z: -0.0134
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0070
Episode_Reward/pen_flat_orientation: -0.0988
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0359
Metrics/base_velocity/error_vel_xy: 0.1633
Metrics/base_velocity/error_vel_yaw: 0.0804
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 128.0417
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 1.08s
                        Total time: 32.88s
                               ETA: 3491.6s

################################################################################
                      [1m Learning iteration 28/3000 [0m                      

                       Computation: 90396 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.2632
                    Surrogate loss: 0.0047
             Mean action noise std: 1.0789
                     Learning rate: 0.0004
                       Mean reward: -4.53
               Mean episode length: 31.55
       Episode_Reward/keep_balance: 0.0320
     Episode_Reward/rew_lin_vel_xy: 0.0273
      Episode_Reward/rew_ang_vel_z: 0.0525
    Episode_Reward/pen_base_height: -0.1377
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0069
Episode_Reward/pen_flat_orientation: -0.0954
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0351
Metrics/base_velocity/error_vel_xy: 0.1624
Metrics/base_velocity/error_vel_yaw: 0.0764
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 128.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 1.09s
                        Total time: 33.97s
                               ETA: 3481.5s

################################################################################
                      [1m Learning iteration 29/3000 [0m                      

                       Computation: 90515 steps/s (collection: 0.967s, learning 0.119s)
               Value function loss: 0.2532
                    Surrogate loss: 0.0069
             Mean action noise std: 1.0795
                     Learning rate: 0.0000
                       Mean reward: -4.55
               Mean episode length: 31.61
       Episode_Reward/keep_balance: 0.0313
     Episode_Reward/rew_lin_vel_xy: 0.0275
      Episode_Reward/rew_ang_vel_z: 0.0519
    Episode_Reward/pen_base_height: -0.1350
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0037
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0068
Episode_Reward/pen_flat_orientation: -0.0938
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0345
Metrics/base_velocity/error_vel_xy: 0.1585
Metrics/base_velocity/error_vel_yaw: 0.0740
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 131.4583
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 1.09s
                        Total time: 35.06s
                               ETA: 3471.9s

################################################################################
                      [1m Learning iteration 30/3000 [0m                      

                       Computation: 90447 steps/s (collection: 0.967s, learning 0.120s)
               Value function loss: 0.2221
                    Surrogate loss: 0.0032
             Mean action noise std: 1.0797
                     Learning rate: 0.0001
                       Mean reward: -4.48
               Mean episode length: 30.91
       Episode_Reward/keep_balance: 0.0310
     Episode_Reward/rew_lin_vel_xy: 0.0265
      Episode_Reward/rew_ang_vel_z: 0.0522
    Episode_Reward/pen_base_height: -0.1347
      Episode_Reward/pen_lin_vel_z: -0.0133
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0037
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0067
Episode_Reward/pen_flat_orientation: -0.0929
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0343
Metrics/base_velocity/error_vel_xy: 0.1560
Metrics/base_velocity/error_vel_yaw: 0.0715
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 133.1667
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 1.09s
                        Total time: 36.14s
                               ETA: 3462.9s

################################################################################
                      [1m Learning iteration 31/3000 [0m                      

                       Computation: 91097 steps/s (collection: 0.959s, learning 0.120s)
               Value function loss: 0.2069
                    Surrogate loss: 0.0063
             Mean action noise std: 1.0803
                     Learning rate: 0.0001
                       Mean reward: -4.05
               Mean episode length: 30.05
       Episode_Reward/keep_balance: 0.0308
     Episode_Reward/rew_lin_vel_xy: 0.0266
      Episode_Reward/rew_ang_vel_z: 0.0523
    Episode_Reward/pen_base_height: -0.1308
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0035
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0067
Episode_Reward/pen_flat_orientation: -0.0896
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0339
Metrics/base_velocity/error_vel_xy: 0.1563
Metrics/base_velocity/error_vel_yaw: 0.0696
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 137.5833
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 1.08s
                        Total time: 37.22s
                               ETA: 3453.6s

################################################################################
                      [1m Learning iteration 32/3000 [0m                      

                       Computation: 90536 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.1867
                    Surrogate loss: 0.0098
             Mean action noise std: 1.0810
                     Learning rate: 0.0000
                       Mean reward: -3.84
               Mean episode length: 29.69
       Episode_Reward/keep_balance: 0.0299
     Episode_Reward/rew_lin_vel_xy: 0.0251
      Episode_Reward/rew_ang_vel_z: 0.0527
    Episode_Reward/pen_base_height: -0.1231
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0064
Episode_Reward/pen_flat_orientation: -0.0839
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0063
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0325
Metrics/base_velocity/error_vel_xy: 0.1550
Metrics/base_velocity/error_vel_yaw: 0.0639
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 139.0417
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 1.09s
                        Total time: 38.31s
                               ETA: 3445.5s

################################################################################
                      [1m Learning iteration 33/3000 [0m                      

                       Computation: 90432 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.1644
                    Surrogate loss: 0.0019
             Mean action noise std: 1.0804
                     Learning rate: 0.0001
                       Mean reward: -3.70
               Mean episode length: 27.61
       Episode_Reward/keep_balance: 0.0289
     Episode_Reward/rew_lin_vel_xy: 0.0244
      Episode_Reward/rew_ang_vel_z: 0.0524
    Episode_Reward/pen_base_height: -0.1166
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0027
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0061
Episode_Reward/pen_flat_orientation: -0.0788
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0064
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0312
Metrics/base_velocity/error_vel_xy: 0.1518
Metrics/base_velocity/error_vel_yaw: 0.0593
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 144.2917
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 1.09s
                        Total time: 39.40s
                               ETA: 3437.9s

################################################################################
                      [1m Learning iteration 34/3000 [0m                      

                       Computation: 90123 steps/s (collection: 0.969s, learning 0.121s)
               Value function loss: 0.1793
                    Surrogate loss: -0.0019
             Mean action noise std: 1.0764
                     Learning rate: 0.0006
                       Mean reward: -3.54
               Mean episode length: 28.28
       Episode_Reward/keep_balance: 0.0286
     Episode_Reward/rew_lin_vel_xy: 0.0239
      Episode_Reward/rew_ang_vel_z: 0.0535
    Episode_Reward/pen_base_height: -0.1138
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0025
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0060
Episode_Reward/pen_flat_orientation: -0.0754
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0068
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0308
Metrics/base_velocity/error_vel_xy: 0.1510
Metrics/base_velocity/error_vel_yaw: 0.0569
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 145.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 1.09s
                        Total time: 40.49s
                               ETA: 3431.0s

################################################################################
                      [1m Learning iteration 35/3000 [0m                      

                       Computation: 90043 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.1654
                    Surrogate loss: -0.0033
             Mean action noise std: 1.0665
                     Learning rate: 0.0009
                       Mean reward: -3.50
               Mean episode length: 29.12
       Episode_Reward/keep_balance: 0.0281
     Episode_Reward/rew_lin_vel_xy: 0.0236
      Episode_Reward/rew_ang_vel_z: 0.0526
    Episode_Reward/pen_base_height: -0.1095
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0023
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0059
Episode_Reward/pen_flat_orientation: -0.0721
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.0071
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0299
Metrics/base_velocity/error_vel_xy: 0.1494
Metrics/base_velocity/error_vel_yaw: 0.0558
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 146.1250
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 1.09s
                        Total time: 41.58s
                               ETA: 3424.5s

################################################################################
                      [1m Learning iteration 36/3000 [0m                      

                       Computation: 90777 steps/s (collection: 0.965s, learning 0.118s)
               Value function loss: 0.1458
                    Surrogate loss: -0.0020
             Mean action noise std: 1.0591
                     Learning rate: 0.0013
                       Mean reward: -3.23
               Mean episode length: 27.26
       Episode_Reward/keep_balance: 0.0277
     Episode_Reward/rew_lin_vel_xy: 0.0241
      Episode_Reward/rew_ang_vel_z: 0.0520
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0057
Episode_Reward/pen_flat_orientation: -0.0698
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.0072
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0295
Metrics/base_velocity/error_vel_xy: 0.1469
Metrics/base_velocity/error_vel_yaw: 0.0552
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 149.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 1.08s
                        Total time: 42.66s
                               ETA: 3417.5s

################################################################################
                      [1m Learning iteration 37/3000 [0m                      

                       Computation: 88538 steps/s (collection: 0.987s, learning 0.123s)
               Value function loss: 0.1467
                    Surrogate loss: -0.0016
             Mean action noise std: 1.0534
                     Learning rate: 0.0013
                       Mean reward: -3.25
               Mean episode length: 27.11
       Episode_Reward/keep_balance: 0.0274
     Episode_Reward/rew_lin_vel_xy: 0.0223
      Episode_Reward/rew_ang_vel_z: 0.0525
    Episode_Reward/pen_base_height: -0.1048
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0056
Episode_Reward/pen_flat_orientation: -0.0680
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0072
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0288
Metrics/base_velocity/error_vel_xy: 0.1493
Metrics/base_velocity/error_vel_yaw: 0.0532
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 149.3333
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 1.11s
                        Total time: 43.77s
                               ETA: 3413.1s

################################################################################
                      [1m Learning iteration 38/3000 [0m                      

                       Computation: 87625 steps/s (collection: 0.997s, learning 0.125s)
               Value function loss: 0.1180
                    Surrogate loss: -0.0029
             Mean action noise std: 1.0448
                     Learning rate: 0.0019
                       Mean reward: -3.25
               Mean episode length: 27.12
       Episode_Reward/keep_balance: 0.0272
     Episode_Reward/rew_lin_vel_xy: 0.0227
      Episode_Reward/rew_ang_vel_z: 0.0525
    Episode_Reward/pen_base_height: -0.1036
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0055
Episode_Reward/pen_flat_orientation: -0.0666
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0072
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0283
Metrics/base_velocity/error_vel_xy: 0.1475
Metrics/base_velocity/error_vel_yaw: 0.0521
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 151.7917
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 1.12s
                        Total time: 44.89s
                               ETA: 3409.6s

################################################################################
                      [1m Learning iteration 39/3000 [0m                      

                       Computation: 88632 steps/s (collection: 0.988s, learning 0.121s)
               Value function loss: 0.1020
                    Surrogate loss: 0.0002
             Mean action noise std: 1.0328
                     Learning rate: 0.0019
                       Mean reward: -3.23
               Mean episode length: 26.73
       Episode_Reward/keep_balance: 0.0269
     Episode_Reward/rew_lin_vel_xy: 0.0226
      Episode_Reward/rew_ang_vel_z: 0.0530
    Episode_Reward/pen_base_height: -0.1021
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0056
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0054
Episode_Reward/pen_flat_orientation: -0.0656
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0070
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0280
Metrics/base_velocity/error_vel_xy: 0.1459
Metrics/base_velocity/error_vel_yaw: 0.0499
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 151.0417
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 1.11s
                        Total time: 46.00s
                               ETA: 3405.4s

################################################################################
                      [1m Learning iteration 40/3000 [0m                      

                       Computation: 91189 steps/s (collection: 0.959s, learning 0.119s)
               Value function loss: 0.0991
                    Surrogate loss: -0.0009
             Mean action noise std: 1.0159
                     Learning rate: 0.0009
                       Mean reward: -3.18
               Mean episode length: 26.64
       Episode_Reward/keep_balance: 0.0270
     Episode_Reward/rew_lin_vel_xy: 0.0229
      Episode_Reward/rew_ang_vel_z: 0.0536
    Episode_Reward/pen_base_height: -0.1013
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0053
Episode_Reward/pen_flat_orientation: -0.0648
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0070
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0280
Metrics/base_velocity/error_vel_xy: 0.1461
Metrics/base_velocity/error_vel_yaw: 0.0493
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 152.9167
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 1.08s
                        Total time: 47.08s
                               ETA: 3399.0s

################################################################################
                      [1m Learning iteration 41/3000 [0m                      

                       Computation: 90194 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.1015
                    Surrogate loss: -0.0032
             Mean action noise std: 1.0064
                     Learning rate: 0.0019
                       Mean reward: -2.98
               Mean episode length: 27.05
       Episode_Reward/keep_balance: 0.0270
     Episode_Reward/rew_lin_vel_xy: 0.0226
      Episode_Reward/rew_ang_vel_z: 0.0547
    Episode_Reward/pen_base_height: -0.1008
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0056
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0052
Episode_Reward/pen_flat_orientation: -0.0643
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0069
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0279
Metrics/base_velocity/error_vel_xy: 0.1471
Metrics/base_velocity/error_vel_yaw: 0.0487
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 151.9167
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 1.09s
                        Total time: 48.17s
                               ETA: 3393.7s

################################################################################
                      [1m Learning iteration 42/3000 [0m                      

                       Computation: 88204 steps/s (collection: 0.990s, learning 0.125s)
               Value function loss: 0.0818
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9915
                     Learning rate: 0.0019
                       Mean reward: -2.98
               Mean episode length: 26.77
       Episode_Reward/keep_balance: 0.0271
     Episode_Reward/rew_lin_vel_xy: 0.0226
      Episode_Reward/rew_ang_vel_z: 0.0560
    Episode_Reward/pen_base_height: -0.1004
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0057
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0051
Episode_Reward/pen_flat_orientation: -0.0632
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0069
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0278
Metrics/base_velocity/error_vel_xy: 0.1474
Metrics/base_velocity/error_vel_yaw: 0.0469
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 151.5000
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 1.11s
                        Total time: 49.29s
                               ETA: 3390.4s

################################################################################
                      [1m Learning iteration 43/3000 [0m                      

                       Computation: 87406 steps/s (collection: 1.005s, learning 0.120s)
               Value function loss: 0.0793
                    Surrogate loss: -0.0012
             Mean action noise std: 0.9778
                     Learning rate: 0.0019
                       Mean reward: -3.09
               Mean episode length: 26.64
       Episode_Reward/keep_balance: 0.0271
     Episode_Reward/rew_lin_vel_xy: 0.0226
      Episode_Reward/rew_ang_vel_z: 0.0568
    Episode_Reward/pen_base_height: -0.1005
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0050
Episode_Reward/pen_flat_orientation: -0.0633
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0066
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0283
Metrics/base_velocity/error_vel_xy: 0.1473
Metrics/base_velocity/error_vel_yaw: 0.0463
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 149.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 1.12s
                        Total time: 50.41s
                               ETA: 3387.8s

################################################################################
                      [1m Learning iteration 44/3000 [0m                      

                       Computation: 89864 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 0.0876
                    Surrogate loss: -0.0021
             Mean action noise std: 0.9653
                     Learning rate: 0.0019
                       Mean reward: -3.01
               Mean episode length: 27.32
       Episode_Reward/keep_balance: 0.0274
     Episode_Reward/rew_lin_vel_xy: 0.0231
      Episode_Reward/rew_ang_vel_z: 0.0588
    Episode_Reward/pen_base_height: -0.1012
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0049
Episode_Reward/pen_flat_orientation: -0.0634
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0064
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0285
Metrics/base_velocity/error_vel_xy: 0.1485
Metrics/base_velocity/error_vel_yaw: 0.0454
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 146.4167
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 1.09s
                        Total time: 51.50s
                               ETA: 3383.2s

################################################################################
                      [1m Learning iteration 45/3000 [0m                      

                       Computation: 90582 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.0780
                    Surrogate loss: -0.0005
             Mean action noise std: 0.9543
                     Learning rate: 0.0019
                       Mean reward: -2.83
               Mean episode length: 26.87
       Episode_Reward/keep_balance: 0.0277
     Episode_Reward/rew_lin_vel_xy: 0.0230
      Episode_Reward/rew_ang_vel_z: 0.0608
    Episode_Reward/pen_base_height: -0.1012
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0048
Episode_Reward/pen_flat_orientation: -0.0635
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0063
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0288
Metrics/base_velocity/error_vel_xy: 0.1493
Metrics/base_velocity/error_vel_yaw: 0.0442
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 149.3750
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 1.09s
                        Total time: 52.59s
                               ETA: 3378.3s

################################################################################
                      [1m Learning iteration 46/3000 [0m                      

                       Computation: 89229 steps/s (collection: 0.977s, learning 0.124s)
               Value function loss: 0.0835
                    Surrogate loss: -0.0016
             Mean action noise std: 0.9445
                     Learning rate: 0.0009
                       Mean reward: -2.81
               Mean episode length: 26.84
       Episode_Reward/keep_balance: 0.0277
     Episode_Reward/rew_lin_vel_xy: 0.0240
      Episode_Reward/rew_ang_vel_z: 0.0616
    Episode_Reward/pen_base_height: -0.1010
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0047
Episode_Reward/pen_flat_orientation: -0.0631
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0289
Metrics/base_velocity/error_vel_xy: 0.1489
Metrics/base_velocity/error_vel_yaw: 0.0434
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 148.5833
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 1.10s
                        Total time: 53.69s
                               ETA: 3374.5s

################################################################################
                      [1m Learning iteration 47/3000 [0m                      

                       Computation: 90024 steps/s (collection: 0.972s, learning 0.120s)
               Value function loss: 0.0747
                    Surrogate loss: -0.0030
             Mean action noise std: 0.9281
                     Learning rate: 0.0013
                       Mean reward: -2.74
               Mean episode length: 28.35
       Episode_Reward/keep_balance: 0.0278
     Episode_Reward/rew_lin_vel_xy: 0.0234
      Episode_Reward/rew_ang_vel_z: 0.0624
    Episode_Reward/pen_base_height: -0.1012
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0046
Episode_Reward/pen_flat_orientation: -0.0621
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0289
Metrics/base_velocity/error_vel_xy: 0.1507
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 143.7917
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 1.09s
                        Total time: 54.78s
                               ETA: 3370.3s

################################################################################
                      [1m Learning iteration 48/3000 [0m                      

                       Computation: 89402 steps/s (collection: 0.978s, learning 0.122s)
               Value function loss: 0.0678
                    Surrogate loss: -0.0026
             Mean action noise std: 0.9147
                     Learning rate: 0.0019
                       Mean reward: -2.67
               Mean episode length: 28.59
       Episode_Reward/keep_balance: 0.0281
     Episode_Reward/rew_lin_vel_xy: 0.0237
      Episode_Reward/rew_ang_vel_z: 0.0640
    Episode_Reward/pen_base_height: -0.1010
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0045
Episode_Reward/pen_flat_orientation: -0.0620
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0059
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0291
Metrics/base_velocity/error_vel_xy: 0.1504
Metrics/base_velocity/error_vel_yaw: 0.0423
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 148.0417
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 1.10s
                        Total time: 55.88s
                               ETA: 3366.6s

################################################################################
                      [1m Learning iteration 49/3000 [0m                      

                       Computation: 89880 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 0.0687
                    Surrogate loss: -0.0016
             Mean action noise std: 0.9038
                     Learning rate: 0.0013
                       Mean reward: -2.76
               Mean episode length: 27.56
       Episode_Reward/keep_balance: 0.0280
     Episode_Reward/rew_lin_vel_xy: 0.0236
      Episode_Reward/rew_ang_vel_z: 0.0648
    Episode_Reward/pen_base_height: -0.1008
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0044
Episode_Reward/pen_flat_orientation: -0.0615
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0057
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0288
Metrics/base_velocity/error_vel_xy: 0.1515
Metrics/base_velocity/error_vel_yaw: 0.0412
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 146.2500
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 1.09s
                        Total time: 56.98s
                               ETA: 3362.7s

################################################################################
                      [1m Learning iteration 50/3000 [0m                      

                       Computation: 89752 steps/s (collection: 0.968s, learning 0.127s)
               Value function loss: 0.0744
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8913
                     Learning rate: 0.0019
                       Mean reward: -2.61
               Mean episode length: 28.91
       Episode_Reward/keep_balance: 0.0283
     Episode_Reward/rew_lin_vel_xy: 0.0237
      Episode_Reward/rew_ang_vel_z: 0.0668
    Episode_Reward/pen_base_height: -0.1011
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0043
Episode_Reward/pen_flat_orientation: -0.0611
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0290
Metrics/base_velocity/error_vel_xy: 0.1533
Metrics/base_velocity/error_vel_yaw: 0.0406
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 145.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 1.10s
                        Total time: 58.07s
                               ETA: 3359.0s

################################################################################
                      [1m Learning iteration 51/3000 [0m                      

                       Computation: 90906 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.0834
                    Surrogate loss: 0.0005
             Mean action noise std: 0.8821
                     Learning rate: 0.0009
                       Mean reward: -2.59
               Mean episode length: 27.90
       Episode_Reward/keep_balance: 0.0283
     Episode_Reward/rew_lin_vel_xy: 0.0235
      Episode_Reward/rew_ang_vel_z: 0.0671
    Episode_Reward/pen_base_height: -0.1006
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0043
Episode_Reward/pen_flat_orientation: -0.0606
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0288
Metrics/base_velocity/error_vel_xy: 0.1523
Metrics/base_velocity/error_vel_yaw: 0.0405
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 142.9167
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 1.08s
                        Total time: 59.15s
                               ETA: 3354.6s

################################################################################
                      [1m Learning iteration 52/3000 [0m                      

                       Computation: 89241 steps/s (collection: 0.977s, learning 0.124s)
               Value function loss: 0.0690
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8706
                     Learning rate: 0.0009
                       Mean reward: -2.66
               Mean episode length: 28.93
       Episode_Reward/keep_balance: 0.0283
     Episode_Reward/rew_lin_vel_xy: 0.0242
      Episode_Reward/rew_ang_vel_z: 0.0686
    Episode_Reward/pen_base_height: -0.1006
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0042
Episode_Reward/pen_flat_orientation: -0.0601
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0054
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0289
Metrics/base_velocity/error_vel_xy: 0.1507
Metrics/base_velocity/error_vel_yaw: 0.0390
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 142.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 1.10s
                        Total time: 60.25s
                               ETA: 3351.5s

################################################################################
                      [1m Learning iteration 53/3000 [0m                      

                       Computation: 89315 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 0.0788
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8593
                     Learning rate: 0.0019
                       Mean reward: -2.58
               Mean episode length: 28.66
       Episode_Reward/keep_balance: 0.0285
     Episode_Reward/rew_lin_vel_xy: 0.0247
      Episode_Reward/rew_ang_vel_z: 0.0692
    Episode_Reward/pen_base_height: -0.1010
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0602
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0292
Metrics/base_velocity/error_vel_xy: 0.1517
Metrics/base_velocity/error_vel_yaw: 0.0394
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 143.9583
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 1.10s
                        Total time: 61.35s
                               ETA: 3348.4s

################################################################################
                      [1m Learning iteration 54/3000 [0m                      

                       Computation: 89470 steps/s (collection: 0.974s, learning 0.125s)
               Value function loss: 0.0703
                    Surrogate loss: 0.0034
             Mean action noise std: 0.8497
                     Learning rate: 0.0009
                       Mean reward: -2.61
               Mean episode length: 28.81
       Episode_Reward/keep_balance: 0.0288
     Episode_Reward/rew_lin_vel_xy: 0.0252
      Episode_Reward/rew_ang_vel_z: 0.0716
    Episode_Reward/pen_base_height: -0.1011
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0597
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0296
Metrics/base_velocity/error_vel_xy: 0.1531
Metrics/base_velocity/error_vel_yaw: 0.0386
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 141.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 1.10s
                        Total time: 62.45s
                               ETA: 3345.2s

################################################################################
                      [1m Learning iteration 55/3000 [0m                      

                       Computation: 89584 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.0710
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8388
                     Learning rate: 0.0013
                       Mean reward: -2.43
               Mean episode length: 29.40
       Episode_Reward/keep_balance: 0.0290
     Episode_Reward/rew_lin_vel_xy: 0.0253
      Episode_Reward/rew_ang_vel_z: 0.0722
    Episode_Reward/pen_base_height: -0.1010
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0591
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0297
Metrics/base_velocity/error_vel_xy: 0.1544
Metrics/base_velocity/error_vel_yaw: 0.0381
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 139.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 1.10s
                        Total time: 63.55s
                               ETA: 3342.1s

################################################################################
                      [1m Learning iteration 56/3000 [0m                      

                       Computation: 89215 steps/s (collection: 0.977s, learning 0.125s)
               Value function loss: 0.0774
                    Surrogate loss: -0.0011
             Mean action noise std: 0.8304
                     Learning rate: 0.0013
                       Mean reward: -2.33
               Mean episode length: 29.98
       Episode_Reward/keep_balance: 0.0293
     Episode_Reward/rew_lin_vel_xy: 0.0259
      Episode_Reward/rew_ang_vel_z: 0.0743
    Episode_Reward/pen_base_height: -0.1022
      Episode_Reward/pen_lin_vel_z: -0.0112
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0593
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0049
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0301
Metrics/base_velocity/error_vel_xy: 0.1543
Metrics/base_velocity/error_vel_yaw: 0.0377
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 139.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 1.10s
                        Total time: 64.65s
                               ETA: 3339.3s

################################################################################
                      [1m Learning iteration 57/3000 [0m                      

                       Computation: 90429 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.0739
                    Surrogate loss: -0.0010
             Mean action noise std: 0.8190
                     Learning rate: 0.0013
                       Mean reward: -2.39
               Mean episode length: 30.09
       Episode_Reward/keep_balance: 0.0297
     Episode_Reward/rew_lin_vel_xy: 0.0266
      Episode_Reward/rew_ang_vel_z: 0.0757
    Episode_Reward/pen_base_height: -0.1019
      Episode_Reward/pen_lin_vel_z: -0.0110
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0306
Metrics/base_velocity/error_vel_xy: 0.1569
Metrics/base_velocity/error_vel_yaw: 0.0378
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 138.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 1.09s
                        Total time: 65.74s
                               ETA: 3335.7s

################################################################################
                      [1m Learning iteration 58/3000 [0m                      

                       Computation: 91120 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.0844
                    Surrogate loss: 0.0018
             Mean action noise std: 0.8136
                     Learning rate: 0.0006
                       Mean reward: -2.23
               Mean episode length: 29.37
       Episode_Reward/keep_balance: 0.0299
     Episode_Reward/rew_lin_vel_xy: 0.0259
      Episode_Reward/rew_ang_vel_z: 0.0769
    Episode_Reward/pen_base_height: -0.1020
      Episode_Reward/pen_lin_vel_z: -0.0110
     Episode_Reward/pen_ang_vel_xy: -0.0201
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0306
Metrics/base_velocity/error_vel_xy: 0.1583
Metrics/base_velocity/error_vel_yaw: 0.0377
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 135.4167
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 1.08s
                        Total time: 66.82s
                               ETA: 3331.9s

################################################################################
                      [1m Learning iteration 59/3000 [0m                      

                       Computation: 89987 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.0876
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8045
                     Learning rate: 0.0009
                       Mean reward: -2.35
               Mean episode length: 30.66
       Episode_Reward/keep_balance: 0.0302
     Episode_Reward/rew_lin_vel_xy: 0.0266
      Episode_Reward/rew_ang_vel_z: 0.0784
    Episode_Reward/pen_base_height: -0.1024
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0582
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0307
Metrics/base_velocity/error_vel_xy: 0.1578
Metrics/base_velocity/error_vel_yaw: 0.0374
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 133.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 1.09s
                        Total time: 67.91s
                               ETA: 3328.8s

################################################################################
                      [1m Learning iteration 60/3000 [0m                      

                       Computation: 90818 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.0889
                    Surrogate loss: -0.0002
             Mean action noise std: 0.7960
                     Learning rate: 0.0013
                       Mean reward: -2.12
               Mean episode length: 30.39
       Episode_Reward/keep_balance: 0.0305
     Episode_Reward/rew_lin_vel_xy: 0.0267
      Episode_Reward/rew_ang_vel_z: 0.0802
    Episode_Reward/pen_base_height: -0.1024
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0310
Metrics/base_velocity/error_vel_xy: 0.1630
Metrics/base_velocity/error_vel_yaw: 0.0373
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 134.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 1.08s
                        Total time: 68.99s
                               ETA: 3325.3s

################################################################################
                      [1m Learning iteration 61/3000 [0m                      

                       Computation: 90602 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 0.0919
                    Surrogate loss: 0.0003
             Mean action noise std: 0.7910
                     Learning rate: 0.0006
                       Mean reward: -2.06
               Mean episode length: 30.45
       Episode_Reward/keep_balance: 0.0305
     Episode_Reward/rew_lin_vel_xy: 0.0263
      Episode_Reward/rew_ang_vel_z: 0.0809
    Episode_Reward/pen_base_height: -0.1028
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0579
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0309
Metrics/base_velocity/error_vel_xy: 0.1620
Metrics/base_velocity/error_vel_yaw: 0.0363
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 133.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 1.09s
                        Total time: 70.08s
                               ETA: 3322.0s

################################################################################
                      [1m Learning iteration 62/3000 [0m                      

                       Computation: 90426 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.0947
                    Surrogate loss: -0.0011
             Mean action noise std: 0.7828
                     Learning rate: 0.0009
                       Mean reward: -2.13
               Mean episode length: 31.80
       Episode_Reward/keep_balance: 0.0308
     Episode_Reward/rew_lin_vel_xy: 0.0258
      Episode_Reward/rew_ang_vel_z: 0.0824
    Episode_Reward/pen_base_height: -0.1028
      Episode_Reward/pen_lin_vel_z: -0.0107
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0313
Metrics/base_velocity/error_vel_xy: 0.1638
Metrics/base_velocity/error_vel_yaw: 0.0363
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 131.8333
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 1.09s
                        Total time: 71.17s
                               ETA: 3318.8s

################################################################################
                      [1m Learning iteration 63/3000 [0m                      

                       Computation: 90963 steps/s (collection: 0.960s, learning 0.120s)
               Value function loss: 0.0941
                    Surrogate loss: -0.0031
             Mean action noise std: 0.7770
                     Learning rate: 0.0009
                       Mean reward: -2.21
               Mean episode length: 30.63
       Episode_Reward/keep_balance: 0.0311
     Episode_Reward/rew_lin_vel_xy: 0.0271
      Episode_Reward/rew_ang_vel_z: 0.0834
    Episode_Reward/pen_base_height: -0.1032
      Episode_Reward/pen_lin_vel_z: -0.0106
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0043
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0316
Metrics/base_velocity/error_vel_xy: 0.1638
Metrics/base_velocity/error_vel_yaw: 0.0367
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 131.2083
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 1.08s
                        Total time: 72.25s
                               ETA: 3315.4s

################################################################################
                      [1m Learning iteration 64/3000 [0m                      

                       Computation: 89869 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.0941
                    Surrogate loss: 0.0010
             Mean action noise std: 0.7691
                     Learning rate: 0.0009
                       Mean reward: -2.07
               Mean episode length: 30.67
       Episode_Reward/keep_balance: 0.0313
     Episode_Reward/rew_lin_vel_xy: 0.0271
      Episode_Reward/rew_ang_vel_z: 0.0845
    Episode_Reward/pen_base_height: -0.1036
      Episode_Reward/pen_lin_vel_z: -0.0105
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0318
Metrics/base_velocity/error_vel_xy: 0.1656
Metrics/base_velocity/error_vel_yaw: 0.0362
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 128.5000
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 1.09s
                        Total time: 73.34s
                               ETA: 3312.7s

################################################################################
                      [1m Learning iteration 65/3000 [0m                      

                       Computation: 90748 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.0915
                    Surrogate loss: -0.0013
             Mean action noise std: 0.7637
                     Learning rate: 0.0013
                       Mean reward: -2.06
               Mean episode length: 31.40
       Episode_Reward/keep_balance: 0.0316
     Episode_Reward/rew_lin_vel_xy: 0.0271
      Episode_Reward/rew_ang_vel_z: 0.0856
    Episode_Reward/pen_base_height: -0.1036
      Episode_Reward/pen_lin_vel_z: -0.0104
     Episode_Reward/pen_ang_vel_xy: -0.0190
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0589
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0320
Metrics/base_velocity/error_vel_xy: 0.1665
Metrics/base_velocity/error_vel_yaw: 0.0364
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 130.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 1.08s
                        Total time: 74.42s
                               ETA: 3309.6s

################################################################################
                      [1m Learning iteration 66/3000 [0m                      

                       Computation: 91226 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.0997
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7591
                     Learning rate: 0.0009
                       Mean reward: -2.06
               Mean episode length: 32.78
       Episode_Reward/keep_balance: 0.0316
     Episode_Reward/rew_lin_vel_xy: 0.0266
      Episode_Reward/rew_ang_vel_z: 0.0861
    Episode_Reward/pen_base_height: -0.1037
      Episode_Reward/pen_lin_vel_z: -0.0105
     Episode_Reward/pen_ang_vel_xy: -0.0193
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0592
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0320
Metrics/base_velocity/error_vel_xy: 0.1671
Metrics/base_velocity/error_vel_yaw: 0.0359
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 131.2083
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 1.08s
                        Total time: 75.50s
                               ETA: 3306.3s

################################################################################
                      [1m Learning iteration 67/3000 [0m                      

                       Computation: 89990 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.0972
                    Surrogate loss: -0.0001
             Mean action noise std: 0.7527
                     Learning rate: 0.0013
                       Mean reward: -2.16
               Mean episode length: 30.25
       Episode_Reward/keep_balance: 0.0316
     Episode_Reward/rew_lin_vel_xy: 0.0276
      Episode_Reward/rew_ang_vel_z: 0.0866
    Episode_Reward/pen_base_height: -0.1033
      Episode_Reward/pen_lin_vel_z: -0.0105
     Episode_Reward/pen_ang_vel_xy: -0.0191
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0319
Metrics/base_velocity/error_vel_xy: 0.1668
Metrics/base_velocity/error_vel_yaw: 0.0354
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 127.0417
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 1.09s
                        Total time: 76.59s
                               ETA: 3303.7s

################################################################################
                      [1m Learning iteration 68/3000 [0m                      

                       Computation: 88446 steps/s (collection: 0.988s, learning 0.123s)
               Value function loss: 0.0905
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7476
                     Learning rate: 0.0006
                       Mean reward: -1.96
               Mean episode length: 32.84
       Episode_Reward/keep_balance: 0.0321
     Episode_Reward/rew_lin_vel_xy: 0.0289
      Episode_Reward/rew_ang_vel_z: 0.0885
    Episode_Reward/pen_base_height: -0.1043
      Episode_Reward/pen_lin_vel_z: -0.0104
     Episode_Reward/pen_ang_vel_xy: -0.0191
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0590
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0325
Metrics/base_velocity/error_vel_xy: 0.1676
Metrics/base_velocity/error_vel_yaw: 0.0357
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 125.1250
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 1.11s
                        Total time: 77.70s
                               ETA: 3301.9s

################################################################################
                      [1m Learning iteration 69/3000 [0m                      

                       Computation: 90246 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.0860
                    Surrogate loss: -0.0026
             Mean action noise std: 0.7423
                     Learning rate: 0.0009
                       Mean reward: -2.00
               Mean episode length: 32.03
       Episode_Reward/keep_balance: 0.0322
     Episode_Reward/rew_lin_vel_xy: 0.0277
      Episode_Reward/rew_ang_vel_z: 0.0894
    Episode_Reward/pen_base_height: -0.1034
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0190
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0323
Metrics/base_velocity/error_vel_xy: 0.1690
Metrics/base_velocity/error_vel_yaw: 0.0347
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 129.8333
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 1.09s
                        Total time: 78.79s
                               ETA: 3299.2s

################################################################################
                      [1m Learning iteration 70/3000 [0m                      

                       Computation: 91407 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.0999
                    Surrogate loss: -0.0019
             Mean action noise std: 0.7359
                     Learning rate: 0.0009
                       Mean reward: -1.92
               Mean episode length: 31.58
       Episode_Reward/keep_balance: 0.0321
     Episode_Reward/rew_lin_vel_xy: 0.0284
      Episode_Reward/rew_ang_vel_z: 0.0893
    Episode_Reward/pen_base_height: -0.1033
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0190
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0589
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0322
Metrics/base_velocity/error_vel_xy: 0.1678
Metrics/base_velocity/error_vel_yaw: 0.0347
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 125.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 1.08s
                        Total time: 79.87s
                               ETA: 3296.0s

################################################################################
                      [1m Learning iteration 71/3000 [0m                      

                       Computation: 91170 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.1023
                    Surrogate loss: -0.0006
             Mean action noise std: 0.7311
                     Learning rate: 0.0009
                       Mean reward: -1.92
               Mean episode length: 32.39
       Episode_Reward/keep_balance: 0.0325
     Episode_Reward/rew_lin_vel_xy: 0.0280
      Episode_Reward/rew_ang_vel_z: 0.0906
    Episode_Reward/pen_base_height: -0.1035
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0189
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0590
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0327
Metrics/base_velocity/error_vel_xy: 0.1722
Metrics/base_velocity/error_vel_yaw: 0.0352
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 124.6667
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 1.08s
                        Total time: 80.95s
                               ETA: 3293.0s

################################################################################
                      [1m Learning iteration 72/3000 [0m                      

                       Computation: 91231 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.0989
                    Surrogate loss: -0.0032
             Mean action noise std: 0.7247
                     Learning rate: 0.0013
                       Mean reward: -1.82
               Mean episode length: 33.23
       Episode_Reward/keep_balance: 0.0328
     Episode_Reward/rew_lin_vel_xy: 0.0279
      Episode_Reward/rew_ang_vel_z: 0.0918
    Episode_Reward/pen_base_height: -0.1038
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0188
   Episode_Reward/pen_joint_torque: -0.0022
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0328
Metrics/base_velocity/error_vel_xy: 0.1720
Metrics/base_velocity/error_vel_yaw: 0.0352
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 127.1250
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 1.08s
                        Total time: 82.03s
                               ETA: 3290.0s

################################################################################
                      [1m Learning iteration 73/3000 [0m                      

                       Computation: 90846 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.1086
                    Surrogate loss: 0.0002
             Mean action noise std: 0.7203
                     Learning rate: 0.0019
                       Mean reward: -1.95
               Mean episode length: 33.41
       Episode_Reward/keep_balance: 0.0326
     Episode_Reward/rew_lin_vel_xy: 0.0293
      Episode_Reward/rew_ang_vel_z: 0.0917
    Episode_Reward/pen_base_height: -0.1029
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0188
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0325
Metrics/base_velocity/error_vel_xy: 0.1699
Metrics/base_velocity/error_vel_yaw: 0.0347
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 124.5000
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 1.08s
                        Total time: 83.11s
                               ETA: 3287.2s

################################################################################
                      [1m Learning iteration 74/3000 [0m                      

                       Computation: 90860 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.1238
                    Surrogate loss: -0.0000
             Mean action noise std: 0.7150
                     Learning rate: 0.0013
                       Mean reward: -1.87
               Mean episode length: 32.11
       Episode_Reward/keep_balance: 0.0329
     Episode_Reward/rew_lin_vel_xy: 0.0292
      Episode_Reward/rew_ang_vel_z: 0.0928
    Episode_Reward/pen_base_height: -0.1031
      Episode_Reward/pen_lin_vel_z: -0.0103
     Episode_Reward/pen_ang_vel_xy: -0.0187
   Episode_Reward/pen_joint_torque: -0.0022
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0327
Metrics/base_velocity/error_vel_xy: 0.1721
Metrics/base_velocity/error_vel_yaw: 0.0348
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 123.1250
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 1.08s
                        Total time: 84.19s
                               ETA: 3284.5s

################################################################################
                      [1m Learning iteration 75/3000 [0m                      

                       Computation: 91826 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 0.1114
                    Surrogate loss: -0.0031
             Mean action noise std: 0.7089
                     Learning rate: 0.0019
                       Mean reward: -1.77
               Mean episode length: 34.15
       Episode_Reward/keep_balance: 0.0331
     Episode_Reward/rew_lin_vel_xy: 0.0290
      Episode_Reward/rew_ang_vel_z: 0.0931
    Episode_Reward/pen_base_height: -0.1030
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0187
   Episode_Reward/pen_joint_torque: -0.0022
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0582
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0330
Metrics/base_velocity/error_vel_xy: 0.1740
Metrics/base_velocity/error_vel_yaw: 0.0350
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 121.5417
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 1.07s
                        Total time: 85.26s
                               ETA: 3281.4s

################################################################################
                      [1m Learning iteration 76/3000 [0m                      

                       Computation: 90535 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.0945
                    Surrogate loss: -0.0008
             Mean action noise std: 0.7051
                     Learning rate: 0.0013
                       Mean reward: -1.80
               Mean episode length: 33.81
       Episode_Reward/keep_balance: 0.0337
     Episode_Reward/rew_lin_vel_xy: 0.0303
      Episode_Reward/rew_ang_vel_z: 0.0953
    Episode_Reward/pen_base_height: -0.1031
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0187
   Episode_Reward/pen_joint_torque: -0.0022
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0335
Metrics/base_velocity/error_vel_xy: 0.1760
Metrics/base_velocity/error_vel_yaw: 0.0354
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 124.5833
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 1.09s
                        Total time: 86.35s
                               ETA: 3278.9s

################################################################################
                      [1m Learning iteration 77/3000 [0m                      

                       Computation: 91067 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.0935
                    Surrogate loss: 0.0000
             Mean action noise std: 0.7010
                     Learning rate: 0.0013
                       Mean reward: -1.87
               Mean episode length: 33.29
       Episode_Reward/keep_balance: 0.0335
     Episode_Reward/rew_lin_vel_xy: 0.0291
      Episode_Reward/rew_ang_vel_z: 0.0951
    Episode_Reward/pen_base_height: -0.1028
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0188
   Episode_Reward/pen_joint_torque: -0.0022
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0033
Episode_Reward/pen_flat_orientation: -0.0578
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0334
Metrics/base_velocity/error_vel_xy: 0.1780
Metrics/base_velocity/error_vel_yaw: 0.0347
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 119.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 1.08s
                        Total time: 87.43s
                               ETA: 3276.2s

################################################################################
                      [1m Learning iteration 78/3000 [0m                      

                       Computation: 88449 steps/s (collection: 0.990s, learning 0.122s)
               Value function loss: 0.1076
                    Surrogate loss: 0.0027
             Mean action noise std: 0.6987
                     Learning rate: 0.0006
                       Mean reward: -1.87
               Mean episode length: 34.95
       Episode_Reward/keep_balance: 0.0341
     Episode_Reward/rew_lin_vel_xy: 0.0299
      Episode_Reward/rew_ang_vel_z: 0.0970
    Episode_Reward/pen_base_height: -0.1033
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0186
   Episode_Reward/pen_joint_torque: -0.0023
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0341
Metrics/base_velocity/error_vel_xy: 0.1808
Metrics/base_velocity/error_vel_yaw: 0.0355
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 117.3333
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 1.11s
                        Total time: 88.54s
                               ETA: 3274.7s

################################################################################
                      [1m Learning iteration 79/3000 [0m                      

                       Computation: 90043 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.1139
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6945
                     Learning rate: 0.0009
                       Mean reward: -1.60
               Mean episode length: 35.19
       Episode_Reward/keep_balance: 0.0346
     Episode_Reward/rew_lin_vel_xy: 0.0301
      Episode_Reward/rew_ang_vel_z: 0.0985
    Episode_Reward/pen_base_height: -0.1033
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0187
   Episode_Reward/pen_joint_torque: -0.0023
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0587
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0346
Metrics/base_velocity/error_vel_xy: 0.1834
Metrics/base_velocity/error_vel_yaw: 0.0361
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 119.8333
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 1.09s
                        Total time: 89.63s
                               ETA: 3272.6s

################################################################################
                      [1m Learning iteration 80/3000 [0m                      

                       Computation: 90136 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.1203
                    Surrogate loss: -0.0001
             Mean action noise std: 0.6919
                     Learning rate: 0.0006
                       Mean reward: -1.82
               Mean episode length: 34.40
       Episode_Reward/keep_balance: 0.0345
     Episode_Reward/rew_lin_vel_xy: 0.0316
      Episode_Reward/rew_ang_vel_z: 0.0985
    Episode_Reward/pen_base_height: -0.1030
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0190
   Episode_Reward/pen_joint_torque: -0.0023
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0578
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0343
Metrics/base_velocity/error_vel_xy: 0.1803
Metrics/base_velocity/error_vel_yaw: 0.0356
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 118.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 1.09s
                        Total time: 90.72s
                               ETA: 3270.4s

################################################################################
                      [1m Learning iteration 81/3000 [0m                      

                       Computation: 89418 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.1119
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6877
                     Learning rate: 0.0009
                       Mean reward: -1.79
               Mean episode length: 34.59
       Episode_Reward/keep_balance: 0.0345
     Episode_Reward/rew_lin_vel_xy: 0.0312
      Episode_Reward/rew_ang_vel_z: 0.0989
    Episode_Reward/pen_base_height: -0.1027
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0189
   Episode_Reward/pen_joint_torque: -0.0023
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0033
Episode_Reward/pen_flat_orientation: -0.0576
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0343
Metrics/base_velocity/error_vel_xy: 0.1808
Metrics/base_velocity/error_vel_yaw: 0.0348
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 1.10s
                        Total time: 91.82s
                               ETA: 3268.5s

################################################################################
                      [1m Learning iteration 82/3000 [0m                      

                       Computation: 87913 steps/s (collection: 0.995s, learning 0.123s)
               Value function loss: 0.1137
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6845
                     Learning rate: 0.0009
                       Mean reward: -1.45
               Mean episode length: 35.89
       Episode_Reward/keep_balance: 0.0351
     Episode_Reward/rew_lin_vel_xy: 0.0309
      Episode_Reward/rew_ang_vel_z: 0.1007
    Episode_Reward/pen_base_height: -0.1026
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0191
   Episode_Reward/pen_joint_torque: -0.0024
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0579
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0349
Metrics/base_velocity/error_vel_xy: 0.1845
Metrics/base_velocity/error_vel_yaw: 0.0356
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 116.7083
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 1.12s
                        Total time: 92.94s
                               ETA: 3267.3s

################################################################################
                      [1m Learning iteration 83/3000 [0m                      

                       Computation: 89664 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.1184
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6804
                     Learning rate: 0.0009
                       Mean reward: -1.58
               Mean episode length: 35.76
       Episode_Reward/keep_balance: 0.0354
     Episode_Reward/rew_lin_vel_xy: 0.0333
      Episode_Reward/rew_ang_vel_z: 0.1021
    Episode_Reward/pen_base_height: -0.1025
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0190
   Episode_Reward/pen_joint_torque: -0.0025
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0353
Metrics/base_velocity/error_vel_xy: 0.1827
Metrics/base_velocity/error_vel_yaw: 0.0357
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 117.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 1.10s
                        Total time: 94.03s
                               ETA: 3265.4s

################################################################################
                      [1m Learning iteration 84/3000 [0m                      

                       Computation: 88643 steps/s (collection: 0.980s, learning 0.129s)
               Value function loss: 0.1147
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6772
                     Learning rate: 0.0009
                       Mean reward: -1.71
               Mean episode length: 34.20
       Episode_Reward/keep_balance: 0.0354
     Episode_Reward/rew_lin_vel_xy: 0.0315
      Episode_Reward/rew_ang_vel_z: 0.1017
    Episode_Reward/pen_base_height: -0.1022
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0192
   Episode_Reward/pen_joint_torque: -0.0025
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0033
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0353
Metrics/base_velocity/error_vel_xy: 0.1866
Metrics/base_velocity/error_vel_yaw: 0.0357
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 109.7083
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 1.11s
                        Total time: 95.14s
                               ETA: 3263.9s

################################################################################
                      [1m Learning iteration 85/3000 [0m                      

                       Computation: 88175 steps/s (collection: 0.986s, learning 0.129s)
               Value function loss: 0.1205
                    Surrogate loss: 0.0038
             Mean action noise std: 0.6752
                     Learning rate: 0.0003
                       Mean reward: -1.61
               Mean episode length: 34.23
       Episode_Reward/keep_balance: 0.0362
     Episode_Reward/rew_lin_vel_xy: 0.0337
      Episode_Reward/rew_ang_vel_z: 0.1046
    Episode_Reward/pen_base_height: -0.1030
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0189
   Episode_Reward/pen_joint_torque: -0.0026
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0361
Metrics/base_velocity/error_vel_xy: 0.1871
Metrics/base_velocity/error_vel_yaw: 0.0365
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.2500
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 1.11s
                        Total time: 96.26s
                               ETA: 3262.7s

################################################################################
                      [1m Learning iteration 86/3000 [0m                      

                       Computation: 90338 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.1166
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6727
                     Learning rate: 0.0006
                       Mean reward: -1.65
               Mean episode length: 35.91
       Episode_Reward/keep_balance: 0.0362
     Episode_Reward/rew_lin_vel_xy: 0.0337
      Episode_Reward/rew_ang_vel_z: 0.1051
    Episode_Reward/pen_base_height: -0.1031
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0188
   Episode_Reward/pen_joint_torque: -0.0026
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0033
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0360
Metrics/base_velocity/error_vel_xy: 0.1881
Metrics/base_velocity/error_vel_yaw: 0.0358
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 111.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 1.09s
                        Total time: 97.34s
                               ETA: 3260.5s

################################################################################
                      [1m Learning iteration 87/3000 [0m                      

                       Computation: 89947 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.1204
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6687
                     Learning rate: 0.0013
                       Mean reward: -1.48
               Mean episode length: 37.63
       Episode_Reward/keep_balance: 0.0368
     Episode_Reward/rew_lin_vel_xy: 0.0335
      Episode_Reward/rew_ang_vel_z: 0.1067
    Episode_Reward/pen_base_height: -0.1038
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0187
   Episode_Reward/pen_joint_torque: -0.0027
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0588
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0366
Metrics/base_velocity/error_vel_xy: 0.1913
Metrics/base_velocity/error_vel_yaw: 0.0366
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 110.6250
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 1.09s
                        Total time: 98.44s
                               ETA: 3258.5s

################################################################################
                      [1m Learning iteration 88/3000 [0m                      

                       Computation: 90265 steps/s (collection: 0.962s, learning 0.127s)
               Value function loss: 0.1347
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6663
                     Learning rate: 0.0009
                       Mean reward: -1.52
               Mean episode length: 37.23
       Episode_Reward/keep_balance: 0.0368
     Episode_Reward/rew_lin_vel_xy: 0.0331
      Episode_Reward/rew_ang_vel_z: 0.1067
    Episode_Reward/pen_base_height: -0.1033
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0188
   Episode_Reward/pen_joint_torque: -0.0027
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0366
Metrics/base_velocity/error_vel_xy: 0.1911
Metrics/base_velocity/error_vel_yaw: 0.0366
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 110.3333
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 1.09s
                        Total time: 99.53s
                               ETA: 3256.4s

################################################################################
                      [1m Learning iteration 89/3000 [0m                      

                       Computation: 89579 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.1415
                    Surrogate loss: 0.0004
             Mean action noise std: 0.6639
                     Learning rate: 0.0013
                       Mean reward: -1.43
               Mean episode length: 36.91
       Episode_Reward/keep_balance: 0.0371
     Episode_Reward/rew_lin_vel_xy: 0.0328
      Episode_Reward/rew_ang_vel_z: 0.1075
    Episode_Reward/pen_base_height: -0.1032
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0188
   Episode_Reward/pen_joint_torque: -0.0028
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0584
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0370
Metrics/base_velocity/error_vel_xy: 0.1945
Metrics/base_velocity/error_vel_yaw: 0.0370
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 111.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 1.10s
                        Total time: 100.62s
                               ETA: 3254.6s

################################################################################
                      [1m Learning iteration 90/3000 [0m                      

                       Computation: 90506 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.1627
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6618
                     Learning rate: 0.0019
                       Mean reward: -1.46
               Mean episode length: 37.46
       Episode_Reward/keep_balance: 0.0374
     Episode_Reward/rew_lin_vel_xy: 0.0343
      Episode_Reward/rew_ang_vel_z: 0.1090
    Episode_Reward/pen_base_height: -0.1032
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0189
   Episode_Reward/pen_joint_torque: -0.0028
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0575
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0373
Metrics/base_velocity/error_vel_xy: 0.1947
Metrics/base_velocity/error_vel_yaw: 0.0366
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 105.2500
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 1.09s
                        Total time: 101.71s
                               ETA: 3252.5s

################################################################################
                      [1m Learning iteration 91/3000 [0m                      

                       Computation: 89140 steps/s (collection: 0.978s, learning 0.125s)
               Value function loss: 0.1249
                    Surrogate loss: 0.0020
             Mean action noise std: 0.6601
                     Learning rate: 0.0006
                       Mean reward: -1.49
               Mean episode length: 38.65
       Episode_Reward/keep_balance: 0.0379
     Episode_Reward/rew_lin_vel_xy: 0.0362
      Episode_Reward/rew_ang_vel_z: 0.1107
    Episode_Reward/pen_base_height: -0.1038
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0190
   Episode_Reward/pen_joint_torque: -0.0028
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0587
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0379
Metrics/base_velocity/error_vel_xy: 0.1945
Metrics/base_velocity/error_vel_yaw: 0.0375
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 109.0417
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 1.10s
                        Total time: 102.81s
                               ETA: 3250.9s

################################################################################
                      [1m Learning iteration 92/3000 [0m                      

                       Computation: 91110 steps/s (collection: 0.954s, learning 0.125s)
               Value function loss: 0.1308
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6564
                     Learning rate: 0.0013
                       Mean reward: -1.51
               Mean episode length: 37.99
       Episode_Reward/keep_balance: 0.0380
     Episode_Reward/rew_lin_vel_xy: 0.0357
      Episode_Reward/rew_ang_vel_z: 0.1114
    Episode_Reward/pen_base_height: -0.1039
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0192
   Episode_Reward/pen_joint_torque: -0.0029
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0380
Metrics/base_velocity/error_vel_xy: 0.1950
Metrics/base_velocity/error_vel_yaw: 0.0368
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 107.4583
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 1.08s
                        Total time: 103.89s
                               ETA: 3248.6s

################################################################################
                      [1m Learning iteration 93/3000 [0m                      

                       Computation: 90724 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.1603
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6533
                     Learning rate: 0.0013
                       Mean reward: -1.47
               Mean episode length: 37.18
       Episode_Reward/keep_balance: 0.0382
     Episode_Reward/rew_lin_vel_xy: 0.0355
      Episode_Reward/rew_ang_vel_z: 0.1120
    Episode_Reward/pen_base_height: -0.1036
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0192
   Episode_Reward/pen_joint_torque: -0.0029
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0588
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0381
Metrics/base_velocity/error_vel_xy: 0.1975
Metrics/base_velocity/error_vel_yaw: 0.0368
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 106.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 1.08s
                        Total time: 104.98s
                               ETA: 3246.4s

################################################################################
                      [1m Learning iteration 94/3000 [0m                      

                       Computation: 91280 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.1539
                    Surrogate loss: 0.0015
             Mean action noise std: 0.6520
                     Learning rate: 0.0006
                       Mean reward: -1.23
               Mean episode length: 39.52
       Episode_Reward/keep_balance: 0.0383
     Episode_Reward/rew_lin_vel_xy: 0.0353
      Episode_Reward/rew_ang_vel_z: 0.1130
    Episode_Reward/pen_base_height: -0.1037
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0192
   Episode_Reward/pen_joint_torque: -0.0029
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0582
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0382
Metrics/base_velocity/error_vel_xy: 0.1994
Metrics/base_velocity/error_vel_yaw: 0.0368
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 104.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 1.08s
                        Total time: 106.05s
                               ETA: 3244.1s

################################################################################
                      [1m Learning iteration 95/3000 [0m                      

                       Computation: 91220 steps/s (collection: 0.953s, learning 0.125s)
               Value function loss: 0.1333
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6514
                     Learning rate: 0.0009
                       Mean reward: -1.39
               Mean episode length: 37.74
       Episode_Reward/keep_balance: 0.0388
     Episode_Reward/rew_lin_vel_xy: 0.0357
      Episode_Reward/rew_ang_vel_z: 0.1140
    Episode_Reward/pen_base_height: -0.1038
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0387
Metrics/base_velocity/error_vel_xy: 0.2007
Metrics/base_velocity/error_vel_yaw: 0.0372
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 106.2917
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 1.08s
                        Total time: 107.13s
                               ETA: 3241.8s

################################################################################
                      [1m Learning iteration 96/3000 [0m                      

                       Computation: 90989 steps/s (collection: 0.955s, learning 0.125s)
               Value function loss: 0.1338
                    Surrogate loss: -0.0010
             Mean action noise std: 0.6485
                     Learning rate: 0.0013
                       Mean reward: -1.30
               Mean episode length: 38.77
       Episode_Reward/keep_balance: 0.0391
     Episode_Reward/rew_lin_vel_xy: 0.0378
      Episode_Reward/rew_ang_vel_z: 0.1153
    Episode_Reward/pen_base_height: -0.1040
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0391
Metrics/base_velocity/error_vel_xy: 0.2023
Metrics/base_velocity/error_vel_yaw: 0.0372
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 104.0417
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 1.08s
                        Total time: 108.21s
                               ETA: 3239.6s

################################################################################
                      [1m Learning iteration 97/3000 [0m                      

                       Computation: 90577 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.1446
                    Surrogate loss: -0.0000
             Mean action noise std: 0.6465
                     Learning rate: 0.0013
                       Mean reward: -1.33
               Mean episode length: 39.95
       Episode_Reward/keep_balance: 0.0395
     Episode_Reward/rew_lin_vel_xy: 0.0371
      Episode_Reward/rew_ang_vel_z: 0.1157
    Episode_Reward/pen_base_height: -0.1038
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0588
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0397
Metrics/base_velocity/error_vel_xy: 0.2047
Metrics/base_velocity/error_vel_yaw: 0.0381
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 103.8750
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 1.09s
                        Total time: 109.30s
                               ETA: 3237.6s

################################################################################
                      [1m Learning iteration 98/3000 [0m                      

                       Computation: 90401 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.1452
                    Surrogate loss: 0.0017
             Mean action noise std: 0.6444
                     Learning rate: 0.0009
                       Mean reward: -1.17
               Mean episode length: 39.94
       Episode_Reward/keep_balance: 0.0394
     Episode_Reward/rew_lin_vel_xy: 0.0364
      Episode_Reward/rew_ang_vel_z: 0.1155
    Episode_Reward/pen_base_height: -0.1035
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0031
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0396
Metrics/base_velocity/error_vel_xy: 0.2066
Metrics/base_velocity/error_vel_yaw: 0.0383
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 102.4583
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 1.09s
                        Total time: 110.38s
                               ETA: 3235.7s

################################################################################
                      [1m Learning iteration 99/3000 [0m                      

                       Computation: 90679 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.1284
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6420
                     Learning rate: 0.0013
                       Mean reward: -1.53
               Mean episode length: 39.38
       Episode_Reward/keep_balance: 0.0397
     Episode_Reward/rew_lin_vel_xy: 0.0376
      Episode_Reward/rew_ang_vel_z: 0.1164
    Episode_Reward/pen_base_height: -0.1030
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0031
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0591
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0398
Metrics/base_velocity/error_vel_xy: 0.2062
Metrics/base_velocity/error_vel_yaw: 0.0383
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 104.7083
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 1.08s
                        Total time: 111.47s
                               ETA: 3233.7s

################################################################################
                     [1m Learning iteration 100/3000 [0m                      

                       Computation: 90146 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.1708
                    Surrogate loss: -0.0006
             Mean action noise std: 0.6399
                     Learning rate: 0.0029
                       Mean reward: -1.21
               Mean episode length: 41.43
       Episode_Reward/keep_balance: 0.0394
     Episode_Reward/rew_lin_vel_xy: 0.0358
      Episode_Reward/rew_ang_vel_z: 0.1160
    Episode_Reward/pen_base_height: -0.1023
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0582
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0393
Metrics/base_velocity/error_vel_xy: 0.2070
Metrics/base_velocity/error_vel_yaw: 0.0372
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 102.5000
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 1.09s
                        Total time: 112.56s
                               ETA: 3231.9s

################################################################################
                     [1m Learning iteration 101/3000 [0m                      

                       Computation: 88470 steps/s (collection: 0.981s, learning 0.131s)
               Value function loss: 0.1738
                    Surrogate loss: 0.0037
             Mean action noise std: 0.6394
                     Learning rate: 0.0006
                       Mean reward: -1.26
               Mean episode length: 38.03
       Episode_Reward/keep_balance: 0.0400
     Episode_Reward/rew_lin_vel_xy: 0.0390
      Episode_Reward/rew_ang_vel_z: 0.1182
    Episode_Reward/pen_base_height: -0.1032
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0031
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0596
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0401
Metrics/base_velocity/error_vel_xy: 0.2065
Metrics/base_velocity/error_vel_yaw: 0.0376
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 102.4167
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 1.11s
                        Total time: 113.67s
                               ETA: 3230.7s

################################################################################
                     [1m Learning iteration 102/3000 [0m                      

                       Computation: 88136 steps/s (collection: 0.991s, learning 0.125s)
               Value function loss: 0.1347
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6380
                     Learning rate: 0.0006
                       Mean reward: -1.25
               Mean episode length: 40.51
       Episode_Reward/keep_balance: 0.0398
     Episode_Reward/rew_lin_vel_xy: 0.0367
      Episode_Reward/rew_ang_vel_z: 0.1170
    Episode_Reward/pen_base_height: -0.1031
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0031
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0584
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0396
Metrics/base_velocity/error_vel_xy: 0.2077
Metrics/base_velocity/error_vel_yaw: 0.0378
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 101.0417
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 1.12s
                        Total time: 114.78s
                               ETA: 3229.6s

################################################################################
                     [1m Learning iteration 103/3000 [0m                      

                       Computation: 89913 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.1355
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6362
                     Learning rate: 0.0009
                       Mean reward: -1.24
               Mean episode length: 38.88
       Episode_Reward/keep_balance: 0.0404
     Episode_Reward/rew_lin_vel_xy: 0.0386
      Episode_Reward/rew_ang_vel_z: 0.1195
    Episode_Reward/pen_base_height: -0.1037
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0032
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0591
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0403
Metrics/base_velocity/error_vel_xy: 0.2101
Metrics/base_velocity/error_vel_yaw: 0.0382
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 101.4583
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 1.09s
                        Total time: 115.88s
                               ETA: 3227.9s

################################################################################
                     [1m Learning iteration 104/3000 [0m                      

                       Computation: 89621 steps/s (collection: 0.969s, learning 0.128s)
               Value function loss: 0.1364
                    Surrogate loss: -0.0003
             Mean action noise std: 0.6334
                     Learning rate: 0.0006
                       Mean reward: -1.07
               Mean episode length: 41.27
       Episode_Reward/keep_balance: 0.0407
     Episode_Reward/rew_lin_vel_xy: 0.0371
      Episode_Reward/rew_ang_vel_z: 0.1209
    Episode_Reward/pen_base_height: -0.1043
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0196
   Episode_Reward/pen_joint_torque: -0.0032
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0594
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0408
Metrics/base_velocity/error_vel_xy: 0.2126
Metrics/base_velocity/error_vel_yaw: 0.0382
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 100.3333
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 1.10s
                        Total time: 116.97s
                               ETA: 3226.3s

################################################################################
                     [1m Learning iteration 105/3000 [0m                      

                       Computation: 88218 steps/s (collection: 0.985s, learning 0.130s)
               Value function loss: 0.1430
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6315
                     Learning rate: 0.0006
                       Mean reward: -1.09
               Mean episode length: 41.87
       Episode_Reward/keep_balance: 0.0410
     Episode_Reward/rew_lin_vel_xy: 0.0414
      Episode_Reward/rew_ang_vel_z: 0.1211
    Episode_Reward/pen_base_height: -0.1043
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0033
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0593
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0411
Metrics/base_velocity/error_vel_xy: 0.2092
Metrics/base_velocity/error_vel_yaw: 0.0384
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 98.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 1.11s
                        Total time: 118.09s
                               ETA: 3225.2s

################################################################################
                     [1m Learning iteration 106/3000 [0m                      

                       Computation: 90525 steps/s (collection: 0.956s, learning 0.130s)
               Value function loss: 0.1469
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6294
                     Learning rate: 0.0013
                       Mean reward: -1.14
               Mean episode length: 43.07
       Episode_Reward/keep_balance: 0.0411
     Episode_Reward/rew_lin_vel_xy: 0.0383
      Episode_Reward/rew_ang_vel_z: 0.1221
    Episode_Reward/pen_base_height: -0.1043
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0034
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0589
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0410
Metrics/base_velocity/error_vel_xy: 0.2125
Metrics/base_velocity/error_vel_yaw: 0.0384
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 99.6667
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 1.09s
                        Total time: 119.18s
                               ETA: 3223.3s

################################################################################
                     [1m Learning iteration 107/3000 [0m                      

                       Computation: 89538 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.1454
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6280
                     Learning rate: 0.0019
                       Mean reward: -1.08
               Mean episode length: 41.70
       Episode_Reward/keep_balance: 0.0416
     Episode_Reward/rew_lin_vel_xy: 0.0404
      Episode_Reward/rew_ang_vel_z: 0.1233
    Episode_Reward/pen_base_height: -0.1050
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0193
   Episode_Reward/pen_joint_torque: -0.0034
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0592
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0415
Metrics/base_velocity/error_vel_xy: 0.2140
Metrics/base_velocity/error_vel_yaw: 0.0393
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 96.5000
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 1.10s
                        Total time: 120.27s
                               ETA: 3221.8s

################################################################################
                     [1m Learning iteration 108/3000 [0m                      

                       Computation: 91394 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.1732
                    Surrogate loss: 0.0032
             Mean action noise std: 0.6274
                     Learning rate: 0.0006
                       Mean reward: -1.22
               Mean episode length: 43.71
       Episode_Reward/keep_balance: 0.0423
     Episode_Reward/rew_lin_vel_xy: 0.0428
      Episode_Reward/rew_ang_vel_z: 0.1254
    Episode_Reward/pen_base_height: -0.1062
      Episode_Reward/pen_lin_vel_z: -0.0103
     Episode_Reward/pen_ang_vel_xy: -0.0193
   Episode_Reward/pen_joint_torque: -0.0036
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0601
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0425
Metrics/base_velocity/error_vel_xy: 0.2145
Metrics/base_velocity/error_vel_yaw: 0.0401
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 97.2500
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 1.08s
                        Total time: 121.35s
                               ETA: 3219.6s

################################################################################
                     [1m Learning iteration 109/3000 [0m                      

                       Computation: 91844 steps/s (collection: 0.946s, learning 0.124s)
               Value function loss: 0.1858
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6270
                     Learning rate: 0.0013
                       Mean reward: -1.09
               Mean episode length: 43.18
       Episode_Reward/keep_balance: 0.0424
     Episode_Reward/rew_lin_vel_xy: 0.0399
      Episode_Reward/rew_ang_vel_z: 0.1252
    Episode_Reward/pen_base_height: -0.1058
      Episode_Reward/pen_lin_vel_z: -0.0104
     Episode_Reward/pen_ang_vel_xy: -0.0196
   Episode_Reward/pen_joint_torque: -0.0036
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0596
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0425
Metrics/base_velocity/error_vel_xy: 0.2208
Metrics/base_velocity/error_vel_yaw: 0.0408
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 95.5833
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 1.07s
                        Total time: 122.42s
                               ETA: 3217.4s

################################################################################
                     [1m Learning iteration 110/3000 [0m                      

                       Computation: 90439 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.1424
                    Surrogate loss: 0.0044
             Mean action noise std: 0.6265
                     Learning rate: 0.0003
                       Mean reward: -1.39
               Mean episode length: 42.32
       Episode_Reward/keep_balance: 0.0427
     Episode_Reward/rew_lin_vel_xy: 0.0403
      Episode_Reward/rew_ang_vel_z: 0.1270
    Episode_Reward/pen_base_height: -0.1057
      Episode_Reward/pen_lin_vel_z: -0.0105
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0037
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0591
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0429
Metrics/base_velocity/error_vel_xy: 0.2200
Metrics/base_velocity/error_vel_yaw: 0.0403
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 95.7500
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 1.09s
                        Total time: 123.51s
                               ETA: 3215.6s

################################################################################
                     [1m Learning iteration 111/3000 [0m                      

                       Computation: 90933 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 0.1409
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6256
                     Learning rate: 0.0006
                       Mean reward: -1.20
               Mean episode length: 43.09
       Episode_Reward/keep_balance: 0.0426
     Episode_Reward/rew_lin_vel_xy: 0.0397
      Episode_Reward/rew_ang_vel_z: 0.1263
    Episode_Reward/pen_base_height: -0.1050
      Episode_Reward/pen_lin_vel_z: -0.0105
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0037
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0425
Metrics/base_velocity/error_vel_xy: 0.2212
Metrics/base_velocity/error_vel_yaw: 0.0402
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 95.1667
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 1.08s
                        Total time: 124.59s
                               ETA: 3213.7s

################################################################################
                     [1m Learning iteration 112/3000 [0m                      

                       Computation: 90867 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.1549
                    Surrogate loss: 0.0018
             Mean action noise std: 0.6249
                     Learning rate: 0.0003
                       Mean reward: -1.01
               Mean episode length: 42.05
       Episode_Reward/keep_balance: 0.0429
     Episode_Reward/rew_lin_vel_xy: 0.0405
      Episode_Reward/rew_ang_vel_z: 0.1278
    Episode_Reward/pen_base_height: -0.1050
      Episode_Reward/pen_lin_vel_z: -0.0105
     Episode_Reward/pen_ang_vel_xy: -0.0196
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0587
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0430
Metrics/base_velocity/error_vel_xy: 0.2222
Metrics/base_velocity/error_vel_yaw: 0.0400
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 93.1250
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 1.08s
                        Total time: 125.67s
                               ETA: 3211.8s

################################################################################
                     [1m Learning iteration 113/3000 [0m                      

                       Computation: 91502 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 0.1485
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6238
                     Learning rate: 0.0009
                       Mean reward: -0.77
               Mean episode length: 43.47
       Episode_Reward/keep_balance: 0.0434
     Episode_Reward/rew_lin_vel_xy: 0.0415
      Episode_Reward/rew_ang_vel_z: 0.1288
    Episode_Reward/pen_base_height: -0.1059
      Episode_Reward/pen_lin_vel_z: -0.0106
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0593
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0437
Metrics/base_velocity/error_vel_xy: 0.2243
Metrics/base_velocity/error_vel_yaw: 0.0410
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 94.4583
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 1.07s
                        Total time: 126.74s
                               ETA: 3209.7s

################################################################################
                     [1m Learning iteration 114/3000 [0m                      

                       Computation: 91334 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.1606
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6224
                     Learning rate: 0.0009
                       Mean reward: -1.13
               Mean episode length: 42.98
       Episode_Reward/keep_balance: 0.0437
     Episode_Reward/rew_lin_vel_xy: 0.0430
      Episode_Reward/rew_ang_vel_z: 0.1296
    Episode_Reward/pen_base_height: -0.1056
      Episode_Reward/pen_lin_vel_z: -0.0106
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0589
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0437
Metrics/base_velocity/error_vel_xy: 0.2264
Metrics/base_velocity/error_vel_yaw: 0.0413
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 95.2500
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 1.08s
                        Total time: 127.82s
                               ETA: 3207.7s

################################################################################
                     [1m Learning iteration 115/3000 [0m                      

                       Computation: 91253 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 0.1623
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6199
                     Learning rate: 0.0013
                       Mean reward: -1.04
               Mean episode length: 44.37
       Episode_Reward/keep_balance: 0.0433
     Episode_Reward/rew_lin_vel_xy: 0.0414
      Episode_Reward/rew_ang_vel_z: 0.1295
    Episode_Reward/pen_base_height: -0.1046
      Episode_Reward/pen_lin_vel_z: -0.0106
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0577
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0437
Metrics/base_velocity/error_vel_xy: 0.2257
Metrics/base_velocity/error_vel_yaw: 0.0396
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 93.7917
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 1.08s
                        Total time: 128.90s
                               ETA: 3205.7s

################################################################################
                     [1m Learning iteration 116/3000 [0m                      

                       Computation: 91092 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.1700
                    Surrogate loss: 0.0014
             Mean action noise std: 0.6184
                     Learning rate: 0.0009
                       Mean reward: -1.10
               Mean episode length: 45.54
       Episode_Reward/keep_balance: 0.0433
     Episode_Reward/rew_lin_vel_xy: 0.0426
      Episode_Reward/rew_ang_vel_z: 0.1287
    Episode_Reward/pen_base_height: -0.1056
      Episode_Reward/pen_lin_vel_z: -0.0107
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0435
Metrics/base_velocity/error_vel_xy: 0.2235
Metrics/base_velocity/error_vel_yaw: 0.0405
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 94.5417
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 1.08s
                        Total time: 129.98s
                               ETA: 3203.8s

################################################################################
                     [1m Learning iteration 117/3000 [0m                      

                       Computation: 91447 steps/s (collection: 0.951s, learning 0.124s)
               Value function loss: 0.1776
                    Surrogate loss: 0.0013
             Mean action noise std: 0.6181
                     Learning rate: 0.0013
                       Mean reward: -0.98
               Mean episode length: 43.51
       Episode_Reward/keep_balance: 0.0440
     Episode_Reward/rew_lin_vel_xy: 0.0454
      Episode_Reward/rew_ang_vel_z: 0.1311
    Episode_Reward/pen_base_height: -0.1062
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0582
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0443
Metrics/base_velocity/error_vel_xy: 0.2220
Metrics/base_velocity/error_vel_yaw: 0.0413
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 1.07s
                        Total time: 131.05s
                               ETA: 3201.9s

################################################################################
                     [1m Learning iteration 118/3000 [0m                      

                       Computation: 91284 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.2201
                    Surrogate loss: 0.0047
             Mean action noise std: 0.6180
                     Learning rate: 0.0003
                       Mean reward: -0.94
               Mean episode length: 46.05
       Episode_Reward/keep_balance: 0.0447
     Episode_Reward/rew_lin_vel_xy: 0.0437
      Episode_Reward/rew_ang_vel_z: 0.1334
    Episode_Reward/pen_base_height: -0.1067
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0594
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0450
Metrics/base_velocity/error_vel_xy: 0.2301
Metrics/base_velocity/error_vel_yaw: 0.0412
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 93.1250
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 1.08s
                        Total time: 132.13s
                               ETA: 3199.9s

################################################################################
                     [1m Learning iteration 119/3000 [0m                      

                       Computation: 90032 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.1714
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6172
                     Learning rate: 0.0006
                       Mean reward: -0.94
               Mean episode length: 45.49
       Episode_Reward/keep_balance: 0.0446
     Episode_Reward/rew_lin_vel_xy: 0.0447
      Episode_Reward/rew_ang_vel_z: 0.1332
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0591
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0445
Metrics/base_velocity/error_vel_xy: 0.2258
Metrics/base_velocity/error_vel_yaw: 0.0414
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 1.09s
                        Total time: 133.22s
                               ETA: 3198.4s

################################################################################
                     [1m Learning iteration 120/3000 [0m                      

                       Computation: 90403 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.1759
                    Surrogate loss: 0.0014
             Mean action noise std: 0.6165
                     Learning rate: 0.0006
                       Mean reward: -1.06
               Mean episode length: 44.56
       Episode_Reward/keep_balance: 0.0443
     Episode_Reward/rew_lin_vel_xy: 0.0424
      Episode_Reward/rew_ang_vel_z: 0.1321
    Episode_Reward/pen_base_height: -0.1062
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0201
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0445
Metrics/base_velocity/error_vel_xy: 0.2276
Metrics/base_velocity/error_vel_yaw: 0.0410
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 1.09s
                        Total time: 134.31s
                               ETA: 3196.7s

################################################################################
                     [1m Learning iteration 121/3000 [0m                      

                       Computation: 89842 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.1680
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6150
                     Learning rate: 0.0009
                       Mean reward: -1.02
               Mean episode length: 44.05
       Episode_Reward/keep_balance: 0.0450
     Episode_Reward/rew_lin_vel_xy: 0.0441
      Episode_Reward/rew_ang_vel_z: 0.1338
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0041
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0597
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0453
Metrics/base_velocity/error_vel_xy: 0.2330
Metrics/base_velocity/error_vel_yaw: 0.0420
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.9583
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 1.09s
                        Total time: 135.40s
                               ETA: 3195.2s

################################################################################
                     [1m Learning iteration 122/3000 [0m                      

                       Computation: 90355 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.1876
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6145
                     Learning rate: 0.0013
                       Mean reward: -1.28
               Mean episode length: 42.86
       Episode_Reward/keep_balance: 0.0451
     Episode_Reward/rew_lin_vel_xy: 0.0452
      Episode_Reward/rew_ang_vel_z: 0.1340
    Episode_Reward/pen_base_height: -0.1067
      Episode_Reward/pen_lin_vel_z: -0.0107
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0041
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0595
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0455
Metrics/base_velocity/error_vel_xy: 0.2291
Metrics/base_velocity/error_vel_yaw: 0.0422
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.7917
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 1.09s
                        Total time: 136.49s
                               ETA: 3193.6s

################################################################################
                     [1m Learning iteration 123/3000 [0m                      

                       Computation: 90331 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.2055
                    Surrogate loss: 0.0012
             Mean action noise std: 0.6149
                     Learning rate: 0.0009
                       Mean reward: -0.76
               Mean episode length: 46.53
       Episode_Reward/keep_balance: 0.0455
     Episode_Reward/rew_lin_vel_xy: 0.0458
      Episode_Reward/rew_ang_vel_z: 0.1358
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0107
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0593
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0460
Metrics/base_velocity/error_vel_xy: 0.2344
Metrics/base_velocity/error_vel_yaw: 0.0421
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 92.5417
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 1.09s
                        Total time: 137.58s
                               ETA: 3192.0s

################################################################################
                     [1m Learning iteration 124/3000 [0m                      

                       Computation: 92449 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 0.1978
                    Surrogate loss: 0.0017
             Mean action noise std: 0.6150
                     Learning rate: 0.0006
                       Mean reward: -1.18
               Mean episode length: 43.39
       Episode_Reward/keep_balance: 0.0448
     Episode_Reward/rew_lin_vel_xy: 0.0436
      Episode_Reward/rew_ang_vel_z: 0.1335
    Episode_Reward/pen_base_height: -0.1065
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0582
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0453
Metrics/base_velocity/error_vel_xy: 0.2321
Metrics/base_velocity/error_vel_yaw: 0.0415
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 89.2083
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 1.06s
                        Total time: 138.64s
                               ETA: 3189.8s

################################################################################
                     [1m Learning iteration 125/3000 [0m                      

                       Computation: 91947 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.1741
                    Surrogate loss: -0.0007
             Mean action noise std: 0.6147
                     Learning rate: 0.0006
                       Mean reward: -0.69
               Mean episode length: 47.68
       Episode_Reward/keep_balance: 0.0455
     Episode_Reward/rew_lin_vel_xy: 0.0466
      Episode_Reward/rew_ang_vel_z: 0.1352
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0201
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0587
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0043
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0457
Metrics/base_velocity/error_vel_xy: 0.2317
Metrics/base_velocity/error_vel_yaw: 0.0426
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.1667
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 1.07s
                        Total time: 139.71s
                               ETA: 3187.8s

################################################################################
                     [1m Learning iteration 126/3000 [0m                      

                       Computation: 90651 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.1704
                    Surrogate loss: 0.0002
             Mean action noise std: 0.6141
                     Learning rate: 0.0009
                       Mean reward: -0.85
               Mean episode length: 45.16
       Episode_Reward/keep_balance: 0.0459
     Episode_Reward/rew_lin_vel_xy: 0.0480
      Episode_Reward/rew_ang_vel_z: 0.1367
    Episode_Reward/pen_base_height: -0.1065
      Episode_Reward/pen_lin_vel_z: -0.0110
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0578
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0043
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2322
Metrics/base_velocity/error_vel_yaw: 0.0420
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 93.2083
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 1.08s
                        Total time: 140.79s
                               ETA: 3186.2s

################################################################################
                     [1m Learning iteration 127/3000 [0m                      

                       Computation: 90853 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 0.1698
                    Surrogate loss: -0.0001
             Mean action noise std: 0.6127
                     Learning rate: 0.0009
                       Mean reward: -0.76
               Mean episode length: 44.34
       Episode_Reward/keep_balance: 0.0451
     Episode_Reward/rew_lin_vel_xy: 0.0428
      Episode_Reward/rew_ang_vel_z: 0.1338
    Episode_Reward/pen_base_height: -0.1060
      Episode_Reward/pen_lin_vel_z: -0.0110
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0575
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0456
Metrics/base_velocity/error_vel_xy: 0.2344
Metrics/base_velocity/error_vel_yaw: 0.0421
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 1.08s
                        Total time: 141.88s
                               ETA: 3184.5s

################################################################################
                     [1m Learning iteration 128/3000 [0m                      

                       Computation: 91693 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.1713
                    Surrogate loss: 0.0004
             Mean action noise std: 0.6119
                     Learning rate: 0.0004
                       Mean reward: -1.02
               Mean episode length: 47.09
       Episode_Reward/keep_balance: 0.0459
     Episode_Reward/rew_lin_vel_xy: 0.0430
      Episode_Reward/rew_ang_vel_z: 0.1365
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0465
Metrics/base_velocity/error_vel_xy: 0.2346
Metrics/base_velocity/error_vel_yaw: 0.0422
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.5000
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 1.07s
                        Total time: 142.95s
                               ETA: 3182.5s

################################################################################
                     [1m Learning iteration 129/3000 [0m                      

                       Computation: 92409 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 0.1511
                    Surrogate loss: 0.0054
             Mean action noise std: 0.6120
                     Learning rate: 0.0002
                       Mean reward: -0.89
               Mean episode length: 47.27
       Episode_Reward/keep_balance: 0.0458
     Episode_Reward/rew_lin_vel_xy: 0.0452
      Episode_Reward/rew_ang_vel_z: 0.1362
    Episode_Reward/pen_base_height: -0.1062
      Episode_Reward/pen_lin_vel_z: -0.0110
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0584
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0463
Metrics/base_velocity/error_vel_xy: 0.2367
Metrics/base_velocity/error_vel_yaw: 0.0420
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.1667
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 1.06s
                        Total time: 144.01s
                               ETA: 3180.5s

################################################################################
                     [1m Learning iteration 130/3000 [0m                      

                       Computation: 92398 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 0.1542
                    Surrogate loss: 0.0003
             Mean action noise std: 0.6115
                     Learning rate: 0.0004
                       Mean reward: -1.13
               Mean episode length: 45.15
       Episode_Reward/keep_balance: 0.0464
     Episode_Reward/rew_lin_vel_xy: 0.0438
      Episode_Reward/rew_ang_vel_z: 0.1378
    Episode_Reward/pen_base_height: -0.1063
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0580
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2383
Metrics/base_velocity/error_vel_yaw: 0.0427
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 91.1250
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 1.06s
                        Total time: 145.08s
                               ETA: 3178.4s

################################################################################
                     [1m Learning iteration 131/3000 [0m                      

                       Computation: 92014 steps/s (collection: 0.947s, learning 0.121s)
               Value function loss: 0.1540
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6097
                     Learning rate: 0.0009
                       Mean reward: -0.77
               Mean episode length: 43.99
       Episode_Reward/keep_balance: 0.0457
     Episode_Reward/rew_lin_vel_xy: 0.0451
      Episode_Reward/rew_ang_vel_z: 0.1354
    Episode_Reward/pen_base_height: -0.1062
      Episode_Reward/pen_lin_vel_z: -0.0112
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0462
Metrics/base_velocity/error_vel_xy: 0.2341
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 91.3333
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 1.07s
                        Total time: 146.14s
                               ETA: 3176.4s

################################################################################
                     [1m Learning iteration 132/3000 [0m                      

                       Computation: 91449 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.1828
                    Surrogate loss: 0.0014
             Mean action noise std: 0.6090
                     Learning rate: 0.0013
                       Mean reward: -0.93
               Mean episode length: 46.29
       Episode_Reward/keep_balance: 0.0450
     Episode_Reward/rew_lin_vel_xy: 0.0428
      Episode_Reward/rew_ang_vel_z: 0.1341
    Episode_Reward/pen_base_height: -0.1054
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0576
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0455
Metrics/base_velocity/error_vel_xy: 0.2324
Metrics/base_velocity/error_vel_yaw: 0.0408
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 1.07s
                        Total time: 147.22s
                               ETA: 3174.6s

################################################################################
                     [1m Learning iteration 133/3000 [0m                      

                       Computation: 92350 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.1663
                    Surrogate loss: 0.0021
             Mean action noise std: 0.6089
                     Learning rate: 0.0006
                       Mean reward: -0.77
               Mean episode length: 46.91
       Episode_Reward/keep_balance: 0.0450
     Episode_Reward/rew_lin_vel_xy: 0.0444
      Episode_Reward/rew_ang_vel_z: 0.1343
    Episode_Reward/pen_base_height: -0.1046
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0041
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0576
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0455
Metrics/base_velocity/error_vel_xy: 0.2310
Metrics/base_velocity/error_vel_yaw: 0.0408
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.7500
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 1.06s
                        Total time: 148.28s
                               ETA: 3172.6s

################################################################################
                     [1m Learning iteration 134/3000 [0m                      

                       Computation: 90953 steps/s (collection: 0.956s, learning 0.125s)
               Value function loss: 0.1623
                    Surrogate loss: 0.0058
             Mean action noise std: 0.6084
                     Learning rate: 0.0003
                       Mean reward: -1.07
               Mean episode length: 45.42
       Episode_Reward/keep_balance: 0.0459
     Episode_Reward/rew_lin_vel_xy: 0.0467
      Episode_Reward/rew_ang_vel_z: 0.1368
    Episode_Reward/pen_base_height: -0.1060
      Episode_Reward/pen_lin_vel_z: -0.0112
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0592
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0463
Metrics/base_velocity/error_vel_xy: 0.2342
Metrics/base_velocity/error_vel_yaw: 0.0421
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.5417
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 1.08s
                        Total time: 149.36s
                               ETA: 3171.0s

################################################################################
                     [1m Learning iteration 135/3000 [0m                      

                       Computation: 90823 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.1574
                    Surrogate loss: 0.0038
             Mean action noise std: 0.6078
                     Learning rate: 0.0006
                       Mean reward: -0.88
               Mean episode length: 46.08
       Episode_Reward/keep_balance: 0.0457
     Episode_Reward/rew_lin_vel_xy: 0.0469
      Episode_Reward/rew_ang_vel_z: 0.1363
    Episode_Reward/pen_base_height: -0.1056
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0579
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0461
Metrics/base_velocity/error_vel_xy: 0.2307
Metrics/base_velocity/error_vel_yaw: 0.0419
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 1.08s
                        Total time: 150.45s
                               ETA: 3169.3s

################################################################################
                     [1m Learning iteration 136/3000 [0m                      

                       Computation: 89647 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.1511
                    Surrogate loss: 0.0089
             Mean action noise std: 0.6075
                     Learning rate: 0.0001
                       Mean reward: -0.79
               Mean episode length: 46.54
       Episode_Reward/keep_balance: 0.0457
     Episode_Reward/rew_lin_vel_xy: 0.0455
      Episode_Reward/rew_ang_vel_z: 0.1369
    Episode_Reward/pen_base_height: -0.1059
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0576
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0461
Metrics/base_velocity/error_vel_xy: 0.2349
Metrics/base_velocity/error_vel_yaw: 0.0412
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 89.1667
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 1.10s
                        Total time: 151.54s
                               ETA: 3168.0s

################################################################################
                     [1m Learning iteration 137/3000 [0m                      

                       Computation: 92130 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 0.1461
                    Surrogate loss: 0.0038
             Mean action noise std: 0.6070
                     Learning rate: 0.0001
                       Mean reward: -0.98
               Mean episode length: 47.20
       Episode_Reward/keep_balance: 0.0458
     Episode_Reward/rew_lin_vel_xy: 0.0446
      Episode_Reward/rew_ang_vel_z: 0.1369
    Episode_Reward/pen_base_height: -0.1059
      Episode_Reward/pen_lin_vel_z: -0.0112
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0579
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2366
Metrics/base_velocity/error_vel_yaw: 0.0414
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 91.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 1.07s
                        Total time: 152.61s
                               ETA: 3166.1s

################################################################################
                     [1m Learning iteration 138/3000 [0m                      

                       Computation: 92883 steps/s (collection: 0.934s, learning 0.124s)
               Value function loss: 0.1527
                    Surrogate loss: 0.0036
             Mean action noise std: 0.6066
                     Learning rate: 0.0001
                       Mean reward: -0.65
               Mean episode length: 45.17
       Episode_Reward/keep_balance: 0.0456
     Episode_Reward/rew_lin_vel_xy: 0.0452
      Episode_Reward/rew_ang_vel_z: 0.1359
    Episode_Reward/pen_base_height: -0.1052
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0461
Metrics/base_velocity/error_vel_xy: 0.2339
Metrics/base_velocity/error_vel_yaw: 0.0418
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 89.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 1.06s
                        Total time: 153.67s
                               ETA: 3164.0s

################################################################################
                     [1m Learning iteration 139/3000 [0m                      

                       Computation: 92511 steps/s (collection: 0.938s, learning 0.124s)
               Value function loss: 0.1509
                    Surrogate loss: 0.0021
             Mean action noise std: 0.6060
                     Learning rate: 0.0003
                       Mean reward: -1.00
               Mean episode length: 45.01
       Episode_Reward/keep_balance: 0.0457
     Episode_Reward/rew_lin_vel_xy: 0.0451
      Episode_Reward/rew_ang_vel_z: 0.1362
    Episode_Reward/pen_base_height: -0.1053
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0460
Metrics/base_velocity/error_vel_xy: 0.2390
Metrics/base_velocity/error_vel_yaw: 0.0417
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.9167
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 1.06s
                        Total time: 154.73s
                               ETA: 3162.0s

################################################################################
                     [1m Learning iteration 140/3000 [0m                      

                       Computation: 89659 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.1602
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6049
                     Learning rate: 0.0004
                       Mean reward: -0.57
               Mean episode length: 47.24
       Episode_Reward/keep_balance: 0.0462
     Episode_Reward/rew_lin_vel_xy: 0.0469
      Episode_Reward/rew_ang_vel_z: 0.1374
    Episode_Reward/pen_base_height: -0.1051
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0571
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0465
Metrics/base_velocity/error_vel_xy: 0.2356
Metrics/base_velocity/error_vel_yaw: 0.0422
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.6250
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 1.10s
                        Total time: 155.83s
                               ETA: 3160.8s

################################################################################
                     [1m Learning iteration 141/3000 [0m                      

                       Computation: 91344 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.1732
                    Surrogate loss: -0.0012
             Mean action noise std: 0.6035
                     Learning rate: 0.0013
                       Mean reward: -0.85
               Mean episode length: 44.31
       Episode_Reward/keep_balance: 0.0460
     Episode_Reward/rew_lin_vel_xy: 0.0464
      Episode_Reward/rew_ang_vel_z: 0.1369
    Episode_Reward/pen_base_height: -0.1049
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0574
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0463
Metrics/base_velocity/error_vel_xy: 0.2355
Metrics/base_velocity/error_vel_yaw: 0.0419
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.9167
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 1.08s
                        Total time: 156.90s
                               ETA: 3159.1s

################################################################################
                     [1m Learning iteration 142/3000 [0m                      

                       Computation: 91475 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.1777
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6019
                     Learning rate: 0.0013
                       Mean reward: -0.96
               Mean episode length: 44.66
       Episode_Reward/keep_balance: 0.0462
     Episode_Reward/rew_lin_vel_xy: 0.0462
      Episode_Reward/rew_ang_vel_z: 0.1375
    Episode_Reward/pen_base_height: -0.1051
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2383
Metrics/base_velocity/error_vel_yaw: 0.0421
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 91.2500
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 1.07s
                        Total time: 157.98s
                               ETA: 3157.4s

################################################################################
                     [1m Learning iteration 143/3000 [0m                      

                       Computation: 91064 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.2070
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6004
                     Learning rate: 0.0019
                       Mean reward: -0.91
               Mean episode length: 45.90
       Episode_Reward/keep_balance: 0.0462
     Episode_Reward/rew_lin_vel_xy: 0.0480
      Episode_Reward/rew_ang_vel_z: 0.1379
    Episode_Reward/pen_base_height: -0.1049
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2371
Metrics/base_velocity/error_vel_yaw: 0.0420
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.7083
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 1.08s
                        Total time: 159.06s
                               ETA: 3155.8s

################################################################################
                     [1m Learning iteration 144/3000 [0m                      

                       Computation: 89973 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.1987
                    Surrogate loss: 0.0020
             Mean action noise std: 0.6001
                     Learning rate: 0.0009
                       Mean reward: -0.59
               Mean episode length: 47.25
       Episode_Reward/keep_balance: 0.0467
     Episode_Reward/rew_lin_vel_xy: 0.0491
      Episode_Reward/rew_ang_vel_z: 0.1393
    Episode_Reward/pen_base_height: -0.1055
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2365
Metrics/base_velocity/error_vel_yaw: 0.0426
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.5833
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 1.09s
                        Total time: 160.15s
                               ETA: 3154.4s

################################################################################
                     [1m Learning iteration 145/3000 [0m                      

                       Computation: 93133 steps/s (collection: 0.934s, learning 0.121s)
               Value function loss: 0.1747
                    Surrogate loss: 0.0001
             Mean action noise std: 0.5990
                     Learning rate: 0.0009
                       Mean reward: -0.98
               Mean episode length: 43.35
       Episode_Reward/keep_balance: 0.0462
     Episode_Reward/rew_lin_vel_xy: 0.0442
      Episode_Reward/rew_ang_vel_z: 0.1378
    Episode_Reward/pen_base_height: -0.1045
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0574
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2386
Metrics/base_velocity/error_vel_yaw: 0.0418
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 1.06s
                        Total time: 161.21s
                               ETA: 3152.4s

################################################################################
                     [1m Learning iteration 146/3000 [0m                      

                       Computation: 91481 steps/s (collection: 0.951s, learning 0.124s)
               Value function loss: 0.1995
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5967
                     Learning rate: 0.0019
                       Mean reward: -0.81
               Mean episode length: 47.30
       Episode_Reward/keep_balance: 0.0468
     Episode_Reward/rew_lin_vel_xy: 0.0462
      Episode_Reward/rew_ang_vel_z: 0.1400
    Episode_Reward/pen_base_height: -0.1051
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0575
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2391
Metrics/base_velocity/error_vel_yaw: 0.0422
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 1.07s
                        Total time: 162.28s
                               ETA: 3150.7s

################################################################################
                     [1m Learning iteration 147/3000 [0m                      

                       Computation: 90855 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.2375
                    Surrogate loss: 0.0010
             Mean action noise std: 0.5961
                     Learning rate: 0.0013
                       Mean reward: -0.39
               Mean episode length: 48.29
       Episode_Reward/keep_balance: 0.0465
     Episode_Reward/rew_lin_vel_xy: 0.0458
      Episode_Reward/rew_ang_vel_z: 0.1389
    Episode_Reward/pen_base_height: -0.1047
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0569
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2391
Metrics/base_velocity/error_vel_yaw: 0.0420
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 1.08s
                        Total time: 163.36s
                               ETA: 3149.2s

################################################################################
                     [1m Learning iteration 148/3000 [0m                      

                       Computation: 90894 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.1647
                    Surrogate loss: 0.0013
             Mean action noise std: 0.5957
                     Learning rate: 0.0009
                       Mean reward: -0.77
               Mean episode length: 45.75
       Episode_Reward/keep_balance: 0.0464
     Episode_Reward/rew_lin_vel_xy: 0.0462
      Episode_Reward/rew_ang_vel_z: 0.1388
    Episode_Reward/pen_base_height: -0.1057
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0574
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0462
Metrics/base_velocity/error_vel_xy: 0.2390
Metrics/base_velocity/error_vel_yaw: 0.0414
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.8333
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 1.08s
                        Total time: 164.44s
                               ETA: 3147.6s

################################################################################
                     [1m Learning iteration 149/3000 [0m                      

                       Computation: 91334 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.2247
                    Surrogate loss: 0.0009
             Mean action noise std: 0.5952
                     Learning rate: 0.0009
                       Mean reward: -0.88
               Mean episode length: 47.32
       Episode_Reward/keep_balance: 0.0474
     Episode_Reward/rew_lin_vel_xy: 0.0489
      Episode_Reward/rew_ang_vel_z: 0.1422
    Episode_Reward/pen_base_height: -0.1058
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0046
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0575
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2419
Metrics/base_velocity/error_vel_yaw: 0.0423
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 1.08s
                        Total time: 165.52s
                               ETA: 3146.0s

################################################################################
                     [1m Learning iteration 150/3000 [0m                      

                       Computation: 91299 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 0.1727
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5940
                     Learning rate: 0.0019
                       Mean reward: -0.98
               Mean episode length: 46.52
       Episode_Reward/keep_balance: 0.0471
     Episode_Reward/rew_lin_vel_xy: 0.0482
      Episode_Reward/rew_ang_vel_z: 0.1411
    Episode_Reward/pen_base_height: -0.1059
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0046
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0570
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2387
Metrics/base_velocity/error_vel_yaw: 0.0424
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.7083
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 1.08s
                        Total time: 166.60s
                               ETA: 3144.4s

################################################################################
                     [1m Learning iteration 151/3000 [0m                      

                       Computation: 90478 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.1793
                    Surrogate loss: 0.0039
             Mean action noise std: 0.5936
                     Learning rate: 0.0009
                       Mean reward: -0.48
               Mean episode length: 48.76
       Episode_Reward/keep_balance: 0.0474
     Episode_Reward/rew_lin_vel_xy: 0.0488
      Episode_Reward/rew_ang_vel_z: 0.1416
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0573
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2411
Metrics/base_velocity/error_vel_yaw: 0.0429
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 1.09s
                        Total time: 167.68s
                               ETA: 3143.0s

################################################################################
                     [1m Learning iteration 152/3000 [0m                      

                       Computation: 90516 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.1441
                    Surrogate loss: 0.0018
             Mean action noise std: 0.5929
                     Learning rate: 0.0004
                       Mean reward: -0.80
               Mean episode length: 47.27
       Episode_Reward/keep_balance: 0.0471
     Episode_Reward/rew_lin_vel_xy: 0.0457
      Episode_Reward/rew_ang_vel_z: 0.1410
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0047
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0571
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0472
Metrics/base_velocity/error_vel_xy: 0.2434
Metrics/base_velocity/error_vel_yaw: 0.0423
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 1.09s
                        Total time: 168.77s
                               ETA: 3141.5s

################################################################################
                     [1m Learning iteration 153/3000 [0m                      

                       Computation: 91787 steps/s (collection: 0.946s, learning 0.125s)
               Value function loss: 0.1487
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5915
                     Learning rate: 0.0009
                       Mean reward: -0.89
               Mean episode length: 46.00
       Episode_Reward/keep_balance: 0.0474
     Episode_Reward/rew_lin_vel_xy: 0.0479
      Episode_Reward/rew_ang_vel_z: 0.1419
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0046
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0577
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2440
Metrics/base_velocity/error_vel_yaw: 0.0426
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.7500
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 1.07s
                        Total time: 169.84s
                               ETA: 3139.9s

################################################################################
                     [1m Learning iteration 154/3000 [0m                      

                       Computation: 91523 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.1576
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5897
                     Learning rate: 0.0013
                       Mean reward: -0.79
               Mean episode length: 46.31
       Episode_Reward/keep_balance: 0.0473
     Episode_Reward/rew_lin_vel_xy: 0.0482
      Episode_Reward/rew_ang_vel_z: 0.1423
    Episode_Reward/pen_base_height: -0.1061
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0047
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0565
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2408
Metrics/base_velocity/error_vel_yaw: 0.0418
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.8750
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 1.07s
                        Total time: 170.92s
                               ETA: 3138.2s

################################################################################
                     [1m Learning iteration 155/3000 [0m                      

                       Computation: 91196 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.2033
                    Surrogate loss: 0.0011
             Mean action noise std: 0.5895
                     Learning rate: 0.0013
                       Mean reward: -0.74
               Mean episode length: 49.13
       Episode_Reward/keep_balance: 0.0479
     Episode_Reward/rew_lin_vel_xy: 0.0484
      Episode_Reward/rew_ang_vel_z: 0.1437
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0048
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0570
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2458
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.6250
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 1.08s
                        Total time: 171.99s
                               ETA: 3136.7s

################################################################################
                     [1m Learning iteration 156/3000 [0m                      

                       Computation: 91651 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.2254
                    Surrogate loss: 0.0016
             Mean action noise std: 0.5891
                     Learning rate: 0.0013
                       Mean reward: -0.73
               Mean episode length: 47.66
       Episode_Reward/keep_balance: 0.0474
     Episode_Reward/rew_lin_vel_xy: 0.0479
      Episode_Reward/rew_ang_vel_z: 0.1428
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0048
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0568
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2396
Metrics/base_velocity/error_vel_yaw: 0.0419
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.8333
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 1.07s
                        Total time: 173.07s
                               ETA: 3135.0s

################################################################################
                     [1m Learning iteration 157/3000 [0m                      

                       Computation: 92195 steps/s (collection: 0.943s, learning 0.123s)
               Value function loss: 0.1900
                    Surrogate loss: 0.0045
             Mean action noise std: 0.5884
                     Learning rate: 0.0004
                       Mean reward: -0.69
               Mean episode length: 48.14
       Episode_Reward/keep_balance: 0.0477
     Episode_Reward/rew_lin_vel_xy: 0.0487
      Episode_Reward/rew_ang_vel_z: 0.1434
    Episode_Reward/pen_base_height: -0.1079
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0569
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2448
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.2917
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 1.07s
                        Total time: 174.13s
                               ETA: 3133.3s

################################################################################
                     [1m Learning iteration 158/3000 [0m                      

                       Computation: 91078 steps/s (collection: 0.952s, learning 0.128s)
               Value function loss: 0.1627
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5881
                     Learning rate: 0.0006
                       Mean reward: -0.67
               Mean episode length: 48.27
       Episode_Reward/keep_balance: 0.0482
     Episode_Reward/rew_lin_vel_xy: 0.0489
      Episode_Reward/rew_ang_vel_z: 0.1453
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0571
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2459
Metrics/base_velocity/error_vel_yaw: 0.0427
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.8750
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 1.08s
                        Total time: 175.21s
                               ETA: 3131.8s

################################################################################
                     [1m Learning iteration 159/3000 [0m                      

                       Computation: 92430 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 0.1604
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5873
                     Learning rate: 0.0009
                       Mean reward: -0.88
               Mean episode length: 47.12
       Episode_Reward/keep_balance: 0.0483
     Episode_Reward/rew_lin_vel_xy: 0.0513
      Episode_Reward/rew_ang_vel_z: 0.1456
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0201
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0567
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2440
Metrics/base_velocity/error_vel_yaw: 0.0426
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.7917
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 1.06s
                        Total time: 176.27s
                               ETA: 3130.0s

################################################################################
                     [1m Learning iteration 160/3000 [0m                      

                       Computation: 93197 steps/s (collection: 0.932s, learning 0.122s)
               Value function loss: 0.1766
                    Surrogate loss: 0.0028
             Mean action noise std: 0.5866
                     Learning rate: 0.0004
                       Mean reward: -0.74
               Mean episode length: 47.55
       Episode_Reward/keep_balance: 0.0484
     Episode_Reward/rew_lin_vel_xy: 0.0506
      Episode_Reward/rew_ang_vel_z: 0.1458
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0201
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0561
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0481
Metrics/base_velocity/error_vel_xy: 0.2466
Metrics/base_velocity/error_vel_yaw: 0.0429
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.3750
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 1.05s
                        Total time: 177.33s
                               ETA: 3128.0s

################################################################################
                     [1m Learning iteration 161/3000 [0m                      

                       Computation: 93007 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 0.1740
                    Surrogate loss: 0.0017
             Mean action noise std: 0.5865
                     Learning rate: 0.0004
                       Mean reward: -0.64
               Mean episode length: 49.65
       Episode_Reward/keep_balance: 0.0483
     Episode_Reward/rew_lin_vel_xy: 0.0491
      Episode_Reward/rew_ang_vel_z: 0.1461
    Episode_Reward/pen_base_height: -0.1083
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0562
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2470
Metrics/base_velocity/error_vel_yaw: 0.0421
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 1.06s
                        Total time: 178.39s
                               ETA: 3126.2s

################################################################################
                     [1m Learning iteration 162/3000 [0m                      

                       Computation: 92988 steps/s (collection: 0.933s, learning 0.124s)
               Value function loss: 0.1841
                    Surrogate loss: 0.0003
             Mean action noise std: 0.5864
                     Learning rate: 0.0009
                       Mean reward: -0.56
               Mean episode length: 48.04
       Episode_Reward/keep_balance: 0.0484
     Episode_Reward/rew_lin_vel_xy: 0.0506
      Episode_Reward/rew_ang_vel_z: 0.1455
    Episode_Reward/pen_base_height: -0.1082
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0567
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2461
Metrics/base_velocity/error_vel_yaw: 0.0429
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.4167
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 1.06s
                        Total time: 179.44s
                               ETA: 3124.3s

################################################################################
                     [1m Learning iteration 163/3000 [0m                      

                       Computation: 91726 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 0.2149
                    Surrogate loss: -0.0011
             Mean action noise std: 0.5865
                     Learning rate: 0.0013
                       Mean reward: -0.19
               Mean episode length: 51.04
       Episode_Reward/keep_balance: 0.0485
     Episode_Reward/rew_lin_vel_xy: 0.0519
      Episode_Reward/rew_ang_vel_z: 0.1461
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0563
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2433
Metrics/base_velocity/error_vel_yaw: 0.0432
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.5833
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 1.07s
                        Total time: 180.52s
                               ETA: 3122.7s

################################################################################
                     [1m Learning iteration 164/3000 [0m                      

                       Computation: 92594 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 0.3121
                    Surrogate loss: -0.0002
             Mean action noise std: 0.5856
                     Learning rate: 0.0029
                       Mean reward: -0.55
               Mean episode length: 46.36
       Episode_Reward/keep_balance: 0.0480
     Episode_Reward/rew_lin_vel_xy: 0.0486
      Episode_Reward/rew_ang_vel_z: 0.1446
    Episode_Reward/pen_base_height: -0.1074
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0558
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2447
Metrics/base_velocity/error_vel_yaw: 0.0429
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 1.06s
                        Total time: 181.58s
                               ETA: 3120.9s

################################################################################
                     [1m Learning iteration 165/3000 [0m                      

                       Computation: 91700 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 0.4729
                    Surrogate loss: 0.0024
             Mean action noise std: 0.5851
                     Learning rate: 0.0044
                       Mean reward: -0.60
               Mean episode length: 48.00
       Episode_Reward/keep_balance: 0.0485
     Episode_Reward/rew_lin_vel_xy: 0.0500
      Episode_Reward/rew_ang_vel_z: 0.1465
    Episode_Reward/pen_base_height: -0.1081
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0558
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2500
Metrics/base_velocity/error_vel_yaw: 0.0428
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.1667
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 1.07s
                        Total time: 182.65s
                               ETA: 3119.3s

################################################################################
                     [1m Learning iteration 166/3000 [0m                      

                       Computation: 91496 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.4212
                    Surrogate loss: 0.0051
             Mean action noise std: 0.5849
                     Learning rate: 0.0009
                       Mean reward: -0.62
               Mean episode length: 48.03
       Episode_Reward/keep_balance: 0.0485
     Episode_Reward/rew_lin_vel_xy: 0.0502
      Episode_Reward/rew_ang_vel_z: 0.1461
    Episode_Reward/pen_base_height: -0.1089
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0566
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2476
Metrics/base_velocity/error_vel_yaw: 0.0436
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.0000
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 1.07s
                        Total time: 183.72s
                               ETA: 3117.8s

################################################################################
                     [1m Learning iteration 167/3000 [0m                      

                       Computation: 91811 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.2399
                    Surrogate loss: 0.0011
             Mean action noise std: 0.5852
                     Learning rate: 0.0009
                       Mean reward: -0.76
               Mean episode length: 47.07
       Episode_Reward/keep_balance: 0.0484
     Episode_Reward/rew_lin_vel_xy: 0.0469
      Episode_Reward/rew_ang_vel_z: 0.1460
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0561
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2530
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.4583
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 1.07s
                        Total time: 184.79s
                               ETA: 3116.2s

################################################################################
                     [1m Learning iteration 168/3000 [0m                      

                       Computation: 92209 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 0.2312
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5859
                     Learning rate: 0.0013
                       Mean reward: -0.56
               Mean episode length: 48.47
       Episode_Reward/keep_balance: 0.0485
     Episode_Reward/rew_lin_vel_xy: 0.0511
      Episode_Reward/rew_ang_vel_z: 0.1464
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0560
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2468
Metrics/base_velocity/error_vel_yaw: 0.0427
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.5417
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 1.07s
                        Total time: 185.86s
                               ETA: 3114.5s

################################################################################
                     [1m Learning iteration 169/3000 [0m                      

                       Computation: 91684 steps/s (collection: 0.949s, learning 0.124s)
               Value function loss: 0.2486
                    Surrogate loss: -0.0019
             Mean action noise std: 0.5858
                     Learning rate: 0.0019
                       Mean reward: -0.65
               Mean episode length: 48.38
       Episode_Reward/keep_balance: 0.0486
     Episode_Reward/rew_lin_vel_xy: 0.0487
      Episode_Reward/rew_ang_vel_z: 0.1469
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0561
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0482
Metrics/base_velocity/error_vel_xy: 0.2471
Metrics/base_velocity/error_vel_yaw: 0.0427
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.5833
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 1.07s
                        Total time: 186.93s
                               ETA: 3113.0s

################################################################################
                     [1m Learning iteration 170/3000 [0m                      

                       Computation: 90789 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.3246
                    Surrogate loss: 0.0038
             Mean action noise std: 0.5865
                     Learning rate: 0.0013
                       Mean reward: -0.88
               Mean episode length: 46.11
       Episode_Reward/keep_balance: 0.0484
     Episode_Reward/rew_lin_vel_xy: 0.0494
      Episode_Reward/rew_ang_vel_z: 0.1468
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0553
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2494
Metrics/base_velocity/error_vel_yaw: 0.0424
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.4583
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 1.08s
                        Total time: 188.02s
                               ETA: 3111.6s

################################################################################
                     [1m Learning iteration 171/3000 [0m                      

                       Computation: 92258 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.2307
                    Surrogate loss: 0.0133
             Mean action noise std: 0.5871
                     Learning rate: 0.0000
                       Mean reward: -0.58
               Mean episode length: 49.49
       Episode_Reward/keep_balance: 0.0493
     Episode_Reward/rew_lin_vel_xy: 0.0494
      Episode_Reward/rew_ang_vel_z: 0.1487
    Episode_Reward/pen_base_height: -0.1086
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0564
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0484
Metrics/base_velocity/error_vel_xy: 0.2547
Metrics/base_velocity/error_vel_yaw: 0.0439
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.4583
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 1.07s
                        Total time: 189.08s
                               ETA: 3109.9s

################################################################################
                     [1m Learning iteration 172/3000 [0m                      

                       Computation: 91399 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.2035
                    Surrogate loss: 0.0033
             Mean action noise std: 0.5872
                     Learning rate: 0.0001
                       Mean reward: -0.45
               Mean episode length: 49.87
       Episode_Reward/keep_balance: 0.0488
     Episode_Reward/rew_lin_vel_xy: 0.0504
      Episode_Reward/rew_ang_vel_z: 0.1471
    Episode_Reward/pen_base_height: -0.1074
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0559
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0049
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2460
Metrics/base_velocity/error_vel_yaw: 0.0431
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.9167
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 1.08s
                        Total time: 190.16s
                               ETA: 3108.5s

################################################################################
                     [1m Learning iteration 173/3000 [0m                      

                       Computation: 91459 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 0.2019
                    Surrogate loss: -0.0019
             Mean action noise std: 0.5872
                     Learning rate: 0.0009
                       Mean reward: -0.65
               Mean episode length: 48.33
       Episode_Reward/keep_balance: 0.0484
     Episode_Reward/rew_lin_vel_xy: 0.0521
      Episode_Reward/rew_ang_vel_z: 0.1462
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0554
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0049
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2428
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 1.07s
                        Total time: 191.23s
                               ETA: 3107.0s

################################################################################
                     [1m Learning iteration 174/3000 [0m                      

                       Computation: 91603 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.2554
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5864
                     Learning rate: 0.0019
                       Mean reward: -0.75
               Mean episode length: 46.60
       Episode_Reward/keep_balance: 0.0478
     Episode_Reward/rew_lin_vel_xy: 0.0490
      Episode_Reward/rew_ang_vel_z: 0.1437
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0552
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2461
Metrics/base_velocity/error_vel_yaw: 0.0428
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 1.07s
                        Total time: 192.30s
                               ETA: 3105.4s

################################################################################
                     [1m Learning iteration 175/3000 [0m                      

                       Computation: 91811 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.1765
                    Surrogate loss: 0.0037
             Mean action noise std: 0.5864
                     Learning rate: 0.0006
                       Mean reward: -0.74
               Mean episode length: 49.94
       Episode_Reward/keep_balance: 0.0487
     Episode_Reward/rew_lin_vel_xy: 0.0492
      Episode_Reward/rew_ang_vel_z: 0.1469
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0555
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0049
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0482
Metrics/base_velocity/error_vel_xy: 0.2484
Metrics/base_velocity/error_vel_yaw: 0.0432
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.5833
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 1.07s
                        Total time: 193.37s
                               ETA: 3103.9s

################################################################################
                     [1m Learning iteration 176/3000 [0m                      

                       Computation: 91611 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.1820
                    Surrogate loss: -0.0016
             Mean action noise std: 0.5856
                     Learning rate: 0.0013
                       Mean reward: -0.73
               Mean episode length: 47.21
       Episode_Reward/keep_balance: 0.0481
     Episode_Reward/rew_lin_vel_xy: 0.0480
      Episode_Reward/rew_ang_vel_z: 0.1451
    Episode_Reward/pen_base_height: -0.1065
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0470
Metrics/base_velocity/error_vel_xy: 0.2468
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.1667
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 1.07s
                        Total time: 194.45s
                               ETA: 3102.4s

################################################################################
                     [1m Learning iteration 177/3000 [0m                      

                       Computation: 91278 steps/s (collection: 0.950s, learning 0.127s)
               Value function loss: 0.2585
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5844
                     Learning rate: 0.0029
                       Mean reward: -0.72
               Mean episode length: 49.26
       Episode_Reward/keep_balance: 0.0492
     Episode_Reward/rew_lin_vel_xy: 0.0512
      Episode_Reward/rew_ang_vel_z: 0.1489
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0201
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0560
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0481
Metrics/base_velocity/error_vel_xy: 0.2483
Metrics/base_velocity/error_vel_yaw: 0.0434
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.0833
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 1.08s
                        Total time: 195.53s
                               ETA: 3100.9s

################################################################################
                     [1m Learning iteration 178/3000 [0m                      

                       Computation: 89563 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.3283
                    Surrogate loss: 0.0019
             Mean action noise std: 0.5844
                     Learning rate: 0.0019
                       Mean reward: -0.69
               Mean episode length: 47.43
       Episode_Reward/keep_balance: 0.0481
     Episode_Reward/rew_lin_vel_xy: 0.0500
      Episode_Reward/rew_ang_vel_z: 0.1455
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0556
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0049
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2402
Metrics/base_velocity/error_vel_yaw: 0.0423
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.3750
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 1.10s
                        Total time: 196.62s
                               ETA: 3099.8s

################################################################################
                     [1m Learning iteration 179/3000 [0m                      

                       Computation: 92651 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 0.2350
                    Surrogate loss: 0.0051
             Mean action noise std: 0.5842
                     Learning rate: 0.0004
                       Mean reward: -0.39
               Mean episode length: 47.89
       Episode_Reward/keep_balance: 0.0489
     Episode_Reward/rew_lin_vel_xy: 0.0518
      Episode_Reward/rew_ang_vel_z: 0.1479
    Episode_Reward/pen_base_height: -0.1079
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0552
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2471
Metrics/base_velocity/error_vel_yaw: 0.0432
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.2083
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 1.06s
                        Total time: 197.68s
                               ETA: 3098.1s

################################################################################
                     [1m Learning iteration 180/3000 [0m                      

                       Computation: 92714 steps/s (collection: 0.938s, learning 0.122s)
               Value function loss: 0.1905
                    Surrogate loss: 0.0043
             Mean action noise std: 0.5839
                     Learning rate: 0.0003
                       Mean reward: -0.71
               Mean episode length: 50.69
       Episode_Reward/keep_balance: 0.0488
     Episode_Reward/rew_lin_vel_xy: 0.0472
      Episode_Reward/rew_ang_vel_z: 0.1470
    Episode_Reward/pen_base_height: -0.1083
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0560
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2522
Metrics/base_velocity/error_vel_yaw: 0.0435
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.0000
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 1.06s
                        Total time: 198.74s
                               ETA: 3096.5s

################################################################################
                     [1m Learning iteration 181/3000 [0m                      

                       Computation: 92107 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 0.1765
                    Surrogate loss: 0.0043
             Mean action noise std: 0.5839
                     Learning rate: 0.0002
                       Mean reward: -0.43
               Mean episode length: 49.98
       Episode_Reward/keep_balance: 0.0495
     Episode_Reward/rew_lin_vel_xy: 0.0529
      Episode_Reward/rew_ang_vel_z: 0.1499
    Episode_Reward/pen_base_height: -0.1094
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0567
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0482
Metrics/base_velocity/error_vel_xy: 0.2488
Metrics/base_velocity/error_vel_yaw: 0.0439
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.0417
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 1.07s
                        Total time: 199.81s
                               ETA: 3094.9s

################################################################################
                     [1m Learning iteration 182/3000 [0m                      

                       Computation: 92245 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.1824
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5834
                     Learning rate: 0.0006
                       Mean reward: -0.41
               Mean episode length: 49.24
       Episode_Reward/keep_balance: 0.0490
     Episode_Reward/rew_lin_vel_xy: 0.0519
      Episode_Reward/rew_ang_vel_z: 0.1482
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0559
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2461
Metrics/base_velocity/error_vel_yaw: 0.0434
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 1.07s
                        Total time: 200.88s
                               ETA: 3093.3s

################################################################################
                     [1m Learning iteration 183/3000 [0m                      

                       Computation: 92859 steps/s (collection: 0.936s, learning 0.122s)
               Value function loss: 0.1931
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5825
                     Learning rate: 0.0013
                       Mean reward: -0.29
               Mean episode length: 50.60
       Episode_Reward/keep_balance: 0.0492
     Episode_Reward/rew_lin_vel_xy: 0.0513
      Episode_Reward/rew_ang_vel_z: 0.1486
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0551
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2500
Metrics/base_velocity/error_vel_yaw: 0.0431
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.0833
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 1.06s
                        Total time: 201.94s
                               ETA: 3091.6s

################################################################################
                     [1m Learning iteration 184/3000 [0m                      

                       Computation: 93025 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 0.2381
                    Surrogate loss: 0.0031
             Mean action noise std: 0.5818
                     Learning rate: 0.0006
                       Mean reward: -0.71
               Mean episode length: 50.98
       Episode_Reward/keep_balance: 0.0493
     Episode_Reward/rew_lin_vel_xy: 0.0498
      Episode_Reward/rew_ang_vel_z: 0.1493
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0552
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2543
Metrics/base_velocity/error_vel_yaw: 0.0429
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.0417
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 1.06s
                        Total time: 202.99s
                               ETA: 3089.9s

################################################################################
                     [1m Learning iteration 185/3000 [0m                      

                       Computation: 93006 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 0.1960
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5818
                     Learning rate: 0.0013
                       Mean reward: -0.64
               Mean episode length: 49.89
       Episode_Reward/keep_balance: 0.0494
     Episode_Reward/rew_lin_vel_xy: 0.0518
      Episode_Reward/rew_ang_vel_z: 0.1493
    Episode_Reward/pen_base_height: -0.1086
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0560
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0482
Metrics/base_velocity/error_vel_xy: 0.2501
Metrics/base_velocity/error_vel_yaw: 0.0436
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.5000
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 1.06s
                        Total time: 204.05s
                               ETA: 3088.2s

################################################################################
                     [1m Learning iteration 186/3000 [0m                      

                       Computation: 90741 steps/s (collection: 0.957s, learning 0.126s)
               Value function loss: 0.1996
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5804
                     Learning rate: 0.0019
                       Mean reward: -0.32
               Mean episode length: 49.32
       Episode_Reward/keep_balance: 0.0494
     Episode_Reward/rew_lin_vel_xy: 0.0510
      Episode_Reward/rew_ang_vel_z: 0.1500
    Episode_Reward/pen_base_height: -0.1092
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0562
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2550
Metrics/base_velocity/error_vel_yaw: 0.0434
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.4167
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 1.08s
                        Total time: 205.13s
                               ETA: 3086.9s

################################################################################
                     [1m Learning iteration 187/3000 [0m                      

                       Computation: 91591 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.2439
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5792
                     Learning rate: 0.0029
                       Mean reward: -0.18
               Mean episode length: 51.49
       Episode_Reward/keep_balance: 0.0492
     Episode_Reward/rew_lin_vel_xy: 0.0510
      Episode_Reward/rew_ang_vel_z: 0.1494
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0549
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2513
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.3750
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 1.07s
                        Total time: 206.21s
                               ETA: 3085.4s

################################################################################
                     [1m Learning iteration 188/3000 [0m                      

                       Computation: 91184 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.2886
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5791
                     Learning rate: 0.0044
                       Mean reward: -0.31
               Mean episode length: 51.16
       Episode_Reward/keep_balance: 0.0493
     Episode_Reward/rew_lin_vel_xy: 0.0510
      Episode_Reward/rew_ang_vel_z: 0.1493
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0555
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2510
Metrics/base_velocity/error_vel_yaw: 0.0432
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.4583
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 1.08s
                        Total time: 207.28s
                               ETA: 3084.0s

################################################################################
                     [1m Learning iteration 189/3000 [0m                      

                       Computation: 91056 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.3155
                    Surrogate loss: 0.0083
             Mean action noise std: 0.5796
                     Learning rate: 0.0004
                       Mean reward: -0.21
               Mean episode length: 49.87
       Episode_Reward/keep_balance: 0.0492
     Episode_Reward/rew_lin_vel_xy: 0.0510
      Episode_Reward/rew_ang_vel_z: 0.1498
    Episode_Reward/pen_base_height: -0.1069
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2512
Metrics/base_velocity/error_vel_yaw: 0.0424
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.3750
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 1.08s
                        Total time: 208.36s
                               ETA: 3082.7s

################################################################################
                     [1m Learning iteration 190/3000 [0m                      

                       Computation: 91233 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.1938
                    Surrogate loss: 0.0017
             Mean action noise std: 0.5796
                     Learning rate: 0.0004
                       Mean reward: -0.46
               Mean episode length: 50.62
       Episode_Reward/keep_balance: 0.0492
     Episode_Reward/rew_lin_vel_xy: 0.0518
      Episode_Reward/rew_ang_vel_z: 0.1498
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0547
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2507
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.5417
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 1.08s
                        Total time: 209.44s
                               ETA: 3081.3s

################################################################################
                     [1m Learning iteration 191/3000 [0m                      

                       Computation: 90851 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.1896
                    Surrogate loss: 0.0012
             Mean action noise std: 0.5799
                     Learning rate: 0.0004
                       Mean reward: -0.41
               Mean episode length: 49.18
       Episode_Reward/keep_balance: 0.0493
     Episode_Reward/rew_lin_vel_xy: 0.0508
      Episode_Reward/rew_ang_vel_z: 0.1500
    Episode_Reward/pen_base_height: -0.1069
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2520
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.0417
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 1.08s
                        Total time: 210.52s
                               ETA: 3080.0s

################################################################################
                     [1m Learning iteration 192/3000 [0m                      

                       Computation: 86587 steps/s (collection: 1.014s, learning 0.122s)
               Value function loss: 0.1849
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5797
                     Learning rate: 0.0009
                       Mean reward: -0.25
               Mean episode length: 49.47
       Episode_Reward/keep_balance: 0.0495
     Episode_Reward/rew_lin_vel_xy: 0.0521
      Episode_Reward/rew_ang_vel_z: 0.1505
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2537
Metrics/base_velocity/error_vel_yaw: 0.0431
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.5000
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 1.14s
                        Total time: 211.66s
                               ETA: 3079.5s

################################################################################
                     [1m Learning iteration 193/3000 [0m                      

                       Computation: 91767 steps/s (collection: 0.946s, learning 0.125s)
               Value function loss: 0.2011
                    Surrogate loss: 0.0056
             Mean action noise std: 0.5795
                     Learning rate: 0.0004
                       Mean reward: -0.38
               Mean episode length: 49.73
       Episode_Reward/keep_balance: 0.0494
     Episode_Reward/rew_lin_vel_xy: 0.0515
      Episode_Reward/rew_ang_vel_z: 0.1503
    Episode_Reward/pen_base_height: -0.1074
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0552
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2486
Metrics/base_velocity/error_vel_yaw: 0.0428
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.8750
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 1.07s
                        Total time: 212.73s
                               ETA: 3078.0s

################################################################################
                     [1m Learning iteration 194/3000 [0m                      

                       Computation: 91574 steps/s (collection: 0.943s, learning 0.130s)
               Value function loss: 0.1795
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5791
                     Learning rate: 0.0003
                       Mean reward: -0.52
               Mean episode length: 49.79
       Episode_Reward/keep_balance: 0.0495
     Episode_Reward/rew_lin_vel_xy: 0.0519
      Episode_Reward/rew_ang_vel_z: 0.1509
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2508
Metrics/base_velocity/error_vel_yaw: 0.0427
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.6250
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 1.07s
                        Total time: 213.80s
                               ETA: 3076.6s

################################################################################
                     [1m Learning iteration 195/3000 [0m                      

                       Computation: 89794 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.1823
                    Surrogate loss: 0.0001
             Mean action noise std: 0.5785
                     Learning rate: 0.0003
                       Mean reward: -0.17
               Mean episode length: 49.79
       Episode_Reward/keep_balance: 0.0499
     Episode_Reward/rew_lin_vel_xy: 0.0546
      Episode_Reward/rew_ang_vel_z: 0.1522
    Episode_Reward/pen_base_height: -0.1069
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2502
Metrics/base_velocity/error_vel_yaw: 0.0429
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.9167
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 1.09s
                        Total time: 214.90s
                               ETA: 3075.5s

################################################################################
                     [1m Learning iteration 196/3000 [0m                      

                       Computation: 90460 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.1741
                    Surrogate loss: -0.0011
             Mean action noise std: 0.5784
                     Learning rate: 0.0004
                       Mean reward: -0.50
               Mean episode length: 49.18
       Episode_Reward/keep_balance: 0.0498
     Episode_Reward/rew_lin_vel_xy: 0.0532
      Episode_Reward/rew_ang_vel_z: 0.1515
    Episode_Reward/pen_base_height: -0.1079
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2500
Metrics/base_velocity/error_vel_yaw: 0.0439
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.5000
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 1.09s
                        Total time: 215.98s
                               ETA: 3074.2s

################################################################################
                     [1m Learning iteration 197/3000 [0m                      

                       Computation: 87632 steps/s (collection: 1.000s, learning 0.122s)
               Value function loss: 0.1833
                    Surrogate loss: 0.0004
             Mean action noise std: 0.5774
                     Learning rate: 0.0006
                       Mean reward: -0.40
               Mean episode length: 50.41
       Episode_Reward/keep_balance: 0.0494
     Episode_Reward/rew_lin_vel_xy: 0.0511
      Episode_Reward/rew_ang_vel_z: 0.1501
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0054
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2497
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.7500
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 1.12s
                        Total time: 217.11s
                               ETA: 3073.5s

################################################################################
                     [1m Learning iteration 198/3000 [0m                      

                       Computation: 89655 steps/s (collection: 0.972s, learning 0.125s)
               Value function loss: 0.1630
                    Surrogate loss: 0.0013
             Mean action noise std: 0.5765
                     Learning rate: 0.0004
                       Mean reward: -0.27
               Mean episode length: 50.73
       Episode_Reward/keep_balance: 0.0500
     Episode_Reward/rew_lin_vel_xy: 0.0518
      Episode_Reward/rew_ang_vel_z: 0.1520
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0547
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0472
Metrics/base_velocity/error_vel_xy: 0.2562
Metrics/base_velocity/error_vel_yaw: 0.0433
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.8333
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 1.10s
                        Total time: 218.20s
                               ETA: 3072.4s

################################################################################
                     [1m Learning iteration 199/3000 [0m                      

                       Computation: 91921 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 0.1745
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5767
                     Learning rate: 0.0006
                       Mean reward: -0.48
               Mean episode length: 50.29
       Episode_Reward/keep_balance: 0.0500
     Episode_Reward/rew_lin_vel_xy: 0.0526
      Episode_Reward/rew_ang_vel_z: 0.1522
    Episode_Reward/pen_base_height: -0.1076
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0054
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2542
Metrics/base_velocity/error_vel_yaw: 0.0433
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.8750
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 1.07s
                        Total time: 219.27s
                               ETA: 3070.9s

################################################################################
                     [1m Learning iteration 200/3000 [0m                      

                       Computation: 92508 steps/s (collection: 0.938s, learning 0.124s)
               Value function loss: 0.1976
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5760
                     Learning rate: 0.0004
                       Mean reward: -0.40
               Mean episode length: 49.68
       Episode_Reward/keep_balance: 0.0498
     Episode_Reward/rew_lin_vel_xy: 0.0511
      Episode_Reward/rew_ang_vel_z: 0.1517
    Episode_Reward/pen_base_height: -0.1074
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2532
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.5000
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 1.06s
                        Total time: 220.33s
                               ETA: 3069.3s

################################################################################
                     [1m Learning iteration 201/3000 [0m                      

                       Computation: 90084 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.1928
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5752
                     Learning rate: 0.0004
                       Mean reward: -0.31
               Mean episode length: 51.49
       Episode_Reward/keep_balance: 0.0499
     Episode_Reward/rew_lin_vel_xy: 0.0512
      Episode_Reward/rew_ang_vel_z: 0.1520
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0468
Metrics/base_velocity/error_vel_xy: 0.2549
Metrics/base_velocity/error_vel_yaw: 0.0431
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 1.09s
                        Total time: 221.43s
                               ETA: 3068.2s

################################################################################
                     [1m Learning iteration 202/3000 [0m                      

                       Computation: 91462 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.1765
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5748
                     Learning rate: 0.0004
                       Mean reward: -0.60
               Mean episode length: 48.32
       Episode_Reward/keep_balance: 0.0499
     Episode_Reward/rew_lin_vel_xy: 0.0509
      Episode_Reward/rew_ang_vel_z: 0.1519
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0057
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2552
Metrics/base_velocity/error_vel_yaw: 0.0433
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 1.07s
                        Total time: 222.50s
                               ETA: 3066.8s

################################################################################
                     [1m Learning iteration 203/3000 [0m                      

                       Computation: 88522 steps/s (collection: 0.985s, learning 0.126s)
               Value function loss: 0.1875
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5747
                     Learning rate: 0.0009
                       Mean reward: -0.34
               Mean episode length: 49.21
       Episode_Reward/keep_balance: 0.0504
     Episode_Reward/rew_lin_vel_xy: 0.0554
      Episode_Reward/rew_ang_vel_z: 0.1539
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0547
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2522
Metrics/base_velocity/error_vel_yaw: 0.0436
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.2917
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 1.11s
                        Total time: 223.61s
                               ETA: 3065.9s

################################################################################
                     [1m Learning iteration 204/3000 [0m                      

                       Computation: 77501 steps/s (collection: 1.144s, learning 0.125s)
               Value function loss: 0.2196
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5743
                     Learning rate: 0.0019
                       Mean reward: -0.44
               Mean episode length: 50.07
       Episode_Reward/keep_balance: 0.0508
     Episode_Reward/rew_lin_vel_xy: 0.0572
      Episode_Reward/rew_ang_vel_z: 0.1553
    Episode_Reward/pen_base_height: -0.1076
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2508
Metrics/base_velocity/error_vel_yaw: 0.0436
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 1.27s
                        Total time: 224.88s
                               ETA: 3067.1s

################################################################################
                     [1m Learning iteration 205/3000 [0m                      

                       Computation: 91117 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.2374
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5740
                     Learning rate: 0.0029
                       Mean reward: -0.20
               Mean episode length: 51.50
       Episode_Reward/keep_balance: 0.0503
     Episode_Reward/rew_lin_vel_xy: 0.0529
      Episode_Reward/rew_ang_vel_z: 0.1533
    Episode_Reward/pen_base_height: -0.1076
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0543
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2521
Metrics/base_velocity/error_vel_yaw: 0.0433
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.6667
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 1.08s
                        Total time: 225.96s
                               ETA: 3065.8s

################################################################################
                     [1m Learning iteration 206/3000 [0m                      

                       Computation: 89511 steps/s (collection: 0.972s, learning 0.126s)
               Value function loss: 0.3368
                    Surrogate loss: 0.0062
             Mean action noise std: 0.5736
                     Learning rate: 0.0003
                       Mean reward: -0.26
               Mean episode length: 50.35
       Episode_Reward/keep_balance: 0.0503
     Episode_Reward/rew_lin_vel_xy: 0.0527
      Episode_Reward/rew_ang_vel_z: 0.1536
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2554
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.3333
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 1.10s
                        Total time: 227.06s
                               ETA: 3064.7s

################################################################################
                     [1m Learning iteration 207/3000 [0m                      

                       Computation: 91406 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.2027
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5729
                     Learning rate: 0.0006
                       Mean reward: -0.02
               Mean episode length: 52.13
       Episode_Reward/keep_balance: 0.0503
     Episode_Reward/rew_lin_vel_xy: 0.0518
      Episode_Reward/rew_ang_vel_z: 0.1544
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0054
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2550
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.7500
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 1.08s
                        Total time: 228.13s
                               ETA: 3063.3s

################################################################################
                     [1m Learning iteration 208/3000 [0m                      

                       Computation: 89286 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 0.1998
                    Surrogate loss: 0.0014
             Mean action noise std: 0.5718
                     Learning rate: 0.0004
                       Mean reward: -0.30
               Mean episode length: 48.96
       Episode_Reward/keep_balance: 0.0505
     Episode_Reward/rew_lin_vel_xy: 0.0541
      Episode_Reward/rew_ang_vel_z: 0.1545
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2525
Metrics/base_velocity/error_vel_yaw: 0.0435
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.5833
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 1.10s
                        Total time: 229.23s
                               ETA: 3062.3s

################################################################################
                     [1m Learning iteration 209/3000 [0m                      

                       Computation: 92637 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 0.2042
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5711
                     Learning rate: 0.0009
                       Mean reward: -0.54
               Mean episode length: 49.47
       Episode_Reward/keep_balance: 0.0502
     Episode_Reward/rew_lin_vel_xy: 0.0497
      Episode_Reward/rew_ang_vel_z: 0.1537
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0539
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0057
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0470
Metrics/base_velocity/error_vel_xy: 0.2558
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.9167
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 1.06s
                        Total time: 230.29s
                               ETA: 3060.7s

################################################################################
                     [1m Learning iteration 210/3000 [0m                      

                       Computation: 92379 steps/s (collection: 0.940s, learning 0.124s)
               Value function loss: 0.2145
                    Surrogate loss: 0.0013
             Mean action noise std: 0.5705
                     Learning rate: 0.0004
                       Mean reward: -0.58
               Mean episode length: 48.27
       Episode_Reward/keep_balance: 0.0503
     Episode_Reward/rew_lin_vel_xy: 0.0516
      Episode_Reward/rew_ang_vel_z: 0.1540
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0057
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2572
Metrics/base_velocity/error_vel_yaw: 0.0429
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 1.06s
                        Total time: 231.36s
                               ETA: 3059.2s

################################################################################
                     [1m Learning iteration 211/3000 [0m                      

                       Computation: 91390 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.1745
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5694
                     Learning rate: 0.0009
                       Mean reward: -0.42
               Mean episode length: 50.36
       Episode_Reward/keep_balance: 0.0506
     Episode_Reward/rew_lin_vel_xy: 0.0500
      Episode_Reward/rew_ang_vel_z: 0.1553
    Episode_Reward/pen_base_height: -0.1076
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0543
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0470
Metrics/base_velocity/error_vel_xy: 0.2606
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 1.08s
                        Total time: 232.43s
                               ETA: 3057.8s

################################################################################
                     [1m Learning iteration 212/3000 [0m                      

                       Computation: 92541 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 0.1787
                    Surrogate loss: 0.0038
             Mean action noise std: 0.5693
                     Learning rate: 0.0003
                       Mean reward: -0.16
               Mean episode length: 52.47
       Episode_Reward/keep_balance: 0.0509
     Episode_Reward/rew_lin_vel_xy: 0.0530
      Episode_Reward/rew_ang_vel_z: 0.1559
    Episode_Reward/pen_base_height: -0.1081
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0472
Metrics/base_velocity/error_vel_xy: 0.2571
Metrics/base_velocity/error_vel_yaw: 0.0438
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.1250
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 1.06s
                        Total time: 233.50s
                               ETA: 3056.3s

################################################################################
                     [1m Learning iteration 213/3000 [0m                      

                       Computation: 93063 steps/s (collection: 0.932s, learning 0.124s)
               Value function loss: 0.1737
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5679
                     Learning rate: 0.0006
                       Mean reward: -0.27
               Mean episode length: 50.17
       Episode_Reward/keep_balance: 0.0512
     Episode_Reward/rew_lin_vel_xy: 0.0546
      Episode_Reward/rew_ang_vel_z: 0.1572
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0058
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0059
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2575
Metrics/base_velocity/error_vel_yaw: 0.0435
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.0833
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 1.06s
                        Total time: 234.55s
                               ETA: 3054.7s

################################################################################
                     [1m Learning iteration 214/3000 [0m                      

                       Computation: 91587 steps/s (collection: 0.949s, learning 0.124s)
               Value function loss: 0.1770
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5671
                     Learning rate: 0.0006
                       Mean reward: -0.35
               Mean episode length: 49.78
       Episode_Reward/keep_balance: 0.0511
     Episode_Reward/rew_lin_vel_xy: 0.0573
      Episode_Reward/rew_ang_vel_z: 0.1572
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2557
Metrics/base_velocity/error_vel_yaw: 0.0431
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.2917
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 1.07s
                        Total time: 235.63s
                               ETA: 3053.3s

################################################################################
                     [1m Learning iteration 215/3000 [0m                      

                       Computation: 90505 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.1918
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5671
                     Learning rate: 0.0003
                       Mean reward: -0.10
               Mean episode length: 51.35
       Episode_Reward/keep_balance: 0.0511
     Episode_Reward/rew_lin_vel_xy: 0.0538
      Episode_Reward/rew_ang_vel_z: 0.1568
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0542
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2564
Metrics/base_velocity/error_vel_yaw: 0.0432
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 1.09s
                        Total time: 236.71s
                               ETA: 3052.1s

################################################################################
                     [1m Learning iteration 216/3000 [0m                      

                       Computation: 91303 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.1655
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5670
                     Learning rate: 0.0006
                       Mean reward: -0.24
               Mean episode length: 50.72
       Episode_Reward/keep_balance: 0.0508
     Episode_Reward/rew_lin_vel_xy: 0.0545
      Episode_Reward/rew_ang_vel_z: 0.1562
    Episode_Reward/pen_base_height: -0.1074
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2598
Metrics/base_velocity/error_vel_yaw: 0.0433
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 77.0417
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 1.08s
                        Total time: 237.79s
                               ETA: 3050.7s

################################################################################
                     [1m Learning iteration 217/3000 [0m                      

                       Computation: 91091 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.1969
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5676
                     Learning rate: 0.0009
                       Mean reward: -0.38
               Mean episode length: 51.44
       Episode_Reward/keep_balance: 0.0515
     Episode_Reward/rew_lin_vel_xy: 0.0529
      Episode_Reward/rew_ang_vel_z: 0.1584
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0058
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0059
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2605
Metrics/base_velocity/error_vel_yaw: 0.0437
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.2083
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 1.08s
                        Total time: 238.87s
                               ETA: 3049.4s

################################################################################
                     [1m Learning iteration 218/3000 [0m                      

                       Computation: 91804 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.1912
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5678
                     Learning rate: 0.0013
                       Mean reward: -0.32
               Mean episode length: 50.37
       Episode_Reward/keep_balance: 0.0509
     Episode_Reward/rew_lin_vel_xy: 0.0522
      Episode_Reward/rew_ang_vel_z: 0.1560
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0058
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0059
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2589
Metrics/base_velocity/error_vel_yaw: 0.0434
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.4167
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 1.07s
                        Total time: 239.94s
                               ETA: 3048.0s

################################################################################
                     [1m Learning iteration 219/3000 [0m                      

                       Computation: 90787 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.1832
                    Surrogate loss: 0.0030
             Mean action noise std: 0.5680
                     Learning rate: 0.0006
                       Mean reward: -0.29
               Mean episode length: 50.70
       Episode_Reward/keep_balance: 0.0511
     Episode_Reward/rew_lin_vel_xy: 0.0544
      Episode_Reward/rew_ang_vel_z: 0.1569
    Episode_Reward/pen_base_height: -0.1076
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0058
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2577
Metrics/base_velocity/error_vel_yaw: 0.0433
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.3750
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 1.08s
                        Total time: 241.02s
                               ETA: 3046.7s

################################################################################
                     [1m Learning iteration 220/3000 [0m                      

                       Computation: 89120 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 0.1806
                    Surrogate loss: -0.0008
             Mean action noise std: 0.5688
                     Learning rate: 0.0009
                       Mean reward: 0.04
               Mean episode length: 52.67
       Episode_Reward/keep_balance: 0.0520
     Episode_Reward/rew_lin_vel_xy: 0.0560
      Episode_Reward/rew_ang_vel_z: 0.1593
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0059
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0547
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0059
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0483
Metrics/base_velocity/error_vel_xy: 0.2590
Metrics/base_velocity/error_vel_yaw: 0.0443
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 77.9583
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 1.10s
                        Total time: 242.12s
                               ETA: 3045.7s

################################################################################
                     [1m Learning iteration 221/3000 [0m                      

                       Computation: 91228 steps/s (collection: 0.950s, learning 0.127s)
               Value function loss: 0.1943
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5687
                     Learning rate: 0.0006
                       Mean reward: -0.59
               Mean episode length: 49.82
       Episode_Reward/keep_balance: 0.0512
     Episode_Reward/rew_lin_vel_xy: 0.0526
      Episode_Reward/rew_ang_vel_z: 0.1571
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0059
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0059
   Episode_Reward/foot_landing_vel: -0.0074
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2608
Metrics/base_velocity/error_vel_yaw: 0.0437
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.8333
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 1.08s
                        Total time: 243.20s
                               ETA: 3044.4s

################################################################################
                     [1m Learning iteration 222/3000 [0m                      

                       Computation: 90252 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.1855
                    Surrogate loss: 0.0003
             Mean action noise std: 0.5681
                     Learning rate: 0.0004
                       Mean reward: -0.15
               Mean episode length: 52.63
       Episode_Reward/keep_balance: 0.0523
     Episode_Reward/rew_lin_vel_xy: 0.0572
      Episode_Reward/rew_ang_vel_z: 0.1606
    Episode_Reward/pen_base_height: -0.1081
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0547
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0074
   Episode_Reward/test_gait_reward: -0.0486
Metrics/base_velocity/error_vel_xy: 0.2637
Metrics/base_velocity/error_vel_yaw: 0.0446
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 1.09s
                        Total time: 244.29s
                               ETA: 3043.2s

################################################################################
                     [1m Learning iteration 223/3000 [0m                      

                       Computation: 91044 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.1626
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5680
                     Learning rate: 0.0004
                       Mean reward: -0.15
               Mean episode length: 52.90
       Episode_Reward/keep_balance: 0.0517
     Episode_Reward/rew_lin_vel_xy: 0.0563
      Episode_Reward/rew_ang_vel_z: 0.1589
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0074
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2621
Metrics/base_velocity/error_vel_yaw: 0.0436
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.7500
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 1.08s
                        Total time: 245.37s
                               ETA: 3041.9s

################################################################################
                     [1m Learning iteration 224/3000 [0m                      

                       Computation: 91035 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.1691
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5680
                     Learning rate: 0.0006
                       Mean reward: -0.59
               Mean episode length: 50.07
       Episode_Reward/keep_balance: 0.0517
     Episode_Reward/rew_lin_vel_xy: 0.0548
      Episode_Reward/rew_ang_vel_z: 0.1588
    Episode_Reward/pen_base_height: -0.1074
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2587
Metrics/base_velocity/error_vel_yaw: 0.0440
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 77.5000
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 1.08s
                        Total time: 246.45s
                               ETA: 3040.7s

################################################################################
                     [1m Learning iteration 225/3000 [0m                      

                       Computation: 90472 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.1780
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5675
                     Learning rate: 0.0004
                       Mean reward: -0.28
               Mean episode length: 52.36
       Episode_Reward/keep_balance: 0.0519
     Episode_Reward/rew_lin_vel_xy: 0.0549
      Episode_Reward/rew_ang_vel_z: 0.1595
    Episode_Reward/pen_base_height: -0.1079
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0534
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0074
   Episode_Reward/test_gait_reward: -0.0480
Metrics/base_velocity/error_vel_xy: 0.2632
Metrics/base_velocity/error_vel_yaw: 0.0439
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 1.09s
                        Total time: 247.54s
                               ETA: 3039.5s

################################################################################
                     [1m Learning iteration 226/3000 [0m                      

                       Computation: 91213 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.1761
                    Surrogate loss: -0.0008
             Mean action noise std: 0.5667
                     Learning rate: 0.0006
                       Mean reward: -0.33
               Mean episode length: 51.34
       Episode_Reward/keep_balance: 0.0517
     Episode_Reward/rew_lin_vel_xy: 0.0566
      Episode_Reward/rew_ang_vel_z: 0.1585
    Episode_Reward/pen_base_height: -0.1069
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0527
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0074
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2601
Metrics/base_velocity/error_vel_yaw: 0.0443
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.0000
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 1.08s
                        Total time: 248.62s
                               ETA: 3038.1s

################################################################################
                     [1m Learning iteration 227/3000 [0m                      

                       Computation: 90168 steps/s (collection: 0.965s, learning 0.125s)
               Value function loss: 0.1754
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5658
                     Learning rate: 0.0006
                       Mean reward: -0.34
               Mean episode length: 51.44
       Episode_Reward/keep_balance: 0.0517
     Episode_Reward/rew_lin_vel_xy: 0.0553
      Episode_Reward/rew_ang_vel_z: 0.1586
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2584
Metrics/base_velocity/error_vel_yaw: 0.0439
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 1.09s
                        Total time: 249.71s
                               ETA: 3037.0s

################################################################################
                     [1m Learning iteration 228/3000 [0m                      

                       Computation: 90919 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.1839
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5650
                     Learning rate: 0.0009
                       Mean reward: -0.30
               Mean episode length: 52.37
       Episode_Reward/keep_balance: 0.0526
     Episode_Reward/rew_lin_vel_xy: 0.0555
      Episode_Reward/rew_ang_vel_z: 0.1606
    Episode_Reward/pen_base_height: -0.1093
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0061
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0557
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0064
   Episode_Reward/foot_landing_vel: -0.0076
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2709
Metrics/base_velocity/error_vel_yaw: 0.0455
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 72.1250
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 1.08s
                        Total time: 250.79s
                               ETA: 3035.7s

################################################################################
                     [1m Learning iteration 229/3000 [0m                      

                       Computation: 90998 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.1848
                    Surrogate loss: 0.0081
             Mean action noise std: 0.5648
                     Learning rate: 0.0001
                       Mean reward: -0.10
               Mean episode length: 56.27
       Episode_Reward/keep_balance: 0.0532
     Episode_Reward/rew_lin_vel_xy: 0.0578
      Episode_Reward/rew_ang_vel_z: 0.1628
    Episode_Reward/pen_base_height: -0.1090
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0063
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0544
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0065
   Episode_Reward/foot_landing_vel: -0.0076
   Episode_Reward/test_gait_reward: -0.0486
Metrics/base_velocity/error_vel_xy: 0.2686
Metrics/base_velocity/error_vel_yaw: 0.0457
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.0417
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 1.08s
                        Total time: 251.87s
                               ETA: 3034.5s

################################################################################
                     [1m Learning iteration 230/3000 [0m                      

                       Computation: 90955 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.1704
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5643
                     Learning rate: 0.0003
                       Mean reward: -0.15
               Mean episode length: 52.80
       Episode_Reward/keep_balance: 0.0532
     Episode_Reward/rew_lin_vel_xy: 0.0570
      Episode_Reward/rew_ang_vel_z: 0.1627
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0061
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0064
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0490
Metrics/base_velocity/error_vel_xy: 0.2675
Metrics/base_velocity/error_vel_yaw: 0.0456
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 77.0000
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 1.08s
                        Total time: 252.95s
                               ETA: 3033.2s

################################################################################
                     [1m Learning iteration 231/3000 [0m                      

                       Computation: 90731 steps/s (collection: 0.959s, learning 0.125s)
               Value function loss: 0.1891
                    Surrogate loss: -0.0011
             Mean action noise std: 0.5639
                     Learning rate: 0.0006
                       Mean reward: -0.33
               Mean episode length: 52.14
       Episode_Reward/keep_balance: 0.0520
     Episode_Reward/rew_lin_vel_xy: 0.0550
      Episode_Reward/rew_ang_vel_z: 0.1593
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0061
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0065
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2647
Metrics/base_velocity/error_vel_yaw: 0.0443
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 77.1250
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 1.08s
                        Total time: 254.03s
                               ETA: 3032.0s

################################################################################
                     [1m Learning iteration 232/3000 [0m                      

                       Computation: 90233 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.2085
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5636
                     Learning rate: 0.0013
                       Mean reward: -0.49
               Mean episode length: 50.66
       Episode_Reward/keep_balance: 0.0528
     Episode_Reward/rew_lin_vel_xy: 0.0579
      Episode_Reward/rew_ang_vel_z: 0.1617
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0061
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0528
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0064
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0483
Metrics/base_velocity/error_vel_xy: 0.2664
Metrics/base_velocity/error_vel_yaw: 0.0449
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.3750
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 1.09s
                        Total time: 255.12s
                               ETA: 3030.8s

################################################################################
                     [1m Learning iteration 233/3000 [0m                      

                       Computation: 91381 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.1982
                    Surrogate loss: 0.0102
             Mean action noise std: 0.5640
                     Learning rate: 0.0002
                       Mean reward: 0.05
               Mean episode length: 53.08
       Episode_Reward/keep_balance: 0.0523
     Episode_Reward/rew_lin_vel_xy: 0.0551
      Episode_Reward/rew_ang_vel_z: 0.1604
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0061
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0534
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0065
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2620
Metrics/base_velocity/error_vel_yaw: 0.0445
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 75.2500
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 1.08s
                        Total time: 256.20s
                               ETA: 3029.5s

################################################################################
                     [1m Learning iteration 234/3000 [0m                      

                       Computation: 91610 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.1769
                    Surrogate loss: -0.0021
             Mean action noise std: 0.5636
                     Learning rate: 0.0004
                       Mean reward: -0.19
               Mean episode length: 51.70
       Episode_Reward/keep_balance: 0.0524
     Episode_Reward/rew_lin_vel_xy: 0.0556
      Episode_Reward/rew_ang_vel_z: 0.1600
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0062
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0066
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2684
Metrics/base_velocity/error_vel_yaw: 0.0450
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.2083
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 1.07s
                        Total time: 257.27s
                               ETA: 3028.1s

################################################################################
                     [1m Learning iteration 235/3000 [0m                      

                       Computation: 89365 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 0.1719
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5629
                     Learning rate: 0.0006
                       Mean reward: -0.24
               Mean episode length: 53.68
       Episode_Reward/keep_balance: 0.0532
     Episode_Reward/rew_lin_vel_xy: 0.0581
      Episode_Reward/rew_ang_vel_z: 0.1636
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0062
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0066
   Episode_Reward/foot_landing_vel: -0.0076
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2618
Metrics/base_velocity/error_vel_yaw: 0.0452
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.8333
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 1.10s
                        Total time: 258.37s
                               ETA: 3027.1s

################################################################################
                     [1m Learning iteration 236/3000 [0m                      

                       Computation: 89886 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.1806
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5613
                     Learning rate: 0.0009
                       Mean reward: -0.11
               Mean episode length: 51.96
       Episode_Reward/keep_balance: 0.0536
     Episode_Reward/rew_lin_vel_xy: 0.0590
      Episode_Reward/rew_ang_vel_z: 0.1651
    Episode_Reward/pen_base_height: -0.1079
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0063
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0066
   Episode_Reward/foot_landing_vel: -0.0076
   Episode_Reward/test_gait_reward: -0.0485
Metrics/base_velocity/error_vel_xy: 0.2705
Metrics/base_velocity/error_vel_yaw: 0.0455
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.9167
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 1.09s
                        Total time: 259.46s
                               ETA: 3026.0s

################################################################################
                     [1m Learning iteration 237/3000 [0m                      

                       Computation: 90147 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.1959
                    Surrogate loss: 0.0010
             Mean action noise std: 0.5607
                     Learning rate: 0.0004
                       Mean reward: -0.00
               Mean episode length: 52.36
       Episode_Reward/keep_balance: 0.0529
     Episode_Reward/rew_lin_vel_xy: 0.0539
      Episode_Reward/rew_ang_vel_z: 0.1623
    Episode_Reward/pen_base_height: -0.1074
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0062
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0067
   Episode_Reward/foot_landing_vel: -0.0077
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2696
Metrics/base_velocity/error_vel_yaw: 0.0451
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.4583
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 1.09s
                        Total time: 260.55s
                               ETA: 3024.8s

################################################################################
                     [1m Learning iteration 238/3000 [0m                      

                       Computation: 90822 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.2007
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5604
                     Learning rate: 0.0009
                       Mean reward: -0.20
               Mean episode length: 52.13
       Episode_Reward/keep_balance: 0.0528
     Episode_Reward/rew_lin_vel_xy: 0.0550
      Episode_Reward/rew_ang_vel_z: 0.1623
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0063
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0068
   Episode_Reward/foot_landing_vel: -0.0077
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2703
Metrics/base_velocity/error_vel_yaw: 0.0451
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.3750
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 1.08s
                        Total time: 261.64s
                               ETA: 3023.6s

################################################################################
                     [1m Learning iteration 239/3000 [0m                      

                       Computation: 92693 steps/s (collection: 0.936s, learning 0.125s)
               Value function loss: 0.2223
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5609
                     Learning rate: 0.0013
                       Mean reward: -0.14
               Mean episode length: 53.18
       Episode_Reward/keep_balance: 0.0536
     Episode_Reward/rew_lin_vel_xy: 0.0554
      Episode_Reward/rew_ang_vel_z: 0.1644
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0063
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0069
   Episode_Reward/foot_landing_vel: -0.0077
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2701
Metrics/base_velocity/error_vel_yaw: 0.0454
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.4167
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 1.06s
                        Total time: 262.70s
                               ETA: 3022.1s

################################################################################
                     [1m Learning iteration 240/3000 [0m                      

                       Computation: 92469 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 0.3015
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5609
                     Learning rate: 0.0029
                       Mean reward: -0.42
               Mean episode length: 53.74
       Episode_Reward/keep_balance: 0.0533
     Episode_Reward/rew_lin_vel_xy: 0.0557
      Episode_Reward/rew_ang_vel_z: 0.1632
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0064
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0071
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2722
Metrics/base_velocity/error_vel_yaw: 0.0457
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 1.06s
                        Total time: 263.76s
                               ETA: 3020.7s

################################################################################
                     [1m Learning iteration 241/3000 [0m                      

                       Computation: 92758 steps/s (collection: 0.938s, learning 0.122s)
               Value function loss: 0.3761
                    Surrogate loss: -0.0011
             Mean action noise std: 0.5614
                     Learning rate: 0.0044
                       Mean reward: -0.07
               Mean episode length: 53.94
       Episode_Reward/keep_balance: 0.0546
     Episode_Reward/rew_lin_vel_xy: 0.0585
      Episode_Reward/rew_ang_vel_z: 0.1671
    Episode_Reward/pen_base_height: -0.1081
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0065
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0070
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0488
Metrics/base_velocity/error_vel_xy: 0.2769
Metrics/base_velocity/error_vel_yaw: 0.0468
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 1.06s
                        Total time: 264.82s
                               ETA: 3019.2s

################################################################################
                     [1m Learning iteration 242/3000 [0m                      

                       Computation: 91709 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.3536
                    Surrogate loss: 0.0057
             Mean action noise std: 0.5621
                     Learning rate: 0.0006
                       Mean reward: 0.19
               Mean episode length: 56.69
       Episode_Reward/keep_balance: 0.0532
     Episode_Reward/rew_lin_vel_xy: 0.0548
      Episode_Reward/rew_ang_vel_z: 0.1630
    Episode_Reward/pen_base_height: -0.1079
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0063
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0532
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0070
   Episode_Reward/foot_landing_vel: -0.0077
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2723
Metrics/base_velocity/error_vel_yaw: 0.0459
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 75.5417
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 1.07s
                        Total time: 265.89s
                               ETA: 3017.8s

################################################################################
                     [1m Learning iteration 243/3000 [0m                      

                       Computation: 91967 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.2386
                    Surrogate loss: -0.0008
             Mean action noise std: 0.5623
                     Learning rate: 0.0003
                       Mean reward: -0.39
               Mean episode length: 51.81
       Episode_Reward/keep_balance: 0.0541
     Episode_Reward/rew_lin_vel_xy: 0.0604
      Episode_Reward/rew_ang_vel_z: 0.1653
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0065
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0073
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0481
Metrics/base_velocity/error_vel_xy: 0.2682
Metrics/base_velocity/error_vel_yaw: 0.0471
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.5833
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 1.07s
                        Total time: 266.96s
                               ETA: 3016.4s

################################################################################
                     [1m Learning iteration 244/3000 [0m                      

                       Computation: 90987 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.2073
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5617
                     Learning rate: 0.0006
                       Mean reward: -0.18
               Mean episode length: 55.20
       Episode_Reward/keep_balance: 0.0541
     Episode_Reward/rew_lin_vel_xy: 0.0585
      Episode_Reward/rew_ang_vel_z: 0.1649
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0221
   Episode_Reward/pen_joint_torque: -0.0065
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0074
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0482
Metrics/base_velocity/error_vel_xy: 0.2726
Metrics/base_velocity/error_vel_yaw: 0.0471
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 75.6250
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 1.08s
                        Total time: 268.04s
                               ETA: 3015.2s

################################################################################
                     [1m Learning iteration 245/3000 [0m                      

                       Computation: 92251 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 0.2027
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5593
                     Learning rate: 0.0009
                       Mean reward: 0.26
               Mean episode length: 54.32
       Episode_Reward/keep_balance: 0.0545
     Episode_Reward/rew_lin_vel_xy: 0.0585
      Episode_Reward/rew_ang_vel_z: 0.1663
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0066
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0074
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0484
Metrics/base_velocity/error_vel_xy: 0.2763
Metrics/base_velocity/error_vel_yaw: 0.0472
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 1.07s
                        Total time: 269.11s
                               ETA: 3013.8s

################################################################################
                     [1m Learning iteration 246/3000 [0m                      

                       Computation: 90633 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.2411
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5577
                     Learning rate: 0.0019
                       Mean reward: -0.04
               Mean episode length: 54.94
       Episode_Reward/keep_balance: 0.0547
     Episode_Reward/rew_lin_vel_xy: 0.0611
      Episode_Reward/rew_ang_vel_z: 0.1674
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0066
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0076
   Episode_Reward/foot_landing_vel: -0.0077
   Episode_Reward/test_gait_reward: -0.0492
Metrics/base_velocity/error_vel_xy: 0.2745
Metrics/base_velocity/error_vel_yaw: 0.0469
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.6250
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 1.08s
                        Total time: 270.19s
                               ETA: 3012.6s

################################################################################
                     [1m Learning iteration 247/3000 [0m                      

                       Computation: 90442 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.2637
                    Surrogate loss: 0.0027
             Mean action noise std: 0.5586
                     Learning rate: 0.0003
                       Mean reward: -0.28
               Mean episode length: 52.78
       Episode_Reward/keep_balance: 0.0553
     Episode_Reward/rew_lin_vel_xy: 0.0589
      Episode_Reward/rew_ang_vel_z: 0.1693
    Episode_Reward/pen_base_height: -0.1082
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0067
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0078
   Episode_Reward/foot_landing_vel: -0.0079
   Episode_Reward/test_gait_reward: -0.0491
Metrics/base_velocity/error_vel_xy: 0.2809
Metrics/base_velocity/error_vel_yaw: 0.0477
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 73.8333
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 1.09s
                        Total time: 271.28s
                               ETA: 3011.4s

################################################################################
                     [1m Learning iteration 248/3000 [0m                      

                       Computation: 91778 steps/s (collection: 0.947s, learning 0.124s)
               Value function loss: 0.2157
                    Surrogate loss: 0.0026
             Mean action noise std: 0.5589
                     Learning rate: 0.0004
                       Mean reward: 0.31
               Mean episode length: 55.99
       Episode_Reward/keep_balance: 0.0545
     Episode_Reward/rew_lin_vel_xy: 0.0600
      Episode_Reward/rew_ang_vel_z: 0.1667
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0221
   Episode_Reward/pen_joint_torque: -0.0066
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0077
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0486
Metrics/base_velocity/error_vel_xy: 0.2724
Metrics/base_velocity/error_vel_yaw: 0.0468
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.6250
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 1.07s
                        Total time: 272.35s
                               ETA: 3010.1s

################################################################################
                     [1m Learning iteration 249/3000 [0m                      

                       Computation: 91470 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.1952
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5585
                     Learning rate: 0.0006
                       Mean reward: -0.24
               Mean episode length: 52.97
       Episode_Reward/keep_balance: 0.0559
     Episode_Reward/rew_lin_vel_xy: 0.0620
      Episode_Reward/rew_ang_vel_z: 0.1711
    Episode_Reward/pen_base_height: -0.1082
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0067
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0042
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0079
   Episode_Reward/foot_landing_vel: -0.0079
   Episode_Reward/test_gait_reward: -0.0495
Metrics/base_velocity/error_vel_xy: 0.2782
Metrics/base_velocity/error_vel_yaw: 0.0478
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 73.2083
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 1.07s
                        Total time: 273.42s
                               ETA: 3008.8s

################################################################################
                     [1m Learning iteration 250/3000 [0m                      

                       Computation: 90554 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.2096
                    Surrogate loss: 0.0015
             Mean action noise std: 0.5578
                     Learning rate: 0.0004
                       Mean reward: -0.32
               Mean episode length: 52.52
       Episode_Reward/keep_balance: 0.0554
     Episode_Reward/rew_lin_vel_xy: 0.0624
      Episode_Reward/rew_ang_vel_z: 0.1701
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0067
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0042
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0079
   Episode_Reward/foot_landing_vel: -0.0079
   Episode_Reward/test_gait_reward: -0.0489
Metrics/base_velocity/error_vel_xy: 0.2764
Metrics/base_velocity/error_vel_yaw: 0.0469
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 73.5417
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 1.09s
                        Total time: 274.51s
                               ETA: 3007.6s

################################################################################
                     [1m Learning iteration 251/3000 [0m                      

                       Computation: 90022 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.1988
                    Surrogate loss: 0.0060
             Mean action noise std: 0.5580
                     Learning rate: 0.0001
                       Mean reward: 0.28
               Mean episode length: 56.34
       Episode_Reward/keep_balance: 0.0562
     Episode_Reward/rew_lin_vel_xy: 0.0621
      Episode_Reward/rew_ang_vel_z: 0.1717
    Episode_Reward/pen_base_height: -0.1095
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0067
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0042
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0078
   Episode_Reward/foot_landing_vel: -0.0079
   Episode_Reward/test_gait_reward: -0.0500
Metrics/base_velocity/error_vel_xy: 0.2794
Metrics/base_velocity/error_vel_yaw: 0.0484
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 71.9167
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 1.09s
                        Total time: 275.60s
                               ETA: 3006.5s

################################################################################
                     [1m Learning iteration 252/3000 [0m                      

                       Computation: 90599 steps/s (collection: 0.960s, learning 0.125s)
               Value function loss: 0.1949
                    Surrogate loss: 0.0026
             Mean action noise std: 0.5584
                     Learning rate: 0.0001
                       Mean reward: 0.16
               Mean episode length: 57.23
       Episode_Reward/keep_balance: 0.0557
     Episode_Reward/rew_lin_vel_xy: 0.0602
      Episode_Reward/rew_ang_vel_z: 0.1706
    Episode_Reward/pen_base_height: -0.1083
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0068
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0042
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0081
   Episode_Reward/foot_landing_vel: -0.0080
   Episode_Reward/test_gait_reward: -0.0494
Metrics/base_velocity/error_vel_xy: 0.2776
Metrics/base_velocity/error_vel_yaw: 0.0477
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.9167
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 1.09s
                        Total time: 276.69s
                               ETA: 3005.3s

################################################################################
                     [1m Learning iteration 253/3000 [0m                      

                       Computation: 91012 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.1837
                    Surrogate loss: 0.0007
             Mean action noise std: 0.5583
                     Learning rate: 0.0001
                       Mean reward: -0.33
               Mean episode length: 54.66
       Episode_Reward/keep_balance: 0.0561
     Episode_Reward/rew_lin_vel_xy: 0.0613
      Episode_Reward/rew_ang_vel_z: 0.1725
    Episode_Reward/pen_base_height: -0.1083
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0068
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0042
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0080
   Episode_Reward/foot_landing_vel: -0.0079
   Episode_Reward/test_gait_reward: -0.0498
Metrics/base_velocity/error_vel_xy: 0.2799
Metrics/base_velocity/error_vel_yaw: 0.0473
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 70.5000
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 1.08s
                        Total time: 277.77s
                               ETA: 3004.0s

################################################################################
                     [1m Learning iteration 254/3000 [0m                      

                       Computation: 90236 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.1992
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5579
                     Learning rate: 0.0003
                       Mean reward: 0.20
               Mean episode length: 57.84
       Episode_Reward/keep_balance: 0.0566
     Episode_Reward/rew_lin_vel_xy: 0.0664
      Episode_Reward/rew_ang_vel_z: 0.1736
    Episode_Reward/pen_base_height: -0.1092
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0069
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0043
Episode_Reward/pen_flat_orientation: -0.0546
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0079
   Episode_Reward/foot_landing_vel: -0.0079
   Episode_Reward/test_gait_reward: -0.0503
Metrics/base_velocity/error_vel_xy: 0.2759
Metrics/base_velocity/error_vel_yaw: 0.0487
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 75.2083
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 1.09s
                        Total time: 278.86s
                               ETA: 3002.9s

################################################################################
                     [1m Learning iteration 255/3000 [0m                      

                       Computation: 90041 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.2094
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5573
                     Learning rate: 0.0006
                       Mean reward: -0.10
               Mean episode length: 55.69
       Episode_Reward/keep_balance: 0.0559
     Episode_Reward/rew_lin_vel_xy: 0.0585
      Episode_Reward/rew_ang_vel_z: 0.1716
    Episode_Reward/pen_base_height: -0.1090
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0069
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0043
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0081
   Episode_Reward/foot_landing_vel: -0.0079
   Episode_Reward/test_gait_reward: -0.0496
Metrics/base_velocity/error_vel_xy: 0.2831
Metrics/base_velocity/error_vel_yaw: 0.0478
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 70.9167
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 1.09s
                        Total time: 279.95s
                               ETA: 3001.8s

################################################################################
                     [1m Learning iteration 256/3000 [0m                      

                       Computation: 90112 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.2248
                    Surrogate loss: 0.0004
             Mean action noise std: 0.5573
                     Learning rate: 0.0009
                       Mean reward: 0.05
               Mean episode length: 57.19
       Episode_Reward/keep_balance: 0.0565
     Episode_Reward/rew_lin_vel_xy: 0.0623
      Episode_Reward/rew_ang_vel_z: 0.1730
    Episode_Reward/pen_base_height: -0.1101
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0071
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0043
Episode_Reward/pen_flat_orientation: -0.0553
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0082
   Episode_Reward/foot_landing_vel: -0.0081
   Episode_Reward/test_gait_reward: -0.0501
Metrics/base_velocity/error_vel_xy: 0.2812
Metrics/base_velocity/error_vel_yaw: 0.0491
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 70.9583
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 1.09s
                        Total time: 281.04s
                               ETA: 3000.7s

################################################################################
                     [1m Learning iteration 257/3000 [0m                      

                       Computation: 89533 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.2369
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5578
                     Learning rate: 0.0009
                       Mean reward: -0.13
               Mean episode length: 55.35
       Episode_Reward/keep_balance: 0.0567
     Episode_Reward/rew_lin_vel_xy: 0.0607
      Episode_Reward/rew_ang_vel_z: 0.1735
    Episode_Reward/pen_base_height: -0.1093
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0071
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0043
Episode_Reward/pen_flat_orientation: -0.0547
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0083
   Episode_Reward/foot_landing_vel: -0.0082
   Episode_Reward/test_gait_reward: -0.0503
Metrics/base_velocity/error_vel_xy: 0.2808
Metrics/base_velocity/error_vel_yaw: 0.0487
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 73.3333
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 1.10s
                        Total time: 282.14s
                               ETA: 2999.6s

################################################################################
                     [1m Learning iteration 258/3000 [0m                      

                       Computation: 89720 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 0.2537
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5568
                     Learning rate: 0.0004
                       Mean reward: 0.46
               Mean episode length: 61.46
       Episode_Reward/keep_balance: 0.0580
     Episode_Reward/rew_lin_vel_xy: 0.0664
      Episode_Reward/rew_ang_vel_z: 0.1781
    Episode_Reward/pen_base_height: -0.1095
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0073
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0044
Episode_Reward/pen_flat_orientation: -0.0555
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0085
   Episode_Reward/foot_landing_vel: -0.0082
   Episode_Reward/test_gait_reward: -0.0513
Metrics/base_velocity/error_vel_xy: 0.2865
Metrics/base_velocity/error_vel_yaw: 0.0496
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 67.4167
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 1.10s
                        Total time: 283.23s
                               ETA: 2998.5s

################################################################################
                     [1m Learning iteration 259/3000 [0m                      

                       Computation: 90990 steps/s (collection: 0.959s, learning 0.121s)
               Value function loss: 0.2453
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5560
                     Learning rate: 0.0003
                       Mean reward: -0.03
               Mean episode length: 58.89
       Episode_Reward/keep_balance: 0.0577
     Episode_Reward/rew_lin_vel_xy: 0.0665
      Episode_Reward/rew_ang_vel_z: 0.1764
    Episode_Reward/pen_base_height: -0.1098
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0073
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0044
Episode_Reward/pen_flat_orientation: -0.0555
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0087
   Episode_Reward/foot_landing_vel: -0.0083
   Episode_Reward/test_gait_reward: -0.0508
Metrics/base_velocity/error_vel_xy: 0.2844
Metrics/base_velocity/error_vel_yaw: 0.0499
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 73.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 1.08s
                        Total time: 284.31s
                               ETA: 2997.3s

################################################################################
                     [1m Learning iteration 260/3000 [0m                      

                       Computation: 90818 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.2657
                    Surrogate loss: -0.0027
             Mean action noise std: 0.5557
                     Learning rate: 0.0006
                       Mean reward: 0.28
               Mean episode length: 59.21
       Episode_Reward/keep_balance: 0.0583
     Episode_Reward/rew_lin_vel_xy: 0.0645
      Episode_Reward/rew_ang_vel_z: 0.1777
    Episode_Reward/pen_base_height: -0.1110
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0074
    Episode_Reward/pen_joint_accel: -0.0056
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0044
Episode_Reward/pen_flat_orientation: -0.0569
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0087
   Episode_Reward/foot_landing_vel: -0.0083
   Episode_Reward/test_gait_reward: -0.0512
Metrics/base_velocity/error_vel_xy: 0.2886
Metrics/base_velocity/error_vel_yaw: 0.0506
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 65.5417
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 1.08s
                        Total time: 285.40s
                               ETA: 2996.1s

################################################################################
                     [1m Learning iteration 261/3000 [0m                      

                       Computation: 92265 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 0.2463
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5559
                     Learning rate: 0.0004
                       Mean reward: 0.21
               Mean episode length: 58.84
       Episode_Reward/keep_balance: 0.0589
     Episode_Reward/rew_lin_vel_xy: 0.0723
      Episode_Reward/rew_ang_vel_z: 0.1787
    Episode_Reward/pen_base_height: -0.1119
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0075
    Episode_Reward/pen_joint_accel: -0.0057
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0045
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0090
   Episode_Reward/foot_landing_vel: -0.0085
   Episode_Reward/test_gait_reward: -0.0516
Metrics/base_velocity/error_vel_xy: 0.2844
Metrics/base_velocity/error_vel_yaw: 0.0524
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 70.0000
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 1.07s
                        Total time: 286.46s
                               ETA: 2994.7s

################################################################################
                     [1m Learning iteration 262/3000 [0m                      

                       Computation: 91159 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.2754
                    Surrogate loss: -0.0021
             Mean action noise std: 0.5561
                     Learning rate: 0.0009
                       Mean reward: 0.08
               Mean episode length: 58.63
       Episode_Reward/keep_balance: 0.0598
     Episode_Reward/rew_lin_vel_xy: 0.0682
      Episode_Reward/rew_ang_vel_z: 0.1823
    Episode_Reward/pen_base_height: -0.1111
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0076
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0045
Episode_Reward/pen_flat_orientation: -0.0567
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0092
   Episode_Reward/foot_landing_vel: -0.0086
   Episode_Reward/test_gait_reward: -0.0522
Metrics/base_velocity/error_vel_xy: 0.2916
Metrics/base_velocity/error_vel_yaw: 0.0522
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 68.5000
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 1.08s
                        Total time: 287.54s
                               ETA: 2993.5s

################################################################################
                     [1m Learning iteration 263/3000 [0m                      

                       Computation: 92286 steps/s (collection: 0.944s, learning 0.121s)
               Value function loss: 0.3095
                    Surrogate loss: -0.0024
             Mean action noise std: 0.5564
                     Learning rate: 0.0019
                       Mean reward: -0.04
               Mean episode length: 58.94
       Episode_Reward/keep_balance: 0.0597
     Episode_Reward/rew_lin_vel_xy: 0.0699
      Episode_Reward/rew_ang_vel_z: 0.1815
    Episode_Reward/pen_base_height: -0.1106
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0077
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0045
Episode_Reward/pen_flat_orientation: -0.0573
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0093
   Episode_Reward/foot_landing_vel: -0.0086
   Episode_Reward/test_gait_reward: -0.0524
Metrics/base_velocity/error_vel_xy: 0.2890
Metrics/base_velocity/error_vel_yaw: 0.0523
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 66.7500
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 1.07s
                        Total time: 288.60s
                               ETA: 2992.1s

################################################################################
                     [1m Learning iteration 264/3000 [0m                      

                       Computation: 92914 steps/s (collection: 0.937s, learning 0.121s)
               Value function loss: 0.3384
                    Surrogate loss: -0.0028
             Mean action noise std: 0.5571
                     Learning rate: 0.0029
                       Mean reward: 0.24
               Mean episode length: 58.34
       Episode_Reward/keep_balance: 0.0604
     Episode_Reward/rew_lin_vel_xy: 0.0718
      Episode_Reward/rew_ang_vel_z: 0.1831
    Episode_Reward/pen_base_height: -0.1122
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0077
    Episode_Reward/pen_joint_accel: -0.0059
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0045
Episode_Reward/pen_flat_orientation: -0.0580
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0093
   Episode_Reward/foot_landing_vel: -0.0086
   Episode_Reward/test_gait_reward: -0.0530
Metrics/base_velocity/error_vel_xy: 0.2924
Metrics/base_velocity/error_vel_yaw: 0.0536
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 68.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 1.06s
                        Total time: 289.66s
                               ETA: 2990.6s

################################################################################
                     [1m Learning iteration 265/3000 [0m                      

                       Computation: 90287 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.3953
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5570
                     Learning rate: 0.0013
                       Mean reward: 0.17
               Mean episode length: 59.82
       Episode_Reward/keep_balance: 0.0606
     Episode_Reward/rew_lin_vel_xy: 0.0700
      Episode_Reward/rew_ang_vel_z: 0.1836
    Episode_Reward/pen_base_height: -0.1117
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0079
    Episode_Reward/pen_joint_accel: -0.0058
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0046
Episode_Reward/pen_flat_orientation: -0.0582
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0093
   Episode_Reward/foot_landing_vel: -0.0085
   Episode_Reward/test_gait_reward: -0.0533
Metrics/base_velocity/error_vel_xy: 0.2905
Metrics/base_velocity/error_vel_yaw: 0.0536
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 66.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 1.09s
                        Total time: 290.75s
                               ETA: 2989.5s

################################################################################
                     [1m Learning iteration 266/3000 [0m                      

                       Computation: 91521 steps/s (collection: 0.950s, learning 0.124s)
               Value function loss: 0.3301
                    Surrogate loss: 0.0011
             Mean action noise std: 0.5561
                     Learning rate: 0.0009
                       Mean reward: 0.13
               Mean episode length: 61.43
       Episode_Reward/keep_balance: 0.0605
     Episode_Reward/rew_lin_vel_xy: 0.0692
      Episode_Reward/rew_ang_vel_z: 0.1831
    Episode_Reward/pen_base_height: -0.1125
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0078
    Episode_Reward/pen_joint_accel: -0.0058
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0046
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0096
   Episode_Reward/foot_landing_vel: -0.0086
   Episode_Reward/test_gait_reward: -0.0532
Metrics/base_velocity/error_vel_xy: 0.2929
Metrics/base_velocity/error_vel_yaw: 0.0538
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 66.7917
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 1.07s
                        Total time: 291.82s
                               ETA: 2988.2s

################################################################################
                     [1m Learning iteration 267/3000 [0m                      

                       Computation: 90415 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.2703
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5560
                     Learning rate: 0.0009
                       Mean reward: 0.00
               Mean episode length: 60.57
       Episode_Reward/keep_balance: 0.0614
     Episode_Reward/rew_lin_vel_xy: 0.0733
      Episode_Reward/rew_ang_vel_z: 0.1867
    Episode_Reward/pen_base_height: -0.1124
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0080
    Episode_Reward/pen_joint_accel: -0.0058
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0047
Episode_Reward/pen_flat_orientation: -0.0589
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0096
   Episode_Reward/foot_landing_vel: -0.0088
   Episode_Reward/test_gait_reward: -0.0537
Metrics/base_velocity/error_vel_xy: 0.2971
Metrics/base_velocity/error_vel_yaw: 0.0540
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 66.3750
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 1.09s
                        Total time: 292.91s
                               ETA: 2987.0s

################################################################################
                     [1m Learning iteration 268/3000 [0m                      

                       Computation: 90886 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.2813
                    Surrogate loss: 0.0000
             Mean action noise std: 0.5563
                     Learning rate: 0.0009
                       Mean reward: 0.55
               Mean episode length: 64.22
       Episode_Reward/keep_balance: 0.0622
     Episode_Reward/rew_lin_vel_xy: 0.0707
      Episode_Reward/rew_ang_vel_z: 0.1886
    Episode_Reward/pen_base_height: -0.1133
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0083
    Episode_Reward/pen_joint_accel: -0.0061
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0047
Episode_Reward/pen_flat_orientation: -0.0599
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0099
   Episode_Reward/foot_landing_vel: -0.0090
   Episode_Reward/test_gait_reward: -0.0540
Metrics/base_velocity/error_vel_xy: 0.3001
Metrics/base_velocity/error_vel_yaw: 0.0550
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 64.8750
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 1.08s
                        Total time: 293.99s
                               ETA: 2985.8s

################################################################################
                     [1m Learning iteration 269/3000 [0m                      

                       Computation: 90597 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.2688
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5568
                     Learning rate: 0.0013
                       Mean reward: 0.25
               Mean episode length: 59.14
       Episode_Reward/keep_balance: 0.0620
     Episode_Reward/rew_lin_vel_xy: 0.0760
      Episode_Reward/rew_ang_vel_z: 0.1883
    Episode_Reward/pen_base_height: -0.1142
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0082
    Episode_Reward/pen_joint_accel: -0.0059
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0047
Episode_Reward/pen_flat_orientation: -0.0603
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0098
   Episode_Reward/foot_landing_vel: -0.0091
   Episode_Reward/test_gait_reward: -0.0542
Metrics/base_velocity/error_vel_xy: 0.2959
Metrics/base_velocity/error_vel_yaw: 0.0547
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 65.9167
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 1.09s
                        Total time: 295.08s
                               ETA: 2984.7s

################################################################################
                     [1m Learning iteration 270/3000 [0m                      

                       Computation: 89412 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.3084
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5563
                     Learning rate: 0.0009
                       Mean reward: 0.54
               Mean episode length: 62.38
       Episode_Reward/keep_balance: 0.0628
     Episode_Reward/rew_lin_vel_xy: 0.0748
      Episode_Reward/rew_ang_vel_z: 0.1906
    Episode_Reward/pen_base_height: -0.1147
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0085
    Episode_Reward/pen_joint_accel: -0.0061
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0048
Episode_Reward/pen_flat_orientation: -0.0602
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0100
   Episode_Reward/foot_landing_vel: -0.0092
   Episode_Reward/test_gait_reward: -0.0553
Metrics/base_velocity/error_vel_xy: 0.2998
Metrics/base_velocity/error_vel_yaw: 0.0562
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 65.4167
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 1.10s
                        Total time: 296.18s
                               ETA: 2983.6s

################################################################################
                     [1m Learning iteration 271/3000 [0m                      

                       Computation: 91170 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.2562
                    Surrogate loss: -0.0000
             Mean action noise std: 0.5563
                     Learning rate: 0.0004
                       Mean reward: 0.16
               Mean episode length: 62.37
       Episode_Reward/keep_balance: 0.0628
     Episode_Reward/rew_lin_vel_xy: 0.0767
      Episode_Reward/rew_ang_vel_z: 0.1908
    Episode_Reward/pen_base_height: -0.1141
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0084
    Episode_Reward/pen_joint_accel: -0.0059
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0048
Episode_Reward/pen_flat_orientation: -0.0600
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0096
   Episode_Reward/foot_landing_vel: -0.0091
   Episode_Reward/test_gait_reward: -0.0544
Metrics/base_velocity/error_vel_xy: 0.3008
Metrics/base_velocity/error_vel_yaw: 0.0553
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 65.7083
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 1.08s
                        Total time: 297.26s
                               ETA: 2982.4s

################################################################################
                     [1m Learning iteration 272/3000 [0m                      

                       Computation: 91402 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.2545
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5569
                     Learning rate: 0.0009
                       Mean reward: 0.51
               Mean episode length: 62.16
       Episode_Reward/keep_balance: 0.0624
     Episode_Reward/rew_lin_vel_xy: 0.0720
      Episode_Reward/rew_ang_vel_z: 0.1901
    Episode_Reward/pen_base_height: -0.1147
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0084
    Episode_Reward/pen_joint_accel: -0.0061
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0047
Episode_Reward/pen_flat_orientation: -0.0607
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0098
   Episode_Reward/foot_landing_vel: -0.0090
   Episode_Reward/test_gait_reward: -0.0549
Metrics/base_velocity/error_vel_xy: 0.2997
Metrics/base_velocity/error_vel_yaw: 0.0548
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 64.7500
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 1.08s
                        Total time: 298.33s
                               ETA: 2981.1s

################################################################################
                     [1m Learning iteration 273/3000 [0m                      

                       Computation: 91022 steps/s (collection: 0.954s, learning 0.126s)
               Value function loss: 0.2962
                    Surrogate loss: 0.0003
             Mean action noise std: 0.5573
                     Learning rate: 0.0006
                       Mean reward: 0.56
               Mean episode length: 63.41
       Episode_Reward/keep_balance: 0.0623
     Episode_Reward/rew_lin_vel_xy: 0.0704
      Episode_Reward/rew_ang_vel_z: 0.1887
    Episode_Reward/pen_base_height: -0.1142
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0083
    Episode_Reward/pen_joint_accel: -0.0061
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0048
Episode_Reward/pen_flat_orientation: -0.0598
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0099
   Episode_Reward/foot_landing_vel: -0.0090
   Episode_Reward/test_gait_reward: -0.0545
Metrics/base_velocity/error_vel_xy: 0.3031
Metrics/base_velocity/error_vel_yaw: 0.0553
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 64.2500
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 1.08s
                        Total time: 299.41s
                               ETA: 2979.9s

################################################################################
                     [1m Learning iteration 274/3000 [0m                      

                       Computation: 90058 steps/s (collection: 0.966s, learning 0.126s)
               Value function loss: 0.2897
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5580
                     Learning rate: 0.0009
                       Mean reward: 0.33
               Mean episode length: 63.83
       Episode_Reward/keep_balance: 0.0631
     Episode_Reward/rew_lin_vel_xy: 0.0785
      Episode_Reward/rew_ang_vel_z: 0.1913
    Episode_Reward/pen_base_height: -0.1151
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0084
    Episode_Reward/pen_joint_accel: -0.0062
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0048
Episode_Reward/pen_flat_orientation: -0.0615
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0097
   Episode_Reward/foot_landing_vel: -0.0091
   Episode_Reward/test_gait_reward: -0.0555
Metrics/base_velocity/error_vel_xy: 0.2972
Metrics/base_velocity/error_vel_yaw: 0.0558
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 64.5417
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 1.09s
                        Total time: 300.50s
                               ETA: 2978.8s

################################################################################
                     [1m Learning iteration 275/3000 [0m                      

                       Computation: 89826 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 0.2827
                    Surrogate loss: 0.0048
             Mean action noise std: 0.5585
                     Learning rate: 0.0002
                       Mean reward: 0.39
               Mean episode length: 63.11
       Episode_Reward/keep_balance: 0.0644
     Episode_Reward/rew_lin_vel_xy: 0.0772
      Episode_Reward/rew_ang_vel_z: 0.1957
    Episode_Reward/pen_base_height: -0.1155
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0086
    Episode_Reward/pen_joint_accel: -0.0060
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0049
Episode_Reward/pen_flat_orientation: -0.0617
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0098
   Episode_Reward/foot_landing_vel: -0.0092
   Episode_Reward/test_gait_reward: -0.0567
Metrics/base_velocity/error_vel_xy: 0.3075
Metrics/base_velocity/error_vel_yaw: 0.0568
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 62.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 1.09s
                        Total time: 301.60s
                               ETA: 2977.7s

################################################################################
                     [1m Learning iteration 276/3000 [0m                      

                       Computation: 90248 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.2536
                    Surrogate loss: -0.0024
             Mean action noise std: 0.5587
                     Learning rate: 0.0004
                       Mean reward: 0.46
               Mean episode length: 66.94
       Episode_Reward/keep_balance: 0.0645
     Episode_Reward/rew_lin_vel_xy: 0.0820
      Episode_Reward/rew_ang_vel_z: 0.1954
    Episode_Reward/pen_base_height: -0.1143
      Episode_Reward/pen_lin_vel_z: -0.0125
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0087
    Episode_Reward/pen_joint_accel: -0.0063
    Episode_Reward/pen_action_rate: -0.0022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0050
Episode_Reward/pen_flat_orientation: -0.0608
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0104
   Episode_Reward/foot_landing_vel: -0.0093
   Episode_Reward/test_gait_reward: -0.0566
Metrics/base_velocity/error_vel_xy: 0.3027
Metrics/base_velocity/error_vel_yaw: 0.0573
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 61.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 1.09s
                        Total time: 302.69s
                               ETA: 2976.6s

################################################################################
                     [1m Learning iteration 277/3000 [0m                      

                       Computation: 90162 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.2633
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5587
                     Learning rate: 0.0009
                       Mean reward: 0.40
               Mean episode length: 62.27
       Episode_Reward/keep_balance: 0.0647
     Episode_Reward/rew_lin_vel_xy: 0.0817
      Episode_Reward/rew_ang_vel_z: 0.1964
    Episode_Reward/pen_base_height: -0.1153
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0087
    Episode_Reward/pen_joint_accel: -0.0063
    Episode_Reward/pen_action_rate: -0.0022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0050
Episode_Reward/pen_flat_orientation: -0.0619
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0103
   Episode_Reward/foot_landing_vel: -0.0095
   Episode_Reward/test_gait_reward: -0.0565
Metrics/base_velocity/error_vel_xy: 0.2998
Metrics/base_velocity/error_vel_yaw: 0.0574
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 62.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 1.09s
                        Total time: 303.78s
                               ETA: 2975.5s

################################################################################
                     [1m Learning iteration 278/3000 [0m                      

                       Computation: 91669 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.3000
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5596
                     Learning rate: 0.0013
                       Mean reward: 0.49
               Mean episode length: 66.97
       Episode_Reward/keep_balance: 0.0660
     Episode_Reward/rew_lin_vel_xy: 0.0831
      Episode_Reward/rew_ang_vel_z: 0.1998
    Episode_Reward/pen_base_height: -0.1161
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0089
    Episode_Reward/pen_joint_accel: -0.0065
    Episode_Reward/pen_action_rate: -0.0022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0024
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0051
Episode_Reward/pen_flat_orientation: -0.0627
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0104
   Episode_Reward/foot_landing_vel: -0.0097
   Episode_Reward/test_gait_reward: -0.0574
Metrics/base_velocity/error_vel_xy: 0.3108
Metrics/base_velocity/error_vel_yaw: 0.0589
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 60.6667
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 1.07s
                        Total time: 304.85s
                               ETA: 2974.2s

################################################################################
                     [1m Learning iteration 279/3000 [0m                      

                       Computation: 91185 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.3254
                    Surrogate loss: 0.0010
             Mean action noise std: 0.5606
                     Learning rate: 0.0006
                       Mean reward: 0.69
               Mean episode length: 67.40
       Episode_Reward/keep_balance: 0.0664
     Episode_Reward/rew_lin_vel_xy: 0.0819
      Episode_Reward/rew_ang_vel_z: 0.2004
    Episode_Reward/pen_base_height: -0.1161
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0089
    Episode_Reward/pen_joint_accel: -0.0063
    Episode_Reward/pen_action_rate: -0.0022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0052
Episode_Reward/pen_flat_orientation: -0.0626
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0103
   Episode_Reward/foot_landing_vel: -0.0097
   Episode_Reward/test_gait_reward: -0.0583
Metrics/base_velocity/error_vel_xy: 0.3115
Metrics/base_velocity/error_vel_yaw: 0.0597
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 61.7500
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 1.08s
                        Total time: 305.93s
                               ETA: 2973.0s

################################################################################
                     [1m Learning iteration 280/3000 [0m                      

                       Computation: 90591 steps/s (collection: 0.960s, learning 0.125s)
               Value function loss: 0.3455
                    Surrogate loss: -0.0029
             Mean action noise std: 0.5601
                     Learning rate: 0.0009
                       Mean reward: 0.66
               Mean episode length: 71.39
       Episode_Reward/keep_balance: 0.0665
     Episode_Reward/rew_lin_vel_xy: 0.0809
      Episode_Reward/rew_ang_vel_z: 0.2009
    Episode_Reward/pen_base_height: -0.1163
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0091
    Episode_Reward/pen_joint_accel: -0.0066
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0024
   Episode_Reward/pen_joint_powers: -0.0035
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0052
Episode_Reward/pen_flat_orientation: -0.0623
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0109
   Episode_Reward/foot_landing_vel: -0.0098
   Episode_Reward/test_gait_reward: -0.0585
Metrics/base_velocity/error_vel_xy: 0.3122
Metrics/base_velocity/error_vel_yaw: 0.0591
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 60.8333
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 1.09s
                        Total time: 307.01s
                               ETA: 2971.8s

################################################################################
                     [1m Learning iteration 281/3000 [0m                      

                       Computation: 91239 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.3333
                    Surrogate loss: 0.0012
             Mean action noise std: 0.5594
                     Learning rate: 0.0002
                       Mean reward: 1.20
               Mean episode length: 73.81
       Episode_Reward/keep_balance: 0.0675
     Episode_Reward/rew_lin_vel_xy: 0.0842
      Episode_Reward/rew_ang_vel_z: 0.2036
    Episode_Reward/pen_base_height: -0.1169
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0092
    Episode_Reward/pen_joint_accel: -0.0066
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0024
   Episode_Reward/pen_joint_powers: -0.0035
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0053
Episode_Reward/pen_flat_orientation: -0.0633
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0108
   Episode_Reward/foot_landing_vel: -0.0098
   Episode_Reward/test_gait_reward: -0.0591
Metrics/base_velocity/error_vel_xy: 0.3104
Metrics/base_velocity/error_vel_yaw: 0.0606
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 60.0833
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 1.08s
                        Total time: 308.09s
                               ETA: 2970.6s

################################################################################
                     [1m Learning iteration 282/3000 [0m                      

                       Computation: 90328 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.3247
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5594
                     Learning rate: 0.0002
                       Mean reward: 0.71
               Mean episode length: 67.01
       Episode_Reward/keep_balance: 0.0672
     Episode_Reward/rew_lin_vel_xy: 0.0839
      Episode_Reward/rew_ang_vel_z: 0.2024
    Episode_Reward/pen_base_height: -0.1166
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0092
    Episode_Reward/pen_joint_accel: -0.0065
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0024
   Episode_Reward/pen_joint_powers: -0.0036
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0053
Episode_Reward/pen_flat_orientation: -0.0633
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0109
   Episode_Reward/foot_landing_vel: -0.0099
   Episode_Reward/test_gait_reward: -0.0585
Metrics/base_velocity/error_vel_xy: 0.3115
Metrics/base_velocity/error_vel_yaw: 0.0608
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 58.1250
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 1.09s
                        Total time: 309.18s
                               ETA: 2969.4s

################################################################################
                     [1m Learning iteration 283/3000 [0m                      

                       Computation: 91078 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.3345
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5595
                     Learning rate: 0.0004
                       Mean reward: 0.20
               Mean episode length: 66.19
       Episode_Reward/keep_balance: 0.0681
     Episode_Reward/rew_lin_vel_xy: 0.0841
      Episode_Reward/rew_ang_vel_z: 0.2063
    Episode_Reward/pen_base_height: -0.1179
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0094
    Episode_Reward/pen_joint_accel: -0.0065
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0024
   Episode_Reward/pen_joint_powers: -0.0036
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0053
Episode_Reward/pen_flat_orientation: -0.0656
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0109
   Episode_Reward/foot_landing_vel: -0.0101
   Episode_Reward/test_gait_reward: -0.0589
Metrics/base_velocity/error_vel_xy: 0.3159
Metrics/base_velocity/error_vel_yaw: 0.0600
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 56.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 1.08s
                        Total time: 310.26s
                               ETA: 2968.2s

################################################################################
                     [1m Learning iteration 284/3000 [0m                      

                       Computation: 90523 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.3523
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5593
                     Learning rate: 0.0009
                       Mean reward: 0.82
               Mean episode length: 69.15
       Episode_Reward/keep_balance: 0.0693
     Episode_Reward/rew_lin_vel_xy: 0.0882
      Episode_Reward/rew_ang_vel_z: 0.2091
    Episode_Reward/pen_base_height: -0.1192
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0095
    Episode_Reward/pen_joint_accel: -0.0068
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0025
   Episode_Reward/pen_joint_powers: -0.0036
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0054
Episode_Reward/pen_flat_orientation: -0.0673
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0112
   Episode_Reward/foot_landing_vel: -0.0100
   Episode_Reward/test_gait_reward: -0.0604
Metrics/base_velocity/error_vel_xy: 0.3183
Metrics/base_velocity/error_vel_yaw: 0.0624
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 59.3750
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 1.09s
                        Total time: 311.34s
                               ETA: 2967.1s

################################################################################
                     [1m Learning iteration 285/3000 [0m                      

                       Computation: 89829 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.3749
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5590
                     Learning rate: 0.0013
                       Mean reward: 0.99
               Mean episode length: 74.09
       Episode_Reward/keep_balance: 0.0710
     Episode_Reward/rew_lin_vel_xy: 0.0923
      Episode_Reward/rew_ang_vel_z: 0.2137
    Episode_Reward/pen_base_height: -0.1202
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0099
    Episode_Reward/pen_joint_accel: -0.0068
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0025
   Episode_Reward/pen_joint_powers: -0.0037
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0056
Episode_Reward/pen_flat_orientation: -0.0678
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0115
   Episode_Reward/foot_landing_vel: -0.0104
   Episode_Reward/test_gait_reward: -0.0615
Metrics/base_velocity/error_vel_xy: 0.3265
Metrics/base_velocity/error_vel_yaw: 0.0642
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 56.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 1.09s
                        Total time: 312.44s
                               ETA: 2966.0s

################################################################################
                     [1m Learning iteration 286/3000 [0m                      

                       Computation: 88685 steps/s (collection: 0.985s, learning 0.124s)
               Value function loss: 0.4241
                    Surrogate loss: -0.0002
             Mean action noise std: 0.5590
                     Learning rate: 0.0013
                       Mean reward: -0.05
               Mean episode length: 66.09
       Episode_Reward/keep_balance: 0.0706
     Episode_Reward/rew_lin_vel_xy: 0.0869
      Episode_Reward/rew_ang_vel_z: 0.2129
    Episode_Reward/pen_base_height: -0.1192
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0101
    Episode_Reward/pen_joint_accel: -0.0066
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0026
   Episode_Reward/pen_joint_powers: -0.0038
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0056
Episode_Reward/pen_flat_orientation: -0.0665
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0121
   Episode_Reward/foot_landing_vel: -0.0106
   Episode_Reward/test_gait_reward: -0.0611
Metrics/base_velocity/error_vel_xy: 0.3239
Metrics/base_velocity/error_vel_yaw: 0.0633
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 58.1250
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 1.11s
                        Total time: 313.55s
                               ETA: 2965.0s

################################################################################
                     [1m Learning iteration 287/3000 [0m                      

                       Computation: 90125 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.4335
                    Surrogate loss: 0.0020
             Mean action noise std: 0.5588
                     Learning rate: 0.0006
                       Mean reward: 0.50
               Mean episode length: 70.23
       Episode_Reward/keep_balance: 0.0707
     Episode_Reward/rew_lin_vel_xy: 0.0844
      Episode_Reward/rew_ang_vel_z: 0.2127
    Episode_Reward/pen_base_height: -0.1198
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0099
    Episode_Reward/pen_joint_accel: -0.0069
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0026
   Episode_Reward/pen_joint_powers: -0.0038
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0056
Episode_Reward/pen_flat_orientation: -0.0678
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0118
   Episode_Reward/foot_landing_vel: -0.0106
   Episode_Reward/test_gait_reward: -0.0616
Metrics/base_velocity/error_vel_xy: 0.3289
Metrics/base_velocity/error_vel_yaw: 0.0640
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 57.0000
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 1.09s
                        Total time: 314.64s
                               ETA: 2963.9s

################################################################################
                     [1m Learning iteration 288/3000 [0m                      

                       Computation: 91538 steps/s (collection: 0.950s, learning 0.124s)
               Value function loss: 0.4574
                    Surrogate loss: 0.0004
             Mean action noise std: 0.5587
                     Learning rate: 0.0009
                       Mean reward: 0.51
               Mean episode length: 74.12
       Episode_Reward/keep_balance: 0.0713
     Episode_Reward/rew_lin_vel_xy: 0.0943
      Episode_Reward/rew_ang_vel_z: 0.2147
    Episode_Reward/pen_base_height: -0.1207
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0102
    Episode_Reward/pen_joint_accel: -0.0067
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0026
   Episode_Reward/pen_joint_powers: -0.0038
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0056
Episode_Reward/pen_flat_orientation: -0.0678
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0120
   Episode_Reward/foot_landing_vel: -0.0107
   Episode_Reward/test_gait_reward: -0.0623
Metrics/base_velocity/error_vel_xy: 0.3236
Metrics/base_velocity/error_vel_yaw: 0.0640
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 52.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 1.07s
                        Total time: 315.71s
                               ETA: 2962.7s

################################################################################
                     [1m Learning iteration 289/3000 [0m                      

                       Computation: 90680 steps/s (collection: 0.955s, learning 0.129s)
               Value function loss: 0.5484
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5592
                     Learning rate: 0.0013
                       Mean reward: 0.41
               Mean episode length: 68.85
       Episode_Reward/keep_balance: 0.0719
     Episode_Reward/rew_lin_vel_xy: 0.0911
      Episode_Reward/rew_ang_vel_z: 0.2163
    Episode_Reward/pen_base_height: -0.1208
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0231
   Episode_Reward/pen_joint_torque: -0.0103
    Episode_Reward/pen_joint_accel: -0.0071
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0027
   Episode_Reward/pen_joint_powers: -0.0039
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0057
Episode_Reward/pen_flat_orientation: -0.0690
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0127
   Episode_Reward/foot_landing_vel: -0.0109
   Episode_Reward/test_gait_reward: -0.0624
Metrics/base_velocity/error_vel_xy: 0.3298
Metrics/base_velocity/error_vel_yaw: 0.0649
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 53.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 1.08s
                        Total time: 316.80s
                               ETA: 2961.5s

################################################################################
                     [1m Learning iteration 290/3000 [0m                      

                       Computation: 92298 steps/s (collection: 0.940s, learning 0.125s)
               Value function loss: 0.5228
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5585
                     Learning rate: 0.0019
                       Mean reward: 0.63
               Mean episode length: 73.79
       Episode_Reward/keep_balance: 0.0748
     Episode_Reward/rew_lin_vel_xy: 0.1072
      Episode_Reward/rew_ang_vel_z: 0.2241
    Episode_Reward/pen_base_height: -0.1249
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0106
    Episode_Reward/pen_joint_accel: -0.0074
    Episode_Reward/pen_action_rate: -0.0026
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0027
   Episode_Reward/pen_joint_powers: -0.0040
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0060
Episode_Reward/pen_flat_orientation: -0.0733
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.0127
   Episode_Reward/foot_landing_vel: -0.0111
   Episode_Reward/test_gait_reward: -0.0651
Metrics/base_velocity/error_vel_xy: 0.3260
Metrics/base_velocity/error_vel_yaw: 0.0687
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 56.0417
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 1.07s
                        Total time: 317.86s
                               ETA: 2960.1s

################################################################################
                     [1m Learning iteration 291/3000 [0m                      

                       Computation: 90656 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.4837
                    Surrogate loss: 0.0067
             Mean action noise std: 0.5586
                     Learning rate: 0.0004
                       Mean reward: 0.94
               Mean episode length: 72.65
       Episode_Reward/keep_balance: 0.0768
     Episode_Reward/rew_lin_vel_xy: 0.1056
      Episode_Reward/rew_ang_vel_z: 0.2295
    Episode_Reward/pen_base_height: -0.1270
      Episode_Reward/pen_lin_vel_z: -0.0131
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0112
    Episode_Reward/pen_joint_accel: -0.0075
    Episode_Reward/pen_action_rate: -0.0027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0028
   Episode_Reward/pen_joint_powers: -0.0042
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0061
Episode_Reward/pen_flat_orientation: -0.0760
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0132
   Episode_Reward/foot_landing_vel: -0.0116
   Episode_Reward/test_gait_reward: -0.0667
Metrics/base_velocity/error_vel_xy: 0.3363
Metrics/base_velocity/error_vel_yaw: 0.0715
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 56.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 1.08s
                        Total time: 318.95s
                               ETA: 2959.0s

################################################################################
                     [1m Learning iteration 292/3000 [0m                      

                       Computation: 90473 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.3984
                    Surrogate loss: 0.0017
             Mean action noise std: 0.5582
                     Learning rate: 0.0003
                       Mean reward: 0.91
               Mean episode length: 76.52
       Episode_Reward/keep_balance: 0.0742
     Episode_Reward/rew_lin_vel_xy: 0.0985
      Episode_Reward/rew_ang_vel_z: 0.2225
    Episode_Reward/pen_base_height: -0.1243
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0107
    Episode_Reward/pen_joint_accel: -0.0072
    Episode_Reward/pen_action_rate: -0.0026
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0027
   Episode_Reward/pen_joint_powers: -0.0040
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0059
Episode_Reward/pen_flat_orientation: -0.0720
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0123
   Episode_Reward/foot_landing_vel: -0.0110
   Episode_Reward/test_gait_reward: -0.0652
Metrics/base_velocity/error_vel_xy: 0.3347
Metrics/base_velocity/error_vel_yaw: 0.0681
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 51.3333
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 1.09s
                        Total time: 320.03s
                               ETA: 2957.8s

################################################################################
                     [1m Learning iteration 293/3000 [0m                      

                       Computation: 89725 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.3848
                    Surrogate loss: 0.0002
             Mean action noise std: 0.5582
                     Learning rate: 0.0004
                       Mean reward: 0.83
               Mean episode length: 74.86
       Episode_Reward/keep_balance: 0.0750
     Episode_Reward/rew_lin_vel_xy: 0.0909
      Episode_Reward/rew_ang_vel_z: 0.2244
    Episode_Reward/pen_base_height: -0.1241
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0108
    Episode_Reward/pen_joint_accel: -0.0069
    Episode_Reward/pen_action_rate: -0.0026
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0027
   Episode_Reward/pen_joint_powers: -0.0040
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0059
Episode_Reward/pen_flat_orientation: -0.0718
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0125
   Episode_Reward/foot_landing_vel: -0.0113
   Episode_Reward/test_gait_reward: -0.0658
Metrics/base_velocity/error_vel_xy: 0.3396
Metrics/base_velocity/error_vel_yaw: 0.0691
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 52.0417
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 1.10s
                        Total time: 321.13s
                               ETA: 2956.8s

################################################################################
                     [1m Learning iteration 294/3000 [0m                      

                       Computation: 91708 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.3586
                    Surrogate loss: -0.0019
             Mean action noise std: 0.5584
                     Learning rate: 0.0006
                       Mean reward: 0.92
               Mean episode length: 81.14
       Episode_Reward/keep_balance: 0.0757
     Episode_Reward/rew_lin_vel_xy: 0.0992
      Episode_Reward/rew_ang_vel_z: 0.2254
    Episode_Reward/pen_base_height: -0.1241
      Episode_Reward/pen_lin_vel_z: -0.0133
     Episode_Reward/pen_ang_vel_xy: -0.0235
   Episode_Reward/pen_joint_torque: -0.0113
    Episode_Reward/pen_joint_accel: -0.0074
    Episode_Reward/pen_action_rate: -0.0027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0028
   Episode_Reward/pen_joint_powers: -0.0042
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0060
Episode_Reward/pen_flat_orientation: -0.0720
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0139
   Episode_Reward/foot_landing_vel: -0.0117
   Episode_Reward/test_gait_reward: -0.0661
Metrics/base_velocity/error_vel_xy: 0.3381
Metrics/base_velocity/error_vel_yaw: 0.0710
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 51.5417
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 1.07s
                        Total time: 322.20s
                               ETA: 2955.5s

################################################################################
                     [1m Learning iteration 295/3000 [0m                      

                       Computation: 91034 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.3839
                    Surrogate loss: 0.0014
             Mean action noise std: 0.5590
                     Learning rate: 0.0004
                       Mean reward: 1.45
               Mean episode length: 81.73
       Episode_Reward/keep_balance: 0.0772
     Episode_Reward/rew_lin_vel_xy: 0.0971
      Episode_Reward/rew_ang_vel_z: 0.2329
    Episode_Reward/pen_base_height: -0.1227
      Episode_Reward/pen_lin_vel_z: -0.0133
     Episode_Reward/pen_ang_vel_xy: -0.0235
   Episode_Reward/pen_joint_torque: -0.0113
    Episode_Reward/pen_joint_accel: -0.0073
    Episode_Reward/pen_action_rate: -0.0027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0028
   Episode_Reward/pen_joint_powers: -0.0042
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0061
Episode_Reward/pen_flat_orientation: -0.0692
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0135
   Episode_Reward/foot_landing_vel: -0.0115
   Episode_Reward/test_gait_reward: -0.0671
Metrics/base_velocity/error_vel_xy: 0.3476
Metrics/base_velocity/error_vel_yaw: 0.0699
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 57.2500
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 1.08s
                        Total time: 323.28s
                               ETA: 2954.3s

################################################################################
                     [1m Learning iteration 296/3000 [0m                      

                       Computation: 91003 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.4147
                    Surrogate loss: -0.0019
             Mean action noise std: 0.5594
                     Learning rate: 0.0006
                       Mean reward: 1.08
               Mean episode length: 76.99
       Episode_Reward/keep_balance: 0.0761
     Episode_Reward/rew_lin_vel_xy: 0.1003
      Episode_Reward/rew_ang_vel_z: 0.2292
    Episode_Reward/pen_base_height: -0.1213
      Episode_Reward/pen_lin_vel_z: -0.0133
     Episode_Reward/pen_ang_vel_xy: -0.0236
   Episode_Reward/pen_joint_torque: -0.0112
    Episode_Reward/pen_joint_accel: -0.0075
    Episode_Reward/pen_action_rate: -0.0027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0028
   Episode_Reward/pen_joint_powers: -0.0042
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0060
Episode_Reward/pen_flat_orientation: -0.0687
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0137
   Episode_Reward/foot_landing_vel: -0.0114
   Episode_Reward/test_gait_reward: -0.0667
Metrics/base_velocity/error_vel_xy: 0.3453
Metrics/base_velocity/error_vel_yaw: 0.0690
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 53.5000
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 1.08s
                        Total time: 324.36s
                               ETA: 2953.1s

################################################################################
                     [1m Learning iteration 297/3000 [0m                      

                       Computation: 90051 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.4013
                    Surrogate loss: -0.0035
             Mean action noise std: 0.5593
                     Learning rate: 0.0013
                       Mean reward: 0.86
               Mean episode length: 78.68
       Episode_Reward/keep_balance: 0.0770
     Episode_Reward/rew_lin_vel_xy: 0.0972
      Episode_Reward/rew_ang_vel_z: 0.2308
    Episode_Reward/pen_base_height: -0.1230
      Episode_Reward/pen_lin_vel_z: -0.0134
     Episode_Reward/pen_ang_vel_xy: -0.0234
   Episode_Reward/pen_joint_torque: -0.0112
    Episode_Reward/pen_joint_accel: -0.0074
    Episode_Reward/pen_action_rate: -0.0027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0029
   Episode_Reward/pen_joint_powers: -0.0042
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0061
Episode_Reward/pen_flat_orientation: -0.0697
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0137
   Episode_Reward/foot_landing_vel: -0.0116
   Episode_Reward/test_gait_reward: -0.0675
Metrics/base_velocity/error_vel_xy: 0.3501
Metrics/base_velocity/error_vel_yaw: 0.0708
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 51.7083
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 1.09s
                        Total time: 325.45s
                               ETA: 2952.0s

################################################################################
                     [1m Learning iteration 298/3000 [0m                      

                       Computation: 90076 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.6114
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5588
                     Learning rate: 0.0029
                       Mean reward: 0.62
               Mean episode length: 74.11
       Episode_Reward/keep_balance: 0.0766
     Episode_Reward/rew_lin_vel_xy: 0.0982
      Episode_Reward/rew_ang_vel_z: 0.2305
    Episode_Reward/pen_base_height: -0.1225
      Episode_Reward/pen_lin_vel_z: -0.0135
     Episode_Reward/pen_ang_vel_xy: -0.0235
   Episode_Reward/pen_joint_torque: -0.0114
    Episode_Reward/pen_joint_accel: -0.0072
    Episode_Reward/pen_action_rate: -0.0027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0029
   Episode_Reward/pen_joint_powers: -0.0043
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0061
Episode_Reward/pen_flat_orientation: -0.0676
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0139
   Episode_Reward/foot_landing_vel: -0.0116
   Episode_Reward/test_gait_reward: -0.0677
Metrics/base_velocity/error_vel_xy: 0.3450
Metrics/base_velocity/error_vel_yaw: 0.0692
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 53.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 1.09s
                        Total time: 326.54s
                               ETA: 2950.9s

################################################################################
                     [1m Learning iteration 299/3000 [0m                      

                       Computation: 88576 steps/s (collection: 0.984s, learning 0.125s)
               Value function loss: 0.6531
                    Surrogate loss: 0.0031
             Mean action noise std: 0.5583
                     Learning rate: 0.0009
                       Mean reward: 0.99
               Mean episode length: 77.19
       Episode_Reward/keep_balance: 0.0759
     Episode_Reward/rew_lin_vel_xy: 0.0994
      Episode_Reward/rew_ang_vel_z: 0.2280
    Episode_Reward/pen_base_height: -0.1220
      Episode_Reward/pen_lin_vel_z: -0.0133
     Episode_Reward/pen_ang_vel_xy: -0.0234
   Episode_Reward/pen_joint_torque: -0.0109
    Episode_Reward/pen_joint_accel: -0.0069
    Episode_Reward/pen_action_rate: -0.0027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0028
   Episode_Reward/pen_joint_powers: -0.0041
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0060
Episode_Reward/pen_flat_orientation: -0.0680
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0133
   Episode_Reward/foot_landing_vel: -0.0112
   Episode_Reward/test_gait_reward: -0.0674
Metrics/base_velocity/error_vel_xy: 0.3432
Metrics/base_velocity/error_vel_yaw: 0.0687
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 51.9583
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 1.11s
                        Total time: 327.65s
                               ETA: 2950.0s

################################################################################
                     [1m Learning iteration 300/3000 [0m                      

                       Computation: 88475 steps/s (collection: 0.987s, learning 0.124s)
               Value function loss: 0.4880
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5584
                     Learning rate: 0.0013
                       Mean reward: 0.79
               Mean episode length: 79.47
       Episode_Reward/keep_balance: 0.0774
     Episode_Reward/rew_lin_vel_xy: 0.1029
      Episode_Reward/rew_ang_vel_z: 0.2318
    Episode_Reward/pen_base_height: -0.1248
      Episode_Reward/pen_lin_vel_z: -0.0134
     Episode_Reward/pen_ang_vel_xy: -0.0236
   Episode_Reward/pen_joint_torque: -0.0113
    Episode_Reward/pen_joint_accel: -0.0076
    Episode_Reward/pen_action_rate: -0.0028
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0029
   Episode_Reward/pen_joint_powers: -0.0043
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0063
Episode_Reward/pen_flat_orientation: -0.0710
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0141
   Episode_Reward/foot_landing_vel: -0.0117
   Episode_Reward/test_gait_reward: -0.0686
Metrics/base_velocity/error_vel_xy: 0.3402
Metrics/base_velocity/error_vel_yaw: 0.0703
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 48.2083
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 1.11s
                        Total time: 328.76s
                               ETA: 2949.0s

################################################################################
                     [1m Learning iteration 301/3000 [0m                      

                       Computation: 90631 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.4569
                    Surrogate loss: 0.0019
             Mean action noise std: 0.5588
                     Learning rate: 0.0006
                       Mean reward: 0.74
               Mean episode length: 78.02
       Episode_Reward/keep_balance: 0.0796
     Episode_Reward/rew_lin_vel_xy: 0.1151
      Episode_Reward/rew_ang_vel_z: 0.2381
    Episode_Reward/pen_base_height: -0.1268
      Episode_Reward/pen_lin_vel_z: -0.0134
     Episode_Reward/pen_ang_vel_xy: -0.0234
   Episode_Reward/pen_joint_torque: -0.0116
    Episode_Reward/pen_joint_accel: -0.0075
    Episode_Reward/pen_action_rate: -0.0028
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0029
   Episode_Reward/pen_joint_powers: -0.0044
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0064
Episode_Reward/pen_flat_orientation: -0.0733
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0140
   Episode_Reward/foot_landing_vel: -0.0116
   Episode_Reward/test_gait_reward: -0.0708
Metrics/base_velocity/error_vel_xy: 0.3419
Metrics/base_velocity/error_vel_yaw: 0.0728
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 52.9583
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 1.08s
                        Total time: 329.85s
                               ETA: 2947.9s

################################################################################
                     [1m Learning iteration 302/3000 [0m                      

                       Computation: 90848 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 0.4429
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5585
                     Learning rate: 0.0013
                       Mean reward: 1.37
               Mean episode length: 81.93
       Episode_Reward/keep_balance: 0.0805
     Episode_Reward/rew_lin_vel_xy: 0.1124
      Episode_Reward/rew_ang_vel_z: 0.2413
    Episode_Reward/pen_base_height: -0.1267
      Episode_Reward/pen_lin_vel_z: -0.0136
     Episode_Reward/pen_ang_vel_xy: -0.0234
   Episode_Reward/pen_joint_torque: -0.0116
    Episode_Reward/pen_joint_accel: -0.0078
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0030
   Episode_Reward/pen_joint_powers: -0.0044
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0065
Episode_Reward/pen_flat_orientation: -0.0738
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0142
   Episode_Reward/foot_landing_vel: -0.0118
   Episode_Reward/test_gait_reward: -0.0714
Metrics/base_velocity/error_vel_xy: 0.3491
Metrics/base_velocity/error_vel_yaw: 0.0736
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 48.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 1.08s
                        Total time: 330.93s
                               ETA: 2946.7s

################################################################################
                     [1m Learning iteration 303/3000 [0m                      

                       Computation: 90713 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.4205
                    Surrogate loss: 0.0028
             Mean action noise std: 0.5581
                     Learning rate: 0.0006
                       Mean reward: 1.49
               Mean episode length: 84.12
       Episode_Reward/keep_balance: 0.0824
     Episode_Reward/rew_lin_vel_xy: 0.1203
      Episode_Reward/rew_ang_vel_z: 0.2463
    Episode_Reward/pen_base_height: -0.1290
      Episode_Reward/pen_lin_vel_z: -0.0136
     Episode_Reward/pen_ang_vel_xy: -0.0237
   Episode_Reward/pen_joint_torque: -0.0118
    Episode_Reward/pen_joint_accel: -0.0079
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0030
   Episode_Reward/pen_joint_powers: -0.0045
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0067
Episode_Reward/pen_flat_orientation: -0.0756
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0141
   Episode_Reward/foot_landing_vel: -0.0119
   Episode_Reward/test_gait_reward: -0.0734
Metrics/base_velocity/error_vel_xy: 0.3477
Metrics/base_velocity/error_vel_yaw: 0.0760
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 50.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 1.08s
                        Total time: 332.01s
                               ETA: 2945.5s

################################################################################
                     [1m Learning iteration 304/3000 [0m                      

                       Computation: 90931 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 0.4090
                    Surrogate loss: 0.0106
             Mean action noise std: 0.5584
                     Learning rate: 0.0001
                       Mean reward: 1.25
               Mean episode length: 82.00
       Episode_Reward/keep_balance: 0.0810
     Episode_Reward/rew_lin_vel_xy: 0.1088
      Episode_Reward/rew_ang_vel_z: 0.2416
    Episode_Reward/pen_base_height: -0.1268
      Episode_Reward/pen_lin_vel_z: -0.0137
     Episode_Reward/pen_ang_vel_xy: -0.0235
   Episode_Reward/pen_joint_torque: -0.0117
    Episode_Reward/pen_joint_accel: -0.0078
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0029
   Episode_Reward/pen_joint_powers: -0.0044
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0066
Episode_Reward/pen_flat_orientation: -0.0742
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0141
   Episode_Reward/foot_landing_vel: -0.0116
   Episode_Reward/test_gait_reward: -0.0726
Metrics/base_velocity/error_vel_xy: 0.3579
Metrics/base_velocity/error_vel_yaw: 0.0749
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 50.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 1.08s
                        Total time: 333.09s
                               ETA: 2944.3s

################################################################################
                     [1m Learning iteration 305/3000 [0m                      

                       Computation: 91213 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.4116
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5586
                     Learning rate: 0.0003
                       Mean reward: 1.18
               Mean episode length: 79.85
       Episode_Reward/keep_balance: 0.0804
     Episode_Reward/rew_lin_vel_xy: 0.1074
      Episode_Reward/rew_ang_vel_z: 0.2398
    Episode_Reward/pen_base_height: -0.1261
      Episode_Reward/pen_lin_vel_z: -0.0135
     Episode_Reward/pen_ang_vel_xy: -0.0236
   Episode_Reward/pen_joint_torque: -0.0116
    Episode_Reward/pen_joint_accel: -0.0080
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0029
   Episode_Reward/pen_joint_powers: -0.0044
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0066
Episode_Reward/pen_flat_orientation: -0.0737
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0140
   Episode_Reward/foot_landing_vel: -0.0115
   Episode_Reward/test_gait_reward: -0.0720
Metrics/base_velocity/error_vel_xy: 0.3550
Metrics/base_velocity/error_vel_yaw: 0.0742
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 45.6667
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 1.08s
                        Total time: 334.17s
                               ETA: 2943.1s

################################################################################
                     [1m Learning iteration 306/3000 [0m                      

                       Computation: 90941 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.3957
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5590
                     Learning rate: 0.0009
                       Mean reward: 1.51
               Mean episode length: 84.41
       Episode_Reward/keep_balance: 0.0816
     Episode_Reward/rew_lin_vel_xy: 0.1109
      Episode_Reward/rew_ang_vel_z: 0.2434
    Episode_Reward/pen_base_height: -0.1284
      Episode_Reward/pen_lin_vel_z: -0.0135
     Episode_Reward/pen_ang_vel_xy: -0.0236
   Episode_Reward/pen_joint_torque: -0.0116
    Episode_Reward/pen_joint_accel: -0.0083
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0030
   Episode_Reward/pen_joint_powers: -0.0044
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0067
Episode_Reward/pen_flat_orientation: -0.0748
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0144
   Episode_Reward/foot_landing_vel: -0.0118
   Episode_Reward/test_gait_reward: -0.0730
Metrics/base_velocity/error_vel_xy: 0.3574
Metrics/base_velocity/error_vel_yaw: 0.0758
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 47.7500
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 1.08s
                        Total time: 335.25s
                               ETA: 2941.9s

################################################################################
                     [1m Learning iteration 307/3000 [0m                      

                       Computation: 91975 steps/s (collection: 0.945s, learning 0.124s)
               Value function loss: 0.4285
                    Surrogate loss: -0.0021
             Mean action noise std: 0.5594
                     Learning rate: 0.0009
                       Mean reward: 1.02
               Mean episode length: 84.68
       Episode_Reward/keep_balance: 0.0839
     Episode_Reward/rew_lin_vel_xy: 0.1191
      Episode_Reward/rew_ang_vel_z: 0.2504
    Episode_Reward/pen_base_height: -0.1296
      Episode_Reward/pen_lin_vel_z: -0.0136
     Episode_Reward/pen_ang_vel_xy: -0.0237
   Episode_Reward/pen_joint_torque: -0.0121
    Episode_Reward/pen_joint_accel: -0.0081
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0030
   Episode_Reward/pen_joint_powers: -0.0046
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0068
Episode_Reward/pen_flat_orientation: -0.0766
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0144
   Episode_Reward/foot_landing_vel: -0.0121
   Episode_Reward/test_gait_reward: -0.0754
Metrics/base_velocity/error_vel_xy: 0.3564
Metrics/base_velocity/error_vel_yaw: 0.0777
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 48.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 1.07s
                        Total time: 336.32s
                               ETA: 2940.6s

################################################################################
                     [1m Learning iteration 308/3000 [0m                      

                       Computation: 91659 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.4729
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5597
                     Learning rate: 0.0006
                       Mean reward: 1.25
               Mean episode length: 85.49
       Episode_Reward/keep_balance: 0.0862
     Episode_Reward/rew_lin_vel_xy: 0.1236
      Episode_Reward/rew_ang_vel_z: 0.2578
    Episode_Reward/pen_base_height: -0.1305
      Episode_Reward/pen_lin_vel_z: -0.0138
     Episode_Reward/pen_ang_vel_xy: -0.0240
   Episode_Reward/pen_joint_torque: -0.0126
    Episode_Reward/pen_joint_accel: -0.0084
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0031
   Episode_Reward/pen_joint_powers: -0.0047
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0070
Episode_Reward/pen_flat_orientation: -0.0782
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0150
   Episode_Reward/foot_landing_vel: -0.0125
   Episode_Reward/test_gait_reward: -0.0773
Metrics/base_velocity/error_vel_xy: 0.3626
Metrics/base_velocity/error_vel_yaw: 0.0794
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 49.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 1.07s
                        Total time: 337.39s
                               ETA: 2939.4s

################################################################################
                     [1m Learning iteration 309/3000 [0m                      

                       Computation: 92288 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.5386
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5600
                     Learning rate: 0.0013
                       Mean reward: 1.53
               Mean episode length: 83.28
       Episode_Reward/keep_balance: 0.0850
     Episode_Reward/rew_lin_vel_xy: 0.1196
      Episode_Reward/rew_ang_vel_z: 0.2537
    Episode_Reward/pen_base_height: -0.1303
      Episode_Reward/pen_lin_vel_z: -0.0135
     Episode_Reward/pen_ang_vel_xy: -0.0239
   Episode_Reward/pen_joint_torque: -0.0122
    Episode_Reward/pen_joint_accel: -0.0087
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0031
   Episode_Reward/pen_joint_powers: -0.0046
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0069
Episode_Reward/pen_flat_orientation: -0.0770
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0151
   Episode_Reward/foot_landing_vel: -0.0123
   Episode_Reward/test_gait_reward: -0.0762
Metrics/base_velocity/error_vel_xy: 0.3602
Metrics/base_velocity/error_vel_yaw: 0.0789
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 45.4167
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 1.07s
                        Total time: 338.46s
                               ETA: 2938.0s

################################################################################
                     [1m Learning iteration 310/3000 [0m                      

                       Computation: 92663 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 0.4526
                    Surrogate loss: 0.0051
             Mean action noise std: 0.5603
                     Learning rate: 0.0002
                       Mean reward: 1.15
               Mean episode length: 84.76
       Episode_Reward/keep_balance: 0.0835
     Episode_Reward/rew_lin_vel_xy: 0.1173
      Episode_Reward/rew_ang_vel_z: 0.2491
    Episode_Reward/pen_base_height: -0.1291
      Episode_Reward/pen_lin_vel_z: -0.0135
     Episode_Reward/pen_ang_vel_xy: -0.0239
   Episode_Reward/pen_joint_torque: -0.0121
    Episode_Reward/pen_joint_accel: -0.0081
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0031
   Episode_Reward/pen_joint_powers: -0.0046
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0068
Episode_Reward/pen_flat_orientation: -0.0760
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0146
   Episode_Reward/foot_landing_vel: -0.0121
   Episode_Reward/test_gait_reward: -0.0751
Metrics/base_velocity/error_vel_xy: 0.3575
Metrics/base_velocity/error_vel_yaw: 0.0772
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 46.4583
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 1.06s
                        Total time: 339.52s
                               ETA: 2936.7s

################################################################################
                     [1m Learning iteration 311/3000 [0m                      

                       Computation: 91605 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.4066
                    Surrogate loss: 0.0032
             Mean action noise std: 0.5605
                     Learning rate: 0.0002
                       Mean reward: 0.76
               Mean episode length: 86.64
       Episode_Reward/keep_balance: 0.0857
     Episode_Reward/rew_lin_vel_xy: 0.1206
      Episode_Reward/rew_ang_vel_z: 0.2540
    Episode_Reward/pen_base_height: -0.1314
      Episode_Reward/pen_lin_vel_z: -0.0138
     Episode_Reward/pen_ang_vel_xy: -0.0239
   Episode_Reward/pen_joint_torque: -0.0125
    Episode_Reward/pen_joint_accel: -0.0084
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0032
   Episode_Reward/pen_joint_powers: -0.0047
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0071
Episode_Reward/pen_flat_orientation: -0.0794
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0155
   Episode_Reward/foot_landing_vel: -0.0127
   Episode_Reward/test_gait_reward: -0.0771
Metrics/base_velocity/error_vel_xy: 0.3648
Metrics/base_velocity/error_vel_yaw: 0.0802
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 44.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 1.07s
                        Total time: 340.59s
                               ETA: 2935.4s

################################################################################
                     [1m Learning iteration 312/3000 [0m                      

                       Computation: 91189 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.4409
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5606
                     Learning rate: 0.0004
                       Mean reward: 1.44
               Mean episode length: 90.44
       Episode_Reward/keep_balance: 0.0892
     Episode_Reward/rew_lin_vel_xy: 0.1274
      Episode_Reward/rew_ang_vel_z: 0.2657
    Episode_Reward/pen_base_height: -0.1329
      Episode_Reward/pen_lin_vel_z: -0.0138
     Episode_Reward/pen_ang_vel_xy: -0.0238
   Episode_Reward/pen_joint_torque: -0.0130
    Episode_Reward/pen_joint_accel: -0.0089
    Episode_Reward/pen_action_rate: -0.0032
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0033
   Episode_Reward/pen_joint_powers: -0.0049
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0074
Episode_Reward/pen_flat_orientation: -0.0811
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0160
   Episode_Reward/foot_landing_vel: -0.0131
   Episode_Reward/test_gait_reward: -0.0800
Metrics/base_velocity/error_vel_xy: 0.3753
Metrics/base_velocity/error_vel_yaw: 0.0828
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 47.2917
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 1.08s
                        Total time: 341.67s
                               ETA: 2934.2s

################################################################################
                     [1m Learning iteration 313/3000 [0m                      

                       Computation: 91773 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.4560
                    Surrogate loss: -0.0030
             Mean action noise std: 0.5609
                     Learning rate: 0.0009
                       Mean reward: 2.37
               Mean episode length: 95.78
       Episode_Reward/keep_balance: 0.0905
     Episode_Reward/rew_lin_vel_xy: 0.1325
      Episode_Reward/rew_ang_vel_z: 0.2697
    Episode_Reward/pen_base_height: -0.1335
      Episode_Reward/pen_lin_vel_z: -0.0140
     Episode_Reward/pen_ang_vel_xy: -0.0240
   Episode_Reward/pen_joint_torque: -0.0133
    Episode_Reward/pen_joint_accel: -0.0089
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0033
   Episode_Reward/pen_joint_powers: -0.0050
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0074
Episode_Reward/pen_flat_orientation: -0.0830
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0168
   Episode_Reward/foot_landing_vel: -0.0135
   Episode_Reward/test_gait_reward: -0.0810
Metrics/base_velocity/error_vel_xy: 0.3763
Metrics/base_velocity/error_vel_yaw: 0.0838
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 41.1250
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 1.07s
                        Total time: 342.74s
                               ETA: 2933.0s

################################################################################
                     [1m Learning iteration 314/3000 [0m                      

                       Computation: 92753 steps/s (collection: 0.936s, learning 0.123s)
               Value function loss: 0.5038
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5608
                     Learning rate: 0.0019
                       Mean reward: 2.28
               Mean episode length: 95.81
       Episode_Reward/keep_balance: 0.0886
     Episode_Reward/rew_lin_vel_xy: 0.1328
      Episode_Reward/rew_ang_vel_z: 0.2631
    Episode_Reward/pen_base_height: -0.1331
      Episode_Reward/pen_lin_vel_z: -0.0139
     Episode_Reward/pen_ang_vel_xy: -0.0237
   Episode_Reward/pen_joint_torque: -0.0129
    Episode_Reward/pen_joint_accel: -0.0090
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0033
   Episode_Reward/pen_joint_powers: -0.0049
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0074
Episode_Reward/pen_flat_orientation: -0.0839
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0162
   Episode_Reward/foot_landing_vel: -0.0133
   Episode_Reward/test_gait_reward: -0.0798
Metrics/base_velocity/error_vel_xy: 0.3687
Metrics/base_velocity/error_vel_yaw: 0.0828
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 44.2083
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 1.06s
                        Total time: 343.80s
                               ETA: 2931.6s

################################################################################
                     [1m Learning iteration 315/3000 [0m                      

                       Computation: 92279 steps/s (collection: 0.941s, learning 0.124s)
               Value function loss: 0.6726
                    Surrogate loss: 0.0000
             Mean action noise std: 0.5613
                     Learning rate: 0.0029
                       Mean reward: 1.51
               Mean episode length: 93.93
       Episode_Reward/keep_balance: 0.0919
     Episode_Reward/rew_lin_vel_xy: 0.1299
      Episode_Reward/rew_ang_vel_z: 0.2744
    Episode_Reward/pen_base_height: -0.1338
      Episode_Reward/pen_lin_vel_z: -0.0142
     Episode_Reward/pen_ang_vel_xy: -0.0245
   Episode_Reward/pen_joint_torque: -0.0135
    Episode_Reward/pen_joint_accel: -0.0089
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0034
   Episode_Reward/pen_joint_powers: -0.0051
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0076
Episode_Reward/pen_flat_orientation: -0.0823
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0163
   Episode_Reward/foot_landing_vel: -0.0134
   Episode_Reward/test_gait_reward: -0.0832
Metrics/base_velocity/error_vel_xy: 0.3903
Metrics/base_velocity/error_vel_yaw: 0.0846
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 42.2917
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 1.07s
                        Total time: 344.87s
                               ETA: 2930.3s

################################################################################
                     [1m Learning iteration 316/3000 [0m                      

                       Computation: 93129 steps/s (collection: 0.933s, learning 0.123s)
               Value function loss: 0.8795
                    Surrogate loss: 0.0325
             Mean action noise std: 0.5632
                     Learning rate: 0.0006
                       Mean reward: 1.63
               Mean episode length: 92.06
       Episode_Reward/keep_balance: 0.0920
     Episode_Reward/rew_lin_vel_xy: 0.1363
      Episode_Reward/rew_ang_vel_z: 0.2748
    Episode_Reward/pen_base_height: -0.1331
      Episode_Reward/pen_lin_vel_z: -0.0144
     Episode_Reward/pen_ang_vel_xy: -0.0245
   Episode_Reward/pen_joint_torque: -0.0137
    Episode_Reward/pen_joint_accel: -0.0089
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0035
   Episode_Reward/pen_joint_powers: -0.0051
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0076
Episode_Reward/pen_flat_orientation: -0.0833
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0176
   Episode_Reward/foot_landing_vel: -0.0137
   Episode_Reward/test_gait_reward: -0.0828
Metrics/base_velocity/error_vel_xy: 0.3901
Metrics/base_velocity/error_vel_yaw: 0.0843
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 42.2500
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 1.06s
                        Total time: 345.92s
                               ETA: 2928.9s

################################################################################
                     [1m Learning iteration 317/3000 [0m                      

                       Computation: 91590 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 0.6991
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5642
                     Learning rate: 0.0009
                       Mean reward: 1.32
               Mean episode length: 83.79
       Episode_Reward/keep_balance: 0.0916
     Episode_Reward/rew_lin_vel_xy: 0.1373
      Episode_Reward/rew_ang_vel_z: 0.2719
    Episode_Reward/pen_base_height: -0.1351
      Episode_Reward/pen_lin_vel_z: -0.0147
     Episode_Reward/pen_ang_vel_xy: -0.0245
   Episode_Reward/pen_joint_torque: -0.0138
    Episode_Reward/pen_joint_accel: -0.0092
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0035
   Episode_Reward/pen_joint_powers: -0.0052
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0077
Episode_Reward/pen_flat_orientation: -0.0838
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0177
   Episode_Reward/foot_landing_vel: -0.0140
   Episode_Reward/test_gait_reward: -0.0830
Metrics/base_velocity/error_vel_xy: 0.3804
Metrics/base_velocity/error_vel_yaw: 0.0859
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 40.8333
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 1.07s
                        Total time: 347.00s
                               ETA: 2927.7s

################################################################################
                     [1m Learning iteration 318/3000 [0m                      

                       Computation: 92126 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.5635
                    Surrogate loss: 0.0004
             Mean action noise std: 0.5652
                     Learning rate: 0.0006
                       Mean reward: 1.71
               Mean episode length: 96.18
       Episode_Reward/keep_balance: 0.0963
     Episode_Reward/rew_lin_vel_xy: 0.1455
      Episode_Reward/rew_ang_vel_z: 0.2852
    Episode_Reward/pen_base_height: -0.1403
      Episode_Reward/pen_lin_vel_z: -0.0147
     Episode_Reward/pen_ang_vel_xy: -0.0243
   Episode_Reward/pen_joint_torque: -0.0146
    Episode_Reward/pen_joint_accel: -0.0096
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0036
   Episode_Reward/pen_joint_powers: -0.0054
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0082
Episode_Reward/pen_flat_orientation: -0.0876
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0181
   Episode_Reward/foot_landing_vel: -0.0147
   Episode_Reward/test_gait_reward: -0.0865
Metrics/base_velocity/error_vel_xy: 0.3929
Metrics/base_velocity/error_vel_yaw: 0.0909
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 39.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 1.07s
                        Total time: 348.06s
                               ETA: 2926.4s

################################################################################
                     [1m Learning iteration 319/3000 [0m                      

                       Computation: 92709 steps/s (collection: 0.939s, learning 0.121s)
               Value function loss: 0.5390
                    Surrogate loss: -0.0002
             Mean action noise std: 0.5657
                     Learning rate: 0.0004
                       Mean reward: 2.23
               Mean episode length: 99.24
       Episode_Reward/keep_balance: 0.0999
     Episode_Reward/rew_lin_vel_xy: 0.1487
      Episode_Reward/rew_ang_vel_z: 0.2973
    Episode_Reward/pen_base_height: -0.1430
      Episode_Reward/pen_lin_vel_z: -0.0147
     Episode_Reward/pen_ang_vel_xy: -0.0244
   Episode_Reward/pen_joint_torque: -0.0156
    Episode_Reward/pen_joint_accel: -0.0096
    Episode_Reward/pen_action_rate: -0.0038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0037
   Episode_Reward/pen_joint_powers: -0.0056
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0084
Episode_Reward/pen_flat_orientation: -0.0892
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0186
   Episode_Reward/foot_landing_vel: -0.0149
   Episode_Reward/test_gait_reward: -0.0903
Metrics/base_velocity/error_vel_xy: 0.4075
Metrics/base_velocity/error_vel_yaw: 0.0932
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 43.5833
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 1.06s
                        Total time: 349.12s
                               ETA: 2925.0s

################################################################################
                     [1m Learning iteration 320/3000 [0m                      

                       Computation: 92516 steps/s (collection: 0.941s, learning 0.121s)
               Value function loss: 0.4882
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5663
                     Learning rate: 0.0009
                       Mean reward: 2.64
               Mean episode length: 107.80
       Episode_Reward/keep_balance: 0.0996
     Episode_Reward/rew_lin_vel_xy: 0.1534
      Episode_Reward/rew_ang_vel_z: 0.2948
    Episode_Reward/pen_base_height: -0.1442
      Episode_Reward/pen_lin_vel_z: -0.0145
     Episode_Reward/pen_ang_vel_xy: -0.0245
   Episode_Reward/pen_joint_torque: -0.0156
    Episode_Reward/pen_joint_accel: -0.0096
    Episode_Reward/pen_action_rate: -0.0038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0037
   Episode_Reward/pen_joint_powers: -0.0055
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0085
Episode_Reward/pen_flat_orientation: -0.0902
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0185
   Episode_Reward/foot_landing_vel: -0.0151
   Episode_Reward/test_gait_reward: -0.0903
Metrics/base_velocity/error_vel_xy: 0.4015
Metrics/base_velocity/error_vel_yaw: 0.0947
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 45.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 1.06s
                        Total time: 350.19s
                               ETA: 2923.7s

################################################################################
                     [1m Learning iteration 321/3000 [0m                      

                       Computation: 92762 steps/s (collection: 0.938s, learning 0.122s)
               Value function loss: 0.5732
                    Surrogate loss: 0.0027
             Mean action noise std: 0.5668
                     Learning rate: 0.0013
                       Mean reward: 2.53
               Mean episode length: 103.35
       Episode_Reward/keep_balance: 0.0983
     Episode_Reward/rew_lin_vel_xy: 0.1516
      Episode_Reward/rew_ang_vel_z: 0.2918
    Episode_Reward/pen_base_height: -0.1423
      Episode_Reward/pen_lin_vel_z: -0.0140
     Episode_Reward/pen_ang_vel_xy: -0.0241
   Episode_Reward/pen_joint_torque: -0.0154
    Episode_Reward/pen_joint_accel: -0.0099
    Episode_Reward/pen_action_rate: -0.0037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0036
   Episode_Reward/pen_joint_powers: -0.0054
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0083
Episode_Reward/pen_flat_orientation: -0.0881
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0177
   Episode_Reward/foot_landing_vel: -0.0146
   Episode_Reward/test_gait_reward: -0.0895
Metrics/base_velocity/error_vel_xy: 0.3947
Metrics/base_velocity/error_vel_yaw: 0.0925
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 43.3750
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 1.06s
                        Total time: 351.25s
                               ETA: 2922.3s

################################################################################
                     [1m Learning iteration 322/3000 [0m                      

                       Computation: 92667 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 0.5720
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5677
                     Learning rate: 0.0013
                       Mean reward: 1.68
               Mean episode length: 88.23
       Episode_Reward/keep_balance: 0.0942
     Episode_Reward/rew_lin_vel_xy: 0.1362
      Episode_Reward/rew_ang_vel_z: 0.2796
    Episode_Reward/pen_base_height: -0.1386
      Episode_Reward/pen_lin_vel_z: -0.0139
     Episode_Reward/pen_ang_vel_xy: -0.0238
   Episode_Reward/pen_joint_torque: -0.0145
    Episode_Reward/pen_joint_accel: -0.0092
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0034
   Episode_Reward/pen_joint_powers: -0.0052
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0080
Episode_Reward/pen_flat_orientation: -0.0836
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0165
   Episode_Reward/foot_landing_vel: -0.0141
   Episode_Reward/test_gait_reward: -0.0863
Metrics/base_velocity/error_vel_xy: 0.3934
Metrics/base_velocity/error_vel_yaw: 0.0882
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 37.9167
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 1.06s
                        Total time: 352.31s
                               ETA: 2921.0s

################################################################################
                     [1m Learning iteration 323/3000 [0m                      

                       Computation: 94083 steps/s (collection: 0.923s, learning 0.122s)
               Value function loss: 0.5539
                    Surrogate loss: 0.0015
             Mean action noise std: 0.5685
                     Learning rate: 0.0009
                       Mean reward: 1.84
               Mean episode length: 97.22
       Episode_Reward/keep_balance: 0.0941
     Episode_Reward/rew_lin_vel_xy: 0.1350
      Episode_Reward/rew_ang_vel_z: 0.2799
    Episode_Reward/pen_base_height: -0.1397
      Episode_Reward/pen_lin_vel_z: -0.0141
     Episode_Reward/pen_ang_vel_xy: -0.0238
   Episode_Reward/pen_joint_torque: -0.0146
    Episode_Reward/pen_joint_accel: -0.0096
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0035
   Episode_Reward/pen_joint_powers: -0.0052
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0080
Episode_Reward/pen_flat_orientation: -0.0840
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0171
   Episode_Reward/foot_landing_vel: -0.0145
   Episode_Reward/test_gait_reward: -0.0866
Metrics/base_velocity/error_vel_xy: 0.3868
Metrics/base_velocity/error_vel_yaw: 0.0876
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 36.4583
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 1.04s
                        Total time: 353.35s
                               ETA: 2919.5s

################################################################################
                     [1m Learning iteration 324/3000 [0m                      

                       Computation: 91787 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 0.5372
                    Surrogate loss: 0.0016
             Mean action noise std: 0.5688
                     Learning rate: 0.0004
                       Mean reward: 2.24
               Mean episode length: 100.42
       Episode_Reward/keep_balance: 0.0986
     Episode_Reward/rew_lin_vel_xy: 0.1440
      Episode_Reward/rew_ang_vel_z: 0.2926
    Episode_Reward/pen_base_height: -0.1413
      Episode_Reward/pen_lin_vel_z: -0.0145
     Episode_Reward/pen_ang_vel_xy: -0.0244
   Episode_Reward/pen_joint_torque: -0.0157
    Episode_Reward/pen_joint_accel: -0.0097
    Episode_Reward/pen_action_rate: -0.0038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0037
   Episode_Reward/pen_joint_powers: -0.0055
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0084
Episode_Reward/pen_flat_orientation: -0.0861
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0182
   Episode_Reward/foot_landing_vel: -0.0150
   Episode_Reward/test_gait_reward: -0.0906
Metrics/base_velocity/error_vel_xy: 0.4105
Metrics/base_velocity/error_vel_yaw: 0.0922
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 39.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 1.07s
                        Total time: 354.42s
                               ETA: 2918.3s

################################################################################
                     [1m Learning iteration 325/3000 [0m                      

                       Computation: 92882 steps/s (collection: 0.937s, learning 0.122s)
               Value function loss: 0.5252
                    Surrogate loss: 0.0009
             Mean action noise std: 0.5689
                     Learning rate: 0.0006
                       Mean reward: 2.72
               Mean episode length: 104.76
       Episode_Reward/keep_balance: 0.1006
     Episode_Reward/rew_lin_vel_xy: 0.1462
      Episode_Reward/rew_ang_vel_z: 0.2999
    Episode_Reward/pen_base_height: -0.1424
      Episode_Reward/pen_lin_vel_z: -0.0147
     Episode_Reward/pen_ang_vel_xy: -0.0246
   Episode_Reward/pen_joint_torque: -0.0160
    Episode_Reward/pen_joint_accel: -0.0102
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0038
   Episode_Reward/pen_joint_powers: -0.0056
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0086
Episode_Reward/pen_flat_orientation: -0.0870
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0184
   Episode_Reward/foot_landing_vel: -0.0156
   Episode_Reward/test_gait_reward: -0.0924
Metrics/base_velocity/error_vel_xy: 0.4152
Metrics/base_velocity/error_vel_yaw: 0.0934
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 35.9167
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 1.06s
                        Total time: 355.48s
                               ETA: 2916.9s

################################################################################
                     [1m Learning iteration 326/3000 [0m                      

                       Computation: 92440 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 0.5611
                    Surrogate loss: 0.0028
             Mean action noise std: 0.5684
                     Learning rate: 0.0004
                       Mean reward: 1.92
               Mean episode length: 102.79
       Episode_Reward/keep_balance: 0.0998
     Episode_Reward/rew_lin_vel_xy: 0.1344
      Episode_Reward/rew_ang_vel_z: 0.2957
    Episode_Reward/pen_base_height: -0.1400
      Episode_Reward/pen_lin_vel_z: -0.0148
     Episode_Reward/pen_ang_vel_xy: -0.0250
   Episode_Reward/pen_joint_torque: -0.0159
    Episode_Reward/pen_joint_accel: -0.0102
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0038
   Episode_Reward/pen_joint_powers: -0.0057
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0086
Episode_Reward/pen_flat_orientation: -0.0837
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0190
   Episode_Reward/foot_landing_vel: -0.0155
   Episode_Reward/test_gait_reward: -0.0922
Metrics/base_velocity/error_vel_xy: 0.4212
Metrics/base_velocity/error_vel_yaw: 0.0936
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 33.8333
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 1.06s
                        Total time: 356.55s
                               ETA: 2915.6s

################################################################################
                     [1m Learning iteration 327/3000 [0m                      

                       Computation: 93392 steps/s (collection: 0.931s, learning 0.122s)
               Value function loss: 0.5396
                    Surrogate loss: -0.0036
             Mean action noise std: 0.5681
                     Learning rate: 0.0006
                       Mean reward: 2.52
               Mean episode length: 105.24
       Episode_Reward/keep_balance: 0.1007
     Episode_Reward/rew_lin_vel_xy: 0.1467
      Episode_Reward/rew_ang_vel_z: 0.2988
    Episode_Reward/pen_base_height: -0.1406
      Episode_Reward/pen_lin_vel_z: -0.0151
     Episode_Reward/pen_ang_vel_xy: -0.0247
   Episode_Reward/pen_joint_torque: -0.0162
    Episode_Reward/pen_joint_accel: -0.0101
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0038
   Episode_Reward/pen_joint_powers: -0.0057
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0087
Episode_Reward/pen_flat_orientation: -0.0850
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0188
   Episode_Reward/foot_landing_vel: -0.0156
   Episode_Reward/test_gait_reward: -0.0924
Metrics/base_velocity/error_vel_xy: 0.4182
Metrics/base_velocity/error_vel_yaw: 0.0944
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 34.4583
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 1.05s
                        Total time: 357.60s
                               ETA: 2914.2s

################################################################################
                     [1m Learning iteration 328/3000 [0m                      

                       Computation: 92480 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 0.5581
                    Surrogate loss: -0.0021
             Mean action noise std: 0.5690
                     Learning rate: 0.0009
                       Mean reward: 1.97
               Mean episode length: 100.93
       Episode_Reward/keep_balance: 0.1058
     Episode_Reward/rew_lin_vel_xy: 0.1483
      Episode_Reward/rew_ang_vel_z: 0.3137
    Episode_Reward/pen_base_height: -0.1420
      Episode_Reward/pen_lin_vel_z: -0.0153
     Episode_Reward/pen_ang_vel_xy: -0.0254
   Episode_Reward/pen_joint_torque: -0.0168
    Episode_Reward/pen_joint_accel: -0.0107
    Episode_Reward/pen_action_rate: -0.0042
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0041
   Episode_Reward/pen_joint_powers: -0.0060
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0092
Episode_Reward/pen_flat_orientation: -0.0864
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0204
   Episode_Reward/foot_landing_vel: -0.0166
   Episode_Reward/test_gait_reward: -0.0975
Metrics/base_velocity/error_vel_xy: 0.4339
Metrics/base_velocity/error_vel_yaw: 0.0994
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 32.9167
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 1.06s
                        Total time: 358.66s
                               ETA: 2912.9s

################################################################################
                     [1m Learning iteration 329/3000 [0m                      

                       Computation: 92441 steps/s (collection: 0.942s, learning 0.121s)
               Value function loss: 0.6480
                    Surrogate loss: 0.0000
             Mean action noise std: 0.5702
                     Learning rate: 0.0013
                       Mean reward: 3.54
               Mean episode length: 118.98
       Episode_Reward/keep_balance: 0.1114
     Episode_Reward/rew_lin_vel_xy: 0.1666
      Episode_Reward/rew_ang_vel_z: 0.3290
    Episode_Reward/pen_base_height: -0.1441
      Episode_Reward/pen_lin_vel_z: -0.0159
     Episode_Reward/pen_ang_vel_xy: -0.0258
   Episode_Reward/pen_joint_torque: -0.0180
    Episode_Reward/pen_joint_accel: -0.0112
    Episode_Reward/pen_action_rate: -0.0045
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0043
   Episode_Reward/pen_joint_powers: -0.0064
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0098
Episode_Reward/pen_flat_orientation: -0.0884
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0213
   Episode_Reward/foot_landing_vel: -0.0176
   Episode_Reward/test_gait_reward: -0.1017
Metrics/base_velocity/error_vel_xy: 0.4526
Metrics/base_velocity/error_vel_yaw: 0.1048
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 32.8333
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 1.06s
                        Total time: 359.72s
                               ETA: 2911.6s

################################################################################
                     [1m Learning iteration 330/3000 [0m                      

                       Computation: 92454 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 0.6229
                    Surrogate loss: 0.0044
             Mean action noise std: 0.5704
                     Learning rate: 0.0002
                       Mean reward: 2.60
               Mean episode length: 112.90
       Episode_Reward/keep_balance: 0.1110
     Episode_Reward/rew_lin_vel_xy: 0.1679
      Episode_Reward/rew_ang_vel_z: 0.3304
    Episode_Reward/pen_base_height: -0.1451
      Episode_Reward/pen_lin_vel_z: -0.0160
     Episode_Reward/pen_ang_vel_xy: -0.0261
   Episode_Reward/pen_joint_torque: -0.0182
    Episode_Reward/pen_joint_accel: -0.0113
    Episode_Reward/pen_action_rate: -0.0044
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0044
   Episode_Reward/pen_joint_powers: -0.0065
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0097
Episode_Reward/pen_flat_orientation: -0.0891
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0216
   Episode_Reward/foot_landing_vel: -0.0176
   Episode_Reward/test_gait_reward: -0.1016
Metrics/base_velocity/error_vel_xy: 0.4494
Metrics/base_velocity/error_vel_yaw: 0.1027
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 29.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 1.06s
                        Total time: 360.79s
                               ETA: 2910.3s

################################################################################
                     [1m Learning iteration 331/3000 [0m                      

                       Computation: 92293 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.5274
                    Surrogate loss: 0.0022
             Mean action noise std: 0.5705
                     Learning rate: 0.0003
                       Mean reward: 4.27
               Mean episode length: 126.39
       Episode_Reward/keep_balance: 0.1147
     Episode_Reward/rew_lin_vel_xy: 0.1770
      Episode_Reward/rew_ang_vel_z: 0.3396
    Episode_Reward/pen_base_height: -0.1475
      Episode_Reward/pen_lin_vel_z: -0.0158
     Episode_Reward/pen_ang_vel_xy: -0.0257
   Episode_Reward/pen_joint_torque: -0.0180
    Episode_Reward/pen_joint_accel: -0.0113
    Episode_Reward/pen_action_rate: -0.0046
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0044
   Episode_Reward/pen_joint_powers: -0.0065
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0101
Episode_Reward/pen_flat_orientation: -0.0918
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0217
   Episode_Reward/foot_landing_vel: -0.0181
   Episode_Reward/test_gait_reward: -0.1048
Metrics/base_velocity/error_vel_xy: 0.4500
Metrics/base_velocity/error_vel_yaw: 0.1075
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 32.8750
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 1.07s
                        Total time: 361.85s
                               ETA: 2909.0s

################################################################################
                     [1m Learning iteration 332/3000 [0m                      

                       Computation: 93626 steps/s (collection: 0.927s, learning 0.123s)
               Value function loss: 0.5504
                    Surrogate loss: 0.0018
             Mean action noise std: 0.5707
                     Learning rate: 0.0003
                       Mean reward: 3.02
               Mean episode length: 119.74
       Episode_Reward/keep_balance: 0.1169
     Episode_Reward/rew_lin_vel_xy: 0.1703
      Episode_Reward/rew_ang_vel_z: 0.3466
    Episode_Reward/pen_base_height: -0.1476
      Episode_Reward/pen_lin_vel_z: -0.0163
     Episode_Reward/pen_ang_vel_xy: -0.0263
   Episode_Reward/pen_joint_torque: -0.0188
    Episode_Reward/pen_joint_accel: -0.0114
    Episode_Reward/pen_action_rate: -0.0047
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0046
   Episode_Reward/pen_joint_powers: -0.0067
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0103
Episode_Reward/pen_flat_orientation: -0.0914
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0228
   Episode_Reward/foot_landing_vel: -0.0186
   Episode_Reward/test_gait_reward: -0.1069
Metrics/base_velocity/error_vel_xy: 0.4800
Metrics/base_velocity/error_vel_yaw: 0.1095
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 31.7917
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 1.05s
                        Total time: 362.90s
                               ETA: 2907.6s

################################################################################
                     [1m Learning iteration 333/3000 [0m                      

                       Computation: 93292 steps/s (collection: 0.931s, learning 0.122s)
               Value function loss: 0.5073
                    Surrogate loss: 0.0027
             Mean action noise std: 0.5709
                     Learning rate: 0.0002
                       Mean reward: 4.05
               Mean episode length: 128.15
       Episode_Reward/keep_balance: 0.1221
     Episode_Reward/rew_lin_vel_xy: 0.1778
      Episode_Reward/rew_ang_vel_z: 0.3625
    Episode_Reward/pen_base_height: -0.1503
      Episode_Reward/pen_lin_vel_z: -0.0167
     Episode_Reward/pen_ang_vel_xy: -0.0264
   Episode_Reward/pen_joint_torque: -0.0196
    Episode_Reward/pen_joint_accel: -0.0126
    Episode_Reward/pen_action_rate: -0.0049
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0048
   Episode_Reward/pen_joint_powers: -0.0070
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0108
Episode_Reward/pen_flat_orientation: -0.0953
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0240
   Episode_Reward/foot_landing_vel: -0.0196
   Episode_Reward/test_gait_reward: -0.1117
Metrics/base_velocity/error_vel_xy: 0.4881
Metrics/base_velocity/error_vel_yaw: 0.1144
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 30.5000
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 1.05s
                        Total time: 363.96s
                               ETA: 2906.2s

################################################################################
                     [1m Learning iteration 334/3000 [0m                      

                       Computation: 92484 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 0.5884
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5707
                     Learning rate: 0.0004
                       Mean reward: 3.96
               Mean episode length: 136.88
       Episode_Reward/keep_balance: 0.1265
     Episode_Reward/rew_lin_vel_xy: 0.1897
      Episode_Reward/rew_ang_vel_z: 0.3747
    Episode_Reward/pen_base_height: -0.1513
      Episode_Reward/pen_lin_vel_z: -0.0170
     Episode_Reward/pen_ang_vel_xy: -0.0272
   Episode_Reward/pen_joint_torque: -0.0206
    Episode_Reward/pen_joint_accel: -0.0124
    Episode_Reward/pen_action_rate: -0.0052
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0048
   Episode_Reward/pen_joint_powers: -0.0073
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0114
Episode_Reward/pen_flat_orientation: -0.0951
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0240
   Episode_Reward/foot_landing_vel: -0.0198
   Episode_Reward/test_gait_reward: -0.1159
Metrics/base_velocity/error_vel_xy: 0.5006
Metrics/base_velocity/error_vel_yaw: 0.1194
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 30.6250
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 1.06s
                        Total time: 365.02s
                               ETA: 2904.9s

################################################################################
                     [1m Learning iteration 335/3000 [0m                      

                       Computation: 93633 steps/s (collection: 0.929s, learning 0.121s)
               Value function loss: 0.7444
                    Surrogate loss: 0.0024
             Mean action noise std: 0.5705
                     Learning rate: 0.0003
                       Mean reward: 2.44
               Mean episode length: 113.84
       Episode_Reward/keep_balance: 0.1211
     Episode_Reward/rew_lin_vel_xy: 0.1725
      Episode_Reward/rew_ang_vel_z: 0.3577
    Episode_Reward/pen_base_height: -0.1489
      Episode_Reward/pen_lin_vel_z: -0.0174
     Episode_Reward/pen_ang_vel_xy: -0.0276
   Episode_Reward/pen_joint_torque: -0.0201
    Episode_Reward/pen_joint_accel: -0.0123
    Episode_Reward/pen_action_rate: -0.0050
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0049
   Episode_Reward/pen_joint_powers: -0.0072
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0108
Episode_Reward/pen_flat_orientation: -0.0911
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0256
   Episode_Reward/foot_landing_vel: -0.0198
   Episode_Reward/test_gait_reward: -0.1113
Metrics/base_velocity/error_vel_xy: 0.4948
Metrics/base_velocity/error_vel_yaw: 0.1137
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 26.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 1.05s
                        Total time: 366.07s
                               ETA: 2903.5s

################################################################################
                     [1m Learning iteration 336/3000 [0m                      

                       Computation: 92948 steps/s (collection: 0.936s, learning 0.122s)
               Value function loss: 0.5696
                    Surrogate loss: -0.0026
             Mean action noise std: 0.5699
                     Learning rate: 0.0006
                       Mean reward: 4.22
               Mean episode length: 136.49
       Episode_Reward/keep_balance: 0.1247
     Episode_Reward/rew_lin_vel_xy: 0.1918
      Episode_Reward/rew_ang_vel_z: 0.3672
    Episode_Reward/pen_base_height: -0.1518
      Episode_Reward/pen_lin_vel_z: -0.0173
     Episode_Reward/pen_ang_vel_xy: -0.0273
   Episode_Reward/pen_joint_torque: -0.0206
    Episode_Reward/pen_joint_accel: -0.0130
    Episode_Reward/pen_action_rate: -0.0052
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0050
   Episode_Reward/pen_joint_powers: -0.0074
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0113
Episode_Reward/pen_flat_orientation: -0.0959
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0255
   Episode_Reward/foot_landing_vel: -0.0205
   Episode_Reward/test_gait_reward: -0.1147
Metrics/base_velocity/error_vel_xy: 0.4922
Metrics/base_velocity/error_vel_yaw: 0.1181
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 28.3333
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 1.06s
                        Total time: 367.13s
                               ETA: 2902.2s

################################################################################
                     [1m Learning iteration 337/3000 [0m                      

                       Computation: 93386 steps/s (collection: 0.928s, learning 0.125s)
               Value function loss: 0.5553
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5696
                     Learning rate: 0.0013
                       Mean reward: 6.89
               Mean episode length: 161.34
       Episode_Reward/keep_balance: 0.1387
     Episode_Reward/rew_lin_vel_xy: 0.2243
      Episode_Reward/rew_ang_vel_z: 0.4128
    Episode_Reward/pen_base_height: -0.1601
      Episode_Reward/pen_lin_vel_z: -0.0176
     Episode_Reward/pen_ang_vel_xy: -0.0272
   Episode_Reward/pen_joint_torque: -0.0220
    Episode_Reward/pen_joint_accel: -0.0142
    Episode_Reward/pen_action_rate: -0.0057
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0053
   Episode_Reward/pen_joint_powers: -0.0078
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0125
Episode_Reward/pen_flat_orientation: -0.1060
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0257
   Episode_Reward/foot_landing_vel: -0.0221
   Episode_Reward/test_gait_reward: -0.1262
Metrics/base_velocity/error_vel_xy: 0.5184
Metrics/base_velocity/error_vel_yaw: 0.1292
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 40.6667
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 1.05s
                        Total time: 368.18s
                               ETA: 2900.8s

################################################################################
                     [1m Learning iteration 338/3000 [0m                      

                       Computation: 91082 steps/s (collection: 0.954s, learning 0.125s)
               Value function loss: 0.7711
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5696
                     Learning rate: 0.0019
                       Mean reward: 4.44
               Mean episode length: 130.77
       Episode_Reward/keep_balance: 0.1352
     Episode_Reward/rew_lin_vel_xy: 0.2199
      Episode_Reward/rew_ang_vel_z: 0.4035
    Episode_Reward/pen_base_height: -0.1559
      Episode_Reward/pen_lin_vel_z: -0.0172
     Episode_Reward/pen_ang_vel_xy: -0.0274
   Episode_Reward/pen_joint_torque: -0.0213
    Episode_Reward/pen_joint_accel: -0.0128
    Episode_Reward/pen_action_rate: -0.0055
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0050
   Episode_Reward/pen_joint_powers: -0.0076
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0120
Episode_Reward/pen_flat_orientation: -0.1001
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0243
   Episode_Reward/foot_landing_vel: -0.0209
   Episode_Reward/test_gait_reward: -0.1238
Metrics/base_velocity/error_vel_xy: 0.5208
Metrics/base_velocity/error_vel_yaw: 0.1254
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 31.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 1.08s
                        Total time: 369.26s
                               ETA: 2899.6s

################################################################################
                     [1m Learning iteration 339/3000 [0m                      

                       Computation: 90977 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.9081
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5697
                     Learning rate: 0.0019
                       Mean reward: 3.74
               Mean episode length: 121.55
       Episode_Reward/keep_balance: 0.1255
     Episode_Reward/rew_lin_vel_xy: 0.1809
      Episode_Reward/rew_ang_vel_z: 0.3715
    Episode_Reward/pen_base_height: -0.1502
      Episode_Reward/pen_lin_vel_z: -0.0170
     Episode_Reward/pen_ang_vel_xy: -0.0271
   Episode_Reward/pen_joint_torque: -0.0203
    Episode_Reward/pen_joint_accel: -0.0128
    Episode_Reward/pen_action_rate: -0.0051
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0050
   Episode_Reward/pen_joint_powers: -0.0073
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0112
Episode_Reward/pen_flat_orientation: -0.0936
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0247
   Episode_Reward/foot_landing_vel: -0.0206
   Episode_Reward/test_gait_reward: -0.1150
Metrics/base_velocity/error_vel_xy: 0.5056
Metrics/base_velocity/error_vel_yaw: 0.1182
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 25.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 1.08s
                        Total time: 370.34s
                               ETA: 2898.4s

################################################################################
                     [1m Learning iteration 340/3000 [0m                      

                       Computation: 91833 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 0.7395
                    Surrogate loss: 0.0007
             Mean action noise std: 0.5700
                     Learning rate: 0.0013
                       Mean reward: 3.69
               Mean episode length: 130.10
       Episode_Reward/keep_balance: 0.1146
     Episode_Reward/rew_lin_vel_xy: 0.1636
      Episode_Reward/rew_ang_vel_z: 0.3383
    Episode_Reward/pen_base_height: -0.1466
      Episode_Reward/pen_lin_vel_z: -0.0162
     Episode_Reward/pen_ang_vel_xy: -0.0260
   Episode_Reward/pen_joint_torque: -0.0184
    Episode_Reward/pen_joint_accel: -0.0121
    Episode_Reward/pen_action_rate: -0.0047
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0046
   Episode_Reward/pen_joint_powers: -0.0067
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0103
Episode_Reward/pen_flat_orientation: -0.0902
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0232
   Episode_Reward/foot_landing_vel: -0.0187
   Episode_Reward/test_gait_reward: -0.1069
Metrics/base_velocity/error_vel_xy: 0.4640
Metrics/base_velocity/error_vel_yaw: 0.1084
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 25.1250
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 1.07s
                        Total time: 371.41s
                               ETA: 2897.2s

################################################################################
                     [1m Learning iteration 341/3000 [0m                      

                       Computation: 92760 steps/s (collection: 0.937s, learning 0.122s)
               Value function loss: 0.6802
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5707
                     Learning rate: 0.0013
                       Mean reward: 4.20
               Mean episode length: 135.70
       Episode_Reward/keep_balance: 0.1229
     Episode_Reward/rew_lin_vel_xy: 0.1801
      Episode_Reward/rew_ang_vel_z: 0.3657
    Episode_Reward/pen_base_height: -0.1519
      Episode_Reward/pen_lin_vel_z: -0.0170
     Episode_Reward/pen_ang_vel_xy: -0.0269
   Episode_Reward/pen_joint_torque: -0.0199
    Episode_Reward/pen_joint_accel: -0.0130
    Episode_Reward/pen_action_rate: -0.0050
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0048
   Episode_Reward/pen_joint_powers: -0.0071
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0109
Episode_Reward/pen_flat_orientation: -0.0959
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0243
   Episode_Reward/foot_landing_vel: -0.0199
   Episode_Reward/test_gait_reward: -0.1128
Metrics/base_velocity/error_vel_xy: 0.4862
Metrics/base_velocity/error_vel_yaw: 0.1153
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 26.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 1.06s
                        Total time: 372.47s
                               ETA: 2895.9s

################################################################################
                     [1m Learning iteration 342/3000 [0m                      

                       Computation: 91757 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.7988
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5712
                     Learning rate: 0.0029
                       Mean reward: 3.96
               Mean episode length: 138.31
       Episode_Reward/keep_balance: 0.1293
     Episode_Reward/rew_lin_vel_xy: 0.1966
      Episode_Reward/rew_ang_vel_z: 0.3849
    Episode_Reward/pen_base_height: -0.1531
      Episode_Reward/pen_lin_vel_z: -0.0173
     Episode_Reward/pen_ang_vel_xy: -0.0276
   Episode_Reward/pen_joint_torque: -0.0208
    Episode_Reward/pen_joint_accel: -0.0136
    Episode_Reward/pen_action_rate: -0.0053
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0051
   Episode_Reward/pen_joint_powers: -0.0074
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0115
Episode_Reward/pen_flat_orientation: -0.0972
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0250
   Episode_Reward/foot_landing_vel: -0.0207
   Episode_Reward/test_gait_reward: -0.1191
Metrics/base_velocity/error_vel_xy: 0.5021
Metrics/base_velocity/error_vel_yaw: 0.1202
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 27.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 1.07s
                        Total time: 373.54s
                               ETA: 2894.7s

################################################################################
                     [1m Learning iteration 343/3000 [0m                      

                       Computation: 92277 steps/s (collection: 0.944s, learning 0.121s)
               Value function loss: 0.7213
                    Surrogate loss: 0.0052
             Mean action noise std: 0.5722
                     Learning rate: 0.0003
                       Mean reward: 4.55
               Mean episode length: 143.51
       Episode_Reward/keep_balance: 0.1329
     Episode_Reward/rew_lin_vel_xy: 0.2107
      Episode_Reward/rew_ang_vel_z: 0.3919
    Episode_Reward/pen_base_height: -0.1536
      Episode_Reward/pen_lin_vel_z: -0.0178
     Episode_Reward/pen_ang_vel_xy: -0.0279
   Episode_Reward/pen_joint_torque: -0.0215
    Episode_Reward/pen_joint_accel: -0.0139
    Episode_Reward/pen_action_rate: -0.0055
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0052
   Episode_Reward/pen_joint_powers: -0.0077
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0121
Episode_Reward/pen_flat_orientation: -0.0983
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0266
   Episode_Reward/foot_landing_vel: -0.0220
   Episode_Reward/test_gait_reward: -0.1218
Metrics/base_velocity/error_vel_xy: 0.5157
Metrics/base_velocity/error_vel_yaw: 0.1266
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 26.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 1.07s
                        Total time: 374.61s
                               ETA: 2893.4s

################################################################################
                     [1m Learning iteration 344/3000 [0m                      

                       Computation: 91751 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.6084
                    Surrogate loss: 0.0070
             Mean action noise std: 0.5723
                     Learning rate: 0.0001
                       Mean reward: 4.50
               Mean episode length: 140.35
       Episode_Reward/keep_balance: 0.1377
     Episode_Reward/rew_lin_vel_xy: 0.2313
      Episode_Reward/rew_ang_vel_z: 0.4109
    Episode_Reward/pen_base_height: -0.1553
      Episode_Reward/pen_lin_vel_z: -0.0183
     Episode_Reward/pen_ang_vel_xy: -0.0279
   Episode_Reward/pen_joint_torque: -0.0230
    Episode_Reward/pen_joint_accel: -0.0133
    Episode_Reward/pen_action_rate: -0.0057
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0053
   Episode_Reward/pen_joint_powers: -0.0081
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0123
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0273
   Episode_Reward/foot_landing_vel: -0.0226
   Episode_Reward/test_gait_reward: -0.1257
Metrics/base_velocity/error_vel_xy: 0.5164
Metrics/base_velocity/error_vel_yaw: 0.1271
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 22.9167
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 1.07s
                        Total time: 375.68s
                               ETA: 2892.2s

################################################################################
                     [1m Learning iteration 345/3000 [0m                      

                       Computation: 92675 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 0.5841
                    Surrogate loss: 0.0032
             Mean action noise std: 0.5725
                     Learning rate: 0.0002
                       Mean reward: 4.51
               Mean episode length: 138.99
       Episode_Reward/keep_balance: 0.1436
     Episode_Reward/rew_lin_vel_xy: 0.2327
      Episode_Reward/rew_ang_vel_z: 0.4275
    Episode_Reward/pen_base_height: -0.1587
      Episode_Reward/pen_lin_vel_z: -0.0187
     Episode_Reward/pen_ang_vel_xy: -0.0282
   Episode_Reward/pen_joint_torque: -0.0238
    Episode_Reward/pen_joint_accel: -0.0143
    Episode_Reward/pen_action_rate: -0.0060
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0056
   Episode_Reward/pen_joint_powers: -0.0084
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0130
Episode_Reward/pen_flat_orientation: -0.1036
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0283
   Episode_Reward/foot_landing_vel: -0.0229
   Episode_Reward/test_gait_reward: -0.1311
Metrics/base_velocity/error_vel_xy: 0.5381
Metrics/base_velocity/error_vel_yaw: 0.1330
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 23.4583
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 1.06s
                        Total time: 376.74s
                               ETA: 2890.9s

################################################################################
                     [1m Learning iteration 346/3000 [0m                      

                       Computation: 92828 steps/s (collection: 0.937s, learning 0.122s)
               Value function loss: 0.5776
                    Surrogate loss: 0.0054
             Mean action noise std: 0.5728
                     Learning rate: 0.0001
                       Mean reward: 5.48
               Mean episode length: 146.53
       Episode_Reward/keep_balance: 0.1416
     Episode_Reward/rew_lin_vel_xy: 0.2188
      Episode_Reward/rew_ang_vel_z: 0.4214
    Episode_Reward/pen_base_height: -0.1564
      Episode_Reward/pen_lin_vel_z: -0.0181
     Episode_Reward/pen_ang_vel_xy: -0.0285
   Episode_Reward/pen_joint_torque: -0.0225
    Episode_Reward/pen_joint_accel: -0.0139
    Episode_Reward/pen_action_rate: -0.0059
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0054
   Episode_Reward/pen_joint_powers: -0.0081
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0128
Episode_Reward/pen_flat_orientation: -0.1044
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0270
   Episode_Reward/foot_landing_vel: -0.0219
   Episode_Reward/test_gait_reward: -0.1291
Metrics/base_velocity/error_vel_xy: 0.5462
Metrics/base_velocity/error_vel_yaw: 0.1324
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 23.7917
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 1.06s
                        Total time: 377.80s
                               ETA: 2889.5s

################################################################################
                     [1m Learning iteration 347/3000 [0m                      

                       Computation: 91189 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.5937
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5730
                     Learning rate: 0.0003
                       Mean reward: 4.93
               Mean episode length: 143.92
       Episode_Reward/keep_balance: 0.1504
     Episode_Reward/rew_lin_vel_xy: 0.2464
      Episode_Reward/rew_ang_vel_z: 0.4478
    Episode_Reward/pen_base_height: -0.1595
      Episode_Reward/pen_lin_vel_z: -0.0184
     Episode_Reward/pen_ang_vel_xy: -0.0282
   Episode_Reward/pen_joint_torque: -0.0241
    Episode_Reward/pen_joint_accel: -0.0152
    Episode_Reward/pen_action_rate: -0.0062
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0056
   Episode_Reward/pen_joint_powers: -0.0085
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0135
Episode_Reward/pen_flat_orientation: -0.1066
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0284
   Episode_Reward/foot_landing_vel: -0.0231
   Episode_Reward/test_gait_reward: -0.1361
Metrics/base_velocity/error_vel_xy: 0.5641
Metrics/base_velocity/error_vel_yaw: 0.1392
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 22.6667
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 1.08s
                        Total time: 378.88s
                               ETA: 2888.4s

################################################################################
                     [1m Learning iteration 348/3000 [0m                      

                       Computation: 91892 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.6294
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5731
                     Learning rate: 0.0009
                       Mean reward: 4.54
               Mean episode length: 144.94
       Episode_Reward/keep_balance: 0.1466
     Episode_Reward/rew_lin_vel_xy: 0.2316
      Episode_Reward/rew_ang_vel_z: 0.4370
    Episode_Reward/pen_base_height: -0.1579
      Episode_Reward/pen_lin_vel_z: -0.0182
     Episode_Reward/pen_ang_vel_xy: -0.0286
   Episode_Reward/pen_joint_torque: -0.0238
    Episode_Reward/pen_joint_accel: -0.0144
    Episode_Reward/pen_action_rate: -0.0061
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0056
   Episode_Reward/pen_joint_powers: -0.0084
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0132
Episode_Reward/pen_flat_orientation: -0.1071
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0283
   Episode_Reward/foot_landing_vel: -0.0235
   Episode_Reward/test_gait_reward: -0.1344
Metrics/base_velocity/error_vel_xy: 0.5635
Metrics/base_velocity/error_vel_yaw: 0.1357
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 24.5833
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 1.07s
                        Total time: 379.94s
                               ETA: 2887.1s

################################################################################
                     [1m Learning iteration 349/3000 [0m                      

                       Computation: 92477 steps/s (collection: 0.938s, learning 0.125s)
               Value function loss: 0.8000
                    Surrogate loss: -0.0008
             Mean action noise std: 0.5731
                     Learning rate: 0.0013
                       Mean reward: 5.24
               Mean episode length: 144.11
       Episode_Reward/keep_balance: 0.1531
     Episode_Reward/rew_lin_vel_xy: 0.2369
      Episode_Reward/rew_ang_vel_z: 0.4574
    Episode_Reward/pen_base_height: -0.1605
      Episode_Reward/pen_lin_vel_z: -0.0192
     Episode_Reward/pen_ang_vel_xy: -0.0293
   Episode_Reward/pen_joint_torque: -0.0249
    Episode_Reward/pen_joint_accel: -0.0158
    Episode_Reward/pen_action_rate: -0.0064
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0060
   Episode_Reward/pen_joint_powers: -0.0088
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0138
Episode_Reward/pen_flat_orientation: -0.1076
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0309
   Episode_Reward/foot_landing_vel: -0.0250
   Episode_Reward/test_gait_reward: -0.1389
Metrics/base_velocity/error_vel_xy: 0.5830
Metrics/base_velocity/error_vel_yaw: 0.1415
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 23.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 1.06s
                        Total time: 381.01s
                               ETA: 2885.9s

################################################################################
                     [1m Learning iteration 350/3000 [0m                      

                       Computation: 91645 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.6447
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5730
                     Learning rate: 0.0009
                       Mean reward: 5.77
               Mean episode length: 151.43
       Episode_Reward/keep_balance: 0.1441
     Episode_Reward/rew_lin_vel_xy: 0.2317
      Episode_Reward/rew_ang_vel_z: 0.4307
    Episode_Reward/pen_base_height: -0.1587
      Episode_Reward/pen_lin_vel_z: -0.0183
     Episode_Reward/pen_ang_vel_xy: -0.0281
   Episode_Reward/pen_joint_torque: -0.0234
    Episode_Reward/pen_joint_accel: -0.0137
    Episode_Reward/pen_action_rate: -0.0060
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0056
   Episode_Reward/pen_joint_powers: -0.0084
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0129
Episode_Reward/pen_flat_orientation: -0.1049
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0289
   Episode_Reward/foot_landing_vel: -0.0228
   Episode_Reward/test_gait_reward: -0.1313
Metrics/base_velocity/error_vel_xy: 0.5488
Metrics/base_velocity/error_vel_yaw: 0.1326
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 19.7917
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 1.07s
                        Total time: 382.08s
                               ETA: 2884.7s

################################################################################
                     [1m Learning iteration 351/3000 [0m                      

                       Computation: 89733 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.7046
                    Surrogate loss: 0.0002
             Mean action noise std: 0.5732
                     Learning rate: 0.0006
                       Mean reward: 6.98
               Mean episode length: 174.54
       Episode_Reward/keep_balance: 0.1678
     Episode_Reward/rew_lin_vel_xy: 0.2868
      Episode_Reward/rew_ang_vel_z: 0.5002
    Episode_Reward/pen_base_height: -0.1663
      Episode_Reward/pen_lin_vel_z: -0.0200
     Episode_Reward/pen_ang_vel_xy: -0.0300
   Episode_Reward/pen_joint_torque: -0.0267
    Episode_Reward/pen_joint_accel: -0.0166
    Episode_Reward/pen_action_rate: -0.0071
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0064
   Episode_Reward/pen_joint_powers: -0.0096
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0153
Episode_Reward/pen_flat_orientation: -0.1182
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0319
   Episode_Reward/foot_landing_vel: -0.0266
   Episode_Reward/test_gait_reward: -0.1526
Metrics/base_velocity/error_vel_xy: 0.6210
Metrics/base_velocity/error_vel_yaw: 0.1552
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 29.0833
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 1.10s
                        Total time: 383.18s
                               ETA: 2883.6s

################################################################################
                     [1m Learning iteration 352/3000 [0m                      

                       Computation: 91547 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 0.7080
                    Surrogate loss: 0.0021
             Mean action noise std: 0.5736
                     Learning rate: 0.0006
                       Mean reward: 6.87
               Mean episode length: 178.13
       Episode_Reward/keep_balance: 0.1647
     Episode_Reward/rew_lin_vel_xy: 0.2866
      Episode_Reward/rew_ang_vel_z: 0.4922
    Episode_Reward/pen_base_height: -0.1665
      Episode_Reward/pen_lin_vel_z: -0.0196
     Episode_Reward/pen_ang_vel_xy: -0.0298
   Episode_Reward/pen_joint_torque: -0.0261
    Episode_Reward/pen_joint_accel: -0.0161
    Episode_Reward/pen_action_rate: -0.0069
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0062
   Episode_Reward/pen_joint_powers: -0.0093
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0149
Episode_Reward/pen_flat_orientation: -0.1138
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0315
   Episode_Reward/foot_landing_vel: -0.0262
   Episode_Reward/test_gait_reward: -0.1498
Metrics/base_velocity/error_vel_xy: 0.6009
Metrics/base_velocity/error_vel_yaw: 0.1513
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 24.7083
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 1.07s
                        Total time: 384.25s
                               ETA: 2882.4s

################################################################################
                     [1m Learning iteration 353/3000 [0m                      

                       Computation: 91840 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.6612
                    Surrogate loss: 0.0002
             Mean action noise std: 0.5730
                     Learning rate: 0.0006
                       Mean reward: 6.30
               Mean episode length: 166.81
       Episode_Reward/keep_balance: 0.1561
     Episode_Reward/rew_lin_vel_xy: 0.2632
      Episode_Reward/rew_ang_vel_z: 0.4657
    Episode_Reward/pen_base_height: -0.1622
      Episode_Reward/pen_lin_vel_z: -0.0186
     Episode_Reward/pen_ang_vel_xy: -0.0291
   Episode_Reward/pen_joint_torque: -0.0247
    Episode_Reward/pen_joint_accel: -0.0150
    Episode_Reward/pen_action_rate: -0.0065
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0059
   Episode_Reward/pen_joint_powers: -0.0089
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0141
Episode_Reward/pen_flat_orientation: -0.1136
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0306
   Episode_Reward/foot_landing_vel: -0.0239
   Episode_Reward/test_gait_reward: -0.1423
Metrics/base_velocity/error_vel_xy: 0.5714
Metrics/base_velocity/error_vel_yaw: 0.1445
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 17.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 1.07s
                        Total time: 385.32s
                               ETA: 2881.2s

################################################################################
                     [1m Learning iteration 354/3000 [0m                      

                       Computation: 91717 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 0.7405
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5728
                     Learning rate: 0.0013
                       Mean reward: 6.64
               Mean episode length: 161.97
       Episode_Reward/keep_balance: 0.1686
     Episode_Reward/rew_lin_vel_xy: 0.2704
      Episode_Reward/rew_ang_vel_z: 0.5058
    Episode_Reward/pen_base_height: -0.1692
      Episode_Reward/pen_lin_vel_z: -0.0200
     Episode_Reward/pen_ang_vel_xy: -0.0299
   Episode_Reward/pen_joint_torque: -0.0270
    Episode_Reward/pen_joint_accel: -0.0164
    Episode_Reward/pen_action_rate: -0.0071
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0064
   Episode_Reward/pen_joint_powers: -0.0097
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0153
Episode_Reward/pen_flat_orientation: -0.1206
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0319
   Episode_Reward/foot_landing_vel: -0.0267
   Episode_Reward/test_gait_reward: -0.1534
Metrics/base_velocity/error_vel_xy: 0.6218
Metrics/base_velocity/error_vel_yaw: 0.1541
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 23.5833
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 1.07s
                        Total time: 386.39s
                               ETA: 2880.0s

################################################################################
                     [1m Learning iteration 355/3000 [0m                      

                       Computation: 92003 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.8465
                    Surrogate loss: -0.0016
             Mean action noise std: 0.5740
                     Learning rate: 0.0029
                       Mean reward: 6.57
               Mean episode length: 148.63
       Episode_Reward/keep_balance: 0.1590
     Episode_Reward/rew_lin_vel_xy: 0.2849
      Episode_Reward/rew_ang_vel_z: 0.4743
    Episode_Reward/pen_base_height: -0.1652
      Episode_Reward/pen_lin_vel_z: -0.0185
     Episode_Reward/pen_ang_vel_xy: -0.0283
   Episode_Reward/pen_joint_torque: -0.0245
    Episode_Reward/pen_joint_accel: -0.0155
    Episode_Reward/pen_action_rate: -0.0066
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0059
   Episode_Reward/pen_joint_powers: -0.0088
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0144
Episode_Reward/pen_flat_orientation: -0.1169
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0290
   Episode_Reward/foot_landing_vel: -0.0242
   Episode_Reward/test_gait_reward: -0.1465
Metrics/base_velocity/error_vel_xy: 0.5695
Metrics/base_velocity/error_vel_yaw: 0.1472
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 23.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 1.07s
                        Total time: 387.46s
                               ETA: 2878.7s

################################################################################
                     [1m Learning iteration 356/3000 [0m                      

                       Computation: 90490 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.7304
                    Surrogate loss: 0.0021
             Mean action noise std: 0.5747
                     Learning rate: 0.0013
                       Mean reward: 5.98
               Mean episode length: 162.82
       Episode_Reward/keep_balance: 0.1693
     Episode_Reward/rew_lin_vel_xy: 0.2818
      Episode_Reward/rew_ang_vel_z: 0.5085
    Episode_Reward/pen_base_height: -0.1672
      Episode_Reward/pen_lin_vel_z: -0.0188
     Episode_Reward/pen_ang_vel_xy: -0.0290
   Episode_Reward/pen_joint_torque: -0.0259
    Episode_Reward/pen_joint_accel: -0.0154
    Episode_Reward/pen_action_rate: -0.0070
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0060
   Episode_Reward/pen_joint_powers: -0.0092
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0153
Episode_Reward/pen_flat_orientation: -0.1194
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0297
   Episode_Reward/foot_landing_vel: -0.0254
   Episode_Reward/test_gait_reward: -0.1531
Metrics/base_velocity/error_vel_xy: 0.6193
Metrics/base_velocity/error_vel_yaw: 0.1540
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 23.2500
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 1.09s
                        Total time: 388.55s
                               ETA: 2877.6s

################################################################################
                     [1m Learning iteration 357/3000 [0m                      

                       Computation: 91109 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.7290
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5752
                     Learning rate: 0.0013
                       Mean reward: 6.82
               Mean episode length: 158.15
       Episode_Reward/keep_balance: 0.1657
     Episode_Reward/rew_lin_vel_xy: 0.2842
      Episode_Reward/rew_ang_vel_z: 0.4993
    Episode_Reward/pen_base_height: -0.1648
      Episode_Reward/pen_lin_vel_z: -0.0187
     Episode_Reward/pen_ang_vel_xy: -0.0288
   Episode_Reward/pen_joint_torque: -0.0254
    Episode_Reward/pen_joint_accel: -0.0166
    Episode_Reward/pen_action_rate: -0.0068
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0059
   Episode_Reward/pen_joint_powers: -0.0090
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0150
Episode_Reward/pen_flat_orientation: -0.1142
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0282
   Episode_Reward/foot_landing_vel: -0.0248
   Episode_Reward/test_gait_reward: -0.1505
Metrics/base_velocity/error_vel_xy: 0.5958
Metrics/base_velocity/error_vel_yaw: 0.1499
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 21.7500
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 1.08s
                        Total time: 389.63s
                               ETA: 2876.5s

################################################################################
                     [1m Learning iteration 358/3000 [0m                      

                       Computation: 91731 steps/s (collection: 0.950s, learning 0.121s)
               Value function loss: 0.8149
                    Surrogate loss: 0.0076
             Mean action noise std: 0.5753
                     Learning rate: 0.0002
                       Mean reward: 5.99
               Mean episode length: 157.89
       Episode_Reward/keep_balance: 0.1752
     Episode_Reward/rew_lin_vel_xy: 0.2972
      Episode_Reward/rew_ang_vel_z: 0.5303
    Episode_Reward/pen_base_height: -0.1708
      Episode_Reward/pen_lin_vel_z: -0.0202
     Episode_Reward/pen_ang_vel_xy: -0.0298
   Episode_Reward/pen_joint_torque: -0.0284
    Episode_Reward/pen_joint_accel: -0.0165
    Episode_Reward/pen_action_rate: -0.0073
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0064
   Episode_Reward/pen_joint_powers: -0.0099
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0157
Episode_Reward/pen_flat_orientation: -0.1189
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0318
   Episode_Reward/foot_landing_vel: -0.0266
   Episode_Reward/test_gait_reward: -0.1586
Metrics/base_velocity/error_vel_xy: 0.6396
Metrics/base_velocity/error_vel_yaw: 0.1557
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 18.1250
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 1.07s
                        Total time: 390.70s
                               ETA: 2875.3s

################################################################################
                     [1m Learning iteration 359/3000 [0m                      

                       Computation: 90801 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.6012
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5753
                     Learning rate: 0.0006
                       Mean reward: 6.78
               Mean episode length: 167.53
       Episode_Reward/keep_balance: 0.1601
     Episode_Reward/rew_lin_vel_xy: 0.2792
      Episode_Reward/rew_ang_vel_z: 0.4763
    Episode_Reward/pen_base_height: -0.1647
      Episode_Reward/pen_lin_vel_z: -0.0186
     Episode_Reward/pen_ang_vel_xy: -0.0286
   Episode_Reward/pen_joint_torque: -0.0255
    Episode_Reward/pen_joint_accel: -0.0157
    Episode_Reward/pen_action_rate: -0.0068
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0060
   Episode_Reward/pen_joint_powers: -0.0090
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0147
Episode_Reward/pen_flat_orientation: -0.1124
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0302
   Episode_Reward/foot_landing_vel: -0.0247
   Episode_Reward/test_gait_reward: -0.1469
Metrics/base_velocity/error_vel_xy: 0.5902
Metrics/base_velocity/error_vel_yaw: 0.1490
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 1.08s
                        Total time: 391.78s
                               ETA: 2874.1s

################################################################################
                     [1m Learning iteration 360/3000 [0m                      

                       Computation: 90678 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.6288
                    Surrogate loss: 0.0010
             Mean action noise std: 0.5749
                     Learning rate: 0.0006
                       Mean reward: 6.28
               Mean episode length: 165.82
       Episode_Reward/keep_balance: 0.1530
     Episode_Reward/rew_lin_vel_xy: 0.2512
      Episode_Reward/rew_ang_vel_z: 0.4608
    Episode_Reward/pen_base_height: -0.1611
      Episode_Reward/pen_lin_vel_z: -0.0177
     Episode_Reward/pen_ang_vel_xy: -0.0279
   Episode_Reward/pen_joint_torque: -0.0241
    Episode_Reward/pen_joint_accel: -0.0143
    Episode_Reward/pen_action_rate: -0.0064
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0056
   Episode_Reward/pen_joint_powers: -0.0085
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0139
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0285
   Episode_Reward/foot_landing_vel: -0.0230
   Episode_Reward/test_gait_reward: -0.1405
Metrics/base_velocity/error_vel_xy: 0.5556
Metrics/base_velocity/error_vel_yaw: 0.1380
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 17.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 1.08s
                        Total time: 392.86s
                               ETA: 2873.0s

################################################################################
                     [1m Learning iteration 361/3000 [0m                      

                       Computation: 91536 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.6028
                    Surrogate loss: 0.0004
             Mean action noise std: 0.5752
                     Learning rate: 0.0006
                       Mean reward: 6.31
               Mean episode length: 169.24
       Episode_Reward/keep_balance: 0.1675
     Episode_Reward/rew_lin_vel_xy: 0.2892
      Episode_Reward/rew_ang_vel_z: 0.5013
    Episode_Reward/pen_base_height: -0.1660
      Episode_Reward/pen_lin_vel_z: -0.0185
     Episode_Reward/pen_ang_vel_xy: -0.0290
   Episode_Reward/pen_joint_torque: -0.0261
    Episode_Reward/pen_joint_accel: -0.0167
    Episode_Reward/pen_action_rate: -0.0071
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0061
   Episode_Reward/pen_joint_powers: -0.0092
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0154
Episode_Reward/pen_flat_orientation: -0.1172
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0305
   Episode_Reward/foot_landing_vel: -0.0256
   Episode_Reward/test_gait_reward: -0.1534
Metrics/base_velocity/error_vel_xy: 0.5962
Metrics/base_velocity/error_vel_yaw: 0.1536
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 17.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 1.07s
                        Total time: 393.94s
                               ETA: 2871.8s

################################################################################
                     [1m Learning iteration 362/3000 [0m                      

                       Computation: 90930 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.5766
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5763
                     Learning rate: 0.0013
                       Mean reward: 7.28
               Mean episode length: 176.38
       Episode_Reward/keep_balance: 0.1728
     Episode_Reward/rew_lin_vel_xy: 0.2931
      Episode_Reward/rew_ang_vel_z: 0.5218
    Episode_Reward/pen_base_height: -0.1681
      Episode_Reward/pen_lin_vel_z: -0.0187
     Episode_Reward/pen_ang_vel_xy: -0.0287
   Episode_Reward/pen_joint_torque: -0.0272
    Episode_Reward/pen_joint_accel: -0.0171
    Episode_Reward/pen_action_rate: -0.0073
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0061
   Episode_Reward/pen_joint_powers: -0.0095
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0159
Episode_Reward/pen_flat_orientation: -0.1203
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0294
   Episode_Reward/foot_landing_vel: -0.0257
   Episode_Reward/test_gait_reward: -0.1572
Metrics/base_velocity/error_vel_xy: 0.6283
Metrics/base_velocity/error_vel_yaw: 0.1547
      Episode_Termination/time_out: 0.0833
  Episode_Termination/base_contact: 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 1.08s
                        Total time: 395.02s
                               ETA: 2870.7s

################################################################################
                     [1m Learning iteration 363/3000 [0m                      

                       Computation: 91025 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.7179
                    Surrogate loss: 0.0007
             Mean action noise std: 0.5760
                     Learning rate: 0.0006
                       Mean reward: 7.87
               Mean episode length: 183.18
       Episode_Reward/keep_balance: 0.1912
     Episode_Reward/rew_lin_vel_xy: 0.3399
      Episode_Reward/rew_ang_vel_z: 0.5800
    Episode_Reward/pen_base_height: -0.1749
      Episode_Reward/pen_lin_vel_z: -0.0200
     Episode_Reward/pen_ang_vel_xy: -0.0301
   Episode_Reward/pen_joint_torque: -0.0298
    Episode_Reward/pen_joint_accel: -0.0176
    Episode_Reward/pen_action_rate: -0.0081
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0067
   Episode_Reward/pen_joint_powers: -0.0104
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0175
Episode_Reward/pen_flat_orientation: -0.1255
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0326
   Episode_Reward/foot_landing_vel: -0.0286
   Episode_Reward/test_gait_reward: -0.1740
Metrics/base_velocity/error_vel_xy: 0.6724
Metrics/base_velocity/error_vel_yaw: 0.1690
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 19.5000
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 1.08s
                        Total time: 396.10s
                               ETA: 2869.5s

################################################################################
                     [1m Learning iteration 364/3000 [0m                      

                       Computation: 89196 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.7556
                    Surrogate loss: 0.0018
             Mean action noise std: 0.5758
                     Learning rate: 0.0004
                       Mean reward: 6.31
               Mean episode length: 175.91
       Episode_Reward/keep_balance: 0.1835
     Episode_Reward/rew_lin_vel_xy: 0.3028
      Episode_Reward/rew_ang_vel_z: 0.5513
    Episode_Reward/pen_base_height: -0.1704
      Episode_Reward/pen_lin_vel_z: -0.0197
     Episode_Reward/pen_ang_vel_xy: -0.0299
   Episode_Reward/pen_joint_torque: -0.0290
    Episode_Reward/pen_joint_accel: -0.0173
    Episode_Reward/pen_action_rate: -0.0078
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0067
   Episode_Reward/pen_joint_powers: -0.0102
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0168
Episode_Reward/pen_flat_orientation: -0.1224
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0337
   Episode_Reward/foot_landing_vel: -0.0285
   Episode_Reward/test_gait_reward: -0.1690
Metrics/base_velocity/error_vel_xy: 0.6827
Metrics/base_velocity/error_vel_yaw: 0.1657
      Episode_Termination/time_out: 0.1250
  Episode_Termination/base_contact: 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 1.10s
                        Total time: 397.20s
                               ETA: 2868.6s

################################################################################
                     [1m Learning iteration 365/3000 [0m                      

                       Computation: 90500 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.6164
                    Surrogate loss: 0.0032
             Mean action noise std: 0.5763
                     Learning rate: 0.0004
                       Mean reward: 8.27
               Mean episode length: 197.12
       Episode_Reward/keep_balance: 0.1717
     Episode_Reward/rew_lin_vel_xy: 0.2797
      Episode_Reward/rew_ang_vel_z: 0.5131
    Episode_Reward/pen_base_height: -0.1690
      Episode_Reward/pen_lin_vel_z: -0.0190
     Episode_Reward/pen_ang_vel_xy: -0.0295
   Episode_Reward/pen_joint_torque: -0.0263
    Episode_Reward/pen_joint_accel: -0.0174
    Episode_Reward/pen_action_rate: -0.0074
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0064
   Episode_Reward/pen_joint_powers: -0.0095
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0159
Episode_Reward/pen_flat_orientation: -0.1222
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0315
   Episode_Reward/foot_landing_vel: -0.0258
   Episode_Reward/test_gait_reward: -0.1584
Metrics/base_velocity/error_vel_xy: 0.6267
Metrics/base_velocity/error_vel_yaw: 0.1578
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 1.09s
                        Total time: 398.29s
                               ETA: 2867.5s

################################################################################
                     [1m Learning iteration 366/3000 [0m                      

                       Computation: 90285 steps/s (collection: 0.963s, learning 0.126s)
               Value function loss: 0.5914
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5762
                     Learning rate: 0.0009
                       Mean reward: 10.97
               Mean episode length: 224.96
       Episode_Reward/keep_balance: 0.1970
     Episode_Reward/rew_lin_vel_xy: 0.3425
      Episode_Reward/rew_ang_vel_z: 0.5974
    Episode_Reward/pen_base_height: -0.1773
      Episode_Reward/pen_lin_vel_z: -0.0204
     Episode_Reward/pen_ang_vel_xy: -0.0307
   Episode_Reward/pen_joint_torque: -0.0306
    Episode_Reward/pen_joint_accel: -0.0191
    Episode_Reward/pen_action_rate: -0.0085
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0070
   Episode_Reward/pen_joint_powers: -0.0107
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0182
Episode_Reward/pen_flat_orientation: -0.1309
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0335
   Episode_Reward/foot_landing_vel: -0.0294
   Episode_Reward/test_gait_reward: -0.1794
Metrics/base_velocity/error_vel_xy: 0.6973
Metrics/base_velocity/error_vel_yaw: 0.1748
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 22.5000
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 1.09s
                        Total time: 399.38s
                               ETA: 2866.4s

################################################################################
                     [1m Learning iteration 367/3000 [0m                      

                       Computation: 90465 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.8113
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5764
                     Learning rate: 0.0009
                       Mean reward: 11.82
               Mean episode length: 220.25
       Episode_Reward/keep_balance: 0.2314
     Episode_Reward/rew_lin_vel_xy: 0.4236
      Episode_Reward/rew_ang_vel_z: 0.6988
    Episode_Reward/pen_base_height: -0.1898
      Episode_Reward/pen_lin_vel_z: -0.0227
     Episode_Reward/pen_ang_vel_xy: -0.0342
   Episode_Reward/pen_joint_torque: -0.0358
    Episode_Reward/pen_joint_accel: -0.0218
    Episode_Reward/pen_action_rate: -0.0101
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0082
   Episode_Reward/pen_joint_powers: -0.0125
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0216
Episode_Reward/pen_flat_orientation: -0.1467
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0400
   Episode_Reward/foot_landing_vel: -0.0343
   Episode_Reward/test_gait_reward: -0.2106
Metrics/base_velocity/error_vel_xy: 0.8090
Metrics/base_velocity/error_vel_yaw: 0.2061
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 1.09s
                        Total time: 400.46s
                               ETA: 2865.3s

################################################################################
                     [1m Learning iteration 368/3000 [0m                      

                       Computation: 91355 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.6071
                    Surrogate loss: 0.0014
             Mean action noise std: 0.5770
                     Learning rate: 0.0004
                       Mean reward: 6.21
               Mean episode length: 173.78
       Episode_Reward/keep_balance: 0.1947
     Episode_Reward/rew_lin_vel_xy: 0.3207
      Episode_Reward/rew_ang_vel_z: 0.5841
    Episode_Reward/pen_base_height: -0.1745
      Episode_Reward/pen_lin_vel_z: -0.0200
     Episode_Reward/pen_ang_vel_xy: -0.0309
   Episode_Reward/pen_joint_torque: -0.0301
    Episode_Reward/pen_joint_accel: -0.0187
    Episode_Reward/pen_action_rate: -0.0084
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0069
   Episode_Reward/pen_joint_powers: -0.0106
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0183
Episode_Reward/pen_flat_orientation: -0.1306
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0333
   Episode_Reward/foot_landing_vel: -0.0291
   Episode_Reward/test_gait_reward: -0.1778
Metrics/base_velocity/error_vel_xy: 0.6983
Metrics/base_velocity/error_vel_yaw: 0.1770
      Episode_Termination/time_out: 0.0833
  Episode_Termination/base_contact: 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 1.08s
                        Total time: 401.54s
                               ETA: 2864.1s

################################################################################
                     [1m Learning iteration 369/3000 [0m                      

                       Computation: 90670 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.5725
                    Surrogate loss: 0.0011
             Mean action noise std: 0.5776
                     Learning rate: 0.0006
                       Mean reward: 10.01
               Mean episode length: 210.89
       Episode_Reward/keep_balance: 0.2075
     Episode_Reward/rew_lin_vel_xy: 0.3685
      Episode_Reward/rew_ang_vel_z: 0.6268
    Episode_Reward/pen_base_height: -0.1811
      Episode_Reward/pen_lin_vel_z: -0.0214
     Episode_Reward/pen_ang_vel_xy: -0.0318
   Episode_Reward/pen_joint_torque: -0.0331
    Episode_Reward/pen_joint_accel: -0.0198
    Episode_Reward/pen_action_rate: -0.0090
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0074
   Episode_Reward/pen_joint_powers: -0.0114
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0193
Episode_Reward/pen_flat_orientation: -0.1405
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0367
   Episode_Reward/foot_landing_vel: -0.0313
   Episode_Reward/test_gait_reward: -0.1902
Metrics/base_velocity/error_vel_xy: 0.7299
Metrics/base_velocity/error_vel_yaw: 0.1851
      Episode_Termination/time_out: 0.1250
  Episode_Termination/base_contact: 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 1.08s
                        Total time: 402.62s
                               ETA: 2863.0s

################################################################################
                     [1m Learning iteration 370/3000 [0m                      

                       Computation: 90871 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.5757
                    Surrogate loss: 0.0016
             Mean action noise std: 0.5777
                     Learning rate: 0.0009
                       Mean reward: 11.50
               Mean episode length: 234.50
       Episode_Reward/keep_balance: 0.2156
     Episode_Reward/rew_lin_vel_xy: 0.3669
      Episode_Reward/rew_ang_vel_z: 0.6503
    Episode_Reward/pen_base_height: -0.1830
      Episode_Reward/pen_lin_vel_z: -0.0223
     Episode_Reward/pen_ang_vel_xy: -0.0329
   Episode_Reward/pen_joint_torque: -0.0340
    Episode_Reward/pen_joint_accel: -0.0210
    Episode_Reward/pen_action_rate: -0.0095
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0079
   Episode_Reward/pen_joint_powers: -0.0120
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0202
Episode_Reward/pen_flat_orientation: -0.1444
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0394
   Episode_Reward/foot_landing_vel: -0.0334
   Episode_Reward/test_gait_reward: -0.1984
Metrics/base_velocity/error_vel_xy: 0.7651
Metrics/base_velocity/error_vel_yaw: 0.1930
      Episode_Termination/time_out: 0.1667
  Episode_Termination/base_contact: 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 1.08s
                        Total time: 403.71s
                               ETA: 2861.8s

################################################################################
                     [1m Learning iteration 371/3000 [0m                      

                       Computation: 90589 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.7602
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5781
                     Learning rate: 0.0013
                       Mean reward: 10.29
               Mean episode length: 230.35
       Episode_Reward/keep_balance: 0.2017
     Episode_Reward/rew_lin_vel_xy: 0.3366
      Episode_Reward/rew_ang_vel_z: 0.6123
    Episode_Reward/pen_base_height: -0.1778
      Episode_Reward/pen_lin_vel_z: -0.0203
     Episode_Reward/pen_ang_vel_xy: -0.0312
   Episode_Reward/pen_joint_torque: -0.0311
    Episode_Reward/pen_joint_accel: -0.0204
    Episode_Reward/pen_action_rate: -0.0087
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0072
   Episode_Reward/pen_joint_powers: -0.0109
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0188
Episode_Reward/pen_flat_orientation: -0.1328
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0339
   Episode_Reward/foot_landing_vel: -0.0306
   Episode_Reward/test_gait_reward: -0.1838
Metrics/base_velocity/error_vel_xy: 0.7141
Metrics/base_velocity/error_vel_yaw: 0.1782
      Episode_Termination/time_out: 0.2083
  Episode_Termination/base_contact: 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 1.09s
                        Total time: 404.79s
                               ETA: 2860.7s

################################################################################
                     [1m Learning iteration 372/3000 [0m                      

                       Computation: 90683 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.7097
                    Surrogate loss: 0.0010
             Mean action noise std: 0.5786
                     Learning rate: 0.0013
                       Mean reward: 8.39
               Mean episode length: 206.06
       Episode_Reward/keep_balance: 0.2000
     Episode_Reward/rew_lin_vel_xy: 0.3290
      Episode_Reward/rew_ang_vel_z: 0.6034
    Episode_Reward/pen_base_height: -0.1787
      Episode_Reward/pen_lin_vel_z: -0.0208
     Episode_Reward/pen_ang_vel_xy: -0.0311
   Episode_Reward/pen_joint_torque: -0.0312
    Episode_Reward/pen_joint_accel: -0.0191
    Episode_Reward/pen_action_rate: -0.0087
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0072
   Episode_Reward/pen_joint_powers: -0.0109
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0187
Episode_Reward/pen_flat_orientation: -0.1366
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0357
   Episode_Reward/foot_landing_vel: -0.0297
   Episode_Reward/test_gait_reward: -0.1843
Metrics/base_velocity/error_vel_xy: 0.7144
Metrics/base_velocity/error_vel_yaw: 0.1801
      Episode_Termination/time_out: 0.1667
  Episode_Termination/base_contact: 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 1.08s
                        Total time: 405.87s
                               ETA: 2859.6s

################################################################################
                     [1m Learning iteration 373/3000 [0m                      

                       Computation: 90985 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.6981
                    Surrogate loss: -0.0027
             Mean action noise std: 0.5781
                     Learning rate: 0.0019
                       Mean reward: 9.41
               Mean episode length: 222.07
       Episode_Reward/keep_balance: 0.2082
     Episode_Reward/rew_lin_vel_xy: 0.3609
      Episode_Reward/rew_ang_vel_z: 0.6286
    Episode_Reward/pen_base_height: -0.1775
      Episode_Reward/pen_lin_vel_z: -0.0212
     Episode_Reward/pen_ang_vel_xy: -0.0322
   Episode_Reward/pen_joint_torque: -0.0330
    Episode_Reward/pen_joint_accel: -0.0203
    Episode_Reward/pen_action_rate: -0.0091
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0075
   Episode_Reward/pen_joint_powers: -0.0115
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0196
Episode_Reward/pen_flat_orientation: -0.1382
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0361
   Episode_Reward/foot_landing_vel: -0.0313
   Episode_Reward/test_gait_reward: -0.1902
Metrics/base_velocity/error_vel_xy: 0.7382
Metrics/base_velocity/error_vel_yaw: 0.1863
      Episode_Termination/time_out: 0.1667
  Episode_Termination/base_contact: 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 1.08s
                        Total time: 406.95s
                               ETA: 2858.5s

################################################################################
                     [1m Learning iteration 374/3000 [0m                      

                       Computation: 90003 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 0.7756
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5777
                     Learning rate: 0.0013
                       Mean reward: 9.32
               Mean episode length: 208.25
       Episode_Reward/keep_balance: 0.2191
     Episode_Reward/rew_lin_vel_xy: 0.3885
      Episode_Reward/rew_ang_vel_z: 0.6646
    Episode_Reward/pen_base_height: -0.1828
      Episode_Reward/pen_lin_vel_z: -0.0213
     Episode_Reward/pen_ang_vel_xy: -0.0326
   Episode_Reward/pen_joint_torque: -0.0334
    Episode_Reward/pen_joint_accel: -0.0197
    Episode_Reward/pen_action_rate: -0.0096
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0076
   Episode_Reward/pen_joint_powers: -0.0117
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0207
Episode_Reward/pen_flat_orientation: -0.1416
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0371
   Episode_Reward/foot_landing_vel: -0.0328
   Episode_Reward/test_gait_reward: -0.1992
Metrics/base_velocity/error_vel_xy: 0.7707
Metrics/base_velocity/error_vel_yaw: 0.1939
      Episode_Termination/time_out: 0.1667
  Episode_Termination/base_contact: 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 1.09s
                        Total time: 408.05s
                               ETA: 2857.4s

################################################################################
                     [1m Learning iteration 375/3000 [0m                      

                       Computation: 91029 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.7319
                    Surrogate loss: 0.0012
             Mean action noise std: 0.5779
                     Learning rate: 0.0004
                       Mean reward: 10.61
               Mean episode length: 227.07
       Episode_Reward/keep_balance: 0.2310
     Episode_Reward/rew_lin_vel_xy: 0.4090
      Episode_Reward/rew_ang_vel_z: 0.6901
    Episode_Reward/pen_base_height: -0.1856
      Episode_Reward/pen_lin_vel_z: -0.0229
     Episode_Reward/pen_ang_vel_xy: -0.0335
   Episode_Reward/pen_joint_torque: -0.0366
    Episode_Reward/pen_joint_accel: -0.0221
    Episode_Reward/pen_action_rate: -0.0102
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0083
   Episode_Reward/pen_joint_powers: -0.0127
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0220
Episode_Reward/pen_flat_orientation: -0.1482
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0414
   Episode_Reward/foot_landing_vel: -0.0342
   Episode_Reward/test_gait_reward: -0.2098
Metrics/base_velocity/error_vel_xy: 0.7882
Metrics/base_velocity/error_vel_yaw: 0.2123
      Episode_Termination/time_out: 0.3333
  Episode_Termination/base_contact: 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 1.08s
                        Total time: 409.13s
                               ETA: 2856.3s

################################################################################
                     [1m Learning iteration 376/3000 [0m                      

                       Computation: 89758 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 0.7245
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5782
                     Learning rate: 0.0009
                       Mean reward: 11.43
               Mean episode length: 244.62
       Episode_Reward/keep_balance: 0.2455
     Episode_Reward/rew_lin_vel_xy: 0.4086
      Episode_Reward/rew_ang_vel_z: 0.7351
    Episode_Reward/pen_base_height: -0.1928
      Episode_Reward/pen_lin_vel_z: -0.0255
     Episode_Reward/pen_ang_vel_xy: -0.0359
   Episode_Reward/pen_joint_torque: -0.0409
    Episode_Reward/pen_joint_accel: -0.0249
    Episode_Reward/pen_action_rate: -0.0112
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0094
   Episode_Reward/pen_joint_powers: -0.0143
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0236
Episode_Reward/pen_flat_orientation: -0.1607
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0455
   Episode_Reward/foot_landing_vel: -0.0416
   Episode_Reward/test_gait_reward: -0.2261
Metrics/base_velocity/error_vel_xy: 0.8609
Metrics/base_velocity/error_vel_yaw: 0.2240
      Episode_Termination/time_out: 0.6250
  Episode_Termination/base_contact: 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 1.10s
                        Total time: 410.22s
                               ETA: 2855.2s

################################################################################
                     [1m Learning iteration 377/3000 [0m                      

                       Computation: 89487 steps/s (collection: 0.976s, learning 0.122s)
               Value function loss: 0.5987
                    Surrogate loss: 0.0015
             Mean action noise std: 0.5785
                     Learning rate: 0.0006
                       Mean reward: 11.66
               Mean episode length: 227.21
       Episode_Reward/keep_balance: 0.2265
     Episode_Reward/rew_lin_vel_xy: 0.3976
      Episode_Reward/rew_ang_vel_z: 0.6886
    Episode_Reward/pen_base_height: -0.1832
      Episode_Reward/pen_lin_vel_z: -0.0218
     Episode_Reward/pen_ang_vel_xy: -0.0331
   Episode_Reward/pen_joint_torque: -0.0353
    Episode_Reward/pen_joint_accel: -0.0215
    Episode_Reward/pen_action_rate: -0.0100
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0078
   Episode_Reward/pen_joint_powers: -0.0122
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0214
Episode_Reward/pen_flat_orientation: -0.1451
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0376
   Episode_Reward/foot_landing_vel: -0.0332
   Episode_Reward/test_gait_reward: -0.2060
Metrics/base_velocity/error_vel_xy: 0.7962
Metrics/base_velocity/error_vel_yaw: 0.1989
      Episode_Termination/time_out: 0.3750
  Episode_Termination/base_contact: 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 1.10s
                        Total time: 411.32s
                               ETA: 2854.2s

################################################################################
                     [1m Learning iteration 378/3000 [0m                      

                       Computation: 90275 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.5868
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5788
                     Learning rate: 0.0009
                       Mean reward: 13.64
               Mean episode length: 274.60
       Episode_Reward/keep_balance: 0.2508
     Episode_Reward/rew_lin_vel_xy: 0.4497
      Episode_Reward/rew_ang_vel_z: 0.7590
    Episode_Reward/pen_base_height: -0.1898
      Episode_Reward/pen_lin_vel_z: -0.0232
     Episode_Reward/pen_ang_vel_xy: -0.0340
   Episode_Reward/pen_joint_torque: -0.0398
    Episode_Reward/pen_joint_accel: -0.0214
    Episode_Reward/pen_action_rate: -0.0110
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0084
   Episode_Reward/pen_joint_powers: -0.0134
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0237
Episode_Reward/pen_flat_orientation: -0.1528
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0413
   Episode_Reward/foot_landing_vel: -0.0361
   Episode_Reward/test_gait_reward: -0.2274
Metrics/base_velocity/error_vel_xy: 0.8783
Metrics/base_velocity/error_vel_yaw: 0.2225
      Episode_Termination/time_out: 0.3333
  Episode_Termination/base_contact: 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 1.09s
                        Total time: 412.41s
                               ETA: 2853.1s

################################################################################
                     [1m Learning iteration 379/3000 [0m                      

                       Computation: 90590 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 0.5549
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5789
                     Learning rate: 0.0013
                       Mean reward: 12.02
               Mean episode length: 258.60
       Episode_Reward/keep_balance: 0.2740
     Episode_Reward/rew_lin_vel_xy: 0.4762
      Episode_Reward/rew_ang_vel_z: 0.8258
    Episode_Reward/pen_base_height: -0.2006
      Episode_Reward/pen_lin_vel_z: -0.0275
     Episode_Reward/pen_ang_vel_xy: -0.0380
   Episode_Reward/pen_joint_torque: -0.0453
    Episode_Reward/pen_joint_accel: -0.0277
    Episode_Reward/pen_action_rate: -0.0125
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0102
   Episode_Reward/pen_joint_powers: -0.0156
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0261
Episode_Reward/pen_flat_orientation: -0.1754
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0528
   Episode_Reward/foot_landing_vel: -0.0432
   Episode_Reward/test_gait_reward: -0.2509
Metrics/base_velocity/error_vel_xy: 0.9404
Metrics/base_velocity/error_vel_yaw: 0.2455
      Episode_Termination/time_out: 0.7500
  Episode_Termination/base_contact: 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 1.09s
                        Total time: 413.49s
                               ETA: 2852.0s

################################################################################
                     [1m Learning iteration 380/3000 [0m                      

                       Computation: 89421 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.6962
                    Surrogate loss: 0.0015
             Mean action noise std: 0.5790
                     Learning rate: 0.0006
                       Mean reward: 13.69
               Mean episode length: 268.04
       Episode_Reward/keep_balance: 0.2499
     Episode_Reward/rew_lin_vel_xy: 0.4535
      Episode_Reward/rew_ang_vel_z: 0.7606
    Episode_Reward/pen_base_height: -0.1922
      Episode_Reward/pen_lin_vel_z: -0.0251
     Episode_Reward/pen_ang_vel_xy: -0.0353
   Episode_Reward/pen_joint_torque: -0.0411
    Episode_Reward/pen_joint_accel: -0.0261
    Episode_Reward/pen_action_rate: -0.0113
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0092
   Episode_Reward/pen_joint_powers: -0.0141
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0237
Episode_Reward/pen_flat_orientation: -0.1606
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0449
   Episode_Reward/foot_landing_vel: -0.0391
   Episode_Reward/test_gait_reward: -0.2279
Metrics/base_velocity/error_vel_xy: 0.8724
Metrics/base_velocity/error_vel_yaw: 0.2187
      Episode_Termination/time_out: 0.5000
  Episode_Termination/base_contact: 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 1.10s
                        Total time: 414.59s
                               ETA: 2851.0s

################################################################################
                     [1m Learning iteration 381/3000 [0m                      

                       Computation: 91486 steps/s (collection: 0.950s, learning 0.125s)
               Value function loss: 0.6236
                    Surrogate loss: -0.0026
             Mean action noise std: 0.5794
                     Learning rate: 0.0013
                       Mean reward: 10.11
               Mean episode length: 248.33
       Episode_Reward/keep_balance: 0.2376
     Episode_Reward/rew_lin_vel_xy: 0.3942
      Episode_Reward/rew_ang_vel_z: 0.7165
    Episode_Reward/pen_base_height: -0.1851
      Episode_Reward/pen_lin_vel_z: -0.0237
     Episode_Reward/pen_ang_vel_xy: -0.0344
   Episode_Reward/pen_joint_torque: -0.0386
    Episode_Reward/pen_joint_accel: -0.0236
    Episode_Reward/pen_action_rate: -0.0108
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0086
   Episode_Reward/pen_joint_powers: -0.0132
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0229
Episode_Reward/pen_flat_orientation: -0.1539
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0410
   Episode_Reward/foot_landing_vel: -0.0375
   Episode_Reward/test_gait_reward: -0.2181
Metrics/base_velocity/error_vel_xy: 0.8349
Metrics/base_velocity/error_vel_yaw: 0.2123
      Episode_Termination/time_out: 0.4583
  Episode_Termination/base_contact: 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 1.07s
                        Total time: 415.67s
                               ETA: 2849.8s

################################################################################
                     [1m Learning iteration 382/3000 [0m                      

                       Computation: 88376 steps/s (collection: 0.989s, learning 0.123s)
               Value function loss: 0.6676
                    Surrogate loss: 0.0015
             Mean action noise std: 0.5802
                     Learning rate: 0.0009
                       Mean reward: 10.85
               Mean episode length: 254.70
       Episode_Reward/keep_balance: 0.2657
     Episode_Reward/rew_lin_vel_xy: 0.4542
      Episode_Reward/rew_ang_vel_z: 0.7980
    Episode_Reward/pen_base_height: -0.1948
      Episode_Reward/pen_lin_vel_z: -0.0253
     Episode_Reward/pen_ang_vel_xy: -0.0362
   Episode_Reward/pen_joint_torque: -0.0423
    Episode_Reward/pen_joint_accel: -0.0271
    Episode_Reward/pen_action_rate: -0.0122
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0096
   Episode_Reward/pen_joint_powers: -0.0145
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0260
Episode_Reward/pen_flat_orientation: -0.1680
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0462
   Episode_Reward/foot_landing_vel: -0.0420
   Episode_Reward/test_gait_reward: -0.2427
Metrics/base_velocity/error_vel_xy: 0.9368
Metrics/base_velocity/error_vel_yaw: 0.2403
      Episode_Termination/time_out: 0.5833
  Episode_Termination/base_contact: 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 1.11s
                        Total time: 416.78s
                               ETA: 2848.9s

################################################################################
                     [1m Learning iteration 383/3000 [0m                      

                       Computation: 89659 steps/s (collection: 0.972s, learning 0.125s)
               Value function loss: 0.6362
                    Surrogate loss: 0.0082
             Mean action noise std: 0.5804
                     Learning rate: 0.0000
                       Mean reward: 15.94
               Mean episode length: 288.13
       Episode_Reward/keep_balance: 0.2685
     Episode_Reward/rew_lin_vel_xy: 0.4902
      Episode_Reward/rew_ang_vel_z: 0.8072
    Episode_Reward/pen_base_height: -0.1963
      Episode_Reward/pen_lin_vel_z: -0.0259
     Episode_Reward/pen_ang_vel_xy: -0.0359
   Episode_Reward/pen_joint_torque: -0.0426
    Episode_Reward/pen_joint_accel: -0.0278
    Episode_Reward/pen_action_rate: -0.0123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0099
   Episode_Reward/pen_joint_powers: -0.0148
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0259
Episode_Reward/pen_flat_orientation: -0.1687
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0488
   Episode_Reward/foot_landing_vel: -0.0432
   Episode_Reward/test_gait_reward: -0.2464
Metrics/base_velocity/error_vel_xy: 0.9058
Metrics/base_velocity/error_vel_yaw: 0.2429
      Episode_Termination/time_out: 0.9167
  Episode_Termination/base_contact: 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 1.10s
                        Total time: 417.88s
                               ETA: 2847.9s

################################################################################
                     [1m Learning iteration 384/3000 [0m                      

                       Computation: 89267 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.6019
                    Surrogate loss: 0.0017
             Mean action noise std: 0.5808
                     Learning rate: 0.0001
                       Mean reward: 13.78
               Mean episode length: 294.56
       Episode_Reward/keep_balance: 0.2906
     Episode_Reward/rew_lin_vel_xy: 0.4773
      Episode_Reward/rew_ang_vel_z: 0.8784
    Episode_Reward/pen_base_height: -0.2099
      Episode_Reward/pen_lin_vel_z: -0.0304
     Episode_Reward/pen_ang_vel_xy: -0.0406
   Episode_Reward/pen_joint_torque: -0.0505
    Episode_Reward/pen_joint_accel: -0.0313
    Episode_Reward/pen_action_rate: -0.0136
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0114
   Episode_Reward/pen_joint_powers: -0.0173
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0282
Episode_Reward/pen_flat_orientation: -0.1829
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0569
   Episode_Reward/foot_landing_vel: -0.0506
   Episode_Reward/test_gait_reward: -0.2679
Metrics/base_velocity/error_vel_xy: 1.0386
Metrics/base_velocity/error_vel_yaw: 0.2583
      Episode_Termination/time_out: 0.7083
  Episode_Termination/base_contact: 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 1.10s
                        Total time: 418.98s
                               ETA: 2846.9s

################################################################################
                     [1m Learning iteration 385/3000 [0m                      

                       Computation: 90002 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.6196
                    Surrogate loss: 0.0034
             Mean action noise std: 0.5812
                     Learning rate: 0.0001
                       Mean reward: 10.97
               Mean episode length: 230.08
       Episode_Reward/keep_balance: 0.2720
     Episode_Reward/rew_lin_vel_xy: 0.5023
      Episode_Reward/rew_ang_vel_z: 0.8151
    Episode_Reward/pen_base_height: -0.2029
      Episode_Reward/pen_lin_vel_z: -0.0271
     Episode_Reward/pen_ang_vel_xy: -0.0381
   Episode_Reward/pen_joint_torque: -0.0466
    Episode_Reward/pen_joint_accel: -0.0284
    Episode_Reward/pen_action_rate: -0.0127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0102
   Episode_Reward/pen_joint_powers: -0.0157
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0266
Episode_Reward/pen_flat_orientation: -0.1667
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0509
   Episode_Reward/foot_landing_vel: -0.0450
   Episode_Reward/test_gait_reward: -0.2489
Metrics/base_velocity/error_vel_xy: 0.9215
Metrics/base_velocity/error_vel_yaw: 0.2475
      Episode_Termination/time_out: 0.7083
  Episode_Termination/base_contact: 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 1.09s
                        Total time: 420.07s
                               ETA: 2845.8s

################################################################################
                     [1m Learning iteration 386/3000 [0m                      

                       Computation: 89655 steps/s (collection: 0.970s, learning 0.126s)
               Value function loss: 0.6815
                    Surrogate loss: 0.0038
             Mean action noise std: 0.5815
                     Learning rate: 0.0001
                       Mean reward: 13.54
               Mean episode length: 262.53
       Episode_Reward/keep_balance: 0.2639
     Episode_Reward/rew_lin_vel_xy: 0.4991
      Episode_Reward/rew_ang_vel_z: 0.8084
    Episode_Reward/pen_base_height: -0.1989
      Episode_Reward/pen_lin_vel_z: -0.0261
     Episode_Reward/pen_ang_vel_xy: -0.0372
   Episode_Reward/pen_joint_torque: -0.0437
    Episode_Reward/pen_joint_accel: -0.0254
    Episode_Reward/pen_action_rate: -0.0121
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0098
   Episode_Reward/pen_joint_powers: -0.0149
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0252
Episode_Reward/pen_flat_orientation: -0.1616
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0476
   Episode_Reward/foot_landing_vel: -0.0437
   Episode_Reward/test_gait_reward: -0.2401
Metrics/base_velocity/error_vel_xy: 0.8880
Metrics/base_velocity/error_vel_yaw: 0.2281
      Episode_Termination/time_out: 0.6250
  Episode_Termination/base_contact: 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 1.10s
                        Total time: 421.17s
                               ETA: 2844.8s

################################################################################
                     [1m Learning iteration 387/3000 [0m                      

                       Computation: 90675 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.6032
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5818
                     Learning rate: 0.0004
                       Mean reward: 14.00
               Mean episode length: 294.96
       Episode_Reward/keep_balance: 0.2899
     Episode_Reward/rew_lin_vel_xy: 0.5026
      Episode_Reward/rew_ang_vel_z: 0.8805
    Episode_Reward/pen_base_height: -0.2075
      Episode_Reward/pen_lin_vel_z: -0.0287
     Episode_Reward/pen_ang_vel_xy: -0.0389
   Episode_Reward/pen_joint_torque: -0.0487
    Episode_Reward/pen_joint_accel: -0.0275
    Episode_Reward/pen_action_rate: -0.0134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0105
   Episode_Reward/pen_joint_powers: -0.0165
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0280
Episode_Reward/pen_flat_orientation: -0.1722
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0548
   Episode_Reward/foot_landing_vel: -0.0456
   Episode_Reward/test_gait_reward: -0.2641
Metrics/base_velocity/error_vel_xy: 1.0084
Metrics/base_velocity/error_vel_yaw: 0.2555
      Episode_Termination/time_out: 0.7083
  Episode_Termination/base_contact: 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 1.08s
                        Total time: 422.25s
                               ETA: 2843.7s

################################################################################
                     [1m Learning iteration 388/3000 [0m                      

                       Computation: 90212 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.7752
                    Surrogate loss: 0.0011
             Mean action noise std: 0.5818
                     Learning rate: 0.0004
                       Mean reward: 17.86
               Mean episode length: 314.76
       Episode_Reward/keep_balance: 0.2981
     Episode_Reward/rew_lin_vel_xy: 0.5405
      Episode_Reward/rew_ang_vel_z: 0.9152
    Episode_Reward/pen_base_height: -0.2107
      Episode_Reward/pen_lin_vel_z: -0.0287
     Episode_Reward/pen_ang_vel_xy: -0.0388
   Episode_Reward/pen_joint_torque: -0.0506
    Episode_Reward/pen_joint_accel: -0.0279
    Episode_Reward/pen_action_rate: -0.0137
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0106
   Episode_Reward/pen_joint_powers: -0.0168
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0285
Episode_Reward/pen_flat_orientation: -0.1743
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0524
   Episode_Reward/foot_landing_vel: -0.0461
   Episode_Reward/test_gait_reward: -0.2703
Metrics/base_velocity/error_vel_xy: 1.0145
Metrics/base_velocity/error_vel_yaw: 0.2554
      Episode_Termination/time_out: 0.7917
  Episode_Termination/base_contact: 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 1.09s
                        Total time: 423.34s
                               ETA: 2842.6s

################################################################################
                     [1m Learning iteration 389/3000 [0m                      

                       Computation: 90486 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.7287
                    Surrogate loss: 0.0000
             Mean action noise std: 0.5820
                     Learning rate: 0.0009
                       Mean reward: 13.92
               Mean episode length: 259.84
       Episode_Reward/keep_balance: 0.2855
     Episode_Reward/rew_lin_vel_xy: 0.5239
      Episode_Reward/rew_ang_vel_z: 0.8665
    Episode_Reward/pen_base_height: -0.2088
      Episode_Reward/pen_lin_vel_z: -0.0277
     Episode_Reward/pen_ang_vel_xy: -0.0390
   Episode_Reward/pen_joint_torque: -0.0468
    Episode_Reward/pen_joint_accel: -0.0263
    Episode_Reward/pen_action_rate: -0.0133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0102
   Episode_Reward/pen_joint_powers: -0.0159
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0279
Episode_Reward/pen_flat_orientation: -0.1679
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0526
   Episode_Reward/foot_landing_vel: -0.0445
   Episode_Reward/test_gait_reward: -0.2614
Metrics/base_velocity/error_vel_xy: 0.9984
Metrics/base_velocity/error_vel_yaw: 0.2533
      Episode_Termination/time_out: 0.6250
  Episode_Termination/base_contact: 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 1.09s
                        Total time: 424.43s
                               ETA: 2841.5s

################################################################################
                     [1m Learning iteration 390/3000 [0m                      

                       Computation: 89543 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.7334
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5838
                     Learning rate: 0.0013
                       Mean reward: 18.49
               Mean episode length: 334.21
       Episode_Reward/keep_balance: 0.3064
     Episode_Reward/rew_lin_vel_xy: 0.5644
      Episode_Reward/rew_ang_vel_z: 0.9281
    Episode_Reward/pen_base_height: -0.2154
      Episode_Reward/pen_lin_vel_z: -0.0305
     Episode_Reward/pen_ang_vel_xy: -0.0411
   Episode_Reward/pen_joint_torque: -0.0525
    Episode_Reward/pen_joint_accel: -0.0296
    Episode_Reward/pen_action_rate: -0.0145
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0114
   Episode_Reward/pen_joint_powers: -0.0177
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0301
Episode_Reward/pen_flat_orientation: -0.1782
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0574
   Episode_Reward/foot_landing_vel: -0.0513
   Episode_Reward/test_gait_reward: -0.2786
Metrics/base_velocity/error_vel_xy: 1.0123
Metrics/base_velocity/error_vel_yaw: 0.2717
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 1.10s
                        Total time: 425.53s
                               ETA: 2840.5s

################################################################################
                     [1m Learning iteration 391/3000 [0m                      

                       Computation: 90137 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.7756
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5849
                     Learning rate: 0.0004
                       Mean reward: 19.96
               Mean episode length: 363.38
       Episode_Reward/keep_balance: 0.3402
     Episode_Reward/rew_lin_vel_xy: 0.6277
      Episode_Reward/rew_ang_vel_z: 1.0373
    Episode_Reward/pen_base_height: -0.2261
      Episode_Reward/pen_lin_vel_z: -0.0322
     Episode_Reward/pen_ang_vel_xy: -0.0431
   Episode_Reward/pen_joint_torque: -0.0566
    Episode_Reward/pen_joint_accel: -0.0315
    Episode_Reward/pen_action_rate: -0.0159
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0122
   Episode_Reward/pen_joint_powers: -0.0190
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0332
Episode_Reward/pen_flat_orientation: -0.1850
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0606
   Episode_Reward/foot_landing_vel: -0.0548
   Episode_Reward/test_gait_reward: -0.3074
Metrics/base_velocity/error_vel_xy: 1.1593
Metrics/base_velocity/error_vel_yaw: 0.2964
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 1.09s
                        Total time: 426.62s
                               ETA: 2839.4s

################################################################################
                     [1m Learning iteration 392/3000 [0m                      

                       Computation: 90231 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.6415
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5851
                     Learning rate: 0.0006
                       Mean reward: 18.49
               Mean episode length: 354.44
       Episode_Reward/keep_balance: 0.3258
     Episode_Reward/rew_lin_vel_xy: 0.5931
      Episode_Reward/rew_ang_vel_z: 0.9851
    Episode_Reward/pen_base_height: -0.2221
      Episode_Reward/pen_lin_vel_z: -0.0321
     Episode_Reward/pen_ang_vel_xy: -0.0429
   Episode_Reward/pen_joint_torque: -0.0557
    Episode_Reward/pen_joint_accel: -0.0331
    Episode_Reward/pen_action_rate: -0.0155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0123
   Episode_Reward/pen_joint_powers: -0.0189
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0321
Episode_Reward/pen_flat_orientation: -0.1920
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0631
   Episode_Reward/foot_landing_vel: -0.0557
   Episode_Reward/test_gait_reward: -0.2971
Metrics/base_velocity/error_vel_xy: 1.0820
Metrics/base_velocity/error_vel_yaw: 0.2906
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 1.09s
                        Total time: 427.71s
                               ETA: 2838.3s

################################################################################
                     [1m Learning iteration 393/3000 [0m                      

                       Computation: 89807 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 0.6839
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5858
                     Learning rate: 0.0009
                       Mean reward: 18.19
               Mean episode length: 339.46
       Episode_Reward/keep_balance: 0.3417
     Episode_Reward/rew_lin_vel_xy: 0.5812
      Episode_Reward/rew_ang_vel_z: 1.0379
    Episode_Reward/pen_base_height: -0.2282
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.0434
   Episode_Reward/pen_joint_torque: -0.0622
    Episode_Reward/pen_joint_accel: -0.0350
    Episode_Reward/pen_action_rate: -0.0165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0207
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0338
Episode_Reward/pen_flat_orientation: -0.1978
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0696
   Episode_Reward/foot_landing_vel: -0.0620
   Episode_Reward/test_gait_reward: -0.3148
Metrics/base_velocity/error_vel_xy: 1.1546
Metrics/base_velocity/error_vel_yaw: 0.3008
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 1.09s
                        Total time: 428.80s
                               ETA: 2837.3s

################################################################################
                     [1m Learning iteration 394/3000 [0m                      

                       Computation: 90198 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.7329
                    Surrogate loss: 0.0001
             Mean action noise std: 0.5852
                     Learning rate: 0.0013
                       Mean reward: 16.93
               Mean episode length: 314.29
       Episode_Reward/keep_balance: 0.3237
     Episode_Reward/rew_lin_vel_xy: 0.5681
      Episode_Reward/rew_ang_vel_z: 0.9830
    Episode_Reward/pen_base_height: -0.2217
      Episode_Reward/pen_lin_vel_z: -0.0313
     Episode_Reward/pen_ang_vel_xy: -0.0425
   Episode_Reward/pen_joint_torque: -0.0560
    Episode_Reward/pen_joint_accel: -0.0326
    Episode_Reward/pen_action_rate: -0.0154
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0121
   Episode_Reward/pen_joint_powers: -0.0187
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0321
Episode_Reward/pen_flat_orientation: -0.1792
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0608
   Episode_Reward/foot_landing_vel: -0.0542
   Episode_Reward/test_gait_reward: -0.2945
Metrics/base_velocity/error_vel_xy: 1.1027
Metrics/base_velocity/error_vel_yaw: 0.2852
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 1.09s
                        Total time: 429.89s
                               ETA: 2836.2s

################################################################################
                     [1m Learning iteration 395/3000 [0m                      

                       Computation: 89640 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.7446
                    Surrogate loss: 0.0017
             Mean action noise std: 0.5846
                     Learning rate: 0.0009
                       Mean reward: 16.33
               Mean episode length: 307.69
       Episode_Reward/keep_balance: 0.3078
     Episode_Reward/rew_lin_vel_xy: 0.5849
      Episode_Reward/rew_ang_vel_z: 0.9414
    Episode_Reward/pen_base_height: -0.2138
      Episode_Reward/pen_lin_vel_z: -0.0306
     Episode_Reward/pen_ang_vel_xy: -0.0397
   Episode_Reward/pen_joint_torque: -0.0545
    Episode_Reward/pen_joint_accel: -0.0294
    Episode_Reward/pen_action_rate: -0.0146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0113
   Episode_Reward/pen_joint_powers: -0.0178
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0301
Episode_Reward/pen_flat_orientation: -0.1689
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0579
   Episode_Reward/foot_landing_vel: -0.0513
   Episode_Reward/test_gait_reward: -0.2807
Metrics/base_velocity/error_vel_xy: 1.0562
Metrics/base_velocity/error_vel_yaw: 0.2670
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 1.10s
                        Total time: 430.99s
                               ETA: 2835.2s

################################################################################
                     [1m Learning iteration 396/3000 [0m                      

                       Computation: 90106 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.7269
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5854
                     Learning rate: 0.0019
                       Mean reward: 17.92
               Mean episode length: 332.83
       Episode_Reward/keep_balance: 0.3054
     Episode_Reward/rew_lin_vel_xy: 0.5864
      Episode_Reward/rew_ang_vel_z: 0.9222
    Episode_Reward/pen_base_height: -0.2157
      Episode_Reward/pen_lin_vel_z: -0.0303
     Episode_Reward/pen_ang_vel_xy: -0.0400
   Episode_Reward/pen_joint_torque: -0.0535
    Episode_Reward/pen_joint_accel: -0.0313
    Episode_Reward/pen_action_rate: -0.0146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0115
   Episode_Reward/pen_joint_powers: -0.0177
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0305
Episode_Reward/pen_flat_orientation: -0.1717
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0580
   Episode_Reward/foot_landing_vel: -0.0511
   Episode_Reward/test_gait_reward: -0.2780
Metrics/base_velocity/error_vel_xy: 1.0142
Metrics/base_velocity/error_vel_yaw: 0.2731
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 1.09s
                        Total time: 432.08s
                               ETA: 2834.1s

################################################################################
                     [1m Learning iteration 397/3000 [0m                      

                       Computation: 89335 steps/s (collection: 0.977s, learning 0.124s)
               Value function loss: 0.8538
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5857
                     Learning rate: 0.0013
                       Mean reward: 20.49
               Mean episode length: 385.15
       Episode_Reward/keep_balance: 0.3499
     Episode_Reward/rew_lin_vel_xy: 0.6860
      Episode_Reward/rew_ang_vel_z: 1.0661
    Episode_Reward/pen_base_height: -0.2303
      Episode_Reward/pen_lin_vel_z: -0.0343
     Episode_Reward/pen_ang_vel_xy: -0.0439
   Episode_Reward/pen_joint_torque: -0.0613
    Episode_Reward/pen_joint_accel: -0.0346
    Episode_Reward/pen_action_rate: -0.0169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0130
   Episode_Reward/pen_joint_powers: -0.0203
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0347
Episode_Reward/pen_flat_orientation: -0.1875
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0660
   Episode_Reward/foot_landing_vel: -0.0619
   Episode_Reward/test_gait_reward: -0.3166
Metrics/base_velocity/error_vel_xy: 1.1275
Metrics/base_velocity/error_vel_yaw: 0.3051
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 1.10s
                        Total time: 433.18s
                               ETA: 2833.1s

################################################################################
                     [1m Learning iteration 398/3000 [0m                      

                       Computation: 89683 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.7432
                    Surrogate loss: 0.0012
             Mean action noise std: 0.5867
                     Learning rate: 0.0013
                       Mean reward: 21.24
               Mean episode length: 392.14
       Episode_Reward/keep_balance: 0.3521
     Episode_Reward/rew_lin_vel_xy: 0.6434
      Episode_Reward/rew_ang_vel_z: 1.0716
    Episode_Reward/pen_base_height: -0.2252
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.0448
   Episode_Reward/pen_joint_torque: -0.0622
    Episode_Reward/pen_joint_accel: -0.0345
    Episode_Reward/pen_action_rate: -0.0171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0209
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0350
Episode_Reward/pen_flat_orientation: -0.1815
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0679
   Episode_Reward/foot_landing_vel: -0.0628
   Episode_Reward/test_gait_reward: -0.3196
Metrics/base_velocity/error_vel_xy: 1.1910
Metrics/base_velocity/error_vel_yaw: 0.3093
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 1.10s
                        Total time: 434.27s
                               ETA: 2832.0s

################################################################################
                     [1m Learning iteration 399/3000 [0m                      

                       Computation: 91103 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.7809
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5875
                     Learning rate: 0.0013
                       Mean reward: 18.26
               Mean episode length: 373.09
       Episode_Reward/keep_balance: 0.3524
     Episode_Reward/rew_lin_vel_xy: 0.6031
      Episode_Reward/rew_ang_vel_z: 1.0648
    Episode_Reward/pen_base_height: -0.2249
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.0451
   Episode_Reward/pen_joint_torque: -0.0653
    Episode_Reward/pen_joint_accel: -0.0364
    Episode_Reward/pen_action_rate: -0.0174
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0219
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0355
Episode_Reward/pen_flat_orientation: -0.1939
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0718
   Episode_Reward/foot_landing_vel: -0.0654
   Episode_Reward/test_gait_reward: -0.3202
Metrics/base_velocity/error_vel_xy: 1.2083
Metrics/base_velocity/error_vel_yaw: 0.3149
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 1.08s
                        Total time: 435.35s
                               ETA: 2830.9s

################################################################################
                     [1m Learning iteration 400/3000 [0m                      

                       Computation: 91159 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.6701
                    Surrogate loss: 0.0096
             Mean action noise std: 0.5879
                     Learning rate: 0.0001
                       Mean reward: 18.71
               Mean episode length: 364.04
       Episode_Reward/keep_balance: 0.3111
     Episode_Reward/rew_lin_vel_xy: 0.5465
      Episode_Reward/rew_ang_vel_z: 0.9401
    Episode_Reward/pen_base_height: -0.2159
      Episode_Reward/pen_lin_vel_z: -0.0310
     Episode_Reward/pen_ang_vel_xy: -0.0417
   Episode_Reward/pen_joint_torque: -0.0543
    Episode_Reward/pen_joint_accel: -0.0316
    Episode_Reward/pen_action_rate: -0.0152
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0118
   Episode_Reward/pen_joint_powers: -0.0182
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0315
Episode_Reward/pen_flat_orientation: -0.1671
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0591
   Episode_Reward/foot_landing_vel: -0.0537
   Episode_Reward/test_gait_reward: -0.2832
Metrics/base_velocity/error_vel_xy: 1.0868
Metrics/base_velocity/error_vel_yaw: 0.2784
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 1.08s
                        Total time: 436.43s
                               ETA: 2829.7s

################################################################################
                     [1m Learning iteration 401/3000 [0m                      

                       Computation: 89055 steps/s (collection: 0.980s, learning 0.124s)
               Value function loss: 0.6363
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5884
                     Learning rate: 0.0003
                       Mean reward: 17.09
               Mean episode length: 323.97
       Episode_Reward/keep_balance: 0.3105
     Episode_Reward/rew_lin_vel_xy: 0.5380
      Episode_Reward/rew_ang_vel_z: 0.9480
    Episode_Reward/pen_base_height: -0.2210
      Episode_Reward/pen_lin_vel_z: -0.0311
     Episode_Reward/pen_ang_vel_xy: -0.0408
   Episode_Reward/pen_joint_torque: -0.0548
    Episode_Reward/pen_joint_accel: -0.0310
    Episode_Reward/pen_action_rate: -0.0150
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0117
   Episode_Reward/pen_joint_powers: -0.0182
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0310
Episode_Reward/pen_flat_orientation: -0.1666
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0594
   Episode_Reward/foot_landing_vel: -0.0531
   Episode_Reward/test_gait_reward: -0.2815
Metrics/base_velocity/error_vel_xy: 1.0731
Metrics/base_velocity/error_vel_yaw: 0.2702
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 1.10s
                        Total time: 437.54s
                               ETA: 2828.7s

################################################################################
                     [1m Learning iteration 402/3000 [0m                      

                       Computation: 89335 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 0.7000
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5890
                     Learning rate: 0.0009
                       Mean reward: 13.92
               Mean episode length: 273.90
       Episode_Reward/keep_balance: 0.2831
     Episode_Reward/rew_lin_vel_xy: 0.4925
      Episode_Reward/rew_ang_vel_z: 0.8594
    Episode_Reward/pen_base_height: -0.2134
      Episode_Reward/pen_lin_vel_z: -0.0282
     Episode_Reward/pen_ang_vel_xy: -0.0382
   Episode_Reward/pen_joint_torque: -0.0485
    Episode_Reward/pen_joint_accel: -0.0284
    Episode_Reward/pen_action_rate: -0.0135
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0101
   Episode_Reward/pen_joint_powers: -0.0159
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0283
Episode_Reward/pen_flat_orientation: -0.1500
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0528
   Episode_Reward/foot_landing_vel: -0.0453
   Episode_Reward/test_gait_reward: -0.2557
Metrics/base_velocity/error_vel_xy: 0.9678
Metrics/base_velocity/error_vel_yaw: 0.2509
      Episode_Termination/time_out: 0.9167
  Episode_Termination/base_contact: 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 1.10s
                        Total time: 438.64s
                               ETA: 2827.7s

################################################################################
                     [1m Learning iteration 403/3000 [0m                      

                       Computation: 90076 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.8273
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5893
                     Learning rate: 0.0013
                       Mean reward: 18.59
               Mean episode length: 338.44
       Episode_Reward/keep_balance: 0.3439
     Episode_Reward/rew_lin_vel_xy: 0.7009
      Episode_Reward/rew_ang_vel_z: 1.0496
    Episode_Reward/pen_base_height: -0.2374
      Episode_Reward/pen_lin_vel_z: -0.0333
     Episode_Reward/pen_ang_vel_xy: -0.0434
   Episode_Reward/pen_joint_torque: -0.0612
    Episode_Reward/pen_joint_accel: -0.0338
    Episode_Reward/pen_action_rate: -0.0167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0124
   Episode_Reward/pen_joint_powers: -0.0197
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0347
Episode_Reward/pen_flat_orientation: -0.1685
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0653
   Episode_Reward/foot_landing_vel: -0.0566
   Episode_Reward/test_gait_reward: -0.3096
Metrics/base_velocity/error_vel_xy: 1.1300
Metrics/base_velocity/error_vel_yaw: 0.3007
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 9.3333
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 1.09s
                        Total time: 439.73s
                               ETA: 2826.7s

################################################################################
                     [1m Learning iteration 404/3000 [0m                      

                       Computation: 90273 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.8338
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5898
                     Learning rate: 0.0013
                       Mean reward: 17.67
               Mean episode length: 325.88
       Episode_Reward/keep_balance: 0.3223
     Episode_Reward/rew_lin_vel_xy: 0.5522
      Episode_Reward/rew_ang_vel_z: 0.9763
    Episode_Reward/pen_base_height: -0.2254
      Episode_Reward/pen_lin_vel_z: -0.0327
     Episode_Reward/pen_ang_vel_xy: -0.0424
   Episode_Reward/pen_joint_torque: -0.0581
    Episode_Reward/pen_joint_accel: -0.0327
    Episode_Reward/pen_action_rate: -0.0158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0121
   Episode_Reward/pen_joint_powers: -0.0191
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0329
Episode_Reward/pen_flat_orientation: -0.1693
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0643
   Episode_Reward/foot_landing_vel: -0.0537
   Episode_Reward/test_gait_reward: -0.2931
Metrics/base_velocity/error_vel_xy: 1.1001
Metrics/base_velocity/error_vel_yaw: 0.2863
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 10.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 1.09s
                        Total time: 440.82s
                               ETA: 2825.6s

################################################################################
                     [1m Learning iteration 405/3000 [0m                      

                       Computation: 84233 steps/s (collection: 1.044s, learning 0.123s)
               Value function loss: 0.9645
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5909
                     Learning rate: 0.0013
                       Mean reward: 18.12
               Mean episode length: 325.83
       Episode_Reward/keep_balance: 0.3291
     Episode_Reward/rew_lin_vel_xy: 0.6220
      Episode_Reward/rew_ang_vel_z: 1.0030
    Episode_Reward/pen_base_height: -0.2310
      Episode_Reward/pen_lin_vel_z: -0.0327
     Episode_Reward/pen_ang_vel_xy: -0.0431
   Episode_Reward/pen_joint_torque: -0.0566
    Episode_Reward/pen_joint_accel: -0.0340
    Episode_Reward/pen_action_rate: -0.0161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0122
   Episode_Reward/pen_joint_powers: -0.0189
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0336
Episode_Reward/pen_flat_orientation: -0.1696
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0621
   Episode_Reward/foot_landing_vel: -0.0556
   Episode_Reward/test_gait_reward: -0.3002
Metrics/base_velocity/error_vel_xy: 1.1031
Metrics/base_velocity/error_vel_yaw: 0.2911
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 1.17s
                        Total time: 441.98s
                               ETA: 2825.0s

################################################################################
                     [1m Learning iteration 406/3000 [0m                      

                       Computation: 88715 steps/s (collection: 0.983s, learning 0.125s)
               Value function loss: 0.8734
                    Surrogate loss: 0.0015
             Mean action noise std: 0.5920
                     Learning rate: 0.0004
                       Mean reward: 17.95
               Mean episode length: 319.53
       Episode_Reward/keep_balance: 0.3349
     Episode_Reward/rew_lin_vel_xy: 0.5829
      Episode_Reward/rew_ang_vel_z: 1.0253
    Episode_Reward/pen_base_height: -0.2300
      Episode_Reward/pen_lin_vel_z: -0.0335
     Episode_Reward/pen_ang_vel_xy: -0.0436
   Episode_Reward/pen_joint_torque: -0.0595
    Episode_Reward/pen_joint_accel: -0.0340
    Episode_Reward/pen_action_rate: -0.0163
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0125
   Episode_Reward/pen_joint_powers: -0.0195
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0337
Episode_Reward/pen_flat_orientation: -0.1688
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0631
   Episode_Reward/foot_landing_vel: -0.0581
   Episode_Reward/test_gait_reward: -0.3034
Metrics/base_velocity/error_vel_xy: 1.1374
Metrics/base_velocity/error_vel_yaw: 0.2898
      Episode_Termination/time_out: 1.0000
  Episode_Termination/base_contact: 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 1.11s
                        Total time: 443.09s
                               ETA: 2824.0s

################################################################################
                     [1m Learning iteration 407/3000 [0m                      

                       Computation: 89564 steps/s (collection: 0.975s, learning 0.122s)
               Value function loss: 0.7193
                    Surrogate loss: -0.0033
             Mean action noise std: 0.5924
                     Learning rate: 0.0009
                       Mean reward: 14.74
               Mean episode length: 298.40
       Episode_Reward/keep_balance: 0.3115
     Episode_Reward/rew_lin_vel_xy: 0.6056
      Episode_Reward/rew_ang_vel_z: 0.9444
    Episode_Reward/pen_base_height: -0.2223
      Episode_Reward/pen_lin_vel_z: -0.0317
     Episode_Reward/pen_ang_vel_xy: -0.0405
   Episode_Reward/pen_joint_torque: -0.0554
    Episode_Reward/pen_joint_accel: -0.0328
    Episode_Reward/pen_action_rate: -0.0152
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0119
   Episode_Reward/pen_joint_powers: -0.0185
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0314
Episode_Reward/pen_flat_orientation: -0.1595
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0621
   Episode_Reward/foot_landing_vel: -0.0542
   Episode_Reward/test_gait_reward: -0.2839
Metrics/base_velocity/error_vel_xy: 1.0420
Metrics/base_velocity/error_vel_yaw: 0.2762
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 1.10s
                        Total time: 444.19s
                               ETA: 2823.0s

################################################################################
                     [1m Learning iteration 408/3000 [0m                      

                       Computation: 90132 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.8195
                    Surrogate loss: 0.0012
             Mean action noise std: 0.5931
                     Learning rate: 0.0002
                       Mean reward: 20.59
               Mean episode length: 365.79
       Episode_Reward/keep_balance: 0.3340
     Episode_Reward/rew_lin_vel_xy: 0.6121
      Episode_Reward/rew_ang_vel_z: 1.0181
    Episode_Reward/pen_base_height: -0.2289
      Episode_Reward/pen_lin_vel_z: -0.0333
     Episode_Reward/pen_ang_vel_xy: -0.0427
   Episode_Reward/pen_joint_torque: -0.0600
    Episode_Reward/pen_joint_accel: -0.0332
    Episode_Reward/pen_action_rate: -0.0164
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0125
   Episode_Reward/pen_joint_powers: -0.0197
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0338
Episode_Reward/pen_flat_orientation: -0.1655
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0640
   Episode_Reward/foot_landing_vel: -0.0580
   Episode_Reward/test_gait_reward: -0.3019
Metrics/base_velocity/error_vel_xy: 1.1514
Metrics/base_velocity/error_vel_yaw: 0.2919
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 1.09s
                        Total time: 445.28s
                               ETA: 2821.9s

################################################################################
                     [1m Learning iteration 409/3000 [0m                      

                       Computation: 90465 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.7552
                    Surrogate loss: 0.0069
             Mean action noise std: 0.5932
                     Learning rate: 0.0000
                       Mean reward: 18.49
               Mean episode length: 344.73
       Episode_Reward/keep_balance: 0.3388
     Episode_Reward/rew_lin_vel_xy: 0.6346
      Episode_Reward/rew_ang_vel_z: 1.0328
    Episode_Reward/pen_base_height: -0.2341
      Episode_Reward/pen_lin_vel_z: -0.0333
     Episode_Reward/pen_ang_vel_xy: -0.0430
   Episode_Reward/pen_joint_torque: -0.0615
    Episode_Reward/pen_joint_accel: -0.0344
    Episode_Reward/pen_action_rate: -0.0167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0125
   Episode_Reward/pen_joint_powers: -0.0197
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0348
Episode_Reward/pen_flat_orientation: -0.1632
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0640
   Episode_Reward/foot_landing_vel: -0.0559
   Episode_Reward/test_gait_reward: -0.3051
Metrics/base_velocity/error_vel_xy: 1.1482
Metrics/base_velocity/error_vel_yaw: 0.2958
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 1.09s
                        Total time: 446.37s
                               ETA: 2820.8s

################################################################################
                     [1m Learning iteration 410/3000 [0m                      

                       Computation: 89545 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.6309
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5932
                     Learning rate: 0.0002
                       Mean reward: 16.64
               Mean episode length: 322.74
       Episode_Reward/keep_balance: 0.3305
     Episode_Reward/rew_lin_vel_xy: 0.6104
      Episode_Reward/rew_ang_vel_z: 1.0106
    Episode_Reward/pen_base_height: -0.2313
      Episode_Reward/pen_lin_vel_z: -0.0336
     Episode_Reward/pen_ang_vel_xy: -0.0437
   Episode_Reward/pen_joint_torque: -0.0618
    Episode_Reward/pen_joint_accel: -0.0348
    Episode_Reward/pen_action_rate: -0.0165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0127
   Episode_Reward/pen_joint_powers: -0.0199
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0340
Episode_Reward/pen_flat_orientation: -0.1637
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0645
   Episode_Reward/foot_landing_vel: -0.0578
   Episode_Reward/test_gait_reward: -0.2992
Metrics/base_velocity/error_vel_xy: 1.1183
Metrics/base_velocity/error_vel_yaw: 0.2877
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 1.10s
                        Total time: 447.46s
                               ETA: 2819.8s

################################################################################
                     [1m Learning iteration 411/3000 [0m                      

                       Computation: 90440 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.7301
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5936
                     Learning rate: 0.0004
                       Mean reward: 17.63
               Mean episode length: 330.81
       Episode_Reward/keep_balance: 0.3713
     Episode_Reward/rew_lin_vel_xy: 0.7527
      Episode_Reward/rew_ang_vel_z: 1.1317
    Episode_Reward/pen_base_height: -0.2384
      Episode_Reward/pen_lin_vel_z: -0.0349
     Episode_Reward/pen_ang_vel_xy: -0.0451
   Episode_Reward/pen_joint_torque: -0.0646
    Episode_Reward/pen_joint_accel: -0.0369
    Episode_Reward/pen_action_rate: -0.0183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0382
Episode_Reward/pen_flat_orientation: -0.1713
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0667
   Episode_Reward/foot_landing_vel: -0.0636
   Episode_Reward/test_gait_reward: -0.3330
Metrics/base_velocity/error_vel_xy: 1.2164
Metrics/base_velocity/error_vel_yaw: 0.3249
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 1.09s
                        Total time: 448.55s
                               ETA: 2818.7s

################################################################################
                     [1m Learning iteration 412/3000 [0m                      

                       Computation: 89846 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.6928
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5944
                     Learning rate: 0.0006
                       Mean reward: 14.46
               Mean episode length: 282.90
       Episode_Reward/keep_balance: 0.3108
     Episode_Reward/rew_lin_vel_xy: 0.5721
      Episode_Reward/rew_ang_vel_z: 0.9392
    Episode_Reward/pen_base_height: -0.2237
      Episode_Reward/pen_lin_vel_z: -0.0326
     Episode_Reward/pen_ang_vel_xy: -0.0425
   Episode_Reward/pen_joint_torque: -0.0582
    Episode_Reward/pen_joint_accel: -0.0325
    Episode_Reward/pen_action_rate: -0.0155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0122
   Episode_Reward/pen_joint_powers: -0.0189
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0321
Episode_Reward/pen_flat_orientation: -0.1587
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0633
   Episode_Reward/foot_landing_vel: -0.0564
   Episode_Reward/test_gait_reward: -0.2811
Metrics/base_velocity/error_vel_xy: 1.0524
Metrics/base_velocity/error_vel_yaw: 0.2777
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 1.09s
                        Total time: 449.64s
                               ETA: 2817.6s

################################################################################
                     [1m Learning iteration 413/3000 [0m                      

                       Computation: 88580 steps/s (collection: 0.987s, learning 0.122s)
               Value function loss: 0.7718
                    Surrogate loss: -0.0024
             Mean action noise std: 0.5949
                     Learning rate: 0.0013
                       Mean reward: 12.22
               Mean episode length: 299.32
       Episode_Reward/keep_balance: 0.2898
     Episode_Reward/rew_lin_vel_xy: 0.5060
      Episode_Reward/rew_ang_vel_z: 0.8766
    Episode_Reward/pen_base_height: -0.2236
      Episode_Reward/pen_lin_vel_z: -0.0317
     Episode_Reward/pen_ang_vel_xy: -0.0406
   Episode_Reward/pen_joint_torque: -0.0560
    Episode_Reward/pen_joint_accel: -0.0321
    Episode_Reward/pen_action_rate: -0.0145
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0117
   Episode_Reward/pen_joint_powers: -0.0181
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0299
Episode_Reward/pen_flat_orientation: -0.1472
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0621
   Episode_Reward/foot_landing_vel: -0.0532
   Episode_Reward/test_gait_reward: -0.2640
Metrics/base_velocity/error_vel_xy: 1.0444
Metrics/base_velocity/error_vel_yaw: 0.2584
      Episode_Termination/time_out: 0.8333
  Episode_Termination/base_contact: 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 1.11s
                        Total time: 450.75s
                               ETA: 2816.7s

################################################################################
                     [1m Learning iteration 414/3000 [0m                      

                       Computation: 89309 steps/s (collection: 0.979s, learning 0.122s)
               Value function loss: 0.7580
                    Surrogate loss: 0.0048
             Mean action noise std: 0.5952
                     Learning rate: 0.0003
                       Mean reward: 11.60
               Mean episode length: 247.13
       Episode_Reward/keep_balance: 0.2842
     Episode_Reward/rew_lin_vel_xy: 0.5145
      Episode_Reward/rew_ang_vel_z: 0.8628
    Episode_Reward/pen_base_height: -0.2149
      Episode_Reward/pen_lin_vel_z: -0.0292
     Episode_Reward/pen_ang_vel_xy: -0.0398
   Episode_Reward/pen_joint_torque: -0.0509
    Episode_Reward/pen_joint_accel: -0.0292
    Episode_Reward/pen_action_rate: -0.0141
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0107
   Episode_Reward/pen_joint_powers: -0.0167
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0294
Episode_Reward/pen_flat_orientation: -0.1402
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0551
   Episode_Reward/foot_landing_vel: -0.0494
   Episode_Reward/test_gait_reward: -0.2577
Metrics/base_velocity/error_vel_xy: 0.9557
Metrics/base_velocity/error_vel_yaw: 0.2520
      Episode_Termination/time_out: 0.9583
  Episode_Termination/base_contact: 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 1.10s
                        Total time: 451.86s
                               ETA: 2815.7s

################################################################################
                     [1m Learning iteration 415/3000 [0m                      

                       Computation: 88903 steps/s (collection: 0.982s, learning 0.123s)
               Value function loss: 0.7921
                    Surrogate loss: -0.0002
             Mean action noise std: 0.5959
                     Learning rate: 0.0006
                       Mean reward: 19.35
               Mean episode length: 347.95
       Episode_Reward/keep_balance: 0.3511
     Episode_Reward/rew_lin_vel_xy: 0.7014
      Episode_Reward/rew_ang_vel_z: 1.0693
    Episode_Reward/pen_base_height: -0.2370
      Episode_Reward/pen_lin_vel_z: -0.0350
     Episode_Reward/pen_ang_vel_xy: -0.0443
   Episode_Reward/pen_joint_torque: -0.0635
    Episode_Reward/pen_joint_accel: -0.0372
    Episode_Reward/pen_action_rate: -0.0176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0206
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0364
Episode_Reward/pen_flat_orientation: -0.1627
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0687
   Episode_Reward/foot_landing_vel: -0.0614
   Episode_Reward/test_gait_reward: -0.3167
Metrics/base_velocity/error_vel_xy: 1.1894
Metrics/base_velocity/error_vel_yaw: 0.3074
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 1.11s
                        Total time: 452.96s
                               ETA: 2814.7s

################################################################################
                     [1m Learning iteration 416/3000 [0m                      

                       Computation: 89006 steps/s (collection: 0.978s, learning 0.126s)
               Value function loss: 0.7399
                    Surrogate loss: 0.0003
             Mean action noise std: 0.5961
                     Learning rate: 0.0004
                       Mean reward: 19.43
               Mean episode length: 331.96
       Episode_Reward/keep_balance: 0.2988
     Episode_Reward/rew_lin_vel_xy: 0.5798
      Episode_Reward/rew_ang_vel_z: 0.9011
    Episode_Reward/pen_base_height: -0.2226
      Episode_Reward/pen_lin_vel_z: -0.0313
     Episode_Reward/pen_ang_vel_xy: -0.0415
   Episode_Reward/pen_joint_torque: -0.0545
    Episode_Reward/pen_joint_accel: -0.0318
    Episode_Reward/pen_action_rate: -0.0150
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0116
   Episode_Reward/pen_joint_powers: -0.0179
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0311
Episode_Reward/pen_flat_orientation: -0.1419
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0598
   Episode_Reward/foot_landing_vel: -0.0528
   Episode_Reward/test_gait_reward: -0.2701
Metrics/base_velocity/error_vel_xy: 1.0019
Metrics/base_velocity/error_vel_yaw: 0.2682
      Episode_Termination/time_out: 0.8750
  Episode_Termination/base_contact: 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 1.10s
                        Total time: 454.07s
                               ETA: 2813.7s

################################################################################
                     [1m Learning iteration 417/3000 [0m                      

                       Computation: 89923 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.7896
                    Surrogate loss: 0.0007
             Mean action noise std: 0.5964
                     Learning rate: 0.0009
                       Mean reward: 15.06
               Mean episode length: 281.87
       Episode_Reward/keep_balance: 0.2655
     Episode_Reward/rew_lin_vel_xy: 0.5190
      Episode_Reward/rew_ang_vel_z: 0.8019
    Episode_Reward/pen_base_height: -0.2089
      Episode_Reward/pen_lin_vel_z: -0.0276
     Episode_Reward/pen_ang_vel_xy: -0.0373
   Episode_Reward/pen_joint_torque: -0.0473
    Episode_Reward/pen_joint_accel: -0.0276
    Episode_Reward/pen_action_rate: -0.0133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0100
   Episode_Reward/pen_joint_powers: -0.0155
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0279
Episode_Reward/pen_flat_orientation: -0.1314
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0515
   Episode_Reward/foot_landing_vel: -0.0444
   Episode_Reward/test_gait_reward: -0.2406
Metrics/base_velocity/error_vel_xy: 0.9095
Metrics/base_velocity/error_vel_yaw: 0.2394
      Episode_Termination/time_out: 0.7917
  Episode_Termination/base_contact: 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 1.09s
                        Total time: 455.16s
                               ETA: 2812.6s

################################################################################
                     [1m Learning iteration 418/3000 [0m                      

                       Computation: 89398 steps/s (collection: 0.978s, learning 0.122s)
               Value function loss: 0.9594
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5966
                     Learning rate: 0.0013
                       Mean reward: 21.13
               Mean episode length: 370.96
       Episode_Reward/keep_balance: 0.3630
     Episode_Reward/rew_lin_vel_xy: 0.7084
      Episode_Reward/rew_ang_vel_z: 1.0929
    Episode_Reward/pen_base_height: -0.2411
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.0480
   Episode_Reward/pen_joint_torque: -0.0671
    Episode_Reward/pen_joint_accel: -0.0413
    Episode_Reward/pen_action_rate: -0.0187
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0148
   Episode_Reward/pen_joint_powers: -0.0224
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0385
Episode_Reward/pen_flat_orientation: -0.1729
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0767
   Episode_Reward/foot_landing_vel: -0.0735
   Episode_Reward/test_gait_reward: -0.3296
Metrics/base_velocity/error_vel_xy: 1.1921
Metrics/base_velocity/error_vel_yaw: 0.3284
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 1.10s
                        Total time: 456.26s
                               ETA: 2811.6s

################################################################################
                     [1m Learning iteration 419/3000 [0m                      

                       Computation: 89288 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 1.0173
                    Surrogate loss: 0.0017
             Mean action noise std: 0.5968
                     Learning rate: 0.0006
                       Mean reward: 21.05
               Mean episode length: 349.92
       Episode_Reward/keep_balance: 0.3385
     Episode_Reward/rew_lin_vel_xy: 0.6898
      Episode_Reward/rew_ang_vel_z: 1.0368
    Episode_Reward/pen_base_height: -0.2336
      Episode_Reward/pen_lin_vel_z: -0.0334
     Episode_Reward/pen_ang_vel_xy: -0.0428
   Episode_Reward/pen_joint_torque: -0.0612
    Episode_Reward/pen_joint_accel: -0.0328
    Episode_Reward/pen_action_rate: -0.0170
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0123
   Episode_Reward/pen_joint_powers: -0.0197
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0354
Episode_Reward/pen_flat_orientation: -0.1485
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0633
   Episode_Reward/foot_landing_vel: -0.0568
   Episode_Reward/test_gait_reward: -0.3050
Metrics/base_velocity/error_vel_xy: 1.1077
Metrics/base_velocity/error_vel_yaw: 0.2913
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 1.10s
                        Total time: 457.36s
                               ETA: 2810.6s

################################################################################
                     [1m Learning iteration 420/3000 [0m                      

                       Computation: 89719 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.7906
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5967
                     Learning rate: 0.0009
                       Mean reward: 17.24
               Mean episode length: 344.03
       Episode_Reward/keep_balance: 0.3320
     Episode_Reward/rew_lin_vel_xy: 0.5982
      Episode_Reward/rew_ang_vel_z: 1.0069
    Episode_Reward/pen_base_height: -0.2398
      Episode_Reward/pen_lin_vel_z: -0.0333
     Episode_Reward/pen_ang_vel_xy: -0.0434
   Episode_Reward/pen_joint_torque: -0.0615
    Episode_Reward/pen_joint_accel: -0.0326
    Episode_Reward/pen_action_rate: -0.0169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0126
   Episode_Reward/pen_joint_powers: -0.0198
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0351
Episode_Reward/pen_flat_orientation: -0.1480
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0651
   Episode_Reward/foot_landing_vel: -0.0585
   Episode_Reward/test_gait_reward: -0.2987
Metrics/base_velocity/error_vel_xy: 1.1346
Metrics/base_velocity/error_vel_yaw: 0.2940
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 1.10s
                        Total time: 458.45s
                               ETA: 2809.5s

################################################################################
                     [1m Learning iteration 421/3000 [0m                      

                       Computation: 88952 steps/s (collection: 0.980s, learning 0.125s)
               Value function loss: 0.7995
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5968
                     Learning rate: 0.0009
                       Mean reward: 18.07
               Mean episode length: 343.03
       Episode_Reward/keep_balance: 0.3108
     Episode_Reward/rew_lin_vel_xy: 0.6230
      Episode_Reward/rew_ang_vel_z: 0.9433
    Episode_Reward/pen_base_height: -0.2354
      Episode_Reward/pen_lin_vel_z: -0.0316
     Episode_Reward/pen_ang_vel_xy: -0.0413
   Episode_Reward/pen_joint_torque: -0.0575
    Episode_Reward/pen_joint_accel: -0.0322
    Episode_Reward/pen_action_rate: -0.0155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0117
   Episode_Reward/pen_joint_powers: -0.0183
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0324
Episode_Reward/pen_flat_orientation: -0.1454
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0619
   Episode_Reward/foot_landing_vel: -0.0546
   Episode_Reward/test_gait_reward: -0.2808
Metrics/base_velocity/error_vel_xy: 1.0377
Metrics/base_velocity/error_vel_yaw: 0.2756
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 1.11s
                        Total time: 459.56s
                               ETA: 2808.5s

################################################################################
                     [1m Learning iteration 422/3000 [0m                      

                       Computation: 90528 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.8199
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5987
                     Learning rate: 0.0006
                       Mean reward: 16.22
               Mean episode length: 295.38
       Episode_Reward/keep_balance: 0.3340
     Episode_Reward/rew_lin_vel_xy: 0.6372
      Episode_Reward/rew_ang_vel_z: 1.0200
    Episode_Reward/pen_base_height: -0.2378
      Episode_Reward/pen_lin_vel_z: -0.0322
     Episode_Reward/pen_ang_vel_xy: -0.0429
   Episode_Reward/pen_joint_torque: -0.0592
    Episode_Reward/pen_joint_accel: -0.0330
    Episode_Reward/pen_action_rate: -0.0167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0119
   Episode_Reward/pen_joint_powers: -0.0190
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0351
Episode_Reward/pen_flat_orientation: -0.1440
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0608
   Episode_Reward/foot_landing_vel: -0.0543
   Episode_Reward/test_gait_reward: -0.2995
Metrics/base_velocity/error_vel_xy: 1.1032
Metrics/base_velocity/error_vel_yaw: 0.2916
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 1.09s
                        Total time: 460.65s
                               ETA: 2807.4s

################################################################################
                     [1m Learning iteration 423/3000 [0m                      

                       Computation: 90230 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.8435
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5988
                     Learning rate: 0.0004
                       Mean reward: 15.58
               Mean episode length: 307.05
       Episode_Reward/keep_balance: 0.3179
     Episode_Reward/rew_lin_vel_xy: 0.5924
      Episode_Reward/rew_ang_vel_z: 0.9640
    Episode_Reward/pen_base_height: -0.2324
      Episode_Reward/pen_lin_vel_z: -0.0338
     Episode_Reward/pen_ang_vel_xy: -0.0427
   Episode_Reward/pen_joint_torque: -0.0600
    Episode_Reward/pen_joint_accel: -0.0329
    Episode_Reward/pen_action_rate: -0.0160
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0126
   Episode_Reward/pen_joint_powers: -0.0196
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0331
Episode_Reward/pen_flat_orientation: -0.1476
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0664
   Episode_Reward/foot_landing_vel: -0.0574
   Episode_Reward/test_gait_reward: -0.2873
Metrics/base_velocity/error_vel_xy: 1.1048
Metrics/base_velocity/error_vel_yaw: 0.2830
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 1.09s
                        Total time: 461.74s
                               ETA: 2806.3s

################################################################################
                     [1m Learning iteration 424/3000 [0m                      

                       Computation: 90661 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.7957
                    Surrogate loss: 0.0038
             Mean action noise std: 0.5989
                     Learning rate: 0.0001
                       Mean reward: 18.25
               Mean episode length: 345.80
       Episode_Reward/keep_balance: 0.3313
     Episode_Reward/rew_lin_vel_xy: 0.6207
      Episode_Reward/rew_ang_vel_z: 1.0017
    Episode_Reward/pen_base_height: -0.2357
      Episode_Reward/pen_lin_vel_z: -0.0336
     Episode_Reward/pen_ang_vel_xy: -0.0424
   Episode_Reward/pen_joint_torque: -0.0613
    Episode_Reward/pen_joint_accel: -0.0328
    Episode_Reward/pen_action_rate: -0.0168
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0125
   Episode_Reward/pen_joint_powers: -0.0198
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0348
Episode_Reward/pen_flat_orientation: -0.1439
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0648
   Episode_Reward/foot_landing_vel: -0.0594
   Episode_Reward/test_gait_reward: -0.2970
Metrics/base_velocity/error_vel_xy: 1.1518
Metrics/base_velocity/error_vel_yaw: 0.2959
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 9.3333
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 1.08s
                        Total time: 462.82s
                               ETA: 2805.2s

################################################################################
                     [1m Learning iteration 425/3000 [0m                      

                       Computation: 88001 steps/s (collection: 0.994s, learning 0.123s)
               Value function loss: 0.8046
                    Surrogate loss: -0.0008
             Mean action noise std: 0.5987
                     Learning rate: 0.0004
                       Mean reward: 16.52
               Mean episode length: 306.55
       Episode_Reward/keep_balance: 0.2928
     Episode_Reward/rew_lin_vel_xy: 0.5880
      Episode_Reward/rew_ang_vel_z: 0.8948
    Episode_Reward/pen_base_height: -0.2249
      Episode_Reward/pen_lin_vel_z: -0.0307
     Episode_Reward/pen_ang_vel_xy: -0.0404
   Episode_Reward/pen_joint_torque: -0.0564
    Episode_Reward/pen_joint_accel: -0.0309
    Episode_Reward/pen_action_rate: -0.0146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0114
   Episode_Reward/pen_joint_powers: -0.0179
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0304
Episode_Reward/pen_flat_orientation: -0.1364
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0596
   Episode_Reward/foot_landing_vel: -0.0512
   Episode_Reward/test_gait_reward: -0.2662
Metrics/base_velocity/error_vel_xy: 0.9970
Metrics/base_velocity/error_vel_yaw: 0.2548
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 1.12s
                        Total time: 463.94s
                               ETA: 2804.3s

################################################################################
                     [1m Learning iteration 426/3000 [0m                      

                       Computation: 89416 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.9104
                    Surrogate loss: -0.0021
             Mean action noise std: 0.5986
                     Learning rate: 0.0009
                       Mean reward: 16.43
               Mean episode length: 287.46
       Episode_Reward/keep_balance: 0.3220
     Episode_Reward/rew_lin_vel_xy: 0.6464
      Episode_Reward/rew_ang_vel_z: 0.9823
    Episode_Reward/pen_base_height: -0.2314
      Episode_Reward/pen_lin_vel_z: -0.0343
     Episode_Reward/pen_ang_vel_xy: -0.0444
   Episode_Reward/pen_joint_torque: -0.0622
    Episode_Reward/pen_joint_accel: -0.0350
    Episode_Reward/pen_action_rate: -0.0166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0128
   Episode_Reward/pen_joint_powers: -0.0201
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0338
Episode_Reward/pen_flat_orientation: -0.1471
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0675
   Episode_Reward/foot_landing_vel: -0.0612
   Episode_Reward/test_gait_reward: -0.2926
Metrics/base_velocity/error_vel_xy: 1.0788
Metrics/base_velocity/error_vel_yaw: 0.2816
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 1.10s
                        Total time: 465.04s
                               ETA: 2803.3s

################################################################################
                     [1m Learning iteration 427/3000 [0m                      

                       Computation: 89039 steps/s (collection: 0.979s, learning 0.125s)
               Value function loss: 0.8892
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6004
                     Learning rate: 0.0019
                       Mean reward: 18.20
               Mean episode length: 303.40
       Episode_Reward/keep_balance: 0.3093
     Episode_Reward/rew_lin_vel_xy: 0.6133
      Episode_Reward/rew_ang_vel_z: 0.9416
    Episode_Reward/pen_base_height: -0.2231
      Episode_Reward/pen_lin_vel_z: -0.0312
     Episode_Reward/pen_ang_vel_xy: -0.0407
   Episode_Reward/pen_joint_torque: -0.0566
    Episode_Reward/pen_joint_accel: -0.0315
    Episode_Reward/pen_action_rate: -0.0155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0114
   Episode_Reward/pen_joint_powers: -0.0182
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0323
Episode_Reward/pen_flat_orientation: -0.1394
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0595
   Episode_Reward/foot_landing_vel: -0.0541
   Episode_Reward/test_gait_reward: -0.2796
Metrics/base_velocity/error_vel_xy: 1.0370
Metrics/base_velocity/error_vel_yaw: 0.2735
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 1.10s
                        Total time: 466.14s
                               ETA: 2802.3s

################################################################################
                     [1m Learning iteration 428/3000 [0m                      

                       Computation: 87840 steps/s (collection: 0.996s, learning 0.123s)
               Value function loss: 1.2544
                    Surrogate loss: 0.0007
             Mean action noise std: 0.6020
                     Learning rate: 0.0019
                       Mean reward: 20.98
               Mean episode length: 372.99
       Episode_Reward/keep_balance: 0.3217
     Episode_Reward/rew_lin_vel_xy: 0.6461
      Episode_Reward/rew_ang_vel_z: 0.9866
    Episode_Reward/pen_base_height: -0.2362
      Episode_Reward/pen_lin_vel_z: -0.0319
     Episode_Reward/pen_ang_vel_xy: -0.0414
   Episode_Reward/pen_joint_torque: -0.0582
    Episode_Reward/pen_joint_accel: -0.0329
    Episode_Reward/pen_action_rate: -0.0162
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0118
   Episode_Reward/pen_joint_powers: -0.0188
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0337
Episode_Reward/pen_flat_orientation: -0.1381
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0604
   Episode_Reward/foot_landing_vel: -0.0535
   Episode_Reward/test_gait_reward: -0.2897
Metrics/base_velocity/error_vel_xy: 1.0747
Metrics/base_velocity/error_vel_yaw: 0.2770
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 1.12s
                        Total time: 467.26s
                               ETA: 2801.4s

################################################################################
                     [1m Learning iteration 429/3000 [0m                      

                       Computation: 89169 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 1.0494
                    Surrogate loss: 0.0031
             Mean action noise std: 0.6022
                     Learning rate: 0.0006
                       Mean reward: 21.50
               Mean episode length: 356.82
       Episode_Reward/keep_balance: 0.3605
     Episode_Reward/rew_lin_vel_xy: 0.7352
      Episode_Reward/rew_ang_vel_z: 1.1141
    Episode_Reward/pen_base_height: -0.2453
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.0441
   Episode_Reward/pen_joint_torque: -0.0670
    Episode_Reward/pen_joint_accel: -0.0334
    Episode_Reward/pen_action_rate: -0.0180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0131
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0376
Episode_Reward/pen_flat_orientation: -0.1520
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0689
   Episode_Reward/foot_landing_vel: -0.0586
   Episode_Reward/test_gait_reward: -0.3253
Metrics/base_velocity/error_vel_xy: 1.1911
Metrics/base_velocity/error_vel_yaw: 0.3048
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 1.10s
                        Total time: 468.36s
                               ETA: 2800.4s

################################################################################
                     [1m Learning iteration 430/3000 [0m                      

                       Computation: 88926 steps/s (collection: 0.981s, learning 0.124s)
               Value function loss: 0.8922
                    Surrogate loss: 0.0010
             Mean action noise std: 0.6026
                     Learning rate: 0.0004
                       Mean reward: 19.37
               Mean episode length: 341.40
       Episode_Reward/keep_balance: 0.3387
     Episode_Reward/rew_lin_vel_xy: 0.6468
      Episode_Reward/rew_ang_vel_z: 1.0359
    Episode_Reward/pen_base_height: -0.2287
      Episode_Reward/pen_lin_vel_z: -0.0335
     Episode_Reward/pen_ang_vel_xy: -0.0425
   Episode_Reward/pen_joint_torque: -0.0616
    Episode_Reward/pen_joint_accel: -0.0355
    Episode_Reward/pen_action_rate: -0.0172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0125
   Episode_Reward/pen_joint_powers: -0.0198
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0358
Episode_Reward/pen_flat_orientation: -0.1450
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0642
   Episode_Reward/foot_landing_vel: -0.0579
   Episode_Reward/test_gait_reward: -0.3056
Metrics/base_velocity/error_vel_xy: 1.1400
Metrics/base_velocity/error_vel_yaw: 0.2943
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 1.11s
                        Total time: 469.47s
                               ETA: 2799.4s

################################################################################
                     [1m Learning iteration 431/3000 [0m                      

                       Computation: 88739 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 0.8650
                    Surrogate loss: 0.0025
             Mean action noise std: 0.6034
                     Learning rate: 0.0002
                       Mean reward: 18.49
               Mean episode length: 310.82
       Episode_Reward/keep_balance: 0.3052
     Episode_Reward/rew_lin_vel_xy: 0.5819
      Episode_Reward/rew_ang_vel_z: 0.9286
    Episode_Reward/pen_base_height: -0.2222
      Episode_Reward/pen_lin_vel_z: -0.0310
     Episode_Reward/pen_ang_vel_xy: -0.0407
   Episode_Reward/pen_joint_torque: -0.0554
    Episode_Reward/pen_joint_accel: -0.0308
    Episode_Reward/pen_action_rate: -0.0155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0115
   Episode_Reward/pen_joint_powers: -0.0180
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0321
Episode_Reward/pen_flat_orientation: -0.1356
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0604
   Episode_Reward/foot_landing_vel: -0.0539
   Episode_Reward/test_gait_reward: -0.2759
Metrics/base_velocity/error_vel_xy: 1.0412
Metrics/base_velocity/error_vel_yaw: 0.2682
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 1.11s
                        Total time: 470.57s
                               ETA: 2798.4s

################################################################################
                     [1m Learning iteration 432/3000 [0m                      

                       Computation: 89289 steps/s (collection: 0.979s, learning 0.122s)
               Value function loss: 0.8071
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6040
                     Learning rate: 0.0004
                       Mean reward: 25.07
               Mean episode length: 392.25
       Episode_Reward/keep_balance: 0.3626
     Episode_Reward/rew_lin_vel_xy: 0.6818
      Episode_Reward/rew_ang_vel_z: 1.1018
    Episode_Reward/pen_base_height: -0.2397
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.0457
   Episode_Reward/pen_joint_torque: -0.0673
    Episode_Reward/pen_joint_accel: -0.0374
    Episode_Reward/pen_action_rate: -0.0188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0217
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0388
Episode_Reward/pen_flat_orientation: -0.1554
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0738
   Episode_Reward/foot_landing_vel: -0.0636
   Episode_Reward/test_gait_reward: -0.3270
Metrics/base_velocity/error_vel_xy: 1.2238
Metrics/base_velocity/error_vel_yaw: 0.3201
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 1.10s
                        Total time: 471.68s
                               ETA: 2797.4s

################################################################################
                     [1m Learning iteration 433/3000 [0m                      

                       Computation: 89591 steps/s (collection: 0.975s, learning 0.122s)
               Value function loss: 0.8483
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6053
                     Learning rate: 0.0009
                       Mean reward: 21.93
               Mean episode length: 353.81
       Episode_Reward/keep_balance: 0.3535
     Episode_Reward/rew_lin_vel_xy: 0.7670
      Episode_Reward/rew_ang_vel_z: 1.0737
    Episode_Reward/pen_base_height: -0.2361
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.0456
   Episode_Reward/pen_joint_torque: -0.0654
    Episode_Reward/pen_joint_accel: -0.0373
    Episode_Reward/pen_action_rate: -0.0182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0135
   Episode_Reward/pen_joint_powers: -0.0213
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0376
Episode_Reward/pen_flat_orientation: -0.1505
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0696
   Episode_Reward/foot_landing_vel: -0.0644
   Episode_Reward/test_gait_reward: -0.3195
Metrics/base_velocity/error_vel_xy: 1.1278
Metrics/base_velocity/error_vel_yaw: 0.3129
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 1.10s
                        Total time: 472.77s
                               ETA: 2796.3s

################################################################################
                     [1m Learning iteration 434/3000 [0m                      

                       Computation: 89487 steps/s (collection: 0.973s, learning 0.125s)
               Value function loss: 0.8280
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6065
                     Learning rate: 0.0013
                       Mean reward: 17.43
               Mean episode length: 344.43
       Episode_Reward/keep_balance: 0.3629
     Episode_Reward/rew_lin_vel_xy: 0.6730
      Episode_Reward/rew_ang_vel_z: 1.1009
    Episode_Reward/pen_base_height: -0.2416
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.0468
   Episode_Reward/pen_joint_torque: -0.0704
    Episode_Reward/pen_joint_accel: -0.0395
    Episode_Reward/pen_action_rate: -0.0190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0146
   Episode_Reward/pen_joint_powers: -0.0227
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0389
Episode_Reward/pen_flat_orientation: -0.1620
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0767
   Episode_Reward/foot_landing_vel: -0.0687
   Episode_Reward/test_gait_reward: -0.3298
Metrics/base_velocity/error_vel_xy: 1.2270
Metrics/base_velocity/error_vel_yaw: 0.3218
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 1.10s
                        Total time: 473.87s
                               ETA: 2795.3s

################################################################################
                     [1m Learning iteration 435/3000 [0m                      

                       Computation: 89036 steps/s (collection: 0.980s, learning 0.124s)
               Value function loss: 0.9406
                    Surrogate loss: 0.0010
             Mean action noise std: 0.6071
                     Learning rate: 0.0004
                       Mean reward: 19.16
               Mean episode length: 322.25
       Episode_Reward/keep_balance: 0.3505
     Episode_Reward/rew_lin_vel_xy: 0.6999
      Episode_Reward/rew_ang_vel_z: 1.0672
    Episode_Reward/pen_base_height: -0.2352
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.0462
   Episode_Reward/pen_joint_torque: -0.0649
    Episode_Reward/pen_joint_accel: -0.0362
    Episode_Reward/pen_action_rate: -0.0181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0133
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0375
Episode_Reward/pen_flat_orientation: -0.1520
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0709
   Episode_Reward/foot_landing_vel: -0.0628
   Episode_Reward/test_gait_reward: -0.3178
Metrics/base_velocity/error_vel_xy: 1.1646
Metrics/base_velocity/error_vel_yaw: 0.3087
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 1.10s
                        Total time: 474.98s
                               ETA: 2794.3s

################################################################################
                     [1m Learning iteration 436/3000 [0m                      

                       Computation: 88866 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 0.8122
                    Surrogate loss: 0.0058
             Mean action noise std: 0.6075
                     Learning rate: 0.0001
                       Mean reward: 19.90
               Mean episode length: 321.33
       Episode_Reward/keep_balance: 0.3377
     Episode_Reward/rew_lin_vel_xy: 0.7048
      Episode_Reward/rew_ang_vel_z: 1.0265
    Episode_Reward/pen_base_height: -0.2311
      Episode_Reward/pen_lin_vel_z: -0.0332
     Episode_Reward/pen_ang_vel_xy: -0.0437
   Episode_Reward/pen_joint_torque: -0.0607
    Episode_Reward/pen_joint_accel: -0.0327
    Episode_Reward/pen_action_rate: -0.0174
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0126
   Episode_Reward/pen_joint_powers: -0.0198
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0363
Episode_Reward/pen_flat_orientation: -0.1418
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0657
   Episode_Reward/foot_landing_vel: -0.0573
   Episode_Reward/test_gait_reward: -0.3038
Metrics/base_velocity/error_vel_xy: 1.1151
Metrics/base_velocity/error_vel_yaw: 0.2974
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 1.11s
                        Total time: 476.08s
                               ETA: 2793.3s

################################################################################
                     [1m Learning iteration 437/3000 [0m                      

                       Computation: 90235 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.8122
                    Surrogate loss: 0.0029
             Mean action noise std: 0.6080
                     Learning rate: 0.0001
                       Mean reward: 18.66
               Mean episode length: 319.06
       Episode_Reward/keep_balance: 0.3551
     Episode_Reward/rew_lin_vel_xy: 0.7413
      Episode_Reward/rew_ang_vel_z: 1.0752
    Episode_Reward/pen_base_height: -0.2433
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.0463
   Episode_Reward/pen_joint_torque: -0.0672
    Episode_Reward/pen_joint_accel: -0.0372
    Episode_Reward/pen_action_rate: -0.0185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0136
   Episode_Reward/pen_joint_powers: -0.0217
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0381
Episode_Reward/pen_flat_orientation: -0.1524
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0755
   Episode_Reward/foot_landing_vel: -0.0629
   Episode_Reward/test_gait_reward: -0.3220
Metrics/base_velocity/error_vel_xy: 1.1701
Metrics/base_velocity/error_vel_yaw: 0.3167
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 1.09s
                        Total time: 477.17s
                               ETA: 2792.2s

################################################################################
                     [1m Learning iteration 438/3000 [0m                      

                       Computation: 89559 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.7926
                    Surrogate loss: 0.0072
             Mean action noise std: 0.6083
                     Learning rate: 0.0000
                       Mean reward: 19.61
               Mean episode length: 340.29
       Episode_Reward/keep_balance: 0.3214
     Episode_Reward/rew_lin_vel_xy: 0.6219
      Episode_Reward/rew_ang_vel_z: 0.9704
    Episode_Reward/pen_base_height: -0.2253
      Episode_Reward/pen_lin_vel_z: -0.0311
     Episode_Reward/pen_ang_vel_xy: -0.0415
   Episode_Reward/pen_joint_torque: -0.0586
    Episode_Reward/pen_joint_accel: -0.0312
    Episode_Reward/pen_action_rate: -0.0167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0118
   Episode_Reward/pen_joint_powers: -0.0187
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0349
Episode_Reward/pen_flat_orientation: -0.1365
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0606
   Episode_Reward/foot_landing_vel: -0.0547
   Episode_Reward/test_gait_reward: -0.2916
Metrics/base_velocity/error_vel_xy: 1.0980
Metrics/base_velocity/error_vel_yaw: 0.2884
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 1.10s
                        Total time: 478.27s
                               ETA: 2791.2s

################################################################################
                     [1m Learning iteration 439/3000 [0m                      

                       Computation: 90776 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.6951
                    Surrogate loss: -0.0012
             Mean action noise std: 0.6088
                     Learning rate: 0.0001
                       Mean reward: 26.31
               Mean episode length: 432.10
       Episode_Reward/keep_balance: 0.3828
     Episode_Reward/rew_lin_vel_xy: 0.8076
      Episode_Reward/rew_ang_vel_z: 1.1623
    Episode_Reward/pen_base_height: -0.2467
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.0480
   Episode_Reward/pen_joint_torque: -0.0685
    Episode_Reward/pen_joint_accel: -0.0397
    Episode_Reward/pen_action_rate: -0.0198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0140
   Episode_Reward/pen_joint_powers: -0.0222
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0411
Episode_Reward/pen_flat_orientation: -0.1501
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0718
   Episode_Reward/foot_landing_vel: -0.0649
   Episode_Reward/test_gait_reward: -0.3423
Metrics/base_velocity/error_vel_xy: 1.2313
Metrics/base_velocity/error_vel_yaw: 0.3373
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 1.08s
                        Total time: 479.35s
                               ETA: 2790.0s

################################################################################
                     [1m Learning iteration 440/3000 [0m                      

                       Computation: 90872 steps/s (collection: 0.955s, learning 0.127s)
               Value function loss: 0.7653
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6092
                     Learning rate: 0.0003
                       Mean reward: 19.03
               Mean episode length: 330.00
       Episode_Reward/keep_balance: 0.3511
     Episode_Reward/rew_lin_vel_xy: 0.7440
      Episode_Reward/rew_ang_vel_z: 1.0691
    Episode_Reward/pen_base_height: -0.2392
      Episode_Reward/pen_lin_vel_z: -0.0349
     Episode_Reward/pen_ang_vel_xy: -0.0461
   Episode_Reward/pen_joint_torque: -0.0664
    Episode_Reward/pen_joint_accel: -0.0340
    Episode_Reward/pen_action_rate: -0.0181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0212
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0374
Episode_Reward/pen_flat_orientation: -0.1470
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0719
   Episode_Reward/foot_landing_vel: -0.0605
   Episode_Reward/test_gait_reward: -0.3210
Metrics/base_velocity/error_vel_xy: 1.1156
Metrics/base_velocity/error_vel_yaw: 0.3089
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 1.08s
                        Total time: 480.43s
                               ETA: 2788.9s

################################################################################
                     [1m Learning iteration 441/3000 [0m                      

                       Computation: 91140 steps/s (collection: 0.954s, learning 0.125s)
               Value function loss: 0.7533
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6088
                     Learning rate: 0.0006
                       Mean reward: 19.67
               Mean episode length: 343.81
       Episode_Reward/keep_balance: 0.3398
     Episode_Reward/rew_lin_vel_xy: 0.7037
      Episode_Reward/rew_ang_vel_z: 1.0262
    Episode_Reward/pen_base_height: -0.2235
      Episode_Reward/pen_lin_vel_z: -0.0340
     Episode_Reward/pen_ang_vel_xy: -0.0444
   Episode_Reward/pen_joint_torque: -0.0641
    Episode_Reward/pen_joint_accel: -0.0363
    Episode_Reward/pen_action_rate: -0.0179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0131
   Episode_Reward/pen_joint_powers: -0.0206
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0372
Episode_Reward/pen_flat_orientation: -0.1433
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0687
   Episode_Reward/foot_landing_vel: -0.0607
   Episode_Reward/test_gait_reward: -0.3095
Metrics/base_velocity/error_vel_xy: 1.1160
Metrics/base_velocity/error_vel_yaw: 0.3037
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 1.08s
                        Total time: 481.51s
                               ETA: 2787.8s

################################################################################
                     [1m Learning iteration 442/3000 [0m                      

                       Computation: 90623 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.8178
                    Surrogate loss: 0.0003
             Mean action noise std: 0.6100
                     Learning rate: 0.0006
                       Mean reward: 19.93
               Mean episode length: 347.76
       Episode_Reward/keep_balance: 0.3367
     Episode_Reward/rew_lin_vel_xy: 0.6957
      Episode_Reward/rew_ang_vel_z: 1.0226
    Episode_Reward/pen_base_height: -0.2233
      Episode_Reward/pen_lin_vel_z: -0.0339
     Episode_Reward/pen_ang_vel_xy: -0.0453
   Episode_Reward/pen_joint_torque: -0.0634
    Episode_Reward/pen_joint_accel: -0.0355
    Episode_Reward/pen_action_rate: -0.0176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0129
   Episode_Reward/pen_joint_powers: -0.0205
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0362
Episode_Reward/pen_flat_orientation: -0.1483
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0706
   Episode_Reward/foot_landing_vel: -0.0583
   Episode_Reward/test_gait_reward: -0.3086
Metrics/base_velocity/error_vel_xy: 1.1091
Metrics/base_velocity/error_vel_yaw: 0.2985
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 1.08s
                        Total time: 482.60s
                               ETA: 2786.6s

################################################################################
                     [1m Learning iteration 443/3000 [0m                      

                       Computation: 89852 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.8849
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6102
                     Learning rate: 0.0013
                       Mean reward: 20.37
               Mean episode length: 396.28
       Episode_Reward/keep_balance: 0.3949
     Episode_Reward/rew_lin_vel_xy: 0.7651
      Episode_Reward/rew_ang_vel_z: 1.2043
    Episode_Reward/pen_base_height: -0.2483
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.0497
   Episode_Reward/pen_joint_torque: -0.0760
    Episode_Reward/pen_joint_accel: -0.0400
    Episode_Reward/pen_action_rate: -0.0209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0152
   Episode_Reward/pen_joint_powers: -0.0242
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0429
Episode_Reward/pen_flat_orientation: -0.1637
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0834
   Episode_Reward/foot_landing_vel: -0.0695
   Episode_Reward/test_gait_reward: -0.3586
Metrics/base_velocity/error_vel_xy: 1.3185
Metrics/base_velocity/error_vel_yaw: 0.3449
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 1.09s
                        Total time: 483.69s
                               ETA: 2785.6s

################################################################################
                     [1m Learning iteration 444/3000 [0m                      

                       Computation: 91015 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.8771
                    Surrogate loss: -0.0007
             Mean action noise std: 0.6103
                     Learning rate: 0.0013
                       Mean reward: 15.90
               Mean episode length: 290.29
       Episode_Reward/keep_balance: 0.3360
     Episode_Reward/rew_lin_vel_xy: 0.6270
      Episode_Reward/rew_ang_vel_z: 1.0149
    Episode_Reward/pen_base_height: -0.2215
      Episode_Reward/pen_lin_vel_z: -0.0333
     Episode_Reward/pen_ang_vel_xy: -0.0455
   Episode_Reward/pen_joint_torque: -0.0603
    Episode_Reward/pen_joint_accel: -0.0338
    Episode_Reward/pen_action_rate: -0.0177
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0127
   Episode_Reward/pen_joint_powers: -0.0199
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0366
Episode_Reward/pen_flat_orientation: -0.1459
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0679
   Episode_Reward/foot_landing_vel: -0.0567
   Episode_Reward/test_gait_reward: -0.3051
Metrics/base_velocity/error_vel_xy: 1.1600
Metrics/base_velocity/error_vel_yaw: 0.3005
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 1.08s
                        Total time: 484.77s
                               ETA: 2784.4s

################################################################################
                     [1m Learning iteration 445/3000 [0m                      

                       Computation: 89778 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.7500
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6106
                     Learning rate: 0.0009
                       Mean reward: 23.11
               Mean episode length: 361.70
       Episode_Reward/keep_balance: 0.3602
     Episode_Reward/rew_lin_vel_xy: 0.7452
      Episode_Reward/rew_ang_vel_z: 1.0986
    Episode_Reward/pen_base_height: -0.2358
      Episode_Reward/pen_lin_vel_z: -0.0353
     Episode_Reward/pen_ang_vel_xy: -0.0460
   Episode_Reward/pen_joint_torque: -0.0668
    Episode_Reward/pen_joint_accel: -0.0342
    Episode_Reward/pen_action_rate: -0.0189
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0133
   Episode_Reward/pen_joint_powers: -0.0215
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0391
Episode_Reward/pen_flat_orientation: -0.1505
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0753
   Episode_Reward/foot_landing_vel: -0.0602
   Episode_Reward/test_gait_reward: -0.3272
Metrics/base_velocity/error_vel_xy: 1.1813
Metrics/base_velocity/error_vel_yaw: 0.3147
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 1.09s
                        Total time: 485.87s
                               ETA: 2783.4s

################################################################################
                     [1m Learning iteration 446/3000 [0m                      

                       Computation: 89860 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.9103
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6107
                     Learning rate: 0.0013
                       Mean reward: 21.88
               Mean episode length: 380.59
       Episode_Reward/keep_balance: 0.3663
     Episode_Reward/rew_lin_vel_xy: 0.7415
      Episode_Reward/rew_ang_vel_z: 1.1065
    Episode_Reward/pen_base_height: -0.2370
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.0499
   Episode_Reward/pen_joint_torque: -0.0686
    Episode_Reward/pen_joint_accel: -0.0383
    Episode_Reward/pen_action_rate: -0.0198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0145
   Episode_Reward/pen_joint_powers: -0.0227
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0403
Episode_Reward/pen_flat_orientation: -0.1595
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0811
   Episode_Reward/foot_landing_vel: -0.0675
   Episode_Reward/test_gait_reward: -0.3348
Metrics/base_velocity/error_vel_xy: 1.2232
Metrics/base_velocity/error_vel_yaw: 0.3281
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 1.09s
                        Total time: 486.96s
                               ETA: 2782.3s

################################################################################
                     [1m Learning iteration 447/3000 [0m                      

                       Computation: 88598 steps/s (collection: 0.985s, learning 0.124s)
               Value function loss: 1.1232
                    Surrogate loss: -0.0012
             Mean action noise std: 0.6112
                     Learning rate: 0.0013
                       Mean reward: 21.58
               Mean episode length: 375.16
       Episode_Reward/keep_balance: 0.3689
     Episode_Reward/rew_lin_vel_xy: 0.6959
      Episode_Reward/rew_ang_vel_z: 1.1259
    Episode_Reward/pen_base_height: -0.2374
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.0483
   Episode_Reward/pen_joint_torque: -0.0684
    Episode_Reward/pen_joint_accel: -0.0377
    Episode_Reward/pen_action_rate: -0.0194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0139
   Episode_Reward/pen_joint_powers: -0.0222
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0398
Episode_Reward/pen_flat_orientation: -0.1539
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0762
   Episode_Reward/foot_landing_vel: -0.0623
   Episode_Reward/test_gait_reward: -0.3359
Metrics/base_velocity/error_vel_xy: 1.2859
Metrics/base_velocity/error_vel_yaw: 0.3210
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 1.11s
                        Total time: 488.07s
                               ETA: 2781.3s

################################################################################
                     [1m Learning iteration 448/3000 [0m                      

                       Computation: 89005 steps/s (collection: 0.979s, learning 0.125s)
               Value function loss: 1.1032
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6116
                     Learning rate: 0.0019
                       Mean reward: 18.51
               Mean episode length: 331.32
       Episode_Reward/keep_balance: 0.3553
     Episode_Reward/rew_lin_vel_xy: 0.6973
      Episode_Reward/rew_ang_vel_z: 1.0796
    Episode_Reward/pen_base_height: -0.2357
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.0472
   Episode_Reward/pen_joint_torque: -0.0675
    Episode_Reward/pen_joint_accel: -0.0376
    Episode_Reward/pen_action_rate: -0.0190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0140
   Episode_Reward/pen_joint_powers: -0.0219
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0389
Episode_Reward/pen_flat_orientation: -0.1546
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0785
   Episode_Reward/foot_landing_vel: -0.0602
   Episode_Reward/test_gait_reward: -0.3266
Metrics/base_velocity/error_vel_xy: 1.1512
Metrics/base_velocity/error_vel_yaw: 0.3149
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 1.10s
                        Total time: 489.17s
                               ETA: 2780.3s

################################################################################
                     [1m Learning iteration 449/3000 [0m                      

                       Computation: 88776 steps/s (collection: 0.984s, learning 0.123s)
               Value function loss: 1.1831
                    Surrogate loss: 0.0123
             Mean action noise std: 0.6122
                     Learning rate: 0.0001
                       Mean reward: 23.06
               Mean episode length: 365.18
       Episode_Reward/keep_balance: 0.4148
     Episode_Reward/rew_lin_vel_xy: 0.9123
      Episode_Reward/rew_ang_vel_z: 1.2572
    Episode_Reward/pen_base_height: -0.2508
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.0526
   Episode_Reward/pen_joint_torque: -0.0771
    Episode_Reward/pen_joint_accel: -0.0435
    Episode_Reward/pen_action_rate: -0.0224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0156
   Episode_Reward/pen_joint_powers: -0.0247
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0463
Episode_Reward/pen_flat_orientation: -0.1733
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0859
   Episode_Reward/foot_landing_vel: -0.0698
   Episode_Reward/test_gait_reward: -0.3758
Metrics/base_velocity/error_vel_xy: 1.3320
Metrics/base_velocity/error_vel_yaw: 0.3684
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 1.11s
                        Total time: 490.28s
                               ETA: 2779.4s

################################################################################
                     [1m Learning iteration 450/3000 [0m                      

                       Computation: 88910 steps/s (collection: 0.979s, learning 0.126s)
               Value function loss: 0.8006
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6123
                     Learning rate: 0.0003
                       Mean reward: 24.02
               Mean episode length: 391.89
       Episode_Reward/keep_balance: 0.4036
     Episode_Reward/rew_lin_vel_xy: 0.8622
      Episode_Reward/rew_ang_vel_z: 1.2295
    Episode_Reward/pen_base_height: -0.2514
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.0508
   Episode_Reward/pen_joint_torque: -0.0765
    Episode_Reward/pen_joint_accel: -0.0420
    Episode_Reward/pen_action_rate: -0.0216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0152
   Episode_Reward/pen_joint_powers: -0.0244
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0444
Episode_Reward/pen_flat_orientation: -0.1641
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0852
   Episode_Reward/foot_landing_vel: -0.0662
   Episode_Reward/test_gait_reward: -0.3686
Metrics/base_velocity/error_vel_xy: 1.3027
Metrics/base_velocity/error_vel_yaw: 0.3540
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 1.11s
                        Total time: 491.39s
                               ETA: 2778.4s

################################################################################
                     [1m Learning iteration 451/3000 [0m                      

                       Computation: 88498 steps/s (collection: 0.987s, learning 0.124s)
               Value function loss: 0.8037
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6126
                     Learning rate: 0.0003
                       Mean reward: 26.02
               Mean episode length: 424.02
       Episode_Reward/keep_balance: 0.3954
     Episode_Reward/rew_lin_vel_xy: 0.8615
      Episode_Reward/rew_ang_vel_z: 1.1978
    Episode_Reward/pen_base_height: -0.2461
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.0525
   Episode_Reward/pen_joint_torque: -0.0760
    Episode_Reward/pen_joint_accel: -0.0444
    Episode_Reward/pen_action_rate: -0.0214
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0156
   Episode_Reward/pen_joint_powers: -0.0246
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0438
Episode_Reward/pen_flat_orientation: -0.1595
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0845
   Episode_Reward/foot_landing_vel: -0.0686
   Episode_Reward/test_gait_reward: -0.3610
Metrics/base_velocity/error_vel_xy: 1.2495
Metrics/base_velocity/error_vel_yaw: 0.3523
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 1.11s
                        Total time: 492.50s
                               ETA: 2777.4s

################################################################################
                     [1m Learning iteration 452/3000 [0m                      

                       Computation: 88330 steps/s (collection: 0.988s, learning 0.125s)
               Value function loss: 0.7378
                    Surrogate loss: 0.0031
             Mean action noise std: 0.6129
                     Learning rate: 0.0001
                       Mean reward: 22.37
               Mean episode length: 354.24
       Episode_Reward/keep_balance: 0.3939
     Episode_Reward/rew_lin_vel_xy: 0.8579
      Episode_Reward/rew_ang_vel_z: 1.1962
    Episode_Reward/pen_base_height: -0.2477
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.0501
   Episode_Reward/pen_joint_torque: -0.0759
    Episode_Reward/pen_joint_accel: -0.0395
    Episode_Reward/pen_action_rate: -0.0214
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0148
   Episode_Reward/pen_joint_powers: -0.0239
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0441
Episode_Reward/pen_flat_orientation: -0.1615
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0838
   Episode_Reward/foot_landing_vel: -0.0629
   Episode_Reward/test_gait_reward: -0.3594
Metrics/base_velocity/error_vel_xy: 1.2698
Metrics/base_velocity/error_vel_yaw: 0.3492
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 1.11s
                        Total time: 493.61s
                               ETA: 2776.4s

################################################################################
                     [1m Learning iteration 453/3000 [0m                      

                       Computation: 89609 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.7287
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6125
                     Learning rate: 0.0001
                       Mean reward: 19.12
               Mean episode length: 371.89
       Episode_Reward/keep_balance: 0.3949
     Episode_Reward/rew_lin_vel_xy: 0.7803
      Episode_Reward/rew_ang_vel_z: 1.1980
    Episode_Reward/pen_base_height: -0.2457
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.0510
   Episode_Reward/pen_joint_torque: -0.0734
    Episode_Reward/pen_joint_accel: -0.0413
    Episode_Reward/pen_action_rate: -0.0216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0153
   Episode_Reward/pen_joint_powers: -0.0239
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0442
Episode_Reward/pen_flat_orientation: -0.1685
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0837
   Episode_Reward/foot_landing_vel: -0.0707
   Episode_Reward/test_gait_reward: -0.3624
Metrics/base_velocity/error_vel_xy: 1.3175
Metrics/base_velocity/error_vel_yaw: 0.3506
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 1.10s
                        Total time: 494.71s
                               ETA: 2775.4s

################################################################################
                     [1m Learning iteration 454/3000 [0m                      

                       Computation: 84384 steps/s (collection: 1.042s, learning 0.123s)
               Value function loss: 0.8187
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6121
                     Learning rate: 0.0001
                       Mean reward: 20.38
               Mean episode length: 354.04
       Episode_Reward/keep_balance: 0.3693
     Episode_Reward/rew_lin_vel_xy: 0.8115
      Episode_Reward/rew_ang_vel_z: 1.1112
    Episode_Reward/pen_base_height: -0.2372
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.0494
   Episode_Reward/pen_joint_torque: -0.0693
    Episode_Reward/pen_joint_accel: -0.0405
    Episode_Reward/pen_action_rate: -0.0205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0229
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0421
Episode_Reward/pen_flat_orientation: -0.1539
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0808
   Episode_Reward/foot_landing_vel: -0.0689
   Episode_Reward/test_gait_reward: -0.3391
Metrics/base_velocity/error_vel_xy: 1.2398
Metrics/base_velocity/error_vel_yaw: 0.3325
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 1.16s
                        Total time: 495.87s
                               ETA: 2774.7s

################################################################################
                     [1m Learning iteration 455/3000 [0m                      

                       Computation: 88751 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 0.8089
                    Surrogate loss: 0.0014
             Mean action noise std: 0.6125
                     Learning rate: 0.0003
                       Mean reward: 21.71
               Mean episode length: 379.57
       Episode_Reward/keep_balance: 0.3955
     Episode_Reward/rew_lin_vel_xy: 0.7977
      Episode_Reward/rew_ang_vel_z: 1.1816
    Episode_Reward/pen_base_height: -0.2504
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.0497
   Episode_Reward/pen_joint_torque: -0.0739
    Episode_Reward/pen_joint_accel: -0.0402
    Episode_Reward/pen_action_rate: -0.0218
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0150
   Episode_Reward/pen_joint_powers: -0.0239
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0450
Episode_Reward/pen_flat_orientation: -0.1610
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0858
   Episode_Reward/foot_landing_vel: -0.0656
   Episode_Reward/test_gait_reward: -0.3610
Metrics/base_velocity/error_vel_xy: 1.3273
Metrics/base_velocity/error_vel_yaw: 0.3638
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 1.11s
                        Total time: 496.98s
                               ETA: 2773.7s

################################################################################
                     [1m Learning iteration 456/3000 [0m                      

                       Computation: 90132 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.8200
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6128
                     Learning rate: 0.0004
                       Mean reward: 20.16
               Mean episode length: 351.15
       Episode_Reward/keep_balance: 0.3740
     Episode_Reward/rew_lin_vel_xy: 0.7719
      Episode_Reward/rew_ang_vel_z: 1.1247
    Episode_Reward/pen_base_height: -0.2332
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.0489
   Episode_Reward/pen_joint_torque: -0.0687
    Episode_Reward/pen_joint_accel: -0.0396
    Episode_Reward/pen_action_rate: -0.0206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0225
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0424
Episode_Reward/pen_flat_orientation: -0.1579
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0816
   Episode_Reward/foot_landing_vel: -0.0618
   Episode_Reward/test_gait_reward: -0.3413
Metrics/base_velocity/error_vel_xy: 1.2244
Metrics/base_velocity/error_vel_yaw: 0.3385
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 1.09s
                        Total time: 498.07s
                               ETA: 2772.6s

################################################################################
                     [1m Learning iteration 457/3000 [0m                      

                       Computation: 89781 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.8559
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6127
                     Learning rate: 0.0009
                       Mean reward: 27.62
               Mean episode length: 396.15
       Episode_Reward/keep_balance: 0.3644
     Episode_Reward/rew_lin_vel_xy: 0.8313
      Episode_Reward/rew_ang_vel_z: 1.1082
    Episode_Reward/pen_base_height: -0.2321
      Episode_Reward/pen_lin_vel_z: -0.0343
     Episode_Reward/pen_ang_vel_xy: -0.0481
   Episode_Reward/pen_joint_torque: -0.0671
    Episode_Reward/pen_joint_accel: -0.0402
    Episode_Reward/pen_action_rate: -0.0200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0140
   Episode_Reward/pen_joint_powers: -0.0219
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0414
Episode_Reward/pen_flat_orientation: -0.1507
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0766
   Episode_Reward/foot_landing_vel: -0.0605
   Episode_Reward/test_gait_reward: -0.3334
Metrics/base_velocity/error_vel_xy: 1.1256
Metrics/base_velocity/error_vel_yaw: 0.3194
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 1.09s
                        Total time: 499.17s
                               ETA: 2771.6s

################################################################################
                     [1m Learning iteration 458/3000 [0m                      

                       Computation: 89858 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 1.2314
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6133
                     Learning rate: 0.0019
                       Mean reward: 21.91
               Mean episode length: 359.25
       Episode_Reward/keep_balance: 0.3962
     Episode_Reward/rew_lin_vel_xy: 0.9207
      Episode_Reward/rew_ang_vel_z: 1.1945
    Episode_Reward/pen_base_height: -0.2397
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.0521
   Episode_Reward/pen_joint_torque: -0.0737
    Episode_Reward/pen_joint_accel: -0.0430
    Episode_Reward/pen_action_rate: -0.0221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0155
   Episode_Reward/pen_joint_powers: -0.0242
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0457
Episode_Reward/pen_flat_orientation: -0.1651
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0854
   Episode_Reward/foot_landing_vel: -0.0705
   Episode_Reward/test_gait_reward: -0.3637
Metrics/base_velocity/error_vel_xy: 1.2486
Metrics/base_velocity/error_vel_yaw: 0.3616
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 1.09s
                        Total time: 500.26s
                               ETA: 2770.5s

################################################################################
                     [1m Learning iteration 459/3000 [0m                      

                       Computation: 89809 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 1.0006
                    Surrogate loss: 0.0031
             Mean action noise std: 0.6141
                     Learning rate: 0.0006
                       Mean reward: 20.01
               Mean episode length: 354.27
       Episode_Reward/keep_balance: 0.3893
     Episode_Reward/rew_lin_vel_xy: 0.8371
      Episode_Reward/rew_ang_vel_z: 1.1825
    Episode_Reward/pen_base_height: -0.2412
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.0509
   Episode_Reward/pen_joint_torque: -0.0727
    Episode_Reward/pen_joint_accel: -0.0407
    Episode_Reward/pen_action_rate: -0.0214
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0151
   Episode_Reward/pen_joint_powers: -0.0237
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0441
Episode_Reward/pen_flat_orientation: -0.1602
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0831
   Episode_Reward/foot_landing_vel: -0.0680
   Episode_Reward/test_gait_reward: -0.3564
Metrics/base_velocity/error_vel_xy: 1.2611
Metrics/base_velocity/error_vel_yaw: 0.3434
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 9.3333
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 1.09s
                        Total time: 501.35s
                               ETA: 2769.4s

################################################################################
                     [1m Learning iteration 460/3000 [0m                      

                       Computation: 88149 steps/s (collection: 0.989s, learning 0.126s)
               Value function loss: 0.8126
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6145
                     Learning rate: 0.0009
                       Mean reward: 26.11
               Mean episode length: 407.92
       Episode_Reward/keep_balance: 0.3894
     Episode_Reward/rew_lin_vel_xy: 0.9103
      Episode_Reward/rew_ang_vel_z: 1.1852
    Episode_Reward/pen_base_height: -0.2400
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.0519
   Episode_Reward/pen_joint_torque: -0.0731
    Episode_Reward/pen_joint_accel: -0.0402
    Episode_Reward/pen_action_rate: -0.0214
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0145
   Episode_Reward/pen_joint_powers: -0.0233
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0442
Episode_Reward/pen_flat_orientation: -0.1566
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0796
   Episode_Reward/foot_landing_vel: -0.0625
   Episode_Reward/test_gait_reward: -0.3555
Metrics/base_velocity/error_vel_xy: 1.2118
Metrics/base_velocity/error_vel_yaw: 0.3429
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 1.12s
                        Total time: 502.47s
                               ETA: 2768.5s

################################################################################
                     [1m Learning iteration 461/3000 [0m                      

                       Computation: 89823 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.8305
                    Surrogate loss: 0.0010
             Mean action noise std: 0.6154
                     Learning rate: 0.0004
                       Mean reward: 25.59
               Mean episode length: 414.83
       Episode_Reward/keep_balance: 0.3840
     Episode_Reward/rew_lin_vel_xy: 0.8361
      Episode_Reward/rew_ang_vel_z: 1.1649
    Episode_Reward/pen_base_height: -0.2391
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.0494
   Episode_Reward/pen_joint_torque: -0.0705
    Episode_Reward/pen_joint_accel: -0.0392
    Episode_Reward/pen_action_rate: -0.0211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0143
   Episode_Reward/pen_joint_powers: -0.0227
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0437
Episode_Reward/pen_flat_orientation: -0.1572
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0792
   Episode_Reward/foot_landing_vel: -0.0634
   Episode_Reward/test_gait_reward: -0.3502
Metrics/base_velocity/error_vel_xy: 1.2484
Metrics/base_velocity/error_vel_yaw: 0.3429
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 1.09s
                        Total time: 503.56s
                               ETA: 2767.4s

################################################################################
                     [1m Learning iteration 462/3000 [0m                      

                       Computation: 89211 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.9090
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6158
                     Learning rate: 0.0006
                       Mean reward: 28.67
               Mean episode length: 432.78
       Episode_Reward/keep_balance: 0.4459
     Episode_Reward/rew_lin_vel_xy: 0.9826
      Episode_Reward/rew_ang_vel_z: 1.3528
    Episode_Reward/pen_base_height: -0.2515
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.0541
   Episode_Reward/pen_joint_torque: -0.0820
    Episode_Reward/pen_joint_accel: -0.0454
    Episode_Reward/pen_action_rate: -0.0248
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0163
   Episode_Reward/pen_joint_powers: -0.0262
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0508
Episode_Reward/pen_flat_orientation: -0.1700
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0916
   Episode_Reward/foot_landing_vel: -0.0737
   Episode_Reward/test_gait_reward: -0.4058
Metrics/base_velocity/error_vel_xy: 1.4568
Metrics/base_velocity/error_vel_yaw: 0.3931
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 1.10s
                        Total time: 504.67s
                               ETA: 2766.4s

################################################################################
                     [1m Learning iteration 463/3000 [0m                      

                       Computation: 89478 steps/s (collection: 0.974s, learning 0.125s)
               Value function loss: 1.0003
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6165
                     Learning rate: 0.0019
                       Mean reward: 24.05
               Mean episode length: 385.52
       Episode_Reward/keep_balance: 0.3859
     Episode_Reward/rew_lin_vel_xy: 0.8120
      Episode_Reward/rew_ang_vel_z: 1.1583
    Episode_Reward/pen_base_height: -0.2368
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.0499
   Episode_Reward/pen_joint_torque: -0.0707
    Episode_Reward/pen_joint_accel: -0.0389
    Episode_Reward/pen_action_rate: -0.0215
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0143
   Episode_Reward/pen_joint_powers: -0.0228
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0444
Episode_Reward/pen_flat_orientation: -0.1524
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0792
   Episode_Reward/foot_landing_vel: -0.0645
   Episode_Reward/test_gait_reward: -0.3540
Metrics/base_velocity/error_vel_xy: 1.2699
Metrics/base_velocity/error_vel_yaw: 0.3499
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 1.10s
                        Total time: 505.76s
                               ETA: 2765.4s

################################################################################
                     [1m Learning iteration 464/3000 [0m                      

                       Computation: 90298 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 1.1061
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6178
                     Learning rate: 0.0006
                       Mean reward: 26.08
               Mean episode length: 388.36
       Episode_Reward/keep_balance: 0.3700
     Episode_Reward/rew_lin_vel_xy: 0.8509
      Episode_Reward/rew_ang_vel_z: 1.1309
    Episode_Reward/pen_base_height: -0.2324
      Episode_Reward/pen_lin_vel_z: -0.0332
     Episode_Reward/pen_ang_vel_xy: -0.0484
   Episode_Reward/pen_joint_torque: -0.0658
    Episode_Reward/pen_joint_accel: -0.0375
    Episode_Reward/pen_action_rate: -0.0202
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0133
   Episode_Reward/pen_joint_powers: -0.0213
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0421
Episode_Reward/pen_flat_orientation: -0.1494
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0715
   Episode_Reward/foot_landing_vel: -0.0581
   Episode_Reward/test_gait_reward: -0.3379
Metrics/base_velocity/error_vel_xy: 1.1727
Metrics/base_velocity/error_vel_yaw: 0.3216
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 1.09s
                        Total time: 506.85s
                               ETA: 2764.3s

################################################################################
                     [1m Learning iteration 465/3000 [0m                      

                       Computation: 89462 steps/s (collection: 0.977s, learning 0.122s)
               Value function loss: 1.2196
                    Surrogate loss: 0.0058
             Mean action noise std: 0.6179
                     Learning rate: 0.0001
                       Mean reward: 23.08
               Mean episode length: 369.98
       Episode_Reward/keep_balance: 0.3662
     Episode_Reward/rew_lin_vel_xy: 0.8088
      Episode_Reward/rew_ang_vel_z: 1.1002
    Episode_Reward/pen_base_height: -0.2297
      Episode_Reward/pen_lin_vel_z: -0.0339
     Episode_Reward/pen_ang_vel_xy: -0.0486
   Episode_Reward/pen_joint_torque: -0.0667
    Episode_Reward/pen_joint_accel: -0.0356
    Episode_Reward/pen_action_rate: -0.0203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0217
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0421
Episode_Reward/pen_flat_orientation: -0.1487
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0769
   Episode_Reward/foot_landing_vel: -0.0593
   Episode_Reward/test_gait_reward: -0.3363
Metrics/base_velocity/error_vel_xy: 1.1667
Metrics/base_velocity/error_vel_yaw: 0.3323
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 1.10s
                        Total time: 507.95s
                               ETA: 2763.2s

################################################################################
                     [1m Learning iteration 466/3000 [0m                      

                       Computation: 89791 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 1.0423
                    Surrogate loss: 0.0061
             Mean action noise std: 0.6180
                     Learning rate: 0.0000
                       Mean reward: 22.53
               Mean episode length: 359.26
       Episode_Reward/keep_balance: 0.3502
     Episode_Reward/rew_lin_vel_xy: 0.7522
      Episode_Reward/rew_ang_vel_z: 1.0431
    Episode_Reward/pen_base_height: -0.2244
      Episode_Reward/pen_lin_vel_z: -0.0340
     Episode_Reward/pen_ang_vel_xy: -0.0485
   Episode_Reward/pen_joint_torque: -0.0630
    Episode_Reward/pen_joint_accel: -0.0373
    Episode_Reward/pen_action_rate: -0.0196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0136
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0406
Episode_Reward/pen_flat_orientation: -0.1476
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0765
   Episode_Reward/foot_landing_vel: -0.0595
   Episode_Reward/test_gait_reward: -0.3214
Metrics/base_velocity/error_vel_xy: 1.1394
Metrics/base_velocity/error_vel_yaw: 0.3278
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 1.09s
                        Total time: 509.05s
                               ETA: 2762.2s

################################################################################
                     [1m Learning iteration 467/3000 [0m                      

                       Computation: 89818 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.9868
                    Surrogate loss: 0.0008
             Mean action noise std: 0.6178
                     Learning rate: 0.0002
                       Mean reward: 23.25
               Mean episode length: 395.33
       Episode_Reward/keep_balance: 0.3822
     Episode_Reward/rew_lin_vel_xy: 0.7723
      Episode_Reward/rew_ang_vel_z: 1.1515
    Episode_Reward/pen_base_height: -0.2316
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.0518
   Episode_Reward/pen_joint_torque: -0.0736
    Episode_Reward/pen_joint_accel: -0.0432
    Episode_Reward/pen_action_rate: -0.0216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0154
   Episode_Reward/pen_joint_powers: -0.0240
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0439
Episode_Reward/pen_flat_orientation: -0.1563
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0847
   Episode_Reward/foot_landing_vel: -0.0669
   Episode_Reward/test_gait_reward: -0.3519
Metrics/base_velocity/error_vel_xy: 1.2845
Metrics/base_velocity/error_vel_yaw: 0.3458
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 1.09s
                        Total time: 510.14s
                               ETA: 2761.1s

################################################################################
                     [1m Learning iteration 468/3000 [0m                      

                       Computation: 90434 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 1.0050
                    Surrogate loss: 0.0022
             Mean action noise std: 0.6177
                     Learning rate: 0.0001
                       Mean reward: 25.46
               Mean episode length: 390.61
       Episode_Reward/keep_balance: 0.4079
     Episode_Reward/rew_lin_vel_xy: 0.9295
      Episode_Reward/rew_ang_vel_z: 1.2270
    Episode_Reward/pen_base_height: -0.2450
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.0541
   Episode_Reward/pen_joint_torque: -0.0788
    Episode_Reward/pen_joint_accel: -0.0437
    Episode_Reward/pen_action_rate: -0.0232
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0162
   Episode_Reward/pen_joint_powers: -0.0255
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0472
Episode_Reward/pen_flat_orientation: -0.1695
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0922
   Episode_Reward/foot_landing_vel: -0.0735
   Episode_Reward/test_gait_reward: -0.3767
Metrics/base_velocity/error_vel_xy: 1.3071
Metrics/base_velocity/error_vel_yaw: 0.3700
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 1.09s
                        Total time: 511.23s
                               ETA: 2760.0s

################################################################################
                     [1m Learning iteration 469/3000 [0m                      

                       Computation: 90198 steps/s (collection: 0.965s, learning 0.125s)
               Value function loss: 0.8361
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6183
                     Learning rate: 0.0006
                       Mean reward: 23.72
               Mean episode length: 371.71
       Episode_Reward/keep_balance: 0.3696
     Episode_Reward/rew_lin_vel_xy: 0.8764
      Episode_Reward/rew_ang_vel_z: 1.1207
    Episode_Reward/pen_base_height: -0.2286
      Episode_Reward/pen_lin_vel_z: -0.0349
     Episode_Reward/pen_ang_vel_xy: -0.0495
   Episode_Reward/pen_joint_torque: -0.0699
    Episode_Reward/pen_joint_accel: -0.0406
    Episode_Reward/pen_action_rate: -0.0206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0142
   Episode_Reward/pen_joint_powers: -0.0224
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0424
Episode_Reward/pen_flat_orientation: -0.1504
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0788
   Episode_Reward/foot_landing_vel: -0.0606
   Episode_Reward/test_gait_reward: -0.3398
Metrics/base_velocity/error_vel_xy: 1.1392
Metrics/base_velocity/error_vel_yaw: 0.3279
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 1.09s
                        Total time: 512.32s
                               ETA: 2758.9s

################################################################################
                     [1m Learning iteration 470/3000 [0m                      

                       Computation: 89488 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.9758
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6188
                     Learning rate: 0.0009
                       Mean reward: 23.81
               Mean episode length: 375.09
       Episode_Reward/keep_balance: 0.3406
     Episode_Reward/rew_lin_vel_xy: 0.7890
      Episode_Reward/rew_ang_vel_z: 1.0315
    Episode_Reward/pen_base_height: -0.2155
      Episode_Reward/pen_lin_vel_z: -0.0314
     Episode_Reward/pen_ang_vel_xy: -0.0473
   Episode_Reward/pen_joint_torque: -0.0620
    Episode_Reward/pen_joint_accel: -0.0341
    Episode_Reward/pen_action_rate: -0.0188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0126
   Episode_Reward/pen_joint_powers: -0.0202
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0390
Episode_Reward/pen_flat_orientation: -0.1374
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0677
   Episode_Reward/foot_landing_vel: -0.0532
   Episode_Reward/test_gait_reward: -0.3127
Metrics/base_velocity/error_vel_xy: 1.0991
Metrics/base_velocity/error_vel_yaw: 0.3040
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 1.10s
                        Total time: 513.42s
                               ETA: 2757.8s

################################################################################
                     [1m Learning iteration 471/3000 [0m                      

                       Computation: 89788 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 1.6251
                    Surrogate loss: 0.0008
             Mean action noise std: 0.6188
                     Learning rate: 0.0006
                       Mean reward: 20.23
               Mean episode length: 320.95
       Episode_Reward/keep_balance: 0.3597
     Episode_Reward/rew_lin_vel_xy: 0.8543
      Episode_Reward/rew_ang_vel_z: 1.0922
    Episode_Reward/pen_base_height: -0.2304
      Episode_Reward/pen_lin_vel_z: -0.0328
     Episode_Reward/pen_ang_vel_xy: -0.0481
   Episode_Reward/pen_joint_torque: -0.0646
    Episode_Reward/pen_joint_accel: -0.0360
    Episode_Reward/pen_action_rate: -0.0200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0133
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0415
Episode_Reward/pen_flat_orientation: -0.1440
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0731
   Episode_Reward/foot_landing_vel: -0.0568
   Episode_Reward/test_gait_reward: -0.3311
Metrics/base_velocity/error_vel_xy: 1.1279
Metrics/base_velocity/error_vel_yaw: 0.3181
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 1.09s
                        Total time: 514.51s
                               ETA: 2756.8s

################################################################################
                     [1m Learning iteration 472/3000 [0m                      

                       Computation: 90328 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.9626
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6197
                     Learning rate: 0.0013
                       Mean reward: 20.55
               Mean episode length: 327.62
       Episode_Reward/keep_balance: 0.3253
     Episode_Reward/rew_lin_vel_xy: 0.7732
      Episode_Reward/rew_ang_vel_z: 0.9756
    Episode_Reward/pen_base_height: -0.2180
      Episode_Reward/pen_lin_vel_z: -0.0308
     Episode_Reward/pen_ang_vel_xy: -0.0461
   Episode_Reward/pen_joint_torque: -0.0595
    Episode_Reward/pen_joint_accel: -0.0348
    Episode_Reward/pen_action_rate: -0.0183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0126
   Episode_Reward/pen_joint_powers: -0.0196
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0379
Episode_Reward/pen_flat_orientation: -0.1378
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0723
   Episode_Reward/foot_landing_vel: -0.0522
   Episode_Reward/test_gait_reward: -0.3020
Metrics/base_velocity/error_vel_xy: 1.0168
Metrics/base_velocity/error_vel_yaw: 0.2975
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 1.09s
                        Total time: 515.60s
                               ETA: 2755.7s

################################################################################
                     [1m Learning iteration 473/3000 [0m                      

                       Computation: 89981 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 1.0770
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6210
                     Learning rate: 0.0013
                       Mean reward: 20.65
               Mean episode length: 336.17
       Episode_Reward/keep_balance: 0.3547
     Episode_Reward/rew_lin_vel_xy: 0.8077
      Episode_Reward/rew_ang_vel_z: 1.0767
    Episode_Reward/pen_base_height: -0.2236
      Episode_Reward/pen_lin_vel_z: -0.0332
     Episode_Reward/pen_ang_vel_xy: -0.0487
   Episode_Reward/pen_joint_torque: -0.0657
    Episode_Reward/pen_joint_accel: -0.0372
    Episode_Reward/pen_action_rate: -0.0198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0212
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0407
Episode_Reward/pen_flat_orientation: -0.1438
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0738
   Episode_Reward/foot_landing_vel: -0.0576
   Episode_Reward/test_gait_reward: -0.3265
Metrics/base_velocity/error_vel_xy: 1.1206
Metrics/base_velocity/error_vel_yaw: 0.3145
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 1.09s
                        Total time: 516.69s
                               ETA: 2754.6s

################################################################################
                     [1m Learning iteration 474/3000 [0m                      

                       Computation: 89648 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 1.2023
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6222
                     Learning rate: 0.0013
                       Mean reward: 27.80
               Mean episode length: 454.43
       Episode_Reward/keep_balance: 0.4106
     Episode_Reward/rew_lin_vel_xy: 0.8950
      Episode_Reward/rew_ang_vel_z: 1.2434
    Episode_Reward/pen_base_height: -0.2412
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.0533
   Episode_Reward/pen_joint_torque: -0.0789
    Episode_Reward/pen_joint_accel: -0.0472
    Episode_Reward/pen_action_rate: -0.0233
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0252
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0478
Episode_Reward/pen_flat_orientation: -0.1637
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0888
   Episode_Reward/foot_landing_vel: -0.0686
   Episode_Reward/test_gait_reward: -0.3776
Metrics/base_velocity/error_vel_xy: 1.3461
Metrics/base_velocity/error_vel_yaw: 0.3662
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 1.10s
                        Total time: 517.79s
                               ETA: 2753.5s

################################################################################
                     [1m Learning iteration 475/3000 [0m                      

                       Computation: 89611 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.8705
                    Surrogate loss: -0.0006
             Mean action noise std: 0.6237
                     Learning rate: 0.0009
                       Mean reward: 23.08
               Mean episode length: 365.05
       Episode_Reward/keep_balance: 0.3934
     Episode_Reward/rew_lin_vel_xy: 0.9331
      Episode_Reward/rew_ang_vel_z: 1.1699
    Episode_Reward/pen_base_height: -0.2285
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.0535
   Episode_Reward/pen_joint_torque: -0.0749
    Episode_Reward/pen_joint_accel: -0.0446
    Episode_Reward/pen_action_rate: -0.0228
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0245
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0465
Episode_Reward/pen_flat_orientation: -0.1676
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0902
   Episode_Reward/foot_landing_vel: -0.0696
   Episode_Reward/test_gait_reward: -0.3640
Metrics/base_velocity/error_vel_xy: 1.2295
Metrics/base_velocity/error_vel_yaw: 0.3659
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 1.10s
                        Total time: 518.89s
                               ETA: 2752.5s

################################################################################
                     [1m Learning iteration 476/3000 [0m                      

                       Computation: 90077 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.9199
                    Surrogate loss: 0.0024
             Mean action noise std: 0.6237
                     Learning rate: 0.0002
                       Mean reward: 24.55
               Mean episode length: 390.97
       Episode_Reward/keep_balance: 0.3621
     Episode_Reward/rew_lin_vel_xy: 0.8102
      Episode_Reward/rew_ang_vel_z: 1.0756
    Episode_Reward/pen_base_height: -0.2225
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.0511
   Episode_Reward/pen_joint_torque: -0.0671
    Episode_Reward/pen_joint_accel: -0.0407
    Episode_Reward/pen_action_rate: -0.0207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0221
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0425
Episode_Reward/pen_flat_orientation: -0.1569
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0807
   Episode_Reward/foot_landing_vel: -0.0621
   Episode_Reward/test_gait_reward: -0.3341
Metrics/base_velocity/error_vel_xy: 1.1770
Metrics/base_velocity/error_vel_yaw: 0.3378
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 1.09s
                        Total time: 519.98s
                               ETA: 2751.4s

################################################################################
                     [1m Learning iteration 477/3000 [0m                      

                       Computation: 89113 steps/s (collection: 0.981s, learning 0.122s)
               Value function loss: 0.8865
                    Surrogate loss: -0.0003
             Mean action noise std: 0.6240
                     Learning rate: 0.0002
                       Mean reward: 20.09
               Mean episode length: 347.97
       Episode_Reward/keep_balance: 0.3689
     Episode_Reward/rew_lin_vel_xy: 0.8085
      Episode_Reward/rew_ang_vel_z: 1.1067
    Episode_Reward/pen_base_height: -0.2231
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.0518
   Episode_Reward/pen_joint_torque: -0.0709
    Episode_Reward/pen_joint_accel: -0.0416
    Episode_Reward/pen_action_rate: -0.0212
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0152
   Episode_Reward/pen_joint_powers: -0.0234
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0433
Episode_Reward/pen_flat_orientation: -0.1582
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0870
   Episode_Reward/foot_landing_vel: -0.0679
   Episode_Reward/test_gait_reward: -0.3411
Metrics/base_velocity/error_vel_xy: 1.2196
Metrics/base_velocity/error_vel_yaw: 0.3380
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 1.10s
                        Total time: 521.08s
                               ETA: 2750.4s

################################################################################
                     [1m Learning iteration 478/3000 [0m                      

                       Computation: 89873 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.8695
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6252
                     Learning rate: 0.0003
                       Mean reward: 22.96
               Mean episode length: 351.39
       Episode_Reward/keep_balance: 0.3668
     Episode_Reward/rew_lin_vel_xy: 0.8971
      Episode_Reward/rew_ang_vel_z: 1.0872
    Episode_Reward/pen_base_height: -0.2268
      Episode_Reward/pen_lin_vel_z: -0.0347
     Episode_Reward/pen_ang_vel_xy: -0.0503
   Episode_Reward/pen_joint_torque: -0.0680
    Episode_Reward/pen_joint_accel: -0.0389
    Episode_Reward/pen_action_rate: -0.0211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0146
   Episode_Reward/pen_joint_powers: -0.0224
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0431
Episode_Reward/pen_flat_orientation: -0.1455
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0837
   Episode_Reward/foot_landing_vel: -0.0635
   Episode_Reward/test_gait_reward: -0.3380
Metrics/base_velocity/error_vel_xy: 1.1334
Metrics/base_velocity/error_vel_yaw: 0.3431
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 1.09s
                        Total time: 522.17s
                               ETA: 2749.3s

################################################################################
                     [1m Learning iteration 479/3000 [0m                      

                       Computation: 88790 steps/s (collection: 0.985s, learning 0.122s)
               Value function loss: 0.8744
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6264
                     Learning rate: 0.0006
                       Mean reward: 23.56
               Mean episode length: 352.06
       Episode_Reward/keep_balance: 0.3622
     Episode_Reward/rew_lin_vel_xy: 0.9008
      Episode_Reward/rew_ang_vel_z: 1.0893
    Episode_Reward/pen_base_height: -0.2258
      Episode_Reward/pen_lin_vel_z: -0.0343
     Episode_Reward/pen_ang_vel_xy: -0.0493
   Episode_Reward/pen_joint_torque: -0.0685
    Episode_Reward/pen_joint_accel: -0.0372
    Episode_Reward/pen_action_rate: -0.0205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0220
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0421
Episode_Reward/pen_flat_orientation: -0.1445
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0788
   Episode_Reward/foot_landing_vel: -0.0592
   Episode_Reward/test_gait_reward: -0.3341
Metrics/base_velocity/error_vel_xy: 1.1054
Metrics/base_velocity/error_vel_yaw: 0.3286
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 1.11s
                        Total time: 523.28s
                               ETA: 2748.3s

################################################################################
                     [1m Learning iteration 480/3000 [0m                      

                       Computation: 89115 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 0.8962
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6262
                     Learning rate: 0.0009
                       Mean reward: 29.75
               Mean episode length: 447.88
       Episode_Reward/keep_balance: 0.4239
     Episode_Reward/rew_lin_vel_xy: 0.9864
      Episode_Reward/rew_ang_vel_z: 1.2574
    Episode_Reward/pen_base_height: -0.2421
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.0559
   Episode_Reward/pen_joint_torque: -0.0809
    Episode_Reward/pen_joint_accel: -0.0494
    Episode_Reward/pen_action_rate: -0.0248
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0170
   Episode_Reward/pen_joint_powers: -0.0263
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0508
Episode_Reward/pen_flat_orientation: -0.1596
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0990
   Episode_Reward/foot_landing_vel: -0.0719
   Episode_Reward/test_gait_reward: -0.3925
Metrics/base_velocity/error_vel_xy: 1.3637
Metrics/base_velocity/error_vel_yaw: 0.3979
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 1.10s
                        Total time: 524.38s
                               ETA: 2747.3s

################################################################################
                     [1m Learning iteration 481/3000 [0m                      

                       Computation: 90287 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.9323
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6263
                     Learning rate: 0.0009
                       Mean reward: 23.24
               Mean episode length: 390.87
       Episode_Reward/keep_balance: 0.4264
     Episode_Reward/rew_lin_vel_xy: 0.9638
      Episode_Reward/rew_ang_vel_z: 1.2635
    Episode_Reward/pen_base_height: -0.2331
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.0574
   Episode_Reward/pen_joint_torque: -0.0802
    Episode_Reward/pen_joint_accel: -0.0489
    Episode_Reward/pen_action_rate: -0.0254
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0176
   Episode_Reward/pen_joint_powers: -0.0267
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0516
Episode_Reward/pen_flat_orientation: -0.1668
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.1004
   Episode_Reward/foot_landing_vel: -0.0790
   Episode_Reward/test_gait_reward: -0.3925
Metrics/base_velocity/error_vel_xy: 1.4044
Metrics/base_velocity/error_vel_yaw: 0.3990
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 1.09s
                        Total time: 525.47s
                               ETA: 2746.2s

################################################################################
                     [1m Learning iteration 482/3000 [0m                      

                       Computation: 90175 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 1.0612
                    Surrogate loss: -0.0038
             Mean action noise std: 0.6271
                     Learning rate: 0.0019
                       Mean reward: 22.16
               Mean episode length: 350.74
       Episode_Reward/keep_balance: 0.3568
     Episode_Reward/rew_lin_vel_xy: 0.7955
      Episode_Reward/rew_ang_vel_z: 1.0703
    Episode_Reward/pen_base_height: -0.2209
      Episode_Reward/pen_lin_vel_z: -0.0334
     Episode_Reward/pen_ang_vel_xy: -0.0479
   Episode_Reward/pen_joint_torque: -0.0670
    Episode_Reward/pen_joint_accel: -0.0359
    Episode_Reward/pen_action_rate: -0.0204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0136
   Episode_Reward/pen_joint_powers: -0.0216
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0419
Episode_Reward/pen_flat_orientation: -0.1371
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0768
   Episode_Reward/foot_landing_vel: -0.0617
   Episode_Reward/test_gait_reward: -0.3280
Metrics/base_velocity/error_vel_xy: 1.1677
Metrics/base_velocity/error_vel_yaw: 0.3255
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 1.09s
                        Total time: 526.56s
                               ETA: 2745.1s

################################################################################
                     [1m Learning iteration 483/3000 [0m                      

                       Computation: 90194 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 1.2005
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6293
                     Learning rate: 0.0009
                       Mean reward: 30.37
               Mean episode length: 415.83
       Episode_Reward/keep_balance: 0.3865
     Episode_Reward/rew_lin_vel_xy: 0.9896
      Episode_Reward/rew_ang_vel_z: 1.1612
    Episode_Reward/pen_base_height: -0.2282
      Episode_Reward/pen_lin_vel_z: -0.0348
     Episode_Reward/pen_ang_vel_xy: -0.0510
   Episode_Reward/pen_joint_torque: -0.0721
    Episode_Reward/pen_joint_accel: -0.0398
    Episode_Reward/pen_action_rate: -0.0223
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0146
   Episode_Reward/pen_joint_powers: -0.0232
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0458
Episode_Reward/pen_flat_orientation: -0.1469
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0828
   Episode_Reward/foot_landing_vel: -0.0644
   Episode_Reward/test_gait_reward: -0.3565
Metrics/base_velocity/error_vel_xy: 1.1439
Metrics/base_velocity/error_vel_yaw: 0.3513
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 1.09s
                        Total time: 527.65s
                               ETA: 2744.0s

################################################################################
                     [1m Learning iteration 484/3000 [0m                      

                       Computation: 90058 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.8658
                    Surrogate loss: -0.0003
             Mean action noise std: 0.6307
                     Learning rate: 0.0009
                       Mean reward: 25.47
               Mean episode length: 390.17
       Episode_Reward/keep_balance: 0.3553
     Episode_Reward/rew_lin_vel_xy: 0.8562
      Episode_Reward/rew_ang_vel_z: 1.0593
    Episode_Reward/pen_base_height: -0.2240
      Episode_Reward/pen_lin_vel_z: -0.0344
     Episode_Reward/pen_ang_vel_xy: -0.0496
   Episode_Reward/pen_joint_torque: -0.0678
    Episode_Reward/pen_joint_accel: -0.0407
    Episode_Reward/pen_action_rate: -0.0208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0146
   Episode_Reward/pen_joint_powers: -0.0225
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0427
Episode_Reward/pen_flat_orientation: -0.1498
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0822
   Episode_Reward/foot_landing_vel: -0.0646
   Episode_Reward/test_gait_reward: -0.3315
Metrics/base_velocity/error_vel_xy: 1.1240
Metrics/base_velocity/error_vel_yaw: 0.3279
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 1.09s
                        Total time: 528.75s
                               ETA: 2742.9s

################################################################################
                     [1m Learning iteration 485/3000 [0m                      

                       Computation: 91198 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.9857
                    Surrogate loss: 0.0020
             Mean action noise std: 0.6316
                     Learning rate: 0.0003
                       Mean reward: 24.29
               Mean episode length: 386.49
       Episode_Reward/keep_balance: 0.3977
     Episode_Reward/rew_lin_vel_xy: 0.9308
      Episode_Reward/rew_ang_vel_z: 1.1804
    Episode_Reward/pen_base_height: -0.2391
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.0542
   Episode_Reward/pen_joint_torque: -0.0749
    Episode_Reward/pen_joint_accel: -0.0421
    Episode_Reward/pen_action_rate: -0.0232
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0162
   Episode_Reward/pen_joint_powers: -0.0248
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0476
Episode_Reward/pen_flat_orientation: -0.1607
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0926
   Episode_Reward/foot_landing_vel: -0.0695
   Episode_Reward/test_gait_reward: -0.3671
Metrics/base_velocity/error_vel_xy: 1.2561
Metrics/base_velocity/error_vel_yaw: 0.3711
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 9.2500
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 1.08s
                        Total time: 529.82s
                               ETA: 2741.8s

################################################################################
                     [1m Learning iteration 486/3000 [0m                      

                       Computation: 90522 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.8684
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6318
                     Learning rate: 0.0006
                       Mean reward: 21.87
               Mean episode length: 352.71
       Episode_Reward/keep_balance: 0.3763
     Episode_Reward/rew_lin_vel_xy: 0.8943
      Episode_Reward/rew_ang_vel_z: 1.1237
    Episode_Reward/pen_base_height: -0.2286
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.0522
   Episode_Reward/pen_joint_torque: -0.0708
    Episode_Reward/pen_joint_accel: -0.0381
    Episode_Reward/pen_action_rate: -0.0218
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0231
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0448
Episode_Reward/pen_flat_orientation: -0.1480
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0833
   Episode_Reward/foot_landing_vel: -0.0633
   Episode_Reward/test_gait_reward: -0.3448
Metrics/base_velocity/error_vel_xy: 1.1799
Metrics/base_velocity/error_vel_yaw: 0.3486
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 1.09s
                        Total time: 530.91s
                               ETA: 2740.7s

################################################################################
                     [1m Learning iteration 487/3000 [0m                      

                       Computation: 91088 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.9013
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6314
                     Learning rate: 0.0004
                       Mean reward: 22.89
               Mean episode length: 350.22
       Episode_Reward/keep_balance: 0.3573
     Episode_Reward/rew_lin_vel_xy: 0.8401
      Episode_Reward/rew_ang_vel_z: 1.0734
    Episode_Reward/pen_base_height: -0.2172
      Episode_Reward/pen_lin_vel_z: -0.0333
     Episode_Reward/pen_ang_vel_xy: -0.0487
   Episode_Reward/pen_joint_torque: -0.0684
    Episode_Reward/pen_joint_accel: -0.0392
    Episode_Reward/pen_action_rate: -0.0208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0140
   Episode_Reward/pen_joint_powers: -0.0221
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0429
Episode_Reward/pen_flat_orientation: -0.1385
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0801
   Episode_Reward/foot_landing_vel: -0.0598
   Episode_Reward/test_gait_reward: -0.3311
Metrics/base_velocity/error_vel_xy: 1.1220
Metrics/base_velocity/error_vel_yaw: 0.3259
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 1.08s
                        Total time: 531.99s
                               ETA: 2739.5s

################################################################################
                     [1m Learning iteration 488/3000 [0m                      

                       Computation: 88965 steps/s (collection: 0.983s, learning 0.122s)
               Value function loss: 0.8290
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6305
                     Learning rate: 0.0009
                       Mean reward: 23.88
               Mean episode length: 371.10
       Episode_Reward/keep_balance: 0.3854
     Episode_Reward/rew_lin_vel_xy: 0.8872
      Episode_Reward/rew_ang_vel_z: 1.1575
    Episode_Reward/pen_base_height: -0.2269
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.0530
   Episode_Reward/pen_joint_torque: -0.0747
    Episode_Reward/pen_joint_accel: -0.0436
    Episode_Reward/pen_action_rate: -0.0227
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0156
   Episode_Reward/pen_joint_powers: -0.0243
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0460
Episode_Reward/pen_flat_orientation: -0.1521
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0895
   Episode_Reward/foot_landing_vel: -0.0697
   Episode_Reward/test_gait_reward: -0.3566
Metrics/base_velocity/error_vel_xy: 1.2302
Metrics/base_velocity/error_vel_yaw: 0.3501
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 1.10s
                        Total time: 533.09s
                               ETA: 2738.5s

################################################################################
                     [1m Learning iteration 489/3000 [0m                      

                       Computation: 91621 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.8105
                    Surrogate loss: 0.0003
             Mean action noise std: 0.6307
                     Learning rate: 0.0004
                       Mean reward: 25.74
               Mean episode length: 388.65
       Episode_Reward/keep_balance: 0.3461
     Episode_Reward/rew_lin_vel_xy: 0.8154
      Episode_Reward/rew_ang_vel_z: 1.0364
    Episode_Reward/pen_base_height: -0.2194
      Episode_Reward/pen_lin_vel_z: -0.0309
     Episode_Reward/pen_ang_vel_xy: -0.0485
   Episode_Reward/pen_joint_torque: -0.0632
    Episode_Reward/pen_joint_accel: -0.0372
    Episode_Reward/pen_action_rate: -0.0200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0133
   Episode_Reward/pen_joint_powers: -0.0206
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0416
Episode_Reward/pen_flat_orientation: -0.1333
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0745
   Episode_Reward/foot_landing_vel: -0.0586
   Episode_Reward/test_gait_reward: -0.3188
Metrics/base_velocity/error_vel_xy: 1.0985
Metrics/base_velocity/error_vel_yaw: 0.3165
      Episode_Termination/time_out: 0.8750
  Episode_Termination/base_contact: 9.7500
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 1.07s
                        Total time: 534.17s
                               ETA: 2737.3s

################################################################################
                     [1m Learning iteration 490/3000 [0m                      

                       Computation: 90154 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.8206
                    Surrogate loss: -0.0006
             Mean action noise std: 0.6311
                     Learning rate: 0.0009
                       Mean reward: 21.35
               Mean episode length: 362.16
       Episode_Reward/keep_balance: 0.3807
     Episode_Reward/rew_lin_vel_xy: 0.8392
      Episode_Reward/rew_ang_vel_z: 1.1291
    Episode_Reward/pen_base_height: -0.2287
      Episode_Reward/pen_lin_vel_z: -0.0353
     Episode_Reward/pen_ang_vel_xy: -0.0514
   Episode_Reward/pen_joint_torque: -0.0711
    Episode_Reward/pen_joint_accel: -0.0405
    Episode_Reward/pen_action_rate: -0.0222
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0149
   Episode_Reward/pen_joint_powers: -0.0231
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0460
Episode_Reward/pen_flat_orientation: -0.1441
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0854
   Episode_Reward/foot_landing_vel: -0.0642
   Episode_Reward/test_gait_reward: -0.3503
Metrics/base_velocity/error_vel_xy: 1.2521
Metrics/base_velocity/error_vel_yaw: 0.3566
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 1.09s
                        Total time: 535.26s
                               ETA: 2736.2s

################################################################################
                     [1m Learning iteration 491/3000 [0m                      

                       Computation: 90816 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.8186
                    Surrogate loss: 0.0022
             Mean action noise std: 0.6318
                     Learning rate: 0.0002
                       Mean reward: 26.51
               Mean episode length: 389.01
       Episode_Reward/keep_balance: 0.4073
     Episode_Reward/rew_lin_vel_xy: 1.0115
      Episode_Reward/rew_ang_vel_z: 1.2332
    Episode_Reward/pen_base_height: -0.2312
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.0543
   Episode_Reward/pen_joint_torque: -0.0763
    Episode_Reward/pen_joint_accel: -0.0435
    Episode_Reward/pen_action_rate: -0.0240
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0162
   Episode_Reward/pen_joint_powers: -0.0252
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0490
Episode_Reward/pen_flat_orientation: -0.1479
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0912
   Episode_Reward/foot_landing_vel: -0.0705
   Episode_Reward/test_gait_reward: -0.3739
Metrics/base_velocity/error_vel_xy: 1.2810
Metrics/base_velocity/error_vel_yaw: 0.3633
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 1.08s
                        Total time: 536.34s
                               ETA: 2735.1s

################################################################################
                     [1m Learning iteration 492/3000 [0m                      

                       Computation: 90873 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.8194
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6329
                     Learning rate: 0.0004
                       Mean reward: 25.14
               Mean episode length: 387.39
       Episode_Reward/keep_balance: 0.4203
     Episode_Reward/rew_lin_vel_xy: 0.9616
      Episode_Reward/rew_ang_vel_z: 1.2399
    Episode_Reward/pen_base_height: -0.2404
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.0571
   Episode_Reward/pen_joint_torque: -0.0834
    Episode_Reward/pen_joint_accel: -0.0462
    Episode_Reward/pen_action_rate: -0.0251
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0174
   Episode_Reward/pen_joint_powers: -0.0271
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0511
Episode_Reward/pen_flat_orientation: -0.1556
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1005
   Episode_Reward/foot_landing_vel: -0.0731
   Episode_Reward/test_gait_reward: -0.3877
Metrics/base_velocity/error_vel_xy: 1.3881
Metrics/base_velocity/error_vel_yaw: 0.3971
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 1.08s
                        Total time: 537.42s
                               ETA: 2734.0s

################################################################################
                     [1m Learning iteration 493/3000 [0m                      

                       Computation: 90377 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.8534
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6347
                     Learning rate: 0.0009
                       Mean reward: 25.91
               Mean episode length: 394.11
       Episode_Reward/keep_balance: 0.3928
     Episode_Reward/rew_lin_vel_xy: 0.9020
      Episode_Reward/rew_ang_vel_z: 1.1685
    Episode_Reward/pen_base_height: -0.2326
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.0547
   Episode_Reward/pen_joint_torque: -0.0783
    Episode_Reward/pen_joint_accel: -0.0456
    Episode_Reward/pen_action_rate: -0.0234
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0164
   Episode_Reward/pen_joint_powers: -0.0254
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0477
Episode_Reward/pen_flat_orientation: -0.1521
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0921
   Episode_Reward/foot_landing_vel: -0.0728
   Episode_Reward/test_gait_reward: -0.3643
Metrics/base_velocity/error_vel_xy: 1.2556
Metrics/base_velocity/error_vel_yaw: 0.3670
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 1.09s
                        Total time: 538.51s
                               ETA: 2732.9s

################################################################################
                     [1m Learning iteration 494/3000 [0m                      

                       Computation: 90485 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 1.0434
                    Surrogate loss: 0.0036
             Mean action noise std: 0.6365
                     Learning rate: 0.0003
                       Mean reward: 32.60
               Mean episode length: 481.95
       Episode_Reward/keep_balance: 0.4307
     Episode_Reward/rew_lin_vel_xy: 1.0901
      Episode_Reward/rew_ang_vel_z: 1.2870
    Episode_Reward/pen_base_height: -0.2446
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.0589
   Episode_Reward/pen_joint_torque: -0.0838
    Episode_Reward/pen_joint_accel: -0.0482
    Episode_Reward/pen_action_rate: -0.0258
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0182
   Episode_Reward/pen_joint_powers: -0.0278
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0523
Episode_Reward/pen_flat_orientation: -0.1700
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1079
   Episode_Reward/foot_landing_vel: -0.0787
   Episode_Reward/test_gait_reward: -0.4013
Metrics/base_velocity/error_vel_xy: 1.3036
Metrics/base_velocity/error_vel_yaw: 0.3966
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 1.09s
                        Total time: 539.59s
                               ETA: 2731.8s

################################################################################
                     [1m Learning iteration 495/3000 [0m                      

                       Computation: 91035 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.8825
                    Surrogate loss: 0.0115
             Mean action noise std: 0.6368
                     Learning rate: 0.0000
                       Mean reward: 25.01
               Mean episode length: 404.67
       Episode_Reward/keep_balance: 0.3969
     Episode_Reward/rew_lin_vel_xy: 0.9458
      Episode_Reward/rew_ang_vel_z: 1.1796
    Episode_Reward/pen_base_height: -0.2363
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.0530
   Episode_Reward/pen_joint_torque: -0.0744
    Episode_Reward/pen_joint_accel: -0.0461
    Episode_Reward/pen_action_rate: -0.0237
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0160
   Episode_Reward/pen_joint_powers: -0.0245
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0489
Episode_Reward/pen_flat_orientation: -0.1474
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0929
   Episode_Reward/foot_landing_vel: -0.0704
   Episode_Reward/test_gait_reward: -0.3688
Metrics/base_velocity/error_vel_xy: 1.2364
Metrics/base_velocity/error_vel_yaw: 0.3711
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 1.08s
                        Total time: 540.67s
                               ETA: 2730.6s

################################################################################
                     [1m Learning iteration 496/3000 [0m                      

                       Computation: 90900 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 0.9476
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6377
                     Learning rate: 0.0003
                       Mean reward: 24.16
               Mean episode length: 368.39
       Episode_Reward/keep_balance: 0.3876
     Episode_Reward/rew_lin_vel_xy: 0.9141
      Episode_Reward/rew_ang_vel_z: 1.1477
    Episode_Reward/pen_base_height: -0.2321
      Episode_Reward/pen_lin_vel_z: -0.0353
     Episode_Reward/pen_ang_vel_xy: -0.0532
   Episode_Reward/pen_joint_torque: -0.0728
    Episode_Reward/pen_joint_accel: -0.0389
    Episode_Reward/pen_action_rate: -0.0229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0151
   Episode_Reward/pen_joint_powers: -0.0238
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0479
Episode_Reward/pen_flat_orientation: -0.1441
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0875
   Episode_Reward/foot_landing_vel: -0.0669
   Episode_Reward/test_gait_reward: -0.3580
Metrics/base_velocity/error_vel_xy: 1.2351
Metrics/base_velocity/error_vel_yaw: 0.3652
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 1.08s
                        Total time: 541.76s
                               ETA: 2729.5s

################################################################################
                     [1m Learning iteration 497/3000 [0m                      

                       Computation: 89086 steps/s (collection: 0.981s, learning 0.123s)
               Value function loss: 0.8952
                    Surrogate loss: -0.0029
             Mean action noise std: 0.6375
                     Learning rate: 0.0006
                       Mean reward: 22.56
               Mean episode length: 350.82
       Episode_Reward/keep_balance: 0.3503
     Episode_Reward/rew_lin_vel_xy: 0.8251
      Episode_Reward/rew_ang_vel_z: 1.0393
    Episode_Reward/pen_base_height: -0.2270
      Episode_Reward/pen_lin_vel_z: -0.0318
     Episode_Reward/pen_ang_vel_xy: -0.0492
   Episode_Reward/pen_joint_torque: -0.0649
    Episode_Reward/pen_joint_accel: -0.0369
    Episode_Reward/pen_action_rate: -0.0205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0431
Episode_Reward/pen_flat_orientation: -0.1325
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0767
   Episode_Reward/foot_landing_vel: -0.0559
   Episode_Reward/test_gait_reward: -0.3237
Metrics/base_velocity/error_vel_xy: 1.1198
Metrics/base_velocity/error_vel_yaw: 0.3270
      Episode_Termination/time_out: 0.8333
  Episode_Termination/base_contact: 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 1.10s
                        Total time: 542.86s
                               ETA: 2728.5s

################################################################################
                     [1m Learning iteration 498/3000 [0m                      

                       Computation: 88710 steps/s (collection: 0.983s, learning 0.125s)
               Value function loss: 1.0963
                    Surrogate loss: -0.0034
             Mean action noise std: 0.6379
                     Learning rate: 0.0013
                       Mean reward: 25.64
               Mean episode length: 390.39
       Episode_Reward/keep_balance: 0.3574
     Episode_Reward/rew_lin_vel_xy: 0.9098
      Episode_Reward/rew_ang_vel_z: 1.0630
    Episode_Reward/pen_base_height: -0.2301
      Episode_Reward/pen_lin_vel_z: -0.0335
     Episode_Reward/pen_ang_vel_xy: -0.0494
   Episode_Reward/pen_joint_torque: -0.0683
    Episode_Reward/pen_joint_accel: -0.0377
    Episode_Reward/pen_action_rate: -0.0208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0138
   Episode_Reward/pen_joint_powers: -0.0222
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0433
Episode_Reward/pen_flat_orientation: -0.1324
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0789
   Episode_Reward/foot_landing_vel: -0.0588
   Episode_Reward/test_gait_reward: -0.3299
Metrics/base_velocity/error_vel_xy: 1.0745
Metrics/base_velocity/error_vel_yaw: 0.3319
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 1.11s
                        Total time: 543.97s
                               ETA: 2727.5s

################################################################################
                     [1m Learning iteration 499/3000 [0m                      

                       Computation: 89370 steps/s (collection: 0.975s, learning 0.125s)
               Value function loss: 1.5414
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6400
                     Learning rate: 0.0029
                       Mean reward: 27.85
               Mean episode length: 397.52
       Episode_Reward/keep_balance: 0.3931
     Episode_Reward/rew_lin_vel_xy: 0.9764
      Episode_Reward/rew_ang_vel_z: 1.1781
    Episode_Reward/pen_base_height: -0.2285
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.0528
   Episode_Reward/pen_joint_torque: -0.0727
    Episode_Reward/pen_joint_accel: -0.0421
    Episode_Reward/pen_action_rate: -0.0232
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0151
   Episode_Reward/pen_joint_powers: -0.0238
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0481
Episode_Reward/pen_flat_orientation: -0.1415
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0862
   Episode_Reward/foot_landing_vel: -0.0659
   Episode_Reward/test_gait_reward: -0.3620
Metrics/base_velocity/error_vel_xy: 1.2430
Metrics/base_velocity/error_vel_yaw: 0.3588
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 1.10s
                        Total time: 545.07s
                               ETA: 2726.4s

################################################################################
                     [1m Learning iteration 500/3000 [0m                      

                       Computation: 88865 steps/s (collection: 0.984s, learning 0.122s)
               Value function loss: 1.1013
                    Surrogate loss: 0.0040
             Mean action noise std: 0.6409
                     Learning rate: 0.0003
                       Mean reward: 25.93
               Mean episode length: 402.80
       Episode_Reward/keep_balance: 0.3563
     Episode_Reward/rew_lin_vel_xy: 0.8436
      Episode_Reward/rew_ang_vel_z: 1.0600
    Episode_Reward/pen_base_height: -0.2248
      Episode_Reward/pen_lin_vel_z: -0.0339
     Episode_Reward/pen_ang_vel_xy: -0.0495
   Episode_Reward/pen_joint_torque: -0.0673
    Episode_Reward/pen_joint_accel: -0.0388
    Episode_Reward/pen_action_rate: -0.0212
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0142
   Episode_Reward/pen_joint_powers: -0.0221
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0439
Episode_Reward/pen_flat_orientation: -0.1325
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0808
   Episode_Reward/foot_landing_vel: -0.0624
   Episode_Reward/test_gait_reward: -0.3325
Metrics/base_velocity/error_vel_xy: 1.1263
Metrics/base_velocity/error_vel_yaw: 0.3314
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 1.11s
                        Total time: 546.17s
                               ETA: 2725.4s

################################################################################
                     [1m Learning iteration 501/3000 [0m                      

                       Computation: 90109 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.9934
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6408
                     Learning rate: 0.0006
                       Mean reward: 22.69
               Mean episode length: 344.19
       Episode_Reward/keep_balance: 0.3545
     Episode_Reward/rew_lin_vel_xy: 0.8326
      Episode_Reward/rew_ang_vel_z: 1.0527
    Episode_Reward/pen_base_height: -0.2202
      Episode_Reward/pen_lin_vel_z: -0.0326
     Episode_Reward/pen_ang_vel_xy: -0.0491
   Episode_Reward/pen_joint_torque: -0.0656
    Episode_Reward/pen_joint_accel: -0.0388
    Episode_Reward/pen_action_rate: -0.0209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0214
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0437
Episode_Reward/pen_flat_orientation: -0.1340
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0767
   Episode_Reward/foot_landing_vel: -0.0601
   Episode_Reward/test_gait_reward: -0.3274
Metrics/base_velocity/error_vel_xy: 1.1436
Metrics/base_velocity/error_vel_yaw: 0.3303
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 1.09s
                        Total time: 547.26s
                               ETA: 2724.3s

################################################################################
                     [1m Learning iteration 502/3000 [0m                      

                       Computation: 88372 steps/s (collection: 0.989s, learning 0.124s)
               Value function loss: 1.2309
                    Surrogate loss: -0.0007
             Mean action noise std: 0.6410
                     Learning rate: 0.0006
                       Mean reward: 24.88
               Mean episode length: 368.83
       Episode_Reward/keep_balance: 0.3827
     Episode_Reward/rew_lin_vel_xy: 0.9858
      Episode_Reward/rew_ang_vel_z: 1.1453
    Episode_Reward/pen_base_height: -0.2263
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.0532
   Episode_Reward/pen_joint_torque: -0.0726
    Episode_Reward/pen_joint_accel: -0.0436
    Episode_Reward/pen_action_rate: -0.0229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0150
   Episode_Reward/pen_joint_powers: -0.0237
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0474
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0841
   Episode_Reward/foot_landing_vel: -0.0639
   Episode_Reward/test_gait_reward: -0.3556
Metrics/base_velocity/error_vel_xy: 1.1858
Metrics/base_velocity/error_vel_yaw: 0.3520
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 1.11s
                        Total time: 548.38s
                               ETA: 2723.4s

################################################################################
                     [1m Learning iteration 503/3000 [0m                      

                       Computation: 89373 steps/s (collection: 0.978s, learning 0.122s)
               Value function loss: 1.1526
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6418
                     Learning rate: 0.0013
                       Mean reward: 26.63
               Mean episode length: 366.37
       Episode_Reward/keep_balance: 0.3840
     Episode_Reward/rew_lin_vel_xy: 0.9770
      Episode_Reward/rew_ang_vel_z: 1.1303
    Episode_Reward/pen_base_height: -0.2296
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.0531
   Episode_Reward/pen_joint_torque: -0.0741
    Episode_Reward/pen_joint_accel: -0.0433
    Episode_Reward/pen_action_rate: -0.0232
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0157
   Episode_Reward/pen_joint_powers: -0.0243
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0482
Episode_Reward/pen_flat_orientation: -0.1435
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.0886
   Episode_Reward/foot_landing_vel: -0.0661
   Episode_Reward/test_gait_reward: -0.3583
Metrics/base_velocity/error_vel_xy: 1.1687
Metrics/base_velocity/error_vel_yaw: 0.3667
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 1.10s
                        Total time: 549.48s
                               ETA: 2722.3s

################################################################################
                     [1m Learning iteration 504/3000 [0m                      

                       Computation: 90130 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 1.3953
                    Surrogate loss: 0.0019
             Mean action noise std: 0.6426
                     Learning rate: 0.0006
                       Mean reward: 22.19
               Mean episode length: 335.55
       Episode_Reward/keep_balance: 0.3405
     Episode_Reward/rew_lin_vel_xy: 0.8520
      Episode_Reward/rew_ang_vel_z: 1.0043
    Episode_Reward/pen_base_height: -0.2133
      Episode_Reward/pen_lin_vel_z: -0.0316
     Episode_Reward/pen_ang_vel_xy: -0.0482
   Episode_Reward/pen_joint_torque: -0.0622
    Episode_Reward/pen_joint_accel: -0.0376
    Episode_Reward/pen_action_rate: -0.0205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0207
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0428
Episode_Reward/pen_flat_orientation: -0.1287
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0775
   Episode_Reward/foot_landing_vel: -0.0579
   Episode_Reward/test_gait_reward: -0.3164
Metrics/base_velocity/error_vel_xy: 1.0414
Metrics/base_velocity/error_vel_yaw: 0.3251
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 1.09s
                        Total time: 550.57s
                               ETA: 2721.2s

################################################################################
                     [1m Learning iteration 505/3000 [0m                      

                       Computation: 90735 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 1.0768
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6437
                     Learning rate: 0.0013
                       Mean reward: 25.62
               Mean episode length: 382.70
       Episode_Reward/keep_balance: 0.3832
     Episode_Reward/rew_lin_vel_xy: 0.9619
      Episode_Reward/rew_ang_vel_z: 1.1468
    Episode_Reward/pen_base_height: -0.2258
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.0523
   Episode_Reward/pen_joint_torque: -0.0711
    Episode_Reward/pen_joint_accel: -0.0421
    Episode_Reward/pen_action_rate: -0.0231
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0152
   Episode_Reward/pen_joint_powers: -0.0235
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0478
Episode_Reward/pen_flat_orientation: -0.1362
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0856
   Episode_Reward/foot_landing_vel: -0.0654
   Episode_Reward/test_gait_reward: -0.3540
Metrics/base_velocity/error_vel_xy: 1.1661
Metrics/base_velocity/error_vel_yaw: 0.3506
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 1.08s
                        Total time: 551.65s
                               ETA: 2720.1s

################################################################################
                     [1m Learning iteration 506/3000 [0m                      

                       Computation: 89855 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 1.2421
                    Surrogate loss: 0.0013
             Mean action noise std: 0.6456
                     Learning rate: 0.0006
                       Mean reward: 23.82
               Mean episode length: 374.05
       Episode_Reward/keep_balance: 0.3820
     Episode_Reward/rew_lin_vel_xy: 0.9037
      Episode_Reward/rew_ang_vel_z: 1.1332
    Episode_Reward/pen_base_height: -0.2332
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.0528
   Episode_Reward/pen_joint_torque: -0.0730
    Episode_Reward/pen_joint_accel: -0.0401
    Episode_Reward/pen_action_rate: -0.0231
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0149
   Episode_Reward/pen_joint_powers: -0.0238
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0480
Episode_Reward/pen_flat_orientation: -0.1371
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0857
   Episode_Reward/foot_landing_vel: -0.0640
   Episode_Reward/test_gait_reward: -0.3549
Metrics/base_velocity/error_vel_xy: 1.2454
Metrics/base_velocity/error_vel_yaw: 0.3583
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 1.09s
                        Total time: 552.75s
                               ETA: 2719.0s

################################################################################
                     [1m Learning iteration 507/3000 [0m                      

                       Computation: 90501 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 1.1029
                    Surrogate loss: -0.0007
             Mean action noise std: 0.6465
                     Learning rate: 0.0004
                       Mean reward: 24.77
               Mean episode length: 368.80
       Episode_Reward/keep_balance: 0.3822
     Episode_Reward/rew_lin_vel_xy: 0.9378
      Episode_Reward/rew_ang_vel_z: 1.1340
    Episode_Reward/pen_base_height: -0.2314
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.0524
   Episode_Reward/pen_joint_torque: -0.0721
    Episode_Reward/pen_joint_accel: -0.0405
    Episode_Reward/pen_action_rate: -0.0229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0235
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0477
Episode_Reward/pen_flat_orientation: -0.1371
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0837
   Episode_Reward/foot_landing_vel: -0.0616
   Episode_Reward/test_gait_reward: -0.3539
Metrics/base_velocity/error_vel_xy: 1.1965
Metrics/base_velocity/error_vel_yaw: 0.3593
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 1.09s
                        Total time: 553.83s
                               ETA: 2717.9s

################################################################################
                     [1m Learning iteration 508/3000 [0m                      

                       Computation: 90336 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 1.2543
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6466
                     Learning rate: 0.0013
                       Mean reward: 19.60
               Mean episode length: 300.31
       Episode_Reward/keep_balance: 0.3327
     Episode_Reward/rew_lin_vel_xy: 0.8275
      Episode_Reward/rew_ang_vel_z: 0.9911
    Episode_Reward/pen_base_height: -0.2087
      Episode_Reward/pen_lin_vel_z: -0.0322
     Episode_Reward/pen_ang_vel_xy: -0.0486
   Episode_Reward/pen_joint_torque: -0.0622
    Episode_Reward/pen_joint_accel: -0.0364
    Episode_Reward/pen_action_rate: -0.0201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0208
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0418
Episode_Reward/pen_flat_orientation: -0.1319
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0742
   Episode_Reward/foot_landing_vel: -0.0585
   Episode_Reward/test_gait_reward: -0.3094
Metrics/base_velocity/error_vel_xy: 1.0460
Metrics/base_velocity/error_vel_yaw: 0.3104
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 1.09s
                        Total time: 554.92s
                               ETA: 2716.8s

################################################################################
                     [1m Learning iteration 509/3000 [0m                      

                       Computation: 87458 steps/s (collection: 1.000s, learning 0.124s)
               Value function loss: 1.1689
                    Surrogate loss: 0.0006
             Mean action noise std: 0.6481
                     Learning rate: 0.0004
                       Mean reward: 26.41
               Mean episode length: 378.43
       Episode_Reward/keep_balance: 0.3973
     Episode_Reward/rew_lin_vel_xy: 0.9934
      Episode_Reward/rew_ang_vel_z: 1.1882
    Episode_Reward/pen_base_height: -0.2298
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.0558
   Episode_Reward/pen_joint_torque: -0.0779
    Episode_Reward/pen_joint_accel: -0.0468
    Episode_Reward/pen_action_rate: -0.0242
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0166
   Episode_Reward/pen_joint_powers: -0.0258
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0499
Episode_Reward/pen_flat_orientation: -0.1473
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0924
   Episode_Reward/foot_landing_vel: -0.0712
   Episode_Reward/test_gait_reward: -0.3693
Metrics/base_velocity/error_vel_xy: 1.2321
Metrics/base_velocity/error_vel_yaw: 0.3655
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 1.12s
                        Total time: 556.04s
                               ETA: 2715.9s

################################################################################
                     [1m Learning iteration 510/3000 [0m                      

                       Computation: 88801 steps/s (collection: 0.984s, learning 0.123s)
               Value function loss: 0.9849
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6492
                     Learning rate: 0.0006
                       Mean reward: 24.62
               Mean episode length: 360.24
       Episode_Reward/keep_balance: 0.3456
     Episode_Reward/rew_lin_vel_xy: 0.8755
      Episode_Reward/rew_ang_vel_z: 1.0283
    Episode_Reward/pen_base_height: -0.2163
      Episode_Reward/pen_lin_vel_z: -0.0325
     Episode_Reward/pen_ang_vel_xy: -0.0488
   Episode_Reward/pen_joint_torque: -0.0650
    Episode_Reward/pen_joint_accel: -0.0370
    Episode_Reward/pen_action_rate: -0.0208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0136
   Episode_Reward/pen_joint_powers: -0.0214
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0436
Episode_Reward/pen_flat_orientation: -0.1330
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.0764
   Episode_Reward/foot_landing_vel: -0.0581
   Episode_Reward/test_gait_reward: -0.3208
Metrics/base_velocity/error_vel_xy: 1.0560
Metrics/base_velocity/error_vel_yaw: 0.3214
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 1.11s
                        Total time: 557.15s
                               ETA: 2714.9s

################################################################################
                     [1m Learning iteration 511/3000 [0m                      

                       Computation: 89405 steps/s (collection: 0.977s, learning 0.122s)
               Value function loss: 1.1210
                    Surrogate loss: 0.0015
             Mean action noise std: 0.6501
                     Learning rate: 0.0002
                       Mean reward: 28.34
               Mean episode length: 397.57
       Episode_Reward/keep_balance: 0.3602
     Episode_Reward/rew_lin_vel_xy: 0.9734
      Episode_Reward/rew_ang_vel_z: 1.0720
    Episode_Reward/pen_base_height: -0.2213
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.0507
   Episode_Reward/pen_joint_torque: -0.0688
    Episode_Reward/pen_joint_accel: -0.0399
    Episode_Reward/pen_action_rate: -0.0220
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0230
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0458
Episode_Reward/pen_flat_orientation: -0.1382
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0857
   Episode_Reward/foot_landing_vel: -0.0626
   Episode_Reward/test_gait_reward: -0.3370
Metrics/base_velocity/error_vel_xy: 1.0512
Metrics/base_velocity/error_vel_yaw: 0.3357
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 1.10s
                        Total time: 558.25s
                               ETA: 2713.8s

################################################################################
                     [1m Learning iteration 512/3000 [0m                      

                       Computation: 90718 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.9270
                    Surrogate loss: 0.0019
             Mean action noise std: 0.6504
                     Learning rate: 0.0001
                       Mean reward: 17.99
               Mean episode length: 296.12
       Episode_Reward/keep_balance: 0.3396
     Episode_Reward/rew_lin_vel_xy: 0.8226
      Episode_Reward/rew_ang_vel_z: 1.0065
    Episode_Reward/pen_base_height: -0.2116
      Episode_Reward/pen_lin_vel_z: -0.0317
     Episode_Reward/pen_ang_vel_xy: -0.0481
   Episode_Reward/pen_joint_torque: -0.0644
    Episode_Reward/pen_joint_accel: -0.0353
    Episode_Reward/pen_action_rate: -0.0205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0133
   Episode_Reward/pen_joint_powers: -0.0212
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0428
Episode_Reward/pen_flat_orientation: -0.1249
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0737
   Episode_Reward/foot_landing_vel: -0.0567
   Episode_Reward/test_gait_reward: -0.3154
Metrics/base_velocity/error_vel_xy: 1.0897
Metrics/base_velocity/error_vel_yaw: 0.3189
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 1.08s
                        Total time: 559.33s
                               ETA: 2712.7s

################################################################################
                     [1m Learning iteration 513/3000 [0m                      

                       Computation: 89572 steps/s (collection: 0.975s, learning 0.122s)
               Value function loss: 1.0388
                    Surrogate loss: 0.0079
             Mean action noise std: 0.6505
                     Learning rate: 0.0000
                       Mean reward: 23.18
               Mean episode length: 334.82
       Episode_Reward/keep_balance: 0.3137
     Episode_Reward/rew_lin_vel_xy: 0.8216
      Episode_Reward/rew_ang_vel_z: 0.9172
    Episode_Reward/pen_base_height: -0.2066
      Episode_Reward/pen_lin_vel_z: -0.0300
     Episode_Reward/pen_ang_vel_xy: -0.0466
   Episode_Reward/pen_joint_torque: -0.0564
    Episode_Reward/pen_joint_accel: -0.0318
    Episode_Reward/pen_action_rate: -0.0190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0125
   Episode_Reward/pen_joint_powers: -0.0192
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0403
Episode_Reward/pen_flat_orientation: -0.1255
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0712
   Episode_Reward/foot_landing_vel: -0.0522
   Episode_Reward/test_gait_reward: -0.2924
Metrics/base_velocity/error_vel_xy: 0.9299
Metrics/base_velocity/error_vel_yaw: 0.3057
      Episode_Termination/time_out: 1.0000
  Episode_Termination/base_contact: 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 1.10s
                        Total time: 560.43s
                               ETA: 2711.7s

################################################################################
                     [1m Learning iteration 514/3000 [0m                      

                       Computation: 89830 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.9062
                    Surrogate loss: 0.0009
             Mean action noise std: 0.6508
                     Learning rate: 0.0001
                       Mean reward: 24.19
               Mean episode length: 366.43
       Episode_Reward/keep_balance: 0.3683
     Episode_Reward/rew_lin_vel_xy: 0.9114
      Episode_Reward/rew_ang_vel_z: 1.1012
    Episode_Reward/pen_base_height: -0.2167
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.0517
   Episode_Reward/pen_joint_torque: -0.0710
    Episode_Reward/pen_joint_accel: -0.0399
    Episode_Reward/pen_action_rate: -0.0226
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0149
   Episode_Reward/pen_joint_powers: -0.0234
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0471
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0825
   Episode_Reward/foot_landing_vel: -0.0643
   Episode_Reward/test_gait_reward: -0.3436
Metrics/base_velocity/error_vel_xy: 1.1481
Metrics/base_velocity/error_vel_yaw: 0.3384
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 1.09s
                        Total time: 561.53s
                               ETA: 2710.6s

################################################################################
                     [1m Learning iteration 515/3000 [0m                      

                       Computation: 88612 steps/s (collection: 0.987s, learning 0.122s)
               Value function loss: 1.0364
                    Surrogate loss: -0.0036
             Mean action noise std: 0.6517
                     Learning rate: 0.0003
                       Mean reward: 27.34
               Mean episode length: 394.33
       Episode_Reward/keep_balance: 0.3797
     Episode_Reward/rew_lin_vel_xy: 0.9544
      Episode_Reward/rew_ang_vel_z: 1.1335
    Episode_Reward/pen_base_height: -0.2221
      Episode_Reward/pen_lin_vel_z: -0.0346
     Episode_Reward/pen_ang_vel_xy: -0.0523
   Episode_Reward/pen_joint_torque: -0.0710
    Episode_Reward/pen_joint_accel: -0.0409
    Episode_Reward/pen_action_rate: -0.0233
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0146
   Episode_Reward/pen_joint_powers: -0.0232
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0486
Episode_Reward/pen_flat_orientation: -0.1323
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0822
   Episode_Reward/foot_landing_vel: -0.0632
   Episode_Reward/test_gait_reward: -0.3493
Metrics/base_velocity/error_vel_xy: 1.1977
Metrics/base_velocity/error_vel_yaw: 0.3514
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 1.11s
                        Total time: 562.63s
                               ETA: 2709.6s

################################################################################
                     [1m Learning iteration 516/3000 [0m                      

                       Computation: 89474 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 1.1520
                    Surrogate loss: 0.0001
             Mean action noise std: 0.6535
                     Learning rate: 0.0006
                       Mean reward: 25.16
               Mean episode length: 363.99
       Episode_Reward/keep_balance: 0.3681
     Episode_Reward/rew_lin_vel_xy: 0.9721
      Episode_Reward/rew_ang_vel_z: 1.0971
    Episode_Reward/pen_base_height: -0.2209
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.0525
   Episode_Reward/pen_joint_torque: -0.0721
    Episode_Reward/pen_joint_accel: -0.0397
    Episode_Reward/pen_action_rate: -0.0227
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0151
   Episode_Reward/pen_joint_powers: -0.0236
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0472
Episode_Reward/pen_flat_orientation: -0.1381
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.0854
   Episode_Reward/foot_landing_vel: -0.0673
   Episode_Reward/test_gait_reward: -0.3426
Metrics/base_velocity/error_vel_xy: 1.0928
Metrics/base_velocity/error_vel_yaw: 0.3441
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 1.10s
                        Total time: 563.73s
                               ETA: 2708.5s

################################################################################
                     [1m Learning iteration 517/3000 [0m                      

                       Computation: 89215 steps/s (collection: 0.977s, learning 0.125s)
               Value function loss: 0.9716
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6541
                     Learning rate: 0.0004
                       Mean reward: 21.68
               Mean episode length: 334.83
       Episode_Reward/keep_balance: 0.3480
     Episode_Reward/rew_lin_vel_xy: 0.8950
      Episode_Reward/rew_ang_vel_z: 1.0307
    Episode_Reward/pen_base_height: -0.2152
      Episode_Reward/pen_lin_vel_z: -0.0340
     Episode_Reward/pen_ang_vel_xy: -0.0513
   Episode_Reward/pen_joint_torque: -0.0663
    Episode_Reward/pen_joint_accel: -0.0379
    Episode_Reward/pen_action_rate: -0.0216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0223
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0449
Episode_Reward/pen_flat_orientation: -0.1351
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.0798
   Episode_Reward/foot_landing_vel: -0.0610
   Episode_Reward/test_gait_reward: -0.3234
Metrics/base_velocity/error_vel_xy: 1.0584
Metrics/base_velocity/error_vel_yaw: 0.3280
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 1.10s
                        Total time: 564.84s
                               ETA: 2707.5s

################################################################################
                     [1m Learning iteration 518/3000 [0m                      

                       Computation: 90385 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 1.0169
                    Surrogate loss: -0.0000
             Mean action noise std: 0.6552
                     Learning rate: 0.0004
                       Mean reward: 21.20
               Mean episode length: 317.73
       Episode_Reward/keep_balance: 0.3425
     Episode_Reward/rew_lin_vel_xy: 0.8616
      Episode_Reward/rew_ang_vel_z: 1.0068
    Episode_Reward/pen_base_height: -0.2136
      Episode_Reward/pen_lin_vel_z: -0.0341
     Episode_Reward/pen_ang_vel_xy: -0.0513
   Episode_Reward/pen_joint_torque: -0.0652
    Episode_Reward/pen_joint_accel: -0.0371
    Episode_Reward/pen_action_rate: -0.0213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0143
   Episode_Reward/pen_joint_powers: -0.0221
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0443
Episode_Reward/pen_flat_orientation: -0.1371
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0815
   Episode_Reward/foot_landing_vel: -0.0622
   Episode_Reward/test_gait_reward: -0.3192
Metrics/base_velocity/error_vel_xy: 1.0718
Metrics/base_velocity/error_vel_yaw: 0.3276
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 1.09s
                        Total time: 565.92s
                               ETA: 2706.4s

################################################################################
                     [1m Learning iteration 519/3000 [0m                      

                       Computation: 90433 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 1.1190
                    Surrogate loss: 0.0043
             Mean action noise std: 0.6554
                     Learning rate: 0.0001
                       Mean reward: 23.73
               Mean episode length: 361.71
       Episode_Reward/keep_balance: 0.3461
     Episode_Reward/rew_lin_vel_xy: 0.8716
      Episode_Reward/rew_ang_vel_z: 1.0269
    Episode_Reward/pen_base_height: -0.2130
      Episode_Reward/pen_lin_vel_z: -0.0333
     Episode_Reward/pen_ang_vel_xy: -0.0504
   Episode_Reward/pen_joint_torque: -0.0667
    Episode_Reward/pen_joint_accel: -0.0357
    Episode_Reward/pen_action_rate: -0.0215
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0224
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0448
Episode_Reward/pen_flat_orientation: -0.1326
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0811
   Episode_Reward/foot_landing_vel: -0.0634
   Episode_Reward/test_gait_reward: -0.3222
Metrics/base_velocity/error_vel_xy: 1.0564
Metrics/base_velocity/error_vel_yaw: 0.3243
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 1.09s
                        Total time: 567.01s
                               ETA: 2705.3s

################################################################################
                     [1m Learning iteration 520/3000 [0m                      

                       Computation: 87165 steps/s (collection: 1.002s, learning 0.126s)
               Value function loss: 0.9069
                    Surrogate loss: -0.0007
             Mean action noise std: 0.6558
                     Learning rate: 0.0002
                       Mean reward: 20.80
               Mean episode length: 316.50
       Episode_Reward/keep_balance: 0.3224
     Episode_Reward/rew_lin_vel_xy: 0.8753
      Episode_Reward/rew_ang_vel_z: 0.9521
    Episode_Reward/pen_base_height: -0.2061
      Episode_Reward/pen_lin_vel_z: -0.0314
     Episode_Reward/pen_ang_vel_xy: -0.0472
   Episode_Reward/pen_joint_torque: -0.0634
    Episode_Reward/pen_joint_accel: -0.0362
    Episode_Reward/pen_action_rate: -0.0199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0130
   Episode_Reward/pen_joint_powers: -0.0206
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0417
Episode_Reward/pen_flat_orientation: -0.1258
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.0738
   Episode_Reward/foot_landing_vel: -0.0563
   Episode_Reward/test_gait_reward: -0.2990
Metrics/base_velocity/error_vel_xy: 0.9515
Metrics/base_velocity/error_vel_yaw: 0.3047
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 1.13s
                        Total time: 568.14s
                               ETA: 2704.4s

################################################################################
                     [1m Learning iteration 521/3000 [0m                      

                       Computation: 89382 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 0.9271
                    Surrogate loss: 0.0023
             Mean action noise std: 0.6563
                     Learning rate: 0.0002
                       Mean reward: 21.96
               Mean episode length: 319.70
       Episode_Reward/keep_balance: 0.3460
     Episode_Reward/rew_lin_vel_xy: 0.9492
      Episode_Reward/rew_ang_vel_z: 1.0205
    Episode_Reward/pen_base_height: -0.2133
      Episode_Reward/pen_lin_vel_z: -0.0325
     Episode_Reward/pen_ang_vel_xy: -0.0498
   Episode_Reward/pen_joint_torque: -0.0649
    Episode_Reward/pen_joint_accel: -0.0361
    Episode_Reward/pen_action_rate: -0.0216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0139
   Episode_Reward/pen_joint_powers: -0.0215
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0456
Episode_Reward/pen_flat_orientation: -0.1264
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.0777
   Episode_Reward/foot_landing_vel: -0.0601
   Episode_Reward/test_gait_reward: -0.3204
Metrics/base_velocity/error_vel_xy: 1.0253
Metrics/base_velocity/error_vel_yaw: 0.3283
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 1.10s
                        Total time: 569.24s
                               ETA: 2703.3s

################################################################################
                     [1m Learning iteration 522/3000 [0m                      

                       Computation: 87529 steps/s (collection: 1.000s, learning 0.123s)
               Value function loss: 0.8705
                    Surrogate loss: 0.0030
             Mean action noise std: 0.6568
                     Learning rate: 0.0001
                       Mean reward: 25.02
               Mean episode length: 360.61
       Episode_Reward/keep_balance: 0.3394
     Episode_Reward/rew_lin_vel_xy: 0.8818
      Episode_Reward/rew_ang_vel_z: 0.9989
    Episode_Reward/pen_base_height: -0.2137
      Episode_Reward/pen_lin_vel_z: -0.0321
     Episode_Reward/pen_ang_vel_xy: -0.0502
   Episode_Reward/pen_joint_torque: -0.0638
    Episode_Reward/pen_joint_accel: -0.0359
    Episode_Reward/pen_action_rate: -0.0213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0138
   Episode_Reward/pen_joint_powers: -0.0214
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0450
Episode_Reward/pen_flat_orientation: -0.1267
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0764
   Episode_Reward/foot_landing_vel: -0.0600
   Episode_Reward/test_gait_reward: -0.3139
Metrics/base_velocity/error_vel_xy: 1.0681
Metrics/base_velocity/error_vel_yaw: 0.3231
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 1.12s
                        Total time: 570.36s
                               ETA: 2702.4s

################################################################################
                     [1m Learning iteration 523/3000 [0m                      

                       Computation: 89214 steps/s (collection: 0.980s, learning 0.122s)
               Value function loss: 0.9806
                    Surrogate loss: 0.0043
             Mean action noise std: 0.6569
                     Learning rate: 0.0000
                       Mean reward: 24.96
               Mean episode length: 357.16
       Episode_Reward/keep_balance: 0.3589
     Episode_Reward/rew_lin_vel_xy: 0.9326
      Episode_Reward/rew_ang_vel_z: 1.0665
    Episode_Reward/pen_base_height: -0.2189
      Episode_Reward/pen_lin_vel_z: -0.0335
     Episode_Reward/pen_ang_vel_xy: -0.0506
   Episode_Reward/pen_joint_torque: -0.0681
    Episode_Reward/pen_joint_accel: -0.0368
    Episode_Reward/pen_action_rate: -0.0224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0142
   Episode_Reward/pen_joint_powers: -0.0224
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0469
Episode_Reward/pen_flat_orientation: -0.1286
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0811
   Episode_Reward/foot_landing_vel: -0.0618
   Episode_Reward/test_gait_reward: -0.3308
Metrics/base_velocity/error_vel_xy: 1.1185
Metrics/base_velocity/error_vel_yaw: 0.3350
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 1.10s
                        Total time: 571.46s
                               ETA: 2701.4s

################################################################################
                     [1m Learning iteration 524/3000 [0m                      

                       Computation: 87655 steps/s (collection: 0.999s, learning 0.123s)
               Value function loss: 1.0350
                    Surrogate loss: 0.0059
             Mean action noise std: 0.6569
                     Learning rate: 0.0000
                       Mean reward: 23.01
               Mean episode length: 356.83
       Episode_Reward/keep_balance: 0.3300
     Episode_Reward/rew_lin_vel_xy: 0.7873
      Episode_Reward/rew_ang_vel_z: 0.9705
    Episode_Reward/pen_base_height: -0.2119
      Episode_Reward/pen_lin_vel_z: -0.0328
     Episode_Reward/pen_ang_vel_xy: -0.0495
   Episode_Reward/pen_joint_torque: -0.0640
    Episode_Reward/pen_joint_accel: -0.0392
    Episode_Reward/pen_action_rate: -0.0208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0215
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0437
Episode_Reward/pen_flat_orientation: -0.1280
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0821
   Episode_Reward/foot_landing_vel: -0.0604
   Episode_Reward/test_gait_reward: -0.3105
Metrics/base_velocity/error_vel_xy: 1.0653
Metrics/base_velocity/error_vel_yaw: 0.3183
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 1.12s
                        Total time: 572.58s
                               ETA: 2700.4s

################################################################################
                     [1m Learning iteration 525/3000 [0m                      

                       Computation: 88658 steps/s (collection: 0.987s, learning 0.122s)
               Value function loss: 0.9871
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6568
                     Learning rate: 0.0001
                       Mean reward: 21.58
               Mean episode length: 295.98
       Episode_Reward/keep_balance: 0.3274
     Episode_Reward/rew_lin_vel_xy: 0.9280
      Episode_Reward/rew_ang_vel_z: 0.9665
    Episode_Reward/pen_base_height: -0.2101
      Episode_Reward/pen_lin_vel_z: -0.0320
     Episode_Reward/pen_ang_vel_xy: -0.0483
   Episode_Reward/pen_joint_torque: -0.0641
    Episode_Reward/pen_joint_accel: -0.0345
    Episode_Reward/pen_action_rate: -0.0206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0214
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0431
Episode_Reward/pen_flat_orientation: -0.1245
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.0813
   Episode_Reward/foot_landing_vel: -0.0573
   Episode_Reward/test_gait_reward: -0.3052
Metrics/base_velocity/error_vel_xy: 0.9346
Metrics/base_velocity/error_vel_yaw: 0.3103
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 1.11s
                        Total time: 573.69s
                               ETA: 2699.4s

################################################################################
                     [1m Learning iteration 526/3000 [0m                      

                       Computation: 89064 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 1.0146
                    Surrogate loss: -0.0010
             Mean action noise std: 0.6575
                     Learning rate: 0.0003
                       Mean reward: 28.12
               Mean episode length: 374.67
       Episode_Reward/keep_balance: 0.3593
     Episode_Reward/rew_lin_vel_xy: 0.9593
      Episode_Reward/rew_ang_vel_z: 1.0625
    Episode_Reward/pen_base_height: -0.2184
      Episode_Reward/pen_lin_vel_z: -0.0334
     Episode_Reward/pen_ang_vel_xy: -0.0511
   Episode_Reward/pen_joint_torque: -0.0677
    Episode_Reward/pen_joint_accel: -0.0392
    Episode_Reward/pen_action_rate: -0.0226
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0225
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0474
Episode_Reward/pen_flat_orientation: -0.1302
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.0791
   Episode_Reward/foot_landing_vel: -0.0609
   Episode_Reward/test_gait_reward: -0.3339
Metrics/base_velocity/error_vel_xy: 1.0976
Metrics/base_velocity/error_vel_yaw: 0.3398
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 1.10s
                        Total time: 574.80s
                               ETA: 2698.4s

################################################################################
                     [1m Learning iteration 527/3000 [0m                      

                       Computation: 88861 steps/s (collection: 0.983s, learning 0.123s)
               Value function loss: 0.9491
                    Surrogate loss: 0.0032
             Mean action noise std: 0.6583
                     Learning rate: 0.0002
                       Mean reward: 22.07
               Mean episode length: 317.20
       Episode_Reward/keep_balance: 0.3541
     Episode_Reward/rew_lin_vel_xy: 0.8966
      Episode_Reward/rew_ang_vel_z: 1.0508
    Episode_Reward/pen_base_height: -0.2148
      Episode_Reward/pen_lin_vel_z: -0.0330
     Episode_Reward/pen_ang_vel_xy: -0.0523
   Episode_Reward/pen_joint_torque: -0.0676
    Episode_Reward/pen_joint_accel: -0.0408
    Episode_Reward/pen_action_rate: -0.0223
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0145
   Episode_Reward/pen_joint_powers: -0.0224
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0467
Episode_Reward/pen_flat_orientation: -0.1322
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.0811
   Episode_Reward/foot_landing_vel: -0.0607
   Episode_Reward/test_gait_reward: -0.3269
Metrics/base_velocity/error_vel_xy: 1.0913
Metrics/base_velocity/error_vel_yaw: 0.3319
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 1.11s
                        Total time: 575.90s
                               ETA: 2697.4s

################################################################################
                     [1m Learning iteration 528/3000 [0m                      

                       Computation: 89819 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.9331
                    Surrogate loss: -0.0031
             Mean action noise std: 0.6586
                     Learning rate: 0.0006
                       Mean reward: 25.00
               Mean episode length: 366.12
       Episode_Reward/keep_balance: 0.3552
     Episode_Reward/rew_lin_vel_xy: 0.9137
      Episode_Reward/rew_ang_vel_z: 1.0548
    Episode_Reward/pen_base_height: -0.2126
      Episode_Reward/pen_lin_vel_z: -0.0332
     Episode_Reward/pen_ang_vel_xy: -0.0527
   Episode_Reward/pen_joint_torque: -0.0671
    Episode_Reward/pen_joint_accel: -0.0390
    Episode_Reward/pen_action_rate: -0.0225
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0145
   Episode_Reward/pen_joint_powers: -0.0225
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0471
Episode_Reward/pen_flat_orientation: -0.1326
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0814
   Episode_Reward/foot_landing_vel: -0.0629
   Episode_Reward/test_gait_reward: -0.3305
Metrics/base_velocity/error_vel_xy: 1.1079
Metrics/base_velocity/error_vel_yaw: 0.3321
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 1.09s
                        Total time: 577.00s
                               ETA: 2696.3s

################################################################################
                     [1m Learning iteration 529/3000 [0m                      

                       Computation: 90060 steps/s (collection: 0.970s, learning 0.121s)
               Value function loss: 1.1742
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6599
                     Learning rate: 0.0009
                       Mean reward: 27.64
               Mean episode length: 377.28
       Episode_Reward/keep_balance: 0.3755
     Episode_Reward/rew_lin_vel_xy: 1.0263
      Episode_Reward/rew_ang_vel_z: 1.1183
    Episode_Reward/pen_base_height: -0.2151
      Episode_Reward/pen_lin_vel_z: -0.0337
     Episode_Reward/pen_ang_vel_xy: -0.0529
   Episode_Reward/pen_joint_torque: -0.0704
    Episode_Reward/pen_joint_accel: -0.0425
    Episode_Reward/pen_action_rate: -0.0236
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0232
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0490
Episode_Reward/pen_flat_orientation: -0.1348
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.0837
   Episode_Reward/foot_landing_vel: -0.0616
   Episode_Reward/test_gait_reward: -0.3453
Metrics/base_velocity/error_vel_xy: 1.1376
Metrics/base_velocity/error_vel_yaw: 0.3486
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 9.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 1.09s
                        Total time: 578.09s
                               ETA: 2695.2s

################################################################################
                     [1m Learning iteration 530/3000 [0m                      

                       Computation: 88175 steps/s (collection: 0.992s, learning 0.123s)
               Value function loss: 1.1563
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6612
                     Learning rate: 0.0019
                       Mean reward: 18.80
               Mean episode length: 294.39
       Episode_Reward/keep_balance: 0.3491
     Episode_Reward/rew_lin_vel_xy: 0.9253
      Episode_Reward/rew_ang_vel_z: 1.0368
    Episode_Reward/pen_base_height: -0.2095
      Episode_Reward/pen_lin_vel_z: -0.0330
     Episode_Reward/pen_ang_vel_xy: -0.0521
   Episode_Reward/pen_joint_torque: -0.0673
    Episode_Reward/pen_joint_accel: -0.0382
    Episode_Reward/pen_action_rate: -0.0223
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0143
   Episode_Reward/pen_joint_powers: -0.0224
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0466
Episode_Reward/pen_flat_orientation: -0.1351
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0791
   Episode_Reward/foot_landing_vel: -0.0604
   Episode_Reward/test_gait_reward: -0.3259
Metrics/base_velocity/error_vel_xy: 1.0649
Metrics/base_velocity/error_vel_yaw: 0.3281
      Episode_Termination/time_out: 0.9167
  Episode_Termination/base_contact: 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 1.11s
                        Total time: 579.20s
                               ETA: 2694.2s

################################################################################
                     [1m Learning iteration 531/3000 [0m                      

                       Computation: 88689 steps/s (collection: 0.986s, learning 0.123s)
               Value function loss: 1.1501
                    Surrogate loss: 0.0009
             Mean action noise std: 0.6637
                     Learning rate: 0.0009
                       Mean reward: 28.65
               Mean episode length: 403.47
       Episode_Reward/keep_balance: 0.3534
     Episode_Reward/rew_lin_vel_xy: 0.9257
      Episode_Reward/rew_ang_vel_z: 1.0511
    Episode_Reward/pen_base_height: -0.2129
      Episode_Reward/pen_lin_vel_z: -0.0325
     Episode_Reward/pen_ang_vel_xy: -0.0519
   Episode_Reward/pen_joint_torque: -0.0653
    Episode_Reward/pen_joint_accel: -0.0401
    Episode_Reward/pen_action_rate: -0.0225
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0221
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0471
Episode_Reward/pen_flat_orientation: -0.1313
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0806
   Episode_Reward/foot_landing_vel: -0.0606
   Episode_Reward/test_gait_reward: -0.3254
Metrics/base_velocity/error_vel_xy: 1.0826
Metrics/base_velocity/error_vel_yaw: 0.3296
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 9.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 1.11s
                        Total time: 580.31s
                               ETA: 2693.2s

################################################################################
                     [1m Learning iteration 532/3000 [0m                      

                       Computation: 89613 steps/s (collection: 0.976s, learning 0.121s)
               Value function loss: 1.2228
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6648
                     Learning rate: 0.0013
                       Mean reward: 22.70
               Mean episode length: 324.89
       Episode_Reward/keep_balance: 0.3262
     Episode_Reward/rew_lin_vel_xy: 0.8598
      Episode_Reward/rew_ang_vel_z: 0.9690
    Episode_Reward/pen_base_height: -0.2054
      Episode_Reward/pen_lin_vel_z: -0.0311
     Episode_Reward/pen_ang_vel_xy: -0.0494
   Episode_Reward/pen_joint_torque: -0.0625
    Episode_Reward/pen_joint_accel: -0.0347
    Episode_Reward/pen_action_rate: -0.0206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0207
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0432
Episode_Reward/pen_flat_orientation: -0.1258
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.0736
   Episode_Reward/foot_landing_vel: -0.0541
   Episode_Reward/test_gait_reward: -0.3031
Metrics/base_velocity/error_vel_xy: 0.9915
Metrics/base_velocity/error_vel_yaw: 0.3085
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 9.5833
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 1.10s
                        Total time: 581.41s
                               ETA: 2692.2s

################################################################################
                     [1m Learning iteration 533/3000 [0m                      

                       Computation: 90467 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 1.2731
                    Surrogate loss: -0.0001
             Mean action noise std: 0.6645
                     Learning rate: 0.0009
                       Mean reward: 24.31
               Mean episode length: 384.88
       Episode_Reward/keep_balance: 0.3618
     Episode_Reward/rew_lin_vel_xy: 0.9616
      Episode_Reward/rew_ang_vel_z: 1.0684
    Episode_Reward/pen_base_height: -0.2195
      Episode_Reward/pen_lin_vel_z: -0.0330
     Episode_Reward/pen_ang_vel_xy: -0.0524
   Episode_Reward/pen_joint_torque: -0.0690
    Episode_Reward/pen_joint_accel: -0.0382
    Episode_Reward/pen_action_rate: -0.0229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0148
   Episode_Reward/pen_joint_powers: -0.0231
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0480
Episode_Reward/pen_flat_orientation: -0.1348
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.0856
   Episode_Reward/foot_landing_vel: -0.0623
   Episode_Reward/test_gait_reward: -0.3365
Metrics/base_velocity/error_vel_xy: 1.0908
Metrics/base_velocity/error_vel_yaw: 0.3433
      Episode_Termination/time_out: 0.9583
  Episode_Termination/base_contact: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 1.09s
                        Total time: 582.50s
                               ETA: 2691.0s

################################################################################
                     [1m Learning iteration 534/3000 [0m                      

                       Computation: 90718 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 1.4296
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6651
                     Learning rate: 0.0009
                       Mean reward: 27.32
               Mean episode length: 405.85
       Episode_Reward/keep_balance: 0.3912
     Episode_Reward/rew_lin_vel_xy: 0.9905
      Episode_Reward/rew_ang_vel_z: 1.1627
    Episode_Reward/pen_base_height: -0.2156
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.0574
   Episode_Reward/pen_joint_torque: -0.0767
    Episode_Reward/pen_joint_accel: -0.0423
    Episode_Reward/pen_action_rate: -0.0255
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0166
   Episode_Reward/pen_joint_powers: -0.0260
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0524
Episode_Reward/pen_flat_orientation: -0.1466
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.0942
   Episode_Reward/foot_landing_vel: -0.0711
   Episode_Reward/test_gait_reward: -0.3646
Metrics/base_velocity/error_vel_xy: 1.2189
Metrics/base_velocity/error_vel_yaw: 0.3647
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 1.08s
                        Total time: 583.58s
                               ETA: 2689.9s

################################################################################
                     [1m Learning iteration 535/3000 [0m                      

                       Computation: 89809 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 1.2465
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6662
                     Learning rate: 0.0013
                       Mean reward: 31.12
               Mean episode length: 403.73
       Episode_Reward/keep_balance: 0.3933
     Episode_Reward/rew_lin_vel_xy: 1.0861
      Episode_Reward/rew_ang_vel_z: 1.1413
    Episode_Reward/pen_base_height: -0.2245
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.0595
   Episode_Reward/pen_joint_torque: -0.0778
    Episode_Reward/pen_joint_accel: -0.0441
    Episode_Reward/pen_action_rate: -0.0262
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0176
   Episode_Reward/pen_joint_powers: -0.0268
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0541
Episode_Reward/pen_flat_orientation: -0.1530
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1041
   Episode_Reward/foot_landing_vel: -0.0747
   Episode_Reward/test_gait_reward: -0.3683
Metrics/base_velocity/error_vel_xy: 1.1216
Metrics/base_velocity/error_vel_yaw: 0.3905
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 1.09s
                        Total time: 584.67s
                               ETA: 2688.8s

################################################################################
                     [1m Learning iteration 536/3000 [0m                      

                       Computation: 90603 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 1.1163
                    Surrogate loss: -0.0003
             Mean action noise std: 0.6673
                     Learning rate: 0.0004
                       Mean reward: 27.16
               Mean episode length: 367.06
       Episode_Reward/keep_balance: 0.3524
     Episode_Reward/rew_lin_vel_xy: 0.9488
      Episode_Reward/rew_ang_vel_z: 1.0386
    Episode_Reward/pen_base_height: -0.2079
      Episode_Reward/pen_lin_vel_z: -0.0326
     Episode_Reward/pen_ang_vel_xy: -0.0521
   Episode_Reward/pen_joint_torque: -0.0666
    Episode_Reward/pen_joint_accel: -0.0404
    Episode_Reward/pen_action_rate: -0.0228
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0222
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0478
Episode_Reward/pen_flat_orientation: -0.1349
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0806
   Episode_Reward/foot_landing_vel: -0.0589
   Episode_Reward/test_gait_reward: -0.3265
Metrics/base_velocity/error_vel_xy: 1.0795
Metrics/base_velocity/error_vel_yaw: 0.3362
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 1.08s
                        Total time: 585.76s
                               ETA: 2687.7s

################################################################################
                     [1m Learning iteration 537/3000 [0m                      

                       Computation: 90959 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 1.1469
                    Surrogate loss: -0.0007
             Mean action noise std: 0.6680
                     Learning rate: 0.0006
                       Mean reward: 23.21
               Mean episode length: 327.20
       Episode_Reward/keep_balance: 0.3790
     Episode_Reward/rew_lin_vel_xy: 1.0261
      Episode_Reward/rew_ang_vel_z: 1.1248
    Episode_Reward/pen_base_height: -0.2184
      Episode_Reward/pen_lin_vel_z: -0.0347
     Episode_Reward/pen_ang_vel_xy: -0.0539
   Episode_Reward/pen_joint_torque: -0.0710
    Episode_Reward/pen_joint_accel: -0.0416
    Episode_Reward/pen_action_rate: -0.0246
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0153
   Episode_Reward/pen_joint_powers: -0.0238
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0512
Episode_Reward/pen_flat_orientation: -0.1406
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.0876
   Episode_Reward/foot_landing_vel: -0.0662
   Episode_Reward/test_gait_reward: -0.3510
Metrics/base_velocity/error_vel_xy: 1.1517
Metrics/base_velocity/error_vel_yaw: 0.3546
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 1.08s
                        Total time: 586.84s
                               ETA: 2686.6s

################################################################################
                     [1m Learning iteration 538/3000 [0m                      

                       Computation: 90070 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 1.2906
                    Surrogate loss: 0.0002
             Mean action noise std: 0.6689
                     Learning rate: 0.0004
                       Mean reward: 29.21
               Mean episode length: 372.31
       Episode_Reward/keep_balance: 0.4001
     Episode_Reward/rew_lin_vel_xy: 1.1311
      Episode_Reward/rew_ang_vel_z: 1.1895
    Episode_Reward/pen_base_height: -0.2232
      Episode_Reward/pen_lin_vel_z: -0.0347
     Episode_Reward/pen_ang_vel_xy: -0.0561
   Episode_Reward/pen_joint_torque: -0.0756
    Episode_Reward/pen_joint_accel: -0.0440
    Episode_Reward/pen_action_rate: -0.0258
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0158
   Episode_Reward/pen_joint_powers: -0.0248
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0545
Episode_Reward/pen_flat_orientation: -0.1426
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.0883
   Episode_Reward/foot_landing_vel: -0.0661
   Episode_Reward/test_gait_reward: -0.3677
Metrics/base_velocity/error_vel_xy: 1.1521
Metrics/base_velocity/error_vel_yaw: 0.3740
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 1.09s
                        Total time: 587.93s
                               ETA: 2685.5s

################################################################################
                     [1m Learning iteration 539/3000 [0m                      

                       Computation: 89524 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 1.1152
                    Surrogate loss: 0.0007
             Mean action noise std: 0.6700
                     Learning rate: 0.0001
                       Mean reward: 26.22
               Mean episode length: 353.86
       Episode_Reward/keep_balance: 0.3748
     Episode_Reward/rew_lin_vel_xy: 1.0249
      Episode_Reward/rew_ang_vel_z: 1.0946
    Episode_Reward/pen_base_height: -0.2218
      Episode_Reward/pen_lin_vel_z: -0.0350
     Episode_Reward/pen_ang_vel_xy: -0.0556
   Episode_Reward/pen_joint_torque: -0.0726
    Episode_Reward/pen_joint_accel: -0.0425
    Episode_Reward/pen_action_rate: -0.0247
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0245
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0517
Episode_Reward/pen_flat_orientation: -0.1433
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.0910
   Episode_Reward/foot_landing_vel: -0.0644
   Episode_Reward/test_gait_reward: -0.3488
Metrics/base_velocity/error_vel_xy: 1.1197
Metrics/base_velocity/error_vel_yaw: 0.3639
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 1.10s
                        Total time: 589.03s
                               ETA: 2684.4s

################################################################################
                     [1m Learning iteration 540/3000 [0m                      

                       Computation: 89463 steps/s (collection: 0.977s, learning 0.121s)
               Value function loss: 1.0295
                    Surrogate loss: 0.0014
             Mean action noise std: 0.6698
                     Learning rate: 0.0001
                       Mean reward: 27.28
               Mean episode length: 374.22
       Episode_Reward/keep_balance: 0.3722
     Episode_Reward/rew_lin_vel_xy: 0.9880
      Episode_Reward/rew_ang_vel_z: 1.1069
    Episode_Reward/pen_base_height: -0.2175
      Episode_Reward/pen_lin_vel_z: -0.0337
     Episode_Reward/pen_ang_vel_xy: -0.0550
   Episode_Reward/pen_joint_torque: -0.0706
    Episode_Reward/pen_joint_accel: -0.0402
    Episode_Reward/pen_action_rate: -0.0242
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0150
   Episode_Reward/pen_joint_powers: -0.0236
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0506
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.0851
   Episode_Reward/foot_landing_vel: -0.0614
   Episode_Reward/test_gait_reward: -0.3437
Metrics/base_velocity/error_vel_xy: 1.1554
Metrics/base_velocity/error_vel_yaw: 0.3475
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 1.10s
                        Total time: 590.13s
                               ETA: 2683.4s

################################################################################
                     [1m Learning iteration 541/3000 [0m                      

                       Computation: 89656 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 0.9380
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6701
                     Learning rate: 0.0002
                       Mean reward: 21.61
               Mean episode length: 313.97
       Episode_Reward/keep_balance: 0.3435
     Episode_Reward/rew_lin_vel_xy: 0.9167
      Episode_Reward/rew_ang_vel_z: 1.0062
    Episode_Reward/pen_base_height: -0.2078
      Episode_Reward/pen_lin_vel_z: -0.0325
     Episode_Reward/pen_ang_vel_xy: -0.0525
   Episode_Reward/pen_joint_torque: -0.0646
    Episode_Reward/pen_joint_accel: -0.0386
    Episode_Reward/pen_action_rate: -0.0225
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0218
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0471
Episode_Reward/pen_flat_orientation: -0.1361
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.0796
   Episode_Reward/foot_landing_vel: -0.0601
   Episode_Reward/test_gait_reward: -0.3194
Metrics/base_velocity/error_vel_xy: 1.0503
Metrics/base_velocity/error_vel_yaw: 0.3338
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 1.10s
                        Total time: 591.22s
                               ETA: 2682.3s

################################################################################
                     [1m Learning iteration 542/3000 [0m                      

                       Computation: 89861 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 1.0488
                    Surrogate loss: 0.0002
             Mean action noise std: 0.6707
                     Learning rate: 0.0002
                       Mean reward: 27.89
               Mean episode length: 386.15
       Episode_Reward/keep_balance: 0.3509
     Episode_Reward/rew_lin_vel_xy: 0.9730
      Episode_Reward/rew_ang_vel_z: 1.0379
    Episode_Reward/pen_base_height: -0.2082
      Episode_Reward/pen_lin_vel_z: -0.0326
     Episode_Reward/pen_ang_vel_xy: -0.0523
   Episode_Reward/pen_joint_torque: -0.0675
    Episode_Reward/pen_joint_accel: -0.0378
    Episode_Reward/pen_action_rate: -0.0229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0140
   Episode_Reward/pen_joint_powers: -0.0223
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0482
Episode_Reward/pen_flat_orientation: -0.1295
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0799
   Episode_Reward/foot_landing_vel: -0.0573
   Episode_Reward/test_gait_reward: -0.3239
Metrics/base_velocity/error_vel_xy: 1.0695
Metrics/base_velocity/error_vel_yaw: 0.3331
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 1.09s
                        Total time: 592.32s
                               ETA: 2681.3s

################################################################################
                     [1m Learning iteration 543/3000 [0m                      

                       Computation: 90188 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.9099
                    Surrogate loss: -0.0029
             Mean action noise std: 0.6709
                     Learning rate: 0.0006
                       Mean reward: 21.76
               Mean episode length: 323.83
       Episode_Reward/keep_balance: 0.3701
     Episode_Reward/rew_lin_vel_xy: 0.9926
      Episode_Reward/rew_ang_vel_z: 1.0832
    Episode_Reward/pen_base_height: -0.2112
      Episode_Reward/pen_lin_vel_z: -0.0337
     Episode_Reward/pen_ang_vel_xy: -0.0545
   Episode_Reward/pen_joint_torque: -0.0699
    Episode_Reward/pen_joint_accel: -0.0422
    Episode_Reward/pen_action_rate: -0.0244
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0152
   Episode_Reward/pen_joint_powers: -0.0236
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0509
Episode_Reward/pen_flat_orientation: -0.1357
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.0866
   Episode_Reward/foot_landing_vel: -0.0608
   Episode_Reward/test_gait_reward: -0.3418
Metrics/base_velocity/error_vel_xy: 1.1335
Metrics/base_velocity/error_vel_yaw: 0.3586
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 1.09s
                        Total time: 593.41s
                               ETA: 2680.2s

################################################################################
                     [1m Learning iteration 544/3000 [0m                      

                       Computation: 89655 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 1.0706
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6721
                     Learning rate: 0.0013
                       Mean reward: 24.23
               Mean episode length: 364.45
       Episode_Reward/keep_balance: 0.3676
     Episode_Reward/rew_lin_vel_xy: 0.9682
      Episode_Reward/rew_ang_vel_z: 1.0777
    Episode_Reward/pen_base_height: -0.2126
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.0569
   Episode_Reward/pen_joint_torque: -0.0712
    Episode_Reward/pen_joint_accel: -0.0433
    Episode_Reward/pen_action_rate: -0.0247
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0244
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0514
Episode_Reward/pen_flat_orientation: -0.1422
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0914
   Episode_Reward/foot_landing_vel: -0.0661
   Episode_Reward/test_gait_reward: -0.3424
Metrics/base_velocity/error_vel_xy: 1.1637
Metrics/base_velocity/error_vel_yaw: 0.3547
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 1.10s
                        Total time: 594.50s
                               ETA: 2679.1s

################################################################################
                     [1m Learning iteration 545/3000 [0m                      

                       Computation: 88447 steps/s (collection: 0.989s, learning 0.122s)
               Value function loss: 1.2747
                    Surrogate loss: 0.0028
             Mean action noise std: 0.6731
                     Learning rate: 0.0002
                       Mean reward: 36.42
               Mean episode length: 476.81
       Episode_Reward/keep_balance: 0.4271
     Episode_Reward/rew_lin_vel_xy: 1.2441
      Episode_Reward/rew_ang_vel_z: 1.2494
    Episode_Reward/pen_base_height: -0.2361
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.0631
   Episode_Reward/pen_joint_torque: -0.0857
    Episode_Reward/pen_joint_accel: -0.0496
    Episode_Reward/pen_action_rate: -0.0289
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0186
   Episode_Reward/pen_joint_powers: -0.0289
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0595
Episode_Reward/pen_flat_orientation: -0.1560
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1108
   Episode_Reward/foot_landing_vel: -0.0770
   Episode_Reward/test_gait_reward: -0.4004
Metrics/base_velocity/error_vel_xy: 1.2420
Metrics/base_velocity/error_vel_yaw: 0.4157
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 1.11s
                        Total time: 595.62s
                               ETA: 2678.1s

################################################################################
                     [1m Learning iteration 546/3000 [0m                      

                       Computation: 89221 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 1.0522
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6731
                     Learning rate: 0.0004
                       Mean reward: 24.91
               Mean episode length: 365.05
       Episode_Reward/keep_balance: 0.3753
     Episode_Reward/rew_lin_vel_xy: 1.0152
      Episode_Reward/rew_ang_vel_z: 1.0872
    Episode_Reward/pen_base_height: -0.2197
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.0584
   Episode_Reward/pen_joint_torque: -0.0723
    Episode_Reward/pen_joint_accel: -0.0457
    Episode_Reward/pen_action_rate: -0.0255
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0169
   Episode_Reward/pen_joint_powers: -0.0254
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0528
Episode_Reward/pen_flat_orientation: -0.1466
  Episode_Reward/pen_feet_distance: -0.0025
Episode_Reward/pen_feet_regulation: -0.0986
   Episode_Reward/foot_landing_vel: -0.0724
   Episode_Reward/test_gait_reward: -0.3500
Metrics/base_velocity/error_vel_xy: 1.1375
Metrics/base_velocity/error_vel_yaw: 0.3737
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 1.10s
                        Total time: 596.72s
                               ETA: 2677.0s

################################################################################
                     [1m Learning iteration 547/3000 [0m                      

                       Computation: 89708 steps/s (collection: 0.974s, learning 0.121s)
               Value function loss: 1.1154
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6738
                     Learning rate: 0.0003
                       Mean reward: 24.37
               Mean episode length: 363.17
       Episode_Reward/keep_balance: 0.3683
     Episode_Reward/rew_lin_vel_xy: 0.9675
      Episode_Reward/rew_ang_vel_z: 1.0775
    Episode_Reward/pen_base_height: -0.2157
      Episode_Reward/pen_lin_vel_z: -0.0340
     Episode_Reward/pen_ang_vel_xy: -0.0554
   Episode_Reward/pen_joint_torque: -0.0704
    Episode_Reward/pen_joint_accel: -0.0411
    Episode_Reward/pen_action_rate: -0.0245
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0156
   Episode_Reward/pen_joint_powers: -0.0241
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0513
Episode_Reward/pen_flat_orientation: -0.1375
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0885
   Episode_Reward/foot_landing_vel: -0.0637
   Episode_Reward/test_gait_reward: -0.3408
Metrics/base_velocity/error_vel_xy: 1.1130
Metrics/base_velocity/error_vel_yaw: 0.3580
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 1.10s
                        Total time: 597.81s
                               ETA: 2676.0s

################################################################################
                     [1m Learning iteration 548/3000 [0m                      

                       Computation: 90558 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.9709
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6757
                     Learning rate: 0.0006
                       Mean reward: 28.19
               Mean episode length: 395.91
       Episode_Reward/keep_balance: 0.3815
     Episode_Reward/rew_lin_vel_xy: 1.0759
      Episode_Reward/rew_ang_vel_z: 1.1298
    Episode_Reward/pen_base_height: -0.2159
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.0560
   Episode_Reward/pen_joint_torque: -0.0740
    Episode_Reward/pen_joint_accel: -0.0430
    Episode_Reward/pen_action_rate: -0.0252
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0157
   Episode_Reward/pen_joint_powers: -0.0246
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0525
Episode_Reward/pen_flat_orientation: -0.1451
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.0899
   Episode_Reward/foot_landing_vel: -0.0621
   Episode_Reward/test_gait_reward: -0.3533
Metrics/base_velocity/error_vel_xy: 1.1252
Metrics/base_velocity/error_vel_yaw: 0.3594
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 9.4167
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 1.09s
                        Total time: 598.90s
                               ETA: 2674.9s

################################################################################
                     [1m Learning iteration 549/3000 [0m                      

                       Computation: 89151 steps/s (collection: 0.977s, learning 0.126s)
               Value function loss: 0.9883
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6765
                     Learning rate: 0.0006
                       Mean reward: 24.06
               Mean episode length: 371.10
       Episode_Reward/keep_balance: 0.3756
     Episode_Reward/rew_lin_vel_xy: 1.0147
      Episode_Reward/rew_ang_vel_z: 1.0939
    Episode_Reward/pen_base_height: -0.2176
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.0591
   Episode_Reward/pen_joint_torque: -0.0732
    Episode_Reward/pen_joint_accel: -0.0423
    Episode_Reward/pen_action_rate: -0.0254
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0163
   Episode_Reward/pen_joint_powers: -0.0254
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0526
Episode_Reward/pen_flat_orientation: -0.1432
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.0950
   Episode_Reward/foot_landing_vel: -0.0649
   Episode_Reward/test_gait_reward: -0.3498
Metrics/base_velocity/error_vel_xy: 1.1168
Metrics/base_velocity/error_vel_yaw: 0.3689
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 1.10s
                        Total time: 600.00s
                               ETA: 2673.8s

################################################################################
                     [1m Learning iteration 550/3000 [0m                      

                       Computation: 89744 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 1.0664
                    Surrogate loss: -0.0035
             Mean action noise std: 0.6773
                     Learning rate: 0.0013
                       Mean reward: 27.74
               Mean episode length: 395.73
       Episode_Reward/keep_balance: 0.4042
     Episode_Reward/rew_lin_vel_xy: 1.1059
      Episode_Reward/rew_ang_vel_z: 1.1829
    Episode_Reward/pen_base_height: -0.2163
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.0597
   Episode_Reward/pen_joint_torque: -0.0787
    Episode_Reward/pen_joint_accel: -0.0418
    Episode_Reward/pen_action_rate: -0.0274
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0170
   Episode_Reward/pen_joint_powers: -0.0266
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0570
Episode_Reward/pen_flat_orientation: -0.1483
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0972
   Episode_Reward/foot_landing_vel: -0.0696
   Episode_Reward/test_gait_reward: -0.3740
Metrics/base_velocity/error_vel_xy: 1.2351
Metrics/base_velocity/error_vel_yaw: 0.3923
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 1.10s
                        Total time: 601.10s
                               ETA: 2672.8s

################################################################################
                     [1m Learning iteration 551/3000 [0m                      

                       Computation: 89101 steps/s (collection: 0.979s, learning 0.125s)
               Value function loss: 1.0524
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6781
                     Learning rate: 0.0006
                       Mean reward: 35.47
               Mean episode length: 475.20
       Episode_Reward/keep_balance: 0.4617
     Episode_Reward/rew_lin_vel_xy: 1.2614
      Episode_Reward/rew_ang_vel_z: 1.3738
    Episode_Reward/pen_base_height: -0.2337
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.0657
   Episode_Reward/pen_joint_torque: -0.0937
    Episode_Reward/pen_joint_accel: -0.0518
    Episode_Reward/pen_action_rate: -0.0314
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0202
   Episode_Reward/pen_joint_powers: -0.0313
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0644
Episode_Reward/pen_flat_orientation: -0.1637
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1172
   Episode_Reward/foot_landing_vel: -0.0831
   Episode_Reward/test_gait_reward: -0.4292
Metrics/base_velocity/error_vel_xy: 1.3879
Metrics/base_velocity/error_vel_yaw: 0.4301
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 1.10s
                        Total time: 602.20s
                               ETA: 2671.7s

################################################################################
                     [1m Learning iteration 552/3000 [0m                      

                       Computation: 89108 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 1.0493
                    Surrogate loss: -0.0012
             Mean action noise std: 0.6789
                     Learning rate: 0.0006
                       Mean reward: 33.46
               Mean episode length: 461.06
       Episode_Reward/keep_balance: 0.4299
     Episode_Reward/rew_lin_vel_xy: 1.1847
      Episode_Reward/rew_ang_vel_z: 1.2740
    Episode_Reward/pen_base_height: -0.2239
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.0626
   Episode_Reward/pen_joint_torque: -0.0852
    Episode_Reward/pen_joint_accel: -0.0489
    Episode_Reward/pen_action_rate: -0.0294
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0186
   Episode_Reward/pen_joint_powers: -0.0288
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0602
Episode_Reward/pen_flat_orientation: -0.1531
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1097
   Episode_Reward/foot_landing_vel: -0.0745
   Episode_Reward/test_gait_reward: -0.3974
Metrics/base_velocity/error_vel_xy: 1.3109
Metrics/base_velocity/error_vel_yaw: 0.4065
      Episode_Termination/time_out: 2.5833
  Episode_Termination/base_contact: 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 1.10s
                        Total time: 603.30s
                               ETA: 2670.7s

################################################################################
                     [1m Learning iteration 553/3000 [0m                      

                       Computation: 89511 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.9992
                    Surrogate loss: 0.0010
             Mean action noise std: 0.6797
                     Learning rate: 0.0003
                       Mean reward: 34.96
               Mean episode length: 437.93
       Episode_Reward/keep_balance: 0.4166
     Episode_Reward/rew_lin_vel_xy: 1.1730
      Episode_Reward/rew_ang_vel_z: 1.2268
    Episode_Reward/pen_base_height: -0.2231
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.0612
   Episode_Reward/pen_joint_torque: -0.0817
    Episode_Reward/pen_joint_accel: -0.0483
    Episode_Reward/pen_action_rate: -0.0285
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0175
   Episode_Reward/pen_joint_powers: -0.0275
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0590
Episode_Reward/pen_flat_orientation: -0.1503
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.1019
   Episode_Reward/foot_landing_vel: -0.0703
   Episode_Reward/test_gait_reward: -0.3877
Metrics/base_velocity/error_vel_xy: 1.2672
Metrics/base_velocity/error_vel_yaw: 0.3970
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 1.10s
                        Total time: 604.40s
                               ETA: 2669.6s

################################################################################
                     [1m Learning iteration 554/3000 [0m                      

                       Computation: 89759 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 1.0556
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6810
                     Learning rate: 0.0006
                       Mean reward: 26.70
               Mean episode length: 385.66
       Episode_Reward/keep_balance: 0.4098
     Episode_Reward/rew_lin_vel_xy: 1.0614
      Episode_Reward/rew_ang_vel_z: 1.2032
    Episode_Reward/pen_base_height: -0.2191
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.0599
   Episode_Reward/pen_joint_torque: -0.0800
    Episode_Reward/pen_joint_accel: -0.0433
    Episode_Reward/pen_action_rate: -0.0280
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0173
   Episode_Reward/pen_joint_powers: -0.0270
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0582
Episode_Reward/pen_flat_orientation: -0.1410
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.0985
   Episode_Reward/foot_landing_vel: -0.0732
   Episode_Reward/test_gait_reward: -0.3766
Metrics/base_velocity/error_vel_xy: 1.3339
Metrics/base_velocity/error_vel_yaw: 0.3944
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 1.10s
                        Total time: 605.50s
                               ETA: 2668.6s

################################################################################
                     [1m Learning iteration 555/3000 [0m                      

                       Computation: 87679 steps/s (collection: 1.000s, learning 0.121s)
               Value function loss: 1.1016
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6824
                     Learning rate: 0.0006
                       Mean reward: 28.09
               Mean episode length: 393.07
       Episode_Reward/keep_balance: 0.3735
     Episode_Reward/rew_lin_vel_xy: 1.0298
      Episode_Reward/rew_ang_vel_z: 1.0917
    Episode_Reward/pen_base_height: -0.2118
      Episode_Reward/pen_lin_vel_z: -0.0345
     Episode_Reward/pen_ang_vel_xy: -0.0565
   Episode_Reward/pen_joint_torque: -0.0721
    Episode_Reward/pen_joint_accel: -0.0456
    Episode_Reward/pen_action_rate: -0.0259
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0164
   Episode_Reward/pen_joint_powers: -0.0249
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0537
Episode_Reward/pen_flat_orientation: -0.1416
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.0923
   Episode_Reward/foot_landing_vel: -0.0675
   Episode_Reward/test_gait_reward: -0.3462
Metrics/base_velocity/error_vel_xy: 1.1314
Metrics/base_velocity/error_vel_yaw: 0.3646
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 6.8750
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 1.12s
                        Total time: 606.62s
                               ETA: 2667.6s

################################################################################
                     [1m Learning iteration 556/3000 [0m                      

                       Computation: 88496 steps/s (collection: 0.989s, learning 0.122s)
               Value function loss: 0.9663
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6823
                     Learning rate: 0.0009
                       Mean reward: 33.03
               Mean episode length: 436.75
       Episode_Reward/keep_balance: 0.4222
     Episode_Reward/rew_lin_vel_xy: 1.1963
      Episode_Reward/rew_ang_vel_z: 1.2395
    Episode_Reward/pen_base_height: -0.2235
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.0622
   Episode_Reward/pen_joint_torque: -0.0825
    Episode_Reward/pen_joint_accel: -0.0465
    Episode_Reward/pen_action_rate: -0.0295
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0181
   Episode_Reward/pen_joint_powers: -0.0281
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0610
Episode_Reward/pen_flat_orientation: -0.1513
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1072
   Episode_Reward/foot_landing_vel: -0.0728
   Episode_Reward/test_gait_reward: -0.3934
Metrics/base_velocity/error_vel_xy: 1.2887
Metrics/base_velocity/error_vel_yaw: 0.4045
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 1.11s
                        Total time: 607.73s
                               ETA: 2666.6s

################################################################################
                     [1m Learning iteration 557/3000 [0m                      

                       Computation: 88766 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 1.1807
                    Surrogate loss: 0.0003
             Mean action noise std: 0.6823
                     Learning rate: 0.0002
                       Mean reward: 28.24
               Mean episode length: 381.57
       Episode_Reward/keep_balance: 0.3812
     Episode_Reward/rew_lin_vel_xy: 1.1225
      Episode_Reward/rew_ang_vel_z: 1.1203
    Episode_Reward/pen_base_height: -0.2151
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.0569
   Episode_Reward/pen_joint_torque: -0.0750
    Episode_Reward/pen_joint_accel: -0.0417
    Episode_Reward/pen_action_rate: -0.0263
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0163
   Episode_Reward/pen_joint_powers: -0.0255
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0542
Episode_Reward/pen_flat_orientation: -0.1407
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0967
   Episode_Reward/foot_landing_vel: -0.0669
   Episode_Reward/test_gait_reward: -0.3553
Metrics/base_velocity/error_vel_xy: 1.1138
Metrics/base_velocity/error_vel_yaw: 0.3638
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 1.11s
                        Total time: 608.84s
                               ETA: 2665.6s

################################################################################
                     [1m Learning iteration 558/3000 [0m                      

                       Computation: 89728 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 1.1199
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6830
                     Learning rate: 0.0004
                       Mean reward: 30.68
               Mean episode length: 419.87
       Episode_Reward/keep_balance: 0.4412
     Episode_Reward/rew_lin_vel_xy: 1.2559
      Episode_Reward/rew_ang_vel_z: 1.2955
    Episode_Reward/pen_base_height: -0.2318
      Episode_Reward/pen_lin_vel_z: -0.0406
     Episode_Reward/pen_ang_vel_xy: -0.0648
   Episode_Reward/pen_joint_torque: -0.0861
    Episode_Reward/pen_joint_accel: -0.0527
    Episode_Reward/pen_action_rate: -0.0309
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0191
   Episode_Reward/pen_joint_powers: -0.0294
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0639
Episode_Reward/pen_flat_orientation: -0.1567
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.1088
   Episode_Reward/foot_landing_vel: -0.0759
   Episode_Reward/test_gait_reward: -0.4094
Metrics/base_velocity/error_vel_xy: 1.3384
Metrics/base_velocity/error_vel_yaw: 0.4231
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 1.10s
                        Total time: 609.93s
                               ETA: 2664.5s

################################################################################
                     [1m Learning iteration 559/3000 [0m                      

                       Computation: 89593 steps/s (collection: 0.975s, learning 0.122s)
               Value function loss: 1.0581
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6829
                     Learning rate: 0.0009
                       Mean reward: 26.15
               Mean episode length: 375.21
       Episode_Reward/keep_balance: 0.4154
     Episode_Reward/rew_lin_vel_xy: 1.2346
      Episode_Reward/rew_ang_vel_z: 1.2078
    Episode_Reward/pen_base_height: -0.2243
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.0605
   Episode_Reward/pen_joint_torque: -0.0817
    Episode_Reward/pen_joint_accel: -0.0473
    Episode_Reward/pen_action_rate: -0.0293
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0181
   Episode_Reward/pen_joint_powers: -0.0277
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0606
Episode_Reward/pen_flat_orientation: -0.1524
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.1049
   Episode_Reward/foot_landing_vel: -0.0733
   Episode_Reward/test_gait_reward: -0.3884
Metrics/base_velocity/error_vel_xy: 1.1721
Metrics/base_velocity/error_vel_yaw: 0.4092
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 1.10s
                        Total time: 611.03s
                               ETA: 2663.4s

################################################################################
                     [1m Learning iteration 560/3000 [0m                      

                       Computation: 90293 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 1.1850
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6840
                     Learning rate: 0.0009
                       Mean reward: 26.02
               Mean episode length: 353.23
       Episode_Reward/keep_balance: 0.3861
     Episode_Reward/rew_lin_vel_xy: 1.0606
      Episode_Reward/rew_ang_vel_z: 1.1245
    Episode_Reward/pen_base_height: -0.2166
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.0598
   Episode_Reward/pen_joint_torque: -0.0743
    Episode_Reward/pen_joint_accel: -0.0434
    Episode_Reward/pen_action_rate: -0.0272
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0168
   Episode_Reward/pen_joint_powers: -0.0259
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0567
Episode_Reward/pen_flat_orientation: -0.1454
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.0981
   Episode_Reward/foot_landing_vel: -0.0675
   Episode_Reward/test_gait_reward: -0.3592
Metrics/base_velocity/error_vel_xy: 1.1650
Metrics/base_velocity/error_vel_yaw: 0.3788
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 1.09s
                        Total time: 612.12s
                               ETA: 2662.3s

################################################################################
                     [1m Learning iteration 561/3000 [0m                      

                       Computation: 90410 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 1.0274
                    Surrogate loss: 0.0030
             Mean action noise std: 0.6849
                     Learning rate: 0.0001
                       Mean reward: 24.84
               Mean episode length: 363.48
       Episode_Reward/keep_balance: 0.3618
     Episode_Reward/rew_lin_vel_xy: 0.9820
      Episode_Reward/rew_ang_vel_z: 1.0543
    Episode_Reward/pen_base_height: -0.2130
      Episode_Reward/pen_lin_vel_z: -0.0327
     Episode_Reward/pen_ang_vel_xy: -0.0562
   Episode_Reward/pen_joint_torque: -0.0677
    Episode_Reward/pen_joint_accel: -0.0408
    Episode_Reward/pen_action_rate: -0.0252
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0154
   Episode_Reward/pen_joint_powers: -0.0236
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0529
Episode_Reward/pen_flat_orientation: -0.1307
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0919
   Episode_Reward/foot_landing_vel: -0.0613
   Episode_Reward/test_gait_reward: -0.3381
Metrics/base_velocity/error_vel_xy: 1.1300
Metrics/base_velocity/error_vel_yaw: 0.3533
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 1.09s
                        Total time: 613.21s
                               ETA: 2661.2s

################################################################################
                     [1m Learning iteration 562/3000 [0m                      

                       Computation: 90619 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 1.0707
                    Surrogate loss: 0.0014
             Mean action noise std: 0.6846
                     Learning rate: 0.0001
                       Mean reward: 31.58
               Mean episode length: 402.33
       Episode_Reward/keep_balance: 0.4177
     Episode_Reward/rew_lin_vel_xy: 1.1824
      Episode_Reward/rew_ang_vel_z: 1.2365
    Episode_Reward/pen_base_height: -0.2217
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.0620
   Episode_Reward/pen_joint_torque: -0.0802
    Episode_Reward/pen_joint_accel: -0.0452
    Episode_Reward/pen_action_rate: -0.0293
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0174
   Episode_Reward/pen_joint_powers: -0.0273
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0608
Episode_Reward/pen_flat_orientation: -0.1432
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1035
   Episode_Reward/foot_landing_vel: -0.0676
   Episode_Reward/test_gait_reward: -0.3880
Metrics/base_velocity/error_vel_xy: 1.2194
Metrics/base_velocity/error_vel_yaw: 0.3940
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 1.08s
                        Total time: 614.29s
                               ETA: 2660.1s

################################################################################
                     [1m Learning iteration 563/3000 [0m                      

                       Computation: 91107 steps/s (collection: 0.958s, learning 0.121s)
               Value function loss: 1.0875
                    Surrogate loss: 0.0004
             Mean action noise std: 0.6844
                     Learning rate: 0.0002
                       Mean reward: 33.03
               Mean episode length: 441.52
       Episode_Reward/keep_balance: 0.4163
     Episode_Reward/rew_lin_vel_xy: 1.1854
      Episode_Reward/rew_ang_vel_z: 1.2299
    Episode_Reward/pen_base_height: -0.2263
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.0611
   Episode_Reward/pen_joint_torque: -0.0826
    Episode_Reward/pen_joint_accel: -0.0465
    Episode_Reward/pen_action_rate: -0.0293
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0177
   Episode_Reward/pen_joint_powers: -0.0279
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0606
Episode_Reward/pen_flat_orientation: -0.1510
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.1064
   Episode_Reward/foot_landing_vel: -0.0688
   Episode_Reward/test_gait_reward: -0.3904
Metrics/base_velocity/error_vel_xy: 1.2123
Metrics/base_velocity/error_vel_yaw: 0.3957
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 1.08s
                        Total time: 615.37s
                               ETA: 2659.0s

################################################################################
                     [1m Learning iteration 564/3000 [0m                      

                       Computation: 91385 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.9615
                    Surrogate loss: -0.0036
             Mean action noise std: 0.6847
                     Learning rate: 0.0004
                       Mean reward: 28.55
               Mean episode length: 395.05
       Episode_Reward/keep_balance: 0.4495
     Episode_Reward/rew_lin_vel_xy: 1.3133
      Episode_Reward/rew_ang_vel_z: 1.2965
    Episode_Reward/pen_base_height: -0.2384
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.0675
   Episode_Reward/pen_joint_torque: -0.0909
    Episode_Reward/pen_joint_accel: -0.0540
    Episode_Reward/pen_action_rate: -0.0328
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0210
   Episode_Reward/pen_joint_powers: -0.0317
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0675
Episode_Reward/pen_flat_orientation: -0.1686
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.1302
   Episode_Reward/foot_landing_vel: -0.0856
   Episode_Reward/test_gait_reward: -0.4195
Metrics/base_velocity/error_vel_xy: 1.3042
Metrics/base_velocity/error_vel_yaw: 0.4511
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 8.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 1.08s
                        Total time: 616.45s
                               ETA: 2657.8s

################################################################################
                     [1m Learning iteration 565/3000 [0m                      

                       Computation: 90342 steps/s (collection: 0.967s, learning 0.121s)
               Value function loss: 1.1472
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6855
                     Learning rate: 0.0009
                       Mean reward: 28.79
               Mean episode length: 392.12
       Episode_Reward/keep_balance: 0.3573
     Episode_Reward/rew_lin_vel_xy: 1.0084
      Episode_Reward/rew_ang_vel_z: 1.0566
    Episode_Reward/pen_base_height: -0.2075
      Episode_Reward/pen_lin_vel_z: -0.0320
     Episode_Reward/pen_ang_vel_xy: -0.0547
   Episode_Reward/pen_joint_torque: -0.0693
    Episode_Reward/pen_joint_accel: -0.0387
    Episode_Reward/pen_action_rate: -0.0250
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0146
   Episode_Reward/pen_joint_powers: -0.0233
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0523
Episode_Reward/pen_flat_orientation: -0.1328
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0865
   Episode_Reward/foot_landing_vel: -0.0579
   Episode_Reward/test_gait_reward: -0.3308
Metrics/base_velocity/error_vel_xy: 1.0515
Metrics/base_velocity/error_vel_yaw: 0.3378
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 9.5833
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 1.09s
                        Total time: 617.53s
                               ETA: 2656.7s

################################################################################
                     [1m Learning iteration 566/3000 [0m                      

                       Computation: 90735 steps/s (collection: 0.962s, learning 0.121s)
               Value function loss: 1.1374
                    Surrogate loss: -0.0007
             Mean action noise std: 0.6855
                     Learning rate: 0.0009
                       Mean reward: 36.95
               Mean episode length: 478.08
       Episode_Reward/keep_balance: 0.4547
     Episode_Reward/rew_lin_vel_xy: 1.3270
      Episode_Reward/rew_ang_vel_z: 1.3406
    Episode_Reward/pen_base_height: -0.2348
      Episode_Reward/pen_lin_vel_z: -0.0420
     Episode_Reward/pen_ang_vel_xy: -0.0664
   Episode_Reward/pen_joint_torque: -0.0918
    Episode_Reward/pen_joint_accel: -0.0517
    Episode_Reward/pen_action_rate: -0.0322
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0196
   Episode_Reward/pen_joint_powers: -0.0308
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0664
Episode_Reward/pen_flat_orientation: -0.1605
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1196
   Episode_Reward/foot_landing_vel: -0.0750
   Episode_Reward/test_gait_reward: -0.4227
Metrics/base_velocity/error_vel_xy: 1.3298
Metrics/base_velocity/error_vel_yaw: 0.4337
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 1.08s
                        Total time: 618.62s
                               ETA: 2655.6s

################################################################################
                     [1m Learning iteration 567/3000 [0m                      

                       Computation: 90736 steps/s (collection: 0.962s, learning 0.121s)
               Value function loss: 1.0208
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6862
                     Learning rate: 0.0006
                       Mean reward: 26.74
               Mean episode length: 412.41
       Episode_Reward/keep_balance: 0.3978
     Episode_Reward/rew_lin_vel_xy: 1.1074
      Episode_Reward/rew_ang_vel_z: 1.1535
    Episode_Reward/pen_base_height: -0.2289
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.0614
   Episode_Reward/pen_joint_torque: -0.0772
    Episode_Reward/pen_joint_accel: -0.0443
    Episode_Reward/pen_action_rate: -0.0283
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0173
   Episode_Reward/pen_joint_powers: -0.0267
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0590
Episode_Reward/pen_flat_orientation: -0.1497
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1019
   Episode_Reward/foot_landing_vel: -0.0665
   Episode_Reward/test_gait_reward: -0.3730
Metrics/base_velocity/error_vel_xy: 1.2168
Metrics/base_velocity/error_vel_yaw: 0.3943
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 1.08s
                        Total time: 619.70s
                               ETA: 2654.5s

################################################################################
                     [1m Learning iteration 568/3000 [0m                      

                       Computation: 90249 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 1.0070
                    Surrogate loss: 0.0003
             Mean action noise std: 0.6866
                     Learning rate: 0.0004
                       Mean reward: 29.38
               Mean episode length: 434.52
       Episode_Reward/keep_balance: 0.3987
     Episode_Reward/rew_lin_vel_xy: 1.1014
      Episode_Reward/rew_ang_vel_z: 1.1642
    Episode_Reward/pen_base_height: -0.2211
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.0595
   Episode_Reward/pen_joint_torque: -0.0755
    Episode_Reward/pen_joint_accel: -0.0431
    Episode_Reward/pen_action_rate: -0.0282
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0168
   Episode_Reward/pen_joint_powers: -0.0260
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0590
Episode_Reward/pen_flat_orientation: -0.1499
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.0978
   Episode_Reward/foot_landing_vel: -0.0641
   Episode_Reward/test_gait_reward: -0.3705
Metrics/base_velocity/error_vel_xy: 1.1855
Metrics/base_velocity/error_vel_yaw: 0.3873
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 1.09s
                        Total time: 620.79s
                               ETA: 2653.4s

################################################################################
                     [1m Learning iteration 569/3000 [0m                      

                       Computation: 90081 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 1.0299
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6872
                     Learning rate: 0.0009
                       Mean reward: 32.96
               Mean episode length: 438.20
       Episode_Reward/keep_balance: 0.4143
     Episode_Reward/rew_lin_vel_xy: 1.1842
      Episode_Reward/rew_ang_vel_z: 1.2268
    Episode_Reward/pen_base_height: -0.2238
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.0626
   Episode_Reward/pen_joint_torque: -0.0822
    Episode_Reward/pen_joint_accel: -0.0459
    Episode_Reward/pen_action_rate: -0.0295
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0176
   Episode_Reward/pen_joint_powers: -0.0279
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0617
Episode_Reward/pen_flat_orientation: -0.1490
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1024
   Episode_Reward/foot_landing_vel: -0.0697
   Episode_Reward/test_gait_reward: -0.3853
Metrics/base_velocity/error_vel_xy: 1.2477
Metrics/base_velocity/error_vel_yaw: 0.3922
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 1.09s
                        Total time: 621.88s
                               ETA: 2652.3s

################################################################################
                     [1m Learning iteration 570/3000 [0m                      

                       Computation: 90327 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 1.0616
                    Surrogate loss: 0.0011
             Mean action noise std: 0.6887
                     Learning rate: 0.0003
                       Mean reward: 29.09
               Mean episode length: 425.10
       Episode_Reward/keep_balance: 0.4025
     Episode_Reward/rew_lin_vel_xy: 1.1065
      Episode_Reward/rew_ang_vel_z: 1.1777
    Episode_Reward/pen_base_height: -0.2212
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.0625
   Episode_Reward/pen_joint_torque: -0.0776
    Episode_Reward/pen_joint_accel: -0.0441
    Episode_Reward/pen_action_rate: -0.0290
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0174
   Episode_Reward/pen_joint_powers: -0.0270
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0601
Episode_Reward/pen_flat_orientation: -0.1468
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1037
   Episode_Reward/foot_landing_vel: -0.0669
   Episode_Reward/test_gait_reward: -0.3737
Metrics/base_velocity/error_vel_xy: 1.2233
Metrics/base_velocity/error_vel_yaw: 0.3905
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 1.09s
                        Total time: 622.97s
                               ETA: 2651.2s

################################################################################
                     [1m Learning iteration 571/3000 [0m                      

                       Computation: 90242 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 1.0100
                    Surrogate loss: 0.0086
             Mean action noise std: 0.6888
                     Learning rate: 0.0000
                       Mean reward: 30.24
               Mean episode length: 398.62
       Episode_Reward/keep_balance: 0.4158
     Episode_Reward/rew_lin_vel_xy: 1.1858
      Episode_Reward/rew_ang_vel_z: 1.2177
    Episode_Reward/pen_base_height: -0.2265
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.0621
   Episode_Reward/pen_joint_torque: -0.0817
    Episode_Reward/pen_joint_accel: -0.0444
    Episode_Reward/pen_action_rate: -0.0298
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0176
   Episode_Reward/pen_joint_powers: -0.0279
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0618
Episode_Reward/pen_flat_orientation: -0.1475
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1028
   Episode_Reward/foot_landing_vel: -0.0696
   Episode_Reward/test_gait_reward: -0.3863
Metrics/base_velocity/error_vel_xy: 1.2428
Metrics/base_velocity/error_vel_yaw: 0.4031
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 1.09s
                        Total time: 624.06s
                               ETA: 2650.1s

################################################################################
                     [1m Learning iteration 572/3000 [0m                      

                       Computation: 89664 steps/s (collection: 0.975s, learning 0.121s)
               Value function loss: 1.1151
                    Surrogate loss: 0.0096
             Mean action noise std: 0.6889
                     Learning rate: 0.0000
                       Mean reward: 28.67
               Mean episode length: 403.49
       Episode_Reward/keep_balance: 0.3848
     Episode_Reward/rew_lin_vel_xy: 1.0327
      Episode_Reward/rew_ang_vel_z: 1.1256
    Episode_Reward/pen_base_height: -0.2153
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.0600
   Episode_Reward/pen_joint_torque: -0.0735
    Episode_Reward/pen_joint_accel: -0.0474
    Episode_Reward/pen_action_rate: -0.0277
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0171
   Episode_Reward/pen_joint_powers: -0.0259
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0578
Episode_Reward/pen_flat_orientation: -0.1490
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1021
   Episode_Reward/foot_landing_vel: -0.0640
   Episode_Reward/test_gait_reward: -0.3585
Metrics/base_velocity/error_vel_xy: 1.2349
Metrics/base_velocity/error_vel_yaw: 0.3748
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 1.10s
                        Total time: 625.15s
                               ETA: 2649.0s

################################################################################
                     [1m Learning iteration 573/3000 [0m                      

                       Computation: 90288 steps/s (collection: 0.967s, learning 0.121s)
               Value function loss: 1.0308
                    Surrogate loss: 0.0072
             Mean action noise std: 0.6890
                     Learning rate: 0.0000
                       Mean reward: 30.88
               Mean episode length: 415.67
       Episode_Reward/keep_balance: 0.4056
     Episode_Reward/rew_lin_vel_xy: 1.1608
      Episode_Reward/rew_ang_vel_z: 1.1966
    Episode_Reward/pen_base_height: -0.2201
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.0596
   Episode_Reward/pen_joint_torque: -0.0792
    Episode_Reward/pen_joint_accel: -0.0456
    Episode_Reward/pen_action_rate: -0.0289
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0172
   Episode_Reward/pen_joint_powers: -0.0271
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0599
Episode_Reward/pen_flat_orientation: -0.1444
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0993
   Episode_Reward/foot_landing_vel: -0.0680
   Episode_Reward/test_gait_reward: -0.3750
Metrics/base_velocity/error_vel_xy: 1.2064
Metrics/base_velocity/error_vel_yaw: 0.3867
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 1.09s
                        Total time: 626.24s
                               ETA: 2647.9s

################################################################################
                     [1m Learning iteration 574/3000 [0m                      

                       Computation: 90884 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 1.1558
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6895
                     Learning rate: 0.0001
                       Mean reward: 31.54
               Mean episode length: 409.14
       Episode_Reward/keep_balance: 0.4177
     Episode_Reward/rew_lin_vel_xy: 1.2266
      Episode_Reward/rew_ang_vel_z: 1.2238
    Episode_Reward/pen_base_height: -0.2281
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.0626
   Episode_Reward/pen_joint_torque: -0.0841
    Episode_Reward/pen_joint_accel: -0.0451
    Episode_Reward/pen_action_rate: -0.0300
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0178
   Episode_Reward/pen_joint_powers: -0.0283
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0623
Episode_Reward/pen_flat_orientation: -0.1487
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.1061
   Episode_Reward/foot_landing_vel: -0.0687
   Episode_Reward/test_gait_reward: -0.3884
Metrics/base_velocity/error_vel_xy: 1.2572
Metrics/base_velocity/error_vel_yaw: 0.4039
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 1.08s
                        Total time: 627.33s
                               ETA: 2646.8s

################################################################################
                     [1m Learning iteration 575/3000 [0m                      

                       Computation: 89796 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 1.0284
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6899
                     Learning rate: 0.0006
                       Mean reward: 32.96
               Mean episode length: 439.10
       Episode_Reward/keep_balance: 0.4122
     Episode_Reward/rew_lin_vel_xy: 1.2050
      Episode_Reward/rew_ang_vel_z: 1.2013
    Episode_Reward/pen_base_height: -0.2328
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.0648
   Episode_Reward/pen_joint_torque: -0.0846
    Episode_Reward/pen_joint_accel: -0.0485
    Episode_Reward/pen_action_rate: -0.0299
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0186
   Episode_Reward/pen_joint_powers: -0.0291
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0616
Episode_Reward/pen_flat_orientation: -0.1582
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1125
   Episode_Reward/foot_landing_vel: -0.0712
   Episode_Reward/test_gait_reward: -0.3873
Metrics/base_velocity/error_vel_xy: 1.2062
Metrics/base_velocity/error_vel_yaw: 0.4062
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 1.09s
                        Total time: 628.42s
                               ETA: 2645.7s

################################################################################
                     [1m Learning iteration 576/3000 [0m                      

                       Computation: 90764 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 1.0838
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6906
                     Learning rate: 0.0013
                       Mean reward: 27.59
               Mean episode length: 395.91
       Episode_Reward/keep_balance: 0.4203
     Episode_Reward/rew_lin_vel_xy: 1.1722
      Episode_Reward/rew_ang_vel_z: 1.2240
    Episode_Reward/pen_base_height: -0.2306
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.0650
   Episode_Reward/pen_joint_torque: -0.0853
    Episode_Reward/pen_joint_accel: -0.0463
    Episode_Reward/pen_action_rate: -0.0306
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0192
   Episode_Reward/pen_joint_powers: -0.0296
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0633
Episode_Reward/pen_flat_orientation: -0.1591
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1146
   Episode_Reward/foot_landing_vel: -0.0771
   Episode_Reward/test_gait_reward: -0.3888
Metrics/base_velocity/error_vel_xy: 1.2731
Metrics/base_velocity/error_vel_yaw: 0.4123
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 1.08s
                        Total time: 629.50s
                               ETA: 2644.6s

################################################################################
                     [1m Learning iteration 577/3000 [0m                      

                       Computation: 90156 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 1.2755
                    Surrogate loss: 0.0027
             Mean action noise std: 0.6918
                     Learning rate: 0.0003
                       Mean reward: 31.49
               Mean episode length: 418.82
       Episode_Reward/keep_balance: 0.3895
     Episode_Reward/rew_lin_vel_xy: 1.0915
      Episode_Reward/rew_ang_vel_z: 1.1366
    Episode_Reward/pen_base_height: -0.2143
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.0608
   Episode_Reward/pen_joint_torque: -0.0775
    Episode_Reward/pen_joint_accel: -0.0442
    Episode_Reward/pen_action_rate: -0.0282
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0169
   Episode_Reward/pen_joint_powers: -0.0263
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0587
Episode_Reward/pen_flat_orientation: -0.1389
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1005
   Episode_Reward/foot_landing_vel: -0.0672
   Episode_Reward/test_gait_reward: -0.3606
Metrics/base_velocity/error_vel_xy: 1.1696
Metrics/base_velocity/error_vel_yaw: 0.3811
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 1.09s
                        Total time: 630.59s
                               ETA: 2643.5s

################################################################################
                     [1m Learning iteration 578/3000 [0m                      

                       Computation: 91528 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 1.0745
                    Surrogate loss: 0.0019
             Mean action noise std: 0.6915
                     Learning rate: 0.0002
                       Mean reward: 28.45
               Mean episode length: 405.17
       Episode_Reward/keep_balance: 0.4276
     Episode_Reward/rew_lin_vel_xy: 1.1861
      Episode_Reward/rew_ang_vel_z: 1.2540
    Episode_Reward/pen_base_height: -0.2217
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.0643
   Episode_Reward/pen_joint_torque: -0.0807
    Episode_Reward/pen_joint_accel: -0.0470
    Episode_Reward/pen_action_rate: -0.0310
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0179
   Episode_Reward/pen_joint_powers: -0.0279
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0648
Episode_Reward/pen_flat_orientation: -0.1482
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1064
   Episode_Reward/foot_landing_vel: -0.0688
   Episode_Reward/test_gait_reward: -0.3951
Metrics/base_velocity/error_vel_xy: 1.3165
Metrics/base_velocity/error_vel_yaw: 0.4110
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 1.07s
                        Total time: 631.67s
                               ETA: 2642.3s

################################################################################
                     [1m Learning iteration 579/3000 [0m                      

                       Computation: 89651 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 1.2145
                    Surrogate loss: 0.0015
             Mean action noise std: 0.6909
                     Learning rate: 0.0002
                       Mean reward: 33.54
               Mean episode length: 423.35
       Episode_Reward/keep_balance: 0.4099
     Episode_Reward/rew_lin_vel_xy: 1.1450
      Episode_Reward/rew_ang_vel_z: 1.2100
    Episode_Reward/pen_base_height: -0.2225
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.0606
   Episode_Reward/pen_joint_torque: -0.0806
    Episode_Reward/pen_joint_accel: -0.0435
    Episode_Reward/pen_action_rate: -0.0292
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0168
   Episode_Reward/pen_joint_powers: -0.0269
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0608
Episode_Reward/pen_flat_orientation: -0.1388
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.0995
   Episode_Reward/foot_landing_vel: -0.0649
   Episode_Reward/test_gait_reward: -0.3787
Metrics/base_velocity/error_vel_xy: 1.2363
Metrics/base_velocity/error_vel_yaw: 0.3882
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 1.10s
                        Total time: 632.76s
                               ETA: 2641.2s

################################################################################
                     [1m Learning iteration 580/3000 [0m                      

                       Computation: 90078 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 1.1236
                    Surrogate loss: 0.0029
             Mean action noise std: 0.6908
                     Learning rate: 0.0001
                       Mean reward: 29.25
               Mean episode length: 426.43
       Episode_Reward/keep_balance: 0.4230
     Episode_Reward/rew_lin_vel_xy: 1.1704
      Episode_Reward/rew_ang_vel_z: 1.2232
    Episode_Reward/pen_base_height: -0.2243
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.0654
   Episode_Reward/pen_joint_torque: -0.0842
    Episode_Reward/pen_joint_accel: -0.0482
    Episode_Reward/pen_action_rate: -0.0311
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0187
   Episode_Reward/pen_joint_powers: -0.0291
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0647
Episode_Reward/pen_flat_orientation: -0.1512
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1118
   Episode_Reward/foot_landing_vel: -0.0714
   Episode_Reward/test_gait_reward: -0.3919
Metrics/base_velocity/error_vel_xy: 1.3020
Metrics/base_velocity/error_vel_yaw: 0.4235
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 1.09s
                        Total time: 633.86s
                               ETA: 2640.2s

################################################################################
                     [1m Learning iteration 581/3000 [0m                      

                       Computation: 90479 steps/s (collection: 0.965s, learning 0.121s)
               Value function loss: 1.0785
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6913
                     Learning rate: 0.0002
                       Mean reward: 31.99
               Mean episode length: 443.63
       Episode_Reward/keep_balance: 0.4458
     Episode_Reward/rew_lin_vel_xy: 1.2577
      Episode_Reward/rew_ang_vel_z: 1.2985
    Episode_Reward/pen_base_height: -0.2353
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.0685
   Episode_Reward/pen_joint_torque: -0.0906
    Episode_Reward/pen_joint_accel: -0.0495
    Episode_Reward/pen_action_rate: -0.0329
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0198
   Episode_Reward/pen_joint_powers: -0.0311
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0678
Episode_Reward/pen_flat_orientation: -0.1570
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1197
   Episode_Reward/foot_landing_vel: -0.0789
   Episode_Reward/test_gait_reward: -0.4139
Metrics/base_velocity/error_vel_xy: 1.3560
Metrics/base_velocity/error_vel_yaw: 0.4361
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 1.09s
                        Total time: 634.94s
                               ETA: 2639.0s

################################################################################
                     [1m Learning iteration 582/3000 [0m                      

                       Computation: 89162 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 1.1135
                    Surrogate loss: 0.0027
             Mean action noise std: 0.6915
                     Learning rate: 0.0001
                       Mean reward: 36.91
               Mean episode length: 458.05
       Episode_Reward/keep_balance: 0.4433
     Episode_Reward/rew_lin_vel_xy: 1.3883
      Episode_Reward/rew_ang_vel_z: 1.2942
    Episode_Reward/pen_base_height: -0.2279
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.0654
   Episode_Reward/pen_joint_torque: -0.0884
    Episode_Reward/pen_joint_accel: -0.0511
    Episode_Reward/pen_action_rate: -0.0326
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0193
   Episode_Reward/pen_joint_powers: -0.0304
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0675
Episode_Reward/pen_flat_orientation: -0.1518
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1145
   Episode_Reward/foot_landing_vel: -0.0761
   Episode_Reward/test_gait_reward: -0.4112
Metrics/base_velocity/error_vel_xy: 1.2426
Metrics/base_velocity/error_vel_yaw: 0.4310
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 1.10s
                        Total time: 636.04s
                               ETA: 2638.0s

################################################################################
                     [1m Learning iteration 583/3000 [0m                      

                       Computation: 89340 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 1.0737
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6915
                     Learning rate: 0.0002
                       Mean reward: 30.68
               Mean episode length: 429.92
       Episode_Reward/keep_balance: 0.4327
     Episode_Reward/rew_lin_vel_xy: 1.3296
      Episode_Reward/rew_ang_vel_z: 1.2521
    Episode_Reward/pen_base_height: -0.2258
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.0654
   Episode_Reward/pen_joint_torque: -0.0847
    Episode_Reward/pen_joint_accel: -0.0497
    Episode_Reward/pen_action_rate: -0.0319
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0189
   Episode_Reward/pen_joint_powers: -0.0293
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0664
Episode_Reward/pen_flat_orientation: -0.1490
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1149
   Episode_Reward/foot_landing_vel: -0.0742
   Episode_Reward/test_gait_reward: -0.4014
Metrics/base_velocity/error_vel_xy: 1.2445
Metrics/base_velocity/error_vel_yaw: 0.4310
      Episode_Termination/time_out: 2.2917
  Episode_Termination/base_contact: 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 1.10s
                        Total time: 637.14s
                               ETA: 2636.9s

################################################################################
                     [1m Learning iteration 584/3000 [0m                      

                       Computation: 89933 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 1.2511
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6910
                     Learning rate: 0.0006
                       Mean reward: 28.41
               Mean episode length: 390.14
       Episode_Reward/keep_balance: 0.4190
     Episode_Reward/rew_lin_vel_xy: 1.1730
      Episode_Reward/rew_ang_vel_z: 1.2303
    Episode_Reward/pen_base_height: -0.2205
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.0637
   Episode_Reward/pen_joint_torque: -0.0831
    Episode_Reward/pen_joint_accel: -0.0464
    Episode_Reward/pen_action_rate: -0.0306
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0179
   Episode_Reward/pen_joint_powers: -0.0284
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0634
Episode_Reward/pen_flat_orientation: -0.1426
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.1087
   Episode_Reward/foot_landing_vel: -0.0677
   Episode_Reward/test_gait_reward: -0.3878
Metrics/base_velocity/error_vel_xy: 1.2595
Metrics/base_velocity/error_vel_yaw: 0.4049
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 1.09s
                        Total time: 638.24s
                               ETA: 2635.9s

################################################################################
                     [1m Learning iteration 585/3000 [0m                      

                       Computation: 87709 steps/s (collection: 0.997s, learning 0.123s)
               Value function loss: 1.4979
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6910
                     Learning rate: 0.0013
                       Mean reward: 29.09
               Mean episode length: 383.01
       Episode_Reward/keep_balance: 0.3940
     Episode_Reward/rew_lin_vel_xy: 1.1588
      Episode_Reward/rew_ang_vel_z: 1.1499
    Episode_Reward/pen_base_height: -0.2120
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.0601
   Episode_Reward/pen_joint_torque: -0.0783
    Episode_Reward/pen_joint_accel: -0.0460
    Episode_Reward/pen_action_rate: -0.0288
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0171
   Episode_Reward/pen_joint_powers: -0.0268
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0600
Episode_Reward/pen_flat_orientation: -0.1390
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.1028
   Episode_Reward/foot_landing_vel: -0.0635
   Episode_Reward/test_gait_reward: -0.3651
Metrics/base_velocity/error_vel_xy: 1.1756
Metrics/base_velocity/error_vel_yaw: 0.3834
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 1.12s
                        Total time: 639.36s
                               ETA: 2634.9s

################################################################################
                     [1m Learning iteration 586/3000 [0m                      

                       Computation: 88114 steps/s (collection: 0.993s, learning 0.122s)
               Value function loss: 1.3597
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6924
                     Learning rate: 0.0019
                       Mean reward: 25.23
               Mean episode length: 345.05
       Episode_Reward/keep_balance: 0.3844
     Episode_Reward/rew_lin_vel_xy: 1.0850
      Episode_Reward/rew_ang_vel_z: 1.1245
    Episode_Reward/pen_base_height: -0.2138
      Episode_Reward/pen_lin_vel_z: -0.0350
     Episode_Reward/pen_ang_vel_xy: -0.0597
   Episode_Reward/pen_joint_torque: -0.0758
    Episode_Reward/pen_joint_accel: -0.0435
    Episode_Reward/pen_action_rate: -0.0282
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0170
   Episode_Reward/pen_joint_powers: -0.0264
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0587
Episode_Reward/pen_flat_orientation: -0.1323
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.1004
   Episode_Reward/foot_landing_vel: -0.0660
   Episode_Reward/test_gait_reward: -0.3559
Metrics/base_velocity/error_vel_xy: 1.1567
Metrics/base_velocity/error_vel_yaw: 0.3738
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 1.12s
                        Total time: 640.47s
                               ETA: 2633.9s

################################################################################
                     [1m Learning iteration 587/3000 [0m                      

                       Computation: 90023 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 1.1176
                    Surrogate loss: 0.0043
             Mean action noise std: 0.6929
                     Learning rate: 0.0003
                       Mean reward: 27.97
               Mean episode length: 420.95
       Episode_Reward/keep_balance: 0.4280
     Episode_Reward/rew_lin_vel_xy: 1.1812
      Episode_Reward/rew_ang_vel_z: 1.2300
    Episode_Reward/pen_base_height: -0.2314
      Episode_Reward/pen_lin_vel_z: -0.0406
     Episode_Reward/pen_ang_vel_xy: -0.0658
   Episode_Reward/pen_joint_torque: -0.0868
    Episode_Reward/pen_joint_accel: -0.0499
    Episode_Reward/pen_action_rate: -0.0319
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0191
   Episode_Reward/pen_joint_powers: -0.0298
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0664
Episode_Reward/pen_flat_orientation: -0.1557
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1175
   Episode_Reward/foot_landing_vel: -0.0771
   Episode_Reward/test_gait_reward: -0.3992
Metrics/base_velocity/error_vel_xy: 1.2996
Metrics/base_velocity/error_vel_yaw: 0.4302
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 1.09s
                        Total time: 641.57s
                               ETA: 2632.8s

################################################################################
                     [1m Learning iteration 588/3000 [0m                      

                       Computation: 89356 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.9356
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6936
                     Learning rate: 0.0004
                       Mean reward: 32.26
               Mean episode length: 429.09
       Episode_Reward/keep_balance: 0.4337
     Episode_Reward/rew_lin_vel_xy: 1.2177
      Episode_Reward/rew_ang_vel_z: 1.2739
    Episode_Reward/pen_base_height: -0.2302
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.0662
   Episode_Reward/pen_joint_torque: -0.0885
    Episode_Reward/pen_joint_accel: -0.0502
    Episode_Reward/pen_action_rate: -0.0319
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0190
   Episode_Reward/pen_joint_powers: -0.0301
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0660
Episode_Reward/pen_flat_orientation: -0.1496
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1146
   Episode_Reward/foot_landing_vel: -0.0739
   Episode_Reward/test_gait_reward: -0.4021
Metrics/base_velocity/error_vel_xy: 1.2885
Metrics/base_velocity/error_vel_yaw: 0.4161
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 1.10s
                        Total time: 642.67s
                               ETA: 2631.8s

################################################################################
                     [1m Learning iteration 589/3000 [0m                      

                       Computation: 89102 steps/s (collection: 0.980s, learning 0.124s)
               Value function loss: 1.1219
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6955
                     Learning rate: 0.0006
                       Mean reward: 29.85
               Mean episode length: 420.69
       Episode_Reward/keep_balance: 0.4556
     Episode_Reward/rew_lin_vel_xy: 1.3301
      Episode_Reward/rew_ang_vel_z: 1.3257
    Episode_Reward/pen_base_height: -0.2393
      Episode_Reward/pen_lin_vel_z: -0.0422
     Episode_Reward/pen_ang_vel_xy: -0.0691
   Episode_Reward/pen_joint_torque: -0.0939
    Episode_Reward/pen_joint_accel: -0.0534
    Episode_Reward/pen_action_rate: -0.0337
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0205
   Episode_Reward/pen_joint_powers: -0.0323
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0693
Episode_Reward/pen_flat_orientation: -0.1499
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1257
   Episode_Reward/foot_landing_vel: -0.0770
   Episode_Reward/test_gait_reward: -0.4246
Metrics/base_velocity/error_vel_xy: 1.3761
Metrics/base_velocity/error_vel_yaw: 0.4472
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 1.10s
                        Total time: 643.77s
                               ETA: 2630.7s

################################################################################
                     [1m Learning iteration 590/3000 [0m                      

                       Computation: 89677 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 1.4791
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6974
                     Learning rate: 0.0013
                       Mean reward: 40.66
               Mean episode length: 528.37
       Episode_Reward/keep_balance: 0.4761
     Episode_Reward/rew_lin_vel_xy: 1.3344
      Episode_Reward/rew_ang_vel_z: 1.4004
    Episode_Reward/pen_base_height: -0.2354
      Episode_Reward/pen_lin_vel_z: -0.0443
     Episode_Reward/pen_ang_vel_xy: -0.0699
   Episode_Reward/pen_joint_torque: -0.0972
    Episode_Reward/pen_joint_accel: -0.0521
    Episode_Reward/pen_action_rate: -0.0352
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0206
   Episode_Reward/pen_joint_powers: -0.0329
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0725
Episode_Reward/pen_flat_orientation: -0.1579
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1236
   Episode_Reward/foot_landing_vel: -0.0795
   Episode_Reward/test_gait_reward: -0.4415
Metrics/base_velocity/error_vel_xy: 1.4327
Metrics/base_velocity/error_vel_yaw: 0.4562
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 1.10s
                        Total time: 644.87s
                               ETA: 2629.7s

################################################################################
                     [1m Learning iteration 591/3000 [0m                      

                       Computation: 89907 steps/s (collection: 0.972s, learning 0.121s)
               Value function loss: 1.1585
                    Surrogate loss: 0.0004
             Mean action noise std: 0.6991
                     Learning rate: 0.0003
                       Mean reward: 33.05
               Mean episode length: 459.66
       Episode_Reward/keep_balance: 0.4041
     Episode_Reward/rew_lin_vel_xy: 1.1821
      Episode_Reward/rew_ang_vel_z: 1.1626
    Episode_Reward/pen_base_height: -0.2227
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.0632
   Episode_Reward/pen_joint_torque: -0.0803
    Episode_Reward/pen_joint_accel: -0.0464
    Episode_Reward/pen_action_rate: -0.0300
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0180
   Episode_Reward/pen_joint_powers: -0.0279
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0628
Episode_Reward/pen_flat_orientation: -0.1423
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1101
   Episode_Reward/foot_landing_vel: -0.0685
   Episode_Reward/test_gait_reward: -0.3748
Metrics/base_velocity/error_vel_xy: 1.1733
Metrics/base_velocity/error_vel_yaw: 0.4074
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 1.09s
                        Total time: 645.96s
                               ETA: 2628.6s

################################################################################
                     [1m Learning iteration 592/3000 [0m                      

                       Computation: 89839 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.9472
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6999
                     Learning rate: 0.0004
                       Mean reward: 26.17
               Mean episode length: 359.97
       Episode_Reward/keep_balance: 0.4028
     Episode_Reward/rew_lin_vel_xy: 1.1373
      Episode_Reward/rew_ang_vel_z: 1.1713
    Episode_Reward/pen_base_height: -0.2200
      Episode_Reward/pen_lin_vel_z: -0.0353
     Episode_Reward/pen_ang_vel_xy: -0.0617
   Episode_Reward/pen_joint_torque: -0.0801
    Episode_Reward/pen_joint_accel: -0.0425
    Episode_Reward/pen_action_rate: -0.0295
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0169
   Episode_Reward/pen_joint_powers: -0.0269
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0619
Episode_Reward/pen_flat_orientation: -0.1391
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.0996
   Episode_Reward/foot_landing_vel: -0.0651
   Episode_Reward/test_gait_reward: -0.3715
Metrics/base_velocity/error_vel_xy: 1.2239
Metrics/base_velocity/error_vel_yaw: 0.3946
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 1.09s
                        Total time: 647.05s
                               ETA: 2627.5s

################################################################################
                     [1m Learning iteration 593/3000 [0m                      

                       Computation: 89766 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 1.0358
                    Surrogate loss: -0.0001
             Mean action noise std: 0.7006
                     Learning rate: 0.0004
                       Mean reward: 33.21
               Mean episode length: 452.10
       Episode_Reward/keep_balance: 0.4311
     Episode_Reward/rew_lin_vel_xy: 1.2719
      Episode_Reward/rew_ang_vel_z: 1.2595
    Episode_Reward/pen_base_height: -0.2301
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.0650
   Episode_Reward/pen_joint_torque: -0.0892
    Episode_Reward/pen_joint_accel: -0.0477
    Episode_Reward/pen_action_rate: -0.0320
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0189
   Episode_Reward/pen_joint_powers: -0.0299
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0660
Episode_Reward/pen_flat_orientation: -0.1459
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.1163
   Episode_Reward/foot_landing_vel: -0.0735
   Episode_Reward/test_gait_reward: -0.4003
Metrics/base_velocity/error_vel_xy: 1.2934
Metrics/base_velocity/error_vel_yaw: 0.4199
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 1.10s
                        Total time: 648.15s
                               ETA: 2626.4s

################################################################################
                     [1m Learning iteration 594/3000 [0m                      

                       Computation: 90440 steps/s (collection: 0.966s, learning 0.121s)
               Value function loss: 1.0153
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7011
                     Learning rate: 0.0006
                       Mean reward: 30.40
               Mean episode length: 426.43
       Episode_Reward/keep_balance: 0.4643
     Episode_Reward/rew_lin_vel_xy: 1.3070
      Episode_Reward/rew_ang_vel_z: 1.3708
    Episode_Reward/pen_base_height: -0.2354
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.0688
   Episode_Reward/pen_joint_torque: -0.0979
    Episode_Reward/pen_joint_accel: -0.0548
    Episode_Reward/pen_action_rate: -0.0348
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0205
   Episode_Reward/pen_joint_powers: -0.0326
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0708
Episode_Reward/pen_flat_orientation: -0.1559
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1254
   Episode_Reward/foot_landing_vel: -0.0792
   Episode_Reward/test_gait_reward: -0.4291
Metrics/base_velocity/error_vel_xy: 1.3948
Metrics/base_velocity/error_vel_yaw: 0.4397
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 1.09s
                        Total time: 649.24s
                               ETA: 2625.3s

################################################################################
                     [1m Learning iteration 595/3000 [0m                      

                       Computation: 90080 steps/s (collection: 0.970s, learning 0.121s)
               Value function loss: 0.9873
                    Surrogate loss: 0.0013
             Mean action noise std: 0.7014
                     Learning rate: 0.0003
                       Mean reward: 32.16
               Mean episode length: 417.57
       Episode_Reward/keep_balance: 0.4372
     Episode_Reward/rew_lin_vel_xy: 1.3124
      Episode_Reward/rew_ang_vel_z: 1.2729
    Episode_Reward/pen_base_height: -0.2320
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.0685
   Episode_Reward/pen_joint_torque: -0.0897
    Episode_Reward/pen_joint_accel: -0.0493
    Episode_Reward/pen_action_rate: -0.0324
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0194
   Episode_Reward/pen_joint_powers: -0.0305
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0674
Episode_Reward/pen_flat_orientation: -0.1452
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.1177
   Episode_Reward/foot_landing_vel: -0.0718
   Episode_Reward/test_gait_reward: -0.4061
Metrics/base_velocity/error_vel_xy: 1.2705
Metrics/base_velocity/error_vel_yaw: 0.4288
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 1.09s
                        Total time: 650.33s
                               ETA: 2624.2s

################################################################################
                     [1m Learning iteration 596/3000 [0m                      

                       Computation: 90164 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.9327
                    Surrogate loss: 0.0036
             Mean action noise std: 0.7021
                     Learning rate: 0.0001
                       Mean reward: 30.01
               Mean episode length: 408.73
       Episode_Reward/keep_balance: 0.3976
     Episode_Reward/rew_lin_vel_xy: 1.2065
      Episode_Reward/rew_ang_vel_z: 1.1381
    Episode_Reward/pen_base_height: -0.2196
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.0627
   Episode_Reward/pen_joint_torque: -0.0818
    Episode_Reward/pen_joint_accel: -0.0449
    Episode_Reward/pen_action_rate: -0.0297
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0179
   Episode_Reward/pen_joint_powers: -0.0280
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0615
Episode_Reward/pen_flat_orientation: -0.1389
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1141
   Episode_Reward/foot_landing_vel: -0.0686
   Episode_Reward/test_gait_reward: -0.3723
Metrics/base_velocity/error_vel_xy: 1.1017
Metrics/base_velocity/error_vel_yaw: 0.4040
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 1.09s
                        Total time: 651.42s
                               ETA: 2623.1s

################################################################################
                     [1m Learning iteration 597/3000 [0m                      

                       Computation: 90757 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.9598
                    Surrogate loss: -0.0025
             Mean action noise std: 0.7016
                     Learning rate: 0.0003
                       Mean reward: 35.20
               Mean episode length: 467.61
       Episode_Reward/keep_balance: 0.4514
     Episode_Reward/rew_lin_vel_xy: 1.3273
      Episode_Reward/rew_ang_vel_z: 1.3141
    Episode_Reward/pen_base_height: -0.2309
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.0663
   Episode_Reward/pen_joint_torque: -0.0917
    Episode_Reward/pen_joint_accel: -0.0505
    Episode_Reward/pen_action_rate: -0.0338
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0193
   Episode_Reward/pen_joint_powers: -0.0307
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0699
Episode_Reward/pen_flat_orientation: -0.1482
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1182
   Episode_Reward/foot_landing_vel: -0.0726
   Episode_Reward/test_gait_reward: -0.4167
Metrics/base_velocity/error_vel_xy: 1.3594
Metrics/base_velocity/error_vel_yaw: 0.4428
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 1.08s
                        Total time: 652.50s
                               ETA: 2622.0s

################################################################################
                     [1m Learning iteration 598/3000 [0m                      

                       Computation: 90131 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.9700
                    Surrogate loss: -0.0032
             Mean action noise std: 0.7014
                     Learning rate: 0.0006
                       Mean reward: 32.70
               Mean episode length: 431.70
       Episode_Reward/keep_balance: 0.4239
     Episode_Reward/rew_lin_vel_xy: 1.2771
      Episode_Reward/rew_ang_vel_z: 1.2319
    Episode_Reward/pen_base_height: -0.2223
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.0632
   Episode_Reward/pen_joint_torque: -0.0846
    Episode_Reward/pen_joint_accel: -0.0474
    Episode_Reward/pen_action_rate: -0.0319
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0188
   Episode_Reward/pen_joint_powers: -0.0290
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0659
Episode_Reward/pen_flat_orientation: -0.1431
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1169
   Episode_Reward/foot_landing_vel: -0.0726
   Episode_Reward/test_gait_reward: -0.3941
Metrics/base_velocity/error_vel_xy: 1.2324
Metrics/base_velocity/error_vel_yaw: 0.4148
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 1.09s
                        Total time: 653.59s
                               ETA: 2620.9s

################################################################################
                     [1m Learning iteration 599/3000 [0m                      

                       Computation: 88700 steps/s (collection: 0.983s, learning 0.125s)
               Value function loss: 1.0411
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7031
                     Learning rate: 0.0004
                       Mean reward: 41.56
               Mean episode length: 558.93
       Episode_Reward/keep_balance: 0.5650
     Episode_Reward/rew_lin_vel_xy: 1.7415
      Episode_Reward/rew_ang_vel_z: 1.6504
    Episode_Reward/pen_base_height: -0.2618
      Episode_Reward/pen_lin_vel_z: -0.0518
     Episode_Reward/pen_ang_vel_xy: -0.0830
   Episode_Reward/pen_joint_torque: -0.1190
    Episode_Reward/pen_joint_accel: -0.0636
    Episode_Reward/pen_action_rate: -0.0431
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0253
   Episode_Reward/pen_joint_powers: -0.0403
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0879
Episode_Reward/pen_flat_orientation: -0.1711
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1539
   Episode_Reward/foot_landing_vel: -0.0975
   Episode_Reward/test_gait_reward: -0.5241
Metrics/base_velocity/error_vel_xy: 1.6231
Metrics/base_velocity/error_vel_yaw: 0.5498
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 1.11s
                        Total time: 654.70s
                               ETA: 2619.9s

################################################################################
                     [1m Learning iteration 600/3000 [0m                      

                       Computation: 87514 steps/s (collection: 0.996s, learning 0.127s)
               Value function loss: 0.9695
                    Surrogate loss: -0.0002
             Mean action noise std: 0.7040
                     Learning rate: 0.0006
                       Mean reward: 35.99
               Mean episode length: 459.89
       Episode_Reward/keep_balance: 0.4712
     Episode_Reward/rew_lin_vel_xy: 1.3550
      Episode_Reward/rew_ang_vel_z: 1.3898
    Episode_Reward/pen_base_height: -0.2381
      Episode_Reward/pen_lin_vel_z: -0.0430
     Episode_Reward/pen_ang_vel_xy: -0.0709
   Episode_Reward/pen_joint_torque: -0.0981
    Episode_Reward/pen_joint_accel: -0.0516
    Episode_Reward/pen_action_rate: -0.0353
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0208
   Episode_Reward/pen_joint_powers: -0.0330
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0723
Episode_Reward/pen_flat_orientation: -0.1529
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.1237
   Episode_Reward/foot_landing_vel: -0.0821
   Episode_Reward/test_gait_reward: -0.4360
Metrics/base_velocity/error_vel_xy: 1.4325
Metrics/base_velocity/error_vel_yaw: 0.4481
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 1.12s
                        Total time: 655.82s
                               ETA: 2618.9s

################################################################################
                     [1m Learning iteration 601/3000 [0m                      

                       Computation: 88473 steps/s (collection: 0.987s, learning 0.124s)
               Value function loss: 0.8895
                    Surrogate loss: -0.0004
             Mean action noise std: 0.7049
                     Learning rate: 0.0004
                       Mean reward: 36.63
               Mean episode length: 504.04
       Episode_Reward/keep_balance: 0.4827
     Episode_Reward/rew_lin_vel_xy: 1.3985
      Episode_Reward/rew_ang_vel_z: 1.3968
    Episode_Reward/pen_base_height: -0.2374
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.0724
   Episode_Reward/pen_joint_torque: -0.1021
    Episode_Reward/pen_joint_accel: -0.0538
    Episode_Reward/pen_action_rate: -0.0369
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0218
   Episode_Reward/pen_joint_powers: -0.0344
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0759
Episode_Reward/pen_flat_orientation: -0.1602
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.1356
   Episode_Reward/foot_landing_vel: -0.0846
   Episode_Reward/test_gait_reward: -0.4475
Metrics/base_velocity/error_vel_xy: 1.3894
Metrics/base_velocity/error_vel_yaw: 0.4765
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 1.11s
                        Total time: 656.93s
                               ETA: 2617.9s

################################################################################
                     [1m Learning iteration 602/3000 [0m                      

                       Computation: 88735 steps/s (collection: 0.983s, learning 0.125s)
               Value function loss: 0.9720
                    Surrogate loss: -0.0032
             Mean action noise std: 0.7054
                     Learning rate: 0.0006
                       Mean reward: 37.21
               Mean episode length: 474.97
       Episode_Reward/keep_balance: 0.5000
     Episode_Reward/rew_lin_vel_xy: 1.4420
      Episode_Reward/rew_ang_vel_z: 1.4495
    Episode_Reward/pen_base_height: -0.2469
      Episode_Reward/pen_lin_vel_z: -0.0440
     Episode_Reward/pen_ang_vel_xy: -0.0753
   Episode_Reward/pen_joint_torque: -0.1028
    Episode_Reward/pen_joint_accel: -0.0557
    Episode_Reward/pen_action_rate: -0.0383
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0227
   Episode_Reward/pen_joint_powers: -0.0354
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0790
Episode_Reward/pen_flat_orientation: -0.1560
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.1386
   Episode_Reward/foot_landing_vel: -0.0875
   Episode_Reward/test_gait_reward: -0.4616
Metrics/base_velocity/error_vel_xy: 1.5038
Metrics/base_velocity/error_vel_yaw: 0.4942
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 1.11s
                        Total time: 658.04s
                               ETA: 2616.9s

################################################################################
                     [1m Learning iteration 603/3000 [0m                      

                       Computation: 89338 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 1.0699
                    Surrogate loss: -0.0005
             Mean action noise std: 0.7060
                     Learning rate: 0.0006
                       Mean reward: 36.58
               Mean episode length: 496.16
       Episode_Reward/keep_balance: 0.4988
     Episode_Reward/rew_lin_vel_xy: 1.4344
      Episode_Reward/rew_ang_vel_z: 1.4516
    Episode_Reward/pen_base_height: -0.2508
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.0755
   Episode_Reward/pen_joint_torque: -0.1022
    Episode_Reward/pen_joint_accel: -0.0576
    Episode_Reward/pen_action_rate: -0.0380
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0220
   Episode_Reward/pen_joint_powers: -0.0346
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0787
Episode_Reward/pen_flat_orientation: -0.1627
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1319
   Episode_Reward/foot_landing_vel: -0.0829
   Episode_Reward/test_gait_reward: -0.4599
Metrics/base_velocity/error_vel_xy: 1.5199
Metrics/base_velocity/error_vel_yaw: 0.4891
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 1.10s
                        Total time: 659.14s
                               ETA: 2615.8s

################################################################################
                     [1m Learning iteration 604/3000 [0m                      

                       Computation: 89727 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 1.0500
                    Surrogate loss: -0.0017
             Mean action noise std: 0.7077
                     Learning rate: 0.0009
                       Mean reward: 36.28
               Mean episode length: 463.80
       Episode_Reward/keep_balance: 0.4729
     Episode_Reward/rew_lin_vel_xy: 1.4880
      Episode_Reward/rew_ang_vel_z: 1.3681
    Episode_Reward/pen_base_height: -0.2413
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.0715
   Episode_Reward/pen_joint_torque: -0.0965
    Episode_Reward/pen_joint_accel: -0.0531
    Episode_Reward/pen_action_rate: -0.0359
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0210
   Episode_Reward/pen_joint_powers: -0.0331
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0739
Episode_Reward/pen_flat_orientation: -0.1563
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1371
   Episode_Reward/foot_landing_vel: -0.0786
   Episode_Reward/test_gait_reward: -0.4384
Metrics/base_velocity/error_vel_xy: 1.2980
Metrics/base_velocity/error_vel_yaw: 0.4700
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 1.10s
                        Total time: 660.24s
                               ETA: 2614.8s

################################################################################
                     [1m Learning iteration 605/3000 [0m                      

                       Computation: 89318 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 1.0880
                    Surrogate loss: 0.0034
             Mean action noise std: 0.7084
                     Learning rate: 0.0003
                       Mean reward: 40.66
               Mean episode length: 528.27
       Episode_Reward/keep_balance: 0.4805
     Episode_Reward/rew_lin_vel_xy: 1.4909
      Episode_Reward/rew_ang_vel_z: 1.4061
    Episode_Reward/pen_base_height: -0.2367
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.0704
   Episode_Reward/pen_joint_torque: -0.1016
    Episode_Reward/pen_joint_accel: -0.0558
    Episode_Reward/pen_action_rate: -0.0366
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0212
   Episode_Reward/pen_joint_powers: -0.0336
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0759
Episode_Reward/pen_flat_orientation: -0.1484
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1322
   Episode_Reward/foot_landing_vel: -0.0803
   Episode_Reward/test_gait_reward: -0.4457
Metrics/base_velocity/error_vel_xy: 1.3343
Metrics/base_velocity/error_vel_yaw: 0.4644
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 1.10s
                        Total time: 661.34s
                               ETA: 2613.7s

################################################################################
                     [1m Learning iteration 606/3000 [0m                      

                       Computation: 89519 steps/s (collection: 0.973s, learning 0.125s)
               Value function loss: 1.2404
                    Surrogate loss: -0.0013
             Mean action noise std: 0.7097
                     Learning rate: 0.0006
                       Mean reward: 49.06
               Mean episode length: 607.92
       Episode_Reward/keep_balance: 0.5563
     Episode_Reward/rew_lin_vel_xy: 1.7639
      Episode_Reward/rew_ang_vel_z: 1.5961
    Episode_Reward/pen_base_height: -0.2739
      Episode_Reward/pen_lin_vel_z: -0.0508
     Episode_Reward/pen_ang_vel_xy: -0.0814
   Episode_Reward/pen_joint_torque: -0.1165
    Episode_Reward/pen_joint_accel: -0.0627
    Episode_Reward/pen_action_rate: -0.0430
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0255
   Episode_Reward/pen_joint_powers: -0.0396
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0886
Episode_Reward/pen_flat_orientation: -0.1728
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.1649
   Episode_Reward/foot_landing_vel: -0.0945
   Episode_Reward/test_gait_reward: -0.5178
Metrics/base_velocity/error_vel_xy: 1.5527
Metrics/base_velocity/error_vel_yaw: 0.5668
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 1.10s
                        Total time: 662.44s
                               ETA: 2612.6s

################################################################################
                     [1m Learning iteration 607/3000 [0m                      

                       Computation: 89543 steps/s (collection: 0.970s, learning 0.128s)
               Value function loss: 1.1100
                    Surrogate loss: -0.0015
             Mean action noise std: 0.7100
                     Learning rate: 0.0009
                       Mean reward: 34.74
               Mean episode length: 483.54
       Episode_Reward/keep_balance: 0.5336
     Episode_Reward/rew_lin_vel_xy: 1.4759
      Episode_Reward/rew_ang_vel_z: 1.5591
    Episode_Reward/pen_base_height: -0.2557
      Episode_Reward/pen_lin_vel_z: -0.0484
     Episode_Reward/pen_ang_vel_xy: -0.0791
   Episode_Reward/pen_joint_torque: -0.1170
    Episode_Reward/pen_joint_accel: -0.0597
    Episode_Reward/pen_action_rate: -0.0411
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0239
   Episode_Reward/pen_joint_powers: -0.0386
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0842
Episode_Reward/pen_flat_orientation: -0.1628
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1511
   Episode_Reward/foot_landing_vel: -0.0931
   Episode_Reward/test_gait_reward: -0.4950
Metrics/base_velocity/error_vel_xy: 1.6746
Metrics/base_velocity/error_vel_yaw: 0.5187
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 1.10s
                        Total time: 663.53s
                               ETA: 2611.6s

################################################################################
                     [1m Learning iteration 608/3000 [0m                      

                       Computation: 88552 steps/s (collection: 0.985s, learning 0.125s)
               Value function loss: 1.1285
                    Surrogate loss: 0.0008
             Mean action noise std: 0.7097
                     Learning rate: 0.0003
                       Mean reward: 35.55
               Mean episode length: 471.11
       Episode_Reward/keep_balance: 0.4547
     Episode_Reward/rew_lin_vel_xy: 1.3286
      Episode_Reward/rew_ang_vel_z: 1.3110
    Episode_Reward/pen_base_height: -0.2361
      Episode_Reward/pen_lin_vel_z: -0.0425
     Episode_Reward/pen_ang_vel_xy: -0.0710
   Episode_Reward/pen_joint_torque: -0.0950
    Episode_Reward/pen_joint_accel: -0.0554
    Episode_Reward/pen_action_rate: -0.0353
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0208
   Episode_Reward/pen_joint_powers: -0.0325
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0734
Episode_Reward/pen_flat_orientation: -0.1478
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1279
   Episode_Reward/foot_landing_vel: -0.0768
   Episode_Reward/test_gait_reward: -0.4227
Metrics/base_velocity/error_vel_xy: 1.3651
Metrics/base_velocity/error_vel_yaw: 0.4532
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 1.11s
                        Total time: 664.64s
                               ETA: 2610.6s

################################################################################
                     [1m Learning iteration 609/3000 [0m                      

                       Computation: 89260 steps/s (collection: 0.975s, learning 0.126s)
               Value function loss: 1.0786
                    Surrogate loss: -0.0019
             Mean action noise std: 0.7107
                     Learning rate: 0.0006
                       Mean reward: 39.12
               Mean episode length: 502.78
       Episode_Reward/keep_balance: 0.4740
     Episode_Reward/rew_lin_vel_xy: 1.3262
      Episode_Reward/rew_ang_vel_z: 1.3560
    Episode_Reward/pen_base_height: -0.2399
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.0705
   Episode_Reward/pen_joint_torque: -0.0940
    Episode_Reward/pen_joint_accel: -0.0527
    Episode_Reward/pen_action_rate: -0.0362
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0201
   Episode_Reward/pen_joint_powers: -0.0317
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0767
Episode_Reward/pen_flat_orientation: -0.1376
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1184
   Episode_Reward/foot_landing_vel: -0.0780
   Episode_Reward/test_gait_reward: -0.4347
Metrics/base_velocity/error_vel_xy: 1.5178
Metrics/base_velocity/error_vel_yaw: 0.4837
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 1.10s
                        Total time: 665.74s
                               ETA: 2609.5s

################################################################################
                     [1m Learning iteration 610/3000 [0m                      

                       Computation: 90085 steps/s (collection: 0.966s, learning 0.125s)
               Value function loss: 1.0344
                    Surrogate loss: -0.0022
             Mean action noise std: 0.7119
                     Learning rate: 0.0009
                       Mean reward: 41.60
               Mean episode length: 564.01
       Episode_Reward/keep_balance: 0.5354
     Episode_Reward/rew_lin_vel_xy: 1.5607
      Episode_Reward/rew_ang_vel_z: 1.5529
    Episode_Reward/pen_base_height: -0.2590
      Episode_Reward/pen_lin_vel_z: -0.0492
     Episode_Reward/pen_ang_vel_xy: -0.0789
   Episode_Reward/pen_joint_torque: -0.1144
    Episode_Reward/pen_joint_accel: -0.0631
    Episode_Reward/pen_action_rate: -0.0414
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0242
   Episode_Reward/pen_joint_powers: -0.0382
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0854
Episode_Reward/pen_flat_orientation: -0.1548
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.1468
   Episode_Reward/foot_landing_vel: -0.0937
   Episode_Reward/test_gait_reward: -0.4951
Metrics/base_velocity/error_vel_xy: 1.5601
Metrics/base_velocity/error_vel_yaw: 0.5277
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 1.09s
                        Total time: 666.84s
                               ETA: 2608.4s

################################################################################
                     [1m Learning iteration 611/3000 [0m                      

                       Computation: 90315 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 1.0814
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7126
                     Learning rate: 0.0004
                       Mean reward: 41.89
               Mean episode length: 551.09
       Episode_Reward/keep_balance: 0.5283
     Episode_Reward/rew_lin_vel_xy: 1.5911
      Episode_Reward/rew_ang_vel_z: 1.5404
    Episode_Reward/pen_base_height: -0.2592
      Episode_Reward/pen_lin_vel_z: -0.0474
     Episode_Reward/pen_ang_vel_xy: -0.0786
   Episode_Reward/pen_joint_torque: -0.1079
    Episode_Reward/pen_joint_accel: -0.0666
    Episode_Reward/pen_action_rate: -0.0409
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0238
   Episode_Reward/pen_joint_powers: -0.0369
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0845
Episode_Reward/pen_flat_orientation: -0.1574
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.1455
   Episode_Reward/foot_landing_vel: -0.0929
   Episode_Reward/test_gait_reward: -0.4854
Metrics/base_velocity/error_vel_xy: 1.5846
Metrics/base_velocity/error_vel_yaw: 0.5181
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 1.09s
                        Total time: 667.92s
                               ETA: 2607.3s

################################################################################
                     [1m Learning iteration 612/3000 [0m                      

                       Computation: 89829 steps/s (collection: 0.969s, learning 0.126s)
               Value function loss: 1.1284
                    Surrogate loss: -0.0012
             Mean action noise std: 0.7132
                     Learning rate: 0.0006
                       Mean reward: 42.21
               Mean episode length: 553.81
       Episode_Reward/keep_balance: 0.5060
     Episode_Reward/rew_lin_vel_xy: 1.5692
      Episode_Reward/rew_ang_vel_z: 1.4555
    Episode_Reward/pen_base_height: -0.2466
      Episode_Reward/pen_lin_vel_z: -0.0479
     Episode_Reward/pen_ang_vel_xy: -0.0766
   Episode_Reward/pen_joint_torque: -0.1076
    Episode_Reward/pen_joint_accel: -0.0652
    Episode_Reward/pen_action_rate: -0.0397
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0238
   Episode_Reward/pen_joint_powers: -0.0370
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0819
Episode_Reward/pen_flat_orientation: -0.1579
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.1463
   Episode_Reward/foot_landing_vel: -0.0950
   Episode_Reward/test_gait_reward: -0.4698
Metrics/base_velocity/error_vel_xy: 1.4629
Metrics/base_velocity/error_vel_yaw: 0.5094
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 1.09s
                        Total time: 669.02s
                               ETA: 2606.2s

################################################################################
                     [1m Learning iteration 613/3000 [0m                      

                       Computation: 89560 steps/s (collection: 0.971s, learning 0.127s)
               Value function loss: 1.1535
                    Surrogate loss: -0.0016
             Mean action noise std: 0.7142
                     Learning rate: 0.0004
                       Mean reward: 40.32
               Mean episode length: 545.16
       Episode_Reward/keep_balance: 0.5464
     Episode_Reward/rew_lin_vel_xy: 1.5841
      Episode_Reward/rew_ang_vel_z: 1.5691
    Episode_Reward/pen_base_height: -0.2608
      Episode_Reward/pen_lin_vel_z: -0.0486
     Episode_Reward/pen_ang_vel_xy: -0.0795
   Episode_Reward/pen_joint_torque: -0.1140
    Episode_Reward/pen_joint_accel: -0.0588
    Episode_Reward/pen_action_rate: -0.0423
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0241
   Episode_Reward/pen_joint_powers: -0.0382
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0883
Episode_Reward/pen_flat_orientation: -0.1562
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.1472
   Episode_Reward/foot_landing_vel: -0.0910
   Episode_Reward/test_gait_reward: -0.5000
Metrics/base_velocity/error_vel_xy: 1.6015
Metrics/base_velocity/error_vel_yaw: 0.5526
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 1.10s
                        Total time: 670.12s
                               ETA: 2605.2s

################################################################################
                     [1m Learning iteration 614/3000 [0m                      

                       Computation: 88158 steps/s (collection: 0.990s, learning 0.125s)
               Value function loss: 1.1595
                    Surrogate loss: -0.0037
             Mean action noise std: 0.7154
                     Learning rate: 0.0009
                       Mean reward: 46.72
               Mean episode length: 585.53
       Episode_Reward/keep_balance: 0.5772
     Episode_Reward/rew_lin_vel_xy: 1.7759
      Episode_Reward/rew_ang_vel_z: 1.6508
    Episode_Reward/pen_base_height: -0.2720
      Episode_Reward/pen_lin_vel_z: -0.0529
     Episode_Reward/pen_ang_vel_xy: -0.0844
   Episode_Reward/pen_joint_torque: -0.1228
    Episode_Reward/pen_joint_accel: -0.0725
    Episode_Reward/pen_action_rate: -0.0451
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0269
   Episode_Reward/pen_joint_powers: -0.0418
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0938
Episode_Reward/pen_flat_orientation: -0.1661
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1614
   Episode_Reward/foot_landing_vel: -0.1043
   Episode_Reward/test_gait_reward: -0.5344
Metrics/base_velocity/error_vel_xy: 1.5327
Metrics/base_velocity/error_vel_yaw: 0.5875
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 1.12s
                        Total time: 671.23s
                               ETA: 2604.2s

################################################################################
                     [1m Learning iteration 615/3000 [0m                      

                       Computation: 88439 steps/s (collection: 0.989s, learning 0.123s)
               Value function loss: 1.3551
                    Surrogate loss: -0.0012
             Mean action noise std: 0.7151
                     Learning rate: 0.0009
                       Mean reward: 47.17
               Mean episode length: 597.96
       Episode_Reward/keep_balance: 0.6024
     Episode_Reward/rew_lin_vel_xy: 1.9558
      Episode_Reward/rew_ang_vel_z: 1.7587
    Episode_Reward/pen_base_height: -0.2758
      Episode_Reward/pen_lin_vel_z: -0.0558
     Episode_Reward/pen_ang_vel_xy: -0.0851
   Episode_Reward/pen_joint_torque: -0.1341
    Episode_Reward/pen_joint_accel: -0.0683
    Episode_Reward/pen_action_rate: -0.0472
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0276
   Episode_Reward/pen_joint_powers: -0.0439
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0960
Episode_Reward/pen_flat_orientation: -0.1659
  Episode_Reward/pen_feet_distance: -0.0025
Episode_Reward/pen_feet_regulation: -0.1763
   Episode_Reward/foot_landing_vel: -0.1117
   Episode_Reward/test_gait_reward: -0.5577
Metrics/base_velocity/error_vel_xy: 1.7135
Metrics/base_velocity/error_vel_yaw: 0.5856
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 1.11s
                        Total time: 672.34s
                               ETA: 2603.1s

################################################################################
                     [1m Learning iteration 616/3000 [0m                      

                       Computation: 89731 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 1.1925
                    Surrogate loss: -0.0003
             Mean action noise std: 0.7169
                     Learning rate: 0.0009
                       Mean reward: 47.98
               Mean episode length: 618.69
       Episode_Reward/keep_balance: 0.5670
     Episode_Reward/rew_lin_vel_xy: 1.7296
      Episode_Reward/rew_ang_vel_z: 1.6395
    Episode_Reward/pen_base_height: -0.2713
      Episode_Reward/pen_lin_vel_z: -0.0536
     Episode_Reward/pen_ang_vel_xy: -0.0835
   Episode_Reward/pen_joint_torque: -0.1243
    Episode_Reward/pen_joint_accel: -0.0716
    Episode_Reward/pen_action_rate: -0.0440
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0269
   Episode_Reward/pen_joint_powers: -0.0421
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0905
Episode_Reward/pen_flat_orientation: -0.1673
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.1672
   Episode_Reward/foot_landing_vel: -0.1026
   Episode_Reward/test_gait_reward: -0.5271
Metrics/base_velocity/error_vel_xy: 1.6573
Metrics/base_velocity/error_vel_yaw: 0.5680
      Episode_Termination/time_out: 2.6667
  Episode_Termination/base_contact: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 1.10s
                        Total time: 673.44s
                               ETA: 2602.1s

################################################################################
                     [1m Learning iteration 617/3000 [0m                      

                       Computation: 89502 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 1.0666
                    Surrogate loss: 0.0015
             Mean action noise std: 0.7179
                     Learning rate: 0.0003
                       Mean reward: 42.97
               Mean episode length: 534.49
       Episode_Reward/keep_balance: 0.5551
     Episode_Reward/rew_lin_vel_xy: 1.6451
      Episode_Reward/rew_ang_vel_z: 1.6127
    Episode_Reward/pen_base_height: -0.2647
      Episode_Reward/pen_lin_vel_z: -0.0495
     Episode_Reward/pen_ang_vel_xy: -0.0782
   Episode_Reward/pen_joint_torque: -0.1222
    Episode_Reward/pen_joint_accel: -0.0628
    Episode_Reward/pen_action_rate: -0.0431
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0250
   Episode_Reward/pen_joint_powers: -0.0401
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0889
Episode_Reward/pen_flat_orientation: -0.1497
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1533
   Episode_Reward/foot_landing_vel: -0.0960
   Episode_Reward/test_gait_reward: -0.5112
Metrics/base_velocity/error_vel_xy: 1.6346
Metrics/base_velocity/error_vel_yaw: 0.5456
      Episode_Termination/time_out: 2.7917
  Episode_Termination/base_contact: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 1.10s
                        Total time: 674.54s
                               ETA: 2601.0s

################################################################################
                     [1m Learning iteration 618/3000 [0m                      

                       Computation: 89018 steps/s (collection: 0.980s, learning 0.124s)
               Value function loss: 0.9826
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7182
                     Learning rate: 0.0004
                       Mean reward: 40.75
               Mean episode length: 541.75
       Episode_Reward/keep_balance: 0.5101
     Episode_Reward/rew_lin_vel_xy: 1.5035
      Episode_Reward/rew_ang_vel_z: 1.4656
    Episode_Reward/pen_base_height: -0.2478
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.0727
   Episode_Reward/pen_joint_torque: -0.1059
    Episode_Reward/pen_joint_accel: -0.0560
    Episode_Reward/pen_action_rate: -0.0396
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0219
   Episode_Reward/pen_joint_powers: -0.0348
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0825
Episode_Reward/pen_flat_orientation: -0.1376
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.1330
   Episode_Reward/foot_landing_vel: -0.0830
   Episode_Reward/test_gait_reward: -0.4686
Metrics/base_velocity/error_vel_xy: 1.5562
Metrics/base_velocity/error_vel_yaw: 0.5144
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 1.10s
                        Total time: 675.64s
                               ETA: 2600.0s

################################################################################
                     [1m Learning iteration 619/3000 [0m                      

                       Computation: 90413 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 1.0257
                    Surrogate loss: -0.0024
             Mean action noise std: 0.7195
                     Learning rate: 0.0006
                       Mean reward: 46.55
               Mean episode length: 565.07
       Episode_Reward/keep_balance: 0.5519
     Episode_Reward/rew_lin_vel_xy: 1.6964
      Episode_Reward/rew_ang_vel_z: 1.5978
    Episode_Reward/pen_base_height: -0.2675
      Episode_Reward/pen_lin_vel_z: -0.0517
     Episode_Reward/pen_ang_vel_xy: -0.0805
   Episode_Reward/pen_joint_torque: -0.1211
    Episode_Reward/pen_joint_accel: -0.0702
    Episode_Reward/pen_action_rate: -0.0433
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0255
   Episode_Reward/pen_joint_powers: -0.0403
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0895
Episode_Reward/pen_flat_orientation: -0.1515
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1582
   Episode_Reward/foot_landing_vel: -0.0978
   Episode_Reward/test_gait_reward: -0.5143
Metrics/base_velocity/error_vel_xy: 1.5843
Metrics/base_velocity/error_vel_yaw: 0.5475
      Episode_Termination/time_out: 2.5417
  Episode_Termination/base_contact: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 1.09s
                        Total time: 676.73s
                               ETA: 2598.9s

################################################################################
                     [1m Learning iteration 620/3000 [0m                      

                       Computation: 88787 steps/s (collection: 0.982s, learning 0.125s)
               Value function loss: 1.0998
                    Surrogate loss: 0.0012
             Mean action noise std: 0.7207
                     Learning rate: 0.0003
                       Mean reward: 37.68
               Mean episode length: 499.30
       Episode_Reward/keep_balance: 0.4980
     Episode_Reward/rew_lin_vel_xy: 1.4933
      Episode_Reward/rew_ang_vel_z: 1.4300
    Episode_Reward/pen_base_height: -0.2502
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.0724
   Episode_Reward/pen_joint_torque: -0.1061
    Episode_Reward/pen_joint_accel: -0.0549
    Episode_Reward/pen_action_rate: -0.0385
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0221
   Episode_Reward/pen_joint_powers: -0.0352
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0808
Episode_Reward/pen_flat_orientation: -0.1406
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1327
   Episode_Reward/foot_landing_vel: -0.0840
   Episode_Reward/test_gait_reward: -0.4592
Metrics/base_velocity/error_vel_xy: 1.4125
Metrics/base_velocity/error_vel_yaw: 0.5056
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 1.11s
                        Total time: 677.84s
                               ETA: 2597.8s

################################################################################
                     [1m Learning iteration 621/3000 [0m                      

                       Computation: 89327 steps/s (collection: 0.975s, learning 0.126s)
               Value function loss: 1.0325
                    Surrogate loss: -0.0023
             Mean action noise std: 0.7217
                     Learning rate: 0.0006
                       Mean reward: 38.04
               Mean episode length: 518.90
       Episode_Reward/keep_balance: 0.5364
     Episode_Reward/rew_lin_vel_xy: 1.6683
      Episode_Reward/rew_ang_vel_z: 1.5347
    Episode_Reward/pen_base_height: -0.2672
      Episode_Reward/pen_lin_vel_z: -0.0496
     Episode_Reward/pen_ang_vel_xy: -0.0794
   Episode_Reward/pen_joint_torque: -0.1175
    Episode_Reward/pen_joint_accel: -0.0685
    Episode_Reward/pen_action_rate: -0.0424
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0252
   Episode_Reward/pen_joint_powers: -0.0395
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0878
Episode_Reward/pen_flat_orientation: -0.1486
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1566
   Episode_Reward/foot_landing_vel: -0.0976
   Episode_Reward/test_gait_reward: -0.4972
Metrics/base_velocity/error_vel_xy: 1.5109
Metrics/base_velocity/error_vel_yaw: 0.5447
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 1.10s
                        Total time: 678.94s
                               ETA: 2596.8s

################################################################################
                     [1m Learning iteration 622/3000 [0m                      

                       Computation: 89034 steps/s (collection: 0.981s, learning 0.123s)
               Value function loss: 0.9888
                    Surrogate loss: 0.0005
             Mean action noise std: 0.7224
                     Learning rate: 0.0001
                       Mean reward: 45.93
               Mean episode length: 594.45
       Episode_Reward/keep_balance: 0.5635
     Episode_Reward/rew_lin_vel_xy: 1.6626
      Episode_Reward/rew_ang_vel_z: 1.6130
    Episode_Reward/pen_base_height: -0.2654
      Episode_Reward/pen_lin_vel_z: -0.0514
     Episode_Reward/pen_ang_vel_xy: -0.0811
   Episode_Reward/pen_joint_torque: -0.1223
    Episode_Reward/pen_joint_accel: -0.0635
    Episode_Reward/pen_action_rate: -0.0443
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0253
   Episode_Reward/pen_joint_powers: -0.0405
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0925
Episode_Reward/pen_flat_orientation: -0.1459
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1535
   Episode_Reward/foot_landing_vel: -0.0997
   Episode_Reward/test_gait_reward: -0.5192
Metrics/base_velocity/error_vel_xy: 1.6943
Metrics/base_velocity/error_vel_yaw: 0.5751
      Episode_Termination/time_out: 2.8750
  Episode_Termination/base_contact: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 1.10s
                        Total time: 680.04s
                               ETA: 2595.7s

################################################################################
                     [1m Learning iteration 623/3000 [0m                      

                       Computation: 89673 steps/s (collection: 0.970s, learning 0.126s)
               Value function loss: 1.1161
                    Surrogate loss: 0.0022
             Mean action noise std: 0.7225
                     Learning rate: 0.0001
                       Mean reward: 41.74
               Mean episode length: 581.07
       Episode_Reward/keep_balance: 0.5572
     Episode_Reward/rew_lin_vel_xy: 1.5840
      Episode_Reward/rew_ang_vel_z: 1.5770
    Episode_Reward/pen_base_height: -0.2577
      Episode_Reward/pen_lin_vel_z: -0.0527
     Episode_Reward/pen_ang_vel_xy: -0.0837
   Episode_Reward/pen_joint_torque: -0.1228
    Episode_Reward/pen_joint_accel: -0.0709
    Episode_Reward/pen_action_rate: -0.0446
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0263
   Episode_Reward/pen_joint_powers: -0.0413
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0925
Episode_Reward/pen_flat_orientation: -0.1500
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1606
   Episode_Reward/foot_landing_vel: -0.1038
   Episode_Reward/test_gait_reward: -0.5163
Metrics/base_velocity/error_vel_xy: 1.7085
Metrics/base_velocity/error_vel_yaw: 0.5786
      Episode_Termination/time_out: 2.8333
  Episode_Termination/base_contact: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 1.10s
                        Total time: 681.14s
                               ETA: 2594.7s

################################################################################
                     [1m Learning iteration 624/3000 [0m                      

                       Computation: 88775 steps/s (collection: 0.982s, learning 0.125s)
               Value function loss: 1.0593
                    Surrogate loss: 0.0033
             Mean action noise std: 0.7226
                     Learning rate: 0.0000
                       Mean reward: 42.44
               Mean episode length: 565.29
       Episode_Reward/keep_balance: 0.5618
     Episode_Reward/rew_lin_vel_xy: 1.6628
      Episode_Reward/rew_ang_vel_z: 1.6158
    Episode_Reward/pen_base_height: -0.2711
      Episode_Reward/pen_lin_vel_z: -0.0514
     Episode_Reward/pen_ang_vel_xy: -0.0818
   Episode_Reward/pen_joint_torque: -0.1214
    Episode_Reward/pen_joint_accel: -0.0660
    Episode_Reward/pen_action_rate: -0.0447
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0260
   Episode_Reward/pen_joint_powers: -0.0409
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0927
Episode_Reward/pen_flat_orientation: -0.1447
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1573
   Episode_Reward/foot_landing_vel: -0.1029
   Episode_Reward/test_gait_reward: -0.5219
Metrics/base_velocity/error_vel_xy: 1.6525
Metrics/base_velocity/error_vel_yaw: 0.5692
      Episode_Termination/time_out: 2.7083
  Episode_Termination/base_contact: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 1.11s
                        Total time: 682.24s
                               ETA: 2593.6s

################################################################################
                     [1m Learning iteration 625/3000 [0m                      

                       Computation: 88814 steps/s (collection: 0.981s, learning 0.125s)
               Value function loss: 1.0487
                    Surrogate loss: -0.0007
             Mean action noise std: 0.7223
                     Learning rate: 0.0001
                       Mean reward: 40.25
               Mean episode length: 537.26
       Episode_Reward/keep_balance: 0.5372
     Episode_Reward/rew_lin_vel_xy: 1.5934
      Episode_Reward/rew_ang_vel_z: 1.5417
    Episode_Reward/pen_base_height: -0.2658
      Episode_Reward/pen_lin_vel_z: -0.0473
     Episode_Reward/pen_ang_vel_xy: -0.0783
   Episode_Reward/pen_joint_torque: -0.1162
    Episode_Reward/pen_joint_accel: -0.0637
    Episode_Reward/pen_action_rate: -0.0423
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0244
   Episode_Reward/pen_joint_powers: -0.0384
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0884
Episode_Reward/pen_flat_orientation: -0.1368
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1493
   Episode_Reward/foot_landing_vel: -0.0944
   Episode_Reward/test_gait_reward: -0.4968
Metrics/base_velocity/error_vel_xy: 1.5859
Metrics/base_velocity/error_vel_yaw: 0.5435
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 1.11s
                        Total time: 683.35s
                               ETA: 2592.6s

################################################################################
                     [1m Learning iteration 626/3000 [0m                      

                       Computation: 89139 steps/s (collection: 0.977s, learning 0.126s)
               Value function loss: 1.0246
                    Surrogate loss: -0.0028
             Mean action noise std: 0.7214
                     Learning rate: 0.0003
                       Mean reward: 45.49
               Mean episode length: 571.46
       Episode_Reward/keep_balance: 0.5655
     Episode_Reward/rew_lin_vel_xy: 1.7390
      Episode_Reward/rew_ang_vel_z: 1.6229
    Episode_Reward/pen_base_height: -0.2729
      Episode_Reward/pen_lin_vel_z: -0.0508
     Episode_Reward/pen_ang_vel_xy: -0.0805
   Episode_Reward/pen_joint_torque: -0.1245
    Episode_Reward/pen_joint_accel: -0.0646
    Episode_Reward/pen_action_rate: -0.0445
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0255
   Episode_Reward/pen_joint_powers: -0.0408
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0926
Episode_Reward/pen_flat_orientation: -0.1407
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1560
   Episode_Reward/foot_landing_vel: -0.0952
   Episode_Reward/test_gait_reward: -0.5215
Metrics/base_velocity/error_vel_xy: 1.5998
Metrics/base_velocity/error_vel_yaw: 0.5711
      Episode_Termination/time_out: 2.7083
  Episode_Termination/base_contact: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 1.10s
                        Total time: 684.45s
                               ETA: 2591.5s

################################################################################
                     [1m Learning iteration 627/3000 [0m                      

                       Computation: 88324 steps/s (collection: 0.986s, learning 0.127s)
               Value function loss: 1.0477
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7219
                     Learning rate: 0.0004
                       Mean reward: 42.13
               Mean episode length: 617.60
       Episode_Reward/keep_balance: 0.5811
     Episode_Reward/rew_lin_vel_xy: 1.6698
      Episode_Reward/rew_ang_vel_z: 1.6484
    Episode_Reward/pen_base_height: -0.2798
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.0861
   Episode_Reward/pen_joint_torque: -0.1318
    Episode_Reward/pen_joint_accel: -0.0684
    Episode_Reward/pen_action_rate: -0.0463
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0278
   Episode_Reward/pen_joint_powers: -0.0435
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0964
Episode_Reward/pen_flat_orientation: -0.1515
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1683
   Episode_Reward/foot_landing_vel: -0.1053
   Episode_Reward/test_gait_reward: -0.5408
Metrics/base_velocity/error_vel_xy: 1.7455
Metrics/base_velocity/error_vel_yaw: 0.6055
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 1.11s
                        Total time: 685.57s
                               ETA: 2590.5s

################################################################################
                     [1m Learning iteration 628/3000 [0m                      

                       Computation: 89742 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 1.0464
                    Surrogate loss: -0.0022
             Mean action noise std: 0.7227
                     Learning rate: 0.0006
                       Mean reward: 41.37
               Mean episode length: 577.21
       Episode_Reward/keep_balance: 0.5642
     Episode_Reward/rew_lin_vel_xy: 1.6944
      Episode_Reward/rew_ang_vel_z: 1.5966
    Episode_Reward/pen_base_height: -0.2680
      Episode_Reward/pen_lin_vel_z: -0.0529
     Episode_Reward/pen_ang_vel_xy: -0.0821
   Episode_Reward/pen_joint_torque: -0.1211
    Episode_Reward/pen_joint_accel: -0.0739
    Episode_Reward/pen_action_rate: -0.0456
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0274
   Episode_Reward/pen_joint_powers: -0.0417
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0948
Episode_Reward/pen_flat_orientation: -0.1443
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1694
   Episode_Reward/foot_landing_vel: -0.1097
   Episode_Reward/test_gait_reward: -0.5248
Metrics/base_velocity/error_vel_xy: 1.7225
Metrics/base_velocity/error_vel_yaw: 0.5894
      Episode_Termination/time_out: 2.6667
  Episode_Termination/base_contact: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 1.10s
                        Total time: 686.66s
                               ETA: 2589.4s

################################################################################
                     [1m Learning iteration 629/3000 [0m                      

                       Computation: 90431 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 1.1906
                    Surrogate loss: -0.0026
             Mean action noise std: 0.7229
                     Learning rate: 0.0009
                       Mean reward: 40.56
               Mean episode length: 534.71
       Episode_Reward/keep_balance: 0.5423
     Episode_Reward/rew_lin_vel_xy: 1.7349
      Episode_Reward/rew_ang_vel_z: 1.5264
    Episode_Reward/pen_base_height: -0.2728
      Episode_Reward/pen_lin_vel_z: -0.0533
     Episode_Reward/pen_ang_vel_xy: -0.0826
   Episode_Reward/pen_joint_torque: -0.1239
    Episode_Reward/pen_joint_accel: -0.0690
    Episode_Reward/pen_action_rate: -0.0440
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0270
   Episode_Reward/pen_joint_powers: -0.0418
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0911
Episode_Reward/pen_flat_orientation: -0.1420
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1680
   Episode_Reward/foot_landing_vel: -0.1092
   Episode_Reward/test_gait_reward: -0.5085
Metrics/base_velocity/error_vel_xy: 1.5146
Metrics/base_velocity/error_vel_yaw: 0.5715
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 1.09s
                        Total time: 687.75s
                               ETA: 2588.3s

################################################################################
                     [1m Learning iteration 630/3000 [0m                      

                       Computation: 88837 steps/s (collection: 0.982s, learning 0.124s)
               Value function loss: 0.9332
                    Surrogate loss: -0.0029
             Mean action noise std: 0.7234
                     Learning rate: 0.0009
                       Mean reward: 40.26
               Mean episode length: 550.31
       Episode_Reward/keep_balance: 0.5887
     Episode_Reward/rew_lin_vel_xy: 1.7296
      Episode_Reward/rew_ang_vel_z: 1.6781
    Episode_Reward/pen_base_height: -0.2867
      Episode_Reward/pen_lin_vel_z: -0.0551
     Episode_Reward/pen_ang_vel_xy: -0.0858
   Episode_Reward/pen_joint_torque: -0.1330
    Episode_Reward/pen_joint_accel: -0.0778
    Episode_Reward/pen_action_rate: -0.0470
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0285
   Episode_Reward/pen_joint_powers: -0.0445
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0969
Episode_Reward/pen_flat_orientation: -0.1423
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1770
   Episode_Reward/foot_landing_vel: -0.1160
   Episode_Reward/test_gait_reward: -0.5449
Metrics/base_velocity/error_vel_xy: 1.7469
Metrics/base_velocity/error_vel_yaw: 0.6053
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 1.11s
                        Total time: 688.86s
                               ETA: 2587.3s

################################################################################
                     [1m Learning iteration 631/3000 [0m                      

                       Computation: 88926 steps/s (collection: 0.982s, learning 0.123s)
               Value function loss: 1.1167
                    Surrogate loss: -0.0004
             Mean action noise std: 0.7249
                     Learning rate: 0.0006
                       Mean reward: 37.14
               Mean episode length: 504.90
       Episode_Reward/keep_balance: 0.5193
     Episode_Reward/rew_lin_vel_xy: 1.5260
      Episode_Reward/rew_ang_vel_z: 1.4790
    Episode_Reward/pen_base_height: -0.2586
      Episode_Reward/pen_lin_vel_z: -0.0466
     Episode_Reward/pen_ang_vel_xy: -0.0740
   Episode_Reward/pen_joint_torque: -0.1143
    Episode_Reward/pen_joint_accel: -0.0603
    Episode_Reward/pen_action_rate: -0.0407
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0233
   Episode_Reward/pen_joint_powers: -0.0372
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0856
Episode_Reward/pen_flat_orientation: -0.1297
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1392
   Episode_Reward/foot_landing_vel: -0.0900
   Episode_Reward/test_gait_reward: -0.4775
Metrics/base_velocity/error_vel_xy: 1.5136
Metrics/base_velocity/error_vel_yaw: 0.5342
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 1.11s
                        Total time: 689.96s
                               ETA: 2586.3s

################################################################################
                     [1m Learning iteration 632/3000 [0m                      

                       Computation: 89122 steps/s (collection: 0.977s, learning 0.126s)
               Value function loss: 1.0200
                    Surrogate loss: -0.0031
             Mean action noise std: 0.7245
                     Learning rate: 0.0006
                       Mean reward: 44.25
               Mean episode length: 559.97
       Episode_Reward/keep_balance: 0.5834
     Episode_Reward/rew_lin_vel_xy: 1.8393
      Episode_Reward/rew_ang_vel_z: 1.6795
    Episode_Reward/pen_base_height: -0.2755
      Episode_Reward/pen_lin_vel_z: -0.0550
     Episode_Reward/pen_ang_vel_xy: -0.0833
   Episode_Reward/pen_joint_torque: -0.1286
    Episode_Reward/pen_joint_accel: -0.0701
    Episode_Reward/pen_action_rate: -0.0460
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0272
   Episode_Reward/pen_joint_powers: -0.0430
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0953
Episode_Reward/pen_flat_orientation: -0.1396
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1674
   Episode_Reward/foot_landing_vel: -0.1106
   Episode_Reward/test_gait_reward: -0.5400
Metrics/base_velocity/error_vel_xy: 1.6369
Metrics/base_velocity/error_vel_yaw: 0.5846
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 1.10s
                        Total time: 691.06s
                               ETA: 2585.2s

################################################################################
                     [1m Learning iteration 633/3000 [0m                      

                       Computation: 90066 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 1.1610
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7246
                     Learning rate: 0.0006
                       Mean reward: 51.17
               Mean episode length: 661.18
       Episode_Reward/keep_balance: 0.5995
     Episode_Reward/rew_lin_vel_xy: 1.8930
      Episode_Reward/rew_ang_vel_z: 1.6936
    Episode_Reward/pen_base_height: -0.2912
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.0883
   Episode_Reward/pen_joint_torque: -0.1375
    Episode_Reward/pen_joint_accel: -0.0802
    Episode_Reward/pen_action_rate: -0.0483
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0298
   Episode_Reward/pen_joint_powers: -0.0462
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1000
Episode_Reward/pen_flat_orientation: -0.1448
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1879
   Episode_Reward/foot_landing_vel: -0.1181
   Episode_Reward/test_gait_reward: -0.5606
Metrics/base_velocity/error_vel_xy: 1.7053
Metrics/base_velocity/error_vel_yaw: 0.6275
      Episode_Termination/time_out: 2.9167
  Episode_Termination/base_contact: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 1.09s
                        Total time: 692.16s
                               ETA: 2584.1s

################################################################################
                     [1m Learning iteration 634/3000 [0m                      

                       Computation: 90232 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 1.1307
                    Surrogate loss: -0.0013
             Mean action noise std: 0.7238
                     Learning rate: 0.0009
                       Mean reward: 52.57
               Mean episode length: 653.12
       Episode_Reward/keep_balance: 0.6510
     Episode_Reward/rew_lin_vel_xy: 2.0330
      Episode_Reward/rew_ang_vel_z: 1.8748
    Episode_Reward/pen_base_height: -0.2909
      Episode_Reward/pen_lin_vel_z: -0.0594
     Episode_Reward/pen_ang_vel_xy: -0.0923
   Episode_Reward/pen_joint_torque: -0.1470
    Episode_Reward/pen_joint_accel: -0.0823
    Episode_Reward/pen_action_rate: -0.0525
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0316
   Episode_Reward/pen_joint_powers: -0.0492
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1087
Episode_Reward/pen_flat_orientation: -0.1407
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.1962
   Episode_Reward/foot_landing_vel: -0.1265
   Episode_Reward/test_gait_reward: -0.6019
Metrics/base_velocity/error_vel_xy: 1.8339
Metrics/base_velocity/error_vel_yaw: 0.6553
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 1.09s
                        Total time: 693.25s
                               ETA: 2583.0s

################################################################################
                     [1m Learning iteration 635/3000 [0m                      

                       Computation: 90550 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 1.1286
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7230
                     Learning rate: 0.0006
                       Mean reward: 44.91
               Mean episode length: 600.42
       Episode_Reward/keep_balance: 0.5879
     Episode_Reward/rew_lin_vel_xy: 1.7712
      Episode_Reward/rew_ang_vel_z: 1.6704
    Episode_Reward/pen_base_height: -0.2766
      Episode_Reward/pen_lin_vel_z: -0.0548
     Episode_Reward/pen_ang_vel_xy: -0.0829
   Episode_Reward/pen_joint_torque: -0.1327
    Episode_Reward/pen_joint_accel: -0.0754
    Episode_Reward/pen_action_rate: -0.0472
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0280
   Episode_Reward/pen_joint_powers: -0.0437
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0977
Episode_Reward/pen_flat_orientation: -0.1399
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.1716
   Episode_Reward/foot_landing_vel: -0.1151
   Episode_Reward/test_gait_reward: -0.5456
Metrics/base_velocity/error_vel_xy: 1.7516
Metrics/base_velocity/error_vel_yaw: 0.6040
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 1.09s
                        Total time: 694.33s
                               ETA: 2581.9s

################################################################################
                     [1m Learning iteration 636/3000 [0m                      

                       Computation: 89736 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 1.1193
                    Surrogate loss: 0.0010
             Mean action noise std: 0.7229
                     Learning rate: 0.0003
                       Mean reward: 42.83
               Mean episode length: 546.63
       Episode_Reward/keep_balance: 0.6101
     Episode_Reward/rew_lin_vel_xy: 2.0007
      Episode_Reward/rew_ang_vel_z: 1.7123
    Episode_Reward/pen_base_height: -0.2826
      Episode_Reward/pen_lin_vel_z: -0.0579
     Episode_Reward/pen_ang_vel_xy: -0.0869
   Episode_Reward/pen_joint_torque: -0.1329
    Episode_Reward/pen_joint_accel: -0.0729
    Episode_Reward/pen_action_rate: -0.0493
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0290
   Episode_Reward/pen_joint_powers: -0.0451
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1032
Episode_Reward/pen_flat_orientation: -0.1467
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.1796
   Episode_Reward/foot_landing_vel: -0.1177
   Episode_Reward/test_gait_reward: -0.5667
Metrics/base_velocity/error_vel_xy: 1.6361
Metrics/base_velocity/error_vel_yaw: 0.6440
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 1.10s
                        Total time: 695.43s
                               ETA: 2580.8s

################################################################################
                     [1m Learning iteration 637/3000 [0m                      

                       Computation: 89403 steps/s (collection: 0.975s, learning 0.125s)
               Value function loss: 1.0333
                    Surrogate loss: -0.0019
             Mean action noise std: 0.7228
                     Learning rate: 0.0004
                       Mean reward: 39.39
               Mean episode length: 510.27
       Episode_Reward/keep_balance: 0.5422
     Episode_Reward/rew_lin_vel_xy: 1.6835
      Episode_Reward/rew_ang_vel_z: 1.5405
    Episode_Reward/pen_base_height: -0.2691
      Episode_Reward/pen_lin_vel_z: -0.0465
     Episode_Reward/pen_ang_vel_xy: -0.0762
   Episode_Reward/pen_joint_torque: -0.1145
    Episode_Reward/pen_joint_accel: -0.0604
    Episode_Reward/pen_action_rate: -0.0427
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0245
   Episode_Reward/pen_joint_powers: -0.0383
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0907
Episode_Reward/pen_flat_orientation: -0.1264
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.1453
   Episode_Reward/foot_landing_vel: -0.0950
   Episode_Reward/test_gait_reward: -0.4994
Metrics/base_velocity/error_vel_xy: 1.5238
Metrics/base_velocity/error_vel_yaw: 0.5602
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 1.10s
                        Total time: 696.53s
                               ETA: 2579.8s

################################################################################
                     [1m Learning iteration 638/3000 [0m                      

                       Computation: 88771 steps/s (collection: 0.981s, learning 0.127s)
               Value function loss: 1.0352
                    Surrogate loss: -0.0011
             Mean action noise std: 0.7234
                     Learning rate: 0.0004
                       Mean reward: 50.38
               Mean episode length: 624.51
       Episode_Reward/keep_balance: 0.6096
     Episode_Reward/rew_lin_vel_xy: 1.9794
      Episode_Reward/rew_ang_vel_z: 1.7315
    Episode_Reward/pen_base_height: -0.2819
      Episode_Reward/pen_lin_vel_z: -0.0528
     Episode_Reward/pen_ang_vel_xy: -0.0837
   Episode_Reward/pen_joint_torque: -0.1316
    Episode_Reward/pen_joint_accel: -0.0766
    Episode_Reward/pen_action_rate: -0.0485
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0287
   Episode_Reward/pen_joint_powers: -0.0442
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1018
Episode_Reward/pen_flat_orientation: -0.1291
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.1743
   Episode_Reward/foot_landing_vel: -0.1152
   Episode_Reward/test_gait_reward: -0.5610
Metrics/base_velocity/error_vel_xy: 1.6488
Metrics/base_velocity/error_vel_yaw: 0.6298
      Episode_Termination/time_out: 2.6667
  Episode_Termination/base_contact: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 1.11s
                        Total time: 697.63s
                               ETA: 2578.7s

################################################################################
                     [1m Learning iteration 639/3000 [0m                      

                       Computation: 88067 steps/s (collection: 0.969s, learning 0.147s)
               Value function loss: 1.1369
                    Surrogate loss: 0.0010
             Mean action noise std: 0.7242
                     Learning rate: 0.0002
                       Mean reward: 52.24
               Mean episode length: 661.38
       Episode_Reward/keep_balance: 0.6614
     Episode_Reward/rew_lin_vel_xy: 2.1268
      Episode_Reward/rew_ang_vel_z: 1.8834
    Episode_Reward/pen_base_height: -0.2963
      Episode_Reward/pen_lin_vel_z: -0.0590
     Episode_Reward/pen_ang_vel_xy: -0.0897
   Episode_Reward/pen_joint_torque: -0.1455
    Episode_Reward/pen_joint_accel: -0.0801
    Episode_Reward/pen_action_rate: -0.0528
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0313
   Episode_Reward/pen_joint_powers: -0.0485
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1102
Episode_Reward/pen_flat_orientation: -0.1437
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.1908
   Episode_Reward/foot_landing_vel: -0.1265
   Episode_Reward/test_gait_reward: -0.6133
Metrics/base_velocity/error_vel_xy: 1.8275
Metrics/base_velocity/error_vel_yaw: 0.6764
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 1.12s
                        Total time: 698.75s
                               ETA: 2577.7s

################################################################################
                     [1m Learning iteration 640/3000 [0m                      

                       Computation: 88450 steps/s (collection: 0.987s, learning 0.124s)
               Value function loss: 1.0811
                    Surrogate loss: -0.0025
             Mean action noise std: 0.7252
                     Learning rate: 0.0004
                       Mean reward: 49.15
               Mean episode length: 598.84
       Episode_Reward/keep_balance: 0.5969
     Episode_Reward/rew_lin_vel_xy: 2.0302
      Episode_Reward/rew_ang_vel_z: 1.6890
    Episode_Reward/pen_base_height: -0.2859
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.0846
   Episode_Reward/pen_joint_torque: -0.1299
    Episode_Reward/pen_joint_accel: -0.0741
    Episode_Reward/pen_action_rate: -0.0478
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0286
   Episode_Reward/pen_joint_powers: -0.0439
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.1005
Episode_Reward/pen_flat_orientation: -0.1325
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.1763
   Episode_Reward/foot_landing_vel: -0.1143
   Episode_Reward/test_gait_reward: -0.5544
Metrics/base_velocity/error_vel_xy: 1.5482
Metrics/base_velocity/error_vel_yaw: 0.6197
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 1.11s
                        Total time: 699.86s
                               ETA: 2576.7s

################################################################################
                     [1m Learning iteration 641/3000 [0m                      

                       Computation: 89296 steps/s (collection: 0.975s, learning 0.125s)
               Value function loss: 0.9905
                    Surrogate loss: 0.0009
             Mean action noise std: 0.7259
                     Learning rate: 0.0002
                       Mean reward: 41.87
               Mean episode length: 532.59
       Episode_Reward/keep_balance: 0.5485
     Episode_Reward/rew_lin_vel_xy: 1.7487
      Episode_Reward/rew_ang_vel_z: 1.5403
    Episode_Reward/pen_base_height: -0.2722
      Episode_Reward/pen_lin_vel_z: -0.0506
     Episode_Reward/pen_ang_vel_xy: -0.0793
   Episode_Reward/pen_joint_torque: -0.1231
    Episode_Reward/pen_joint_accel: -0.0710
    Episode_Reward/pen_action_rate: -0.0444
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0268
   Episode_Reward/pen_joint_powers: -0.0412
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0932
Episode_Reward/pen_flat_orientation: -0.1304
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1624
   Episode_Reward/foot_landing_vel: -0.1099
   Episode_Reward/test_gait_reward: -0.5112
Metrics/base_velocity/error_vel_xy: 1.5278
Metrics/base_velocity/error_vel_yaw: 0.5820
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 1.10s
                        Total time: 700.96s
                               ETA: 2575.7s

################################################################################
                     [1m Learning iteration 642/3000 [0m                      

                       Computation: 89751 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 1.1243
                    Surrogate loss: -0.0011
             Mean action noise std: 0.7265
                     Learning rate: 0.0003
                       Mean reward: 46.85
               Mean episode length: 583.57
       Episode_Reward/keep_balance: 0.5709
     Episode_Reward/rew_lin_vel_xy: 1.7438
      Episode_Reward/rew_ang_vel_z: 1.6193
    Episode_Reward/pen_base_height: -0.2682
      Episode_Reward/pen_lin_vel_z: -0.0510
     Episode_Reward/pen_ang_vel_xy: -0.0812
   Episode_Reward/pen_joint_torque: -0.1245
    Episode_Reward/pen_joint_accel: -0.0670
    Episode_Reward/pen_action_rate: -0.0459
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0272
   Episode_Reward/pen_joint_powers: -0.0418
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0965
Episode_Reward/pen_flat_orientation: -0.1352
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.1624
   Episode_Reward/foot_landing_vel: -0.1082
   Episode_Reward/test_gait_reward: -0.5291
Metrics/base_velocity/error_vel_xy: 1.6870
Metrics/base_velocity/error_vel_yaw: 0.5923
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 1.10s
                        Total time: 702.06s
                               ETA: 2574.6s

################################################################################
                     [1m Learning iteration 643/3000 [0m                      

                       Computation: 89311 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 1.1230
                    Surrogate loss: -0.0021
             Mean action noise std: 0.7274
                     Learning rate: 0.0003
                       Mean reward: 52.68
               Mean episode length: 669.08
       Episode_Reward/keep_balance: 0.6460
     Episode_Reward/rew_lin_vel_xy: 2.0255
      Episode_Reward/rew_ang_vel_z: 1.8162
    Episode_Reward/pen_base_height: -0.2972
      Episode_Reward/pen_lin_vel_z: -0.0587
     Episode_Reward/pen_ang_vel_xy: -0.0888
   Episode_Reward/pen_joint_torque: -0.1460
    Episode_Reward/pen_joint_accel: -0.0799
    Episode_Reward/pen_action_rate: -0.0521
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0312
   Episode_Reward/pen_joint_powers: -0.0490
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1091
Episode_Reward/pen_flat_orientation: -0.1352
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1938
   Episode_Reward/foot_landing_vel: -0.1262
   Episode_Reward/test_gait_reward: -0.6011
Metrics/base_velocity/error_vel_xy: 1.7827
Metrics/base_velocity/error_vel_yaw: 0.6798
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 1.10s
                        Total time: 703.16s
                               ETA: 2573.5s

################################################################################
                     [1m Learning iteration 644/3000 [0m                      

                       Computation: 90201 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 1.1175
                    Surrogate loss: -0.0036
             Mean action noise std: 0.7288
                     Learning rate: 0.0006
                       Mean reward: 48.76
               Mean episode length: 605.89
       Episode_Reward/keep_balance: 0.6036
     Episode_Reward/rew_lin_vel_xy: 1.8551
      Episode_Reward/rew_ang_vel_z: 1.7131
    Episode_Reward/pen_base_height: -0.2733
      Episode_Reward/pen_lin_vel_z: -0.0508
     Episode_Reward/pen_ang_vel_xy: -0.0823
   Episode_Reward/pen_joint_torque: -0.1276
    Episode_Reward/pen_joint_accel: -0.0742
    Episode_Reward/pen_action_rate: -0.0486
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0280
   Episode_Reward/pen_joint_powers: -0.0429
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1028
Episode_Reward/pen_flat_orientation: -0.1202
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1620
   Episode_Reward/foot_landing_vel: -0.1163
   Episode_Reward/test_gait_reward: -0.5530
Metrics/base_velocity/error_vel_xy: 1.6869
Metrics/base_velocity/error_vel_yaw: 0.6224
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 1.09s
                        Total time: 704.25s
                               ETA: 2572.4s

################################################################################
                     [1m Learning iteration 645/3000 [0m                      

                       Computation: 89693 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 1.2014
                    Surrogate loss: 0.0014
             Mean action noise std: 0.7296
                     Learning rate: 0.0001
                       Mean reward: 40.31
               Mean episode length: 554.72
       Episode_Reward/keep_balance: 0.5788
     Episode_Reward/rew_lin_vel_xy: 1.6927
      Episode_Reward/rew_ang_vel_z: 1.6220
    Episode_Reward/pen_base_height: -0.2788
      Episode_Reward/pen_lin_vel_z: -0.0503
     Episode_Reward/pen_ang_vel_xy: -0.0804
   Episode_Reward/pen_joint_torque: -0.1263
    Episode_Reward/pen_joint_accel: -0.0732
    Episode_Reward/pen_action_rate: -0.0468
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0275
   Episode_Reward/pen_joint_powers: -0.0423
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0989
Episode_Reward/pen_flat_orientation: -0.1241
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.1678
   Episode_Reward/foot_landing_vel: -0.1162
   Episode_Reward/test_gait_reward: -0.5349
Metrics/base_velocity/error_vel_xy: 1.7237
Metrics/base_velocity/error_vel_yaw: 0.6193
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 1.10s
                        Total time: 705.34s
                               ETA: 2571.3s

################################################################################
                     [1m Learning iteration 646/3000 [0m                      

                       Computation: 90359 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 1.2371
                    Surrogate loss: 0.0050
             Mean action noise std: 0.7297
                     Learning rate: 0.0001
                       Mean reward: 52.38
               Mean episode length: 665.43
       Episode_Reward/keep_balance: 0.6386
     Episode_Reward/rew_lin_vel_xy: 1.9668
      Episode_Reward/rew_ang_vel_z: 1.8070
    Episode_Reward/pen_base_height: -0.2895
      Episode_Reward/pen_lin_vel_z: -0.0546
     Episode_Reward/pen_ang_vel_xy: -0.0906
   Episode_Reward/pen_joint_torque: -0.1361
    Episode_Reward/pen_joint_accel: -0.0818
    Episode_Reward/pen_action_rate: -0.0518
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0297
   Episode_Reward/pen_joint_powers: -0.0459
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1086
Episode_Reward/pen_flat_orientation: -0.1336
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1748
   Episode_Reward/foot_landing_vel: -0.1224
   Episode_Reward/test_gait_reward: -0.5860
Metrics/base_velocity/error_vel_xy: 1.8379
Metrics/base_velocity/error_vel_yaw: 0.6648
      Episode_Termination/time_out: 2.5417
  Episode_Termination/base_contact: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 1.09s
                        Total time: 706.43s
                               ETA: 2570.2s

################################################################################
                     [1m Learning iteration 647/3000 [0m                      

                       Computation: 92068 steps/s (collection: 0.944s, learning 0.124s)
               Value function loss: 1.1804
                    Surrogate loss: -0.0029
             Mean action noise std: 0.7300
                     Learning rate: 0.0003
                       Mean reward: 57.19
               Mean episode length: 722.60
       Episode_Reward/keep_balance: 0.7235
     Episode_Reward/rew_lin_vel_xy: 2.2342
      Episode_Reward/rew_ang_vel_z: 2.0533
    Episode_Reward/pen_base_height: -0.3025
      Episode_Reward/pen_lin_vel_z: -0.0650
     Episode_Reward/pen_ang_vel_xy: -0.0988
   Episode_Reward/pen_joint_torque: -0.1665
    Episode_Reward/pen_joint_accel: -0.0911
    Episode_Reward/pen_action_rate: -0.0590
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0346
   Episode_Reward/pen_joint_powers: -0.0544
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1231
Episode_Reward/pen_flat_orientation: -0.1391
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.2050
   Episode_Reward/foot_landing_vel: -0.1496
   Episode_Reward/test_gait_reward: -0.6692
Metrics/base_velocity/error_vel_xy: 2.0443
Metrics/base_velocity/error_vel_yaw: 0.7504
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 1.07s
                        Total time: 707.50s
                               ETA: 2569.1s

################################################################################
                     [1m Learning iteration 648/3000 [0m                      

                       Computation: 91144 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.1707
                    Surrogate loss: -0.0032
             Mean action noise std: 0.7314
                     Learning rate: 0.0006
                       Mean reward: 44.07
               Mean episode length: 581.48
       Episode_Reward/keep_balance: 0.6015
     Episode_Reward/rew_lin_vel_xy: 1.8591
      Episode_Reward/rew_ang_vel_z: 1.6951
    Episode_Reward/pen_base_height: -0.2781
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.0865
   Episode_Reward/pen_joint_torque: -0.1362
    Episode_Reward/pen_joint_accel: -0.0762
    Episode_Reward/pen_action_rate: -0.0492
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0292
   Episode_Reward/pen_joint_powers: -0.0454
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.1034
Episode_Reward/pen_flat_orientation: -0.1290
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1768
   Episode_Reward/foot_landing_vel: -0.1225
   Episode_Reward/test_gait_reward: -0.5565
Metrics/base_velocity/error_vel_xy: 1.6929
Metrics/base_velocity/error_vel_yaw: 0.6312
      Episode_Termination/time_out: 2.2917
  Episode_Termination/base_contact: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 1.08s
                        Total time: 708.58s
                               ETA: 2567.9s

################################################################################
                     [1m Learning iteration 649/3000 [0m                      

                       Computation: 90144 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 1.2613
                    Surrogate loss: -0.0030
             Mean action noise std: 0.7321
                     Learning rate: 0.0006
                       Mean reward: 36.05
               Mean episode length: 487.89
       Episode_Reward/keep_balance: 0.5288
     Episode_Reward/rew_lin_vel_xy: 1.6809
      Episode_Reward/rew_ang_vel_z: 1.4790
    Episode_Reward/pen_base_height: -0.2648
      Episode_Reward/pen_lin_vel_z: -0.0477
     Episode_Reward/pen_ang_vel_xy: -0.0761
   Episode_Reward/pen_joint_torque: -0.1171
    Episode_Reward/pen_joint_accel: -0.0666
    Episode_Reward/pen_action_rate: -0.0427
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0254
   Episode_Reward/pen_joint_powers: -0.0392
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0896
Episode_Reward/pen_flat_orientation: -0.1266
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.1486
   Episode_Reward/foot_landing_vel: -0.0989
   Episode_Reward/test_gait_reward: -0.4913
Metrics/base_velocity/error_vel_xy: 1.4600
Metrics/base_velocity/error_vel_yaw: 0.5691
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 1.09s
                        Total time: 709.67s
                               ETA: 2566.8s

################################################################################
                     [1m Learning iteration 650/3000 [0m                      

                       Computation: 90744 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 1.1971
                    Surrogate loss: -0.0031
             Mean action noise std: 0.7332
                     Learning rate: 0.0006
                       Mean reward: 50.19
               Mean episode length: 642.93
       Episode_Reward/keep_balance: 0.6519
     Episode_Reward/rew_lin_vel_xy: 2.0296
      Episode_Reward/rew_ang_vel_z: 1.8387
    Episode_Reward/pen_base_height: -0.2827
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.0880
   Episode_Reward/pen_joint_torque: -0.1395
    Episode_Reward/pen_joint_accel: -0.0840
    Episode_Reward/pen_action_rate: -0.0526
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0300
   Episode_Reward/pen_joint_powers: -0.0462
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1115
Episode_Reward/pen_flat_orientation: -0.1261
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1670
   Episode_Reward/foot_landing_vel: -0.1264
   Episode_Reward/test_gait_reward: -0.5949
Metrics/base_velocity/error_vel_xy: 1.8503
Metrics/base_velocity/error_vel_yaw: 0.6831
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 1.08s
                        Total time: 710.75s
                               ETA: 2565.7s

################################################################################
                     [1m Learning iteration 651/3000 [0m                      

                       Computation: 90668 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 1.4134
                    Surrogate loss: -0.0039
             Mean action noise std: 0.7339
                     Learning rate: 0.0009
                       Mean reward: 51.92
               Mean episode length: 650.39
       Episode_Reward/keep_balance: 0.6438
     Episode_Reward/rew_lin_vel_xy: 2.0306
      Episode_Reward/rew_ang_vel_z: 1.8309
    Episode_Reward/pen_base_height: -0.2904
      Episode_Reward/pen_lin_vel_z: -0.0548
     Episode_Reward/pen_ang_vel_xy: -0.0883
   Episode_Reward/pen_joint_torque: -0.1385
    Episode_Reward/pen_joint_accel: -0.0721
    Episode_Reward/pen_action_rate: -0.0521
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0293
   Episode_Reward/pen_joint_powers: -0.0462
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1103
Episode_Reward/pen_flat_orientation: -0.1299
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.1712
   Episode_Reward/foot_landing_vel: -0.1213
   Episode_Reward/test_gait_reward: -0.5922
Metrics/base_velocity/error_vel_xy: 1.7697
Metrics/base_velocity/error_vel_yaw: 0.6634
      Episode_Termination/time_out: 2.5417
  Episode_Termination/base_contact: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 1.08s
                        Total time: 711.84s
                               ETA: 2564.6s

################################################################################
                     [1m Learning iteration 652/3000 [0m                      

                       Computation: 90744 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 1.4765
                    Surrogate loss: -0.0022
             Mean action noise std: 0.7346
                     Learning rate: 0.0009
                       Mean reward: 48.25
               Mean episode length: 650.69
       Episode_Reward/keep_balance: 0.6624
     Episode_Reward/rew_lin_vel_xy: 2.0052
      Episode_Reward/rew_ang_vel_z: 1.8869
    Episode_Reward/pen_base_height: -0.2980
      Episode_Reward/pen_lin_vel_z: -0.0584
     Episode_Reward/pen_ang_vel_xy: -0.0936
   Episode_Reward/pen_joint_torque: -0.1423
    Episode_Reward/pen_joint_accel: -0.0898
    Episode_Reward/pen_action_rate: -0.0538
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0317
   Episode_Reward/pen_joint_powers: -0.0486
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1127
Episode_Reward/pen_flat_orientation: -0.1379
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.1859
   Episode_Reward/foot_landing_vel: -0.1325
   Episode_Reward/test_gait_reward: -0.6129
Metrics/base_velocity/error_vel_xy: 1.8884
Metrics/base_velocity/error_vel_yaw: 0.6861
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 1.08s
                        Total time: 712.92s
                               ETA: 2563.5s

################################################################################
                     [1m Learning iteration 653/3000 [0m                      

                       Computation: 90868 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 1.3889
                    Surrogate loss: -0.0022
             Mean action noise std: 0.7363
                     Learning rate: 0.0009
                       Mean reward: 46.12
               Mean episode length: 598.95
       Episode_Reward/keep_balance: 0.6429
     Episode_Reward/rew_lin_vel_xy: 1.9933
      Episode_Reward/rew_ang_vel_z: 1.8210
    Episode_Reward/pen_base_height: -0.2882
      Episode_Reward/pen_lin_vel_z: -0.0578
     Episode_Reward/pen_ang_vel_xy: -0.0884
   Episode_Reward/pen_joint_torque: -0.1441
    Episode_Reward/pen_joint_accel: -0.0826
    Episode_Reward/pen_action_rate: -0.0521
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0310
   Episode_Reward/pen_joint_powers: -0.0481
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1087
Episode_Reward/pen_flat_orientation: -0.1317
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.1828
   Episode_Reward/foot_landing_vel: -0.1289
   Episode_Reward/test_gait_reward: -0.5965
Metrics/base_velocity/error_vel_xy: 1.8290
Metrics/base_velocity/error_vel_yaw: 0.6694
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 1.08s
                        Total time: 714.00s
                               ETA: 2562.3s

################################################################################
                     [1m Learning iteration 654/3000 [0m                      

                       Computation: 90993 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 1.4385
                    Surrogate loss: -0.0029
             Mean action noise std: 0.7372
                     Learning rate: 0.0013
                       Mean reward: 51.60
               Mean episode length: 638.30
       Episode_Reward/keep_balance: 0.6176
     Episode_Reward/rew_lin_vel_xy: 1.9566
      Episode_Reward/rew_ang_vel_z: 1.7416
    Episode_Reward/pen_base_height: -0.2791
      Episode_Reward/pen_lin_vel_z: -0.0569
     Episode_Reward/pen_ang_vel_xy: -0.0878
   Episode_Reward/pen_joint_torque: -0.1379
    Episode_Reward/pen_joint_accel: -0.0825
    Episode_Reward/pen_action_rate: -0.0505
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0298
   Episode_Reward/pen_joint_powers: -0.0464
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1048
Episode_Reward/pen_flat_orientation: -0.1297
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1803
   Episode_Reward/foot_landing_vel: -0.1244
   Episode_Reward/test_gait_reward: -0.5756
Metrics/base_velocity/error_vel_xy: 1.7594
Metrics/base_velocity/error_vel_yaw: 0.6508
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 1.08s
                        Total time: 715.08s
                               ETA: 2561.2s

################################################################################
                     [1m Learning iteration 655/3000 [0m                      

                       Computation: 91248 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 1.3252
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7398
                     Learning rate: 0.0006
                       Mean reward: 60.84
               Mean episode length: 741.93
       Episode_Reward/keep_balance: 0.7009
     Episode_Reward/rew_lin_vel_xy: 2.2858
      Episode_Reward/rew_ang_vel_z: 1.9676
    Episode_Reward/pen_base_height: -0.3018
      Episode_Reward/pen_lin_vel_z: -0.0638
     Episode_Reward/pen_ang_vel_xy: -0.0974
   Episode_Reward/pen_joint_torque: -0.1625
    Episode_Reward/pen_joint_accel: -0.0854
    Episode_Reward/pen_action_rate: -0.0579
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0348
   Episode_Reward/pen_joint_powers: -0.0539
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1219
Episode_Reward/pen_flat_orientation: -0.1470
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2085
   Episode_Reward/foot_landing_vel: -0.1389
   Episode_Reward/test_gait_reward: -0.6489
Metrics/base_velocity/error_vel_xy: 1.9161
Metrics/base_velocity/error_vel_yaw: 0.7451
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 1.08s
                        Total time: 716.16s
                               ETA: 2560.0s

################################################################################
                     [1m Learning iteration 656/3000 [0m                      

                       Computation: 91089 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 1.2825
                    Surrogate loss: -0.0032
             Mean action noise std: 0.7396
                     Learning rate: 0.0009
                       Mean reward: 55.73
               Mean episode length: 700.37
       Episode_Reward/keep_balance: 0.6540
     Episode_Reward/rew_lin_vel_xy: 2.0889
      Episode_Reward/rew_ang_vel_z: 1.8382
    Episode_Reward/pen_base_height: -0.2969
      Episode_Reward/pen_lin_vel_z: -0.0583
     Episode_Reward/pen_ang_vel_xy: -0.0907
   Episode_Reward/pen_joint_torque: -0.1427
    Episode_Reward/pen_joint_accel: -0.0829
    Episode_Reward/pen_action_rate: -0.0535
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0317
   Episode_Reward/pen_joint_powers: -0.0481
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1120
Episode_Reward/pen_flat_orientation: -0.1339
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1918
   Episode_Reward/foot_landing_vel: -0.1248
   Episode_Reward/test_gait_reward: -0.6074
Metrics/base_velocity/error_vel_xy: 1.7962
Metrics/base_velocity/error_vel_yaw: 0.7001
      Episode_Termination/time_out: 2.9167
  Episode_Termination/base_contact: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 1.08s
                        Total time: 717.24s
                               ETA: 2558.9s

################################################################################
                     [1m Learning iteration 657/3000 [0m                      

                       Computation: 90098 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 1.2404
                    Surrogate loss: -0.0036
             Mean action noise std: 0.7402
                     Learning rate: 0.0009
                       Mean reward: 63.11
               Mean episode length: 762.84
       Episode_Reward/keep_balance: 0.7467
     Episode_Reward/rew_lin_vel_xy: 2.5325
      Episode_Reward/rew_ang_vel_z: 2.1086
    Episode_Reward/pen_base_height: -0.3108
      Episode_Reward/pen_lin_vel_z: -0.0665
     Episode_Reward/pen_ang_vel_xy: -0.1048
   Episode_Reward/pen_joint_torque: -0.1683
    Episode_Reward/pen_joint_accel: -0.0942
    Episode_Reward/pen_action_rate: -0.0611
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0363
   Episode_Reward/pen_joint_powers: -0.0566
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.1277
Episode_Reward/pen_flat_orientation: -0.1428
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2172
   Episode_Reward/foot_landing_vel: -0.1472
   Episode_Reward/test_gait_reward: -0.6900
Metrics/base_velocity/error_vel_xy: 1.9771
Metrics/base_velocity/error_vel_yaw: 0.7849
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 1.09s
                        Total time: 718.33s
                               ETA: 2557.8s

################################################################################
                     [1m Learning iteration 658/3000 [0m                      

                       Computation: 90228 steps/s (collection: 0.964s, learning 0.126s)
               Value function loss: 1.2153
                    Surrogate loss: -0.0010
             Mean action noise std: 0.7420
                     Learning rate: 0.0004
                       Mean reward: 66.71
               Mean episode length: 788.14
       Episode_Reward/keep_balance: 0.7639
     Episode_Reward/rew_lin_vel_xy: 2.5315
      Episode_Reward/rew_ang_vel_z: 2.1633
    Episode_Reward/pen_base_height: -0.3150
      Episode_Reward/pen_lin_vel_z: -0.0672
     Episode_Reward/pen_ang_vel_xy: -0.1021
   Episode_Reward/pen_joint_torque: -0.1713
    Episode_Reward/pen_joint_accel: -0.1015
    Episode_Reward/pen_action_rate: -0.0624
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0369
   Episode_Reward/pen_joint_powers: -0.0574
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1304
Episode_Reward/pen_flat_orientation: -0.1436
  Episode_Reward/pen_feet_distance: -0.0029
Episode_Reward/pen_feet_regulation: -0.2217
   Episode_Reward/foot_landing_vel: -0.1511
   Episode_Reward/test_gait_reward: -0.7089
Metrics/base_velocity/error_vel_xy: 2.0780
Metrics/base_velocity/error_vel_yaw: 0.7957
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 1.09s
                        Total time: 719.42s
                               ETA: 2556.7s

################################################################################
                     [1m Learning iteration 659/3000 [0m                      

                       Computation: 89202 steps/s (collection: 0.978s, learning 0.124s)
               Value function loss: 1.1659
                    Surrogate loss: -0.0006
             Mean action noise std: 0.7420
                     Learning rate: 0.0001
                       Mean reward: 56.29
               Mean episode length: 693.25
       Episode_Reward/keep_balance: 0.7100
     Episode_Reward/rew_lin_vel_xy: 2.3023
      Episode_Reward/rew_ang_vel_z: 2.0172
    Episode_Reward/pen_base_height: -0.3045
      Episode_Reward/pen_lin_vel_z: -0.0593
     Episode_Reward/pen_ang_vel_xy: -0.0961
   Episode_Reward/pen_joint_torque: -0.1574
    Episode_Reward/pen_joint_accel: -0.0868
    Episode_Reward/pen_action_rate: -0.0578
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0335
   Episode_Reward/pen_joint_powers: -0.0523
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.1213
Episode_Reward/pen_flat_orientation: -0.1296
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1997
   Episode_Reward/foot_landing_vel: -0.1323
   Episode_Reward/test_gait_reward: -0.6521
Metrics/base_velocity/error_vel_xy: 1.9917
Metrics/base_velocity/error_vel_yaw: 0.7345
      Episode_Termination/time_out: 2.7500
  Episode_Termination/base_contact: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 1.10s
                        Total time: 720.52s
                               ETA: 2555.7s

################################################################################
                     [1m Learning iteration 660/3000 [0m                      

                       Computation: 88990 steps/s (collection: 0.982s, learning 0.122s)
               Value function loss: 1.0823
                    Surrogate loss: -0.0036
             Mean action noise std: 0.7421
                     Learning rate: 0.0003
                       Mean reward: 58.24
               Mean episode length: 711.93
       Episode_Reward/keep_balance: 0.7607
     Episode_Reward/rew_lin_vel_xy: 2.4815
      Episode_Reward/rew_ang_vel_z: 2.1288
    Episode_Reward/pen_base_height: -0.3022
      Episode_Reward/pen_lin_vel_z: -0.0605
     Episode_Reward/pen_ang_vel_xy: -0.0975
   Episode_Reward/pen_joint_torque: -0.1622
    Episode_Reward/pen_joint_accel: -0.0967
    Episode_Reward/pen_action_rate: -0.0617
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0346
   Episode_Reward/pen_joint_powers: -0.0538
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1311
Episode_Reward/pen_flat_orientation: -0.1329
  Episode_Reward/pen_feet_distance: -0.0037
Episode_Reward/pen_feet_regulation: -0.1985
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.6955
Metrics/base_velocity/error_vel_xy: 2.0564
Metrics/base_velocity/error_vel_yaw: 0.8111
      Episode_Termination/time_out: 2.8750
  Episode_Termination/base_contact: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 1.10s
                        Total time: 721.62s
                               ETA: 2554.6s

################################################################################
                     [1m Learning iteration 661/3000 [0m                      

                       Computation: 91204 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.1071
                    Surrogate loss: -0.0016
             Mean action noise std: 0.7421
                     Learning rate: 0.0002
                       Mean reward: 60.86
               Mean episode length: 793.94
       Episode_Reward/keep_balance: 0.7695
     Episode_Reward/rew_lin_vel_xy: 2.2991
      Episode_Reward/rew_ang_vel_z: 2.1443
    Episode_Reward/pen_base_height: -0.3081
      Episode_Reward/pen_lin_vel_z: -0.0633
     Episode_Reward/pen_ang_vel_xy: -0.1006
   Episode_Reward/pen_joint_torque: -0.1698
    Episode_Reward/pen_joint_accel: -0.0982
    Episode_Reward/pen_action_rate: -0.0635
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0357
   Episode_Reward/pen_joint_powers: -0.0560
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.1345
Episode_Reward/pen_flat_orientation: -0.1354
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2164
   Episode_Reward/foot_landing_vel: -0.1395
   Episode_Reward/test_gait_reward: -0.7074
Metrics/base_velocity/error_vel_xy: 2.2560
Metrics/base_velocity/error_vel_yaw: 0.8261
      Episode_Termination/time_out: 2.9167
  Episode_Termination/base_contact: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 1.08s
                        Total time: 722.70s
                               ETA: 2553.5s

################################################################################
                     [1m Learning iteration 662/3000 [0m                      

                       Computation: 89356 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 1.0847
                    Surrogate loss: -0.0030
             Mean action noise std: 0.7430
                     Learning rate: 0.0003
                       Mean reward: 65.99
               Mean episode length: 776.58
       Episode_Reward/keep_balance: 0.7716
     Episode_Reward/rew_lin_vel_xy: 2.5470
      Episode_Reward/rew_ang_vel_z: 2.1838
    Episode_Reward/pen_base_height: -0.3131
      Episode_Reward/pen_lin_vel_z: -0.0659
     Episode_Reward/pen_ang_vel_xy: -0.1016
   Episode_Reward/pen_joint_torque: -0.1700
    Episode_Reward/pen_joint_accel: -0.0867
    Episode_Reward/pen_action_rate: -0.0632
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0363
   Episode_Reward/pen_joint_powers: -0.0572
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1324
Episode_Reward/pen_flat_orientation: -0.1308
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2170
   Episode_Reward/foot_landing_vel: -0.1487
   Episode_Reward/test_gait_reward: -0.7100
Metrics/base_velocity/error_vel_xy: 2.0779
Metrics/base_velocity/error_vel_yaw: 0.8021
      Episode_Termination/time_out: 3.1250
  Episode_Termination/base_contact: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 1.10s
                        Total time: 723.80s
                               ETA: 2552.4s

################################################################################
                     [1m Learning iteration 663/3000 [0m                      

                       Computation: 90259 steps/s (collection: 0.956s, learning 0.133s)
               Value function loss: 1.0351
                    Surrogate loss: -0.0020
             Mean action noise std: 0.7443
                     Learning rate: 0.0006
                       Mean reward: 65.11
               Mean episode length: 786.37
       Episode_Reward/keep_balance: 0.7786
     Episode_Reward/rew_lin_vel_xy: 2.5520
      Episode_Reward/rew_ang_vel_z: 2.1806
    Episode_Reward/pen_base_height: -0.3171
      Episode_Reward/pen_lin_vel_z: -0.0644
     Episode_Reward/pen_ang_vel_xy: -0.1058
   Episode_Reward/pen_joint_torque: -0.1751
    Episode_Reward/pen_joint_accel: -0.0981
    Episode_Reward/pen_action_rate: -0.0641
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0377
   Episode_Reward/pen_joint_powers: -0.0579
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1355
Episode_Reward/pen_flat_orientation: -0.1435
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2233
   Episode_Reward/foot_landing_vel: -0.1539
   Episode_Reward/test_gait_reward: -0.7157
Metrics/base_velocity/error_vel_xy: 2.1906
Metrics/base_velocity/error_vel_yaw: 0.8276
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 1.09s
                        Total time: 724.89s
                               ETA: 2551.3s

################################################################################
                     [1m Learning iteration 664/3000 [0m                      

                       Computation: 91904 steps/s (collection: 0.945s, learning 0.125s)
               Value function loss: 1.0867
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7442
                     Learning rate: 0.0004
                       Mean reward: 61.45
               Mean episode length: 759.23
       Episode_Reward/keep_balance: 0.7585
     Episode_Reward/rew_lin_vel_xy: 2.4993
      Episode_Reward/rew_ang_vel_z: 2.0819
    Episode_Reward/pen_base_height: -0.2977
      Episode_Reward/pen_lin_vel_z: -0.0639
     Episode_Reward/pen_ang_vel_xy: -0.1037
   Episode_Reward/pen_joint_torque: -0.1691
    Episode_Reward/pen_joint_accel: -0.0923
    Episode_Reward/pen_action_rate: -0.0636
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0363
   Episode_Reward/pen_joint_powers: -0.0562
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1345
Episode_Reward/pen_flat_orientation: -0.1489
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2224
   Episode_Reward/foot_landing_vel: -0.1464
   Episode_Reward/test_gait_reward: -0.6974
Metrics/base_velocity/error_vel_xy: 2.0035
Metrics/base_velocity/error_vel_yaw: 0.8379
      Episode_Termination/time_out: 2.7917
  Episode_Termination/base_contact: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 1.07s
                        Total time: 725.96s
                               ETA: 2550.1s

################################################################################
                     [1m Learning iteration 665/3000 [0m                      

                       Computation: 91338 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 1.0032
                    Surrogate loss: -0.0022
             Mean action noise std: 0.7435
                     Learning rate: 0.0004
                       Mean reward: 69.02
               Mean episode length: 798.39
       Episode_Reward/keep_balance: 0.8049
     Episode_Reward/rew_lin_vel_xy: 2.7712
      Episode_Reward/rew_ang_vel_z: 2.2714
    Episode_Reward/pen_base_height: -0.3168
      Episode_Reward/pen_lin_vel_z: -0.0693
     Episode_Reward/pen_ang_vel_xy: -0.1083
   Episode_Reward/pen_joint_torque: -0.1814
    Episode_Reward/pen_joint_accel: -0.1029
    Episode_Reward/pen_action_rate: -0.0664
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0388
   Episode_Reward/pen_joint_powers: -0.0605
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1389
Episode_Reward/pen_flat_orientation: -0.1403
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.2330
   Episode_Reward/foot_landing_vel: -0.1552
   Episode_Reward/test_gait_reward: -0.7484
Metrics/base_velocity/error_vel_xy: 2.1571
Metrics/base_velocity/error_vel_yaw: 0.8404
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 1.08s
                        Total time: 727.04s
                               ETA: 2549.0s

################################################################################
                     [1m Learning iteration 666/3000 [0m                      

                       Computation: 91679 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 1.1926
                    Surrogate loss: -0.0004
             Mean action noise std: 0.7440
                     Learning rate: 0.0002
                       Mean reward: 68.24
               Mean episode length: 820.59
       Episode_Reward/keep_balance: 0.8332
     Episode_Reward/rew_lin_vel_xy: 2.7021
      Episode_Reward/rew_ang_vel_z: 2.3432
    Episode_Reward/pen_base_height: -0.3223
      Episode_Reward/pen_lin_vel_z: -0.0696
     Episode_Reward/pen_ang_vel_xy: -0.1097
   Episode_Reward/pen_joint_torque: -0.1881
    Episode_Reward/pen_joint_accel: -0.1044
    Episode_Reward/pen_action_rate: -0.0689
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0390
   Episode_Reward/pen_joint_powers: -0.0618
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1440
Episode_Reward/pen_flat_orientation: -0.1341
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2296
   Episode_Reward/foot_landing_vel: -0.1640
   Episode_Reward/test_gait_reward: -0.7699
Metrics/base_velocity/error_vel_xy: 2.2472
Metrics/base_velocity/error_vel_yaw: 0.8814
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 1.07s
                        Total time: 728.11s
                               ETA: 2547.8s

################################################################################
                     [1m Learning iteration 667/3000 [0m                      

                       Computation: 92294 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.9983
                    Surrogate loss: -0.0035
             Mean action noise std: 0.7454
                     Learning rate: 0.0004
                       Mean reward: 71.29
               Mean episode length: 822.28
       Episode_Reward/keep_balance: 0.8353
     Episode_Reward/rew_lin_vel_xy: 2.7497
      Episode_Reward/rew_ang_vel_z: 2.3634
    Episode_Reward/pen_base_height: -0.3189
      Episode_Reward/pen_lin_vel_z: -0.0664
     Episode_Reward/pen_ang_vel_xy: -0.1110
   Episode_Reward/pen_joint_torque: -0.1840
    Episode_Reward/pen_joint_accel: -0.0965
    Episode_Reward/pen_action_rate: -0.0687
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0380
   Episode_Reward/pen_joint_powers: -0.0608
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1448
Episode_Reward/pen_flat_orientation: -0.1344
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2313
   Episode_Reward/foot_landing_vel: -0.1467
   Episode_Reward/test_gait_reward: -0.7634
Metrics/base_velocity/error_vel_xy: 2.2523
Metrics/base_velocity/error_vel_yaw: 0.8731
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 1.07s
                        Total time: 729.18s
                               ETA: 2546.7s

################################################################################
                     [1m Learning iteration 668/3000 [0m                      

                       Computation: 90998 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 1.0517
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7467
                     Learning rate: 0.0004
                       Mean reward: 72.86
               Mean episode length: 820.78
       Episode_Reward/keep_balance: 0.8194
     Episode_Reward/rew_lin_vel_xy: 2.8987
      Episode_Reward/rew_ang_vel_z: 2.2968
    Episode_Reward/pen_base_height: -0.3179
      Episode_Reward/pen_lin_vel_z: -0.0651
     Episode_Reward/pen_ang_vel_xy: -0.1098
   Episode_Reward/pen_joint_torque: -0.1766
    Episode_Reward/pen_joint_accel: -0.0997
    Episode_Reward/pen_action_rate: -0.0678
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0367
   Episode_Reward/pen_joint_powers: -0.0582
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1438
Episode_Reward/pen_flat_orientation: -0.1362
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.2090
   Episode_Reward/foot_landing_vel: -0.1429
   Episode_Reward/test_gait_reward: -0.7472
Metrics/base_velocity/error_vel_xy: 2.0561
Metrics/base_velocity/error_vel_yaw: 0.8717
      Episode_Termination/time_out: 3.0000
  Episode_Termination/base_contact: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 1.08s
                        Total time: 730.26s
                               ETA: 2545.5s

################################################################################
                     [1m Learning iteration 669/3000 [0m                      

                       Computation: 90769 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 1.0603
                    Surrogate loss: -0.0006
             Mean action noise std: 0.7472
                     Learning rate: 0.0004
                       Mean reward: 65.42
               Mean episode length: 766.84
       Episode_Reward/keep_balance: 0.7532
     Episode_Reward/rew_lin_vel_xy: 2.3540
      Episode_Reward/rew_ang_vel_z: 2.1222
    Episode_Reward/pen_base_height: -0.3066
      Episode_Reward/pen_lin_vel_z: -0.0635
     Episode_Reward/pen_ang_vel_xy: -0.1020
   Episode_Reward/pen_joint_torque: -0.1703
    Episode_Reward/pen_joint_accel: -0.0908
    Episode_Reward/pen_action_rate: -0.0621
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0359
   Episode_Reward/pen_joint_powers: -0.0556
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.1303
Episode_Reward/pen_flat_orientation: -0.1471
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2162
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.6994
Metrics/base_velocity/error_vel_xy: 2.1953
Metrics/base_velocity/error_vel_yaw: 0.7967
      Episode_Termination/time_out: 2.7083
  Episode_Termination/base_contact: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 1.08s
                        Total time: 731.34s
                               ETA: 2544.4s

################################################################################
                     [1m Learning iteration 670/3000 [0m                      

                       Computation: 90896 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 1.0752
                    Surrogate loss: 0.0014
             Mean action noise std: 0.7479
                     Learning rate: 0.0001
                       Mean reward: 69.63
               Mean episode length: 856.20
       Episode_Reward/keep_balance: 0.8701
     Episode_Reward/rew_lin_vel_xy: 2.8201
      Episode_Reward/rew_ang_vel_z: 2.4373
    Episode_Reward/pen_base_height: -0.3386
      Episode_Reward/pen_lin_vel_z: -0.0706
     Episode_Reward/pen_ang_vel_xy: -0.1195
   Episode_Reward/pen_joint_torque: -0.1934
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.0724
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0407
   Episode_Reward/pen_joint_powers: -0.0642
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.1517
Episode_Reward/pen_flat_orientation: -0.1528
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2491
   Episode_Reward/foot_landing_vel: -0.1634
   Episode_Reward/test_gait_reward: -0.8015
Metrics/base_velocity/error_vel_xy: 2.4365
Metrics/base_velocity/error_vel_yaw: 0.9273
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 1.08s
                        Total time: 732.42s
                               ETA: 2543.3s

################################################################################
                     [1m Learning iteration 671/3000 [0m                      

                       Computation: 89877 steps/s (collection: 0.967s, learning 0.127s)
               Value function loss: 1.0925
                    Surrogate loss: -0.0023
             Mean action noise std: 0.7486
                     Learning rate: 0.0001
                       Mean reward: 68.83
               Mean episode length: 836.52
       Episode_Reward/keep_balance: 0.8381
     Episode_Reward/rew_lin_vel_xy: 2.6366
      Episode_Reward/rew_ang_vel_z: 2.3559
    Episode_Reward/pen_base_height: -0.3142
      Episode_Reward/pen_lin_vel_z: -0.0683
     Episode_Reward/pen_ang_vel_xy: -0.1149
   Episode_Reward/pen_joint_torque: -0.1832
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.0706
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0392
   Episode_Reward/pen_joint_powers: -0.0612
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1484
Episode_Reward/pen_flat_orientation: -0.1348
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.2331
   Episode_Reward/foot_landing_vel: -0.1636
   Episode_Reward/test_gait_reward: -0.7684
Metrics/base_velocity/error_vel_xy: 2.3101
Metrics/base_velocity/error_vel_yaw: 0.8830
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 1.09s
                        Total time: 733.51s
                               ETA: 2542.2s

################################################################################
                     [1m Learning iteration 672/3000 [0m                      

                       Computation: 90379 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 1.1561
                    Surrogate loss: -0.0040
             Mean action noise std: 0.7485
                     Learning rate: 0.0003
                       Mean reward: 70.24
               Mean episode length: 836.33
       Episode_Reward/keep_balance: 0.8509
     Episode_Reward/rew_lin_vel_xy: 2.8201
      Episode_Reward/rew_ang_vel_z: 2.3742
    Episode_Reward/pen_base_height: -0.3393
      Episode_Reward/pen_lin_vel_z: -0.0704
     Episode_Reward/pen_ang_vel_xy: -0.1151
   Episode_Reward/pen_joint_torque: -0.1943
    Episode_Reward/pen_joint_accel: -0.1044
    Episode_Reward/pen_action_rate: -0.0712
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0403
   Episode_Reward/pen_joint_powers: -0.0645
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1487
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2461
   Episode_Reward/foot_landing_vel: -0.1591
   Episode_Reward/test_gait_reward: -0.7836
Metrics/base_velocity/error_vel_xy: 2.2463
Metrics/base_velocity/error_vel_yaw: 0.9133
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 1.09s
                        Total time: 734.60s
                               ETA: 2541.1s

################################################################################
                     [1m Learning iteration 673/3000 [0m                      

                       Computation: 91050 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 1.0743
                    Surrogate loss: -0.0006
             Mean action noise std: 0.7488
                     Learning rate: 0.0002
                       Mean reward: 67.34
               Mean episode length: 811.87
       Episode_Reward/keep_balance: 0.8016
     Episode_Reward/rew_lin_vel_xy: 2.7575
      Episode_Reward/rew_ang_vel_z: 2.2424
    Episode_Reward/pen_base_height: -0.3167
      Episode_Reward/pen_lin_vel_z: -0.0666
     Episode_Reward/pen_ang_vel_xy: -0.1137
   Episode_Reward/pen_joint_torque: -0.1788
    Episode_Reward/pen_joint_accel: -0.1013
    Episode_Reward/pen_action_rate: -0.0677
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0385
   Episode_Reward/pen_joint_powers: -0.0601
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1424
Episode_Reward/pen_flat_orientation: -0.1527
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2308
   Episode_Reward/foot_landing_vel: -0.1517
   Episode_Reward/test_gait_reward: -0.7417
Metrics/base_velocity/error_vel_xy: 2.0700
Metrics/base_velocity/error_vel_yaw: 0.8606
      Episode_Termination/time_out: 2.9583
  Episode_Termination/base_contact: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 1.08s
                        Total time: 735.68s
                               ETA: 2540.0s

################################################################################
                     [1m Learning iteration 674/3000 [0m                      

                       Computation: 89922 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 1.0834
                    Surrogate loss: -0.0011
             Mean action noise std: 0.7487
                     Learning rate: 0.0001
                       Mean reward: 74.79
               Mean episode length: 868.20
       Episode_Reward/keep_balance: 0.8666
     Episode_Reward/rew_lin_vel_xy: 2.9736
      Episode_Reward/rew_ang_vel_z: 2.4096
    Episode_Reward/pen_base_height: -0.3290
      Episode_Reward/pen_lin_vel_z: -0.0727
     Episode_Reward/pen_ang_vel_xy: -0.1199
   Episode_Reward/pen_joint_torque: -0.1937
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.0730
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0653
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1530
Episode_Reward/pen_flat_orientation: -0.1550
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2591
   Episode_Reward/foot_landing_vel: -0.1644
   Episode_Reward/test_gait_reward: -0.7990
Metrics/base_velocity/error_vel_xy: 2.3163
Metrics/base_velocity/error_vel_yaw: 0.9351
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 1.09s
                        Total time: 736.77s
                               ETA: 2538.9s

################################################################################
                     [1m Learning iteration 675/3000 [0m                      

                       Computation: 89626 steps/s (collection: 0.971s, learning 0.126s)
               Value function loss: 1.1565
                    Surrogate loss: -0.0031
             Mean action noise std: 0.7481
                     Learning rate: 0.0002
                       Mean reward: 80.60
               Mean episode length: 901.28
       Episode_Reward/keep_balance: 0.8977
     Episode_Reward/rew_lin_vel_xy: 3.0822
      Episode_Reward/rew_ang_vel_z: 2.5385
    Episode_Reward/pen_base_height: -0.3242
      Episode_Reward/pen_lin_vel_z: -0.0688
     Episode_Reward/pen_ang_vel_xy: -0.1210
   Episode_Reward/pen_joint_torque: -0.1960
    Episode_Reward/pen_joint_accel: -0.1202
    Episode_Reward/pen_action_rate: -0.0753
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0648
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1584
Episode_Reward/pen_flat_orientation: -0.1402
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.2417
   Episode_Reward/foot_landing_vel: -0.1636
   Episode_Reward/test_gait_reward: -0.8196
Metrics/base_velocity/error_vel_xy: 2.3620
Metrics/base_velocity/error_vel_yaw: 0.9392
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 1.10s
                        Total time: 737.87s
                               ETA: 2537.8s

################################################################################
                     [1m Learning iteration 676/3000 [0m                      

                       Computation: 90296 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 1.0940
                    Surrogate loss: -0.0037
             Mean action noise std: 0.7490
                     Learning rate: 0.0004
                       Mean reward: 74.16
               Mean episode length: 840.44
       Episode_Reward/keep_balance: 0.8760
     Episode_Reward/rew_lin_vel_xy: 3.0696
      Episode_Reward/rew_ang_vel_z: 2.4517
    Episode_Reward/pen_base_height: -0.3244
      Episode_Reward/pen_lin_vel_z: -0.0720
     Episode_Reward/pen_ang_vel_xy: -0.1212
   Episode_Reward/pen_joint_torque: -0.2049
    Episode_Reward/pen_joint_accel: -0.1167
    Episode_Reward/pen_action_rate: -0.0742
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0426
   Episode_Reward/pen_joint_powers: -0.0666
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1544
Episode_Reward/pen_flat_orientation: -0.1453
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2617
   Episode_Reward/foot_landing_vel: -0.1639
   Episode_Reward/test_gait_reward: -0.8110
Metrics/base_velocity/error_vel_xy: 2.3700
Metrics/base_velocity/error_vel_yaw: 0.9323
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 1.09s
                        Total time: 738.96s
                               ETA: 2536.7s

################################################################################
                     [1m Learning iteration 677/3000 [0m                      

                       Computation: 90767 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 1.0740
                    Surrogate loss: -0.0024
             Mean action noise std: 0.7503
                     Learning rate: 0.0004
                       Mean reward: 70.53
               Mean episode length: 851.96
       Episode_Reward/keep_balance: 0.8606
     Episode_Reward/rew_lin_vel_xy: 2.7847
      Episode_Reward/rew_ang_vel_z: 2.4249
    Episode_Reward/pen_base_height: -0.3061
      Episode_Reward/pen_lin_vel_z: -0.0693
     Episode_Reward/pen_ang_vel_xy: -0.1153
   Episode_Reward/pen_joint_torque: -0.1931
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.0726
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0401
   Episode_Reward/pen_joint_powers: -0.0630
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1519
Episode_Reward/pen_flat_orientation: -0.1487
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.2436
   Episode_Reward/foot_landing_vel: -0.1586
   Episode_Reward/test_gait_reward: -0.7897
Metrics/base_velocity/error_vel_xy: 2.3605
Metrics/base_velocity/error_vel_yaw: 0.9041
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 1.08s
                        Total time: 740.04s
                               ETA: 2535.6s

################################################################################
                     [1m Learning iteration 678/3000 [0m                      

                       Computation: 91323 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 1.0946
                    Surrogate loss: -0.0024
             Mean action noise std: 0.7511
                     Learning rate: 0.0006
                       Mean reward: 70.21
               Mean episode length: 832.61
       Episode_Reward/keep_balance: 0.8259
     Episode_Reward/rew_lin_vel_xy: 2.6886
      Episode_Reward/rew_ang_vel_z: 2.2788
    Episode_Reward/pen_base_height: -0.3107
      Episode_Reward/pen_lin_vel_z: -0.0658
     Episode_Reward/pen_ang_vel_xy: -0.1152
   Episode_Reward/pen_joint_torque: -0.1793
    Episode_Reward/pen_joint_accel: -0.1030
    Episode_Reward/pen_action_rate: -0.0708
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0386
   Episode_Reward/pen_joint_powers: -0.0601
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.1499
Episode_Reward/pen_flat_orientation: -0.1474
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2330
   Episode_Reward/foot_landing_vel: -0.1450
   Episode_Reward/test_gait_reward: -0.7575
Metrics/base_velocity/error_vel_xy: 2.2990
Metrics/base_velocity/error_vel_yaw: 0.9147
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 1.08s
                        Total time: 741.12s
                               ETA: 2534.4s

################################################################################
                     [1m Learning iteration 679/3000 [0m                      

                       Computation: 91734 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 1.0967
                    Surrogate loss: -0.0033
             Mean action noise std: 0.7512
                     Learning rate: 0.0009
                       Mean reward: 77.24
               Mean episode length: 866.16
       Episode_Reward/keep_balance: 0.8635
     Episode_Reward/rew_lin_vel_xy: 2.8911
      Episode_Reward/rew_ang_vel_z: 2.4196
    Episode_Reward/pen_base_height: -0.3127
      Episode_Reward/pen_lin_vel_z: -0.0638
     Episode_Reward/pen_ang_vel_xy: -0.1158
   Episode_Reward/pen_joint_torque: -0.1813
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.0727
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0384
   Episode_Reward/pen_joint_powers: -0.0601
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1543
Episode_Reward/pen_flat_orientation: -0.1370
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.2306
   Episode_Reward/foot_landing_vel: -0.1456
   Episode_Reward/test_gait_reward: -0.7868
Metrics/base_velocity/error_vel_xy: 2.3474
Metrics/base_velocity/error_vel_yaw: 0.9209
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 1.07s
                        Total time: 742.19s
                               ETA: 2533.3s

################################################################################
                     [1m Learning iteration 680/3000 [0m                      

                       Computation: 91019 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 1.1332
                    Surrogate loss: -0.0029
             Mean action noise std: 0.7516
                     Learning rate: 0.0013
                       Mean reward: 73.13
               Mean episode length: 842.32
       Episode_Reward/keep_balance: 0.8505
     Episode_Reward/rew_lin_vel_xy: 2.8443
      Episode_Reward/rew_ang_vel_z: 2.3872
    Episode_Reward/pen_base_height: -0.3113
      Episode_Reward/pen_lin_vel_z: -0.0640
     Episode_Reward/pen_ang_vel_xy: -0.1153
   Episode_Reward/pen_joint_torque: -0.1821
    Episode_Reward/pen_joint_accel: -0.0985
    Episode_Reward/pen_action_rate: -0.0727
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0377
   Episode_Reward/pen_joint_powers: -0.0598
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1537
Episode_Reward/pen_flat_orientation: -0.1381
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2241
   Episode_Reward/foot_landing_vel: -0.1421
   Episode_Reward/test_gait_reward: -0.7756
Metrics/base_velocity/error_vel_xy: 2.3296
Metrics/base_velocity/error_vel_yaw: 0.9068
      Episode_Termination/time_out: 2.9167
  Episode_Termination/base_contact: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 1.08s
                        Total time: 743.27s
                               ETA: 2532.1s

################################################################################
                     [1m Learning iteration 681/3000 [0m                      

                       Computation: 91224 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.1816
                    Surrogate loss: 0.0001
             Mean action noise std: 0.7528
                     Learning rate: 0.0004
                       Mean reward: 80.02
               Mean episode length: 877.21
       Episode_Reward/keep_balance: 0.8808
     Episode_Reward/rew_lin_vel_xy: 3.1564
      Episode_Reward/rew_ang_vel_z: 2.4647
    Episode_Reward/pen_base_height: -0.3199
      Episode_Reward/pen_lin_vel_z: -0.0658
     Episode_Reward/pen_ang_vel_xy: -0.1163
   Episode_Reward/pen_joint_torque: -0.1886
    Episode_Reward/pen_joint_accel: -0.1005
    Episode_Reward/pen_action_rate: -0.0742
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0396
   Episode_Reward/pen_joint_powers: -0.0625
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1565
Episode_Reward/pen_flat_orientation: -0.1424
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2335
   Episode_Reward/foot_landing_vel: -0.1539
   Episode_Reward/test_gait_reward: -0.8089
Metrics/base_velocity/error_vel_xy: 2.1283
Metrics/base_velocity/error_vel_yaw: 0.9347
      Episode_Termination/time_out: 3.2500
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 1.08s
                        Total time: 744.35s
                               ETA: 2531.0s

################################################################################
                     [1m Learning iteration 682/3000 [0m                      

                       Computation: 91177 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.2164
                    Surrogate loss: -0.0042
             Mean action noise std: 0.7542
                     Learning rate: 0.0009
                       Mean reward: 73.68
               Mean episode length: 863.82
       Episode_Reward/keep_balance: 0.8718
     Episode_Reward/rew_lin_vel_xy: 2.9029
      Episode_Reward/rew_ang_vel_z: 2.4158
    Episode_Reward/pen_base_height: -0.3194
      Episode_Reward/pen_lin_vel_z: -0.0642
     Episode_Reward/pen_ang_vel_xy: -0.1165
   Episode_Reward/pen_joint_torque: -0.1881
    Episode_Reward/pen_joint_accel: -0.1000
    Episode_Reward/pen_action_rate: -0.0741
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0399
   Episode_Reward/pen_joint_powers: -0.0625
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1557
Episode_Reward/pen_flat_orientation: -0.1411
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2467
   Episode_Reward/foot_landing_vel: -0.1555
   Episode_Reward/test_gait_reward: -0.8003
Metrics/base_velocity/error_vel_xy: 2.3900
Metrics/base_velocity/error_vel_yaw: 0.9441
      Episode_Termination/time_out: 3.0833
  Episode_Termination/base_contact: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 1.08s
                        Total time: 745.43s
                               ETA: 2529.9s

################################################################################
                     [1m Learning iteration 683/3000 [0m                      

                       Computation: 89325 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 1.1680
                    Surrogate loss: -0.0015
             Mean action noise std: 0.7552
                     Learning rate: 0.0004
                       Mean reward: 73.74
               Mean episode length: 837.30
       Episode_Reward/keep_balance: 0.8237
     Episode_Reward/rew_lin_vel_xy: 2.8040
      Episode_Reward/rew_ang_vel_z: 2.2847
    Episode_Reward/pen_base_height: -0.3007
      Episode_Reward/pen_lin_vel_z: -0.0603
     Episode_Reward/pen_ang_vel_xy: -0.1172
   Episode_Reward/pen_joint_torque: -0.1749
    Episode_Reward/pen_joint_accel: -0.0962
    Episode_Reward/pen_action_rate: -0.0704
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0377
   Episode_Reward/pen_joint_powers: -0.0587
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1494
Episode_Reward/pen_flat_orientation: -0.1375
  Episode_Reward/pen_feet_distance: -0.0036
Episode_Reward/pen_feet_regulation: -0.2233
   Episode_Reward/foot_landing_vel: -0.1428
   Episode_Reward/test_gait_reward: -0.7566
Metrics/base_velocity/error_vel_xy: 2.1595
Metrics/base_velocity/error_vel_yaw: 0.8956
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 1.10s
                        Total time: 746.53s
                               ETA: 2528.8s

################################################################################
                     [1m Learning iteration 684/3000 [0m                      

                       Computation: 91707 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 1.2297
                    Surrogate loss: -0.0008
             Mean action noise std: 0.7552
                     Learning rate: 0.0003
                       Mean reward: 81.22
               Mean episode length: 881.13
       Episode_Reward/keep_balance: 0.8801
     Episode_Reward/rew_lin_vel_xy: 3.0471
      Episode_Reward/rew_ang_vel_z: 2.4866
    Episode_Reward/pen_base_height: -0.3075
      Episode_Reward/pen_lin_vel_z: -0.0635
     Episode_Reward/pen_ang_vel_xy: -0.1174
   Episode_Reward/pen_joint_torque: -0.1861
    Episode_Reward/pen_joint_accel: -0.0947
    Episode_Reward/pen_action_rate: -0.0740
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0378
   Episode_Reward/pen_joint_powers: -0.0606
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1573
Episode_Reward/pen_flat_orientation: -0.1398
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2179
   Episode_Reward/foot_landing_vel: -0.1439
   Episode_Reward/test_gait_reward: -0.7960
Metrics/base_velocity/error_vel_xy: 2.2215
Metrics/base_velocity/error_vel_yaw: 0.9206
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 1.07s
                        Total time: 747.60s
                               ETA: 2527.6s

################################################################################
                     [1m Learning iteration 685/3000 [0m                      

                       Computation: 92466 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 1.0291
                    Surrogate loss: -0.0043
             Mean action noise std: 0.7555
                     Learning rate: 0.0006
                       Mean reward: 69.74
               Mean episode length: 792.79
       Episode_Reward/keep_balance: 0.8150
     Episode_Reward/rew_lin_vel_xy: 2.8597
      Episode_Reward/rew_ang_vel_z: 2.2765
    Episode_Reward/pen_base_height: -0.3086
      Episode_Reward/pen_lin_vel_z: -0.0622
     Episode_Reward/pen_ang_vel_xy: -0.1180
   Episode_Reward/pen_joint_torque: -0.1716
    Episode_Reward/pen_joint_accel: -0.0998
    Episode_Reward/pen_action_rate: -0.0710
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0381
   Episode_Reward/pen_joint_powers: -0.0593
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1491
Episode_Reward/pen_flat_orientation: -0.1451
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2359
   Episode_Reward/foot_landing_vel: -0.1448
   Episode_Reward/test_gait_reward: -0.7513
Metrics/base_velocity/error_vel_xy: 2.0564
Metrics/base_velocity/error_vel_yaw: 0.8776
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 1.06s
                        Total time: 748.66s
                               ETA: 2526.5s

################################################################################
                     [1m Learning iteration 686/3000 [0m                      

                       Computation: 93292 steps/s (collection: 0.931s, learning 0.123s)
               Value function loss: 1.1545
                    Surrogate loss: -0.0024
             Mean action noise std: 0.7582
                     Learning rate: 0.0004
                       Mean reward: 70.57
               Mean episode length: 817.59
       Episode_Reward/keep_balance: 0.8331
     Episode_Reward/rew_lin_vel_xy: 2.8461
      Episode_Reward/rew_ang_vel_z: 2.2905
    Episode_Reward/pen_base_height: -0.3085
      Episode_Reward/pen_lin_vel_z: -0.0592
     Episode_Reward/pen_ang_vel_xy: -0.1164
   Episode_Reward/pen_joint_torque: -0.1752
    Episode_Reward/pen_joint_accel: -0.1012
    Episode_Reward/pen_action_rate: -0.0723
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0384
   Episode_Reward/pen_joint_powers: -0.0591
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1543
Episode_Reward/pen_flat_orientation: -0.1473
  Episode_Reward/pen_feet_distance: -0.0027
Episode_Reward/pen_feet_regulation: -0.2295
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.7612
Metrics/base_velocity/error_vel_xy: 2.1369
Metrics/base_velocity/error_vel_yaw: 0.9262
      Episode_Termination/time_out: 2.8750
  Episode_Termination/base_contact: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 1.05s
                        Total time: 749.72s
                               ETA: 2525.2s

################################################################################
                     [1m Learning iteration 687/3000 [0m                      

                       Computation: 91687 steps/s (collection: 0.947s, learning 0.125s)
               Value function loss: 1.1551
                    Surrogate loss: -0.0038
             Mean action noise std: 0.7601
                     Learning rate: 0.0006
                       Mean reward: 69.64
               Mean episode length: 803.29
       Episode_Reward/keep_balance: 0.8420
     Episode_Reward/rew_lin_vel_xy: 2.8537
      Episode_Reward/rew_ang_vel_z: 2.3425
    Episode_Reward/pen_base_height: -0.3112
      Episode_Reward/pen_lin_vel_z: -0.0601
     Episode_Reward/pen_ang_vel_xy: -0.1191
   Episode_Reward/pen_joint_torque: -0.1769
    Episode_Reward/pen_joint_accel: -0.0948
    Episode_Reward/pen_action_rate: -0.0722
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0369
   Episode_Reward/pen_joint_powers: -0.0589
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1525
Episode_Reward/pen_flat_orientation: -0.1348
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.2288
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.7688
Metrics/base_velocity/error_vel_xy: 2.2197
Metrics/base_velocity/error_vel_yaw: 0.9122
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 1.07s
                        Total time: 750.79s
                               ETA: 2524.1s

################################################################################
                     [1m Learning iteration 688/3000 [0m                      

                       Computation: 89787 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 1.1656
                    Surrogate loss: -0.0025
             Mean action noise std: 0.7609
                     Learning rate: 0.0006
                       Mean reward: 69.72
               Mean episode length: 796.10
       Episode_Reward/keep_balance: 0.7857
     Episode_Reward/rew_lin_vel_xy: 2.7846
      Episode_Reward/rew_ang_vel_z: 2.1633
    Episode_Reward/pen_base_height: -0.3005
      Episode_Reward/pen_lin_vel_z: -0.0616
     Episode_Reward/pen_ang_vel_xy: -0.1167
   Episode_Reward/pen_joint_torque: -0.1734
    Episode_Reward/pen_joint_accel: -0.0984
    Episode_Reward/pen_action_rate: -0.0688
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0378
   Episode_Reward/pen_joint_powers: -0.0582
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1441
Episode_Reward/pen_flat_orientation: -0.1513
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2319
   Episode_Reward/foot_landing_vel: -0.1461
   Episode_Reward/test_gait_reward: -0.7295
Metrics/base_velocity/error_vel_xy: 2.0246
Metrics/base_velocity/error_vel_yaw: 0.8735
      Episode_Termination/time_out: 2.8750
  Episode_Termination/base_contact: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 1.09s
                        Total time: 751.88s
                               ETA: 2523.0s

################################################################################
                     [1m Learning iteration 689/3000 [0m                      

                       Computation: 91174 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 1.0970
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7610
                     Learning rate: 0.0006
                       Mean reward: 72.24
               Mean episode length: 859.18
       Episode_Reward/keep_balance: 0.8767
     Episode_Reward/rew_lin_vel_xy: 2.9772
      Episode_Reward/rew_ang_vel_z: 2.4219
    Episode_Reward/pen_base_height: -0.3208
      Episode_Reward/pen_lin_vel_z: -0.0685
     Episode_Reward/pen_ang_vel_xy: -0.1294
   Episode_Reward/pen_joint_torque: -0.1924
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.0772
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0421
   Episode_Reward/pen_joint_powers: -0.0646
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1628
Episode_Reward/pen_flat_orientation: -0.1592
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2650
   Episode_Reward/foot_landing_vel: -0.1570
   Episode_Reward/test_gait_reward: -0.8074
Metrics/base_velocity/error_vel_xy: 2.3321
Metrics/base_velocity/error_vel_yaw: 0.9623
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 1.08s
                        Total time: 752.96s
                               ETA: 2521.9s

################################################################################
                     [1m Learning iteration 690/3000 [0m                      

                       Computation: 90585 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 1.1513
                    Surrogate loss: 0.0011
             Mean action noise std: 0.7619
                     Learning rate: 0.0001
                       Mean reward: 70.49
               Mean episode length: 821.24
       Episode_Reward/keep_balance: 0.8252
     Episode_Reward/rew_lin_vel_xy: 2.8012
      Episode_Reward/rew_ang_vel_z: 2.2902
    Episode_Reward/pen_base_height: -0.2998
      Episode_Reward/pen_lin_vel_z: -0.0607
     Episode_Reward/pen_ang_vel_xy: -0.1184
   Episode_Reward/pen_joint_torque: -0.1791
    Episode_Reward/pen_joint_accel: -0.0999
    Episode_Reward/pen_action_rate: -0.0713
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0375
   Episode_Reward/pen_joint_powers: -0.0595
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1502
Episode_Reward/pen_flat_orientation: -0.1481
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.2299
   Episode_Reward/foot_landing_vel: -0.1381
   Episode_Reward/test_gait_reward: -0.7563
Metrics/base_velocity/error_vel_xy: 2.2437
Metrics/base_velocity/error_vel_yaw: 0.8976
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 1.09s
                        Total time: 754.05s
                               ETA: 2520.8s

################################################################################
                     [1m Learning iteration 691/3000 [0m                      

                       Computation: 90471 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 1.1608
                    Surrogate loss: -0.0046
             Mean action noise std: 0.7637
                     Learning rate: 0.0003
                       Mean reward: 82.01
               Mean episode length: 901.73
       Episode_Reward/keep_balance: 0.9039
     Episode_Reward/rew_lin_vel_xy: 3.2375
      Episode_Reward/rew_ang_vel_z: 2.5231
    Episode_Reward/pen_base_height: -0.3209
      Episode_Reward/pen_lin_vel_z: -0.0672
     Episode_Reward/pen_ang_vel_xy: -0.1254
   Episode_Reward/pen_joint_torque: -0.1944
    Episode_Reward/pen_joint_accel: -0.1148
    Episode_Reward/pen_action_rate: -0.0784
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0416
   Episode_Reward/pen_joint_powers: -0.0649
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1651
Episode_Reward/pen_flat_orientation: -0.1490
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2568
   Episode_Reward/foot_landing_vel: -0.1555
   Episode_Reward/test_gait_reward: -0.8303
Metrics/base_velocity/error_vel_xy: 2.3343
Metrics/base_velocity/error_vel_yaw: 0.9648
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 1.09s
                        Total time: 755.13s
                               ETA: 2519.7s

################################################################################
                     [1m Learning iteration 692/3000 [0m                      

                       Computation: 91475 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 1.1188
                    Surrogate loss: -0.0022
             Mean action noise std: 0.7649
                     Learning rate: 0.0003
                       Mean reward: 78.20
               Mean episode length: 889.45
       Episode_Reward/keep_balance: 0.8906
     Episode_Reward/rew_lin_vel_xy: 3.1481
      Episode_Reward/rew_ang_vel_z: 2.4653
    Episode_Reward/pen_base_height: -0.3033
      Episode_Reward/pen_lin_vel_z: -0.0625
     Episode_Reward/pen_ang_vel_xy: -0.1258
   Episode_Reward/pen_joint_torque: -0.1900
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.0776
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0408
   Episode_Reward/pen_joint_powers: -0.0641
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1642
Episode_Reward/pen_flat_orientation: -0.1404
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2460
   Episode_Reward/foot_landing_vel: -0.1533
   Episode_Reward/test_gait_reward: -0.8154
Metrics/base_velocity/error_vel_xy: 2.3251
Metrics/base_velocity/error_vel_yaw: 0.9686
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 1.07s
                        Total time: 756.21s
                               ETA: 2518.5s

################################################################################
                     [1m Learning iteration 693/3000 [0m                      

                       Computation: 90851 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 1.2139
                    Surrogate loss: -0.0021
             Mean action noise std: 0.7648
                     Learning rate: 0.0004
                       Mean reward: 79.94
               Mean episode length: 879.48
       Episode_Reward/keep_balance: 0.8787
     Episode_Reward/rew_lin_vel_xy: 3.1329
      Episode_Reward/rew_ang_vel_z: 2.4676
    Episode_Reward/pen_base_height: -0.3180
      Episode_Reward/pen_lin_vel_z: -0.0653
     Episode_Reward/pen_ang_vel_xy: -0.1249
   Episode_Reward/pen_joint_torque: -0.1843
    Episode_Reward/pen_joint_accel: -0.0930
    Episode_Reward/pen_action_rate: -0.0759
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0402
   Episode_Reward/pen_joint_powers: -0.0629
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1592
Episode_Reward/pen_flat_orientation: -0.1455
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2504
   Episode_Reward/foot_landing_vel: -0.1563
   Episode_Reward/test_gait_reward: -0.8098
Metrics/base_velocity/error_vel_xy: 2.1885
Metrics/base_velocity/error_vel_yaw: 0.9268
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 1.08s
                        Total time: 757.29s
                               ETA: 2517.4s

################################################################################
                     [1m Learning iteration 694/3000 [0m                      

                       Computation: 91914 steps/s (collection: 0.948s, learning 0.121s)
               Value function loss: 1.1772
                    Surrogate loss: -0.0010
             Mean action noise std: 0.7653
                     Learning rate: 0.0004
                       Mean reward: 81.75
               Mean episode length: 903.87
       Episode_Reward/keep_balance: 0.9134
     Episode_Reward/rew_lin_vel_xy: 3.1787
      Episode_Reward/rew_ang_vel_z: 2.5464
    Episode_Reward/pen_base_height: -0.3151
      Episode_Reward/pen_lin_vel_z: -0.0650
     Episode_Reward/pen_ang_vel_xy: -0.1294
   Episode_Reward/pen_joint_torque: -0.1927
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.0796
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0649
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1692
Episode_Reward/pen_flat_orientation: -0.1437
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2447
   Episode_Reward/foot_landing_vel: -0.1552
   Episode_Reward/test_gait_reward: -0.8337
Metrics/base_velocity/error_vel_xy: 2.4578
Metrics/base_velocity/error_vel_yaw: 0.9802
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 1.07s
                        Total time: 758.36s
                               ETA: 2516.2s

################################################################################
                     [1m Learning iteration 695/3000 [0m                      

                       Computation: 92017 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 1.0684
                    Surrogate loss: -0.0016
             Mean action noise std: 0.7672
                     Learning rate: 0.0003
                       Mean reward: 73.56
               Mean episode length: 863.65
       Episode_Reward/keep_balance: 0.8820
     Episode_Reward/rew_lin_vel_xy: 2.9607
      Episode_Reward/rew_ang_vel_z: 2.4547
    Episode_Reward/pen_base_height: -0.3189
      Episode_Reward/pen_lin_vel_z: -0.0663
     Episode_Reward/pen_ang_vel_xy: -0.1272
   Episode_Reward/pen_joint_torque: -0.1927
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.0771
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0405
   Episode_Reward/pen_joint_powers: -0.0640
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1609
Episode_Reward/pen_flat_orientation: -0.1554
  Episode_Reward/pen_feet_distance: -0.0037
Episode_Reward/pen_feet_regulation: -0.2562
   Episode_Reward/foot_landing_vel: -0.1466
   Episode_Reward/test_gait_reward: -0.8135
Metrics/base_velocity/error_vel_xy: 2.3860
Metrics/base_velocity/error_vel_yaw: 0.9558
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 1.07s
                        Total time: 759.43s
                               ETA: 2515.1s

################################################################################
                     [1m Learning iteration 696/3000 [0m                      

                       Computation: 92417 steps/s (collection: 0.939s, learning 0.125s)
               Value function loss: 1.1197
                    Surrogate loss: -0.0024
             Mean action noise std: 0.7686
                     Learning rate: 0.0004
                       Mean reward: 84.06
               Mean episode length: 924.69
       Episode_Reward/keep_balance: 0.9059
     Episode_Reward/rew_lin_vel_xy: 3.2314
      Episode_Reward/rew_ang_vel_z: 2.4841
    Episode_Reward/pen_base_height: -0.3125
      Episode_Reward/pen_lin_vel_z: -0.0656
     Episode_Reward/pen_ang_vel_xy: -0.1333
   Episode_Reward/pen_joint_torque: -0.1897
    Episode_Reward/pen_joint_accel: -0.1096
    Episode_Reward/pen_action_rate: -0.0803
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0426
   Episode_Reward/pen_joint_powers: -0.0654
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1701
Episode_Reward/pen_flat_orientation: -0.1485
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.2569
   Episode_Reward/foot_landing_vel: -0.1526
   Episode_Reward/test_gait_reward: -0.8318
Metrics/base_velocity/error_vel_xy: 2.2923
Metrics/base_velocity/error_vel_yaw: 1.0115
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 1.06s
                        Total time: 760.49s
                               ETA: 2513.9s

################################################################################
                     [1m Learning iteration 697/3000 [0m                      

                       Computation: 92253 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 1.1831
                    Surrogate loss: -0.0023
             Mean action noise std: 0.7705
                     Learning rate: 0.0006
                       Mean reward: 80.46
               Mean episode length: 912.59
       Episode_Reward/keep_balance: 0.9193
     Episode_Reward/rew_lin_vel_xy: 3.2420
      Episode_Reward/rew_ang_vel_z: 2.5421
    Episode_Reward/pen_base_height: -0.3150
      Episode_Reward/pen_lin_vel_z: -0.0666
     Episode_Reward/pen_ang_vel_xy: -0.1305
   Episode_Reward/pen_joint_torque: -0.1983
    Episode_Reward/pen_joint_accel: -0.1102
    Episode_Reward/pen_action_rate: -0.0806
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0433
   Episode_Reward/pen_joint_powers: -0.0671
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1706
Episode_Reward/pen_flat_orientation: -0.1533
  Episode_Reward/pen_feet_distance: -0.0029
Episode_Reward/pen_feet_regulation: -0.2686
   Episode_Reward/foot_landing_vel: -0.1622
   Episode_Reward/test_gait_reward: -0.8451
Metrics/base_velocity/error_vel_xy: 2.3827
Metrics/base_velocity/error_vel_yaw: 1.0019
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 1.07s
                        Total time: 761.56s
                               ETA: 2512.7s

################################################################################
                     [1m Learning iteration 698/3000 [0m                      

                       Computation: 91473 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 1.2332
                    Surrogate loss: -0.0026
             Mean action noise std: 0.7715
                     Learning rate: 0.0006
                       Mean reward: 88.29
               Mean episode length: 898.97
       Episode_Reward/keep_balance: 0.8863
     Episode_Reward/rew_lin_vel_xy: 3.4634
      Episode_Reward/rew_ang_vel_z: 2.4507
    Episode_Reward/pen_base_height: -0.3107
      Episode_Reward/pen_lin_vel_z: -0.0635
     Episode_Reward/pen_ang_vel_xy: -0.1305
   Episode_Reward/pen_joint_torque: -0.1831
    Episode_Reward/pen_joint_accel: -0.1009
    Episode_Reward/pen_action_rate: -0.0785
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0409
   Episode_Reward/pen_joint_powers: -0.0631
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1671
Episode_Reward/pen_flat_orientation: -0.1542
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2529
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.8144
Metrics/base_velocity/error_vel_xy: 2.0507
Metrics/base_velocity/error_vel_yaw: 0.9737
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 1.07s
                        Total time: 762.63s
                               ETA: 2511.6s

################################################################################
                     [1m Learning iteration 699/3000 [0m                      

                       Computation: 90499 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 1.1594
                    Surrogate loss: -0.0045
             Mean action noise std: 0.7727
                     Learning rate: 0.0009
                       Mean reward: 81.89
               Mean episode length: 885.03
       Episode_Reward/keep_balance: 0.8940
     Episode_Reward/rew_lin_vel_xy: 3.2726
      Episode_Reward/rew_ang_vel_z: 2.4825
    Episode_Reward/pen_base_height: -0.3090
      Episode_Reward/pen_lin_vel_z: -0.0674
     Episode_Reward/pen_ang_vel_xy: -0.1253
   Episode_Reward/pen_joint_torque: -0.1954
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.0776
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0653
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1628
Episode_Reward/pen_flat_orientation: -0.1486
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2600
   Episode_Reward/foot_landing_vel: -0.1512
   Episode_Reward/test_gait_reward: -0.8198
Metrics/base_velocity/error_vel_xy: 2.2197
Metrics/base_velocity/error_vel_yaw: 0.9690
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 1.09s
                        Total time: 763.72s
                               ETA: 2510.4s

################################################################################
                     [1m Learning iteration 700/3000 [0m                      

                       Computation: 90464 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 1.1071
                    Surrogate loss: 0.0090
             Mean action noise std: 0.7739
                     Learning rate: 0.0001
                       Mean reward: 78.21
               Mean episode length: 894.14
       Episode_Reward/keep_balance: 0.8749
     Episode_Reward/rew_lin_vel_xy: 3.0698
      Episode_Reward/rew_ang_vel_z: 2.4044
    Episode_Reward/pen_base_height: -0.3047
      Episode_Reward/pen_lin_vel_z: -0.0630
     Episode_Reward/pen_ang_vel_xy: -0.1273
   Episode_Reward/pen_joint_torque: -0.1919
    Episode_Reward/pen_joint_accel: -0.1169
    Episode_Reward/pen_action_rate: -0.0775
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0649
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1633
Episode_Reward/pen_flat_orientation: -0.1481
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.2506
   Episode_Reward/foot_landing_vel: -0.1526
   Episode_Reward/test_gait_reward: -0.8056
Metrics/base_velocity/error_vel_xy: 2.3046
Metrics/base_velocity/error_vel_yaw: 0.9697
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 1.09s
                        Total time: 764.80s
                               ETA: 2509.3s

################################################################################
                     [1m Learning iteration 701/3000 [0m                      

                       Computation: 90980 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.9826
                    Surrogate loss: -0.0036
             Mean action noise std: 0.7748
                     Learning rate: 0.0002
                       Mean reward: 78.47
               Mean episode length: 875.20
       Episode_Reward/keep_balance: 0.8621
     Episode_Reward/rew_lin_vel_xy: 3.0579
      Episode_Reward/rew_ang_vel_z: 2.3969
    Episode_Reward/pen_base_height: -0.3094
      Episode_Reward/pen_lin_vel_z: -0.0617
     Episode_Reward/pen_ang_vel_xy: -0.1280
   Episode_Reward/pen_joint_torque: -0.1819
    Episode_Reward/pen_joint_accel: -0.1102
    Episode_Reward/pen_action_rate: -0.0760
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0400
   Episode_Reward/pen_joint_powers: -0.0617
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1606
Episode_Reward/pen_flat_orientation: -0.1534
  Episode_Reward/pen_feet_distance: -0.0028
Episode_Reward/pen_feet_regulation: -0.2424
   Episode_Reward/foot_landing_vel: -0.1453
   Episode_Reward/test_gait_reward: -0.7902
Metrics/base_velocity/error_vel_xy: 2.2438
Metrics/base_velocity/error_vel_yaw: 0.9410
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 1.08s
                        Total time: 765.88s
                               ETA: 2508.2s

################################################################################
                     [1m Learning iteration 702/3000 [0m                      

                       Computation: 91157 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.1295
                    Surrogate loss: -0.0034
             Mean action noise std: 0.7766
                     Learning rate: 0.0004
                       Mean reward: 87.33
               Mean episode length: 954.94
       Episode_Reward/keep_balance: 0.9493
     Episode_Reward/rew_lin_vel_xy: 3.6097
      Episode_Reward/rew_ang_vel_z: 2.5755
    Episode_Reward/pen_base_height: -0.3123
      Episode_Reward/pen_lin_vel_z: -0.0667
     Episode_Reward/pen_ang_vel_xy: -0.1417
   Episode_Reward/pen_joint_torque: -0.2003
    Episode_Reward/pen_joint_accel: -0.1238
    Episode_Reward/pen_action_rate: -0.0853
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0451
   Episode_Reward/pen_joint_powers: -0.0692
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.1816
Episode_Reward/pen_flat_orientation: -0.1525
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2809
   Episode_Reward/foot_landing_vel: -0.1581
   Episode_Reward/test_gait_reward: -0.8791
Metrics/base_velocity/error_vel_xy: 2.1441
Metrics/base_velocity/error_vel_yaw: 1.0753
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 1.08s
                        Total time: 766.96s
                               ETA: 2507.1s

################################################################################
                     [1m Learning iteration 703/3000 [0m                      

                       Computation: 90640 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 1.3113
                    Surrogate loss: -0.0033
             Mean action noise std: 0.7786
                     Learning rate: 0.0009
                       Mean reward: 80.55
               Mean episode length: 903.62
       Episode_Reward/keep_balance: 0.8991
     Episode_Reward/rew_lin_vel_xy: 3.2642
      Episode_Reward/rew_ang_vel_z: 2.4401
    Episode_Reward/pen_base_height: -0.3164
      Episode_Reward/pen_lin_vel_z: -0.0640
     Episode_Reward/pen_ang_vel_xy: -0.1329
   Episode_Reward/pen_joint_torque: -0.1950
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.0805
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0424
   Episode_Reward/pen_joint_powers: -0.0667
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1701
Episode_Reward/pen_flat_orientation: -0.1605
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.2759
   Episode_Reward/foot_landing_vel: -0.1475
   Episode_Reward/test_gait_reward: -0.8327
Metrics/base_velocity/error_vel_xy: 2.2517
Metrics/base_velocity/error_vel_yaw: 1.0297
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 1.08s
                        Total time: 768.05s
                               ETA: 2506.0s

################################################################################
                     [1m Learning iteration 704/3000 [0m                      

                       Computation: 89641 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 1.1973
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7805
                     Learning rate: 0.0009
                       Mean reward: 82.86
               Mean episode length: 876.19
       Episode_Reward/keep_balance: 0.8978
     Episode_Reward/rew_lin_vel_xy: 3.3916
      Episode_Reward/rew_ang_vel_z: 2.4916
    Episode_Reward/pen_base_height: -0.2997
      Episode_Reward/pen_lin_vel_z: -0.0628
     Episode_Reward/pen_ang_vel_xy: -0.1278
   Episode_Reward/pen_joint_torque: -0.1892
    Episode_Reward/pen_joint_accel: -0.0975
    Episode_Reward/pen_action_rate: -0.0787
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0397
   Episode_Reward/pen_joint_powers: -0.0627
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1670
Episode_Reward/pen_flat_orientation: -0.1435
  Episode_Reward/pen_feet_distance: -0.0038
Episode_Reward/pen_feet_regulation: -0.2398
   Episode_Reward/foot_landing_vel: -0.1449
   Episode_Reward/test_gait_reward: -0.8176
Metrics/base_velocity/error_vel_xy: 2.2540
Metrics/base_velocity/error_vel_yaw: 0.9735
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 1.10s
                        Total time: 769.14s
                               ETA: 2504.9s

################################################################################
                     [1m Learning iteration 705/3000 [0m                      

                       Computation: 91116 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 1.1470
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7811
                     Learning rate: 0.0004
                       Mean reward: 84.72
               Mean episode length: 937.05
       Episode_Reward/keep_balance: 0.8886
     Episode_Reward/rew_lin_vel_xy: 3.2389
      Episode_Reward/rew_ang_vel_z: 2.4270
    Episode_Reward/pen_base_height: -0.3061
      Episode_Reward/pen_lin_vel_z: -0.0626
     Episode_Reward/pen_ang_vel_xy: -0.1341
   Episode_Reward/pen_joint_torque: -0.1868
    Episode_Reward/pen_joint_accel: -0.1036
    Episode_Reward/pen_action_rate: -0.0797
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0421
   Episode_Reward/pen_joint_powers: -0.0643
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1700
Episode_Reward/pen_flat_orientation: -0.1490
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2534
   Episode_Reward/foot_landing_vel: -0.1503
   Episode_Reward/test_gait_reward: -0.8124
Metrics/base_velocity/error_vel_xy: 2.1588
Metrics/base_velocity/error_vel_yaw: 0.9965
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 1.08s
                        Total time: 770.22s
                               ETA: 2503.8s

################################################################################
                     [1m Learning iteration 706/3000 [0m                      

                       Computation: 91380 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 1.1023
                    Surrogate loss: -0.0022
             Mean action noise std: 0.7823
                     Learning rate: 0.0004
                       Mean reward: 83.09
               Mean episode length: 916.93
       Episode_Reward/keep_balance: 0.8759
     Episode_Reward/rew_lin_vel_xy: 3.1743
      Episode_Reward/rew_ang_vel_z: 2.4042
    Episode_Reward/pen_base_height: -0.3055
      Episode_Reward/pen_lin_vel_z: -0.0641
     Episode_Reward/pen_ang_vel_xy: -0.1281
   Episode_Reward/pen_joint_torque: -0.1896
    Episode_Reward/pen_joint_accel: -0.1004
    Episode_Reward/pen_action_rate: -0.0773
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0405
   Episode_Reward/pen_joint_powers: -0.0638
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1635
Episode_Reward/pen_flat_orientation: -0.1594
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.2482
   Episode_Reward/foot_landing_vel: -0.1537
   Episode_Reward/test_gait_reward: -0.8028
Metrics/base_velocity/error_vel_xy: 2.2296
Metrics/base_velocity/error_vel_yaw: 0.9806
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 1.08s
                        Total time: 771.30s
                               ETA: 2502.6s

################################################################################
                     [1m Learning iteration 707/3000 [0m                      

                       Computation: 91515 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.1145
                    Surrogate loss: -0.0004
             Mean action noise std: 0.7828
                     Learning rate: 0.0002
                       Mean reward: 82.62
               Mean episode length: 928.12
       Episode_Reward/keep_balance: 0.9367
     Episode_Reward/rew_lin_vel_xy: 3.3962
      Episode_Reward/rew_ang_vel_z: 2.5801
    Episode_Reward/pen_base_height: -0.3169
      Episode_Reward/pen_lin_vel_z: -0.0675
     Episode_Reward/pen_ang_vel_xy: -0.1361
   Episode_Reward/pen_joint_torque: -0.2050
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.0825
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0433
   Episode_Reward/pen_joint_powers: -0.0685
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1742
Episode_Reward/pen_flat_orientation: -0.1533
  Episode_Reward/pen_feet_distance: -0.0037
Episode_Reward/pen_feet_regulation: -0.2677
   Episode_Reward/foot_landing_vel: -0.1604
   Episode_Reward/test_gait_reward: -0.8643
Metrics/base_velocity/error_vel_xy: 2.3588
Metrics/base_velocity/error_vel_yaw: 1.0276
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 1.07s
                        Total time: 772.37s
                               ETA: 2501.5s

################################################################################
                     [1m Learning iteration 708/3000 [0m                      

                       Computation: 90861 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 1.0488
                    Surrogate loss: -0.0039
             Mean action noise std: 0.7838
                     Learning rate: 0.0004
                       Mean reward: 82.97
               Mean episode length: 885.13
       Episode_Reward/keep_balance: 0.8847
     Episode_Reward/rew_lin_vel_xy: 3.2233
      Episode_Reward/rew_ang_vel_z: 2.4291
    Episode_Reward/pen_base_height: -0.3050
      Episode_Reward/pen_lin_vel_z: -0.0632
     Episode_Reward/pen_ang_vel_xy: -0.1341
   Episode_Reward/pen_joint_torque: -0.1871
    Episode_Reward/pen_joint_accel: -0.1050
    Episode_Reward/pen_action_rate: -0.0784
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0407
   Episode_Reward/pen_joint_powers: -0.0638
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1654
Episode_Reward/pen_flat_orientation: -0.1513
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2553
   Episode_Reward/foot_landing_vel: -0.1420
   Episode_Reward/test_gait_reward: -0.8132
Metrics/base_velocity/error_vel_xy: 2.2489
Metrics/base_velocity/error_vel_yaw: 0.9838
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 1.08s
                        Total time: 773.46s
                               ETA: 2500.4s

################################################################################
                     [1m Learning iteration 709/3000 [0m                      

                       Computation: 91499 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 1.0870
                    Surrogate loss: -0.0021
             Mean action noise std: 0.7858
                     Learning rate: 0.0004
                       Mean reward: 83.80
               Mean episode length: 905.26
       Episode_Reward/keep_balance: 0.8931
     Episode_Reward/rew_lin_vel_xy: 3.2725
      Episode_Reward/rew_ang_vel_z: 2.4695
    Episode_Reward/pen_base_height: -0.3109
      Episode_Reward/pen_lin_vel_z: -0.0620
     Episode_Reward/pen_ang_vel_xy: -0.1334
   Episode_Reward/pen_joint_torque: -0.1875
    Episode_Reward/pen_joint_accel: -0.0993
    Episode_Reward/pen_action_rate: -0.0788
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0407
   Episode_Reward/pen_joint_powers: -0.0639
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1671
Episode_Reward/pen_flat_orientation: -0.1534
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2547
   Episode_Reward/foot_landing_vel: -0.1402
   Episode_Reward/test_gait_reward: -0.8207
Metrics/base_velocity/error_vel_xy: 2.2764
Metrics/base_velocity/error_vel_yaw: 0.9770
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 1.07s
                        Total time: 774.53s
                               ETA: 2499.2s

################################################################################
                     [1m Learning iteration 710/3000 [0m                      

                       Computation: 91374 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 1.1582
                    Surrogate loss: 0.0042
             Mean action noise std: 0.7861
                     Learning rate: 0.0000
                       Mean reward: 88.78
               Mean episode length: 934.55
       Episode_Reward/keep_balance: 0.9504
     Episode_Reward/rew_lin_vel_xy: 3.6657
      Episode_Reward/rew_ang_vel_z: 2.6097
    Episode_Reward/pen_base_height: -0.3238
      Episode_Reward/pen_lin_vel_z: -0.0649
     Episode_Reward/pen_ang_vel_xy: -0.1415
   Episode_Reward/pen_joint_torque: -0.2026
    Episode_Reward/pen_joint_accel: -0.1097
    Episode_Reward/pen_action_rate: -0.0846
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0423
   Episode_Reward/pen_joint_powers: -0.0678
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1792
Episode_Reward/pen_flat_orientation: -0.1532
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2663
   Episode_Reward/foot_landing_vel: -0.1468
   Episode_Reward/test_gait_reward: -0.8719
Metrics/base_velocity/error_vel_xy: 2.2435
Metrics/base_velocity/error_vel_yaw: 1.0541
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 1.08s
                        Total time: 775.61s
                               ETA: 2498.1s

################################################################################
                     [1m Learning iteration 711/3000 [0m                      

                       Computation: 91216 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 1.0392
                    Surrogate loss: -0.0029
             Mean action noise std: 0.7856
                     Learning rate: 0.0001
                       Mean reward: 85.01
               Mean episode length: 893.10
       Episode_Reward/keep_balance: 0.9000
     Episode_Reward/rew_lin_vel_xy: 3.3907
      Episode_Reward/rew_ang_vel_z: 2.4776
    Episode_Reward/pen_base_height: -0.3088
      Episode_Reward/pen_lin_vel_z: -0.0638
     Episode_Reward/pen_ang_vel_xy: -0.1388
   Episode_Reward/pen_joint_torque: -0.1893
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.0800
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0417
   Episode_Reward/pen_joint_powers: -0.0646
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1694
Episode_Reward/pen_flat_orientation: -0.1541
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2504
   Episode_Reward/foot_landing_vel: -0.1453
   Episode_Reward/test_gait_reward: -0.8263
Metrics/base_velocity/error_vel_xy: 2.1998
Metrics/base_velocity/error_vel_yaw: 0.9950
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 1.08s
                        Total time: 776.68s
                               ETA: 2496.9s

################################################################################
                     [1m Learning iteration 712/3000 [0m                      

                       Computation: 90615 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.9523
                    Surrogate loss: -0.0041
             Mean action noise std: 0.7850
                     Learning rate: 0.0003
                       Mean reward: 86.63
               Mean episode length: 936.47
       Episode_Reward/keep_balance: 0.9237
     Episode_Reward/rew_lin_vel_xy: 3.5159
      Episode_Reward/rew_ang_vel_z: 2.5071
    Episode_Reward/pen_base_height: -0.3230
      Episode_Reward/pen_lin_vel_z: -0.0644
     Episode_Reward/pen_ang_vel_xy: -0.1466
   Episode_Reward/pen_joint_torque: -0.1954
    Episode_Reward/pen_joint_accel: -0.1092
    Episode_Reward/pen_action_rate: -0.0838
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0429
   Episode_Reward/pen_joint_powers: -0.0674
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1773
Episode_Reward/pen_flat_orientation: -0.1593
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2709
   Episode_Reward/foot_landing_vel: -0.1449
   Episode_Reward/test_gait_reward: -0.8528
Metrics/base_velocity/error_vel_xy: 2.2228
Metrics/base_velocity/error_vel_yaw: 1.0525
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 1.08s
                        Total time: 777.77s
                               ETA: 2495.8s

################################################################################
                     [1m Learning iteration 713/3000 [0m                      

                       Computation: 90766 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 1.1172
                    Surrogate loss: -0.0032
             Mean action noise std: 0.7859
                     Learning rate: 0.0006
                       Mean reward: 82.21
               Mean episode length: 887.00
       Episode_Reward/keep_balance: 0.9063
     Episode_Reward/rew_lin_vel_xy: 3.4413
      Episode_Reward/rew_ang_vel_z: 2.4730
    Episode_Reward/pen_base_height: -0.3205
      Episode_Reward/pen_lin_vel_z: -0.0660
     Episode_Reward/pen_ang_vel_xy: -0.1396
   Episode_Reward/pen_joint_torque: -0.1969
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.0813
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0429
   Episode_Reward/pen_joint_powers: -0.0673
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1726
Episode_Reward/pen_flat_orientation: -0.1606
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.2713
   Episode_Reward/foot_landing_vel: -0.1557
   Episode_Reward/test_gait_reward: -0.8305
Metrics/base_velocity/error_vel_xy: 2.1819
Metrics/base_velocity/error_vel_yaw: 1.0229
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 1.08s
                        Total time: 778.85s
                               ETA: 2494.7s

################################################################################
                     [1m Learning iteration 714/3000 [0m                      

                       Computation: 89644 steps/s (collection: 0.971s, learning 0.126s)
               Value function loss: 1.1589
                    Surrogate loss: -0.0033
             Mean action noise std: 0.7887
                     Learning rate: 0.0006
                       Mean reward: 84.90
               Mean episode length: 896.73
       Episode_Reward/keep_balance: 0.8874
     Episode_Reward/rew_lin_vel_xy: 3.4554
      Episode_Reward/rew_ang_vel_z: 2.4069
    Episode_Reward/pen_base_height: -0.3207
      Episode_Reward/pen_lin_vel_z: -0.0641
     Episode_Reward/pen_ang_vel_xy: -0.1385
   Episode_Reward/pen_joint_torque: -0.1922
    Episode_Reward/pen_joint_accel: -0.1009
    Episode_Reward/pen_action_rate: -0.0802
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0419
   Episode_Reward/pen_joint_powers: -0.0665
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1694
Episode_Reward/pen_flat_orientation: -0.1620
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.2731
   Episode_Reward/foot_landing_vel: -0.1402
   Episode_Reward/test_gait_reward: -0.8249
Metrics/base_velocity/error_vel_xy: 2.0735
Metrics/base_velocity/error_vel_yaw: 1.0131
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 1.10s
                        Total time: 779.95s
                               ETA: 2493.7s

################################################################################
                     [1m Learning iteration 715/3000 [0m                      

                       Computation: 91042 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 1.1785
                    Surrogate loss: -0.0004
             Mean action noise std: 0.7904
                     Learning rate: 0.0003
                       Mean reward: 82.88
               Mean episode length: 893.99
       Episode_Reward/keep_balance: 0.8989
     Episode_Reward/rew_lin_vel_xy: 3.2671
      Episode_Reward/rew_ang_vel_z: 2.4594
    Episode_Reward/pen_base_height: -0.3089
      Episode_Reward/pen_lin_vel_z: -0.0618
     Episode_Reward/pen_ang_vel_xy: -0.1420
   Episode_Reward/pen_joint_torque: -0.1924
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.0813
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0423
   Episode_Reward/pen_joint_powers: -0.0663
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1731
Episode_Reward/pen_flat_orientation: -0.1582
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.2601
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.8293
Metrics/base_velocity/error_vel_xy: 2.1773
Metrics/base_velocity/error_vel_yaw: 1.0143
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 1.08s
                        Total time: 781.03s
                               ETA: 2492.5s

################################################################################
                     [1m Learning iteration 716/3000 [0m                      

                       Computation: 90276 steps/s (collection: 0.964s, learning 0.125s)
               Value function loss: 1.0943
                    Surrogate loss: -0.0042
             Mean action noise std: 0.7923
                     Learning rate: 0.0006
                       Mean reward: 80.33
               Mean episode length: 908.46
       Episode_Reward/keep_balance: 0.9358
     Episode_Reward/rew_lin_vel_xy: 3.3857
      Episode_Reward/rew_ang_vel_z: 2.5276
    Episode_Reward/pen_base_height: -0.3110
      Episode_Reward/pen_lin_vel_z: -0.0629
     Episode_Reward/pen_ang_vel_xy: -0.1430
   Episode_Reward/pen_joint_torque: -0.1986
    Episode_Reward/pen_joint_accel: -0.1132
    Episode_Reward/pen_action_rate: -0.0854
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0439
   Episode_Reward/pen_joint_powers: -0.0687
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1822
Episode_Reward/pen_flat_orientation: -0.1583
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2667
   Episode_Reward/foot_landing_vel: -0.1521
   Episode_Reward/test_gait_reward: -0.8620
Metrics/base_velocity/error_vel_xy: 2.2635
Metrics/base_velocity/error_vel_yaw: 1.0785
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 1.09s
                        Total time: 782.12s
                               ETA: 2491.4s

################################################################################
                     [1m Learning iteration 717/3000 [0m                      

                       Computation: 91511 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 1.1403
                    Surrogate loss: -0.0040
             Mean action noise std: 0.7917
                     Learning rate: 0.0009
                       Mean reward: 84.03
               Mean episode length: 930.10
       Episode_Reward/keep_balance: 0.9517
     Episode_Reward/rew_lin_vel_xy: 3.6221
      Episode_Reward/rew_ang_vel_z: 2.6260
    Episode_Reward/pen_base_height: -0.3284
      Episode_Reward/pen_lin_vel_z: -0.0658
     Episode_Reward/pen_ang_vel_xy: -0.1469
   Episode_Reward/pen_joint_torque: -0.2063
    Episode_Reward/pen_joint_accel: -0.1143
    Episode_Reward/pen_action_rate: -0.0857
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0706
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1819
Episode_Reward/pen_flat_orientation: -0.1599
  Episode_Reward/pen_feet_distance: -0.0025
Episode_Reward/pen_feet_regulation: -0.2778
   Episode_Reward/foot_landing_vel: -0.1541
   Episode_Reward/test_gait_reward: -0.8773
Metrics/base_velocity/error_vel_xy: 2.3188
Metrics/base_velocity/error_vel_yaw: 1.0479
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 1.07s
                        Total time: 783.19s
                               ETA: 2490.3s

################################################################################
                     [1m Learning iteration 718/3000 [0m                      

                       Computation: 91468 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 1.2609
                    Surrogate loss: -0.0044
             Mean action noise std: 0.7929
                     Learning rate: 0.0013
                       Mean reward: 85.95
               Mean episode length: 921.94
       Episode_Reward/keep_balance: 0.9253
     Episode_Reward/rew_lin_vel_xy: 3.5572
      Episode_Reward/rew_ang_vel_z: 2.5053
    Episode_Reward/pen_base_height: -0.3100
      Episode_Reward/pen_lin_vel_z: -0.0633
     Episode_Reward/pen_ang_vel_xy: -0.1361
   Episode_Reward/pen_joint_torque: -0.1976
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.0823
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0417
   Episode_Reward/pen_joint_powers: -0.0665
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1756
Episode_Reward/pen_flat_orientation: -0.1566
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.2595
   Episode_Reward/foot_landing_vel: -0.1456
   Episode_Reward/test_gait_reward: -0.8532
Metrics/base_velocity/error_vel_xy: 2.1531
Metrics/base_velocity/error_vel_yaw: 1.0511
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 1.07s
                        Total time: 784.27s
                               ETA: 2489.1s

################################################################################
                     [1m Learning iteration 719/3000 [0m                      

                       Computation: 91437 steps/s (collection: 0.951s, learning 0.124s)
               Value function loss: 1.3285
                    Surrogate loss: -0.0026
             Mean action noise std: 0.7932
                     Learning rate: 0.0019
                       Mean reward: 82.53
               Mean episode length: 908.34
       Episode_Reward/keep_balance: 0.9205
     Episode_Reward/rew_lin_vel_xy: 3.3846
      Episode_Reward/rew_ang_vel_z: 2.4950
    Episode_Reward/pen_base_height: -0.3017
      Episode_Reward/pen_lin_vel_z: -0.0613
     Episode_Reward/pen_ang_vel_xy: -0.1370
   Episode_Reward/pen_joint_torque: -0.1924
    Episode_Reward/pen_joint_accel: -0.0989
    Episode_Reward/pen_action_rate: -0.0829
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0411
   Episode_Reward/pen_joint_powers: -0.0653
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1783
Episode_Reward/pen_flat_orientation: -0.1551
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2532
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.8426
Metrics/base_velocity/error_vel_xy: 2.3815
Metrics/base_velocity/error_vel_yaw: 1.0535
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 1.08s
                        Total time: 785.34s
                               ETA: 2488.0s

################################################################################
                     [1m Learning iteration 720/3000 [0m                      

                       Computation: 91289 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 1.2975
                    Surrogate loss: 0.0031
             Mean action noise std: 0.7937
                     Learning rate: 0.0003
                       Mean reward: 79.71
               Mean episode length: 870.99
       Episode_Reward/keep_balance: 0.8948
     Episode_Reward/rew_lin_vel_xy: 3.2727
      Episode_Reward/rew_ang_vel_z: 2.4187
    Episode_Reward/pen_base_height: -0.3060
      Episode_Reward/pen_lin_vel_z: -0.0633
     Episode_Reward/pen_ang_vel_xy: -0.1420
   Episode_Reward/pen_joint_torque: -0.1877
    Episode_Reward/pen_joint_accel: -0.1020
    Episode_Reward/pen_action_rate: -0.0821
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0422
   Episode_Reward/pen_joint_powers: -0.0658
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1756
Episode_Reward/pen_flat_orientation: -0.1645
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2631
   Episode_Reward/foot_landing_vel: -0.1403
   Episode_Reward/test_gait_reward: -0.8262
Metrics/base_velocity/error_vel_xy: 2.2016
Metrics/base_velocity/error_vel_yaw: 1.0323
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 1.08s
                        Total time: 786.42s
                               ETA: 2486.9s

################################################################################
                     [1m Learning iteration 721/3000 [0m                      

                       Computation: 91139 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.0484
                    Surrogate loss: -0.0041
             Mean action noise std: 0.7936
                     Learning rate: 0.0006
                       Mean reward: 80.29
               Mean episode length: 874.35
       Episode_Reward/keep_balance: 0.8829
     Episode_Reward/rew_lin_vel_xy: 3.2184
      Episode_Reward/rew_ang_vel_z: 2.3741
    Episode_Reward/pen_base_height: -0.3023
      Episode_Reward/pen_lin_vel_z: -0.0580
     Episode_Reward/pen_ang_vel_xy: -0.1376
   Episode_Reward/pen_joint_torque: -0.1867
    Episode_Reward/pen_joint_accel: -0.1030
    Episode_Reward/pen_action_rate: -0.0804
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0406
   Episode_Reward/pen_joint_powers: -0.0640
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1718
Episode_Reward/pen_flat_orientation: -0.1480
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.2508
   Episode_Reward/foot_landing_vel: -0.1323
   Episode_Reward/test_gait_reward: -0.8113
Metrics/base_velocity/error_vel_xy: 2.2016
Metrics/base_velocity/error_vel_yaw: 1.0285
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 1.08s
                        Total time: 787.50s
                               ETA: 2485.7s

################################################################################
                     [1m Learning iteration 722/3000 [0m                      

                       Computation: 91338 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 1.1261
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7955
                     Learning rate: 0.0009
                       Mean reward: 83.08
               Mean episode length: 882.85
       Episode_Reward/keep_balance: 0.8548
     Episode_Reward/rew_lin_vel_xy: 3.1832
      Episode_Reward/rew_ang_vel_z: 2.3259
    Episode_Reward/pen_base_height: -0.2863
      Episode_Reward/pen_lin_vel_z: -0.0549
     Episode_Reward/pen_ang_vel_xy: -0.1277
   Episode_Reward/pen_joint_torque: -0.1775
    Episode_Reward/pen_joint_accel: -0.0925
    Episode_Reward/pen_action_rate: -0.0766
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0378
   Episode_Reward/pen_joint_powers: -0.0605
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1651
Episode_Reward/pen_flat_orientation: -0.1420
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2301
   Episode_Reward/foot_landing_vel: -0.1251
   Episode_Reward/test_gait_reward: -0.7809
Metrics/base_velocity/error_vel_xy: 1.9817
Metrics/base_velocity/error_vel_yaw: 0.9676
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 1.08s
                        Total time: 788.57s
                               ETA: 2484.6s

################################################################################
                     [1m Learning iteration 723/3000 [0m                      

                       Computation: 91257 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 1.1167
                    Surrogate loss: -0.0023
             Mean action noise std: 0.7964
                     Learning rate: 0.0009
                       Mean reward: 87.85
               Mean episode length: 907.74
       Episode_Reward/keep_balance: 0.9079
     Episode_Reward/rew_lin_vel_xy: 3.6346
      Episode_Reward/rew_ang_vel_z: 2.4304
    Episode_Reward/pen_base_height: -0.3195
      Episode_Reward/pen_lin_vel_z: -0.0602
     Episode_Reward/pen_ang_vel_xy: -0.1384
   Episode_Reward/pen_joint_torque: -0.1922
    Episode_Reward/pen_joint_accel: -0.0991
    Episode_Reward/pen_action_rate: -0.0826
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0421
   Episode_Reward/pen_joint_powers: -0.0657
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1766
Episode_Reward/pen_flat_orientation: -0.1658
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2613
   Episode_Reward/foot_landing_vel: -0.1420
   Episode_Reward/test_gait_reward: -0.8393
Metrics/base_velocity/error_vel_xy: 2.0688
Metrics/base_velocity/error_vel_yaw: 1.0586
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 1.08s
                        Total time: 789.65s
                               ETA: 2483.5s

################################################################################
                     [1m Learning iteration 724/3000 [0m                      

                       Computation: 91185 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.1478
                    Surrogate loss: -0.0028
             Mean action noise std: 0.7975
                     Learning rate: 0.0013
                       Mean reward: 83.79
               Mean episode length: 881.79
       Episode_Reward/keep_balance: 0.8957
     Episode_Reward/rew_lin_vel_xy: 3.6349
      Episode_Reward/rew_ang_vel_z: 2.4189
    Episode_Reward/pen_base_height: -0.3086
      Episode_Reward/pen_lin_vel_z: -0.0610
     Episode_Reward/pen_ang_vel_xy: -0.1371
   Episode_Reward/pen_joint_torque: -0.1890
    Episode_Reward/pen_joint_accel: -0.0995
    Episode_Reward/pen_action_rate: -0.0816
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0417
   Episode_Reward/pen_joint_powers: -0.0651
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1745
Episode_Reward/pen_flat_orientation: -0.1589
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2578
   Episode_Reward/foot_landing_vel: -0.1444
   Episode_Reward/test_gait_reward: -0.8254
Metrics/base_velocity/error_vel_xy: 1.9600
Metrics/base_velocity/error_vel_yaw: 1.0300
      Episode_Termination/time_out: 2.9583
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 1.08s
                        Total time: 790.73s
                               ETA: 2482.3s

################################################################################
                     [1m Learning iteration 725/3000 [0m                      

                       Computation: 91360 steps/s (collection: 0.951s, learning 0.125s)
               Value function loss: 1.0881
                    Surrogate loss: -0.0024
             Mean action noise std: 0.7991
                     Learning rate: 0.0013
                       Mean reward: 89.74
               Mean episode length: 942.29
       Episode_Reward/keep_balance: 0.9295
     Episode_Reward/rew_lin_vel_xy: 3.4886
      Episode_Reward/rew_ang_vel_z: 2.5425
    Episode_Reward/pen_base_height: -0.2989
      Episode_Reward/pen_lin_vel_z: -0.0586
     Episode_Reward/pen_ang_vel_xy: -0.1395
   Episode_Reward/pen_joint_torque: -0.1891
    Episode_Reward/pen_joint_accel: -0.0983
    Episode_Reward/pen_action_rate: -0.0835
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0401
   Episode_Reward/pen_joint_powers: -0.0647
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1801
Episode_Reward/pen_flat_orientation: -0.1487
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2468
   Episode_Reward/foot_landing_vel: -0.1345
   Episode_Reward/test_gait_reward: -0.8504
Metrics/base_velocity/error_vel_xy: 2.2319
Metrics/base_velocity/error_vel_yaw: 1.0413
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 1.08s
                        Total time: 791.80s
                               ETA: 2481.2s

################################################################################
                     [1m Learning iteration 726/3000 [0m                      

                       Computation: 91849 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 1.1388
                    Surrogate loss: -0.0008
             Mean action noise std: 0.8004
                     Learning rate: 0.0004
                       Mean reward: 83.74
               Mean episode length: 919.24
       Episode_Reward/keep_balance: 0.9032
     Episode_Reward/rew_lin_vel_xy: 3.3385
      Episode_Reward/rew_ang_vel_z: 2.4213
    Episode_Reward/pen_base_height: -0.3082
      Episode_Reward/pen_lin_vel_z: -0.0637
     Episode_Reward/pen_ang_vel_xy: -0.1434
   Episode_Reward/pen_joint_torque: -0.1916
    Episode_Reward/pen_joint_accel: -0.0950
    Episode_Reward/pen_action_rate: -0.0829
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0422
   Episode_Reward/pen_joint_powers: -0.0666
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1767
Episode_Reward/pen_flat_orientation: -0.1685
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2643
   Episode_Reward/foot_landing_vel: -0.1395
   Episode_Reward/test_gait_reward: -0.8325
Metrics/base_velocity/error_vel_xy: 2.2430
Metrics/base_velocity/error_vel_yaw: 1.0597
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 1.07s
                        Total time: 792.87s
                               ETA: 2480.0s

################################################################################
                     [1m Learning iteration 727/3000 [0m                      

                       Computation: 88680 steps/s (collection: 0.951s, learning 0.157s)
               Value function loss: 1.1414
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8016
                     Learning rate: 0.0006
                       Mean reward: 87.61
               Mean episode length: 918.74
       Episode_Reward/keep_balance: 0.8930
     Episode_Reward/rew_lin_vel_xy: 3.3997
      Episode_Reward/rew_ang_vel_z: 2.4218
    Episode_Reward/pen_base_height: -0.3077
      Episode_Reward/pen_lin_vel_z: -0.0594
     Episode_Reward/pen_ang_vel_xy: -0.1392
   Episode_Reward/pen_joint_torque: -0.1884
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.0825
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0417
   Episode_Reward/pen_joint_powers: -0.0654
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1770
Episode_Reward/pen_flat_orientation: -0.1560
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2555
   Episode_Reward/foot_landing_vel: -0.1388
   Episode_Reward/test_gait_reward: -0.8240
Metrics/base_velocity/error_vel_xy: 2.1243
Metrics/base_velocity/error_vel_yaw: 1.0275
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 1.11s
                        Total time: 793.98s
                               ETA: 2479.0s

################################################################################
                     [1m Learning iteration 728/3000 [0m                      

                       Computation: 90204 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 1.0807
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8028
                     Learning rate: 0.0009
                       Mean reward: 86.26
               Mean episode length: 922.44
       Episode_Reward/keep_balance: 0.9010
     Episode_Reward/rew_lin_vel_xy: 3.4821
      Episode_Reward/rew_ang_vel_z: 2.3713
    Episode_Reward/pen_base_height: -0.3064
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.1400
   Episode_Reward/pen_joint_torque: -0.1806
    Episode_Reward/pen_joint_accel: -0.1021
    Episode_Reward/pen_action_rate: -0.0851
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0633
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1842
Episode_Reward/pen_flat_orientation: -0.1581
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.2515
   Episode_Reward/foot_landing_vel: -0.1345
   Episode_Reward/test_gait_reward: -0.8330
Metrics/base_velocity/error_vel_xy: 2.0394
Metrics/base_velocity/error_vel_yaw: 1.0936
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 1.09s
                        Total time: 795.07s
                               ETA: 2477.9s

################################################################################
                     [1m Learning iteration 729/3000 [0m                      

                       Computation: 91470 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 1.2359
                    Surrogate loss: -0.0004
             Mean action noise std: 0.8032
                     Learning rate: 0.0004
                       Mean reward: 84.92
               Mean episode length: 900.47
       Episode_Reward/keep_balance: 0.8863
     Episode_Reward/rew_lin_vel_xy: 3.4217
      Episode_Reward/rew_ang_vel_z: 2.3988
    Episode_Reward/pen_base_height: -0.3160
      Episode_Reward/pen_lin_vel_z: -0.0571
     Episode_Reward/pen_ang_vel_xy: -0.1419
   Episode_Reward/pen_joint_torque: -0.1828
    Episode_Reward/pen_joint_accel: -0.0950
    Episode_Reward/pen_action_rate: -0.0830
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0405
   Episode_Reward/pen_joint_powers: -0.0641
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1777
Episode_Reward/pen_flat_orientation: -0.1509
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.2540
   Episode_Reward/foot_landing_vel: -0.1341
   Episode_Reward/test_gait_reward: -0.8232
Metrics/base_velocity/error_vel_xy: 2.1550
Metrics/base_velocity/error_vel_yaw: 1.0214
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 1.07s
                        Total time: 796.15s
                               ETA: 2476.8s

################################################################################
                     [1m Learning iteration 730/3000 [0m                      

                       Computation: 90491 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 1.0233
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8033
                     Learning rate: 0.0006
                       Mean reward: 83.47
               Mean episode length: 891.19
       Episode_Reward/keep_balance: 0.9137
     Episode_Reward/rew_lin_vel_xy: 3.4967
      Episode_Reward/rew_ang_vel_z: 2.4890
    Episode_Reward/pen_base_height: -0.2986
      Episode_Reward/pen_lin_vel_z: -0.0603
     Episode_Reward/pen_ang_vel_xy: -0.1447
   Episode_Reward/pen_joint_torque: -0.1901
    Episode_Reward/pen_joint_accel: -0.1008
    Episode_Reward/pen_action_rate: -0.0844
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0420
   Episode_Reward/pen_joint_powers: -0.0653
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1805
Episode_Reward/pen_flat_orientation: -0.1548
  Episode_Reward/pen_feet_distance: -0.0025
Episode_Reward/pen_feet_regulation: -0.2578
   Episode_Reward/foot_landing_vel: -0.1457
   Episode_Reward/test_gait_reward: -0.8393
Metrics/base_velocity/error_vel_xy: 2.2429
Metrics/base_velocity/error_vel_yaw: 1.0400
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 1.09s
                        Total time: 797.23s
                               ETA: 2475.7s

################################################################################
                     [1m Learning iteration 731/3000 [0m                      

                       Computation: 92061 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.9675
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8037
                     Learning rate: 0.0006
                       Mean reward: 85.38
               Mean episode length: 901.93
       Episode_Reward/keep_balance: 0.8974
     Episode_Reward/rew_lin_vel_xy: 3.5239
      Episode_Reward/rew_ang_vel_z: 2.3857
    Episode_Reward/pen_base_height: -0.3223
      Episode_Reward/pen_lin_vel_z: -0.0608
     Episode_Reward/pen_ang_vel_xy: -0.1439
   Episode_Reward/pen_joint_torque: -0.1906
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.0848
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0434
   Episode_Reward/pen_joint_powers: -0.0668
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1816
Episode_Reward/pen_flat_orientation: -0.1678
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2752
   Episode_Reward/foot_landing_vel: -0.1405
   Episode_Reward/test_gait_reward: -0.8331
Metrics/base_velocity/error_vel_xy: 2.0181
Metrics/base_velocity/error_vel_yaw: 1.0755
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 1.07s
                        Total time: 798.30s
                               ETA: 2474.5s

################################################################################
                     [1m Learning iteration 732/3000 [0m                      

                       Computation: 92603 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 1.0499
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8058
                     Learning rate: 0.0009
                       Mean reward: 89.55
               Mean episode length: 944.88
       Episode_Reward/keep_balance: 0.9390
     Episode_Reward/rew_lin_vel_xy: 3.5790
      Episode_Reward/rew_ang_vel_z: 2.5264
    Episode_Reward/pen_base_height: -0.3075
      Episode_Reward/pen_lin_vel_z: -0.0613
     Episode_Reward/pen_ang_vel_xy: -0.1444
   Episode_Reward/pen_joint_torque: -0.1986
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.0871
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0429
   Episode_Reward/pen_joint_powers: -0.0682
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1858
Episode_Reward/pen_flat_orientation: -0.1563
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2664
   Episode_Reward/foot_landing_vel: -0.1432
   Episode_Reward/test_gait_reward: -0.8677
Metrics/base_velocity/error_vel_xy: 2.1879
Metrics/base_velocity/error_vel_yaw: 1.0846
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 1.06s
                        Total time: 799.36s
                               ETA: 2473.3s

################################################################################
                     [1m Learning iteration 733/3000 [0m                      

                       Computation: 92313 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 1.1170
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8076
                     Learning rate: 0.0013
                       Mean reward: 87.69
               Mean episode length: 950.57
       Episode_Reward/keep_balance: 0.9433
     Episode_Reward/rew_lin_vel_xy: 3.6565
      Episode_Reward/rew_ang_vel_z: 2.5127
    Episode_Reward/pen_base_height: -0.3240
      Episode_Reward/pen_lin_vel_z: -0.0610
     Episode_Reward/pen_ang_vel_xy: -0.1503
   Episode_Reward/pen_joint_torque: -0.1992
    Episode_Reward/pen_joint_accel: -0.1153
    Episode_Reward/pen_action_rate: -0.0884
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0449
   Episode_Reward/pen_joint_powers: -0.0694
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1894
Episode_Reward/pen_flat_orientation: -0.1627
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2780
   Episode_Reward/foot_landing_vel: -0.1485
   Episode_Reward/test_gait_reward: -0.8807
Metrics/base_velocity/error_vel_xy: 2.1631
Metrics/base_velocity/error_vel_yaw: 1.1110
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 1.06s
                        Total time: 800.43s
                               ETA: 2472.2s

################################################################################
                     [1m Learning iteration 734/3000 [0m                      

                       Computation: 89526 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 1.0882
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8100
                     Learning rate: 0.0013
                       Mean reward: 90.65
               Mean episode length: 933.01
       Episode_Reward/keep_balance: 0.9475
     Episode_Reward/rew_lin_vel_xy: 3.8138
      Episode_Reward/rew_ang_vel_z: 2.5659
    Episode_Reward/pen_base_height: -0.3160
      Episode_Reward/pen_lin_vel_z: -0.0625
     Episode_Reward/pen_ang_vel_xy: -0.1475
   Episode_Reward/pen_joint_torque: -0.2023
    Episode_Reward/pen_joint_accel: -0.1101
    Episode_Reward/pen_action_rate: -0.0884
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0448
   Episode_Reward/pen_joint_powers: -0.0702
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1894
Episode_Reward/pen_flat_orientation: -0.1611
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2838
   Episode_Reward/foot_landing_vel: -0.1610
   Episode_Reward/test_gait_reward: -0.8777
Metrics/base_velocity/error_vel_xy: 2.1461
Metrics/base_velocity/error_vel_yaw: 1.0819
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 1.10s
                        Total time: 801.53s
                               ETA: 2471.1s

################################################################################
                     [1m Learning iteration 735/3000 [0m                      

                       Computation: 91020 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 1.1407
                    Surrogate loss: 0.0076
             Mean action noise std: 0.8111
                     Learning rate: 0.0001
                       Mean reward: 85.94
               Mean episode length: 928.20
       Episode_Reward/keep_balance: 0.9510
     Episode_Reward/rew_lin_vel_xy: 3.6668
      Episode_Reward/rew_ang_vel_z: 2.5700
    Episode_Reward/pen_base_height: -0.3094
      Episode_Reward/pen_lin_vel_z: -0.0599
     Episode_Reward/pen_ang_vel_xy: -0.1527
   Episode_Reward/pen_joint_torque: -0.1927
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.0891
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0444
   Episode_Reward/pen_joint_powers: -0.0685
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1914
Episode_Reward/pen_flat_orientation: -0.1532
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2716
   Episode_Reward/foot_landing_vel: -0.1510
   Episode_Reward/test_gait_reward: -0.8839
Metrics/base_velocity/error_vel_xy: 2.1919
Metrics/base_velocity/error_vel_yaw: 1.0921
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 1.08s
                        Total time: 802.61s
                               ETA: 2470.0s

################################################################################
                     [1m Learning iteration 736/3000 [0m                      

                       Computation: 92426 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 1.0169
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8108
                     Learning rate: 0.0002
                       Mean reward: 88.47
               Mean episode length: 901.62
       Episode_Reward/keep_balance: 0.9214
     Episode_Reward/rew_lin_vel_xy: 3.7822
      Episode_Reward/rew_ang_vel_z: 2.4738
    Episode_Reward/pen_base_height: -0.3028
      Episode_Reward/pen_lin_vel_z: -0.0596
     Episode_Reward/pen_ang_vel_xy: -0.1427
   Episode_Reward/pen_joint_torque: -0.1899
    Episode_Reward/pen_joint_accel: -0.1015
    Episode_Reward/pen_action_rate: -0.0862
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0422
   Episode_Reward/pen_joint_powers: -0.0665
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1858
Episode_Reward/pen_flat_orientation: -0.1489
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2602
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.8522
Metrics/base_velocity/error_vel_xy: 2.0068
Metrics/base_velocity/error_vel_yaw: 1.0742
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 1.06s
                        Total time: 803.67s
                               ETA: 2468.8s

################################################################################
                     [1m Learning iteration 737/3000 [0m                      

                       Computation: 92273 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 1.0703
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8105
                     Learning rate: 0.0004
                       Mean reward: 88.23
               Mean episode length: 945.81
       Episode_Reward/keep_balance: 0.9486
     Episode_Reward/rew_lin_vel_xy: 3.5789
      Episode_Reward/rew_ang_vel_z: 2.5769
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0639
     Episode_Reward/pen_ang_vel_xy: -0.1502
   Episode_Reward/pen_joint_torque: -0.2028
    Episode_Reward/pen_joint_accel: -0.1123
    Episode_Reward/pen_action_rate: -0.0888
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0704
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1887
Episode_Reward/pen_flat_orientation: -0.1597
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.2872
   Episode_Reward/foot_landing_vel: -0.1477
   Episode_Reward/test_gait_reward: -0.8832
Metrics/base_velocity/error_vel_xy: 2.2669
Metrics/base_velocity/error_vel_yaw: 1.0760
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 1.07s
                        Total time: 804.73s
                               ETA: 2467.6s

################################################################################
                     [1m Learning iteration 738/3000 [0m                      

                       Computation: 92147 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 0.9810
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8113
                     Learning rate: 0.0006
                       Mean reward: 89.26
               Mean episode length: 935.60
       Episode_Reward/keep_balance: 0.9431
     Episode_Reward/rew_lin_vel_xy: 3.5772
      Episode_Reward/rew_ang_vel_z: 2.5463
    Episode_Reward/pen_base_height: -0.3022
      Episode_Reward/pen_lin_vel_z: -0.0620
     Episode_Reward/pen_ang_vel_xy: -0.1455
   Episode_Reward/pen_joint_torque: -0.1948
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.0887
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0432
   Episode_Reward/pen_joint_powers: -0.0682
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1915
Episode_Reward/pen_flat_orientation: -0.1540
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2713
   Episode_Reward/foot_landing_vel: -0.1435
   Episode_Reward/test_gait_reward: -0.8610
Metrics/base_velocity/error_vel_xy: 2.2744
Metrics/base_velocity/error_vel_yaw: 1.0843
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 1.07s
                        Total time: 805.80s
                               ETA: 2466.5s

################################################################################
                     [1m Learning iteration 739/3000 [0m                      

                       Computation: 93173 steps/s (collection: 0.933s, learning 0.122s)
               Value function loss: 1.1049
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8111
                     Learning rate: 0.0006
                       Mean reward: 90.59
               Mean episode length: 944.49
       Episode_Reward/keep_balance: 0.9433
     Episode_Reward/rew_lin_vel_xy: 3.8148
      Episode_Reward/rew_ang_vel_z: 2.4939
    Episode_Reward/pen_base_height: -0.3140
      Episode_Reward/pen_lin_vel_z: -0.0606
     Episode_Reward/pen_ang_vel_xy: -0.1504
   Episode_Reward/pen_joint_torque: -0.1968
    Episode_Reward/pen_joint_accel: -0.1054
    Episode_Reward/pen_action_rate: -0.0898
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0697
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1943
Episode_Reward/pen_flat_orientation: -0.1549
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2814
   Episode_Reward/foot_landing_vel: -0.1433
   Episode_Reward/test_gait_reward: -0.8789
Metrics/base_velocity/error_vel_xy: 2.1084
Metrics/base_velocity/error_vel_yaw: 1.1316
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 1.06s
                        Total time: 806.86s
                               ETA: 2465.3s

################################################################################
                     [1m Learning iteration 740/3000 [0m                      

                       Computation: 92462 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 0.9959
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8131
                     Learning rate: 0.0006
                       Mean reward: 92.18
               Mean episode length: 970.05
       Episode_Reward/keep_balance: 0.9644
     Episode_Reward/rew_lin_vel_xy: 3.6167
      Episode_Reward/rew_ang_vel_z: 2.6159
    Episode_Reward/pen_base_height: -0.3033
      Episode_Reward/pen_lin_vel_z: -0.0598
     Episode_Reward/pen_ang_vel_xy: -0.1513
   Episode_Reward/pen_joint_torque: -0.1977
    Episode_Reward/pen_joint_accel: -0.1010
    Episode_Reward/pen_action_rate: -0.0904
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0436
   Episode_Reward/pen_joint_powers: -0.0686
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1956
Episode_Reward/pen_flat_orientation: -0.1502
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2703
   Episode_Reward/foot_landing_vel: -0.1406
   Episode_Reward/test_gait_reward: -0.8888
Metrics/base_velocity/error_vel_xy: 2.3477
Metrics/base_velocity/error_vel_yaw: 1.1008
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 1.06s
                        Total time: 807.92s
                               ETA: 2464.1s

################################################################################
                     [1m Learning iteration 741/3000 [0m                      

                       Computation: 92375 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 1.0651
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8142
                     Learning rate: 0.0006
                       Mean reward: 93.51
               Mean episode length: 964.85
       Episode_Reward/keep_balance: 0.9593
     Episode_Reward/rew_lin_vel_xy: 3.7370
      Episode_Reward/rew_ang_vel_z: 2.5568
    Episode_Reward/pen_base_height: -0.3121
      Episode_Reward/pen_lin_vel_z: -0.0616
     Episode_Reward/pen_ang_vel_xy: -0.1487
   Episode_Reward/pen_joint_torque: -0.2053
    Episode_Reward/pen_joint_accel: -0.1129
    Episode_Reward/pen_action_rate: -0.0912
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0457
   Episode_Reward/pen_joint_powers: -0.0711
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1951
Episode_Reward/pen_flat_orientation: -0.1616
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.2807
   Episode_Reward/foot_landing_vel: -0.1464
   Episode_Reward/test_gait_reward: -0.8847
Metrics/base_velocity/error_vel_xy: 2.2427
Metrics/base_velocity/error_vel_yaw: 1.1317
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 1.06s
                        Total time: 808.98s
                               ETA: 2462.9s

################################################################################
                     [1m Learning iteration 742/3000 [0m                      

                       Computation: 91108 steps/s (collection: 0.958s, learning 0.121s)
               Value function loss: 1.0471
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8128
                     Learning rate: 0.0006
                       Mean reward: 84.62
               Mean episode length: 921.70
       Episode_Reward/keep_balance: 0.9102
     Episode_Reward/rew_lin_vel_xy: 3.4460
      Episode_Reward/rew_ang_vel_z: 2.4353
    Episode_Reward/pen_base_height: -0.3175
      Episode_Reward/pen_lin_vel_z: -0.0654
     Episode_Reward/pen_ang_vel_xy: -0.1529
   Episode_Reward/pen_joint_torque: -0.2038
    Episode_Reward/pen_joint_accel: -0.1168
    Episode_Reward/pen_action_rate: -0.0876
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0463
   Episode_Reward/pen_joint_powers: -0.0718
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1850
Episode_Reward/pen_flat_orientation: -0.1684
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2943
   Episode_Reward/foot_landing_vel: -0.1560
   Episode_Reward/test_gait_reward: -0.8546
Metrics/base_velocity/error_vel_xy: 2.1589
Metrics/base_velocity/error_vel_yaw: 1.0653
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 1.08s
                        Total time: 810.06s
                               ETA: 2461.8s

################################################################################
                     [1m Learning iteration 743/3000 [0m                      

                       Computation: 92467 steps/s (collection: 0.942s, learning 0.121s)
               Value function loss: 1.0636
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8129
                     Learning rate: 0.0006
                       Mean reward: 86.91
               Mean episode length: 938.91
       Episode_Reward/keep_balance: 0.9527
     Episode_Reward/rew_lin_vel_xy: 3.6136
      Episode_Reward/rew_ang_vel_z: 2.5302
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0577
     Episode_Reward/pen_ang_vel_xy: -0.1472
   Episode_Reward/pen_joint_torque: -0.1939
    Episode_Reward/pen_joint_accel: -0.1153
    Episode_Reward/pen_action_rate: -0.0905
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0444
   Episode_Reward/pen_joint_powers: -0.0684
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1952
Episode_Reward/pen_flat_orientation: -0.1537
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2753
   Episode_Reward/foot_landing_vel: -0.1487
   Episode_Reward/test_gait_reward: -0.8821
Metrics/base_velocity/error_vel_xy: 2.1873
Metrics/base_velocity/error_vel_yaw: 1.1314
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 1.06s
                        Total time: 811.13s
                               ETA: 2460.6s

################################################################################
                     [1m Learning iteration 744/3000 [0m                      

                       Computation: 93212 steps/s (collection: 0.932s, learning 0.122s)
               Value function loss: 1.1255
                    Surrogate loss: -0.0008
             Mean action noise std: 0.8146
                     Learning rate: 0.0003
                       Mean reward: 87.19
               Mean episode length: 926.72
       Episode_Reward/keep_balance: 0.9307
     Episode_Reward/rew_lin_vel_xy: 3.4649
      Episode_Reward/rew_ang_vel_z: 2.4761
    Episode_Reward/pen_base_height: -0.2945
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.1519
   Episode_Reward/pen_joint_torque: -0.1861
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.0894
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0434
   Episode_Reward/pen_joint_powers: -0.0662
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1940
Episode_Reward/pen_flat_orientation: -0.1435
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2595
   Episode_Reward/foot_landing_vel: -0.1363
   Episode_Reward/test_gait_reward: -0.8633
Metrics/base_velocity/error_vel_xy: 2.1503
Metrics/base_velocity/error_vel_yaw: 1.1031
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 1.05s
                        Total time: 812.18s
                               ETA: 2459.4s

################################################################################
                     [1m Learning iteration 745/3000 [0m                      

                       Computation: 91927 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.1000
                    Surrogate loss: 0.0007
             Mean action noise std: 0.8153
                     Learning rate: 0.0000
                       Mean reward: 93.04
               Mean episode length: 936.77
       Episode_Reward/keep_balance: 0.9143
     Episode_Reward/rew_lin_vel_xy: 3.8499
      Episode_Reward/rew_ang_vel_z: 2.4421
    Episode_Reward/pen_base_height: -0.3110
      Episode_Reward/pen_lin_vel_z: -0.0587
     Episode_Reward/pen_ang_vel_xy: -0.1396
   Episode_Reward/pen_joint_torque: -0.1899
    Episode_Reward/pen_joint_accel: -0.1015
    Episode_Reward/pen_action_rate: -0.0868
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0425
   Episode_Reward/pen_joint_powers: -0.0659
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1876
Episode_Reward/pen_flat_orientation: -0.1576
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2664
   Episode_Reward/foot_landing_vel: -0.1388
   Episode_Reward/test_gait_reward: -0.8482
Metrics/base_velocity/error_vel_xy: 1.9223
Metrics/base_velocity/error_vel_yaw: 1.0804
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 1.07s
                        Total time: 813.25s
                               ETA: 2458.3s

################################################################################
                     [1m Learning iteration 746/3000 [0m                      

                       Computation: 91875 steps/s (collection: 0.949s, learning 0.121s)
               Value function loss: 1.0214
                    Surrogate loss: 0.0050
             Mean action noise std: 0.8153
                     Learning rate: 0.0000
                       Mean reward: 86.62
               Mean episode length: 926.09
       Episode_Reward/keep_balance: 0.8998
     Episode_Reward/rew_lin_vel_xy: 3.4875
      Episode_Reward/rew_ang_vel_z: 2.4045
    Episode_Reward/pen_base_height: -0.3067
      Episode_Reward/pen_lin_vel_z: -0.0585
     Episode_Reward/pen_ang_vel_xy: -0.1485
   Episode_Reward/pen_joint_torque: -0.1886
    Episode_Reward/pen_joint_accel: -0.0957
    Episode_Reward/pen_action_rate: -0.0867
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0427
   Episode_Reward/pen_joint_powers: -0.0663
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1869
Episode_Reward/pen_flat_orientation: -0.1582
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2654
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.8369
Metrics/base_velocity/error_vel_xy: 2.0897
Metrics/base_velocity/error_vel_yaw: 1.0571
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 1.07s
                        Total time: 814.32s
                               ETA: 2457.1s

################################################################################
                     [1m Learning iteration 747/3000 [0m                      

                       Computation: 92698 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 1.1048
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8151
                     Learning rate: 0.0001
                       Mean reward: 83.01
               Mean episode length: 881.76
       Episode_Reward/keep_balance: 0.8936
     Episode_Reward/rew_lin_vel_xy: 3.4181
      Episode_Reward/rew_ang_vel_z: 2.3512
    Episode_Reward/pen_base_height: -0.3127
      Episode_Reward/pen_lin_vel_z: -0.0616
     Episode_Reward/pen_ang_vel_xy: -0.1479
   Episode_Reward/pen_joint_torque: -0.1935
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.0872
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0440
   Episode_Reward/pen_joint_powers: -0.0677
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1860
Episode_Reward/pen_flat_orientation: -0.1576
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2730
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.8318
Metrics/base_velocity/error_vel_xy: 2.1254
Metrics/base_velocity/error_vel_yaw: 1.0816
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 1.06s
                        Total time: 815.38s
                               ETA: 2456.0s

################################################################################
                     [1m Learning iteration 748/3000 [0m                      

                       Computation: 91317 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 1.1278
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8156
                     Learning rate: 0.0003
                       Mean reward: 85.32
               Mean episode length: 926.20
       Episode_Reward/keep_balance: 0.9340
     Episode_Reward/rew_lin_vel_xy: 3.7439
      Episode_Reward/rew_ang_vel_z: 2.5037
    Episode_Reward/pen_base_height: -0.3046
      Episode_Reward/pen_lin_vel_z: -0.0580
     Episode_Reward/pen_ang_vel_xy: -0.1456
   Episode_Reward/pen_joint_torque: -0.1961
    Episode_Reward/pen_joint_accel: -0.1074
    Episode_Reward/pen_action_rate: -0.0889
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0424
   Episode_Reward/pen_joint_powers: -0.0672
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1916
Episode_Reward/pen_flat_orientation: -0.1519
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2624
   Episode_Reward/foot_landing_vel: -0.1382
   Episode_Reward/test_gait_reward: -0.8674
Metrics/base_velocity/error_vel_xy: 2.0332
Metrics/base_velocity/error_vel_yaw: 1.0881
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 1.08s
                        Total time: 816.46s
                               ETA: 2454.8s

################################################################################
                     [1m Learning iteration 749/3000 [0m                      

                       Computation: 92140 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 1.0825
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8190
                     Learning rate: 0.0006
                       Mean reward: 77.87
               Mean episode length: 871.30
       Episode_Reward/keep_balance: 0.8905
     Episode_Reward/rew_lin_vel_xy: 3.3970
      Episode_Reward/rew_ang_vel_z: 2.3719
    Episode_Reward/pen_base_height: -0.3187
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1449
   Episode_Reward/pen_joint_torque: -0.1842
    Episode_Reward/pen_joint_accel: -0.1027
    Episode_Reward/pen_action_rate: -0.0860
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0416
   Episode_Reward/pen_joint_powers: -0.0645
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1852
Episode_Reward/pen_flat_orientation: -0.1546
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2600
   Episode_Reward/foot_landing_vel: -0.1388
   Episode_Reward/test_gait_reward: -0.8277
Metrics/base_velocity/error_vel_xy: 2.1162
Metrics/base_velocity/error_vel_yaw: 1.0600
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 1.07s
                        Total time: 817.52s
                               ETA: 2453.7s

################################################################################
                     [1m Learning iteration 750/3000 [0m                      

                       Computation: 92338 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 1.0652
                    Surrogate loss: -0.0012
             Mean action noise std: 0.8199
                     Learning rate: 0.0003
                       Mean reward: 86.80
               Mean episode length: 920.37
       Episode_Reward/keep_balance: 0.9195
     Episode_Reward/rew_lin_vel_xy: 3.7089
      Episode_Reward/rew_ang_vel_z: 2.4435
    Episode_Reward/pen_base_height: -0.3097
      Episode_Reward/pen_lin_vel_z: -0.0583
     Episode_Reward/pen_ang_vel_xy: -0.1488
   Episode_Reward/pen_joint_torque: -0.1886
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.0887
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0439
   Episode_Reward/pen_joint_powers: -0.0672
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1923
Episode_Reward/pen_flat_orientation: -0.1553
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2722
   Episode_Reward/foot_landing_vel: -0.1433
   Episode_Reward/test_gait_reward: -0.8511
Metrics/base_velocity/error_vel_xy: 2.0158
Metrics/base_velocity/error_vel_yaw: 1.0938
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 1.06s
                        Total time: 818.59s
                               ETA: 2452.5s

################################################################################
                     [1m Learning iteration 751/3000 [0m                      

                       Computation: 92969 steps/s (collection: 0.936s, learning 0.121s)
               Value function loss: 0.9626
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8188
                     Learning rate: 0.0006
                       Mean reward: 88.41
               Mean episode length: 941.63
       Episode_Reward/keep_balance: 0.9023
     Episode_Reward/rew_lin_vel_xy: 3.4686
      Episode_Reward/rew_ang_vel_z: 2.4377
    Episode_Reward/pen_base_height: -0.3089
      Episode_Reward/pen_lin_vel_z: -0.0585
     Episode_Reward/pen_ang_vel_xy: -0.1430
   Episode_Reward/pen_joint_torque: -0.1945
    Episode_Reward/pen_joint_accel: -0.0993
    Episode_Reward/pen_action_rate: -0.0859
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0416
   Episode_Reward/pen_joint_powers: -0.0662
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1850
Episode_Reward/pen_flat_orientation: -0.1513
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.2667
   Episode_Reward/foot_landing_vel: -0.1304
   Episode_Reward/test_gait_reward: -0.8331
Metrics/base_velocity/error_vel_xy: 2.1459
Metrics/base_velocity/error_vel_yaw: 1.0356
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 1.06s
                        Total time: 819.65s
                               ETA: 2451.3s

################################################################################
                     [1m Learning iteration 752/3000 [0m                      

                       Computation: 93622 steps/s (collection: 0.928s, learning 0.122s)
               Value function loss: 1.0816
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8181
                     Learning rate: 0.0006
                       Mean reward: 91.58
               Mean episode length: 936.15
       Episode_Reward/keep_balance: 0.9411
     Episode_Reward/rew_lin_vel_xy: 3.7638
      Episode_Reward/rew_ang_vel_z: 2.5284
    Episode_Reward/pen_base_height: -0.3065
      Episode_Reward/pen_lin_vel_z: -0.0571
     Episode_Reward/pen_ang_vel_xy: -0.1491
   Episode_Reward/pen_joint_torque: -0.1932
    Episode_Reward/pen_joint_accel: -0.1041
    Episode_Reward/pen_action_rate: -0.0900
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0656
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1952
Episode_Reward/pen_flat_orientation: -0.1415
  Episode_Reward/pen_feet_distance: -0.0028
Episode_Reward/pen_feet_regulation: -0.2478
   Episode_Reward/foot_landing_vel: -0.1323
   Episode_Reward/test_gait_reward: -0.8696
Metrics/base_velocity/error_vel_xy: 2.1187
Metrics/base_velocity/error_vel_yaw: 1.0884
      Episode_Termination/time_out: 3.1250
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 1.05s
                        Total time: 820.70s
                               ETA: 2450.1s

################################################################################
                     [1m Learning iteration 753/3000 [0m                      

                       Computation: 91766 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 1.1314
                    Surrogate loss: -0.0005
             Mean action noise std: 0.8174
                     Learning rate: 0.0004
                       Mean reward: 89.10
               Mean episode length: 927.93
       Episode_Reward/keep_balance: 0.9379
     Episode_Reward/rew_lin_vel_xy: 3.6872
      Episode_Reward/rew_ang_vel_z: 2.4695
    Episode_Reward/pen_base_height: -0.3064
      Episode_Reward/pen_lin_vel_z: -0.0587
     Episode_Reward/pen_ang_vel_xy: -0.1528
   Episode_Reward/pen_joint_torque: -0.1925
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.0912
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0441
   Episode_Reward/pen_joint_powers: -0.0679
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1987
Episode_Reward/pen_flat_orientation: -0.1509
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2688
   Episode_Reward/foot_landing_vel: -0.1447
   Episode_Reward/test_gait_reward: -0.8630
Metrics/base_velocity/error_vel_xy: 2.2301
Metrics/base_velocity/error_vel_yaw: 1.1306
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 1.07s
                        Total time: 821.77s
                               ETA: 2449.0s

################################################################################
                     [1m Learning iteration 754/3000 [0m                      

                       Computation: 91995 steps/s (collection: 0.944s, learning 0.124s)
               Value function loss: 1.0857
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8180
                     Learning rate: 0.0006
                       Mean reward: 79.06
               Mean episode length: 885.07
       Episode_Reward/keep_balance: 0.8859
     Episode_Reward/rew_lin_vel_xy: 3.3381
      Episode_Reward/rew_ang_vel_z: 2.3490
    Episode_Reward/pen_base_height: -0.3099
      Episode_Reward/pen_lin_vel_z: -0.0591
     Episode_Reward/pen_ang_vel_xy: -0.1480
   Episode_Reward/pen_joint_torque: -0.1873
    Episode_Reward/pen_joint_accel: -0.0972
    Episode_Reward/pen_action_rate: -0.0864
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0419
   Episode_Reward/pen_joint_powers: -0.0652
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1870
Episode_Reward/pen_flat_orientation: -0.1498
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2700
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.8197
Metrics/base_velocity/error_vel_xy: 2.1260
Metrics/base_velocity/error_vel_yaw: 1.0606
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 1.07s
                        Total time: 822.84s
                               ETA: 2447.8s

################################################################################
                     [1m Learning iteration 755/3000 [0m                      

                       Computation: 92984 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 1.1454
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8196
                     Learning rate: 0.0009
                       Mean reward: 92.39
               Mean episode length: 951.07
       Episode_Reward/keep_balance: 0.9494
     Episode_Reward/rew_lin_vel_xy: 3.8976
      Episode_Reward/rew_ang_vel_z: 2.5216
    Episode_Reward/pen_base_height: -0.3332
      Episode_Reward/pen_lin_vel_z: -0.0635
     Episode_Reward/pen_ang_vel_xy: -0.1525
   Episode_Reward/pen_joint_torque: -0.2081
    Episode_Reward/pen_joint_accel: -0.1126
    Episode_Reward/pen_action_rate: -0.0930
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0452
   Episode_Reward/pen_joint_powers: -0.0717
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1985
Episode_Reward/pen_flat_orientation: -0.1565
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2954
   Episode_Reward/foot_landing_vel: -0.1535
   Episode_Reward/test_gait_reward: -0.8884
Metrics/base_velocity/error_vel_xy: 2.0951
Metrics/base_velocity/error_vel_yaw: 1.1281
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 1.06s
                        Total time: 823.89s
                               ETA: 2446.6s

################################################################################
                     [1m Learning iteration 756/3000 [0m                      

                       Computation: 89709 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 1.2267
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8188
                     Learning rate: 0.0009
                       Mean reward: 85.70
               Mean episode length: 909.32
       Episode_Reward/keep_balance: 0.9135
     Episode_Reward/rew_lin_vel_xy: 3.3890
      Episode_Reward/rew_ang_vel_z: 2.4301
    Episode_Reward/pen_base_height: -0.3113
      Episode_Reward/pen_lin_vel_z: -0.0558
     Episode_Reward/pen_ang_vel_xy: -0.1463
   Episode_Reward/pen_joint_torque: -0.1956
    Episode_Reward/pen_joint_accel: -0.1020
    Episode_Reward/pen_action_rate: -0.0890
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0418
   Episode_Reward/pen_joint_powers: -0.0663
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1934
Episode_Reward/pen_flat_orientation: -0.1451
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.2596
   Episode_Reward/foot_landing_vel: -0.1333
   Episode_Reward/test_gait_reward: -0.8405
Metrics/base_velocity/error_vel_xy: 2.1946
Metrics/base_velocity/error_vel_yaw: 1.0930
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 1.10s
                        Total time: 824.99s
                               ETA: 2445.5s

################################################################################
                     [1m Learning iteration 757/3000 [0m                      

                       Computation: 91662 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 1.0720
                    Surrogate loss: -0.0009
             Mean action noise std: 0.8197
                     Learning rate: 0.0006
                       Mean reward: 82.63
               Mean episode length: 919.78
       Episode_Reward/keep_balance: 0.9231
     Episode_Reward/rew_lin_vel_xy: 3.4768
      Episode_Reward/rew_ang_vel_z: 2.4433
    Episode_Reward/pen_base_height: -0.3181
      Episode_Reward/pen_lin_vel_z: -0.0630
     Episode_Reward/pen_ang_vel_xy: -0.1566
   Episode_Reward/pen_joint_torque: -0.2051
    Episode_Reward/pen_joint_accel: -0.1172
    Episode_Reward/pen_action_rate: -0.0909
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0466
   Episode_Reward/pen_joint_powers: -0.0725
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1958
Episode_Reward/pen_flat_orientation: -0.1614
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2958
   Episode_Reward/foot_landing_vel: -0.1508
   Episode_Reward/test_gait_reward: -0.8605
Metrics/base_velocity/error_vel_xy: 2.2366
Metrics/base_velocity/error_vel_yaw: 1.1051
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 1.07s
                        Total time: 826.06s
                               ETA: 2444.4s

################################################################################
                     [1m Learning iteration 758/3000 [0m                      

                       Computation: 90315 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 1.0614
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8192
                     Learning rate: 0.0004
                       Mean reward: 89.74
               Mean episode length: 939.08
       Episode_Reward/keep_balance: 0.9344
     Episode_Reward/rew_lin_vel_xy: 3.6667
      Episode_Reward/rew_ang_vel_z: 2.4754
    Episode_Reward/pen_base_height: -0.3175
      Episode_Reward/pen_lin_vel_z: -0.0590
     Episode_Reward/pen_ang_vel_xy: -0.1523
   Episode_Reward/pen_joint_torque: -0.2020
    Episode_Reward/pen_joint_accel: -0.1132
    Episode_Reward/pen_action_rate: -0.0912
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0449
   Episode_Reward/pen_joint_powers: -0.0701
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1967
Episode_Reward/pen_flat_orientation: -0.1573
  Episode_Reward/pen_feet_distance: -0.0044
Episode_Reward/pen_feet_regulation: -0.2831
   Episode_Reward/foot_landing_vel: -0.1470
   Episode_Reward/test_gait_reward: -0.8634
Metrics/base_velocity/error_vel_xy: 2.1987
Metrics/base_velocity/error_vel_yaw: 1.1199
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 1.09s
                        Total time: 827.15s
                               ETA: 2443.3s

################################################################################
                     [1m Learning iteration 759/3000 [0m                      

                       Computation: 91657 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 1.2029
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8178
                     Learning rate: 0.0009
                       Mean reward: 86.69
               Mean episode length: 942.75
       Episode_Reward/keep_balance: 0.9052
     Episode_Reward/rew_lin_vel_xy: 3.5561
      Episode_Reward/rew_ang_vel_z: 2.4241
    Episode_Reward/pen_base_height: -0.3064
      Episode_Reward/pen_lin_vel_z: -0.0590
     Episode_Reward/pen_ang_vel_xy: -0.1482
   Episode_Reward/pen_joint_torque: -0.1965
    Episode_Reward/pen_joint_accel: -0.1121
    Episode_Reward/pen_action_rate: -0.0891
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0440
   Episode_Reward/pen_joint_powers: -0.0680
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1920
Episode_Reward/pen_flat_orientation: -0.1460
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2779
   Episode_Reward/foot_landing_vel: -0.1468
   Episode_Reward/test_gait_reward: -0.8383
Metrics/base_velocity/error_vel_xy: 2.1200
Metrics/base_velocity/error_vel_yaw: 1.0657
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 1.07s
                        Total time: 828.22s
                               ETA: 2442.2s

################################################################################
                     [1m Learning iteration 760/3000 [0m                      

                       Computation: 90843 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 1.0455
                    Surrogate loss: 0.0002
             Mean action noise std: 0.8182
                     Learning rate: 0.0004
                       Mean reward: 83.34
               Mean episode length: 897.12
       Episode_Reward/keep_balance: 0.9028
     Episode_Reward/rew_lin_vel_xy: 3.5635
      Episode_Reward/rew_ang_vel_z: 2.3906
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0611
     Episode_Reward/pen_ang_vel_xy: -0.1429
   Episode_Reward/pen_joint_torque: -0.2017
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.0877
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0436
   Episode_Reward/pen_joint_powers: -0.0686
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1895
Episode_Reward/pen_flat_orientation: -0.1576
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2843
   Episode_Reward/foot_landing_vel: -0.1426
   Episode_Reward/test_gait_reward: -0.8363
Metrics/base_velocity/error_vel_xy: 2.0825
Metrics/base_velocity/error_vel_yaw: 1.0804
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 1.08s
                        Total time: 829.30s
                               ETA: 2441.1s

################################################################################
                     [1m Learning iteration 761/3000 [0m                      

                       Computation: 89195 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 1.1898
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8196
                     Learning rate: 0.0006
                       Mean reward: 85.62
               Mean episode length: 924.05
       Episode_Reward/keep_balance: 0.9223
     Episode_Reward/rew_lin_vel_xy: 3.6480
      Episode_Reward/rew_ang_vel_z: 2.4285
    Episode_Reward/pen_base_height: -0.3246
      Episode_Reward/pen_lin_vel_z: -0.0609
     Episode_Reward/pen_ang_vel_xy: -0.1514
   Episode_Reward/pen_joint_torque: -0.2000
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.0914
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0449
   Episode_Reward/pen_joint_powers: -0.0697
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1971
Episode_Reward/pen_flat_orientation: -0.1675
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.2961
   Episode_Reward/foot_landing_vel: -0.1466
   Episode_Reward/test_gait_reward: -0.8585
Metrics/base_velocity/error_vel_xy: 2.1096
Metrics/base_velocity/error_vel_yaw: 1.1188
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 1.10s
                        Total time: 830.41s
                               ETA: 2440.0s

################################################################################
                     [1m Learning iteration 762/3000 [0m                      

                       Computation: 89537 steps/s (collection: 0.976s, learning 0.122s)
               Value function loss: 1.0646
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8199
                     Learning rate: 0.0009
                       Mean reward: 83.58
               Mean episode length: 893.86
       Episode_Reward/keep_balance: 0.8693
     Episode_Reward/rew_lin_vel_xy: 3.4685
      Episode_Reward/rew_ang_vel_z: 2.2553
    Episode_Reward/pen_base_height: -0.3114
      Episode_Reward/pen_lin_vel_z: -0.0602
     Episode_Reward/pen_ang_vel_xy: -0.1530
   Episode_Reward/pen_joint_torque: -0.1873
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.0882
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0451
   Episode_Reward/pen_joint_powers: -0.0677
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1895
Episode_Reward/pen_flat_orientation: -0.1635
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2877
   Episode_Reward/foot_landing_vel: -0.1423
   Episode_Reward/test_gait_reward: -0.8132
Metrics/base_velocity/error_vel_xy: 1.9785
Metrics/base_velocity/error_vel_yaw: 1.0967
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 1.10s
                        Total time: 831.50s
                               ETA: 2438.9s

################################################################################
                     [1m Learning iteration 763/3000 [0m                      

                       Computation: 88817 steps/s (collection: 0.982s, learning 0.124s)
               Value function loss: 1.1293
                    Surrogate loss: 0.0002
             Mean action noise std: 0.8203
                     Learning rate: 0.0004
                       Mean reward: 88.09
               Mean episode length: 923.71
       Episode_Reward/keep_balance: 0.9360
     Episode_Reward/rew_lin_vel_xy: 3.7664
      Episode_Reward/rew_ang_vel_z: 2.4716
    Episode_Reward/pen_base_height: -0.3294
      Episode_Reward/pen_lin_vel_z: -0.0589
     Episode_Reward/pen_ang_vel_xy: -0.1500
   Episode_Reward/pen_joint_torque: -0.2092
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.0921
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0441
   Episode_Reward/pen_joint_powers: -0.0703
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1988
Episode_Reward/pen_flat_orientation: -0.1594
  Episode_Reward/pen_feet_distance: -0.0031
Episode_Reward/pen_feet_regulation: -0.2920
   Episode_Reward/foot_landing_vel: -0.1392
   Episode_Reward/test_gait_reward: -0.8661
Metrics/base_velocity/error_vel_xy: 2.1520
Metrics/base_velocity/error_vel_yaw: 1.1212
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 1.11s
                        Total time: 832.61s
                               ETA: 2437.9s

################################################################################
                     [1m Learning iteration 764/3000 [0m                      

                       Computation: 89313 steps/s (collection: 0.978s, learning 0.122s)
               Value function loss: 1.0674
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8205
                     Learning rate: 0.0006
                       Mean reward: 87.57
               Mean episode length: 928.79
       Episode_Reward/keep_balance: 0.9241
     Episode_Reward/rew_lin_vel_xy: 3.6583
      Episode_Reward/rew_ang_vel_z: 2.4717
    Episode_Reward/pen_base_height: -0.3209
      Episode_Reward/pen_lin_vel_z: -0.0625
     Episode_Reward/pen_ang_vel_xy: -0.1505
   Episode_Reward/pen_joint_torque: -0.2069
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.0908
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0706
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1952
Episode_Reward/pen_flat_orientation: -0.1497
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.2966
   Episode_Reward/foot_landing_vel: -0.1527
   Episode_Reward/test_gait_reward: -0.8535
Metrics/base_velocity/error_vel_xy: 2.2327
Metrics/base_velocity/error_vel_yaw: 1.0824
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 1.10s
                        Total time: 833.71s
                               ETA: 2436.8s

################################################################################
                     [1m Learning iteration 765/3000 [0m                      

                       Computation: 89802 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 0.9964
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8202
                     Learning rate: 0.0004
                       Mean reward: 86.84
               Mean episode length: 943.34
       Episode_Reward/keep_balance: 0.9471
     Episode_Reward/rew_lin_vel_xy: 3.9279
      Episode_Reward/rew_ang_vel_z: 2.4467
    Episode_Reward/pen_base_height: -0.3423
      Episode_Reward/pen_lin_vel_z: -0.0641
     Episode_Reward/pen_ang_vel_xy: -0.1499
   Episode_Reward/pen_joint_torque: -0.2084
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.0945
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0470
   Episode_Reward/pen_joint_powers: -0.0727
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2038
Episode_Reward/pen_flat_orientation: -0.1678
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.3185
   Episode_Reward/foot_landing_vel: -0.1591
   Episode_Reward/test_gait_reward: -0.8845
Metrics/base_velocity/error_vel_xy: 2.0645
Metrics/base_velocity/error_vel_yaw: 1.1751
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 1.09s
                        Total time: 834.81s
                               ETA: 2435.8s

################################################################################
                     [1m Learning iteration 766/3000 [0m                      

                       Computation: 91130 steps/s (collection: 0.953s, learning 0.125s)
               Value function loss: 1.0910
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8212
                     Learning rate: 0.0006
                       Mean reward: 85.60
               Mean episode length: 932.68
       Episode_Reward/keep_balance: 0.9228
     Episode_Reward/rew_lin_vel_xy: 3.4597
      Episode_Reward/rew_ang_vel_z: 2.4368
    Episode_Reward/pen_base_height: -0.3221
      Episode_Reward/pen_lin_vel_z: -0.0582
     Episode_Reward/pen_ang_vel_xy: -0.1547
   Episode_Reward/pen_joint_torque: -0.2066
    Episode_Reward/pen_joint_accel: -0.1128
    Episode_Reward/pen_action_rate: -0.0922
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0711
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1985
Episode_Reward/pen_flat_orientation: -0.1542
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2856
   Episode_Reward/foot_landing_vel: -0.1504
   Episode_Reward/test_gait_reward: -0.8510
Metrics/base_velocity/error_vel_xy: 2.2180
Metrics/base_velocity/error_vel_yaw: 1.1190
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 1.08s
                        Total time: 835.88s
                               ETA: 2434.6s

################################################################################
                     [1m Learning iteration 767/3000 [0m                      

                       Computation: 91429 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 1.0840
                    Surrogate loss: 0.0038
             Mean action noise std: 0.8216
                     Learning rate: 0.0001
                       Mean reward: 84.59
               Mean episode length: 911.89
       Episode_Reward/keep_balance: 0.9186
     Episode_Reward/rew_lin_vel_xy: 3.4272
      Episode_Reward/rew_ang_vel_z: 2.4435
    Episode_Reward/pen_base_height: -0.3108
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1490
   Episode_Reward/pen_joint_torque: -0.1934
    Episode_Reward/pen_joint_accel: -0.0966
    Episode_Reward/pen_action_rate: -0.0899
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0428
   Episode_Reward/pen_joint_powers: -0.0666
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1957
Episode_Reward/pen_flat_orientation: -0.1445
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2746
   Episode_Reward/foot_landing_vel: -0.1387
   Episode_Reward/test_gait_reward: -0.8422
Metrics/base_velocity/error_vel_xy: 2.2349
Metrics/base_velocity/error_vel_yaw: 1.0920
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 1.08s
                        Total time: 836.96s
                               ETA: 2433.5s

################################################################################
                     [1m Learning iteration 768/3000 [0m                      

                       Computation: 90205 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.9825
                    Surrogate loss: -0.0003
             Mean action noise std: 0.8216
                     Learning rate: 0.0001
                       Mean reward: 83.48
               Mean episode length: 901.02
       Episode_Reward/keep_balance: 0.8815
     Episode_Reward/rew_lin_vel_xy: 3.4916
      Episode_Reward/rew_ang_vel_z: 2.3342
    Episode_Reward/pen_base_height: -0.3022
      Episode_Reward/pen_lin_vel_z: -0.0547
     Episode_Reward/pen_ang_vel_xy: -0.1427
   Episode_Reward/pen_joint_torque: -0.1880
    Episode_Reward/pen_joint_accel: -0.0962
    Episode_Reward/pen_action_rate: -0.0869
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0405
   Episode_Reward/pen_joint_powers: -0.0640
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1896
Episode_Reward/pen_flat_orientation: -0.1441
  Episode_Reward/pen_feet_distance: -0.0029
Episode_Reward/pen_feet_regulation: -0.2536
   Episode_Reward/foot_landing_vel: -0.1297
   Episode_Reward/test_gait_reward: -0.8086
Metrics/base_velocity/error_vel_xy: 2.0432
Metrics/base_velocity/error_vel_yaw: 1.0571
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 1.09s
                        Total time: 838.05s
                               ETA: 2432.4s

################################################################################
                     [1m Learning iteration 769/3000 [0m                      

                       Computation: 91187 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.1025
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8219
                     Learning rate: 0.0002
                       Mean reward: 87.93
               Mean episode length: 917.71
       Episode_Reward/keep_balance: 0.9312
     Episode_Reward/rew_lin_vel_xy: 3.6810
      Episode_Reward/rew_ang_vel_z: 2.4682
    Episode_Reward/pen_base_height: -0.3145
      Episode_Reward/pen_lin_vel_z: -0.0551
     Episode_Reward/pen_ang_vel_xy: -0.1452
   Episode_Reward/pen_joint_torque: -0.2041
    Episode_Reward/pen_joint_accel: -0.1083
    Episode_Reward/pen_action_rate: -0.0918
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0429
   Episode_Reward/pen_joint_powers: -0.0684
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1993
Episode_Reward/pen_flat_orientation: -0.1417
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2770
   Episode_Reward/foot_landing_vel: -0.1338
   Episode_Reward/test_gait_reward: -0.8623
Metrics/base_velocity/error_vel_xy: 2.1734
Metrics/base_velocity/error_vel_yaw: 1.1031
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 1.08s
                        Total time: 839.13s
                               ETA: 2431.3s

################################################################################
                     [1m Learning iteration 770/3000 [0m                      

                       Computation: 91559 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 1.0659
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8211
                     Learning rate: 0.0004
                       Mean reward: 93.87
               Mean episode length: 958.23
       Episode_Reward/keep_balance: 0.9596
     Episode_Reward/rew_lin_vel_xy: 4.0660
      Episode_Reward/rew_ang_vel_z: 2.4796
    Episode_Reward/pen_base_height: -0.3177
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1611
   Episode_Reward/pen_joint_torque: -0.2005
    Episode_Reward/pen_joint_accel: -0.1184
    Episode_Reward/pen_action_rate: -0.0965
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0459
   Episode_Reward/pen_joint_powers: -0.0702
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2110
Episode_Reward/pen_flat_orientation: -0.1482
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2970
   Episode_Reward/foot_landing_vel: -0.1543
   Episode_Reward/test_gait_reward: -0.8873
Metrics/base_velocity/error_vel_xy: 2.0414
Metrics/base_velocity/error_vel_yaw: 1.1942
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 1.07s
                        Total time: 840.20s
                               ETA: 2430.2s

################################################################################
                     [1m Learning iteration 771/3000 [0m                      

                       Computation: 90999 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 1.1179
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8209
                     Learning rate: 0.0006
                       Mean reward: 94.77
               Mean episode length: 947.97
       Episode_Reward/keep_balance: 0.9600
     Episode_Reward/rew_lin_vel_xy: 4.0378
      Episode_Reward/rew_ang_vel_z: 2.5645
    Episode_Reward/pen_base_height: -0.3145
      Episode_Reward/pen_lin_vel_z: -0.0590
     Episode_Reward/pen_ang_vel_xy: -0.1559
   Episode_Reward/pen_joint_torque: -0.2044
    Episode_Reward/pen_joint_accel: -0.1077
    Episode_Reward/pen_action_rate: -0.0956
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0448
   Episode_Reward/pen_joint_powers: -0.0703
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2073
Episode_Reward/pen_flat_orientation: -0.1456
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2833
   Episode_Reward/foot_landing_vel: -0.1454
   Episode_Reward/test_gait_reward: -0.8911
Metrics/base_velocity/error_vel_xy: 2.0839
Metrics/base_velocity/error_vel_yaw: 1.1260
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 1.08s
                        Total time: 841.28s
                               ETA: 2429.0s

################################################################################
                     [1m Learning iteration 772/3000 [0m                      

                       Computation: 89942 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 1.1628
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8226
                     Learning rate: 0.0004
                       Mean reward: 87.15
               Mean episode length: 924.84
       Episode_Reward/keep_balance: 0.9161
     Episode_Reward/rew_lin_vel_xy: 3.6683
      Episode_Reward/rew_ang_vel_z: 2.4143
    Episode_Reward/pen_base_height: -0.3219
      Episode_Reward/pen_lin_vel_z: -0.0549
     Episode_Reward/pen_ang_vel_xy: -0.1469
   Episode_Reward/pen_joint_torque: -0.1971
    Episode_Reward/pen_joint_accel: -0.1032
    Episode_Reward/pen_action_rate: -0.0907
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0419
   Episode_Reward/pen_joint_powers: -0.0665
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1988
Episode_Reward/pen_flat_orientation: -0.1544
  Episode_Reward/pen_feet_distance: -0.0036
Episode_Reward/pen_feet_regulation: -0.2704
   Episode_Reward/foot_landing_vel: -0.1356
   Episode_Reward/test_gait_reward: -0.8431
Metrics/base_velocity/error_vel_xy: 2.0238
Metrics/base_velocity/error_vel_yaw: 1.1069
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 1.09s
                        Total time: 842.37s
                               ETA: 2428.0s

################################################################################
                     [1m Learning iteration 773/3000 [0m                      

                       Computation: 90146 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 1.0362
                    Surrogate loss: 0.0041
             Mean action noise std: 0.8231
                     Learning rate: 0.0000
                       Mean reward: 86.87
               Mean episode length: 920.26
       Episode_Reward/keep_balance: 0.9181
     Episode_Reward/rew_lin_vel_xy: 3.6995
      Episode_Reward/rew_ang_vel_z: 2.4028
    Episode_Reward/pen_base_height: -0.3210
      Episode_Reward/pen_lin_vel_z: -0.0589
     Episode_Reward/pen_ang_vel_xy: -0.1600
   Episode_Reward/pen_joint_torque: -0.1977
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.0935
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0464
   Episode_Reward/pen_joint_powers: -0.0707
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2030
Episode_Reward/pen_flat_orientation: -0.1573
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.3077
   Episode_Reward/foot_landing_vel: -0.1465
   Episode_Reward/test_gait_reward: -0.8587
Metrics/base_velocity/error_vel_xy: 2.0297
Metrics/base_velocity/error_vel_yaw: 1.1295
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 1.09s
                        Total time: 843.46s
                               ETA: 2426.9s

################################################################################
                     [1m Learning iteration 774/3000 [0m                      

                       Computation: 91729 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 1.0766
                    Surrogate loss: 0.0053
             Mean action noise std: 0.8231
                     Learning rate: 0.0000
                       Mean reward: 89.79
               Mean episode length: 952.61
       Episode_Reward/keep_balance: 0.9423
     Episode_Reward/rew_lin_vel_xy: 3.5755
      Episode_Reward/rew_ang_vel_z: 2.4855
    Episode_Reward/pen_base_height: -0.3246
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1466
   Episode_Reward/pen_joint_torque: -0.2054
    Episode_Reward/pen_joint_accel: -0.1036
    Episode_Reward/pen_action_rate: -0.0938
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0433
   Episode_Reward/pen_joint_powers: -0.0688
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2035
Episode_Reward/pen_flat_orientation: -0.1419
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2737
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.8709
Metrics/base_velocity/error_vel_xy: 2.3497
Metrics/base_velocity/error_vel_yaw: 1.1319
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 1.07s
                        Total time: 844.54s
                               ETA: 2425.7s

################################################################################
                     [1m Learning iteration 775/3000 [0m                      

                       Computation: 91187 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.0914
                    Surrogate loss: 0.0021
             Mean action noise std: 0.8234
                     Learning rate: 0.0000
                       Mean reward: 86.43
               Mean episode length: 944.18
       Episode_Reward/keep_balance: 0.9481
     Episode_Reward/rew_lin_vel_xy: 3.6927
      Episode_Reward/rew_ang_vel_z: 2.5035
    Episode_Reward/pen_base_height: -0.3254
      Episode_Reward/pen_lin_vel_z: -0.0592
     Episode_Reward/pen_ang_vel_xy: -0.1520
   Episode_Reward/pen_joint_torque: -0.2141
    Episode_Reward/pen_joint_accel: -0.1150
    Episode_Reward/pen_action_rate: -0.0940
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0455
   Episode_Reward/pen_joint_powers: -0.0719
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2041
Episode_Reward/pen_flat_orientation: -0.1547
  Episode_Reward/pen_feet_distance: -0.0031
Episode_Reward/pen_feet_regulation: -0.2960
   Episode_Reward/foot_landing_vel: -0.1537
   Episode_Reward/test_gait_reward: -0.8731
Metrics/base_velocity/error_vel_xy: 2.1687
Metrics/base_velocity/error_vel_yaw: 1.1368
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 1.08s
                        Total time: 845.61s
                               ETA: 2424.6s

################################################################################
                     [1m Learning iteration 776/3000 [0m                      

                       Computation: 91116 steps/s (collection: 0.952s, learning 0.127s)
               Value function loss: 1.0457
                    Surrogate loss: 0.0035
             Mean action noise std: 0.8235
                     Learning rate: 0.0000
                       Mean reward: 87.33
               Mean episode length: 926.87
       Episode_Reward/keep_balance: 0.9320
     Episode_Reward/rew_lin_vel_xy: 3.7339
      Episode_Reward/rew_ang_vel_z: 2.5067
    Episode_Reward/pen_base_height: -0.3062
      Episode_Reward/pen_lin_vel_z: -0.0549
     Episode_Reward/pen_ang_vel_xy: -0.1513
   Episode_Reward/pen_joint_torque: -0.1969
    Episode_Reward/pen_joint_accel: -0.0944
    Episode_Reward/pen_action_rate: -0.0921
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0423
   Episode_Reward/pen_joint_powers: -0.0674
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2008
Episode_Reward/pen_flat_orientation: -0.1439
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.2620
   Episode_Reward/foot_landing_vel: -0.1407
   Episode_Reward/test_gait_reward: -0.8498
Metrics/base_velocity/error_vel_xy: 2.0679
Metrics/base_velocity/error_vel_yaw: 1.0898
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 1.08s
                        Total time: 846.69s
                               ETA: 2423.5s

################################################################################
                     [1m Learning iteration 777/3000 [0m                      

                       Computation: 90757 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 1.0728
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8235
                     Learning rate: 0.0001
                       Mean reward: 86.13
               Mean episode length: 942.92
       Episode_Reward/keep_balance: 0.9473
     Episode_Reward/rew_lin_vel_xy: 3.6173
      Episode_Reward/rew_ang_vel_z: 2.5069
    Episode_Reward/pen_base_height: -0.3294
      Episode_Reward/pen_lin_vel_z: -0.0590
     Episode_Reward/pen_ang_vel_xy: -0.1596
   Episode_Reward/pen_joint_torque: -0.2006
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.0963
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0457
   Episode_Reward/pen_joint_powers: -0.0706
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2096
Episode_Reward/pen_flat_orientation: -0.1546
  Episode_Reward/pen_feet_distance: -0.0031
Episode_Reward/pen_feet_regulation: -0.2937
   Episode_Reward/foot_landing_vel: -0.1499
   Episode_Reward/test_gait_reward: -0.8741
Metrics/base_velocity/error_vel_xy: 2.1767
Metrics/base_velocity/error_vel_yaw: 1.1381
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 1.08s
                        Total time: 847.78s
                               ETA: 2422.4s

################################################################################
                     [1m Learning iteration 778/3000 [0m                      

                       Computation: 91201 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 1.0960
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8228
                     Learning rate: 0.0003
                       Mean reward: 89.82
               Mean episode length: 939.96
       Episode_Reward/keep_balance: 0.9452
     Episode_Reward/rew_lin_vel_xy: 3.7298
      Episode_Reward/rew_ang_vel_z: 2.4974
    Episode_Reward/pen_base_height: -0.3197
      Episode_Reward/pen_lin_vel_z: -0.0566
     Episode_Reward/pen_ang_vel_xy: -0.1516
   Episode_Reward/pen_joint_torque: -0.2072
    Episode_Reward/pen_joint_accel: -0.1095
    Episode_Reward/pen_action_rate: -0.0942
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0438
   Episode_Reward/pen_joint_powers: -0.0696
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2044
Episode_Reward/pen_flat_orientation: -0.1481
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.2775
   Episode_Reward/foot_landing_vel: -0.1423
   Episode_Reward/test_gait_reward: -0.8685
Metrics/base_velocity/error_vel_xy: 2.1918
Metrics/base_velocity/error_vel_yaw: 1.1348
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 1.08s
                        Total time: 848.85s
                               ETA: 2421.3s

################################################################################
                     [1m Learning iteration 779/3000 [0m                      

                       Computation: 89515 steps/s (collection: 0.973s, learning 0.125s)
               Value function loss: 1.0084
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8217
                     Learning rate: 0.0006
                       Mean reward: 86.25
               Mean episode length: 908.25
       Episode_Reward/keep_balance: 0.9197
     Episode_Reward/rew_lin_vel_xy: 3.5657
      Episode_Reward/rew_ang_vel_z: 2.4545
    Episode_Reward/pen_base_height: -0.3179
      Episode_Reward/pen_lin_vel_z: -0.0568
     Episode_Reward/pen_ang_vel_xy: -0.1449
   Episode_Reward/pen_joint_torque: -0.2021
    Episode_Reward/pen_joint_accel: -0.0979
    Episode_Reward/pen_action_rate: -0.0901
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0668
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1952
Episode_Reward/pen_flat_orientation: -0.1420
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.2687
   Episode_Reward/foot_landing_vel: -0.1361
   Episode_Reward/test_gait_reward: -0.8405
Metrics/base_velocity/error_vel_xy: 2.1929
Metrics/base_velocity/error_vel_yaw: 1.0782
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 1.10s
                        Total time: 849.95s
                               ETA: 2420.2s

################################################################################
                     [1m Learning iteration 780/3000 [0m                      

                       Computation: 92640 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 1.1664
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8227
                     Learning rate: 0.0013
                       Mean reward: 90.16
               Mean episode length: 926.48
       Episode_Reward/keep_balance: 0.9253
     Episode_Reward/rew_lin_vel_xy: 3.8324
      Episode_Reward/rew_ang_vel_z: 2.4724
    Episode_Reward/pen_base_height: -0.3009
      Episode_Reward/pen_lin_vel_z: -0.0579
     Episode_Reward/pen_ang_vel_xy: -0.1462
   Episode_Reward/pen_joint_torque: -0.1974
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.0927
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0434
   Episode_Reward/pen_joint_powers: -0.0681
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2030
Episode_Reward/pen_flat_orientation: -0.1399
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2813
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.8464
Metrics/base_velocity/error_vel_xy: 2.0448
Metrics/base_velocity/error_vel_yaw: 1.0836
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 1.06s
                        Total time: 851.01s
                               ETA: 2419.0s

################################################################################
                     [1m Learning iteration 781/3000 [0m                      

                       Computation: 92858 steps/s (collection: 0.937s, learning 0.122s)
               Value function loss: 1.3048
                    Surrogate loss: -0.0009
             Mean action noise std: 0.8247
                     Learning rate: 0.0013
                       Mean reward: 89.67
               Mean episode length: 929.28
       Episode_Reward/keep_balance: 0.9111
     Episode_Reward/rew_lin_vel_xy: 3.6550
      Episode_Reward/rew_ang_vel_z: 2.4144
    Episode_Reward/pen_base_height: -0.3108
      Episode_Reward/pen_lin_vel_z: -0.0542
     Episode_Reward/pen_ang_vel_xy: -0.1438
   Episode_Reward/pen_joint_torque: -0.1955
    Episode_Reward/pen_joint_accel: -0.0946
    Episode_Reward/pen_action_rate: -0.0910
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0421
   Episode_Reward/pen_joint_powers: -0.0670
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1990
Episode_Reward/pen_flat_orientation: -0.1481
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.2722
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.8356
Metrics/base_velocity/error_vel_xy: 2.0319
Metrics/base_velocity/error_vel_yaw: 1.0942
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 1.06s
                        Total time: 852.07s
                               ETA: 2417.8s

################################################################################
                     [1m Learning iteration 782/3000 [0m                      

                       Computation: 91985 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 1.1784
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8257
                     Learning rate: 0.0019
                       Mean reward: 94.25
               Mean episode length: 966.00
       Episode_Reward/keep_balance: 0.9646
     Episode_Reward/rew_lin_vel_xy: 3.9783
      Episode_Reward/rew_ang_vel_z: 2.5495
    Episode_Reward/pen_base_height: -0.3338
      Episode_Reward/pen_lin_vel_z: -0.0613
     Episode_Reward/pen_ang_vel_xy: -0.1554
   Episode_Reward/pen_joint_torque: -0.2183
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.0967
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0729
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2105
Episode_Reward/pen_flat_orientation: -0.1538
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2989
   Episode_Reward/foot_landing_vel: -0.1420
   Episode_Reward/test_gait_reward: -0.8899
Metrics/base_velocity/error_vel_xy: 2.1407
Metrics/base_velocity/error_vel_yaw: 1.1612
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 1.07s
                        Total time: 853.14s
                               ETA: 2416.7s

################################################################################
                     [1m Learning iteration 783/3000 [0m                      

                       Computation: 92132 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 1.2157
                    Surrogate loss: -0.0014
             Mean action noise std: 0.8258
                     Learning rate: 0.0009
                       Mean reward: 90.66
               Mean episode length: 956.45
       Episode_Reward/keep_balance: 0.9522
     Episode_Reward/rew_lin_vel_xy: 3.7555
      Episode_Reward/rew_ang_vel_z: 2.5044
    Episode_Reward/pen_base_height: -0.3167
      Episode_Reward/pen_lin_vel_z: -0.0606
     Episode_Reward/pen_ang_vel_xy: -0.1499
   Episode_Reward/pen_joint_torque: -0.2146
    Episode_Reward/pen_joint_accel: -0.1104
    Episode_Reward/pen_action_rate: -0.0955
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0453
   Episode_Reward/pen_joint_powers: -0.0725
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2072
Episode_Reward/pen_flat_orientation: -0.1512
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.2998
   Episode_Reward/foot_landing_vel: -0.1503
   Episode_Reward/test_gait_reward: -0.8723
Metrics/base_velocity/error_vel_xy: 2.2260
Metrics/base_velocity/error_vel_yaw: 1.1458
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 1.07s
                        Total time: 854.21s
                               ETA: 2415.5s

################################################################################
                     [1m Learning iteration 784/3000 [0m                      

                       Computation: 90897 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 1.1025
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8259
                     Learning rate: 0.0019
                       Mean reward: 90.73
               Mean episode length: 939.46
       Episode_Reward/keep_balance: 0.9382
     Episode_Reward/rew_lin_vel_xy: 3.7974
      Episode_Reward/rew_ang_vel_z: 2.4726
    Episode_Reward/pen_base_height: -0.3221
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1482
   Episode_Reward/pen_joint_torque: -0.2046
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.0937
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0436
   Episode_Reward/pen_joint_powers: -0.0688
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2046
Episode_Reward/pen_flat_orientation: -0.1471
  Episode_Reward/pen_feet_distance: -0.0038
Episode_Reward/pen_feet_regulation: -0.2763
   Episode_Reward/foot_landing_vel: -0.1409
   Episode_Reward/test_gait_reward: -0.8564
Metrics/base_velocity/error_vel_xy: 2.0341
Metrics/base_velocity/error_vel_yaw: 1.1300
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 1.08s
                        Total time: 855.29s
                               ETA: 2414.4s

################################################################################
                     [1m Learning iteration 785/3000 [0m                      

                       Computation: 90911 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 1.2501
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8265
                     Learning rate: 0.0029
                       Mean reward: 90.60
               Mean episode length: 958.06
       Episode_Reward/keep_balance: 0.9681
     Episode_Reward/rew_lin_vel_xy: 3.8704
      Episode_Reward/rew_ang_vel_z: 2.5517
    Episode_Reward/pen_base_height: -0.3180
      Episode_Reward/pen_lin_vel_z: -0.0553
     Episode_Reward/pen_ang_vel_xy: -0.1524
   Episode_Reward/pen_joint_torque: -0.2039
    Episode_Reward/pen_joint_accel: -0.1193
    Episode_Reward/pen_action_rate: -0.0972
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0705
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2138
Episode_Reward/pen_flat_orientation: -0.1445
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2913
   Episode_Reward/foot_landing_vel: -0.1406
   Episode_Reward/test_gait_reward: -0.8902
Metrics/base_velocity/error_vel_xy: 2.1762
Metrics/base_velocity/error_vel_yaw: 1.1648
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 1.08s
                        Total time: 856.37s
                               ETA: 2413.3s

################################################################################
                     [1m Learning iteration 786/3000 [0m                      

                       Computation: 91813 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 1.4113
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8290
                     Learning rate: 0.0029
                       Mean reward: 89.08
               Mean episode length: 941.39
       Episode_Reward/keep_balance: 0.9528
     Episode_Reward/rew_lin_vel_xy: 3.8618
      Episode_Reward/rew_ang_vel_z: 2.4875
    Episode_Reward/pen_base_height: -0.3216
      Episode_Reward/pen_lin_vel_z: -0.0534
     Episode_Reward/pen_ang_vel_xy: -0.1598
   Episode_Reward/pen_joint_torque: -0.2004
    Episode_Reward/pen_joint_accel: -0.1154
    Episode_Reward/pen_action_rate: -0.0979
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0706
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2141
Episode_Reward/pen_flat_orientation: -0.1495
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.2893
   Episode_Reward/foot_landing_vel: -0.1459
   Episode_Reward/test_gait_reward: -0.8781
Metrics/base_velocity/error_vel_xy: 2.0933
Metrics/base_velocity/error_vel_yaw: 1.1730
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 1.07s
                        Total time: 857.44s
                               ETA: 2412.2s

################################################################################
                     [1m Learning iteration 787/3000 [0m                      

                       Computation: 92073 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 1.1824
                    Surrogate loss: -0.0006
             Mean action noise std: 0.8310
                     Learning rate: 0.0013
                       Mean reward: 88.99
               Mean episode length: 929.86
       Episode_Reward/keep_balance: 0.9395
     Episode_Reward/rew_lin_vel_xy: 3.8276
      Episode_Reward/rew_ang_vel_z: 2.4576
    Episode_Reward/pen_base_height: -0.3240
      Episode_Reward/pen_lin_vel_z: -0.0591
     Episode_Reward/pen_ang_vel_xy: -0.1509
   Episode_Reward/pen_joint_torque: -0.2091
    Episode_Reward/pen_joint_accel: -0.1008
    Episode_Reward/pen_action_rate: -0.0950
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0713
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2072
Episode_Reward/pen_flat_orientation: -0.1481
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2894
   Episode_Reward/foot_landing_vel: -0.1460
   Episode_Reward/test_gait_reward: -0.8645
Metrics/base_velocity/error_vel_xy: 2.1077
Metrics/base_velocity/error_vel_yaw: 1.1451
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 1.07s
                        Total time: 858.51s
                               ETA: 2411.0s

################################################################################
                     [1m Learning iteration 788/3000 [0m                      

                       Computation: 91709 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 1.1317
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8314
                     Learning rate: 0.0019
                       Mean reward: 91.06
               Mean episode length: 950.41
       Episode_Reward/keep_balance: 0.9186
     Episode_Reward/rew_lin_vel_xy: 3.6050
      Episode_Reward/rew_ang_vel_z: 2.4751
    Episode_Reward/pen_base_height: -0.3025
      Episode_Reward/pen_lin_vel_z: -0.0567
     Episode_Reward/pen_ang_vel_xy: -0.1503
   Episode_Reward/pen_joint_torque: -0.2056
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.0922
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0437
   Episode_Reward/pen_joint_powers: -0.0695
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2028
Episode_Reward/pen_flat_orientation: -0.1384
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2776
   Episode_Reward/foot_landing_vel: -0.1402
   Episode_Reward/test_gait_reward: -0.8389
Metrics/base_velocity/error_vel_xy: 2.1425
Metrics/base_velocity/error_vel_yaw: 1.0660
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 1.07s
                        Total time: 859.58s
                               ETA: 2409.9s

################################################################################
                     [1m Learning iteration 789/3000 [0m                      

                       Computation: 93338 steps/s (collection: 0.928s, learning 0.125s)
               Value function loss: 1.0397
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8315
                     Learning rate: 0.0006
                       Mean reward: 91.20
               Mean episode length: 944.65
       Episode_Reward/keep_balance: 0.9614
     Episode_Reward/rew_lin_vel_xy: 3.7891
      Episode_Reward/rew_ang_vel_z: 2.5054
    Episode_Reward/pen_base_height: -0.3080
      Episode_Reward/pen_lin_vel_z: -0.0533
     Episode_Reward/pen_ang_vel_xy: -0.1485
   Episode_Reward/pen_joint_torque: -0.2021
    Episode_Reward/pen_joint_accel: -0.1060
    Episode_Reward/pen_action_rate: -0.0968
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0437
   Episode_Reward/pen_joint_powers: -0.0686
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2134
Episode_Reward/pen_flat_orientation: -0.1422
  Episode_Reward/pen_feet_distance: -0.0029
Episode_Reward/pen_feet_regulation: -0.2696
   Episode_Reward/foot_landing_vel: -0.1434
   Episode_Reward/test_gait_reward: -0.8718
Metrics/base_velocity/error_vel_xy: 2.2273
Metrics/base_velocity/error_vel_yaw: 1.1781
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 1.05s
                        Total time: 860.63s
                               ETA: 2408.7s

################################################################################
                     [1m Learning iteration 790/3000 [0m                      

                       Computation: 90596 steps/s (collection: 0.959s, learning 0.126s)
               Value function loss: 0.9898
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8311
                     Learning rate: 0.0009
                       Mean reward: 93.41
               Mean episode length: 952.93
       Episode_Reward/keep_balance: 0.9606
     Episode_Reward/rew_lin_vel_xy: 4.0045
      Episode_Reward/rew_ang_vel_z: 2.5505
    Episode_Reward/pen_base_height: -0.3247
      Episode_Reward/pen_lin_vel_z: -0.0586
     Episode_Reward/pen_ang_vel_xy: -0.1542
   Episode_Reward/pen_joint_torque: -0.2116
    Episode_Reward/pen_joint_accel: -0.1024
    Episode_Reward/pen_action_rate: -0.0967
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0444
   Episode_Reward/pen_joint_powers: -0.0711
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2113
Episode_Reward/pen_flat_orientation: -0.1453
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.2950
   Episode_Reward/foot_landing_vel: -0.1468
   Episode_Reward/test_gait_reward: -0.8825
Metrics/base_velocity/error_vel_xy: 2.1100
Metrics/base_velocity/error_vel_yaw: 1.1387
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 1.09s
                        Total time: 861.72s
                               ETA: 2407.6s

################################################################################
                     [1m Learning iteration 791/3000 [0m                      

                       Computation: 91171 steps/s (collection: 0.954s, learning 0.125s)
               Value function loss: 1.0514
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8310
                     Learning rate: 0.0013
                       Mean reward: 86.51
               Mean episode length: 949.87
       Episode_Reward/keep_balance: 0.9636
     Episode_Reward/rew_lin_vel_xy: 3.7739
      Episode_Reward/rew_ang_vel_z: 2.5316
    Episode_Reward/pen_base_height: -0.3385
      Episode_Reward/pen_lin_vel_z: -0.0602
     Episode_Reward/pen_ang_vel_xy: -0.1573
   Episode_Reward/pen_joint_torque: -0.2151
    Episode_Reward/pen_joint_accel: -0.1066
    Episode_Reward/pen_action_rate: -0.0978
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0455
   Episode_Reward/pen_joint_powers: -0.0727
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2122
Episode_Reward/pen_flat_orientation: -0.1530
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.3073
   Episode_Reward/foot_landing_vel: -0.1418
   Episode_Reward/test_gait_reward: -0.8889
Metrics/base_velocity/error_vel_xy: 2.1715
Metrics/base_velocity/error_vel_yaw: 1.1704
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 1.08s
                        Total time: 862.80s
                               ETA: 2406.5s

################################################################################
                     [1m Learning iteration 792/3000 [0m                      

                       Computation: 89839 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 1.0090
                    Surrogate loss: 0.0006
             Mean action noise std: 0.8314
                     Learning rate: 0.0002
                       Mean reward: 91.99
               Mean episode length: 946.91
       Episode_Reward/keep_balance: 0.9505
     Episode_Reward/rew_lin_vel_xy: 3.8405
      Episode_Reward/rew_ang_vel_z: 2.5238
    Episode_Reward/pen_base_height: -0.3154
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.1527
   Episode_Reward/pen_joint_torque: -0.2058
    Episode_Reward/pen_joint_accel: -0.0962
    Episode_Reward/pen_action_rate: -0.0944
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0437
   Episode_Reward/pen_joint_powers: -0.0698
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2079
Episode_Reward/pen_flat_orientation: -0.1377
  Episode_Reward/pen_feet_distance: -0.0035
Episode_Reward/pen_feet_regulation: -0.2806
   Episode_Reward/foot_landing_vel: -0.1324
   Episode_Reward/test_gait_reward: -0.8588
Metrics/base_velocity/error_vel_xy: 2.1183
Metrics/base_velocity/error_vel_yaw: 1.1225
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 1.09s
                        Total time: 863.89s
                               ETA: 2405.4s

################################################################################
                     [1m Learning iteration 793/3000 [0m                      

                       Computation: 91296 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 1.0548
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8305
                     Learning rate: 0.0004
                       Mean reward: 96.36
               Mean episode length: 962.73
       Episode_Reward/keep_balance: 0.9745
     Episode_Reward/rew_lin_vel_xy: 4.0460
      Episode_Reward/rew_ang_vel_z: 2.5656
    Episode_Reward/pen_base_height: -0.3198
      Episode_Reward/pen_lin_vel_z: -0.0536
     Episode_Reward/pen_ang_vel_xy: -0.1543
   Episode_Reward/pen_joint_torque: -0.2051
    Episode_Reward/pen_joint_accel: -0.1063
    Episode_Reward/pen_action_rate: -0.0975
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0428
   Episode_Reward/pen_joint_powers: -0.0689
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2159
Episode_Reward/pen_flat_orientation: -0.1378
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.2734
   Episode_Reward/foot_landing_vel: -0.1290
   Episode_Reward/test_gait_reward: -0.8882
Metrics/base_velocity/error_vel_xy: 2.1152
Metrics/base_velocity/error_vel_yaw: 1.1712
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 1.08s
                        Total time: 864.97s
                               ETA: 2404.3s

################################################################################
                     [1m Learning iteration 794/3000 [0m                      

                       Computation: 91272 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.9962
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8310
                     Learning rate: 0.0009
                       Mean reward: 94.72
               Mean episode length: 941.91
       Episode_Reward/keep_balance: 0.9499
     Episode_Reward/rew_lin_vel_xy: 3.9971
      Episode_Reward/rew_ang_vel_z: 2.4899
    Episode_Reward/pen_base_height: -0.3263
      Episode_Reward/pen_lin_vel_z: -0.0584
     Episode_Reward/pen_ang_vel_xy: -0.1672
   Episode_Reward/pen_joint_torque: -0.2041
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.0981
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0475
   Episode_Reward/pen_joint_powers: -0.0721
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2163
Episode_Reward/pen_flat_orientation: -0.1558
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.3025
   Episode_Reward/foot_landing_vel: -0.1436
   Episode_Reward/test_gait_reward: -0.8737
Metrics/base_velocity/error_vel_xy: 2.0156
Metrics/base_velocity/error_vel_yaw: 1.1692
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 1.08s
                        Total time: 866.05s
                               ETA: 2403.1s

################################################################################
                     [1m Learning iteration 795/3000 [0m                      

                       Computation: 90782 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.9767
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8312
                     Learning rate: 0.0006
                       Mean reward: 88.38
               Mean episode length: 925.85
       Episode_Reward/keep_balance: 0.9265
     Episode_Reward/rew_lin_vel_xy: 3.7734
      Episode_Reward/rew_ang_vel_z: 2.4137
    Episode_Reward/pen_base_height: -0.3158
      Episode_Reward/pen_lin_vel_z: -0.0572
     Episode_Reward/pen_ang_vel_xy: -0.1582
   Episode_Reward/pen_joint_torque: -0.2026
    Episode_Reward/pen_joint_accel: -0.1016
    Episode_Reward/pen_action_rate: -0.0940
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0442
   Episode_Reward/pen_joint_powers: -0.0698
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2053
Episode_Reward/pen_flat_orientation: -0.1435
  Episode_Reward/pen_feet_distance: -0.0031
Episode_Reward/pen_feet_regulation: -0.2865
   Episode_Reward/foot_landing_vel: -0.1396
   Episode_Reward/test_gait_reward: -0.8508
Metrics/base_velocity/error_vel_xy: 2.0772
Metrics/base_velocity/error_vel_yaw: 1.1426
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 1.08s
                        Total time: 867.13s
                               ETA: 2402.0s

################################################################################
                     [1m Learning iteration 796/3000 [0m                      

                       Computation: 92096 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 1.0781
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8311
                     Learning rate: 0.0009
                       Mean reward: 89.72
               Mean episode length: 960.05
       Episode_Reward/keep_balance: 0.9654
     Episode_Reward/rew_lin_vel_xy: 3.7729
      Episode_Reward/rew_ang_vel_z: 2.5568
    Episode_Reward/pen_base_height: -0.3368
      Episode_Reward/pen_lin_vel_z: -0.0579
     Episode_Reward/pen_ang_vel_xy: -0.1588
   Episode_Reward/pen_joint_torque: -0.2098
    Episode_Reward/pen_joint_accel: -0.1037
    Episode_Reward/pen_action_rate: -0.0973
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0444
   Episode_Reward/pen_joint_powers: -0.0716
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2121
Episode_Reward/pen_flat_orientation: -0.1457
  Episode_Reward/pen_feet_distance: -0.0031
Episode_Reward/pen_feet_regulation: -0.2951
   Episode_Reward/foot_landing_vel: -0.1468
   Episode_Reward/test_gait_reward: -0.8793
Metrics/base_velocity/error_vel_xy: 2.2896
Metrics/base_velocity/error_vel_yaw: 1.1496
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 1.07s
                        Total time: 868.20s
                               ETA: 2400.9s

################################################################################
                     [1m Learning iteration 797/3000 [0m                      

                       Computation: 91731 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 1.0766
                    Surrogate loss: 0.0114
             Mean action noise std: 0.8311
                     Learning rate: 0.0000
                       Mean reward: 91.29
               Mean episode length: 949.93
       Episode_Reward/keep_balance: 0.9558
     Episode_Reward/rew_lin_vel_xy: 3.8430
      Episode_Reward/rew_ang_vel_z: 2.4944
    Episode_Reward/pen_base_height: -0.3301
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1535
   Episode_Reward/pen_joint_torque: -0.2085
    Episode_Reward/pen_joint_accel: -0.1006
    Episode_Reward/pen_action_rate: -0.0961
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0436
   Episode_Reward/pen_joint_powers: -0.0707
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2102
Episode_Reward/pen_flat_orientation: -0.1437
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2864
   Episode_Reward/foot_landing_vel: -0.1338
   Episode_Reward/test_gait_reward: -0.8794
Metrics/base_velocity/error_vel_xy: 2.1470
Metrics/base_velocity/error_vel_yaw: 1.1776
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 1.07s
                        Total time: 869.27s
                               ETA: 2399.7s

################################################################################
                     [1m Learning iteration 798/3000 [0m                      

                       Computation: 87237 steps/s (collection: 1.000s, learning 0.127s)
               Value function loss: 1.1215
                    Surrogate loss: -0.0001
             Mean action noise std: 0.8312
                     Learning rate: 0.0001
                       Mean reward: 95.31
               Mean episode length: 958.60
       Episode_Reward/keep_balance: 0.9363
     Episode_Reward/rew_lin_vel_xy: 3.9378
      Episode_Reward/rew_ang_vel_z: 2.4471
    Episode_Reward/pen_base_height: -0.3251
      Episode_Reward/pen_lin_vel_z: -0.0568
     Episode_Reward/pen_ang_vel_xy: -0.1590
   Episode_Reward/pen_joint_torque: -0.2083
    Episode_Reward/pen_joint_accel: -0.1047
    Episode_Reward/pen_action_rate: -0.0957
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0715
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2096
Episode_Reward/pen_flat_orientation: -0.1507
  Episode_Reward/pen_feet_distance: -0.0039
Episode_Reward/pen_feet_regulation: -0.2941
   Episode_Reward/foot_landing_vel: -0.1392
   Episode_Reward/test_gait_reward: -0.8567
Metrics/base_velocity/error_vel_xy: 1.9633
Metrics/base_velocity/error_vel_yaw: 1.1455
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 1.13s
                        Total time: 870.39s
                               ETA: 2398.8s

################################################################################
                     [1m Learning iteration 799/3000 [0m                      

                       Computation: 92199 steps/s (collection: 0.940s, learning 0.126s)
               Value function loss: 1.0218
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8305
                     Learning rate: 0.0003
                       Mean reward: 89.60
               Mean episode length: 941.30
       Episode_Reward/keep_balance: 0.9436
     Episode_Reward/rew_lin_vel_xy: 3.7732
      Episode_Reward/rew_ang_vel_z: 2.4862
    Episode_Reward/pen_base_height: -0.3247
      Episode_Reward/pen_lin_vel_z: -0.0585
     Episode_Reward/pen_ang_vel_xy: -0.1526
   Episode_Reward/pen_joint_torque: -0.2094
    Episode_Reward/pen_joint_accel: -0.1074
    Episode_Reward/pen_action_rate: -0.0947
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0715
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2079
Episode_Reward/pen_flat_orientation: -0.1480
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.2926
   Episode_Reward/foot_landing_vel: -0.1407
   Episode_Reward/test_gait_reward: -0.8614
Metrics/base_velocity/error_vel_xy: 2.1142
Metrics/base_velocity/error_vel_yaw: 1.1411
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 1.07s
                        Total time: 871.46s
                               ETA: 2397.6s

################################################################################
                     [1m Learning iteration 800/3000 [0m                      

                       Computation: 91459 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 1.0944
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8313
                     Learning rate: 0.0006
                       Mean reward: 90.32
               Mean episode length: 911.05
       Episode_Reward/keep_balance: 0.9187
     Episode_Reward/rew_lin_vel_xy: 3.7450
      Episode_Reward/rew_ang_vel_z: 2.4437
    Episode_Reward/pen_base_height: -0.3080
      Episode_Reward/pen_lin_vel_z: -0.0540
     Episode_Reward/pen_ang_vel_xy: -0.1508
   Episode_Reward/pen_joint_torque: -0.1986
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.0925
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0422
   Episode_Reward/pen_joint_powers: -0.0679
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2038
Episode_Reward/pen_flat_orientation: -0.1431
  Episode_Reward/pen_feet_distance: -0.0039
Episode_Reward/pen_feet_regulation: -0.2707
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.8354
Metrics/base_velocity/error_vel_xy: 2.0382
Metrics/base_velocity/error_vel_yaw: 1.0915
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 1.07s
                        Total time: 872.54s
                               ETA: 2396.5s

################################################################################
                     [1m Learning iteration 801/3000 [0m                      

                       Computation: 91269 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 1.0916
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8321
                     Learning rate: 0.0009
                       Mean reward: 92.41
               Mean episode length: 951.04
       Episode_Reward/keep_balance: 0.9508
     Episode_Reward/rew_lin_vel_xy: 3.9291
      Episode_Reward/rew_ang_vel_z: 2.5104
    Episode_Reward/pen_base_height: -0.3224
      Episode_Reward/pen_lin_vel_z: -0.0555
     Episode_Reward/pen_ang_vel_xy: -0.1544
   Episode_Reward/pen_joint_torque: -0.2130
    Episode_Reward/pen_joint_accel: -0.1022
    Episode_Reward/pen_action_rate: -0.0952
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0437
   Episode_Reward/pen_joint_powers: -0.0708
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2087
Episode_Reward/pen_flat_orientation: -0.1438
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2809
   Episode_Reward/foot_landing_vel: -0.1311
   Episode_Reward/test_gait_reward: -0.8705
Metrics/base_velocity/error_vel_xy: 2.0777
Metrics/base_velocity/error_vel_yaw: 1.1363
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 1.08s
                        Total time: 873.61s
                               ETA: 2395.4s

################################################################################
                     [1m Learning iteration 802/3000 [0m                      

                       Computation: 92337 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 1.2798
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8325
                     Learning rate: 0.0013
                       Mean reward: 91.19
               Mean episode length: 946.02
       Episode_Reward/keep_balance: 0.9559
     Episode_Reward/rew_lin_vel_xy: 3.8001
      Episode_Reward/rew_ang_vel_z: 2.5573
    Episode_Reward/pen_base_height: -0.3046
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.1494
   Episode_Reward/pen_joint_torque: -0.2101
    Episode_Reward/pen_joint_accel: -0.0953
    Episode_Reward/pen_action_rate: -0.0940
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0425
   Episode_Reward/pen_joint_powers: -0.0701
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2081
Episode_Reward/pen_flat_orientation: -0.1408
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2685
   Episode_Reward/foot_landing_vel: -0.1325
   Episode_Reward/test_gait_reward: -0.8620
Metrics/base_velocity/error_vel_xy: 2.1836
Metrics/base_velocity/error_vel_yaw: 1.1168
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 1.06s
                        Total time: 874.68s
                               ETA: 2394.2s

################################################################################
                     [1m Learning iteration 803/3000 [0m                      

                       Computation: 90910 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 1.2593
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8337
                     Learning rate: 0.0004
                       Mean reward: 88.98
               Mean episode length: 956.51
       Episode_Reward/keep_balance: 0.9469
     Episode_Reward/rew_lin_vel_xy: 3.7520
      Episode_Reward/rew_ang_vel_z: 2.4844
    Episode_Reward/pen_base_height: -0.3283
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1584
   Episode_Reward/pen_joint_torque: -0.2087
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.0958
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0455
   Episode_Reward/pen_joint_powers: -0.0724
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2092
Episode_Reward/pen_flat_orientation: -0.1552
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2855
   Episode_Reward/foot_landing_vel: -0.1370
   Episode_Reward/test_gait_reward: -0.8649
Metrics/base_velocity/error_vel_xy: 2.1539
Metrics/base_velocity/error_vel_yaw: 1.1578
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 1.08s
                        Total time: 875.76s
                               ETA: 2393.1s

################################################################################
                     [1m Learning iteration 804/3000 [0m                      

                       Computation: 90643 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 1.0624
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8352
                     Learning rate: 0.0004
                       Mean reward: 91.96
               Mean episode length: 920.69
       Episode_Reward/keep_balance: 0.9241
     Episode_Reward/rew_lin_vel_xy: 3.7285
      Episode_Reward/rew_ang_vel_z: 2.4514
    Episode_Reward/pen_base_height: -0.3074
      Episode_Reward/pen_lin_vel_z: -0.0505
     Episode_Reward/pen_ang_vel_xy: -0.1519
   Episode_Reward/pen_joint_torque: -0.1962
    Episode_Reward/pen_joint_accel: -0.1001
    Episode_Reward/pen_action_rate: -0.0921
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0668
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2035
Episode_Reward/pen_flat_orientation: -0.1383
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2612
   Episode_Reward/foot_landing_vel: -0.1286
   Episode_Reward/test_gait_reward: -0.8411
Metrics/base_velocity/error_vel_xy: 1.9586
Metrics/base_velocity/error_vel_yaw: 1.0941
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 1.08s
                        Total time: 876.84s
                               ETA: 2392.0s

################################################################################
                     [1m Learning iteration 805/3000 [0m                      

                       Computation: 89753 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 1.1312
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8352
                     Learning rate: 0.0009
                       Mean reward: 91.08
               Mean episode length: 941.35
       Episode_Reward/keep_balance: 0.9522
     Episode_Reward/rew_lin_vel_xy: 3.8520
      Episode_Reward/rew_ang_vel_z: 2.5067
    Episode_Reward/pen_base_height: -0.3214
      Episode_Reward/pen_lin_vel_z: -0.0578
     Episode_Reward/pen_ang_vel_xy: -0.1567
   Episode_Reward/pen_joint_torque: -0.2109
    Episode_Reward/pen_joint_accel: -0.1041
    Episode_Reward/pen_action_rate: -0.0961
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0441
   Episode_Reward/pen_joint_powers: -0.0715
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2113
Episode_Reward/pen_flat_orientation: -0.1448
  Episode_Reward/pen_feet_distance: -0.0027
Episode_Reward/pen_feet_regulation: -0.2917
   Episode_Reward/foot_landing_vel: -0.1285
   Episode_Reward/test_gait_reward: -0.8762
Metrics/base_velocity/error_vel_xy: 2.1394
Metrics/base_velocity/error_vel_yaw: 1.1454
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 1.10s
                        Total time: 877.94s
                               ETA: 2390.9s

################################################################################
                     [1m Learning iteration 806/3000 [0m                      

                       Computation: 90097 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 1.1957
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8339
                     Learning rate: 0.0013
                       Mean reward: 93.18
               Mean episode length: 946.65
       Episode_Reward/keep_balance: 0.9485
     Episode_Reward/rew_lin_vel_xy: 3.8174
      Episode_Reward/rew_ang_vel_z: 2.4927
    Episode_Reward/pen_base_height: -0.3145
      Episode_Reward/pen_lin_vel_z: -0.0525
     Episode_Reward/pen_ang_vel_xy: -0.1487
   Episode_Reward/pen_joint_torque: -0.2019
    Episode_Reward/pen_joint_accel: -0.1030
    Episode_Reward/pen_action_rate: -0.0949
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0427
   Episode_Reward/pen_joint_powers: -0.0684
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2106
Episode_Reward/pen_flat_orientation: -0.1435
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.2701
   Episode_Reward/foot_landing_vel: -0.1368
   Episode_Reward/test_gait_reward: -0.8595
Metrics/base_velocity/error_vel_xy: 2.1262
Metrics/base_velocity/error_vel_yaw: 1.1444
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 1.09s
                        Total time: 879.03s
                               ETA: 2389.8s

################################################################################
                     [1m Learning iteration 807/3000 [0m                      

                       Computation: 90459 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 1.1445
                    Surrogate loss: 0.0002
             Mean action noise std: 0.8352
                     Learning rate: 0.0004
                       Mean reward: 88.68
               Mean episode length: 899.43
       Episode_Reward/keep_balance: 0.8939
     Episode_Reward/rew_lin_vel_xy: 3.6980
      Episode_Reward/rew_ang_vel_z: 2.3230
    Episode_Reward/pen_base_height: -0.3207
      Episode_Reward/pen_lin_vel_z: -0.0514
     Episode_Reward/pen_ang_vel_xy: -0.1516
   Episode_Reward/pen_joint_torque: -0.1922
    Episode_Reward/pen_joint_accel: -0.0928
    Episode_Reward/pen_action_rate: -0.0901
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0421
   Episode_Reward/pen_joint_powers: -0.0667
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1990
Episode_Reward/pen_flat_orientation: -0.1479
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2674
   Episode_Reward/foot_landing_vel: -0.1266
   Episode_Reward/test_gait_reward: -0.8145
Metrics/base_velocity/error_vel_xy: 1.8835
Metrics/base_velocity/error_vel_yaw: 1.1106
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 1.09s
                        Total time: 880.12s
                               ETA: 2388.7s

################################################################################
                     [1m Learning iteration 808/3000 [0m                      

                       Computation: 89561 steps/s (collection: 0.976s, learning 0.122s)
               Value function loss: 1.0836
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8357
                     Learning rate: 0.0006
                       Mean reward: 97.26
               Mean episode length: 951.56
       Episode_Reward/keep_balance: 0.9505
     Episode_Reward/rew_lin_vel_xy: 4.0208
      Episode_Reward/rew_ang_vel_z: 2.5175
    Episode_Reward/pen_base_height: -0.3070
      Episode_Reward/pen_lin_vel_z: -0.0532
     Episode_Reward/pen_ang_vel_xy: -0.1531
   Episode_Reward/pen_joint_torque: -0.2023
    Episode_Reward/pen_joint_accel: -0.0980
    Episode_Reward/pen_action_rate: -0.0949
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0431
   Episode_Reward/pen_joint_powers: -0.0693
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2101
Episode_Reward/pen_flat_orientation: -0.1424
  Episode_Reward/pen_feet_distance: -0.0029
Episode_Reward/pen_feet_regulation: -0.2687
   Episode_Reward/foot_landing_vel: -0.1311
   Episode_Reward/test_gait_reward: -0.8650
Metrics/base_velocity/error_vel_xy: 1.9915
Metrics/base_velocity/error_vel_yaw: 1.1394
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 1.10s
                        Total time: 881.21s
                               ETA: 2387.7s

################################################################################
                     [1m Learning iteration 809/3000 [0m                      

                       Computation: 90688 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 1.1939
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8370
                     Learning rate: 0.0013
                       Mean reward: 94.94
               Mean episode length: 958.22
       Episode_Reward/keep_balance: 0.9420
     Episode_Reward/rew_lin_vel_xy: 3.8771
      Episode_Reward/rew_ang_vel_z: 2.5037
    Episode_Reward/pen_base_height: -0.3132
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1530
   Episode_Reward/pen_joint_torque: -0.2020
    Episode_Reward/pen_joint_accel: -0.0913
    Episode_Reward/pen_action_rate: -0.0945
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0437
   Episode_Reward/pen_joint_powers: -0.0696
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2084
Episode_Reward/pen_flat_orientation: -0.1485
  Episode_Reward/pen_feet_distance: -0.0035
Episode_Reward/pen_feet_regulation: -0.2886
   Episode_Reward/foot_landing_vel: -0.1310
   Episode_Reward/test_gait_reward: -0.8615
Metrics/base_velocity/error_vel_xy: 2.0440
Metrics/base_velocity/error_vel_yaw: 1.1132
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 1.08s
                        Total time: 882.30s
                               ETA: 2386.6s

################################################################################
                     [1m Learning iteration 810/3000 [0m                      

                       Computation: 90598 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 1.1035
                    Surrogate loss: 0.0012
             Mean action noise std: 0.8378
                     Learning rate: 0.0003
                       Mean reward: 89.44
               Mean episode length: 901.34
       Episode_Reward/keep_balance: 0.9179
     Episode_Reward/rew_lin_vel_xy: 3.8566
      Episode_Reward/rew_ang_vel_z: 2.4418
    Episode_Reward/pen_base_height: -0.3311
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1599
   Episode_Reward/pen_joint_torque: -0.2008
    Episode_Reward/pen_joint_accel: -0.1019
    Episode_Reward/pen_action_rate: -0.0940
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0440
   Episode_Reward/pen_joint_powers: -0.0706
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2046
Episode_Reward/pen_flat_orientation: -0.1500
  Episode_Reward/pen_feet_distance: -0.0098
Episode_Reward/pen_feet_regulation: -0.2910
   Episode_Reward/foot_landing_vel: -0.1270
   Episode_Reward/test_gait_reward: -0.8467
Metrics/base_velocity/error_vel_xy: 1.9577
Metrics/base_velocity/error_vel_yaw: 1.0916
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 1.09s
                        Total time: 883.38s
                               ETA: 2385.5s

################################################################################
                     [1m Learning iteration 811/3000 [0m                      

                       Computation: 90319 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.9977
                    Surrogate loss: -0.0014
             Mean action noise std: 0.8373
                     Learning rate: 0.0003
                       Mean reward: 92.64
               Mean episode length: 945.79
       Episode_Reward/keep_balance: 0.9331
     Episode_Reward/rew_lin_vel_xy: 3.8534
      Episode_Reward/rew_ang_vel_z: 2.4296
    Episode_Reward/pen_base_height: -0.3124
      Episode_Reward/pen_lin_vel_z: -0.0522
     Episode_Reward/pen_ang_vel_xy: -0.1585
   Episode_Reward/pen_joint_torque: -0.1980
    Episode_Reward/pen_joint_accel: -0.1039
    Episode_Reward/pen_action_rate: -0.0954
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0446
   Episode_Reward/pen_joint_powers: -0.0700
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2113
Episode_Reward/pen_flat_orientation: -0.1524
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.2836
   Episode_Reward/foot_landing_vel: -0.1331
   Episode_Reward/test_gait_reward: -0.8519
Metrics/base_velocity/error_vel_xy: 1.9681
Metrics/base_velocity/error_vel_yaw: 1.1513
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 1.09s
                        Total time: 884.47s
                               ETA: 2384.4s

################################################################################
                     [1m Learning iteration 812/3000 [0m                      

                       Computation: 91457 steps/s (collection: 0.951s, learning 0.124s)
               Value function loss: 1.0223
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8384
                     Learning rate: 0.0004
                       Mean reward: 94.94
               Mean episode length: 963.81
       Episode_Reward/keep_balance: 0.9495
     Episode_Reward/rew_lin_vel_xy: 3.7708
      Episode_Reward/rew_ang_vel_z: 2.5039
    Episode_Reward/pen_base_height: -0.3046
      Episode_Reward/pen_lin_vel_z: -0.0504
     Episode_Reward/pen_ang_vel_xy: -0.1621
   Episode_Reward/pen_joint_torque: -0.1897
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.0971
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0437
   Episode_Reward/pen_joint_powers: -0.0681
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2161
Episode_Reward/pen_flat_orientation: -0.1329
  Episode_Reward/pen_feet_distance: -0.0031
Episode_Reward/pen_feet_regulation: -0.2759
   Episode_Reward/foot_landing_vel: -0.1321
   Episode_Reward/test_gait_reward: -0.8690
Metrics/base_velocity/error_vel_xy: 2.1461
Metrics/base_velocity/error_vel_yaw: 1.1376
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 1.07s
                        Total time: 885.55s
                               ETA: 2383.2s

################################################################################
                     [1m Learning iteration 813/3000 [0m                      

                       Computation: 90586 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 0.9596
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8389
                     Learning rate: 0.0003
                       Mean reward: 95.80
               Mean episode length: 963.93
       Episode_Reward/keep_balance: 0.9640
     Episode_Reward/rew_lin_vel_xy: 4.1372
      Episode_Reward/rew_ang_vel_z: 2.5432
    Episode_Reward/pen_base_height: -0.3249
      Episode_Reward/pen_lin_vel_z: -0.0580
     Episode_Reward/pen_ang_vel_xy: -0.1652
   Episode_Reward/pen_joint_torque: -0.2081
    Episode_Reward/pen_joint_accel: -0.1112
    Episode_Reward/pen_action_rate: -0.0988
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0466
   Episode_Reward/pen_joint_powers: -0.0733
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2169
Episode_Reward/pen_flat_orientation: -0.1581
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2972
   Episode_Reward/foot_landing_vel: -0.1414
   Episode_Reward/test_gait_reward: -0.8918
Metrics/base_velocity/error_vel_xy: 1.9417
Metrics/base_velocity/error_vel_yaw: 1.1641
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 1.09s
                        Total time: 886.63s
                               ETA: 2382.1s

################################################################################
                     [1m Learning iteration 814/3000 [0m                      

                       Computation: 90981 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 1.1236
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8402
                     Learning rate: 0.0006
                       Mean reward: 92.43
               Mean episode length: 955.77
       Episode_Reward/keep_balance: 0.9654
     Episode_Reward/rew_lin_vel_xy: 3.9726
      Episode_Reward/rew_ang_vel_z: 2.5248
    Episode_Reward/pen_base_height: -0.3255
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.1698
   Episode_Reward/pen_joint_torque: -0.2033
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.0994
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0472
   Episode_Reward/pen_joint_powers: -0.0728
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2198
Episode_Reward/pen_flat_orientation: -0.1472
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2934
   Episode_Reward/foot_landing_vel: -0.1535
   Episode_Reward/test_gait_reward: -0.8891
Metrics/base_velocity/error_vel_xy: 2.0981
Metrics/base_velocity/error_vel_yaw: 1.1840
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 1.08s
                        Total time: 887.71s
                               ETA: 2381.0s

################################################################################
                     [1m Learning iteration 815/3000 [0m                      

                       Computation: 90854 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 1.0790
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8409
                     Learning rate: 0.0013
                       Mean reward: 92.31
               Mean episode length: 951.58
       Episode_Reward/keep_balance: 0.9575
     Episode_Reward/rew_lin_vel_xy: 4.0183
      Episode_Reward/rew_ang_vel_z: 2.4973
    Episode_Reward/pen_base_height: -0.3248
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1631
   Episode_Reward/pen_joint_torque: -0.2041
    Episode_Reward/pen_joint_accel: -0.1091
    Episode_Reward/pen_action_rate: -0.0983
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0459
   Episode_Reward/pen_joint_powers: -0.0722
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2161
Episode_Reward/pen_flat_orientation: -0.1559
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.2945
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.8843
Metrics/base_velocity/error_vel_xy: 1.9792
Metrics/base_velocity/error_vel_yaw: 1.1813
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 1.08s
                        Total time: 888.79s
                               ETA: 2379.9s

################################################################################
                     [1m Learning iteration 816/3000 [0m                      

                       Computation: 88419 steps/s (collection: 0.989s, learning 0.123s)
               Value function loss: 1.0899
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8428
                     Learning rate: 0.0013
                       Mean reward: 87.98
               Mean episode length: 892.38
       Episode_Reward/keep_balance: 0.9281
     Episode_Reward/rew_lin_vel_xy: 3.9660
      Episode_Reward/rew_ang_vel_z: 2.4718
    Episode_Reward/pen_base_height: -0.3168
      Episode_Reward/pen_lin_vel_z: -0.0531
     Episode_Reward/pen_ang_vel_xy: -0.1540
   Episode_Reward/pen_joint_torque: -0.1973
    Episode_Reward/pen_joint_accel: -0.1004
    Episode_Reward/pen_action_rate: -0.0934
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0425
   Episode_Reward/pen_joint_powers: -0.0683
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2051
Episode_Reward/pen_flat_orientation: -0.1495
  Episode_Reward/pen_feet_distance: -0.0037
Episode_Reward/pen_feet_regulation: -0.2739
   Episode_Reward/foot_landing_vel: -0.1271
   Episode_Reward/test_gait_reward: -0.8534
Metrics/base_velocity/error_vel_xy: 1.9259
Metrics/base_velocity/error_vel_yaw: 1.1001
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 1.11s
                        Total time: 889.91s
                               ETA: 2378.9s

################################################################################
                     [1m Learning iteration 817/3000 [0m                      

                       Computation: 92066 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 1.0870
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8433
                     Learning rate: 0.0009
                       Mean reward: 93.20
               Mean episode length: 955.58
       Episode_Reward/keep_balance: 0.9639
     Episode_Reward/rew_lin_vel_xy: 3.8858
      Episode_Reward/rew_ang_vel_z: 2.5442
    Episode_Reward/pen_base_height: -0.3205
      Episode_Reward/pen_lin_vel_z: -0.0564
     Episode_Reward/pen_ang_vel_xy: -0.1607
   Episode_Reward/pen_joint_torque: -0.2095
    Episode_Reward/pen_joint_accel: -0.1155
    Episode_Reward/pen_action_rate: -0.0979
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0463
   Episode_Reward/pen_joint_powers: -0.0731
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2156
Episode_Reward/pen_flat_orientation: -0.1479
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.3010
   Episode_Reward/foot_landing_vel: -0.1460
   Episode_Reward/test_gait_reward: -0.8861
Metrics/base_velocity/error_vel_xy: 2.1496
Metrics/base_velocity/error_vel_yaw: 1.1547
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 1.07s
                        Total time: 890.97s
                               ETA: 2377.7s

################################################################################
                     [1m Learning iteration 818/3000 [0m                      

                       Computation: 91183 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.1191
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8439
                     Learning rate: 0.0006
                       Mean reward: 88.28
               Mean episode length: 924.74
       Episode_Reward/keep_balance: 0.9404
     Episode_Reward/rew_lin_vel_xy: 3.7997
      Episode_Reward/rew_ang_vel_z: 2.5021
    Episode_Reward/pen_base_height: -0.3115
      Episode_Reward/pen_lin_vel_z: -0.0561
     Episode_Reward/pen_ang_vel_xy: -0.1656
   Episode_Reward/pen_joint_torque: -0.2020
    Episode_Reward/pen_joint_accel: -0.0918
    Episode_Reward/pen_action_rate: -0.0961
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0459
   Episode_Reward/pen_joint_powers: -0.0725
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2109
Episode_Reward/pen_flat_orientation: -0.1548
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.2953
   Episode_Reward/foot_landing_vel: -0.1418
   Episode_Reward/test_gait_reward: -0.8659
Metrics/base_velocity/error_vel_xy: 1.9743
Metrics/base_velocity/error_vel_yaw: 1.1188
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 1.08s
                        Total time: 892.05s
                               ETA: 2376.6s

################################################################################
                     [1m Learning iteration 819/3000 [0m                      

                       Computation: 90280 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 1.0527
                    Surrogate loss: -0.0016
             Mean action noise std: 0.8455
                     Learning rate: 0.0009
                       Mean reward: 85.15
               Mean episode length: 918.08
       Episode_Reward/keep_balance: 0.9228
     Episode_Reward/rew_lin_vel_xy: 3.6469
      Episode_Reward/rew_ang_vel_z: 2.4292
    Episode_Reward/pen_base_height: -0.3087
      Episode_Reward/pen_lin_vel_z: -0.0501
     Episode_Reward/pen_ang_vel_xy: -0.1568
   Episode_Reward/pen_joint_torque: -0.1899
    Episode_Reward/pen_joint_accel: -0.0925
    Episode_Reward/pen_action_rate: -0.0938
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0419
   Episode_Reward/pen_joint_powers: -0.0666
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2078
Episode_Reward/pen_flat_orientation: -0.1419
  Episode_Reward/pen_feet_distance: -0.0055
Episode_Reward/pen_feet_regulation: -0.2519
   Episode_Reward/foot_landing_vel: -0.1241
   Episode_Reward/test_gait_reward: -0.8416
Metrics/base_velocity/error_vel_xy: 2.0631
Metrics/base_velocity/error_vel_yaw: 1.1149
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 1.09s
                        Total time: 893.14s
                               ETA: 2375.5s

################################################################################
                     [1m Learning iteration 820/3000 [0m                      

                       Computation: 90843 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.9926
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8445
                     Learning rate: 0.0006
                       Mean reward: 94.60
               Mean episode length: 955.62
       Episode_Reward/keep_balance: 0.9641
     Episode_Reward/rew_lin_vel_xy: 3.9391
      Episode_Reward/rew_ang_vel_z: 2.5772
    Episode_Reward/pen_base_height: -0.3142
      Episode_Reward/pen_lin_vel_z: -0.0576
     Episode_Reward/pen_ang_vel_xy: -0.1597
   Episode_Reward/pen_joint_torque: -0.2081
    Episode_Reward/pen_joint_accel: -0.1076
    Episode_Reward/pen_action_rate: -0.0975
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0448
   Episode_Reward/pen_joint_powers: -0.0718
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2135
Episode_Reward/pen_flat_orientation: -0.1455
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.2878
   Episode_Reward/foot_landing_vel: -0.1346
   Episode_Reward/test_gait_reward: -0.8819
Metrics/base_velocity/error_vel_xy: 2.1105
Metrics/base_velocity/error_vel_yaw: 1.1292
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 1.08s
                        Total time: 894.22s
                               ETA: 2374.4s

################################################################################
                     [1m Learning iteration 821/3000 [0m                      

                       Computation: 92526 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 1.0406
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8450
                     Learning rate: 0.0009
                       Mean reward: 97.67
               Mean episode length: 977.27
       Episode_Reward/keep_balance: 0.9650
     Episode_Reward/rew_lin_vel_xy: 3.9900
      Episode_Reward/rew_ang_vel_z: 2.5680
    Episode_Reward/pen_base_height: -0.3223
      Episode_Reward/pen_lin_vel_z: -0.0589
     Episode_Reward/pen_ang_vel_xy: -0.1683
   Episode_Reward/pen_joint_torque: -0.2143
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.0986
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0461
   Episode_Reward/pen_joint_powers: -0.0746
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2158
Episode_Reward/pen_flat_orientation: -0.1563
  Episode_Reward/pen_feet_distance: -0.0038
Episode_Reward/pen_feet_regulation: -0.3029
   Episode_Reward/foot_landing_vel: -0.1395
   Episode_Reward/test_gait_reward: -0.8861
Metrics/base_velocity/error_vel_xy: 2.1299
Metrics/base_velocity/error_vel_yaw: 1.1413
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 1.06s
                        Total time: 895.28s
                               ETA: 2373.3s

################################################################################
                     [1m Learning iteration 822/3000 [0m                      

                       Computation: 92020 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.9581
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8459
                     Learning rate: 0.0009
                       Mean reward: 93.28
               Mean episode length: 944.22
       Episode_Reward/keep_balance: 0.9230
     Episode_Reward/rew_lin_vel_xy: 3.8957
      Episode_Reward/rew_ang_vel_z: 2.3995
    Episode_Reward/pen_base_height: -0.3082
      Episode_Reward/pen_lin_vel_z: -0.0537
     Episode_Reward/pen_ang_vel_xy: -0.1589
   Episode_Reward/pen_joint_torque: -0.1987
    Episode_Reward/pen_joint_accel: -0.1053
    Episode_Reward/pen_action_rate: -0.0952
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0456
   Episode_Reward/pen_joint_powers: -0.0715
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2106
Episode_Reward/pen_flat_orientation: -0.1461
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.2900
   Episode_Reward/foot_landing_vel: -0.1376
   Episode_Reward/test_gait_reward: -0.8491
Metrics/base_velocity/error_vel_xy: 1.9457
Metrics/base_velocity/error_vel_yaw: 1.1409
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 1.07s
                        Total time: 896.35s
                               ETA: 2372.1s

################################################################################
                     [1m Learning iteration 823/3000 [0m                      

                       Computation: 91882 steps/s (collection: 0.946s, learning 0.124s)
               Value function loss: 1.1454
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8461
                     Learning rate: 0.0006
                       Mean reward: 99.27
               Mean episode length: 967.94
       Episode_Reward/keep_balance: 0.9679
     Episode_Reward/rew_lin_vel_xy: 4.0213
      Episode_Reward/rew_ang_vel_z: 2.6001
    Episode_Reward/pen_base_height: -0.3123
      Episode_Reward/pen_lin_vel_z: -0.0551
     Episode_Reward/pen_ang_vel_xy: -0.1585
   Episode_Reward/pen_joint_torque: -0.2063
    Episode_Reward/pen_joint_accel: -0.1025
    Episode_Reward/pen_action_rate: -0.0965
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0441
   Episode_Reward/pen_joint_powers: -0.0714
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2129
Episode_Reward/pen_flat_orientation: -0.1417
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.2775
   Episode_Reward/foot_landing_vel: -0.1346
   Episode_Reward/test_gait_reward: -0.8812
Metrics/base_velocity/error_vel_xy: 2.0859
Metrics/base_velocity/error_vel_yaw: 1.1271
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 1.07s
                        Total time: 897.42s
                               ETA: 2371.0s

################################################################################
                     [1m Learning iteration 824/3000 [0m                      

                       Computation: 90353 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 1.0422
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8469
                     Learning rate: 0.0006
                       Mean reward: 90.61
               Mean episode length: 927.05
       Episode_Reward/keep_balance: 0.9265
     Episode_Reward/rew_lin_vel_xy: 3.7648
      Episode_Reward/rew_ang_vel_z: 2.4414
    Episode_Reward/pen_base_height: -0.3115
      Episode_Reward/pen_lin_vel_z: -0.0525
     Episode_Reward/pen_ang_vel_xy: -0.1540
   Episode_Reward/pen_joint_torque: -0.1983
    Episode_Reward/pen_joint_accel: -0.0985
    Episode_Reward/pen_action_rate: -0.0943
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0439
   Episode_Reward/pen_joint_powers: -0.0695
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2065
Episode_Reward/pen_flat_orientation: -0.1443
  Episode_Reward/pen_feet_distance: -0.0078
Episode_Reward/pen_feet_regulation: -0.2728
   Episode_Reward/foot_landing_vel: -0.1282
   Episode_Reward/test_gait_reward: -0.8453
Metrics/base_velocity/error_vel_xy: 1.9794
Metrics/base_velocity/error_vel_yaw: 1.1216
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 1.09s
                        Total time: 898.51s
                               ETA: 2369.9s

################################################################################
                     [1m Learning iteration 825/3000 [0m                      

                       Computation: 91311 steps/s (collection: 0.952s, learning 0.125s)
               Value function loss: 0.9885
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8480
                     Learning rate: 0.0009
                       Mean reward: 92.46
               Mean episode length: 923.28
       Episode_Reward/keep_balance: 0.9090
     Episode_Reward/rew_lin_vel_xy: 3.9515
      Episode_Reward/rew_ang_vel_z: 2.4024
    Episode_Reward/pen_base_height: -0.3093
      Episode_Reward/pen_lin_vel_z: -0.0580
     Episode_Reward/pen_ang_vel_xy: -0.1563
   Episode_Reward/pen_joint_torque: -0.2042
    Episode_Reward/pen_joint_accel: -0.1043
    Episode_Reward/pen_action_rate: -0.0925
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0721
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2008
Episode_Reward/pen_flat_orientation: -0.1573
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2904
   Episode_Reward/foot_landing_vel: -0.1293
   Episode_Reward/test_gait_reward: -0.8391
Metrics/base_velocity/error_vel_xy: 1.8953
Metrics/base_velocity/error_vel_yaw: 1.0927
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 1.08s
                        Total time: 899.59s
                               ETA: 2368.8s

################################################################################
                     [1m Learning iteration 826/3000 [0m                      

                       Computation: 91449 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 1.1109
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8494
                     Learning rate: 0.0004
                       Mean reward: 91.86
               Mean episode length: 923.18
       Episode_Reward/keep_balance: 0.9461
     Episode_Reward/rew_lin_vel_xy: 3.9282
      Episode_Reward/rew_ang_vel_z: 2.5072
    Episode_Reward/pen_base_height: -0.3133
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.1563
   Episode_Reward/pen_joint_torque: -0.1987
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.0960
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0448
   Episode_Reward/pen_joint_powers: -0.0704
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2124
Episode_Reward/pen_flat_orientation: -0.1416
  Episode_Reward/pen_feet_distance: -0.0031
Episode_Reward/pen_feet_regulation: -0.2809
   Episode_Reward/foot_landing_vel: -0.1358
   Episode_Reward/test_gait_reward: -0.8700
Metrics/base_velocity/error_vel_xy: 2.0630
Metrics/base_velocity/error_vel_yaw: 1.1273
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 1.07s
                        Total time: 900.66s
                               ETA: 2367.6s

################################################################################
                     [1m Learning iteration 827/3000 [0m                      

                       Computation: 92037 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 1.2028
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8506
                     Learning rate: 0.0006
                       Mean reward: 93.84
               Mean episode length: 953.38
       Episode_Reward/keep_balance: 0.9241
     Episode_Reward/rew_lin_vel_xy: 3.8549
      Episode_Reward/rew_ang_vel_z: 2.3772
    Episode_Reward/pen_base_height: -0.3133
      Episode_Reward/pen_lin_vel_z: -0.0521
     Episode_Reward/pen_ang_vel_xy: -0.1632
   Episode_Reward/pen_joint_torque: -0.1891
    Episode_Reward/pen_joint_accel: -0.1078
    Episode_Reward/pen_action_rate: -0.0967
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0453
   Episode_Reward/pen_joint_powers: -0.0694
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2141
Episode_Reward/pen_flat_orientation: -0.1491
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.2887
   Episode_Reward/foot_landing_vel: -0.1335
   Episode_Reward/test_gait_reward: -0.8561
Metrics/base_velocity/error_vel_xy: 1.9323
Metrics/base_velocity/error_vel_yaw: 1.1688
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 1.07s
                        Total time: 901.73s
                               ETA: 2366.5s

################################################################################
                     [1m Learning iteration 828/3000 [0m                      

                       Computation: 91517 steps/s (collection: 0.950s, learning 0.124s)
               Value function loss: 1.1122
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8509
                     Learning rate: 0.0009
                       Mean reward: 91.64
               Mean episode length: 943.34
       Episode_Reward/keep_balance: 0.9424
     Episode_Reward/rew_lin_vel_xy: 3.9448
      Episode_Reward/rew_ang_vel_z: 2.4692
    Episode_Reward/pen_base_height: -0.3198
      Episode_Reward/pen_lin_vel_z: -0.0529
     Episode_Reward/pen_ang_vel_xy: -0.1617
   Episode_Reward/pen_joint_torque: -0.1979
    Episode_Reward/pen_joint_accel: -0.1087
    Episode_Reward/pen_action_rate: -0.0979
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0464
   Episode_Reward/pen_joint_powers: -0.0719
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2155
Episode_Reward/pen_flat_orientation: -0.1506
  Episode_Reward/pen_feet_distance: -0.0061
Episode_Reward/pen_feet_regulation: -0.2978
   Episode_Reward/foot_landing_vel: -0.1378
   Episode_Reward/test_gait_reward: -0.8725
Metrics/base_velocity/error_vel_xy: 1.9200
Metrics/base_velocity/error_vel_yaw: 1.1536
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 1.07s
                        Total time: 902.80s
                               ETA: 2365.4s

################################################################################
                     [1m Learning iteration 829/3000 [0m                      

                       Computation: 90941 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 1.1150
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8504
                     Learning rate: 0.0006
                       Mean reward: 92.81
               Mean episode length: 950.26
       Episode_Reward/keep_balance: 0.9590
     Episode_Reward/rew_lin_vel_xy: 4.0426
      Episode_Reward/rew_ang_vel_z: 2.5130
    Episode_Reward/pen_base_height: -0.3146
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1626
   Episode_Reward/pen_joint_torque: -0.2036
    Episode_Reward/pen_joint_accel: -0.0962
    Episode_Reward/pen_action_rate: -0.0984
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0451
   Episode_Reward/pen_joint_powers: -0.0722
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2174
Episode_Reward/pen_flat_orientation: -0.1447
  Episode_Reward/pen_feet_distance: -0.0025
Episode_Reward/pen_feet_regulation: -0.2865
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.8795
Metrics/base_velocity/error_vel_xy: 2.0656
Metrics/base_velocity/error_vel_yaw: 1.1643
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 1.08s
                        Total time: 903.89s
                               ETA: 2364.3s

################################################################################
                     [1m Learning iteration 830/3000 [0m                      

                       Computation: 90879 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 1.0382
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8509
                     Learning rate: 0.0009
                       Mean reward: 94.00
               Mean episode length: 942.64
       Episode_Reward/keep_balance: 0.9474
     Episode_Reward/rew_lin_vel_xy: 3.8597
      Episode_Reward/rew_ang_vel_z: 2.4892
    Episode_Reward/pen_base_height: -0.3061
      Episode_Reward/pen_lin_vel_z: -0.0522
     Episode_Reward/pen_ang_vel_xy: -0.1718
   Episode_Reward/pen_joint_torque: -0.1967
    Episode_Reward/pen_joint_accel: -0.1089
    Episode_Reward/pen_action_rate: -0.0995
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0471
   Episode_Reward/pen_joint_powers: -0.0717
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2187
Episode_Reward/pen_flat_orientation: -0.1480
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2763
   Episode_Reward/foot_landing_vel: -0.1420
   Episode_Reward/test_gait_reward: -0.8618
Metrics/base_velocity/error_vel_xy: 2.1010
Metrics/base_velocity/error_vel_yaw: 1.1651
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 1.08s
                        Total time: 904.97s
                               ETA: 2363.2s

################################################################################
                     [1m Learning iteration 831/3000 [0m                      

                       Computation: 93259 steps/s (collection: 0.931s, learning 0.123s)
               Value function loss: 1.0895
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8514
                     Learning rate: 0.0006
                       Mean reward: 95.36
               Mean episode length: 969.53
       Episode_Reward/keep_balance: 0.9617
     Episode_Reward/rew_lin_vel_xy: 3.9544
      Episode_Reward/rew_ang_vel_z: 2.5313
    Episode_Reward/pen_base_height: -0.3259
      Episode_Reward/pen_lin_vel_z: -0.0581
     Episode_Reward/pen_ang_vel_xy: -0.1619
   Episode_Reward/pen_joint_torque: -0.2070
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.0980
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0461
   Episode_Reward/pen_joint_powers: -0.0732
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2151
Episode_Reward/pen_flat_orientation: -0.1585
  Episode_Reward/pen_feet_distance: -0.0057
Episode_Reward/pen_feet_regulation: -0.2958
   Episode_Reward/foot_landing_vel: -0.1458
   Episode_Reward/test_gait_reward: -0.8836
Metrics/base_velocity/error_vel_xy: 2.0687
Metrics/base_velocity/error_vel_yaw: 1.1608
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 1.05s
                        Total time: 906.02s
                               ETA: 2362.0s

################################################################################
                     [1m Learning iteration 832/3000 [0m                      

                       Computation: 91335 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 1.1705
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8497
                     Learning rate: 0.0006
                       Mean reward: 95.96
               Mean episode length: 958.47
       Episode_Reward/keep_balance: 0.9512
     Episode_Reward/rew_lin_vel_xy: 3.9769
      Episode_Reward/rew_ang_vel_z: 2.4979
    Episode_Reward/pen_base_height: -0.3227
      Episode_Reward/pen_lin_vel_z: -0.0552
     Episode_Reward/pen_ang_vel_xy: -0.1601
   Episode_Reward/pen_joint_torque: -0.2118
    Episode_Reward/pen_joint_accel: -0.1044
    Episode_Reward/pen_action_rate: -0.0966
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0729
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2114
Episode_Reward/pen_flat_orientation: -0.1499
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.2887
   Episode_Reward/foot_landing_vel: -0.1350
   Episode_Reward/test_gait_reward: -0.8721
Metrics/base_velocity/error_vel_xy: 2.0015
Metrics/base_velocity/error_vel_yaw: 1.1512
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 1.08s
                        Total time: 907.10s
                               ETA: 2360.8s

################################################################################
                     [1m Learning iteration 833/3000 [0m                      

                       Computation: 90454 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 1.0992
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8505
                     Learning rate: 0.0004
                       Mean reward: 94.56
               Mean episode length: 948.60
       Episode_Reward/keep_balance: 0.9553
     Episode_Reward/rew_lin_vel_xy: 3.9973
      Episode_Reward/rew_ang_vel_z: 2.5545
    Episode_Reward/pen_base_height: -0.3133
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.1629
   Episode_Reward/pen_joint_torque: -0.2006
    Episode_Reward/pen_joint_accel: -0.1025
    Episode_Reward/pen_action_rate: -0.0970
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0711
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2130
Episode_Reward/pen_flat_orientation: -0.1462
  Episode_Reward/pen_feet_distance: -0.0035
Episode_Reward/pen_feet_regulation: -0.2862
   Episode_Reward/foot_landing_vel: -0.1313
   Episode_Reward/test_gait_reward: -0.8717
Metrics/base_velocity/error_vel_xy: 1.9968
Metrics/base_velocity/error_vel_yaw: 1.1254
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 1.09s
                        Total time: 908.18s
                               ETA: 2359.8s

################################################################################
                     [1m Learning iteration 834/3000 [0m                      

                       Computation: 91868 steps/s (collection: 0.946s, learning 0.124s)
               Value function loss: 1.0334
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8526
                     Learning rate: 0.0009
                       Mean reward: 93.43
               Mean episode length: 955.61
       Episode_Reward/keep_balance: 0.9508
     Episode_Reward/rew_lin_vel_xy: 3.8706
      Episode_Reward/rew_ang_vel_z: 2.5025
    Episode_Reward/pen_base_height: -0.3178
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1680
   Episode_Reward/pen_joint_torque: -0.2054
    Episode_Reward/pen_joint_accel: -0.0998
    Episode_Reward/pen_action_rate: -0.0975
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0465
   Episode_Reward/pen_joint_powers: -0.0732
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2138
Episode_Reward/pen_flat_orientation: -0.1462
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.2943
   Episode_Reward/foot_landing_vel: -0.1315
   Episode_Reward/test_gait_reward: -0.8711
Metrics/base_velocity/error_vel_xy: 2.0779
Metrics/base_velocity/error_vel_yaw: 1.1510
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 1.07s
                        Total time: 909.25s
                               ETA: 2358.6s

################################################################################
                     [1m Learning iteration 835/3000 [0m                      

                       Computation: 92120 steps/s (collection: 0.943s, learning 0.124s)
               Value function loss: 1.1168
                    Surrogate loss: -0.0014
             Mean action noise std: 0.8543
                     Learning rate: 0.0006
                       Mean reward: 89.85
               Mean episode length: 939.30
       Episode_Reward/keep_balance: 0.9335
     Episode_Reward/rew_lin_vel_xy: 3.9010
      Episode_Reward/rew_ang_vel_z: 2.4484
    Episode_Reward/pen_base_height: -0.3104
      Episode_Reward/pen_lin_vel_z: -0.0556
     Episode_Reward/pen_ang_vel_xy: -0.1638
   Episode_Reward/pen_joint_torque: -0.2028
    Episode_Reward/pen_joint_accel: -0.1136
    Episode_Reward/pen_action_rate: -0.0957
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0457
   Episode_Reward/pen_joint_powers: -0.0718
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2112
Episode_Reward/pen_flat_orientation: -0.1417
  Episode_Reward/pen_feet_distance: -0.0048
Episode_Reward/pen_feet_regulation: -0.2984
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.8578
Metrics/base_velocity/error_vel_xy: 1.9638
Metrics/base_velocity/error_vel_yaw: 1.1330
      Episode_Termination/time_out: 2.6667
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 1.07s
                        Total time: 910.32s
                               ETA: 2357.5s

################################################################################
                     [1m Learning iteration 836/3000 [0m                      

                       Computation: 92977 steps/s (collection: 0.936s, learning 0.122s)
               Value function loss: 1.0949
                    Surrogate loss: -0.0000
             Mean action noise std: 0.8564
                     Learning rate: 0.0002
                       Mean reward: 87.49
               Mean episode length: 908.68
       Episode_Reward/keep_balance: 0.9322
     Episode_Reward/rew_lin_vel_xy: 3.7787
      Episode_Reward/rew_ang_vel_z: 2.4272
    Episode_Reward/pen_base_height: -0.3174
      Episode_Reward/pen_lin_vel_z: -0.0541
     Episode_Reward/pen_ang_vel_xy: -0.1707
   Episode_Reward/pen_joint_torque: -0.1962
    Episode_Reward/pen_joint_accel: -0.1019
    Episode_Reward/pen_action_rate: -0.0964
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0464
   Episode_Reward/pen_joint_powers: -0.0714
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2112
Episode_Reward/pen_flat_orientation: -0.1524
  Episode_Reward/pen_feet_distance: -0.0029
Episode_Reward/pen_feet_regulation: -0.2876
   Episode_Reward/foot_landing_vel: -0.1336
   Episode_Reward/test_gait_reward: -0.8552
Metrics/base_velocity/error_vel_xy: 2.0851
Metrics/base_velocity/error_vel_yaw: 1.1509
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 1.06s
                        Total time: 911.38s
                               ETA: 2356.3s

################################################################################
                     [1m Learning iteration 837/3000 [0m                      

                       Computation: 92366 steps/s (collection: 0.941s, learning 0.124s)
               Value function loss: 1.0929
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8574
                     Learning rate: 0.0003
                       Mean reward: 89.33
               Mean episode length: 963.56
       Episode_Reward/keep_balance: 0.9773
     Episode_Reward/rew_lin_vel_xy: 3.9437
      Episode_Reward/rew_ang_vel_z: 2.5353
    Episode_Reward/pen_base_height: -0.3245
      Episode_Reward/pen_lin_vel_z: -0.0574
     Episode_Reward/pen_ang_vel_xy: -0.1722
   Episode_Reward/pen_joint_torque: -0.2094
    Episode_Reward/pen_joint_accel: -0.0992
    Episode_Reward/pen_action_rate: -0.1008
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0473
   Episode_Reward/pen_joint_powers: -0.0746
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2202
Episode_Reward/pen_flat_orientation: -0.1500
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.3095
   Episode_Reward/foot_landing_vel: -0.1387
   Episode_Reward/test_gait_reward: -0.8956
Metrics/base_velocity/error_vel_xy: 2.1873
Metrics/base_velocity/error_vel_yaw: 1.2132
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 1.06s
                        Total time: 912.44s
                               ETA: 2355.1s

################################################################################
                     [1m Learning iteration 838/3000 [0m                      

                       Computation: 91530 steps/s (collection: 0.948s, learning 0.126s)
               Value function loss: 0.9871
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8598
                     Learning rate: 0.0004
                       Mean reward: 94.00
               Mean episode length: 925.24
       Episode_Reward/keep_balance: 0.9282
     Episode_Reward/rew_lin_vel_xy: 3.9404
      Episode_Reward/rew_ang_vel_z: 2.4638
    Episode_Reward/pen_base_height: -0.3246
      Episode_Reward/pen_lin_vel_z: -0.0557
     Episode_Reward/pen_ang_vel_xy: -0.1619
   Episode_Reward/pen_joint_torque: -0.2035
    Episode_Reward/pen_joint_accel: -0.1011
    Episode_Reward/pen_action_rate: -0.0943
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0717
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2055
Episode_Reward/pen_flat_orientation: -0.1444
  Episode_Reward/pen_feet_distance: -0.0046
Episode_Reward/pen_feet_regulation: -0.2945
   Episode_Reward/foot_landing_vel: -0.1334
   Episode_Reward/test_gait_reward: -0.8464
Metrics/base_velocity/error_vel_xy: 1.9425
Metrics/base_velocity/error_vel_yaw: 1.1053
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 1.07s
                        Total time: 913.52s
                               ETA: 2354.0s

################################################################################
                     [1m Learning iteration 839/3000 [0m                      

                       Computation: 92651 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 1.0163
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8599
                     Learning rate: 0.0006
                       Mean reward: 95.18
               Mean episode length: 961.07
       Episode_Reward/keep_balance: 0.9692
     Episode_Reward/rew_lin_vel_xy: 3.9362
      Episode_Reward/rew_ang_vel_z: 2.5690
    Episode_Reward/pen_base_height: -0.3207
      Episode_Reward/pen_lin_vel_z: -0.0533
     Episode_Reward/pen_ang_vel_xy: -0.1683
   Episode_Reward/pen_joint_torque: -0.2061
    Episode_Reward/pen_joint_accel: -0.0986
    Episode_Reward/pen_action_rate: -0.0984
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0452
   Episode_Reward/pen_joint_powers: -0.0724
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2177
Episode_Reward/pen_flat_orientation: -0.1395
  Episode_Reward/pen_feet_distance: -0.0044
Episode_Reward/pen_feet_regulation: -0.2930
   Episode_Reward/foot_landing_vel: -0.1331
   Episode_Reward/test_gait_reward: -0.8800
Metrics/base_velocity/error_vel_xy: 2.1898
Metrics/base_velocity/error_vel_yaw: 1.1544
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 1.06s
                        Total time: 914.58s
                               ETA: 2352.9s

################################################################################
                     [1m Learning iteration 840/3000 [0m                      

                       Computation: 92185 steps/s (collection: 0.943s, learning 0.124s)
               Value function loss: 1.0303
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8603
                     Learning rate: 0.0004
                       Mean reward: 94.34
               Mean episode length: 953.09
       Episode_Reward/keep_balance: 0.9642
     Episode_Reward/rew_lin_vel_xy: 3.9456
      Episode_Reward/rew_ang_vel_z: 2.5494
    Episode_Reward/pen_base_height: -0.3244
      Episode_Reward/pen_lin_vel_z: -0.0556
     Episode_Reward/pen_ang_vel_xy: -0.1634
   Episode_Reward/pen_joint_torque: -0.2124
    Episode_Reward/pen_joint_accel: -0.1021
    Episode_Reward/pen_action_rate: -0.0984
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0460
   Episode_Reward/pen_joint_powers: -0.0737
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2167
Episode_Reward/pen_flat_orientation: -0.1449
  Episode_Reward/pen_feet_distance: -0.0064
Episode_Reward/pen_feet_regulation: -0.3006
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.8817
Metrics/base_velocity/error_vel_xy: 2.0152
Metrics/base_velocity/error_vel_yaw: 1.1493
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 1.07s
                        Total time: 915.64s
                               ETA: 2351.7s

################################################################################
                     [1m Learning iteration 841/3000 [0m                      

                       Computation: 90575 steps/s (collection: 0.960s, learning 0.125s)
               Value function loss: 1.1215
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8608
                     Learning rate: 0.0009
                       Mean reward: 94.69
               Mean episode length: 949.66
       Episode_Reward/keep_balance: 0.9574
     Episode_Reward/rew_lin_vel_xy: 3.9545
      Episode_Reward/rew_ang_vel_z: 2.4978
    Episode_Reward/pen_base_height: -0.3113
      Episode_Reward/pen_lin_vel_z: -0.0559
     Episode_Reward/pen_ang_vel_xy: -0.1661
   Episode_Reward/pen_joint_torque: -0.2074
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.0980
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0465
   Episode_Reward/pen_joint_powers: -0.0737
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2158
Episode_Reward/pen_flat_orientation: -0.1448
  Episode_Reward/pen_feet_distance: -0.0044
Episode_Reward/pen_feet_regulation: -0.2983
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.8747
Metrics/base_velocity/error_vel_xy: 2.0615
Metrics/base_velocity/error_vel_yaw: 1.1734
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 1.09s
                        Total time: 916.73s
                               ETA: 2350.6s

################################################################################
                     [1m Learning iteration 842/3000 [0m                      

                       Computation: 91869 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.0900
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8607
                     Learning rate: 0.0013
                       Mean reward: 90.23
               Mean episode length: 933.06
       Episode_Reward/keep_balance: 0.9277
     Episode_Reward/rew_lin_vel_xy: 3.8387
      Episode_Reward/rew_ang_vel_z: 2.4391
    Episode_Reward/pen_base_height: -0.3145
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.1641
   Episode_Reward/pen_joint_torque: -0.2043
    Episode_Reward/pen_joint_accel: -0.0980
    Episode_Reward/pen_action_rate: -0.0953
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0717
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2100
Episode_Reward/pen_flat_orientation: -0.1435
  Episode_Reward/pen_feet_distance: -0.0055
Episode_Reward/pen_feet_regulation: -0.2938
   Episode_Reward/foot_landing_vel: -0.1310
   Episode_Reward/test_gait_reward: -0.8499
Metrics/base_velocity/error_vel_xy: 2.0619
Metrics/base_velocity/error_vel_yaw: 1.1186
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 1.07s
                        Total time: 917.80s
                               ETA: 2349.5s

################################################################################
                     [1m Learning iteration 843/3000 [0m                      

                       Computation: 91929 steps/s (collection: 0.945s, learning 0.124s)
               Value function loss: 1.2391
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8594
                     Learning rate: 0.0019
                       Mean reward: 90.28
               Mean episode length: 935.33
       Episode_Reward/keep_balance: 0.9360
     Episode_Reward/rew_lin_vel_xy: 3.7927
      Episode_Reward/rew_ang_vel_z: 2.4573
    Episode_Reward/pen_base_height: -0.3165
      Episode_Reward/pen_lin_vel_z: -0.0540
     Episode_Reward/pen_ang_vel_xy: -0.1596
   Episode_Reward/pen_joint_torque: -0.2075
    Episode_Reward/pen_joint_accel: -0.0956
    Episode_Reward/pen_action_rate: -0.0949
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0446
   Episode_Reward/pen_joint_powers: -0.0722
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2084
Episode_Reward/pen_flat_orientation: -0.1466
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.2850
   Episode_Reward/foot_landing_vel: -0.1288
   Episode_Reward/test_gait_reward: -0.8577
Metrics/base_velocity/error_vel_xy: 2.1009
Metrics/base_velocity/error_vel_yaw: 1.1451
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 1.07s
                        Total time: 918.87s
                               ETA: 2348.3s

################################################################################
                     [1m Learning iteration 844/3000 [0m                      

                       Computation: 91545 steps/s (collection: 0.949s, learning 0.125s)
               Value function loss: 1.1292
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8607
                     Learning rate: 0.0006
                       Mean reward: 93.42
               Mean episode length: 938.14
       Episode_Reward/keep_balance: 0.9374
     Episode_Reward/rew_lin_vel_xy: 3.9598
      Episode_Reward/rew_ang_vel_z: 2.4949
    Episode_Reward/pen_base_height: -0.3148
      Episode_Reward/pen_lin_vel_z: -0.0543
     Episode_Reward/pen_ang_vel_xy: -0.1630
   Episode_Reward/pen_joint_torque: -0.2077
    Episode_Reward/pen_joint_accel: -0.0984
    Episode_Reward/pen_action_rate: -0.0960
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0732
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2101
Episode_Reward/pen_flat_orientation: -0.1425
  Episode_Reward/pen_feet_distance: -0.0119
Episode_Reward/pen_feet_regulation: -0.3006
   Episode_Reward/foot_landing_vel: -0.1409
   Episode_Reward/test_gait_reward: -0.8617
Metrics/base_velocity/error_vel_xy: 1.9590
Metrics/base_velocity/error_vel_yaw: 1.1119
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 1.07s
                        Total time: 919.94s
                               ETA: 2347.2s

################################################################################
                     [1m Learning iteration 845/3000 [0m                      

                       Computation: 89457 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 1.0263
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8594
                     Learning rate: 0.0013
                       Mean reward: 89.23
               Mean episode length: 944.11
       Episode_Reward/keep_balance: 0.9538
     Episode_Reward/rew_lin_vel_xy: 3.7839
      Episode_Reward/rew_ang_vel_z: 2.4883
    Episode_Reward/pen_base_height: -0.3125
      Episode_Reward/pen_lin_vel_z: -0.0548
     Episode_Reward/pen_ang_vel_xy: -0.1682
   Episode_Reward/pen_joint_torque: -0.2052
    Episode_Reward/pen_joint_accel: -0.1039
    Episode_Reward/pen_action_rate: -0.0978
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0465
   Episode_Reward/pen_joint_powers: -0.0733
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2151
Episode_Reward/pen_flat_orientation: -0.1448
  Episode_Reward/pen_feet_distance: -0.0054
Episode_Reward/pen_feet_regulation: -0.2967
   Episode_Reward/foot_landing_vel: -0.1385
   Episode_Reward/test_gait_reward: -0.8707
Metrics/base_velocity/error_vel_xy: 2.1354
Metrics/base_velocity/error_vel_yaw: 1.1737
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 1.10s
                        Total time: 921.04s
                               ETA: 2346.2s

################################################################################
                     [1m Learning iteration 846/3000 [0m                      

                       Computation: 91264 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 1.1436
                    Surrogate loss: 0.0007
             Mean action noise std: 0.8602
                     Learning rate: 0.0004
                       Mean reward: 94.61
               Mean episode length: 956.15
       Episode_Reward/keep_balance: 0.9504
     Episode_Reward/rew_lin_vel_xy: 3.9182
      Episode_Reward/rew_ang_vel_z: 2.4657
    Episode_Reward/pen_base_height: -0.3262
      Episode_Reward/pen_lin_vel_z: -0.0518
     Episode_Reward/pen_ang_vel_xy: -0.1691
   Episode_Reward/pen_joint_torque: -0.2042
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.0985
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0460
   Episode_Reward/pen_joint_powers: -0.0727
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2171
Episode_Reward/pen_flat_orientation: -0.1448
  Episode_Reward/pen_feet_distance: -0.0035
Episode_Reward/pen_feet_regulation: -0.2969
   Episode_Reward/foot_landing_vel: -0.1291
   Episode_Reward/test_gait_reward: -0.8693
Metrics/base_velocity/error_vel_xy: 2.0329
Metrics/base_velocity/error_vel_yaw: 1.1850
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 1.08s
                        Total time: 922.12s
                               ETA: 2345.0s

################################################################################
                     [1m Learning iteration 847/3000 [0m                      

                       Computation: 90181 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 1.0387
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8609
                     Learning rate: 0.0006
                       Mean reward: 95.23
               Mean episode length: 951.19
       Episode_Reward/keep_balance: 0.9506
     Episode_Reward/rew_lin_vel_xy: 3.9796
      Episode_Reward/rew_ang_vel_z: 2.4986
    Episode_Reward/pen_base_height: -0.3031
      Episode_Reward/pen_lin_vel_z: -0.0516
     Episode_Reward/pen_ang_vel_xy: -0.1611
   Episode_Reward/pen_joint_torque: -0.2025
    Episode_Reward/pen_joint_accel: -0.0980
    Episode_Reward/pen_action_rate: -0.0965
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0711
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2145
Episode_Reward/pen_flat_orientation: -0.1387
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.2838
   Episode_Reward/foot_landing_vel: -0.1291
   Episode_Reward/test_gait_reward: -0.8601
Metrics/base_velocity/error_vel_xy: 2.0842
Metrics/base_velocity/error_vel_yaw: 1.1469
      Episode_Termination/time_out: 3.2500
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 1.09s
                        Total time: 923.21s
                               ETA: 2344.0s

################################################################################
                     [1m Learning iteration 848/3000 [0m                      

                       Computation: 90542 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 1.0745
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8612
                     Learning rate: 0.0004
                       Mean reward: 89.06
               Mean episode length: 917.76
       Episode_Reward/keep_balance: 0.8901
     Episode_Reward/rew_lin_vel_xy: 3.8041
      Episode_Reward/rew_ang_vel_z: 2.3067
    Episode_Reward/pen_base_height: -0.3106
      Episode_Reward/pen_lin_vel_z: -0.0528
     Episode_Reward/pen_ang_vel_xy: -0.1571
   Episode_Reward/pen_joint_torque: -0.1995
    Episode_Reward/pen_joint_accel: -0.0931
    Episode_Reward/pen_action_rate: -0.0918
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0445
   Episode_Reward/pen_joint_powers: -0.0705
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2015
Episode_Reward/pen_flat_orientation: -0.1427
  Episode_Reward/pen_feet_distance: -0.0047
Episode_Reward/pen_feet_regulation: -0.2953
   Episode_Reward/foot_landing_vel: -0.1325
   Episode_Reward/test_gait_reward: -0.8181
Metrics/base_velocity/error_vel_xy: 1.8599
Metrics/base_velocity/error_vel_yaw: 1.1038
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 1.09s
                        Total time: 924.30s
                               ETA: 2342.9s

################################################################################
                     [1m Learning iteration 849/3000 [0m                      

                       Computation: 90181 steps/s (collection: 0.965s, learning 0.125s)
               Value function loss: 1.0086
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8622
                     Learning rate: 0.0004
                       Mean reward: 90.25
               Mean episode length: 962.89
       Episode_Reward/keep_balance: 0.9790
     Episode_Reward/rew_lin_vel_xy: 3.9279
      Episode_Reward/rew_ang_vel_z: 2.5608
    Episode_Reward/pen_base_height: -0.3100
      Episode_Reward/pen_lin_vel_z: -0.0533
     Episode_Reward/pen_ang_vel_xy: -0.1634
   Episode_Reward/pen_joint_torque: -0.2105
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.1000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0460
   Episode_Reward/pen_joint_powers: -0.0734
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2224
Episode_Reward/pen_flat_orientation: -0.1338
  Episode_Reward/pen_feet_distance: -0.0043
Episode_Reward/pen_feet_regulation: -0.2881
   Episode_Reward/foot_landing_vel: -0.1428
   Episode_Reward/test_gait_reward: -0.8867
Metrics/base_velocity/error_vel_xy: 2.2158
Metrics/base_velocity/error_vel_yaw: 1.1932
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 1.09s
                        Total time: 925.39s
                               ETA: 2341.8s

################################################################################
                     [1m Learning iteration 850/3000 [0m                      

                       Computation: 90130 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 1.0219
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8623
                     Learning rate: 0.0009
                       Mean reward: 98.10
               Mean episode length: 955.26
       Episode_Reward/keep_balance: 0.9617
     Episode_Reward/rew_lin_vel_xy: 4.1020
      Episode_Reward/rew_ang_vel_z: 2.5341
    Episode_Reward/pen_base_height: -0.3161
      Episode_Reward/pen_lin_vel_z: -0.0528
     Episode_Reward/pen_ang_vel_xy: -0.1650
   Episode_Reward/pen_joint_torque: -0.2097
    Episode_Reward/pen_joint_accel: -0.0963
    Episode_Reward/pen_action_rate: -0.0986
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0466
   Episode_Reward/pen_joint_powers: -0.0739
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2176
Episode_Reward/pen_flat_orientation: -0.1384
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3041
   Episode_Reward/foot_landing_vel: -0.1388
   Episode_Reward/test_gait_reward: -0.8831
Metrics/base_velocity/error_vel_xy: 2.0121
Metrics/base_velocity/error_vel_yaw: 1.1581
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 1.09s
                        Total time: 926.48s
                               ETA: 2340.7s

################################################################################
                     [1m Learning iteration 851/3000 [0m                      

                       Computation: 91014 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.9855
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8649
                     Learning rate: 0.0009
                       Mean reward: 90.59
               Mean episode length: 950.69
       Episode_Reward/keep_balance: 0.9514
     Episode_Reward/rew_lin_vel_xy: 3.8758
      Episode_Reward/rew_ang_vel_z: 2.4942
    Episode_Reward/pen_base_height: -0.3293
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1706
   Episode_Reward/pen_joint_torque: -0.2106
    Episode_Reward/pen_joint_accel: -0.0996
    Episode_Reward/pen_action_rate: -0.0980
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0474
   Episode_Reward/pen_joint_powers: -0.0749
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2142
Episode_Reward/pen_flat_orientation: -0.1453
  Episode_Reward/pen_feet_distance: -0.0054
Episode_Reward/pen_feet_regulation: -0.3065
   Episode_Reward/foot_landing_vel: -0.1387
   Episode_Reward/test_gait_reward: -0.8716
Metrics/base_velocity/error_vel_xy: 2.0821
Metrics/base_velocity/error_vel_yaw: 1.1597
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 1.08s
                        Total time: 927.56s
                               ETA: 2339.6s

################################################################################
                     [1m Learning iteration 852/3000 [0m                      

                       Computation: 88977 steps/s (collection: 0.983s, learning 0.122s)
               Value function loss: 1.0483
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8658
                     Learning rate: 0.0004
                       Mean reward: 92.63
               Mean episode length: 951.99
       Episode_Reward/keep_balance: 0.9644
     Episode_Reward/rew_lin_vel_xy: 3.9662
      Episode_Reward/rew_ang_vel_z: 2.5539
    Episode_Reward/pen_base_height: -0.3293
      Episode_Reward/pen_lin_vel_z: -0.0542
     Episode_Reward/pen_ang_vel_xy: -0.1661
   Episode_Reward/pen_joint_torque: -0.2123
    Episode_Reward/pen_joint_accel: -0.1076
    Episode_Reward/pen_action_rate: -0.0995
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0470
   Episode_Reward/pen_joint_powers: -0.0753
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2183
Episode_Reward/pen_flat_orientation: -0.1408
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3083
   Episode_Reward/foot_landing_vel: -0.1370
   Episode_Reward/test_gait_reward: -0.8923
Metrics/base_velocity/error_vel_xy: 2.0938
Metrics/base_velocity/error_vel_yaw: 1.1508
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 1.10s
                        Total time: 928.66s
                               ETA: 2338.5s

################################################################################
                     [1m Learning iteration 853/3000 [0m                      

                       Computation: 91842 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.9804
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8639
                     Learning rate: 0.0006
                       Mean reward: 92.80
               Mean episode length: 953.01
       Episode_Reward/keep_balance: 0.9594
     Episode_Reward/rew_lin_vel_xy: 4.1065
      Episode_Reward/rew_ang_vel_z: 2.4709
    Episode_Reward/pen_base_height: -0.3138
      Episode_Reward/pen_lin_vel_z: -0.0508
     Episode_Reward/pen_ang_vel_xy: -0.1672
   Episode_Reward/pen_joint_torque: -0.2034
    Episode_Reward/pen_joint_accel: -0.1096
    Episode_Reward/pen_action_rate: -0.1003
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0465
   Episode_Reward/pen_joint_powers: -0.0725
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2232
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.3021
   Episode_Reward/foot_landing_vel: -0.1360
   Episode_Reward/test_gait_reward: -0.8821
Metrics/base_velocity/error_vel_xy: 1.9376
Metrics/base_velocity/error_vel_yaw: 1.1995
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 1.07s
                        Total time: 929.73s
                               ETA: 2337.4s

################################################################################
                     [1m Learning iteration 854/3000 [0m                      

                       Computation: 90272 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 1.0608
                    Surrogate loss: -0.0008
             Mean action noise std: 0.8631
                     Learning rate: 0.0001
                       Mean reward: 97.32
               Mean episode length: 940.81
       Episode_Reward/keep_balance: 0.9010
     Episode_Reward/rew_lin_vel_xy: 3.9470
      Episode_Reward/rew_ang_vel_z: 2.3896
    Episode_Reward/pen_base_height: -0.2998
      Episode_Reward/pen_lin_vel_z: -0.0494
     Episode_Reward/pen_ang_vel_xy: -0.1599
   Episode_Reward/pen_joint_torque: -0.1907
    Episode_Reward/pen_joint_accel: -0.1008
    Episode_Reward/pen_action_rate: -0.0922
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0433
   Episode_Reward/pen_joint_powers: -0.0685
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2047
Episode_Reward/pen_flat_orientation: -0.1321
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.2729
   Episode_Reward/foot_landing_vel: -0.1303
   Episode_Reward/test_gait_reward: -0.8237
Metrics/base_velocity/error_vel_xy: 1.8749
Metrics/base_velocity/error_vel_yaw: 1.0742
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 1.09s
                        Total time: 930.82s
                               ETA: 2336.3s

################################################################################
                     [1m Learning iteration 855/3000 [0m                      

                       Computation: 90267 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.9844
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8625
                     Learning rate: 0.0003
                       Mean reward: 95.58
               Mean episode length: 956.83
       Episode_Reward/keep_balance: 0.9651
     Episode_Reward/rew_lin_vel_xy: 4.2588
      Episode_Reward/rew_ang_vel_z: 2.5343
    Episode_Reward/pen_base_height: -0.3294
      Episode_Reward/pen_lin_vel_z: -0.0558
     Episode_Reward/pen_ang_vel_xy: -0.1702
   Episode_Reward/pen_joint_torque: -0.2135
    Episode_Reward/pen_joint_accel: -0.1060
    Episode_Reward/pen_action_rate: -0.1002
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0485
   Episode_Reward/pen_joint_powers: -0.0759
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2204
Episode_Reward/pen_flat_orientation: -0.1451
  Episode_Reward/pen_feet_distance: -0.0084
Episode_Reward/pen_feet_regulation: -0.3217
   Episode_Reward/foot_landing_vel: -0.1440
   Episode_Reward/test_gait_reward: -0.8964
Metrics/base_velocity/error_vel_xy: 1.9273
Metrics/base_velocity/error_vel_yaw: 1.1684
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 1.09s
                        Total time: 931.91s
                               ETA: 2335.2s

################################################################################
                     [1m Learning iteration 856/3000 [0m                      

                       Computation: 89883 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 1.0515
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8621
                     Learning rate: 0.0006
                       Mean reward: 95.58
               Mean episode length: 935.88
       Episode_Reward/keep_balance: 0.9176
     Episode_Reward/rew_lin_vel_xy: 3.9735
      Episode_Reward/rew_ang_vel_z: 2.3576
    Episode_Reward/pen_base_height: -0.3179
      Episode_Reward/pen_lin_vel_z: -0.0504
     Episode_Reward/pen_ang_vel_xy: -0.1701
   Episode_Reward/pen_joint_torque: -0.1939
    Episode_Reward/pen_joint_accel: -0.1019
    Episode_Reward/pen_action_rate: -0.0958
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0462
   Episode_Reward/pen_joint_powers: -0.0712
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2125
Episode_Reward/pen_flat_orientation: -0.1367
  Episode_Reward/pen_feet_distance: -0.0039
Episode_Reward/pen_feet_regulation: -0.2920
   Episode_Reward/foot_landing_vel: -0.1360
   Episode_Reward/test_gait_reward: -0.8489
Metrics/base_velocity/error_vel_xy: 1.8049
Metrics/base_velocity/error_vel_yaw: 1.1584
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 1.09s
                        Total time: 933.00s
                               ETA: 2334.1s

################################################################################
                     [1m Learning iteration 857/3000 [0m                      

                       Computation: 90788 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.9209
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8624
                     Learning rate: 0.0009
                       Mean reward: 97.66
               Mean episode length: 973.63
       Episode_Reward/keep_balance: 0.9729
     Episode_Reward/rew_lin_vel_xy: 4.2717
      Episode_Reward/rew_ang_vel_z: 2.5326
    Episode_Reward/pen_base_height: -0.3314
      Episode_Reward/pen_lin_vel_z: -0.0556
     Episode_Reward/pen_ang_vel_xy: -0.1691
   Episode_Reward/pen_joint_torque: -0.2138
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.1014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0479
   Episode_Reward/pen_joint_powers: -0.0754
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2221
Episode_Reward/pen_flat_orientation: -0.1408
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3179
   Episode_Reward/foot_landing_vel: -0.1401
   Episode_Reward/test_gait_reward: -0.8937
Metrics/base_velocity/error_vel_xy: 1.9338
Metrics/base_velocity/error_vel_yaw: 1.2007
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 1.08s
                        Total time: 934.09s
                               ETA: 2333.0s

################################################################################
                     [1m Learning iteration 858/3000 [0m                      

                       Computation: 90402 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 1.0576
                    Surrogate loss: -0.0008
             Mean action noise std: 0.8627
                     Learning rate: 0.0003
                       Mean reward: 95.92
               Mean episode length: 984.02
       Episode_Reward/keep_balance: 0.9772
     Episode_Reward/rew_lin_vel_xy: 4.0744
      Episode_Reward/rew_ang_vel_z: 2.5774
    Episode_Reward/pen_base_height: -0.3409
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1674
   Episode_Reward/pen_joint_torque: -0.2216
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1011
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0472
   Episode_Reward/pen_joint_powers: -0.0760
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2224
Episode_Reward/pen_flat_orientation: -0.1413
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.3115
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.9055
Metrics/base_velocity/error_vel_xy: 2.1194
Metrics/base_velocity/error_vel_yaw: 1.1759
      Episode_Termination/time_out: 5.0833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 1.09s
                        Total time: 935.17s
                               ETA: 2331.9s

################################################################################
                     [1m Learning iteration 859/3000 [0m                      

                       Computation: 90538 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 1.0746
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8621
                     Learning rate: 0.0006
                       Mean reward: 96.65
               Mean episode length: 949.93
       Episode_Reward/keep_balance: 0.9145
     Episode_Reward/rew_lin_vel_xy: 3.9622
      Episode_Reward/rew_ang_vel_z: 2.4170
    Episode_Reward/pen_base_height: -0.3063
      Episode_Reward/pen_lin_vel_z: -0.0523
     Episode_Reward/pen_ang_vel_xy: -0.1610
   Episode_Reward/pen_joint_torque: -0.2028
    Episode_Reward/pen_joint_accel: -0.1049
    Episode_Reward/pen_action_rate: -0.0942
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0456
   Episode_Reward/pen_joint_powers: -0.0720
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2083
Episode_Reward/pen_flat_orientation: -0.1372
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.2934
   Episode_Reward/foot_landing_vel: -0.1407
   Episode_Reward/test_gait_reward: -0.8403
Metrics/base_velocity/error_vel_xy: 1.9018
Metrics/base_velocity/error_vel_yaw: 1.0973
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 1.09s
                        Total time: 936.26s
                               ETA: 2330.8s

################################################################################
                     [1m Learning iteration 860/3000 [0m                      

                       Computation: 90191 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 1.0699
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8619
                     Learning rate: 0.0006
                       Mean reward: 90.83
               Mean episode length: 946.86
       Episode_Reward/keep_balance: 0.9525
     Episode_Reward/rew_lin_vel_xy: 3.9197
      Episode_Reward/rew_ang_vel_z: 2.5076
    Episode_Reward/pen_base_height: -0.3181
      Episode_Reward/pen_lin_vel_z: -0.0534
     Episode_Reward/pen_ang_vel_xy: -0.1661
   Episode_Reward/pen_joint_torque: -0.2043
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.0990
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0464
   Episode_Reward/pen_joint_powers: -0.0729
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2192
Episode_Reward/pen_flat_orientation: -0.1368
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.2975
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.8721
Metrics/base_velocity/error_vel_xy: 2.0895
Metrics/base_velocity/error_vel_yaw: 1.1565
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 1.09s
                        Total time: 937.35s
                               ETA: 2329.8s

################################################################################
                     [1m Learning iteration 861/3000 [0m                      

                       Computation: 90093 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 1.0926
                    Surrogate loss: 0.0007
             Mean action noise std: 0.8628
                     Learning rate: 0.0002
                       Mean reward: 93.68
               Mean episode length: 920.52
       Episode_Reward/keep_balance: 0.9380
     Episode_Reward/rew_lin_vel_xy: 4.1926
      Episode_Reward/rew_ang_vel_z: 2.4497
    Episode_Reward/pen_base_height: -0.3272
      Episode_Reward/pen_lin_vel_z: -0.0534
     Episode_Reward/pen_ang_vel_xy: -0.1654
   Episode_Reward/pen_joint_torque: -0.2034
    Episode_Reward/pen_joint_accel: -0.0933
    Episode_Reward/pen_action_rate: -0.0976
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0459
   Episode_Reward/pen_joint_powers: -0.0725
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2142
Episode_Reward/pen_flat_orientation: -0.1380
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.2982
   Episode_Reward/foot_landing_vel: -0.1345
   Episode_Reward/test_gait_reward: -0.8716
Metrics/base_velocity/error_vel_xy: 1.7913
Metrics/base_velocity/error_vel_yaw: 1.1590
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 1.09s
                        Total time: 938.44s
                               ETA: 2328.7s

################################################################################
                     [1m Learning iteration 862/3000 [0m                      

                       Computation: 91052 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 1.0546
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8625
                     Learning rate: 0.0004
                       Mean reward: 95.85
               Mean episode length: 962.85
       Episode_Reward/keep_balance: 0.9690
     Episode_Reward/rew_lin_vel_xy: 4.0050
      Episode_Reward/rew_ang_vel_z: 2.5964
    Episode_Reward/pen_base_height: -0.3247
      Episode_Reward/pen_lin_vel_z: -0.0553
     Episode_Reward/pen_ang_vel_xy: -0.1655
   Episode_Reward/pen_joint_torque: -0.2209
    Episode_Reward/pen_joint_accel: -0.1048
    Episode_Reward/pen_action_rate: -0.0982
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0746
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2164
Episode_Reward/pen_flat_orientation: -0.1317
  Episode_Reward/pen_feet_distance: -0.0079
Episode_Reward/pen_feet_regulation: -0.2949
   Episode_Reward/foot_landing_vel: -0.1377
   Episode_Reward/test_gait_reward: -0.8882
Metrics/base_velocity/error_vel_xy: 2.1003
Metrics/base_velocity/error_vel_yaw: 1.1254
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 1.08s
                        Total time: 939.52s
                               ETA: 2327.6s

################################################################################
                     [1m Learning iteration 863/3000 [0m                      

                       Computation: 92790 steps/s (collection: 0.937s, learning 0.122s)
               Value function loss: 1.0615
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8633
                     Learning rate: 0.0009
                       Mean reward: 94.13
               Mean episode length: 942.75
       Episode_Reward/keep_balance: 0.9511
     Episode_Reward/rew_lin_vel_xy: 3.9643
      Episode_Reward/rew_ang_vel_z: 2.5477
    Episode_Reward/pen_base_height: -0.3316
      Episode_Reward/pen_lin_vel_z: -0.0583
     Episode_Reward/pen_ang_vel_xy: -0.1687
   Episode_Reward/pen_joint_torque: -0.2173
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.0983
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0475
   Episode_Reward/pen_joint_powers: -0.0759
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2164
Episode_Reward/pen_flat_orientation: -0.1485
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3078
   Episode_Reward/foot_landing_vel: -0.1455
   Episode_Reward/test_gait_reward: -0.8735
Metrics/base_velocity/error_vel_xy: 2.0385
Metrics/base_velocity/error_vel_yaw: 1.1162
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 1.06s
                        Total time: 940.58s
                               ETA: 2326.4s

################################################################################
                     [1m Learning iteration 864/3000 [0m                      

                       Computation: 91663 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 1.0152
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8647
                     Learning rate: 0.0013
                       Mean reward: 92.67
               Mean episode length: 943.66
       Episode_Reward/keep_balance: 0.9183
     Episode_Reward/rew_lin_vel_xy: 3.8275
      Episode_Reward/rew_ang_vel_z: 2.3766
    Episode_Reward/pen_base_height: -0.3234
      Episode_Reward/pen_lin_vel_z: -0.0543
     Episode_Reward/pen_ang_vel_xy: -0.1590
   Episode_Reward/pen_joint_torque: -0.2048
    Episode_Reward/pen_joint_accel: -0.1013
    Episode_Reward/pen_action_rate: -0.0957
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0460
   Episode_Reward/pen_joint_powers: -0.0728
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2117
Episode_Reward/pen_flat_orientation: -0.1404
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3037
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.8459
Metrics/base_velocity/error_vel_xy: 2.0172
Metrics/base_velocity/error_vel_yaw: 1.1556
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 1.07s
                        Total time: 941.65s
                               ETA: 2325.3s

################################################################################
                     [1m Learning iteration 865/3000 [0m                      

                       Computation: 91963 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 1.0881
                    Surrogate loss: 0.0002
             Mean action noise std: 0.8639
                     Learning rate: 0.0002
                       Mean reward: 99.45
               Mean episode length: 990.86
       Episode_Reward/keep_balance: 0.9773
     Episode_Reward/rew_lin_vel_xy: 4.1148
      Episode_Reward/rew_ang_vel_z: 2.5880
    Episode_Reward/pen_base_height: -0.3352
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1687
   Episode_Reward/pen_joint_torque: -0.2221
    Episode_Reward/pen_joint_accel: -0.1074
    Episode_Reward/pen_action_rate: -0.1012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0488
   Episode_Reward/pen_joint_powers: -0.0774
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2218
Episode_Reward/pen_flat_orientation: -0.1455
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.3280
   Episode_Reward/foot_landing_vel: -0.1498
   Episode_Reward/test_gait_reward: -0.9026
Metrics/base_velocity/error_vel_xy: 2.0853
Metrics/base_velocity/error_vel_yaw: 1.1702
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 1.07s
                        Total time: 942.72s
                               ETA: 2324.1s

################################################################################
                     [1m Learning iteration 866/3000 [0m                      

                       Computation: 92070 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 1.0580
                    Surrogate loss: 0.0030
             Mean action noise std: 0.8636
                     Learning rate: 0.0000
                       Mean reward: 95.57
               Mean episode length: 969.25
       Episode_Reward/keep_balance: 0.9655
     Episode_Reward/rew_lin_vel_xy: 4.0096
      Episode_Reward/rew_ang_vel_z: 2.5123
    Episode_Reward/pen_base_height: -0.3235
      Episode_Reward/pen_lin_vel_z: -0.0565
     Episode_Reward/pen_ang_vel_xy: -0.1639
   Episode_Reward/pen_joint_torque: -0.2208
    Episode_Reward/pen_joint_accel: -0.1082
    Episode_Reward/pen_action_rate: -0.0998
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0485
   Episode_Reward/pen_joint_powers: -0.0774
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2185
Episode_Reward/pen_flat_orientation: -0.1361
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.3187
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.8896
Metrics/base_velocity/error_vel_xy: 2.1022
Metrics/base_velocity/error_vel_yaw: 1.1894
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 1.07s
                        Total time: 943.79s
                               ETA: 2323.0s

################################################################################
                     [1m Learning iteration 867/3000 [0m                      

                       Computation: 91720 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 1.0297
                    Surrogate loss: 0.0053
             Mean action noise std: 0.8634
                     Learning rate: 0.0000
                       Mean reward: 90.27
               Mean episode length: 933.04
       Episode_Reward/keep_balance: 0.9209
     Episode_Reward/rew_lin_vel_xy: 3.8891
      Episode_Reward/rew_ang_vel_z: 2.4303
    Episode_Reward/pen_base_height: -0.3196
      Episode_Reward/pen_lin_vel_z: -0.0556
     Episode_Reward/pen_ang_vel_xy: -0.1591
   Episode_Reward/pen_joint_torque: -0.2153
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.0954
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0456
   Episode_Reward/pen_joint_powers: -0.0740
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2099
Episode_Reward/pen_flat_orientation: -0.1431
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.2934
   Episode_Reward/foot_landing_vel: -0.1358
   Episode_Reward/test_gait_reward: -0.8460
Metrics/base_velocity/error_vel_xy: 1.9535
Metrics/base_velocity/error_vel_yaw: 1.1041
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 1.07s
                        Total time: 944.86s
                               ETA: 2321.9s

################################################################################
                     [1m Learning iteration 868/3000 [0m                      

                       Computation: 91227 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.0555
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8631
                     Learning rate: 0.0002
                       Mean reward: 89.33
               Mean episode length: 939.84
       Episode_Reward/keep_balance: 0.9289
     Episode_Reward/rew_lin_vel_xy: 3.9540
      Episode_Reward/rew_ang_vel_z: 2.4029
    Episode_Reward/pen_base_height: -0.3335
      Episode_Reward/pen_lin_vel_z: -0.0522
     Episode_Reward/pen_ang_vel_xy: -0.1644
   Episode_Reward/pen_joint_torque: -0.2004
    Episode_Reward/pen_joint_accel: -0.1117
    Episode_Reward/pen_action_rate: -0.0970
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0475
   Episode_Reward/pen_joint_powers: -0.0726
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2149
Episode_Reward/pen_flat_orientation: -0.1436
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.3035
   Episode_Reward/foot_landing_vel: -0.1454
   Episode_Reward/test_gait_reward: -0.8634
Metrics/base_velocity/error_vel_xy: 1.9356
Metrics/base_velocity/error_vel_yaw: 1.1634
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 1.08s
                        Total time: 945.94s
                               ETA: 2320.8s

################################################################################
                     [1m Learning iteration 869/3000 [0m                      

                       Computation: 91776 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 0.9959
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8636
                     Learning rate: 0.0006
                       Mean reward: 95.26
               Mean episode length: 937.44
       Episode_Reward/keep_balance: 0.9288
     Episode_Reward/rew_lin_vel_xy: 4.0325
      Episode_Reward/rew_ang_vel_z: 2.4391
    Episode_Reward/pen_base_height: -0.3188
      Episode_Reward/pen_lin_vel_z: -0.0504
     Episode_Reward/pen_ang_vel_xy: -0.1642
   Episode_Reward/pen_joint_torque: -0.1994
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.0966
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0445
   Episode_Reward/pen_joint_powers: -0.0704
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2140
Episode_Reward/pen_flat_orientation: -0.1345
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2818
   Episode_Reward/foot_landing_vel: -0.1263
   Episode_Reward/test_gait_reward: -0.8575
Metrics/base_velocity/error_vel_xy: 1.8953
Metrics/base_velocity/error_vel_yaw: 1.1266
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 1.07s
                        Total time: 947.01s
                               ETA: 2319.6s

################################################################################
                     [1m Learning iteration 870/3000 [0m                      

                       Computation: 91118 steps/s (collection: 0.953s, learning 0.126s)
               Value function loss: 1.0885
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8653
                     Learning rate: 0.0006
                       Mean reward: 95.13
               Mean episode length: 962.97
       Episode_Reward/keep_balance: 0.9710
     Episode_Reward/rew_lin_vel_xy: 4.0722
      Episode_Reward/rew_ang_vel_z: 2.5538
    Episode_Reward/pen_base_height: -0.3315
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1650
   Episode_Reward/pen_joint_torque: -0.2170
    Episode_Reward/pen_joint_accel: -0.1104
    Episode_Reward/pen_action_rate: -0.1008
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0479
   Episode_Reward/pen_joint_powers: -0.0757
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2227
Episode_Reward/pen_flat_orientation: -0.1416
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.3138
   Episode_Reward/foot_landing_vel: -0.1451
   Episode_Reward/test_gait_reward: -0.8911
Metrics/base_velocity/error_vel_xy: 2.1305
Metrics/base_velocity/error_vel_yaw: 1.1718
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 1.08s
                        Total time: 948.09s
                               ETA: 2318.5s

################################################################################
                     [1m Learning iteration 871/3000 [0m                      

                       Computation: 90006 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 1.1266
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8672
                     Learning rate: 0.0013
                       Mean reward: 88.48
               Mean episode length: 933.64
       Episode_Reward/keep_balance: 0.9418
     Episode_Reward/rew_lin_vel_xy: 3.8462
      Episode_Reward/rew_ang_vel_z: 2.4748
    Episode_Reward/pen_base_height: -0.3321
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.1663
   Episode_Reward/pen_joint_torque: -0.2072
    Episode_Reward/pen_joint_accel: -0.1050
    Episode_Reward/pen_action_rate: -0.0986
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0470
   Episode_Reward/pen_joint_powers: -0.0742
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2188
Episode_Reward/pen_flat_orientation: -0.1453
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.3031
   Episode_Reward/foot_landing_vel: -0.1425
   Episode_Reward/test_gait_reward: -0.8652
Metrics/base_velocity/error_vel_xy: 2.0954
Metrics/base_velocity/error_vel_yaw: 1.1423
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 1.09s
                        Total time: 949.18s
                               ETA: 2317.4s

################################################################################
                     [1m Learning iteration 872/3000 [0m                      

                       Computation: 93711 steps/s (collection: 0.926s, learning 0.123s)
               Value function loss: 1.0767
                    Surrogate loss: -0.0001
             Mean action noise std: 0.8673
                     Learning rate: 0.0006
                       Mean reward: 94.34
               Mean episode length: 954.23
       Episode_Reward/keep_balance: 0.9610
     Episode_Reward/rew_lin_vel_xy: 4.1316
      Episode_Reward/rew_ang_vel_z: 2.5077
    Episode_Reward/pen_base_height: -0.3442
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1767
   Episode_Reward/pen_joint_torque: -0.2141
    Episode_Reward/pen_joint_accel: -0.1197
    Episode_Reward/pen_action_rate: -0.1009
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0489
   Episode_Reward/pen_joint_powers: -0.0761
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2235
Episode_Reward/pen_flat_orientation: -0.1472
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3060
   Episode_Reward/foot_landing_vel: -0.1475
   Episode_Reward/test_gait_reward: -0.8901
Metrics/base_velocity/error_vel_xy: 2.0670
Metrics/base_velocity/error_vel_yaw: 1.1804
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 1.05s
                        Total time: 950.23s
                               ETA: 2316.2s

################################################################################
                     [1m Learning iteration 873/3000 [0m                      

                       Computation: 92483 steps/s (collection: 0.939s, learning 0.124s)
               Value function loss: 1.1400
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8677
                     Learning rate: 0.0009
                       Mean reward: 94.31
               Mean episode length: 973.39
       Episode_Reward/keep_balance: 0.9627
     Episode_Reward/rew_lin_vel_xy: 3.9872
      Episode_Reward/rew_ang_vel_z: 2.5276
    Episode_Reward/pen_base_height: -0.3462
      Episode_Reward/pen_lin_vel_z: -0.0589
     Episode_Reward/pen_ang_vel_xy: -0.1634
   Episode_Reward/pen_joint_torque: -0.2348
    Episode_Reward/pen_joint_accel: -0.1078
    Episode_Reward/pen_action_rate: -0.1004
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0495
   Episode_Reward/pen_joint_powers: -0.0800
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2198
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3320
   Episode_Reward/foot_landing_vel: -0.1508
   Episode_Reward/test_gait_reward: -0.8856
Metrics/base_velocity/error_vel_xy: 2.0623
Metrics/base_velocity/error_vel_yaw: 1.1674
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 1.06s
                        Total time: 951.29s
                               ETA: 2315.1s

################################################################################
                     [1m Learning iteration 874/3000 [0m                      

                       Computation: 91914 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 1.1377
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8675
                     Learning rate: 0.0009
                       Mean reward: 89.64
               Mean episode length: 941.08
       Episode_Reward/keep_balance: 0.9225
     Episode_Reward/rew_lin_vel_xy: 3.8114
      Episode_Reward/rew_ang_vel_z: 2.4082
    Episode_Reward/pen_base_height: -0.3277
      Episode_Reward/pen_lin_vel_z: -0.0538
     Episode_Reward/pen_ang_vel_xy: -0.1657
   Episode_Reward/pen_joint_torque: -0.2057
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.0969
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0725
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2149
Episode_Reward/pen_flat_orientation: -0.1377
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.2938
   Episode_Reward/foot_landing_vel: -0.1412
   Episode_Reward/test_gait_reward: -0.8488
Metrics/base_velocity/error_vel_xy: 2.0438
Metrics/base_velocity/error_vel_yaw: 1.1344
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 1.07s
                        Total time: 952.36s
                               ETA: 2314.0s

################################################################################
                     [1m Learning iteration 875/3000 [0m                      

                       Computation: 90993 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 1.1794
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8674
                     Learning rate: 0.0013
                       Mean reward: 102.53
               Mean episode length: 982.03
       Episode_Reward/keep_balance: 0.9873
     Episode_Reward/rew_lin_vel_xy: 4.4449
      Episode_Reward/rew_ang_vel_z: 2.6346
    Episode_Reward/pen_base_height: -0.3299
      Episode_Reward/pen_lin_vel_z: -0.0540
     Episode_Reward/pen_ang_vel_xy: -0.1655
   Episode_Reward/pen_joint_torque: -0.2172
    Episode_Reward/pen_joint_accel: -0.1086
    Episode_Reward/pen_action_rate: -0.1005
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0467
   Episode_Reward/pen_joint_powers: -0.0756
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2250
Episode_Reward/pen_flat_orientation: -0.1355
  Episode_Reward/pen_feet_distance: -0.0043
Episode_Reward/pen_feet_regulation: -0.2971
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.9034
Metrics/base_velocity/error_vel_xy: 1.9232
Metrics/base_velocity/error_vel_yaw: 1.1589
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 1.08s
                        Total time: 953.44s
                               ETA: 2312.9s

################################################################################
                     [1m Learning iteration 876/3000 [0m                      

                       Computation: 91115 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 1.0322
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8689
                     Learning rate: 0.0006
                       Mean reward: 87.50
               Mean episode length: 900.02
       Episode_Reward/keep_balance: 0.9057
     Episode_Reward/rew_lin_vel_xy: 3.9826
      Episode_Reward/rew_ang_vel_z: 2.3567
    Episode_Reward/pen_base_height: -0.3374
      Episode_Reward/pen_lin_vel_z: -0.0594
     Episode_Reward/pen_ang_vel_xy: -0.1666
   Episode_Reward/pen_joint_torque: -0.2111
    Episode_Reward/pen_joint_accel: -0.1054
    Episode_Reward/pen_action_rate: -0.0963
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0487
   Episode_Reward/pen_joint_powers: -0.0757
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2119
Episode_Reward/pen_flat_orientation: -0.1489
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3238
   Episode_Reward/foot_landing_vel: -0.1451
   Episode_Reward/test_gait_reward: -0.8469
Metrics/base_velocity/error_vel_xy: 1.9173
Metrics/base_velocity/error_vel_yaw: 1.1209
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 1.08s
                        Total time: 954.52s
                               ETA: 2311.7s

################################################################################
                     [1m Learning iteration 877/3000 [0m                      

                       Computation: 92588 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 1.0287
                    Surrogate loss: -0.0011
             Mean action noise std: 0.8698
                     Learning rate: 0.0002
                       Mean reward: 89.24
               Mean episode length: 921.10
       Episode_Reward/keep_balance: 0.8986
     Episode_Reward/rew_lin_vel_xy: 3.8389
      Episode_Reward/rew_ang_vel_z: 2.3267
    Episode_Reward/pen_base_height: -0.3347
      Episode_Reward/pen_lin_vel_z: -0.0528
     Episode_Reward/pen_ang_vel_xy: -0.1626
   Episode_Reward/pen_joint_torque: -0.2046
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.0949
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0466
   Episode_Reward/pen_joint_powers: -0.0731
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2100
Episode_Reward/pen_flat_orientation: -0.1503
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.2903
   Episode_Reward/foot_landing_vel: -0.1338
   Episode_Reward/test_gait_reward: -0.8334
Metrics/base_velocity/error_vel_xy: 1.8241
Metrics/base_velocity/error_vel_yaw: 1.1332
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 1.06s
                        Total time: 955.58s
                               ETA: 2310.6s

################################################################################
                     [1m Learning iteration 878/3000 [0m                      

                       Computation: 90225 steps/s (collection: 0.964s, learning 0.126s)
               Value function loss: 1.1000
                    Surrogate loss: 0.0005
             Mean action noise std: 0.8702
                     Learning rate: 0.0001
                       Mean reward: 86.18
               Mean episode length: 943.93
       Episode_Reward/keep_balance: 0.9474
     Episode_Reward/rew_lin_vel_xy: 3.7137
      Episode_Reward/rew_ang_vel_z: 2.4089
    Episode_Reward/pen_base_height: -0.3499
      Episode_Reward/pen_lin_vel_z: -0.0571
     Episode_Reward/pen_ang_vel_xy: -0.1741
   Episode_Reward/pen_joint_torque: -0.2173
    Episode_Reward/pen_joint_accel: -0.1028
    Episode_Reward/pen_action_rate: -0.1010
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0489
   Episode_Reward/pen_joint_powers: -0.0776
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2224
Episode_Reward/pen_flat_orientation: -0.1450
  Episode_Reward/pen_feet_distance: -0.0066
Episode_Reward/pen_feet_regulation: -0.3267
   Episode_Reward/foot_landing_vel: -0.1367
   Episode_Reward/test_gait_reward: -0.8851
Metrics/base_velocity/error_vel_xy: 2.1532
Metrics/base_velocity/error_vel_yaw: 1.2181
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 1.09s
                        Total time: 956.67s
                               ETA: 2309.5s

################################################################################
                     [1m Learning iteration 879/3000 [0m                      

                       Computation: 91222 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.9895
                    Surrogate loss: 0.0058
             Mean action noise std: 0.8705
                     Learning rate: 0.0000
                       Mean reward: 89.40
               Mean episode length: 934.17
       Episode_Reward/keep_balance: 0.9381
     Episode_Reward/rew_lin_vel_xy: 3.9576
      Episode_Reward/rew_ang_vel_z: 2.4317
    Episode_Reward/pen_base_height: -0.3403
      Episode_Reward/pen_lin_vel_z: -0.0591
     Episode_Reward/pen_ang_vel_xy: -0.1711
   Episode_Reward/pen_joint_torque: -0.2143
    Episode_Reward/pen_joint_accel: -0.1058
    Episode_Reward/pen_action_rate: -0.0996
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0489
   Episode_Reward/pen_joint_powers: -0.0765
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2201
Episode_Reward/pen_flat_orientation: -0.1449
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3233
   Episode_Reward/foot_landing_vel: -0.1495
   Episode_Reward/test_gait_reward: -0.8684
Metrics/base_velocity/error_vel_xy: 2.0386
Metrics/base_velocity/error_vel_yaw: 1.1692
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 1.08s
                        Total time: 957.75s
                               ETA: 2308.4s

################################################################################
                     [1m Learning iteration 880/3000 [0m                      

                       Computation: 90831 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.9536
                    Surrogate loss: 0.0026
             Mean action noise std: 0.8705
                     Learning rate: 0.0000
                       Mean reward: 95.21
               Mean episode length: 959.95
       Episode_Reward/keep_balance: 0.9378
     Episode_Reward/rew_lin_vel_xy: 3.9912
      Episode_Reward/rew_ang_vel_z: 2.4522
    Episode_Reward/pen_base_height: -0.3449
      Episode_Reward/pen_lin_vel_z: -0.0550
     Episode_Reward/pen_ang_vel_xy: -0.1656
   Episode_Reward/pen_joint_torque: -0.2102
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.0988
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0477
   Episode_Reward/pen_joint_powers: -0.0750
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2188
Episode_Reward/pen_flat_orientation: -0.1459
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.3169
   Episode_Reward/foot_landing_vel: -0.1428
   Episode_Reward/test_gait_reward: -0.8693
Metrics/base_velocity/error_vel_xy: 2.0389
Metrics/base_velocity/error_vel_yaw: 1.1522
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 1.08s
                        Total time: 958.83s
                               ETA: 2307.3s

################################################################################
                     [1m Learning iteration 881/3000 [0m                      

                       Computation: 90658 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 1.0055
                    Surrogate loss: 0.0033
             Mean action noise std: 0.8708
                     Learning rate: 0.0000
                       Mean reward: 103.24
               Mean episode length: 991.94
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 4.4341
      Episode_Reward/rew_ang_vel_z: 2.6439
    Episode_Reward/pen_base_height: -0.3339
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1675
   Episode_Reward/pen_joint_torque: -0.2234
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0487
   Episode_Reward/pen_joint_powers: -0.0775
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2324
Episode_Reward/pen_flat_orientation: -0.1341
  Episode_Reward/pen_feet_distance: -0.0051
Episode_Reward/pen_feet_regulation: -0.3221
   Episode_Reward/foot_landing_vel: -0.1524
   Episode_Reward/test_gait_reward: -0.9262
Metrics/base_velocity/error_vel_xy: 1.9992
Metrics/base_velocity/error_vel_yaw: 1.1860
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 1.08s
                        Total time: 959.92s
                               ETA: 2306.2s

################################################################################
                     [1m Learning iteration 882/3000 [0m                      

                       Computation: 90316 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 1.0526
                    Surrogate loss: 0.0026
             Mean action noise std: 0.8707
                     Learning rate: 0.0000
                       Mean reward: 90.56
               Mean episode length: 928.93
       Episode_Reward/keep_balance: 0.9467
     Episode_Reward/rew_lin_vel_xy: 4.0035
      Episode_Reward/rew_ang_vel_z: 2.4864
    Episode_Reward/pen_base_height: -0.3261
      Episode_Reward/pen_lin_vel_z: -0.0538
     Episode_Reward/pen_ang_vel_xy: -0.1620
   Episode_Reward/pen_joint_torque: -0.2146
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.0980
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0470
   Episode_Reward/pen_joint_powers: -0.0748
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2182
Episode_Reward/pen_flat_orientation: -0.1331
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.2939
   Episode_Reward/foot_landing_vel: -0.1460
   Episode_Reward/test_gait_reward: -0.8677
Metrics/base_velocity/error_vel_xy: 2.0671
Metrics/base_velocity/error_vel_yaw: 1.1392
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 1.09s
                        Total time: 961.00s
                               ETA: 2305.1s

################################################################################
                     [1m Learning iteration 883/3000 [0m                      

                       Computation: 91452 steps/s (collection: 0.954s, learning 0.121s)
               Value function loss: 1.0264
                    Surrogate loss: 0.0011
             Mean action noise std: 0.8702
                     Learning rate: 0.0000
                       Mean reward: 91.11
               Mean episode length: 952.32
       Episode_Reward/keep_balance: 0.9600
     Episode_Reward/rew_lin_vel_xy: 3.9924
      Episode_Reward/rew_ang_vel_z: 2.5022
    Episode_Reward/pen_base_height: -0.3239
      Episode_Reward/pen_lin_vel_z: -0.0567
     Episode_Reward/pen_ang_vel_xy: -0.1697
   Episode_Reward/pen_joint_torque: -0.2208
    Episode_Reward/pen_joint_accel: -0.1142
    Episode_Reward/pen_action_rate: -0.1007
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0488
   Episode_Reward/pen_joint_powers: -0.0780
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2248
Episode_Reward/pen_flat_orientation: -0.1358
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.3182
   Episode_Reward/foot_landing_vel: -0.1462
   Episode_Reward/test_gait_reward: -0.8827
Metrics/base_velocity/error_vel_xy: 2.1106
Metrics/base_velocity/error_vel_yaw: 1.1740
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 1.07s
                        Total time: 962.08s
                               ETA: 2304.0s

################################################################################
                     [1m Learning iteration 884/3000 [0m                      

                       Computation: 90914 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 1.1742
                    Surrogate loss: 0.0004
             Mean action noise std: 0.8704
                     Learning rate: 0.0001
                       Mean reward: 97.31
               Mean episode length: 977.03
       Episode_Reward/keep_balance: 0.9755
     Episode_Reward/rew_lin_vel_xy: 4.2663
      Episode_Reward/rew_ang_vel_z: 2.5499
    Episode_Reward/pen_base_height: -0.3496
      Episode_Reward/pen_lin_vel_z: -0.0586
     Episode_Reward/pen_ang_vel_xy: -0.1741
   Episode_Reward/pen_joint_torque: -0.2205
    Episode_Reward/pen_joint_accel: -0.1096
    Episode_Reward/pen_action_rate: -0.1028
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0495
   Episode_Reward/pen_joint_powers: -0.0782
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2297
Episode_Reward/pen_flat_orientation: -0.1362
  Episode_Reward/pen_feet_distance: -0.0061
Episode_Reward/pen_feet_regulation: -0.3290
   Episode_Reward/foot_landing_vel: -0.1473
   Episode_Reward/test_gait_reward: -0.9107
Metrics/base_velocity/error_vel_xy: 2.0587
Metrics/base_velocity/error_vel_yaw: 1.1838
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 1.08s
                        Total time: 963.16s
                               ETA: 2302.9s

################################################################################
                     [1m Learning iteration 885/3000 [0m                      

                       Computation: 91054 steps/s (collection: 0.958s, learning 0.121s)
               Value function loss: 1.0938
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8706
                     Learning rate: 0.0002
                       Mean reward: 95.39
               Mean episode length: 956.09
       Episode_Reward/keep_balance: 0.9513
     Episode_Reward/rew_lin_vel_xy: 4.1797
      Episode_Reward/rew_ang_vel_z: 2.5003
    Episode_Reward/pen_base_height: -0.3371
      Episode_Reward/pen_lin_vel_z: -0.0569
     Episode_Reward/pen_ang_vel_xy: -0.1629
   Episode_Reward/pen_joint_torque: -0.2230
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.0990
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0485
   Episode_Reward/pen_joint_powers: -0.0777
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2194
Episode_Reward/pen_flat_orientation: -0.1406
  Episode_Reward/pen_feet_distance: -0.0069
Episode_Reward/pen_feet_regulation: -0.3124
   Episode_Reward/foot_landing_vel: -0.1495
   Episode_Reward/test_gait_reward: -0.8737
Metrics/base_velocity/error_vel_xy: 1.9690
Metrics/base_velocity/error_vel_yaw: 1.1458
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 1.08s
                        Total time: 964.24s
                               ETA: 2301.8s

################################################################################
                     [1m Learning iteration 886/3000 [0m                      

                       Computation: 91323 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.9168
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8692
                     Learning rate: 0.0004
                       Mean reward: 91.27
               Mean episode length: 926.83
       Episode_Reward/keep_balance: 0.9296
     Episode_Reward/rew_lin_vel_xy: 4.0083
      Episode_Reward/rew_ang_vel_z: 2.4475
    Episode_Reward/pen_base_height: -0.3373
      Episode_Reward/pen_lin_vel_z: -0.0556
     Episode_Reward/pen_ang_vel_xy: -0.1660
   Episode_Reward/pen_joint_torque: -0.2126
    Episode_Reward/pen_joint_accel: -0.0950
    Episode_Reward/pen_action_rate: -0.0982
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0473
   Episode_Reward/pen_joint_powers: -0.0758
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2177
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0072
Episode_Reward/pen_feet_regulation: -0.3162
   Episode_Reward/foot_landing_vel: -0.1467
   Episode_Reward/test_gait_reward: -0.8674
Metrics/base_velocity/error_vel_xy: 1.9747
Metrics/base_velocity/error_vel_yaw: 1.1263
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 1.08s
                        Total time: 965.32s
                               ETA: 2300.7s

################################################################################
                     [1m Learning iteration 887/3000 [0m                      

                       Computation: 91402 steps/s (collection: 0.951s, learning 0.124s)
               Value function loss: 1.0121
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8694
                     Learning rate: 0.0009
                       Mean reward: 95.54
               Mean episode length: 993.15
       Episode_Reward/keep_balance: 0.9890
     Episode_Reward/rew_lin_vel_xy: 4.1189
      Episode_Reward/rew_ang_vel_z: 2.5624
    Episode_Reward/pen_base_height: -0.3439
      Episode_Reward/pen_lin_vel_z: -0.0586
     Episode_Reward/pen_ang_vel_xy: -0.1760
   Episode_Reward/pen_joint_torque: -0.2212
    Episode_Reward/pen_joint_accel: -0.1159
    Episode_Reward/pen_action_rate: -0.1044
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0507
   Episode_Reward/pen_joint_powers: -0.0795
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2326
Episode_Reward/pen_flat_orientation: -0.1405
  Episode_Reward/pen_feet_distance: -0.0064
Episode_Reward/pen_feet_regulation: -0.3330
   Episode_Reward/foot_landing_vel: -0.1550
   Episode_Reward/test_gait_reward: -0.9165
Metrics/base_velocity/error_vel_xy: 2.1402
Metrics/base_velocity/error_vel_yaw: 1.2266
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 1.08s
                        Total time: 966.39s
                               ETA: 2299.5s

################################################################################
                     [1m Learning iteration 888/3000 [0m                      

                       Computation: 90946 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 0.9887
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8702
                     Learning rate: 0.0006
                       Mean reward: 90.65
               Mean episode length: 929.90
       Episode_Reward/keep_balance: 0.9314
     Episode_Reward/rew_lin_vel_xy: 4.1079
      Episode_Reward/rew_ang_vel_z: 2.3974
    Episode_Reward/pen_base_height: -0.3417
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.1692
   Episode_Reward/pen_joint_torque: -0.2113
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.0997
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0485
   Episode_Reward/pen_joint_powers: -0.0765
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2219
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3185
   Episode_Reward/foot_landing_vel: -0.1365
   Episode_Reward/test_gait_reward: -0.8764
Metrics/base_velocity/error_vel_xy: 1.8676
Metrics/base_velocity/error_vel_yaw: 1.1721
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 1.08s
                        Total time: 967.47s
                               ETA: 2298.4s

################################################################################
                     [1m Learning iteration 889/3000 [0m                      

                       Computation: 91065 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 1.1406
                    Surrogate loss: -0.0016
             Mean action noise std: 0.8700
                     Learning rate: 0.0006
                       Mean reward: 91.24
               Mean episode length: 936.99
       Episode_Reward/keep_balance: 0.9337
     Episode_Reward/rew_lin_vel_xy: 4.0607
      Episode_Reward/rew_ang_vel_z: 2.4011
    Episode_Reward/pen_base_height: -0.3268
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1702
   Episode_Reward/pen_joint_torque: -0.2048
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.0997
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0498
   Episode_Reward/pen_joint_powers: -0.0768
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2217
Episode_Reward/pen_flat_orientation: -0.1424
  Episode_Reward/pen_feet_distance: -0.0069
Episode_Reward/pen_feet_regulation: -0.3265
   Episode_Reward/foot_landing_vel: -0.1569
   Episode_Reward/test_gait_reward: -0.8658
Metrics/base_velocity/error_vel_xy: 1.9301
Metrics/base_velocity/error_vel_yaw: 1.1763
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 1.08s
                        Total time: 968.55s
                               ETA: 2297.3s

################################################################################
                     [1m Learning iteration 890/3000 [0m                      

                       Computation: 91100 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 1.0048
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8705
                     Learning rate: 0.0009
                       Mean reward: 92.82
               Mean episode length: 943.40
       Episode_Reward/keep_balance: 0.9444
     Episode_Reward/rew_lin_vel_xy: 4.0796
      Episode_Reward/rew_ang_vel_z: 2.4476
    Episode_Reward/pen_base_height: -0.3249
      Episode_Reward/pen_lin_vel_z: -0.0527
     Episode_Reward/pen_ang_vel_xy: -0.1655
   Episode_Reward/pen_joint_torque: -0.2130
    Episode_Reward/pen_joint_accel: -0.0984
    Episode_Reward/pen_action_rate: -0.0992
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0470
   Episode_Reward/pen_joint_powers: -0.0753
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2221
Episode_Reward/pen_flat_orientation: -0.1368
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.3002
   Episode_Reward/foot_landing_vel: -0.1401
   Episode_Reward/test_gait_reward: -0.8732
Metrics/base_velocity/error_vel_xy: 1.9597
Metrics/base_velocity/error_vel_yaw: 1.1689
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 1.08s
                        Total time: 969.63s
                               ETA: 2296.2s

################################################################################
                     [1m Learning iteration 891/3000 [0m                      

                       Computation: 90463 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 1.1229
                    Surrogate loss: -0.0014
             Mean action noise std: 0.8712
                     Learning rate: 0.0006
                       Mean reward: 92.85
               Mean episode length: 973.76
       Episode_Reward/keep_balance: 0.9664
     Episode_Reward/rew_lin_vel_xy: 3.9801
      Episode_Reward/rew_ang_vel_z: 2.5041
    Episode_Reward/pen_base_height: -0.3176
      Episode_Reward/pen_lin_vel_z: -0.0537
     Episode_Reward/pen_ang_vel_xy: -0.1676
   Episode_Reward/pen_joint_torque: -0.2189
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.1027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0491
   Episode_Reward/pen_joint_powers: -0.0778
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2289
Episode_Reward/pen_flat_orientation: -0.1355
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.3072
   Episode_Reward/foot_landing_vel: -0.1490
   Episode_Reward/test_gait_reward: -0.8927
Metrics/base_velocity/error_vel_xy: 2.1084
Metrics/base_velocity/error_vel_yaw: 1.2057
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 1.09s
                        Total time: 970.72s
                               ETA: 2295.1s

################################################################################
                     [1m Learning iteration 892/3000 [0m                      

                       Computation: 91917 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.1769
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8712
                     Learning rate: 0.0006
                       Mean reward: 95.25
               Mean episode length: 951.18
       Episode_Reward/keep_balance: 0.9510
     Episode_Reward/rew_lin_vel_xy: 4.1895
      Episode_Reward/rew_ang_vel_z: 2.4902
    Episode_Reward/pen_base_height: -0.3428
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1697
   Episode_Reward/pen_joint_torque: -0.2096
    Episode_Reward/pen_joint_accel: -0.1006
    Episode_Reward/pen_action_rate: -0.1010
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0486
   Episode_Reward/pen_joint_powers: -0.0760
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2254
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.3182
   Episode_Reward/foot_landing_vel: -0.1497
   Episode_Reward/test_gait_reward: -0.8834
Metrics/base_velocity/error_vel_xy: 1.9553
Metrics/base_velocity/error_vel_yaw: 1.1645
      Episode_Termination/time_out: 4.9167
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 1.07s
                        Total time: 971.79s
                               ETA: 2294.0s

################################################################################
                     [1m Learning iteration 893/3000 [0m                      

                       Computation: 92556 steps/s (collection: 0.935s, learning 0.127s)
               Value function loss: 1.1250
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8707
                     Learning rate: 0.0013
                       Mean reward: 91.58
               Mean episode length: 964.61
       Episode_Reward/keep_balance: 0.9707
     Episode_Reward/rew_lin_vel_xy: 3.9606
      Episode_Reward/rew_ang_vel_z: 2.5159
    Episode_Reward/pen_base_height: -0.3423
      Episode_Reward/pen_lin_vel_z: -0.0589
     Episode_Reward/pen_ang_vel_xy: -0.1797
   Episode_Reward/pen_joint_torque: -0.2240
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1049
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0518
   Episode_Reward/pen_joint_powers: -0.0815
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2325
Episode_Reward/pen_flat_orientation: -0.1449
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.3374
   Episode_Reward/foot_landing_vel: -0.1568
   Episode_Reward/test_gait_reward: -0.9025
Metrics/base_velocity/error_vel_xy: 2.1951
Metrics/base_velocity/error_vel_yaw: 1.2134
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 1.06s
                        Total time: 972.85s
                               ETA: 2292.8s

################################################################################
                     [1m Learning iteration 894/3000 [0m                      

                       Computation: 91590 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 1.1006
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8701
                     Learning rate: 0.0009
                       Mean reward: 94.31
               Mean episode length: 957.29
       Episode_Reward/keep_balance: 0.9616
     Episode_Reward/rew_lin_vel_xy: 4.2116
      Episode_Reward/rew_ang_vel_z: 2.5083
    Episode_Reward/pen_base_height: -0.3466
      Episode_Reward/pen_lin_vel_z: -0.0537
     Episode_Reward/pen_ang_vel_xy: -0.1693
   Episode_Reward/pen_joint_torque: -0.2144
    Episode_Reward/pen_joint_accel: -0.1116
    Episode_Reward/pen_action_rate: -0.1028
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0495
   Episode_Reward/pen_joint_powers: -0.0775
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2300
Episode_Reward/pen_flat_orientation: -0.1473
  Episode_Reward/pen_feet_distance: -0.0095
Episode_Reward/pen_feet_regulation: -0.3224
   Episode_Reward/foot_landing_vel: -0.1480
   Episode_Reward/test_gait_reward: -0.8985
Metrics/base_velocity/error_vel_xy: 1.9704
Metrics/base_velocity/error_vel_yaw: 1.1787
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 1.07s
                        Total time: 973.92s
                               ETA: 2291.7s

################################################################################
                     [1m Learning iteration 895/3000 [0m                      

                       Computation: 90265 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 1.1892
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8685
                     Learning rate: 0.0019
                       Mean reward: 94.07
               Mean episode length: 950.07
       Episode_Reward/keep_balance: 0.9637
     Episode_Reward/rew_lin_vel_xy: 4.2468
      Episode_Reward/rew_ang_vel_z: 2.4599
    Episode_Reward/pen_base_height: -0.3238
      Episode_Reward/pen_lin_vel_z: -0.0526
     Episode_Reward/pen_ang_vel_xy: -0.1771
   Episode_Reward/pen_joint_torque: -0.2075
    Episode_Reward/pen_joint_accel: -0.1097
    Episode_Reward/pen_action_rate: -0.1045
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0488
   Episode_Reward/pen_joint_powers: -0.0765
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2345
Episode_Reward/pen_flat_orientation: -0.1385
  Episode_Reward/pen_feet_distance: -0.0049
Episode_Reward/pen_feet_regulation: -0.3233
   Episode_Reward/foot_landing_vel: -0.1478
   Episode_Reward/test_gait_reward: -0.8924
Metrics/base_velocity/error_vel_xy: 1.9313
Metrics/base_velocity/error_vel_yaw: 1.2412
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 1.09s
                        Total time: 975.01s
                               ETA: 2290.6s

################################################################################
                     [1m Learning iteration 896/3000 [0m                      

                       Computation: 92437 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 1.2313
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8664
                     Learning rate: 0.0019
                       Mean reward: 96.20
               Mean episode length: 955.16
       Episode_Reward/keep_balance: 0.9702
     Episode_Reward/rew_lin_vel_xy: 4.1514
      Episode_Reward/rew_ang_vel_z: 2.5008
    Episode_Reward/pen_base_height: -0.3275
      Episode_Reward/pen_lin_vel_z: -0.0569
     Episode_Reward/pen_ang_vel_xy: -0.1748
   Episode_Reward/pen_joint_torque: -0.2142
    Episode_Reward/pen_joint_accel: -0.1133
    Episode_Reward/pen_action_rate: -0.1037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0503
   Episode_Reward/pen_joint_powers: -0.0791
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2306
Episode_Reward/pen_flat_orientation: -0.1350
  Episode_Reward/pen_feet_distance: -0.0064
Episode_Reward/pen_feet_regulation: -0.3191
   Episode_Reward/foot_landing_vel: -0.1518
   Episode_Reward/test_gait_reward: -0.9038
Metrics/base_velocity/error_vel_xy: 2.1067
Metrics/base_velocity/error_vel_yaw: 1.2158
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 1.06s
                        Total time: 976.08s
                               ETA: 2289.5s

################################################################################
                     [1m Learning iteration 897/3000 [0m                      

                       Computation: 91406 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 1.2244
                    Surrogate loss: -0.0007
             Mean action noise std: 0.8662
                     Learning rate: 0.0006
                       Mean reward: 95.29
               Mean episode length: 966.52
       Episode_Reward/keep_balance: 0.9689
     Episode_Reward/rew_lin_vel_xy: 4.2641
      Episode_Reward/rew_ang_vel_z: 2.5021
    Episode_Reward/pen_base_height: -0.3453
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1746
   Episode_Reward/pen_joint_torque: -0.2199
    Episode_Reward/pen_joint_accel: -0.1048
    Episode_Reward/pen_action_rate: -0.1037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0505
   Episode_Reward/pen_joint_powers: -0.0798
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2307
Episode_Reward/pen_flat_orientation: -0.1452
  Episode_Reward/pen_feet_distance: -0.0049
Episode_Reward/pen_feet_regulation: -0.3398
   Episode_Reward/foot_landing_vel: -0.1538
   Episode_Reward/test_gait_reward: -0.9113
Metrics/base_velocity/error_vel_xy: 1.9748
Metrics/base_velocity/error_vel_yaw: 1.2093
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 1.08s
                        Total time: 977.15s
                               ETA: 2288.4s

################################################################################
                     [1m Learning iteration 898/3000 [0m                      

                       Computation: 92085 steps/s (collection: 0.944s, learning 0.124s)
               Value function loss: 1.1184
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8681
                     Learning rate: 0.0013
                       Mean reward: 96.49
               Mean episode length: 957.00
       Episode_Reward/keep_balance: 0.9418
     Episode_Reward/rew_lin_vel_xy: 4.2464
      Episode_Reward/rew_ang_vel_z: 2.4342
    Episode_Reward/pen_base_height: -0.3468
      Episode_Reward/pen_lin_vel_z: -0.0532
     Episode_Reward/pen_ang_vel_xy: -0.1715
   Episode_Reward/pen_joint_torque: -0.2046
    Episode_Reward/pen_joint_accel: -0.1033
    Episode_Reward/pen_action_rate: -0.1013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0480
   Episode_Reward/pen_joint_powers: -0.0754
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2272
Episode_Reward/pen_flat_orientation: -0.1458
  Episode_Reward/pen_feet_distance: -0.0047
Episode_Reward/pen_feet_regulation: -0.3114
   Episode_Reward/foot_landing_vel: -0.1437
   Episode_Reward/test_gait_reward: -0.8838
Metrics/base_velocity/error_vel_xy: 1.9117
Metrics/base_velocity/error_vel_yaw: 1.1722
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 1.07s
                        Total time: 978.22s
                               ETA: 2287.2s

################################################################################
                     [1m Learning iteration 899/3000 [0m                      

                       Computation: 90317 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 1.0590
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8698
                     Learning rate: 0.0013
                       Mean reward: 101.59
               Mean episode length: 991.95
       Episode_Reward/keep_balance: 0.9681
     Episode_Reward/rew_lin_vel_xy: 4.2936
      Episode_Reward/rew_ang_vel_z: 2.4819
    Episode_Reward/pen_base_height: -0.3281
      Episode_Reward/pen_lin_vel_z: -0.0545
     Episode_Reward/pen_ang_vel_xy: -0.1736
   Episode_Reward/pen_joint_torque: -0.2138
    Episode_Reward/pen_joint_accel: -0.1104
    Episode_Reward/pen_action_rate: -0.1037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0485
   Episode_Reward/pen_joint_powers: -0.0774
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2322
Episode_Reward/pen_flat_orientation: -0.1391
  Episode_Reward/pen_feet_distance: -0.0055
Episode_Reward/pen_feet_regulation: -0.3081
   Episode_Reward/foot_landing_vel: -0.1363
   Episode_Reward/test_gait_reward: -0.9050
Metrics/base_velocity/error_vel_xy: 1.9174
Metrics/base_velocity/error_vel_yaw: 1.2272
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 1.09s
                        Total time: 979.31s
                               ETA: 2286.1s

################################################################################
                     [1m Learning iteration 900/3000 [0m                      

                       Computation: 90825 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 1.1001
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8703
                     Learning rate: 0.0019
                       Mean reward: 94.91
               Mean episode length: 968.43
       Episode_Reward/keep_balance: 0.9790
     Episode_Reward/rew_lin_vel_xy: 4.1904
      Episode_Reward/rew_ang_vel_z: 2.5749
    Episode_Reward/pen_base_height: -0.3218
      Episode_Reward/pen_lin_vel_z: -0.0525
     Episode_Reward/pen_ang_vel_xy: -0.1689
   Episode_Reward/pen_joint_torque: -0.2150
    Episode_Reward/pen_joint_accel: -0.1114
    Episode_Reward/pen_action_rate: -0.1038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0485
   Episode_Reward/pen_joint_powers: -0.0769
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2328
Episode_Reward/pen_flat_orientation: -0.1376
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.3079
   Episode_Reward/foot_landing_vel: -0.1490
   Episode_Reward/test_gait_reward: -0.9067
Metrics/base_velocity/error_vel_xy: 2.0922
Metrics/base_velocity/error_vel_yaw: 1.1799
      Episode_Termination/time_out: 4.9583
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 1.08s
                        Total time: 980.39s
                               ETA: 2285.0s

################################################################################
                     [1m Learning iteration 901/3000 [0m                      

                       Computation: 91839 steps/s (collection: 0.947s, learning 0.124s)
               Value function loss: 1.0693
                    Surrogate loss: 0.0037
             Mean action noise std: 0.8712
                     Learning rate: 0.0001
                       Mean reward: 97.96
               Mean episode length: 958.87
       Episode_Reward/keep_balance: 0.9633
     Episode_Reward/rew_lin_vel_xy: 4.2830
      Episode_Reward/rew_ang_vel_z: 2.5326
    Episode_Reward/pen_base_height: -0.3189
      Episode_Reward/pen_lin_vel_z: -0.0524
     Episode_Reward/pen_ang_vel_xy: -0.1645
   Episode_Reward/pen_joint_torque: -0.2072
    Episode_Reward/pen_joint_accel: -0.1048
    Episode_Reward/pen_action_rate: -0.1018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0472
   Episode_Reward/pen_joint_powers: -0.0750
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2291
Episode_Reward/pen_flat_orientation: -0.1384
  Episode_Reward/pen_feet_distance: -0.0051
Episode_Reward/pen_feet_regulation: -0.2971
   Episode_Reward/foot_landing_vel: -0.1473
   Episode_Reward/test_gait_reward: -0.8940
Metrics/base_velocity/error_vel_xy: 1.9390
Metrics/base_velocity/error_vel_yaw: 1.1631
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 1.07s
                        Total time: 981.46s
                               ETA: 2283.9s

################################################################################
                     [1m Learning iteration 902/3000 [0m                      

                       Computation: 92472 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 0.9710
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8706
                     Learning rate: 0.0004
                       Mean reward: 98.28
               Mean episode length: 954.36
       Episode_Reward/keep_balance: 0.9431
     Episode_Reward/rew_lin_vel_xy: 4.2662
      Episode_Reward/rew_ang_vel_z: 2.4509
    Episode_Reward/pen_base_height: -0.3170
      Episode_Reward/pen_lin_vel_z: -0.0516
     Episode_Reward/pen_ang_vel_xy: -0.1740
   Episode_Reward/pen_joint_torque: -0.2003
    Episode_Reward/pen_joint_accel: -0.1083
    Episode_Reward/pen_action_rate: -0.1017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0484
   Episode_Reward/pen_joint_powers: -0.0747
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2277
Episode_Reward/pen_flat_orientation: -0.1308
  Episode_Reward/pen_feet_distance: -0.0048
Episode_Reward/pen_feet_regulation: -0.3059
   Episode_Reward/foot_landing_vel: -0.1425
   Episode_Reward/test_gait_reward: -0.8784
Metrics/base_velocity/error_vel_xy: 1.8826
Metrics/base_velocity/error_vel_yaw: 1.1697
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 1.06s
                        Total time: 982.52s
                               ETA: 2282.8s

################################################################################
                     [1m Learning iteration 903/3000 [0m                      

                       Computation: 91558 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.9713
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8720
                     Learning rate: 0.0009
                       Mean reward: 104.88
               Mean episode length: 988.66
       Episode_Reward/keep_balance: 0.9828
     Episode_Reward/rew_lin_vel_xy: 4.4138
      Episode_Reward/rew_ang_vel_z: 2.5542
    Episode_Reward/pen_base_height: -0.3390
      Episode_Reward/pen_lin_vel_z: -0.0542
     Episode_Reward/pen_ang_vel_xy: -0.1721
   Episode_Reward/pen_joint_torque: -0.2186
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.1051
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0489
   Episode_Reward/pen_joint_powers: -0.0781
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2332
Episode_Reward/pen_flat_orientation: -0.1388
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3130
   Episode_Reward/foot_landing_vel: -0.1412
   Episode_Reward/test_gait_reward: -0.9183
Metrics/base_velocity/error_vel_xy: 1.9116
Metrics/base_velocity/error_vel_yaw: 1.2132
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 1.07s
                        Total time: 983.60s
                               ETA: 2281.6s

################################################################################
                     [1m Learning iteration 904/3000 [0m                      

                       Computation: 92478 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 1.0096
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8744
                     Learning rate: 0.0013
                       Mean reward: 93.98
               Mean episode length: 964.82
       Episode_Reward/keep_balance: 0.9749
     Episode_Reward/rew_lin_vel_xy: 4.1845
      Episode_Reward/rew_ang_vel_z: 2.5343
    Episode_Reward/pen_base_height: -0.3376
      Episode_Reward/pen_lin_vel_z: -0.0546
     Episode_Reward/pen_ang_vel_xy: -0.1788
   Episode_Reward/pen_joint_torque: -0.2109
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1055
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0496
   Episode_Reward/pen_joint_powers: -0.0780
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2358
Episode_Reward/pen_flat_orientation: -0.1445
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3226
   Episode_Reward/foot_landing_vel: -0.1455
   Episode_Reward/test_gait_reward: -0.9123
Metrics/base_velocity/error_vel_xy: 2.1127
Metrics/base_velocity/error_vel_yaw: 1.2121
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 1.06s
                        Total time: 984.66s
                               ETA: 2280.5s

################################################################################
                     [1m Learning iteration 905/3000 [0m                      

                       Computation: 91490 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 1.0226
                    Surrogate loss: -0.0013
             Mean action noise std: 0.8763
                     Learning rate: 0.0006
                       Mean reward: 97.99
               Mean episode length: 956.42
       Episode_Reward/keep_balance: 0.9645
     Episode_Reward/rew_lin_vel_xy: 4.4839
      Episode_Reward/rew_ang_vel_z: 2.5034
    Episode_Reward/pen_base_height: -0.3141
      Episode_Reward/pen_lin_vel_z: -0.0571
     Episode_Reward/pen_ang_vel_xy: -0.1747
   Episode_Reward/pen_joint_torque: -0.2213
    Episode_Reward/pen_joint_accel: -0.1137
    Episode_Reward/pen_action_rate: -0.1049
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0516
   Episode_Reward/pen_joint_powers: -0.0811
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2344
Episode_Reward/pen_flat_orientation: -0.1298
  Episode_Reward/pen_feet_distance: -0.0044
Episode_Reward/pen_feet_regulation: -0.3463
   Episode_Reward/foot_landing_vel: -0.1575
   Episode_Reward/test_gait_reward: -0.9001
Metrics/base_velocity/error_vel_xy: 1.8040
Metrics/base_velocity/error_vel_yaw: 1.1921
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 1.07s
                        Total time: 985.73s
                               ETA: 2279.4s

################################################################################
                     [1m Learning iteration 906/3000 [0m                      

                       Computation: 90761 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 1.0531
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8782
                     Learning rate: 0.0009
                       Mean reward: 88.04
               Mean episode length: 926.83
       Episode_Reward/keep_balance: 0.9177
     Episode_Reward/rew_lin_vel_xy: 3.8510
      Episode_Reward/rew_ang_vel_z: 2.3639
    Episode_Reward/pen_base_height: -0.3265
      Episode_Reward/pen_lin_vel_z: -0.0534
     Episode_Reward/pen_ang_vel_xy: -0.1638
   Episode_Reward/pen_joint_torque: -0.2038
    Episode_Reward/pen_joint_accel: -0.0957
    Episode_Reward/pen_action_rate: -0.0995
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0475
   Episode_Reward/pen_joint_powers: -0.0748
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2231
Episode_Reward/pen_flat_orientation: -0.1456
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3070
   Episode_Reward/foot_landing_vel: -0.1365
   Episode_Reward/test_gait_reward: -0.8510
Metrics/base_velocity/error_vel_xy: 2.0197
Metrics/base_velocity/error_vel_yaw: 1.1652
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 1.08s
                        Total time: 986.82s
                               ETA: 2278.3s

################################################################################
                     [1m Learning iteration 907/3000 [0m                      

                       Computation: 92204 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 1.0817
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8803
                     Learning rate: 0.0013
                       Mean reward: 96.35
               Mean episode length: 943.23
       Episode_Reward/keep_balance: 0.9319
     Episode_Reward/rew_lin_vel_xy: 4.1822
      Episode_Reward/rew_ang_vel_z: 2.4175
    Episode_Reward/pen_base_height: -0.3151
      Episode_Reward/pen_lin_vel_z: -0.0546
     Episode_Reward/pen_ang_vel_xy: -0.1653
   Episode_Reward/pen_joint_torque: -0.2118
    Episode_Reward/pen_joint_accel: -0.1015
    Episode_Reward/pen_action_rate: -0.1008
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0483
   Episode_Reward/pen_joint_powers: -0.0764
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2241
Episode_Reward/pen_flat_orientation: -0.1337
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.3146
   Episode_Reward/foot_landing_vel: -0.1434
   Episode_Reward/test_gait_reward: -0.8683
Metrics/base_velocity/error_vel_xy: 1.8709
Metrics/base_velocity/error_vel_yaw: 1.1589
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 1.07s
                        Total time: 987.88s
                               ETA: 2277.1s

################################################################################
                     [1m Learning iteration 908/3000 [0m                      

                       Computation: 91287 steps/s (collection: 0.952s, learning 0.125s)
               Value function loss: 1.0396
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8802
                     Learning rate: 0.0006
                       Mean reward: 90.93
               Mean episode length: 913.66
       Episode_Reward/keep_balance: 0.9290
     Episode_Reward/rew_lin_vel_xy: 4.1027
      Episode_Reward/rew_ang_vel_z: 2.3685
    Episode_Reward/pen_base_height: -0.3219
      Episode_Reward/pen_lin_vel_z: -0.0519
     Episode_Reward/pen_ang_vel_xy: -0.1685
   Episode_Reward/pen_joint_torque: -0.2090
    Episode_Reward/pen_joint_accel: -0.1142
    Episode_Reward/pen_action_rate: -0.1023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0498
   Episode_Reward/pen_joint_powers: -0.0773
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2277
Episode_Reward/pen_flat_orientation: -0.1502
  Episode_Reward/pen_feet_distance: -0.0052
Episode_Reward/pen_feet_regulation: -0.3061
   Episode_Reward/foot_landing_vel: -0.1465
   Episode_Reward/test_gait_reward: -0.8634
Metrics/base_velocity/error_vel_xy: 1.8752
Metrics/base_velocity/error_vel_yaw: 1.2097
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 1.08s
                        Total time: 988.96s
                               ETA: 2276.0s

################################################################################
                     [1m Learning iteration 909/3000 [0m                      

                       Computation: 91516 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 1.1727
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8794
                     Learning rate: 0.0013
                       Mean reward: 90.87
               Mean episode length: 929.88
       Episode_Reward/keep_balance: 0.9439
     Episode_Reward/rew_lin_vel_xy: 4.0318
      Episode_Reward/rew_ang_vel_z: 2.4710
    Episode_Reward/pen_base_height: -0.3142
      Episode_Reward/pen_lin_vel_z: -0.0496
     Episode_Reward/pen_ang_vel_xy: -0.1616
   Episode_Reward/pen_joint_torque: -0.2103
    Episode_Reward/pen_joint_accel: -0.1102
    Episode_Reward/pen_action_rate: -0.1014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0472
   Episode_Reward/pen_joint_powers: -0.0754
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2277
Episode_Reward/pen_flat_orientation: -0.1357
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.2961
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.8757
Metrics/base_velocity/error_vel_xy: 2.0130
Metrics/base_velocity/error_vel_yaw: 1.1500
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 1.07s
                        Total time: 990.03s
                               ETA: 2274.9s

################################################################################
                     [1m Learning iteration 910/3000 [0m                      

                       Computation: 90646 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 1.1509
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8803
                     Learning rate: 0.0019
                       Mean reward: 96.41
               Mean episode length: 932.90
       Episode_Reward/keep_balance: 0.9378
     Episode_Reward/rew_lin_vel_xy: 4.2621
      Episode_Reward/rew_ang_vel_z: 2.4024
    Episode_Reward/pen_base_height: -0.3200
      Episode_Reward/pen_lin_vel_z: -0.0499
     Episode_Reward/pen_ang_vel_xy: -0.1599
   Episode_Reward/pen_joint_torque: -0.1974
    Episode_Reward/pen_joint_accel: -0.1068
    Episode_Reward/pen_action_rate: -0.1016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0469
   Episode_Reward/pen_joint_powers: -0.0733
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2304
Episode_Reward/pen_flat_orientation: -0.1399
  Episode_Reward/pen_feet_distance: -0.0055
Episode_Reward/pen_feet_regulation: -0.3024
   Episode_Reward/foot_landing_vel: -0.1343
   Episode_Reward/test_gait_reward: -0.8795
Metrics/base_velocity/error_vel_xy: 1.8497
Metrics/base_velocity/error_vel_yaw: 1.1936
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 1.08s
                        Total time: 991.12s
                               ETA: 2273.8s

################################################################################
                     [1m Learning iteration 911/3000 [0m                      

                       Computation: 91083 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 1.1061
                    Surrogate loss: -0.0000
             Mean action noise std: 0.8811
                     Learning rate: 0.0004
                       Mean reward: 91.79
               Mean episode length: 907.56
       Episode_Reward/keep_balance: 0.9107
     Episode_Reward/rew_lin_vel_xy: 4.0756
      Episode_Reward/rew_ang_vel_z: 2.3535
    Episode_Reward/pen_base_height: -0.3058
      Episode_Reward/pen_lin_vel_z: -0.0472
     Episode_Reward/pen_ang_vel_xy: -0.1663
   Episode_Reward/pen_joint_torque: -0.1918
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.0990
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0461
   Episode_Reward/pen_joint_powers: -0.0717
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2219
Episode_Reward/pen_flat_orientation: -0.1333
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.2941
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.8459
Metrics/base_velocity/error_vel_xy: 1.8269
Metrics/base_velocity/error_vel_yaw: 1.1474
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 1.08s
                        Total time: 992.20s
                               ETA: 2272.7s

################################################################################
                     [1m Learning iteration 912/3000 [0m                      

                       Computation: 90456 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.9990
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8822
                     Learning rate: 0.0009
                       Mean reward: 90.36
               Mean episode length: 940.93
       Episode_Reward/keep_balance: 0.9366
     Episode_Reward/rew_lin_vel_xy: 4.0650
      Episode_Reward/rew_ang_vel_z: 2.3856
    Episode_Reward/pen_base_height: -0.3248
      Episode_Reward/pen_lin_vel_z: -0.0538
     Episode_Reward/pen_ang_vel_xy: -0.1705
   Episode_Reward/pen_joint_torque: -0.2082
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0493
   Episode_Reward/pen_joint_powers: -0.0773
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2335
Episode_Reward/pen_flat_orientation: -0.1418
  Episode_Reward/pen_feet_distance: -0.0058
Episode_Reward/pen_feet_regulation: -0.3150
   Episode_Reward/foot_landing_vel: -0.1396
   Episode_Reward/test_gait_reward: -0.8746
Metrics/base_velocity/error_vel_xy: 1.9622
Metrics/base_velocity/error_vel_yaw: 1.2110
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 1.09s
                        Total time: 993.28s
                               ETA: 2271.6s

################################################################################
                     [1m Learning iteration 913/3000 [0m                      

                       Computation: 89617 steps/s (collection: 0.975s, learning 0.122s)
               Value function loss: 1.1208
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8831
                     Learning rate: 0.0013
                       Mean reward: 96.67
               Mean episode length: 953.72
       Episode_Reward/keep_balance: 0.9591
     Episode_Reward/rew_lin_vel_xy: 4.3367
      Episode_Reward/rew_ang_vel_z: 2.5116
    Episode_Reward/pen_base_height: -0.3249
      Episode_Reward/pen_lin_vel_z: -0.0545
     Episode_Reward/pen_ang_vel_xy: -0.1737
   Episode_Reward/pen_joint_torque: -0.2167
    Episode_Reward/pen_joint_accel: -0.1185
    Episode_Reward/pen_action_rate: -0.1047
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0505
   Episode_Reward/pen_joint_powers: -0.0794
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.2344
Episode_Reward/pen_flat_orientation: -0.1362
  Episode_Reward/pen_feet_distance: -0.0089
Episode_Reward/pen_feet_regulation: -0.3205
   Episode_Reward/foot_landing_vel: -0.1495
   Episode_Reward/test_gait_reward: -0.8975
Metrics/base_velocity/error_vel_xy: 1.9040
Metrics/base_velocity/error_vel_yaw: 1.1706
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 1.10s
                        Total time: 994.38s
                               ETA: 2270.5s

################################################################################
                     [1m Learning iteration 914/3000 [0m                      

                       Computation: 93400 steps/s (collection: 0.930s, learning 0.123s)
               Value function loss: 1.0317
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8840
                     Learning rate: 0.0006
                       Mean reward: 95.24
               Mean episode length: 951.42
       Episode_Reward/keep_balance: 0.9428
     Episode_Reward/rew_lin_vel_xy: 4.1708
      Episode_Reward/rew_ang_vel_z: 2.4228
    Episode_Reward/pen_base_height: -0.3084
      Episode_Reward/pen_lin_vel_z: -0.0504
     Episode_Reward/pen_ang_vel_xy: -0.1628
   Episode_Reward/pen_joint_torque: -0.2011
    Episode_Reward/pen_joint_accel: -0.1023
    Episode_Reward/pen_action_rate: -0.1017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0465
   Episode_Reward/pen_joint_powers: -0.0741
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2291
Episode_Reward/pen_flat_orientation: -0.1332
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.2882
   Episode_Reward/foot_landing_vel: -0.1364
   Episode_Reward/test_gait_reward: -0.8716
Metrics/base_velocity/error_vel_xy: 1.9629
Metrics/base_velocity/error_vel_yaw: 1.1947
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 1.05s
                        Total time: 995.43s
                               ETA: 2269.4s

################################################################################
                     [1m Learning iteration 915/3000 [0m                      

                       Computation: 91665 steps/s (collection: 0.948s, learning 0.125s)
               Value function loss: 1.0357
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8852
                     Learning rate: 0.0013
                       Mean reward: 92.51
               Mean episode length: 957.85
       Episode_Reward/keep_balance: 0.9661
     Episode_Reward/rew_lin_vel_xy: 4.1080
      Episode_Reward/rew_ang_vel_z: 2.5177
    Episode_Reward/pen_base_height: -0.3196
      Episode_Reward/pen_lin_vel_z: -0.0546
     Episode_Reward/pen_ang_vel_xy: -0.1734
   Episode_Reward/pen_joint_torque: -0.2199
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1063
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0502
   Episode_Reward/pen_joint_powers: -0.0792
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2388
Episode_Reward/pen_flat_orientation: -0.1315
  Episode_Reward/pen_feet_distance: -0.0047
Episode_Reward/pen_feet_regulation: -0.3336
   Episode_Reward/foot_landing_vel: -0.1487
   Episode_Reward/test_gait_reward: -0.9010
Metrics/base_velocity/error_vel_xy: 2.1882
Metrics/base_velocity/error_vel_yaw: 1.1927
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 1.07s
                        Total time: 996.51s
                               ETA: 2268.2s

################################################################################
                     [1m Learning iteration 916/3000 [0m                      

                       Computation: 92118 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 1.0755
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8870
                     Learning rate: 0.0009
                       Mean reward: 96.74
               Mean episode length: 945.46
       Episode_Reward/keep_balance: 0.9379
     Episode_Reward/rew_lin_vel_xy: 4.2270
      Episode_Reward/rew_ang_vel_z: 2.4393
    Episode_Reward/pen_base_height: -0.3265
      Episode_Reward/pen_lin_vel_z: -0.0548
     Episode_Reward/pen_ang_vel_xy: -0.1698
   Episode_Reward/pen_joint_torque: -0.2153
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0487
   Episode_Reward/pen_joint_powers: -0.0779
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2281
Episode_Reward/pen_flat_orientation: -0.1392
  Episode_Reward/pen_feet_distance: -0.0065
Episode_Reward/pen_feet_regulation: -0.3140
   Episode_Reward/foot_landing_vel: -0.1418
   Episode_Reward/test_gait_reward: -0.8811
Metrics/base_velocity/error_vel_xy: 1.9074
Metrics/base_velocity/error_vel_yaw: 1.1651
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 1.07s
                        Total time: 997.57s
                               ETA: 2267.1s

################################################################################
                     [1m Learning iteration 917/3000 [0m                      

                       Computation: 93691 steps/s (collection: 0.928s, learning 0.122s)
               Value function loss: 1.0275
                    Surrogate loss: -0.0001
             Mean action noise std: 0.8871
                     Learning rate: 0.0003
                       Mean reward: 98.31
               Mean episode length: 961.63
       Episode_Reward/keep_balance: 0.9636
     Episode_Reward/rew_lin_vel_xy: 4.3266
      Episode_Reward/rew_ang_vel_z: 2.4822
    Episode_Reward/pen_base_height: -0.3147
      Episode_Reward/pen_lin_vel_z: -0.0516
     Episode_Reward/pen_ang_vel_xy: -0.1727
   Episode_Reward/pen_joint_torque: -0.2122
    Episode_Reward/pen_joint_accel: -0.1020
    Episode_Reward/pen_action_rate: -0.1058
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0496
   Episode_Reward/pen_joint_powers: -0.0785
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2386
Episode_Reward/pen_flat_orientation: -0.1301
  Episode_Reward/pen_feet_distance: -0.0079
Episode_Reward/pen_feet_regulation: -0.3322
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9004
Metrics/base_velocity/error_vel_xy: 1.8979
Metrics/base_velocity/error_vel_yaw: 1.2145
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 1.05s
                        Total time: 998.62s
                               ETA: 2265.9s

################################################################################
                     [1m Learning iteration 918/3000 [0m                      

                       Computation: 92806 steps/s (collection: 0.938s, learning 0.121s)
               Value function loss: 0.9874
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8864
                     Learning rate: 0.0004
                       Mean reward: 98.50
               Mean episode length: 945.59
       Episode_Reward/keep_balance: 0.9512
     Episode_Reward/rew_lin_vel_xy: 4.3387
      Episode_Reward/rew_ang_vel_z: 2.4550
    Episode_Reward/pen_base_height: -0.3177
      Episode_Reward/pen_lin_vel_z: -0.0501
     Episode_Reward/pen_ang_vel_xy: -0.1678
   Episode_Reward/pen_joint_torque: -0.2080
    Episode_Reward/pen_joint_accel: -0.1027
    Episode_Reward/pen_action_rate: -0.1045
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0467
   Episode_Reward/pen_joint_powers: -0.0749
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2348
Episode_Reward/pen_flat_orientation: -0.1398
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.2915
   Episode_Reward/foot_landing_vel: -0.1340
   Episode_Reward/test_gait_reward: -0.8765
Metrics/base_velocity/error_vel_xy: 1.8498
Metrics/base_velocity/error_vel_yaw: 1.2114
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 1.06s
                        Total time: 999.68s
                               ETA: 2264.8s

################################################################################
                     [1m Learning iteration 919/3000 [0m                      

                       Computation: 92879 steps/s (collection: 0.937s, learning 0.121s)
               Value function loss: 1.1327
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8846
                     Learning rate: 0.0009
                       Mean reward: 94.29
               Mean episode length: 921.09
       Episode_Reward/keep_balance: 0.9126
     Episode_Reward/rew_lin_vel_xy: 4.1678
      Episode_Reward/rew_ang_vel_z: 2.3225
    Episode_Reward/pen_base_height: -0.3214
      Episode_Reward/pen_lin_vel_z: -0.0511
     Episode_Reward/pen_ang_vel_xy: -0.1696
   Episode_Reward/pen_joint_torque: -0.2057
    Episode_Reward/pen_joint_accel: -0.1146
    Episode_Reward/pen_action_rate: -0.1030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0497
   Episode_Reward/pen_joint_powers: -0.0769
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2293
Episode_Reward/pen_flat_orientation: -0.1398
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3283
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.8631
Metrics/base_velocity/error_vel_xy: 1.7797
Metrics/base_velocity/error_vel_yaw: 1.1740
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 1.06s
                        Total time: 1000.74s
                               ETA: 2263.6s

################################################################################
                     [1m Learning iteration 920/3000 [0m                      

                       Computation: 90805 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 1.1591
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8851
                     Learning rate: 0.0003
                       Mean reward: 97.62
               Mean episode length: 964.13
       Episode_Reward/keep_balance: 0.9452
     Episode_Reward/rew_lin_vel_xy: 4.2913
      Episode_Reward/rew_ang_vel_z: 2.3842
    Episode_Reward/pen_base_height: -0.3142
      Episode_Reward/pen_lin_vel_z: -0.0550
     Episode_Reward/pen_ang_vel_xy: -0.1746
   Episode_Reward/pen_joint_torque: -0.2106
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1068
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0508
   Episode_Reward/pen_joint_powers: -0.0787
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2386
Episode_Reward/pen_flat_orientation: -0.1358
  Episode_Reward/pen_feet_distance: -0.0057
Episode_Reward/pen_feet_regulation: -0.3291
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.8947
Metrics/base_velocity/error_vel_xy: 1.8297
Metrics/base_velocity/error_vel_yaw: 1.2387
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 1.08s
                        Total time: 1001.82s
                               ETA: 2262.5s

################################################################################
                     [1m Learning iteration 921/3000 [0m                      

                       Computation: 91730 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.9576
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8851
                     Learning rate: 0.0002
                       Mean reward: 94.80
               Mean episode length: 944.01
       Episode_Reward/keep_balance: 0.9370
     Episode_Reward/rew_lin_vel_xy: 4.2212
      Episode_Reward/rew_ang_vel_z: 2.4187
    Episode_Reward/pen_base_height: -0.3191
      Episode_Reward/pen_lin_vel_z: -0.0524
     Episode_Reward/pen_ang_vel_xy: -0.1670
   Episode_Reward/pen_joint_torque: -0.2081
    Episode_Reward/pen_joint_accel: -0.0985
    Episode_Reward/pen_action_rate: -0.1037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0476
   Episode_Reward/pen_joint_powers: -0.0759
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2312
Episode_Reward/pen_flat_orientation: -0.1333
  Episode_Reward/pen_feet_distance: -0.0058
Episode_Reward/pen_feet_regulation: -0.3171
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.8767
Metrics/base_velocity/error_vel_xy: 1.8892
Metrics/base_velocity/error_vel_yaw: 1.1788
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 1.07s
                        Total time: 1002.89s
                               ETA: 2261.4s

################################################################################
                     [1m Learning iteration 922/3000 [0m                      

                       Computation: 91437 steps/s (collection: 0.954s, learning 0.121s)
               Value function loss: 1.0563
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8846
                     Learning rate: 0.0003
                       Mean reward: 94.65
               Mean episode length: 956.28
       Episode_Reward/keep_balance: 0.9553
     Episode_Reward/rew_lin_vel_xy: 4.2653
      Episode_Reward/rew_ang_vel_z: 2.4288
    Episode_Reward/pen_base_height: -0.3221
      Episode_Reward/pen_lin_vel_z: -0.0501
     Episode_Reward/pen_ang_vel_xy: -0.1750
   Episode_Reward/pen_joint_torque: -0.2077
    Episode_Reward/pen_joint_accel: -0.1087
    Episode_Reward/pen_action_rate: -0.1070
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0496
   Episode_Reward/pen_joint_powers: -0.0775
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2414
Episode_Reward/pen_flat_orientation: -0.1325
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3232
   Episode_Reward/foot_landing_vel: -0.1411
   Episode_Reward/test_gait_reward: -0.8984
Metrics/base_velocity/error_vel_xy: 1.9110
Metrics/base_velocity/error_vel_yaw: 1.2324
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 1.08s
                        Total time: 1003.97s
                               ETA: 2260.3s

################################################################################
                     [1m Learning iteration 923/3000 [0m                      

                       Computation: 91749 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 1.0273
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8827
                     Learning rate: 0.0006
                       Mean reward: 98.54
               Mean episode length: 926.76
       Episode_Reward/keep_balance: 0.9252
     Episode_Reward/rew_lin_vel_xy: 4.3358
      Episode_Reward/rew_ang_vel_z: 2.3958
    Episode_Reward/pen_base_height: -0.3069
      Episode_Reward/pen_lin_vel_z: -0.0476
     Episode_Reward/pen_ang_vel_xy: -0.1623
   Episode_Reward/pen_joint_torque: -0.2009
    Episode_Reward/pen_joint_accel: -0.1005
    Episode_Reward/pen_action_rate: -0.1016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0461
   Episode_Reward/pen_joint_powers: -0.0733
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2287
Episode_Reward/pen_flat_orientation: -0.1248
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.2903
   Episode_Reward/foot_landing_vel: -0.1326
   Episode_Reward/test_gait_reward: -0.8580
Metrics/base_velocity/error_vel_xy: 1.7152
Metrics/base_velocity/error_vel_yaw: 1.1568
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 1.07s
                        Total time: 1005.04s
                               ETA: 2259.2s

################################################################################
                     [1m Learning iteration 924/3000 [0m                      

                       Computation: 92873 steps/s (collection: 0.932s, learning 0.127s)
               Value function loss: 1.0559
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8859
                     Learning rate: 0.0013
                       Mean reward: 99.98
               Mean episode length: 948.34
       Episode_Reward/keep_balance: 0.9434
     Episode_Reward/rew_lin_vel_xy: 4.3542
      Episode_Reward/rew_ang_vel_z: 2.4312
    Episode_Reward/pen_base_height: -0.3125
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.1674
   Episode_Reward/pen_joint_torque: -0.2080
    Episode_Reward/pen_joint_accel: -0.1074
    Episode_Reward/pen_action_rate: -0.1045
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0478
   Episode_Reward/pen_joint_powers: -0.0761
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2355
Episode_Reward/pen_flat_orientation: -0.1299
  Episode_Reward/pen_feet_distance: -0.0050
Episode_Reward/pen_feet_regulation: -0.3013
   Episode_Reward/foot_landing_vel: -0.1375
   Episode_Reward/test_gait_reward: -0.8843
Metrics/base_velocity/error_vel_xy: 1.8587
Metrics/base_velocity/error_vel_yaw: 1.1855
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 1.06s
                        Total time: 1006.10s
                               ETA: 2258.0s

################################################################################
                     [1m Learning iteration 925/3000 [0m                      

                       Computation: 91242 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.9384
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8881
                     Learning rate: 0.0009
                       Mean reward: 97.48
               Mean episode length: 937.26
       Episode_Reward/keep_balance: 0.9501
     Episode_Reward/rew_lin_vel_xy: 4.3699
      Episode_Reward/rew_ang_vel_z: 2.4290
    Episode_Reward/pen_base_height: -0.3157
      Episode_Reward/pen_lin_vel_z: -0.0516
     Episode_Reward/pen_ang_vel_xy: -0.1747
   Episode_Reward/pen_joint_torque: -0.2077
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.1069
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0489
   Episode_Reward/pen_joint_powers: -0.0773
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2405
Episode_Reward/pen_flat_orientation: -0.1315
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3137
   Episode_Reward/foot_landing_vel: -0.1399
   Episode_Reward/test_gait_reward: -0.8865
Metrics/base_velocity/error_vel_xy: 1.8343
Metrics/base_velocity/error_vel_yaw: 1.2153
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 1.08s
                        Total time: 1007.18s
                               ETA: 2256.9s

################################################################################
                     [1m Learning iteration 926/3000 [0m                      

                       Computation: 91065 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 1.0881
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8874
                     Learning rate: 0.0013
                       Mean reward: 99.15
               Mean episode length: 950.65
       Episode_Reward/keep_balance: 0.9612
     Episode_Reward/rew_lin_vel_xy: 4.4110
      Episode_Reward/rew_ang_vel_z: 2.5008
    Episode_Reward/pen_base_height: -0.3110
      Episode_Reward/pen_lin_vel_z: -0.0492
     Episode_Reward/pen_ang_vel_xy: -0.1682
   Episode_Reward/pen_joint_torque: -0.2141
    Episode_Reward/pen_joint_accel: -0.0988
    Episode_Reward/pen_action_rate: -0.1048
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0465
   Episode_Reward/pen_joint_powers: -0.0755
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2377
Episode_Reward/pen_flat_orientation: -0.1227
  Episode_Reward/pen_feet_distance: -0.0047
Episode_Reward/pen_feet_regulation: -0.2961
   Episode_Reward/foot_landing_vel: -0.1325
   Episode_Reward/test_gait_reward: -0.8912
Metrics/base_velocity/error_vel_xy: 1.8147
Metrics/base_velocity/error_vel_yaw: 1.1828
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 1.08s
                        Total time: 1008.26s
                               ETA: 2255.8s

################################################################################
                     [1m Learning iteration 927/3000 [0m                      

                       Computation: 91876 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.0946
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8882
                     Learning rate: 0.0009
                       Mean reward: 97.14
               Mean episode length: 945.34
       Episode_Reward/keep_balance: 0.9323
     Episode_Reward/rew_lin_vel_xy: 4.1626
      Episode_Reward/rew_ang_vel_z: 2.4040
    Episode_Reward/pen_base_height: -0.3145
      Episode_Reward/pen_lin_vel_z: -0.0511
     Episode_Reward/pen_ang_vel_xy: -0.1662
   Episode_Reward/pen_joint_torque: -0.2057
    Episode_Reward/pen_joint_accel: -0.1019
    Episode_Reward/pen_action_rate: -0.1043
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0492
   Episode_Reward/pen_joint_powers: -0.0768
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2340
Episode_Reward/pen_flat_orientation: -0.1309
  Episode_Reward/pen_feet_distance: -0.0049
Episode_Reward/pen_feet_regulation: -0.3176
   Episode_Reward/foot_landing_vel: -0.1441
   Episode_Reward/test_gait_reward: -0.8699
Metrics/base_velocity/error_vel_xy: 1.9144
Metrics/base_velocity/error_vel_yaw: 1.1732
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 1.07s
                        Total time: 1009.33s
                               ETA: 2254.7s

################################################################################
                     [1m Learning iteration 928/3000 [0m                      

                       Computation: 90703 steps/s (collection: 0.959s, learning 0.125s)
               Value function loss: 1.0790
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8887
                     Learning rate: 0.0019
                       Mean reward: 99.08
               Mean episode length: 955.09
       Episode_Reward/keep_balance: 0.9571
     Episode_Reward/rew_lin_vel_xy: 4.4283
      Episode_Reward/rew_ang_vel_z: 2.4375
    Episode_Reward/pen_base_height: -0.3316
      Episode_Reward/pen_lin_vel_z: -0.0528
     Episode_Reward/pen_ang_vel_xy: -0.1718
   Episode_Reward/pen_joint_torque: -0.2188
    Episode_Reward/pen_joint_accel: -0.1042
    Episode_Reward/pen_action_rate: -0.1084
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0501
   Episode_Reward/pen_joint_powers: -0.0797
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2411
Episode_Reward/pen_flat_orientation: -0.1355
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3311
   Episode_Reward/foot_landing_vel: -0.1377
   Episode_Reward/test_gait_reward: -0.9045
Metrics/base_velocity/error_vel_xy: 1.7758
Metrics/base_velocity/error_vel_yaw: 1.2372
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 1.08s
                        Total time: 1010.41s
                               ETA: 2253.6s

################################################################################
                     [1m Learning iteration 929/3000 [0m                      

                       Computation: 92355 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 1.2060
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8878
                     Learning rate: 0.0019
                       Mean reward: 95.53
               Mean episode length: 960.35
       Episode_Reward/keep_balance: 0.9588
     Episode_Reward/rew_lin_vel_xy: 4.1881
      Episode_Reward/rew_ang_vel_z: 2.4650
    Episode_Reward/pen_base_height: -0.3191
      Episode_Reward/pen_lin_vel_z: -0.0519
     Episode_Reward/pen_ang_vel_xy: -0.1716
   Episode_Reward/pen_joint_torque: -0.2148
    Episode_Reward/pen_joint_accel: -0.1057
    Episode_Reward/pen_action_rate: -0.1072
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0489
   Episode_Reward/pen_joint_powers: -0.0780
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2412
Episode_Reward/pen_flat_orientation: -0.1315
  Episode_Reward/pen_feet_distance: -0.0048
Episode_Reward/pen_feet_regulation: -0.3223
   Episode_Reward/foot_landing_vel: -0.1390
   Episode_Reward/test_gait_reward: -0.8916
Metrics/base_velocity/error_vel_xy: 1.9820
Metrics/base_velocity/error_vel_yaw: 1.2115
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 1.06s
                        Total time: 1011.47s
                               ETA: 2252.4s

################################################################################
                     [1m Learning iteration 930/3000 [0m                      

                       Computation: 91548 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.1892
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8890
                     Learning rate: 0.0019
                       Mean reward: 94.22
               Mean episode length: 943.01
       Episode_Reward/keep_balance: 0.9445
     Episode_Reward/rew_lin_vel_xy: 4.1555
      Episode_Reward/rew_ang_vel_z: 2.4046
    Episode_Reward/pen_base_height: -0.3051
      Episode_Reward/pen_lin_vel_z: -0.0469
     Episode_Reward/pen_ang_vel_xy: -0.1673
   Episode_Reward/pen_joint_torque: -0.2042
    Episode_Reward/pen_joint_accel: -0.1079
    Episode_Reward/pen_action_rate: -0.1059
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0479
   Episode_Reward/pen_joint_powers: -0.0749
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2414
Episode_Reward/pen_flat_orientation: -0.1302
  Episode_Reward/pen_feet_distance: -0.0061
Episode_Reward/pen_feet_regulation: -0.3008
   Episode_Reward/foot_landing_vel: -0.1315
   Episode_Reward/test_gait_reward: -0.8735
Metrics/base_velocity/error_vel_xy: 1.9281
Metrics/base_velocity/error_vel_yaw: 1.2153
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 1.07s
                        Total time: 1012.55s
                               ETA: 2251.3s

################################################################################
                     [1m Learning iteration 931/3000 [0m                      

                       Computation: 91039 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 1.0955
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8895
                     Learning rate: 0.0013
                       Mean reward: 98.93
               Mean episode length: 940.49
       Episode_Reward/keep_balance: 0.9349
     Episode_Reward/rew_lin_vel_xy: 4.2769
      Episode_Reward/rew_ang_vel_z: 2.3889
    Episode_Reward/pen_base_height: -0.3060
      Episode_Reward/pen_lin_vel_z: -0.0496
     Episode_Reward/pen_ang_vel_xy: -0.1623
   Episode_Reward/pen_joint_torque: -0.2021
    Episode_Reward/pen_joint_accel: -0.1017
    Episode_Reward/pen_action_rate: -0.1043
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0473
   Episode_Reward/pen_joint_powers: -0.0740
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2357
Episode_Reward/pen_flat_orientation: -0.1239
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.3119
   Episode_Reward/foot_landing_vel: -0.1425
   Episode_Reward/test_gait_reward: -0.8718
Metrics/base_velocity/error_vel_xy: 1.7979
Metrics/base_velocity/error_vel_yaw: 1.1893
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 1.08s
                        Total time: 1013.63s
                               ETA: 2250.2s

################################################################################
                     [1m Learning iteration 932/3000 [0m                      

                       Computation: 91939 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 1.0129
                    Surrogate loss: -0.0001
             Mean action noise std: 0.8899
                     Learning rate: 0.0004
                       Mean reward: 99.79
               Mean episode length: 959.40
       Episode_Reward/keep_balance: 0.9658
     Episode_Reward/rew_lin_vel_xy: 4.3614
      Episode_Reward/rew_ang_vel_z: 2.4583
    Episode_Reward/pen_base_height: -0.3043
      Episode_Reward/pen_lin_vel_z: -0.0485
     Episode_Reward/pen_ang_vel_xy: -0.1687
   Episode_Reward/pen_joint_torque: -0.2085
    Episode_Reward/pen_joint_accel: -0.1009
    Episode_Reward/pen_action_rate: -0.1075
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0480
   Episode_Reward/pen_joint_powers: -0.0758
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2444
Episode_Reward/pen_flat_orientation: -0.1168
  Episode_Reward/pen_feet_distance: -0.0052
Episode_Reward/pen_feet_regulation: -0.3036
   Episode_Reward/foot_landing_vel: -0.1415
   Episode_Reward/test_gait_reward: -0.8934
Metrics/base_velocity/error_vel_xy: 1.9597
Metrics/base_velocity/error_vel_yaw: 1.2365
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 1.07s
                        Total time: 1014.70s
                               ETA: 2249.1s

################################################################################
                     [1m Learning iteration 933/3000 [0m                      

                       Computation: 91442 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.9965
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8890
                     Learning rate: 0.0004
                       Mean reward: 93.40
               Mean episode length: 946.75
       Episode_Reward/keep_balance: 0.9416
     Episode_Reward/rew_lin_vel_xy: 4.0766
      Episode_Reward/rew_ang_vel_z: 2.3918
    Episode_Reward/pen_base_height: -0.3063
      Episode_Reward/pen_lin_vel_z: -0.0483
     Episode_Reward/pen_ang_vel_xy: -0.1691
   Episode_Reward/pen_joint_torque: -0.2052
    Episode_Reward/pen_joint_accel: -0.0959
    Episode_Reward/pen_action_rate: -0.1061
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0486
   Episode_Reward/pen_joint_powers: -0.0760
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2393
Episode_Reward/pen_flat_orientation: -0.1245
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.3148
   Episode_Reward/foot_landing_vel: -0.1401
   Episode_Reward/test_gait_reward: -0.8750
Metrics/base_velocity/error_vel_xy: 1.9073
Metrics/base_velocity/error_vel_yaw: 1.2165
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 1.08s
                        Total time: 1015.77s
                               ETA: 2248.0s

################################################################################
                     [1m Learning iteration 934/3000 [0m                      

                       Computation: 87321 steps/s (collection: 1.003s, learning 0.122s)
               Value function loss: 0.9723
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8884
                     Learning rate: 0.0006
                       Mean reward: 99.67
               Mean episode length: 947.64
       Episode_Reward/keep_balance: 0.9305
     Episode_Reward/rew_lin_vel_xy: 4.2034
      Episode_Reward/rew_ang_vel_z: 2.4208
    Episode_Reward/pen_base_height: -0.3147
      Episode_Reward/pen_lin_vel_z: -0.0517
     Episode_Reward/pen_ang_vel_xy: -0.1644
   Episode_Reward/pen_joint_torque: -0.2094
    Episode_Reward/pen_joint_accel: -0.0943
    Episode_Reward/pen_action_rate: -0.1040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0476
   Episode_Reward/pen_joint_powers: -0.0755
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2329
Episode_Reward/pen_flat_orientation: -0.1273
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.3133
   Episode_Reward/foot_landing_vel: -0.1373
   Episode_Reward/test_gait_reward: -0.8672
Metrics/base_velocity/error_vel_xy: 1.7847
Metrics/base_velocity/error_vel_yaw: 1.1546
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 1.13s
                        Total time: 1016.90s
                               ETA: 2247.0s

################################################################################
                     [1m Learning iteration 935/3000 [0m                      

                       Computation: 90432 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 1.0259
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8881
                     Learning rate: 0.0006
                       Mean reward: 92.43
               Mean episode length: 936.80
       Episode_Reward/keep_balance: 0.9310
     Episode_Reward/rew_lin_vel_xy: 4.0790
      Episode_Reward/rew_ang_vel_z: 2.3837
    Episode_Reward/pen_base_height: -0.3238
      Episode_Reward/pen_lin_vel_z: -0.0494
     Episode_Reward/pen_ang_vel_xy: -0.1725
   Episode_Reward/pen_joint_torque: -0.2103
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1058
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0491
   Episode_Reward/pen_joint_powers: -0.0774
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2370
Episode_Reward/pen_flat_orientation: -0.1283
  Episode_Reward/pen_feet_distance: -0.0069
Episode_Reward/pen_feet_regulation: -0.3177
   Episode_Reward/foot_landing_vel: -0.1421
   Episode_Reward/test_gait_reward: -0.8744
Metrics/base_velocity/error_vel_xy: 1.8456
Metrics/base_velocity/error_vel_yaw: 1.1891
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 1.09s
                        Total time: 1017.99s
                               ETA: 2245.9s

################################################################################
                     [1m Learning iteration 936/3000 [0m                      

                       Computation: 91730 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 1.1047
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8889
                     Learning rate: 0.0009
                       Mean reward: 94.55
               Mean episode length: 958.14
       Episode_Reward/keep_balance: 0.9586
     Episode_Reward/rew_lin_vel_xy: 4.1969
      Episode_Reward/rew_ang_vel_z: 2.4041
    Episode_Reward/pen_base_height: -0.3215
      Episode_Reward/pen_lin_vel_z: -0.0496
     Episode_Reward/pen_ang_vel_xy: -0.1798
   Episode_Reward/pen_joint_torque: -0.2129
    Episode_Reward/pen_joint_accel: -0.1104
    Episode_Reward/pen_action_rate: -0.1115
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0523
   Episode_Reward/pen_joint_powers: -0.0802
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2511
Episode_Reward/pen_flat_orientation: -0.1330
  Episode_Reward/pen_feet_distance: -0.0038
Episode_Reward/pen_feet_regulation: -0.3480
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.9032
Metrics/base_velocity/error_vel_xy: 1.9446
Metrics/base_velocity/error_vel_yaw: 1.2717
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 1.07s
                        Total time: 1019.06s
                               ETA: 2244.8s

################################################################################
                     [1m Learning iteration 937/3000 [0m                      

                       Computation: 90957 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 1.0904
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8880
                     Learning rate: 0.0004
                       Mean reward: 91.72
               Mean episode length: 919.75
       Episode_Reward/keep_balance: 0.9366
     Episode_Reward/rew_lin_vel_xy: 4.2971
      Episode_Reward/rew_ang_vel_z: 2.3491
    Episode_Reward/pen_base_height: -0.3137
      Episode_Reward/pen_lin_vel_z: -0.0464
     Episode_Reward/pen_ang_vel_xy: -0.1713
   Episode_Reward/pen_joint_torque: -0.2031
    Episode_Reward/pen_joint_accel: -0.1021
    Episode_Reward/pen_action_rate: -0.1071
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0484
   Episode_Reward/pen_joint_powers: -0.0759
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2414
Episode_Reward/pen_flat_orientation: -0.1293
  Episode_Reward/pen_feet_distance: -0.0069
Episode_Reward/pen_feet_regulation: -0.3128
   Episode_Reward/foot_landing_vel: -0.1354
   Episode_Reward/test_gait_reward: -0.8767
Metrics/base_velocity/error_vel_xy: 1.7489
Metrics/base_velocity/error_vel_yaw: 1.2413
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 1.08s
                        Total time: 1020.14s
                               ETA: 2243.7s

################################################################################
                     [1m Learning iteration 938/3000 [0m                      

                       Computation: 92888 steps/s (collection: 0.937s, learning 0.121s)
               Value function loss: 1.0846
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8885
                     Learning rate: 0.0009
                       Mean reward: 96.94
               Mean episode length: 950.29
       Episode_Reward/keep_balance: 0.9436
     Episode_Reward/rew_lin_vel_xy: 4.2710
      Episode_Reward/rew_ang_vel_z: 2.3991
    Episode_Reward/pen_base_height: -0.3188
      Episode_Reward/pen_lin_vel_z: -0.0487
     Episode_Reward/pen_ang_vel_xy: -0.1689
   Episode_Reward/pen_joint_torque: -0.2132
    Episode_Reward/pen_joint_accel: -0.1048
    Episode_Reward/pen_action_rate: -0.1073
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0497
   Episode_Reward/pen_joint_powers: -0.0787
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2397
Episode_Reward/pen_flat_orientation: -0.1310
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3157
   Episode_Reward/foot_landing_vel: -0.1428
   Episode_Reward/test_gait_reward: -0.8892
Metrics/base_velocity/error_vel_xy: 1.8599
Metrics/base_velocity/error_vel_yaw: 1.2227
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 1.06s
                        Total time: 1021.20s
                               ETA: 2242.5s

################################################################################
                     [1m Learning iteration 939/3000 [0m                      

                       Computation: 91793 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 1.0107
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8885
                     Learning rate: 0.0009
                       Mean reward: 96.75
               Mean episode length: 956.55
       Episode_Reward/keep_balance: 0.9651
     Episode_Reward/rew_lin_vel_xy: 4.3017
      Episode_Reward/rew_ang_vel_z: 2.4094
    Episode_Reward/pen_base_height: -0.3285
      Episode_Reward/pen_lin_vel_z: -0.0470
     Episode_Reward/pen_ang_vel_xy: -0.1782
   Episode_Reward/pen_joint_torque: -0.2090
    Episode_Reward/pen_joint_accel: -0.0969
    Episode_Reward/pen_action_rate: -0.1116
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0501
   Episode_Reward/pen_joint_powers: -0.0786
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2520
Episode_Reward/pen_flat_orientation: -0.1274
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3263
   Episode_Reward/foot_landing_vel: -0.1406
   Episode_Reward/test_gait_reward: -0.9112
Metrics/base_velocity/error_vel_xy: 1.8597
Metrics/base_velocity/error_vel_yaw: 1.2843
      Episode_Termination/time_out: 3.0000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 1.07s
                        Total time: 1022.27s
                               ETA: 2241.4s

################################################################################
                     [1m Learning iteration 940/3000 [0m                      

                       Computation: 89465 steps/s (collection: 0.978s, learning 0.121s)
               Value function loss: 0.9585
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8870
                     Learning rate: 0.0009
                       Mean reward: 97.69
               Mean episode length: 973.17
       Episode_Reward/keep_balance: 0.9737
     Episode_Reward/rew_lin_vel_xy: 4.3491
      Episode_Reward/rew_ang_vel_z: 2.4701
    Episode_Reward/pen_base_height: -0.3265
      Episode_Reward/pen_lin_vel_z: -0.0506
     Episode_Reward/pen_ang_vel_xy: -0.1766
   Episode_Reward/pen_joint_torque: -0.2158
    Episode_Reward/pen_joint_accel: -0.1114
    Episode_Reward/pen_action_rate: -0.1113
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0506
   Episode_Reward/pen_joint_powers: -0.0790
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2495
Episode_Reward/pen_flat_orientation: -0.1303
  Episode_Reward/pen_feet_distance: -0.0082
Episode_Reward/pen_feet_regulation: -0.3325
   Episode_Reward/foot_landing_vel: -0.1409
   Episode_Reward/test_gait_reward: -0.9114
Metrics/base_velocity/error_vel_xy: 1.9457
Metrics/base_velocity/error_vel_yaw: 1.2643
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 1.10s
                        Total time: 1023.37s
                               ETA: 2240.3s

################################################################################
                     [1m Learning iteration 941/3000 [0m                      

                       Computation: 90679 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 1.0708
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8876
                     Learning rate: 0.0013
                       Mean reward: 103.99
               Mean episode length: 978.20
       Episode_Reward/keep_balance: 0.9824
     Episode_Reward/rew_lin_vel_xy: 4.5338
      Episode_Reward/rew_ang_vel_z: 2.5204
    Episode_Reward/pen_base_height: -0.3274
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.1773
   Episode_Reward/pen_joint_torque: -0.2096
    Episode_Reward/pen_joint_accel: -0.1058
    Episode_Reward/pen_action_rate: -0.1117
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0498
   Episode_Reward/pen_joint_powers: -0.0780
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2506
Episode_Reward/pen_flat_orientation: -0.1246
  Episode_Reward/pen_feet_distance: -0.0079
Episode_Reward/pen_feet_regulation: -0.3258
   Episode_Reward/foot_landing_vel: -0.1400
   Episode_Reward/test_gait_reward: -0.9249
Metrics/base_velocity/error_vel_xy: 1.7771
Metrics/base_velocity/error_vel_yaw: 1.2438
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 1.08s
                        Total time: 1024.45s
                               ETA: 2239.2s

################################################################################
                     [1m Learning iteration 942/3000 [0m                      

                       Computation: 91760 steps/s (collection: 0.944s, learning 0.128s)
               Value function loss: 1.1317
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8885
                     Learning rate: 0.0004
                       Mean reward: 101.27
               Mean episode length: 952.24
       Episode_Reward/keep_balance: 0.9557
     Episode_Reward/rew_lin_vel_xy: 4.4702
      Episode_Reward/rew_ang_vel_z: 2.4564
    Episode_Reward/pen_base_height: -0.3167
      Episode_Reward/pen_lin_vel_z: -0.0486
     Episode_Reward/pen_ang_vel_xy: -0.1716
   Episode_Reward/pen_joint_torque: -0.2097
    Episode_Reward/pen_joint_accel: -0.1135
    Episode_Reward/pen_action_rate: -0.1074
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0481
   Episode_Reward/pen_joint_powers: -0.0762
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2432
Episode_Reward/pen_flat_orientation: -0.1224
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.3042
   Episode_Reward/foot_landing_vel: -0.1370
   Episode_Reward/test_gait_reward: -0.8935
Metrics/base_velocity/error_vel_xy: 1.7817
Metrics/base_velocity/error_vel_yaw: 1.2105
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 1.07s
                        Total time: 1025.52s
                               ETA: 2238.1s

################################################################################
                     [1m Learning iteration 943/3000 [0m                      

                       Computation: 90656 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 1.0256
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8890
                     Learning rate: 0.0009
                       Mean reward: 99.45
               Mean episode length: 960.43
       Episode_Reward/keep_balance: 0.9572
     Episode_Reward/rew_lin_vel_xy: 4.3720
      Episode_Reward/rew_ang_vel_z: 2.4401
    Episode_Reward/pen_base_height: -0.3392
      Episode_Reward/pen_lin_vel_z: -0.0497
     Episode_Reward/pen_ang_vel_xy: -0.1749
   Episode_Reward/pen_joint_torque: -0.2117
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1101
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0501
   Episode_Reward/pen_joint_powers: -0.0787
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2461
Episode_Reward/pen_flat_orientation: -0.1301
  Episode_Reward/pen_feet_distance: -0.0086
Episode_Reward/pen_feet_regulation: -0.3289
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.9040
Metrics/base_velocity/error_vel_xy: 1.7846
Metrics/base_velocity/error_vel_yaw: 1.2289
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 1.08s
                        Total time: 1026.61s
                               ETA: 2237.0s

################################################################################
                     [1m Learning iteration 944/3000 [0m                      

                       Computation: 92199 steps/s (collection: 0.943s, learning 0.124s)
               Value function loss: 0.9544
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8882
                     Learning rate: 0.0009
                       Mean reward: 101.25
               Mean episode length: 981.33
       Episode_Reward/keep_balance: 0.9822
     Episode_Reward/rew_lin_vel_xy: 4.5130
      Episode_Reward/rew_ang_vel_z: 2.5095
    Episode_Reward/pen_base_height: -0.3248
      Episode_Reward/pen_lin_vel_z: -0.0497
     Episode_Reward/pen_ang_vel_xy: -0.1835
   Episode_Reward/pen_joint_torque: -0.2124
    Episode_Reward/pen_joint_accel: -0.1001
    Episode_Reward/pen_action_rate: -0.1133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0498
   Episode_Reward/pen_joint_powers: -0.0779
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2531
Episode_Reward/pen_flat_orientation: -0.1212
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.3204
   Episode_Reward/foot_landing_vel: -0.1395
   Episode_Reward/test_gait_reward: -0.9220
Metrics/base_velocity/error_vel_xy: 1.9317
Metrics/base_velocity/error_vel_yaw: 1.2602
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 1.07s
                        Total time: 1027.67s
                               ETA: 2235.9s

################################################################################
                     [1m Learning iteration 945/3000 [0m                      

                       Computation: 91581 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.1632
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8878
                     Learning rate: 0.0009
                       Mean reward: 96.64
               Mean episode length: 961.35
       Episode_Reward/keep_balance: 0.9589
     Episode_Reward/rew_lin_vel_xy: 4.3418
      Episode_Reward/rew_ang_vel_z: 2.4439
    Episode_Reward/pen_base_height: -0.3465
      Episode_Reward/pen_lin_vel_z: -0.0538
     Episode_Reward/pen_ang_vel_xy: -0.1802
   Episode_Reward/pen_joint_torque: -0.2143
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1117
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0519
   Episode_Reward/pen_joint_powers: -0.0803
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2475
Episode_Reward/pen_flat_orientation: -0.1355
  Episode_Reward/pen_feet_distance: -0.0052
Episode_Reward/pen_feet_regulation: -0.3446
   Episode_Reward/foot_landing_vel: -0.1463
   Episode_Reward/test_gait_reward: -0.9056
Metrics/base_velocity/error_vel_xy: 1.8328
Metrics/base_velocity/error_vel_yaw: 1.2405
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 1.07s
                        Total time: 1028.75s
                               ETA: 2234.7s

################################################################################
                     [1m Learning iteration 946/3000 [0m                      

                       Computation: 90552 steps/s (collection: 0.964s, learning 0.121s)
               Value function loss: 1.0488
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8874
                     Learning rate: 0.0009
                       Mean reward: 92.82
               Mean episode length: 938.18
       Episode_Reward/keep_balance: 0.9378
     Episode_Reward/rew_lin_vel_xy: 4.0779
      Episode_Reward/rew_ang_vel_z: 2.4092
    Episode_Reward/pen_base_height: -0.3187
      Episode_Reward/pen_lin_vel_z: -0.0512
     Episode_Reward/pen_ang_vel_xy: -0.1750
   Episode_Reward/pen_joint_torque: -0.2146
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1073
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0490
   Episode_Reward/pen_joint_powers: -0.0779
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2398
Episode_Reward/pen_flat_orientation: -0.1232
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3193
   Episode_Reward/foot_landing_vel: -0.1439
   Episode_Reward/test_gait_reward: -0.8715
Metrics/base_velocity/error_vel_xy: 2.0034
Metrics/base_velocity/error_vel_yaw: 1.1877
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 1.09s
                        Total time: 1029.83s
                               ETA: 2233.7s

################################################################################
                     [1m Learning iteration 947/3000 [0m                      

                       Computation: 91704 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 1.0432
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8893
                     Learning rate: 0.0009
                       Mean reward: 97.90
               Mean episode length: 949.45
       Episode_Reward/keep_balance: 0.9546
     Episode_Reward/rew_lin_vel_xy: 4.4655
      Episode_Reward/rew_ang_vel_z: 2.4003
    Episode_Reward/pen_base_height: -0.3272
      Episode_Reward/pen_lin_vel_z: -0.0493
     Episode_Reward/pen_ang_vel_xy: -0.1757
   Episode_Reward/pen_joint_torque: -0.2055
    Episode_Reward/pen_joint_accel: -0.1044
    Episode_Reward/pen_action_rate: -0.1097
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0500
   Episode_Reward/pen_joint_powers: -0.0775
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2484
Episode_Reward/pen_flat_orientation: -0.1297
  Episode_Reward/pen_feet_distance: -0.0051
Episode_Reward/pen_feet_regulation: -0.3238
   Episode_Reward/foot_landing_vel: -0.1478
   Episode_Reward/test_gait_reward: -0.8975
Metrics/base_velocity/error_vel_xy: 1.7272
Metrics/base_velocity/error_vel_yaw: 1.2669
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 1.07s
                        Total time: 1030.90s
                               ETA: 2232.5s

################################################################################
                     [1m Learning iteration 948/3000 [0m                      

                       Computation: 91264 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.9925
                    Surrogate loss: -0.0007
             Mean action noise std: 0.8921
                     Learning rate: 0.0004
                       Mean reward: 104.14
               Mean episode length: 983.12
       Episode_Reward/keep_balance: 0.9840
     Episode_Reward/rew_lin_vel_xy: 4.6223
      Episode_Reward/rew_ang_vel_z: 2.5221
    Episode_Reward/pen_base_height: -0.3186
      Episode_Reward/pen_lin_vel_z: -0.0511
     Episode_Reward/pen_ang_vel_xy: -0.1759
   Episode_Reward/pen_joint_torque: -0.2186
    Episode_Reward/pen_joint_accel: -0.1092
    Episode_Reward/pen_action_rate: -0.1123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0502
   Episode_Reward/pen_joint_powers: -0.0791
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2531
Episode_Reward/pen_flat_orientation: -0.1231
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3187
   Episode_Reward/foot_landing_vel: -0.1431
   Episode_Reward/test_gait_reward: -0.9244
Metrics/base_velocity/error_vel_xy: 1.8301
Metrics/base_velocity/error_vel_yaw: 1.2465
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 1.08s
                        Total time: 1031.98s
                               ETA: 2231.4s

################################################################################
                     [1m Learning iteration 949/3000 [0m                      

                       Computation: 91261 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.9912
                    Surrogate loss: -0.0056
             Mean action noise std: 0.8918
                     Learning rate: 0.0006
                       Mean reward: 100.25
               Mean episode length: 983.21
       Episode_Reward/keep_balance: 0.9814
     Episode_Reward/rew_lin_vel_xy: 4.5052
      Episode_Reward/rew_ang_vel_z: 2.4913
    Episode_Reward/pen_base_height: -0.3397
      Episode_Reward/pen_lin_vel_z: -0.0523
     Episode_Reward/pen_ang_vel_xy: -0.1769
   Episode_Reward/pen_joint_torque: -0.2240
    Episode_Reward/pen_joint_accel: -0.1090
    Episode_Reward/pen_action_rate: -0.1129
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0518
   Episode_Reward/pen_joint_powers: -0.0815
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2507
Episode_Reward/pen_flat_orientation: -0.1337
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3437
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.9282
Metrics/base_velocity/error_vel_xy: 1.9109
Metrics/base_velocity/error_vel_yaw: 1.2710
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 1.08s
                        Total time: 1033.06s
                               ETA: 2230.3s

################################################################################
                     [1m Learning iteration 950/3000 [0m                      

                       Computation: 91691 steps/s (collection: 0.951s, learning 0.121s)
               Value function loss: 0.9284
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8901
                     Learning rate: 0.0013
                       Mean reward: 105.18
               Mean episode length: 974.66
       Episode_Reward/keep_balance: 0.9812
     Episode_Reward/rew_lin_vel_xy: 4.7657
      Episode_Reward/rew_ang_vel_z: 2.5468
    Episode_Reward/pen_base_height: -0.3213
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1704
   Episode_Reward/pen_joint_torque: -0.2262
    Episode_Reward/pen_joint_accel: -0.1136
    Episode_Reward/pen_action_rate: -0.1103
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0507
   Episode_Reward/pen_joint_powers: -0.0807
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2475
Episode_Reward/pen_flat_orientation: -0.1239
  Episode_Reward/pen_feet_distance: -0.0050
Episode_Reward/pen_feet_regulation: -0.3283
   Episode_Reward/foot_landing_vel: -0.1531
   Episode_Reward/test_gait_reward: -0.9121
Metrics/base_velocity/error_vel_xy: 1.7509
Metrics/base_velocity/error_vel_yaw: 1.2185
      Episode_Termination/time_out: 3.2500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 1.07s
                        Total time: 1034.13s
                               ETA: 2229.2s

################################################################################
                     [1m Learning iteration 951/3000 [0m                      

                       Computation: 92023 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.9423
                    Surrogate loss: 0.0011
             Mean action noise std: 0.8913
                     Learning rate: 0.0004
                       Mean reward: 104.08
               Mean episode length: 981.83
       Episode_Reward/keep_balance: 0.9877
     Episode_Reward/rew_lin_vel_xy: 4.5619
      Episode_Reward/rew_ang_vel_z: 2.5399
    Episode_Reward/pen_base_height: -0.3254
      Episode_Reward/pen_lin_vel_z: -0.0508
     Episode_Reward/pen_ang_vel_xy: -0.1766
   Episode_Reward/pen_joint_torque: -0.2142
    Episode_Reward/pen_joint_accel: -0.1158
    Episode_Reward/pen_action_rate: -0.1117
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0504
   Episode_Reward/pen_joint_powers: -0.0786
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2533
Episode_Reward/pen_flat_orientation: -0.1278
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3192
   Episode_Reward/foot_landing_vel: -0.1480
   Episode_Reward/test_gait_reward: -0.9223
Metrics/base_velocity/error_vel_xy: 1.9011
Metrics/base_velocity/error_vel_yaw: 1.2484
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 1.07s
                        Total time: 1035.20s
                               ETA: 2228.1s

################################################################################
                     [1m Learning iteration 952/3000 [0m                      

                       Computation: 90115 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 1.0824
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8919
                     Learning rate: 0.0009
                       Mean reward: 101.82
               Mean episode length: 981.26
       Episode_Reward/keep_balance: 0.9712
     Episode_Reward/rew_lin_vel_xy: 4.5281
      Episode_Reward/rew_ang_vel_z: 2.4271
    Episode_Reward/pen_base_height: -0.3326
      Episode_Reward/pen_lin_vel_z: -0.0520
     Episode_Reward/pen_ang_vel_xy: -0.1742
   Episode_Reward/pen_joint_torque: -0.2133
    Episode_Reward/pen_joint_accel: -0.1174
    Episode_Reward/pen_action_rate: -0.1120
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0505
   Episode_Reward/pen_joint_powers: -0.0790
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2533
Episode_Reward/pen_flat_orientation: -0.1278
  Episode_Reward/pen_feet_distance: -0.0058
Episode_Reward/pen_feet_regulation: -0.3402
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.9142
Metrics/base_velocity/error_vel_xy: 1.8185
Metrics/base_velocity/error_vel_yaw: 1.2941
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 1.09s
                        Total time: 1036.29s
                               ETA: 2227.0s

################################################################################
                     [1m Learning iteration 953/3000 [0m                      

                       Computation: 90590 steps/s (collection: 0.964s, learning 0.121s)
               Value function loss: 1.1208
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8923
                     Learning rate: 0.0006
                       Mean reward: 96.95
               Mean episode length: 948.14
       Episode_Reward/keep_balance: 0.9548
     Episode_Reward/rew_lin_vel_xy: 4.3482
      Episode_Reward/rew_ang_vel_z: 2.4452
    Episode_Reward/pen_base_height: -0.3455
      Episode_Reward/pen_lin_vel_z: -0.0522
     Episode_Reward/pen_ang_vel_xy: -0.1744
   Episode_Reward/pen_joint_torque: -0.2189
    Episode_Reward/pen_joint_accel: -0.1187
    Episode_Reward/pen_action_rate: -0.1095
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0509
   Episode_Reward/pen_joint_powers: -0.0796
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2440
Episode_Reward/pen_flat_orientation: -0.1337
  Episode_Reward/pen_feet_distance: -0.0066
Episode_Reward/pen_feet_regulation: -0.3383
   Episode_Reward/foot_landing_vel: -0.1517
   Episode_Reward/test_gait_reward: -0.8950
Metrics/base_velocity/error_vel_xy: 1.8481
Metrics/base_velocity/error_vel_yaw: 1.2225
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 1.09s
                        Total time: 1037.37s
                               ETA: 2225.9s

################################################################################
                     [1m Learning iteration 954/3000 [0m                      

                       Computation: 90483 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 1.0512
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8936
                     Learning rate: 0.0006
                       Mean reward: 94.93
               Mean episode length: 908.95
       Episode_Reward/keep_balance: 0.9111
     Episode_Reward/rew_lin_vel_xy: 4.3260
      Episode_Reward/rew_ang_vel_z: 2.2926
    Episode_Reward/pen_base_height: -0.3238
      Episode_Reward/pen_lin_vel_z: -0.0525
     Episode_Reward/pen_ang_vel_xy: -0.1693
   Episode_Reward/pen_joint_torque: -0.2088
    Episode_Reward/pen_joint_accel: -0.1010
    Episode_Reward/pen_action_rate: -0.1059
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0500
   Episode_Reward/pen_joint_powers: -0.0779
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2370
Episode_Reward/pen_flat_orientation: -0.1315
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3260
   Episode_Reward/foot_landing_vel: -0.1445
   Episode_Reward/test_gait_reward: -0.8637
Metrics/base_velocity/error_vel_xy: 1.6484
Metrics/base_velocity/error_vel_yaw: 1.2024
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 1.09s
                        Total time: 1038.46s
                               ETA: 2224.8s

################################################################################
                     [1m Learning iteration 955/3000 [0m                      

                       Computation: 91646 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 1.0661
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8932
                     Learning rate: 0.0004
                       Mean reward: 98.06
               Mean episode length: 956.99
       Episode_Reward/keep_balance: 0.9453
     Episode_Reward/rew_lin_vel_xy: 4.2767
      Episode_Reward/rew_ang_vel_z: 2.4283
    Episode_Reward/pen_base_height: -0.3303
      Episode_Reward/pen_lin_vel_z: -0.0508
     Episode_Reward/pen_ang_vel_xy: -0.1716
   Episode_Reward/pen_joint_torque: -0.2129
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1072
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0488
   Episode_Reward/pen_joint_powers: -0.0773
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2417
Episode_Reward/pen_flat_orientation: -0.1306
  Episode_Reward/pen_feet_distance: -0.0052
Episode_Reward/pen_feet_regulation: -0.3140
   Episode_Reward/foot_landing_vel: -0.1402
   Episode_Reward/test_gait_reward: -0.8792
Metrics/base_velocity/error_vel_xy: 1.8817
Metrics/base_velocity/error_vel_yaw: 1.2074
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 1.07s
                        Total time: 1039.53s
                               ETA: 2223.7s

################################################################################
                     [1m Learning iteration 956/3000 [0m                      

                       Computation: 91643 steps/s (collection: 0.951s, learning 0.121s)
               Value function loss: 1.0303
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8926
                     Learning rate: 0.0009
                       Mean reward: 94.32
               Mean episode length: 940.80
       Episode_Reward/keep_balance: 0.9022
     Episode_Reward/rew_lin_vel_xy: 4.0051
      Episode_Reward/rew_ang_vel_z: 2.3058
    Episode_Reward/pen_base_height: -0.3249
      Episode_Reward/pen_lin_vel_z: -0.0533
     Episode_Reward/pen_ang_vel_xy: -0.1650
   Episode_Reward/pen_joint_torque: -0.2084
    Episode_Reward/pen_joint_accel: -0.1019
    Episode_Reward/pen_action_rate: -0.1032
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0485
   Episode_Reward/pen_joint_powers: -0.0759
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2300
Episode_Reward/pen_flat_orientation: -0.1273
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3246
   Episode_Reward/foot_landing_vel: -0.1463
   Episode_Reward/test_gait_reward: -0.8425
Metrics/base_velocity/error_vel_xy: 1.8677
Metrics/base_velocity/error_vel_yaw: 1.1543
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 1.07s
                        Total time: 1040.61s
                               ETA: 2222.6s

################################################################################
                     [1m Learning iteration 957/3000 [0m                      

                       Computation: 90344 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 1.0548
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8940
                     Learning rate: 0.0006
                       Mean reward: 97.73
               Mean episode length: 968.19
       Episode_Reward/keep_balance: 0.9410
     Episode_Reward/rew_lin_vel_xy: 4.2217
      Episode_Reward/rew_ang_vel_z: 2.3961
    Episode_Reward/pen_base_height: -0.3321
      Episode_Reward/pen_lin_vel_z: -0.0534
     Episode_Reward/pen_ang_vel_xy: -0.1802
   Episode_Reward/pen_joint_torque: -0.2183
    Episode_Reward/pen_joint_accel: -0.1147
    Episode_Reward/pen_action_rate: -0.1091
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0518
   Episode_Reward/pen_joint_powers: -0.0802
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2449
Episode_Reward/pen_flat_orientation: -0.1324
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.3350
   Episode_Reward/foot_landing_vel: -0.1499
   Episode_Reward/test_gait_reward: -0.8861
Metrics/base_velocity/error_vel_xy: 1.8550
Metrics/base_velocity/error_vel_yaw: 1.2267
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 1.09s
                        Total time: 1041.69s
                               ETA: 2221.5s

################################################################################
                     [1m Learning iteration 958/3000 [0m                      

                       Computation: 92888 steps/s (collection: 0.936s, learning 0.122s)
               Value function loss: 1.0145
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8962
                     Learning rate: 0.0009
                       Mean reward: 101.74
               Mean episode length: 952.70
       Episode_Reward/keep_balance: 0.9333
     Episode_Reward/rew_lin_vel_xy: 4.3853
      Episode_Reward/rew_ang_vel_z: 2.4068
    Episode_Reward/pen_base_height: -0.3342
      Episode_Reward/pen_lin_vel_z: -0.0511
     Episode_Reward/pen_ang_vel_xy: -0.1705
   Episode_Reward/pen_joint_torque: -0.2169
    Episode_Reward/pen_joint_accel: -0.1042
    Episode_Reward/pen_action_rate: -0.1056
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0486
   Episode_Reward/pen_joint_powers: -0.0776
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2356
Episode_Reward/pen_flat_orientation: -0.1269
  Episode_Reward/pen_feet_distance: -0.0089
Episode_Reward/pen_feet_regulation: -0.3188
   Episode_Reward/foot_landing_vel: -0.1358
   Episode_Reward/test_gait_reward: -0.8713
Metrics/base_velocity/error_vel_xy: 1.7841
Metrics/base_velocity/error_vel_yaw: 1.1759
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 1.06s
                        Total time: 1042.75s
                               ETA: 2220.3s

################################################################################
                     [1m Learning iteration 959/3000 [0m                      

                       Computation: 92896 steps/s (collection: 0.933s, learning 0.125s)
               Value function loss: 1.0304
                    Surrogate loss: 0.0007
             Mean action noise std: 0.8966
                     Learning rate: 0.0001
                       Mean reward: 102.78
               Mean episode length: 972.92
       Episode_Reward/keep_balance: 0.9587
     Episode_Reward/rew_lin_vel_xy: 4.4282
      Episode_Reward/rew_ang_vel_z: 2.4664
    Episode_Reward/pen_base_height: -0.3313
      Episode_Reward/pen_lin_vel_z: -0.0520
     Episode_Reward/pen_ang_vel_xy: -0.1758
   Episode_Reward/pen_joint_torque: -0.2158
    Episode_Reward/pen_joint_accel: -0.1004
    Episode_Reward/pen_action_rate: -0.1088
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0498
   Episode_Reward/pen_joint_powers: -0.0785
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2444
Episode_Reward/pen_flat_orientation: -0.1244
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3291
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.8958
Metrics/base_velocity/error_vel_xy: 1.8594
Metrics/base_velocity/error_vel_yaw: 1.2045
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 1.06s
                        Total time: 1043.81s
                               ETA: 2219.2s

################################################################################
                     [1m Learning iteration 960/3000 [0m                      

                       Computation: 90730 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 1.1070
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8974
                     Learning rate: 0.0002
                       Mean reward: 104.76
               Mean episode length: 967.44
       Episode_Reward/keep_balance: 0.9795
     Episode_Reward/rew_lin_vel_xy: 4.8526
      Episode_Reward/rew_ang_vel_z: 2.4338
    Episode_Reward/pen_base_height: -0.3304
      Episode_Reward/pen_lin_vel_z: -0.0489
     Episode_Reward/pen_ang_vel_xy: -0.1766
   Episode_Reward/pen_joint_torque: -0.2219
    Episode_Reward/pen_joint_accel: -0.1215
    Episode_Reward/pen_action_rate: -0.1138
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0512
   Episode_Reward/pen_joint_powers: -0.0802
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2572
Episode_Reward/pen_flat_orientation: -0.1260
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3249
   Episode_Reward/foot_landing_vel: -0.1450
   Episode_Reward/test_gait_reward: -0.9205
Metrics/base_velocity/error_vel_xy: 1.6315
Metrics/base_velocity/error_vel_yaw: 1.3248
      Episode_Termination/time_out: 2.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 1.08s
                        Total time: 1044.89s
                               ETA: 2218.1s

################################################################################
                     [1m Learning iteration 961/3000 [0m                      

                       Computation: 90742 steps/s (collection: 0.962s, learning 0.121s)
               Value function loss: 0.9500
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8976
                     Learning rate: 0.0004
                       Mean reward: 100.02
               Mean episode length: 963.47
       Episode_Reward/keep_balance: 0.9532
     Episode_Reward/rew_lin_vel_xy: 4.2806
      Episode_Reward/rew_ang_vel_z: 2.4394
    Episode_Reward/pen_base_height: -0.3312
      Episode_Reward/pen_lin_vel_z: -0.0518
     Episode_Reward/pen_ang_vel_xy: -0.1753
   Episode_Reward/pen_joint_torque: -0.2145
    Episode_Reward/pen_joint_accel: -0.1022
    Episode_Reward/pen_action_rate: -0.1085
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0504
   Episode_Reward/pen_joint_powers: -0.0783
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2432
Episode_Reward/pen_flat_orientation: -0.1275
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.3278
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.8904
Metrics/base_velocity/error_vel_xy: 1.9279
Metrics/base_velocity/error_vel_yaw: 1.2157
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 1.08s
                        Total time: 1045.98s
                               ETA: 2217.0s

################################################################################
                     [1m Learning iteration 962/3000 [0m                      

                       Computation: 91491 steps/s (collection: 0.951s, learning 0.124s)
               Value function loss: 0.9904
                    Surrogate loss: -0.0016
             Mean action noise std: 0.8960
                     Learning rate: 0.0006
                       Mean reward: 96.44
               Mean episode length: 953.81
       Episode_Reward/keep_balance: 0.9509
     Episode_Reward/rew_lin_vel_xy: 4.2502
      Episode_Reward/rew_ang_vel_z: 2.4094
    Episode_Reward/pen_base_height: -0.3267
      Episode_Reward/pen_lin_vel_z: -0.0507
     Episode_Reward/pen_ang_vel_xy: -0.1748
   Episode_Reward/pen_joint_torque: -0.2136
    Episode_Reward/pen_joint_accel: -0.1008
    Episode_Reward/pen_action_rate: -0.1079
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0484
   Episode_Reward/pen_joint_powers: -0.0773
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2426
Episode_Reward/pen_flat_orientation: -0.1274
  Episode_Reward/pen_feet_distance: -0.0113
Episode_Reward/pen_feet_regulation: -0.3126
   Episode_Reward/foot_landing_vel: -0.1346
   Episode_Reward/test_gait_reward: -0.8830
Metrics/base_velocity/error_vel_xy: 1.9463
Metrics/base_velocity/error_vel_yaw: 1.2344
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 1.07s
                        Total time: 1047.05s
                               ETA: 2215.9s

################################################################################
                     [1m Learning iteration 963/3000 [0m                      

                       Computation: 91389 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.9803
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8958
                     Learning rate: 0.0003
                       Mean reward: 102.72
               Mean episode length: 980.59
       Episode_Reward/keep_balance: 0.9733
     Episode_Reward/rew_lin_vel_xy: 4.5179
      Episode_Reward/rew_ang_vel_z: 2.4892
    Episode_Reward/pen_base_height: -0.3484
      Episode_Reward/pen_lin_vel_z: -0.0531
     Episode_Reward/pen_ang_vel_xy: -0.1758
   Episode_Reward/pen_joint_torque: -0.2218
    Episode_Reward/pen_joint_accel: -0.1088
    Episode_Reward/pen_action_rate: -0.1105
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0506
   Episode_Reward/pen_joint_powers: -0.0802
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2481
Episode_Reward/pen_flat_orientation: -0.1261
  Episode_Reward/pen_feet_distance: -0.0075
Episode_Reward/pen_feet_regulation: -0.3364
   Episode_Reward/foot_landing_vel: -0.1458
   Episode_Reward/test_gait_reward: -0.9099
Metrics/base_velocity/error_vel_xy: 1.8031
Metrics/base_velocity/error_vel_yaw: 1.2436
      Episode_Termination/time_out: 5.2500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 1.08s
                        Total time: 1048.13s
                               ETA: 2214.8s

################################################################################
                     [1m Learning iteration 964/3000 [0m                      

                       Computation: 89333 steps/s (collection: 0.975s, learning 0.125s)
               Value function loss: 1.0196
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8965
                     Learning rate: 0.0006
                       Mean reward: 100.38
               Mean episode length: 949.48
       Episode_Reward/keep_balance: 0.9477
     Episode_Reward/rew_lin_vel_xy: 4.4671
      Episode_Reward/rew_ang_vel_z: 2.4328
    Episode_Reward/pen_base_height: -0.3341
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.1725
   Episode_Reward/pen_joint_torque: -0.2122
    Episode_Reward/pen_joint_accel: -0.1113
    Episode_Reward/pen_action_rate: -0.1073
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0508
   Episode_Reward/pen_joint_powers: -0.0784
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2412
Episode_Reward/pen_flat_orientation: -0.1255
  Episode_Reward/pen_feet_distance: -0.0057
Episode_Reward/pen_feet_regulation: -0.3449
   Episode_Reward/foot_landing_vel: -0.1509
   Episode_Reward/test_gait_reward: -0.8875
Metrics/base_velocity/error_vel_xy: 1.8331
Metrics/base_velocity/error_vel_yaw: 1.1968
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 1.10s
                        Total time: 1049.23s
                               ETA: 2213.7s

################################################################################
                     [1m Learning iteration 965/3000 [0m                      

                       Computation: 89682 steps/s (collection: 0.972s, learning 0.125s)
               Value function loss: 1.0562
                    Surrogate loss: -0.0006
             Mean action noise std: 0.8964
                     Learning rate: 0.0002
                       Mean reward: 95.91
               Mean episode length: 947.66
       Episode_Reward/keep_balance: 0.9390
     Episode_Reward/rew_lin_vel_xy: 4.2612
      Episode_Reward/rew_ang_vel_z: 2.3814
    Episode_Reward/pen_base_height: -0.3355
      Episode_Reward/pen_lin_vel_z: -0.0548
     Episode_Reward/pen_ang_vel_xy: -0.1747
   Episode_Reward/pen_joint_torque: -0.2218
    Episode_Reward/pen_joint_accel: -0.1082
    Episode_Reward/pen_action_rate: -0.1089
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0511
   Episode_Reward/pen_joint_powers: -0.0800
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2426
Episode_Reward/pen_flat_orientation: -0.1265
  Episode_Reward/pen_feet_distance: -0.0052
Episode_Reward/pen_feet_regulation: -0.3488
   Episode_Reward/foot_landing_vel: -0.1494
   Episode_Reward/test_gait_reward: -0.8790
Metrics/base_velocity/error_vel_xy: 1.8160
Metrics/base_velocity/error_vel_yaw: 1.2162
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 1.10s
                        Total time: 1050.32s
                               ETA: 2212.6s

################################################################################
                     [1m Learning iteration 966/3000 [0m                      

                       Computation: 90320 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 1.0107
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8957
                     Learning rate: 0.0004
                       Mean reward: 94.76
               Mean episode length: 946.29
       Episode_Reward/keep_balance: 0.9350
     Episode_Reward/rew_lin_vel_xy: 4.2841
      Episode_Reward/rew_ang_vel_z: 2.3532
    Episode_Reward/pen_base_height: -0.3269
      Episode_Reward/pen_lin_vel_z: -0.0527
     Episode_Reward/pen_ang_vel_xy: -0.1769
   Episode_Reward/pen_joint_torque: -0.2128
    Episode_Reward/pen_joint_accel: -0.1131
    Episode_Reward/pen_action_rate: -0.1080
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0515
   Episode_Reward/pen_joint_powers: -0.0793
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2418
Episode_Reward/pen_flat_orientation: -0.1365
  Episode_Reward/pen_feet_distance: -0.0108
Episode_Reward/pen_feet_regulation: -0.3332
   Episode_Reward/foot_landing_vel: -0.1532
   Episode_Reward/test_gait_reward: -0.8712
Metrics/base_velocity/error_vel_xy: 1.8165
Metrics/base_velocity/error_vel_yaw: 1.2420
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 1.09s
                        Total time: 1051.41s
                               ETA: 2211.6s

################################################################################
                     [1m Learning iteration 967/3000 [0m                      

                       Computation: 90792 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.9771
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8995
                     Learning rate: 0.0009
                       Mean reward: 93.34
               Mean episode length: 937.65
       Episode_Reward/keep_balance: 0.9423
     Episode_Reward/rew_lin_vel_xy: 4.2622
      Episode_Reward/rew_ang_vel_z: 2.3792
    Episode_Reward/pen_base_height: -0.3327
      Episode_Reward/pen_lin_vel_z: -0.0514
     Episode_Reward/pen_ang_vel_xy: -0.1750
   Episode_Reward/pen_joint_torque: -0.2146
    Episode_Reward/pen_joint_accel: -0.1072
    Episode_Reward/pen_action_rate: -0.1085
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0503
   Episode_Reward/pen_joint_powers: -0.0791
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2421
Episode_Reward/pen_flat_orientation: -0.1257
  Episode_Reward/pen_feet_distance: -0.0085
Episode_Reward/pen_feet_regulation: -0.3287
   Episode_Reward/foot_landing_vel: -0.1413
   Episode_Reward/test_gait_reward: -0.8797
Metrics/base_velocity/error_vel_xy: 1.8328
Metrics/base_velocity/error_vel_yaw: 1.2368
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 1.08s
                        Total time: 1052.49s
                               ETA: 2210.5s

################################################################################
                     [1m Learning iteration 968/3000 [0m                      

                       Computation: 91575 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 1.0273
                    Surrogate loss: -0.0026
             Mean action noise std: 0.9002
                     Learning rate: 0.0009
                       Mean reward: 103.21
               Mean episode length: 980.88
       Episode_Reward/keep_balance: 0.9763
     Episode_Reward/rew_lin_vel_xy: 4.6319
      Episode_Reward/rew_ang_vel_z: 2.5163
    Episode_Reward/pen_base_height: -0.3323
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.1777
   Episode_Reward/pen_joint_torque: -0.2197
    Episode_Reward/pen_joint_accel: -0.1026
    Episode_Reward/pen_action_rate: -0.1087
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0503
   Episode_Reward/pen_joint_powers: -0.0802
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2446
Episode_Reward/pen_flat_orientation: -0.1224
  Episode_Reward/pen_feet_distance: -0.0087
Episode_Reward/pen_feet_regulation: -0.3312
   Episode_Reward/foot_landing_vel: -0.1462
   Episode_Reward/test_gait_reward: -0.9091
Metrics/base_velocity/error_vel_xy: 1.7890
Metrics/base_velocity/error_vel_yaw: 1.2210
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 1.07s
                        Total time: 1053.57s
                               ETA: 2209.3s

################################################################################
                     [1m Learning iteration 969/3000 [0m                      

                       Computation: 90961 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.9444
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8995
                     Learning rate: 0.0009
                       Mean reward: 95.66
               Mean episode length: 942.58
       Episode_Reward/keep_balance: 0.9614
     Episode_Reward/rew_lin_vel_xy: 4.4529
      Episode_Reward/rew_ang_vel_z: 2.4486
    Episode_Reward/pen_base_height: -0.3300
      Episode_Reward/pen_lin_vel_z: -0.0515
     Episode_Reward/pen_ang_vel_xy: -0.1737
   Episode_Reward/pen_joint_torque: -0.2183
    Episode_Reward/pen_joint_accel: -0.1014
    Episode_Reward/pen_action_rate: -0.1094
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0501
   Episode_Reward/pen_joint_powers: -0.0789
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2467
Episode_Reward/pen_flat_orientation: -0.1290
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3329
   Episode_Reward/foot_landing_vel: -0.1462
   Episode_Reward/test_gait_reward: -0.9018
Metrics/base_velocity/error_vel_xy: 1.8095
Metrics/base_velocity/error_vel_yaw: 1.2364
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 1.08s
                        Total time: 1054.65s
                               ETA: 2208.2s

################################################################################
                     [1m Learning iteration 970/3000 [0m                      

                       Computation: 89486 steps/s (collection: 0.974s, learning 0.125s)
               Value function loss: 0.9575
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9007
                     Learning rate: 0.0009
                       Mean reward: 98.56
               Mean episode length: 961.92
       Episode_Reward/keep_balance: 0.9571
     Episode_Reward/rew_lin_vel_xy: 4.3611
      Episode_Reward/rew_ang_vel_z: 2.4014
    Episode_Reward/pen_base_height: -0.3376
      Episode_Reward/pen_lin_vel_z: -0.0528
     Episode_Reward/pen_ang_vel_xy: -0.1795
   Episode_Reward/pen_joint_torque: -0.2167
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.1104
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0518
   Episode_Reward/pen_joint_powers: -0.0803
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2484
Episode_Reward/pen_flat_orientation: -0.1287
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.3407
   Episode_Reward/foot_landing_vel: -0.1457
   Episode_Reward/test_gait_reward: -0.8922
Metrics/base_velocity/error_vel_xy: 1.8894
Metrics/base_velocity/error_vel_yaw: 1.2696
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 1.10s
                        Total time: 1055.75s
                               ETA: 2207.2s

################################################################################
                     [1m Learning iteration 971/3000 [0m                      

                       Computation: 90384 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.9601
                    Surrogate loss: -0.0011
             Mean action noise std: 0.9004
                     Learning rate: 0.0006
                       Mean reward: 99.41
               Mean episode length: 971.13
       Episode_Reward/keep_balance: 0.9697
     Episode_Reward/rew_lin_vel_xy: 4.4831
      Episode_Reward/rew_ang_vel_z: 2.4872
    Episode_Reward/pen_base_height: -0.3397
      Episode_Reward/pen_lin_vel_z: -0.0519
     Episode_Reward/pen_ang_vel_xy: -0.1769
   Episode_Reward/pen_joint_torque: -0.2174
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1097
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0509
   Episode_Reward/pen_joint_powers: -0.0797
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2478
Episode_Reward/pen_flat_orientation: -0.1282
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3392
   Episode_Reward/foot_landing_vel: -0.1393
   Episode_Reward/test_gait_reward: -0.9047
Metrics/base_velocity/error_vel_xy: 1.9237
Metrics/base_velocity/error_vel_yaw: 1.2308
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 1.09s
                        Total time: 1056.83s
                               ETA: 2206.1s

################################################################################
                     [1m Learning iteration 972/3000 [0m                      

                       Computation: 90914 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 0.9067
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8992
                     Learning rate: 0.0009
                       Mean reward: 97.32
               Mean episode length: 952.41
       Episode_Reward/keep_balance: 0.9609
     Episode_Reward/rew_lin_vel_xy: 4.4870
      Episode_Reward/rew_ang_vel_z: 2.4227
    Episode_Reward/pen_base_height: -0.3311
      Episode_Reward/pen_lin_vel_z: -0.0532
     Episode_Reward/pen_ang_vel_xy: -0.1808
   Episode_Reward/pen_joint_torque: -0.2165
    Episode_Reward/pen_joint_accel: -0.1104
    Episode_Reward/pen_action_rate: -0.1092
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0515
   Episode_Reward/pen_joint_powers: -0.0798
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2461
Episode_Reward/pen_flat_orientation: -0.1342
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.3402
   Episode_Reward/foot_landing_vel: -0.1516
   Episode_Reward/test_gait_reward: -0.8996
Metrics/base_velocity/error_vel_xy: 1.8395
Metrics/base_velocity/error_vel_yaw: 1.2618
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 1.08s
                        Total time: 1057.92s
                               ETA: 2205.0s

################################################################################
                     [1m Learning iteration 973/3000 [0m                      

                       Computation: 85344 steps/s (collection: 1.029s, learning 0.123s)
               Value function loss: 1.0493
                    Surrogate loss: -0.0017
             Mean action noise std: 0.9002
                     Learning rate: 0.0004
                       Mean reward: 96.57
               Mean episode length: 971.82
       Episode_Reward/keep_balance: 0.9641
     Episode_Reward/rew_lin_vel_xy: 4.2772
      Episode_Reward/rew_ang_vel_z: 2.3945
    Episode_Reward/pen_base_height: -0.3250
      Episode_Reward/pen_lin_vel_z: -0.0519
     Episode_Reward/pen_ang_vel_xy: -0.1803
   Episode_Reward/pen_joint_torque: -0.2117
    Episode_Reward/pen_joint_accel: -0.1121
    Episode_Reward/pen_action_rate: -0.1114
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0527
   Episode_Reward/pen_joint_powers: -0.0802
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2509
Episode_Reward/pen_flat_orientation: -0.1270
  Episode_Reward/pen_feet_distance: -0.0055
Episode_Reward/pen_feet_regulation: -0.3539
   Episode_Reward/foot_landing_vel: -0.1539
   Episode_Reward/test_gait_reward: -0.9029
Metrics/base_velocity/error_vel_xy: 1.9172
Metrics/base_velocity/error_vel_yaw: 1.2891
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 1.15s
                        Total time: 1059.07s
                               ETA: 2204.0s

################################################################################
                     [1m Learning iteration 974/3000 [0m                      

                       Computation: 87735 steps/s (collection: 0.992s, learning 0.129s)
               Value function loss: 1.0700
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9034
                     Learning rate: 0.0009
                       Mean reward: 94.51
               Mean episode length: 930.09
       Episode_Reward/keep_balance: 0.9302
     Episode_Reward/rew_lin_vel_xy: 4.3378
      Episode_Reward/rew_ang_vel_z: 2.3454
    Episode_Reward/pen_base_height: -0.3133
      Episode_Reward/pen_lin_vel_z: -0.0524
     Episode_Reward/pen_ang_vel_xy: -0.1706
   Episode_Reward/pen_joint_torque: -0.2077
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.1060
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0498
   Episode_Reward/pen_joint_powers: -0.0771
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2391
Episode_Reward/pen_flat_orientation: -0.1254
  Episode_Reward/pen_feet_distance: -0.0077
Episode_Reward/pen_feet_regulation: -0.3268
   Episode_Reward/foot_landing_vel: -0.1487
   Episode_Reward/test_gait_reward: -0.8577
Metrics/base_velocity/error_vel_xy: 1.8142
Metrics/base_velocity/error_vel_yaw: 1.2134
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 1.12s
                        Total time: 1060.19s
                               ETA: 2203.0s

################################################################################
                     [1m Learning iteration 975/3000 [0m                      

                       Computation: 89555 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 1.0062
                    Surrogate loss: -0.0019
             Mean action noise std: 0.9038
                     Learning rate: 0.0006
                       Mean reward: 94.87
               Mean episode length: 943.90
       Episode_Reward/keep_balance: 0.9475
     Episode_Reward/rew_lin_vel_xy: 4.2512
      Episode_Reward/rew_ang_vel_z: 2.4054
    Episode_Reward/pen_base_height: -0.3291
      Episode_Reward/pen_lin_vel_z: -0.0526
     Episode_Reward/pen_ang_vel_xy: -0.1765
   Episode_Reward/pen_joint_torque: -0.2099
    Episode_Reward/pen_joint_accel: -0.1042
    Episode_Reward/pen_action_rate: -0.1091
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0507
   Episode_Reward/pen_joint_powers: -0.0783
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2441
Episode_Reward/pen_flat_orientation: -0.1323
  Episode_Reward/pen_feet_distance: -0.0096
Episode_Reward/pen_feet_regulation: -0.3416
   Episode_Reward/foot_landing_vel: -0.1453
   Episode_Reward/test_gait_reward: -0.8874
Metrics/base_velocity/error_vel_xy: 1.9260
Metrics/base_velocity/error_vel_yaw: 1.2349
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 1.10s
                        Total time: 1061.29s
                               ETA: 2202.0s

################################################################################
                     [1m Learning iteration 976/3000 [0m                      

                       Computation: 92131 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 1.0142
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9055
                     Learning rate: 0.0009
                       Mean reward: 96.65
               Mean episode length: 935.34
       Episode_Reward/keep_balance: 0.9239
     Episode_Reward/rew_lin_vel_xy: 4.1778
      Episode_Reward/rew_ang_vel_z: 2.3636
    Episode_Reward/pen_base_height: -0.3282
      Episode_Reward/pen_lin_vel_z: -0.0532
     Episode_Reward/pen_ang_vel_xy: -0.1796
   Episode_Reward/pen_joint_torque: -0.2132
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.1057
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0514
   Episode_Reward/pen_joint_powers: -0.0785
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2358
Episode_Reward/pen_flat_orientation: -0.1370
  Episode_Reward/pen_feet_distance: -0.0107
Episode_Reward/pen_feet_regulation: -0.3311
   Episode_Reward/foot_landing_vel: -0.1467
   Episode_Reward/test_gait_reward: -0.8601
Metrics/base_velocity/error_vel_xy: 1.8310
Metrics/base_velocity/error_vel_yaw: 1.1846
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 1.07s
                        Total time: 1062.35s
                               ETA: 2200.8s

################################################################################
                     [1m Learning iteration 977/3000 [0m                      

                       Computation: 90112 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 1.0210
                    Surrogate loss: -0.0019
             Mean action noise std: 0.9051
                     Learning rate: 0.0009
                       Mean reward: 95.56
               Mean episode length: 942.53
       Episode_Reward/keep_balance: 0.9418
     Episode_Reward/rew_lin_vel_xy: 4.4303
      Episode_Reward/rew_ang_vel_z: 2.3717
    Episode_Reward/pen_base_height: -0.3324
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.1780
   Episode_Reward/pen_joint_torque: -0.2183
    Episode_Reward/pen_joint_accel: -0.1162
    Episode_Reward/pen_action_rate: -0.1096
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0534
   Episode_Reward/pen_joint_powers: -0.0817
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2433
Episode_Reward/pen_flat_orientation: -0.1327
  Episode_Reward/pen_feet_distance: -0.0078
Episode_Reward/pen_feet_regulation: -0.3595
   Episode_Reward/foot_landing_vel: -0.1546
   Episode_Reward/test_gait_reward: -0.8913
Metrics/base_velocity/error_vel_xy: 1.6929
Metrics/base_velocity/error_vel_yaw: 1.2418
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 1.09s
                        Total time: 1063.44s
                               ETA: 2199.7s

################################################################################
                     [1m Learning iteration 978/3000 [0m                      

                       Computation: 90150 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.9833
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9038
                     Learning rate: 0.0006
                       Mean reward: 96.16
               Mean episode length: 940.00
       Episode_Reward/keep_balance: 0.9520
     Episode_Reward/rew_lin_vel_xy: 4.4283
      Episode_Reward/rew_ang_vel_z: 2.3933
    Episode_Reward/pen_base_height: -0.3227
      Episode_Reward/pen_lin_vel_z: -0.0486
     Episode_Reward/pen_ang_vel_xy: -0.1839
   Episode_Reward/pen_joint_torque: -0.2124
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1104
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0514
   Episode_Reward/pen_joint_powers: -0.0793
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2487
Episode_Reward/pen_flat_orientation: -0.1312
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3436
   Episode_Reward/foot_landing_vel: -0.1421
   Episode_Reward/test_gait_reward: -0.8984
Metrics/base_velocity/error_vel_xy: 1.8739
Metrics/base_velocity/error_vel_yaw: 1.2528
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 1.09s
                        Total time: 1064.53s
                               ETA: 2198.7s

################################################################################
                     [1m Learning iteration 979/3000 [0m                      

                       Computation: 91772 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 1.0006
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9030
                     Learning rate: 0.0004
                       Mean reward: 99.98
               Mean episode length: 945.49
       Episode_Reward/keep_balance: 0.9360
     Episode_Reward/rew_lin_vel_xy: 4.4106
      Episode_Reward/rew_ang_vel_z: 2.4131
    Episode_Reward/pen_base_height: -0.3169
      Episode_Reward/pen_lin_vel_z: -0.0491
     Episode_Reward/pen_ang_vel_xy: -0.1712
   Episode_Reward/pen_joint_torque: -0.2122
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.1057
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0488
   Episode_Reward/pen_joint_powers: -0.0772
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2372
Episode_Reward/pen_flat_orientation: -0.1254
  Episode_Reward/pen_feet_distance: -0.0075
Episode_Reward/pen_feet_regulation: -0.3234
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.8711
Metrics/base_velocity/error_vel_xy: 1.7931
Metrics/base_velocity/error_vel_yaw: 1.1732
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 1.07s
                        Total time: 1065.61s
                               ETA: 2197.5s

################################################################################
                     [1m Learning iteration 980/3000 [0m                      

                       Computation: 90543 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.9201
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9030
                     Learning rate: 0.0004
                       Mean reward: 101.11
               Mean episode length: 948.58
       Episode_Reward/keep_balance: 0.9690
     Episode_Reward/rew_lin_vel_xy: 4.7238
      Episode_Reward/rew_ang_vel_z: 2.4890
    Episode_Reward/pen_base_height: -0.3308
      Episode_Reward/pen_lin_vel_z: -0.0526
     Episode_Reward/pen_ang_vel_xy: -0.1770
   Episode_Reward/pen_joint_torque: -0.2251
    Episode_Reward/pen_joint_accel: -0.1003
    Episode_Reward/pen_action_rate: -0.1096
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0515
   Episode_Reward/pen_joint_powers: -0.0816
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2439
Episode_Reward/pen_flat_orientation: -0.1326
  Episode_Reward/pen_feet_distance: -0.0072
Episode_Reward/pen_feet_regulation: -0.3431
   Episode_Reward/foot_landing_vel: -0.1532
   Episode_Reward/test_gait_reward: -0.9084
Metrics/base_velocity/error_vel_xy: 1.7116
Metrics/base_velocity/error_vel_yaw: 1.2311
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 1.09s
                        Total time: 1066.69s
                               ETA: 2196.4s

################################################################################
                     [1m Learning iteration 981/3000 [0m                      

                       Computation: 91362 steps/s (collection: 0.949s, learning 0.127s)
               Value function loss: 1.0563
                    Surrogate loss: -0.0038
             Mean action noise std: 0.9047
                     Learning rate: 0.0006
                       Mean reward: 97.54
               Mean episode length: 939.19
       Episode_Reward/keep_balance: 0.9436
     Episode_Reward/rew_lin_vel_xy: 4.5084
      Episode_Reward/rew_ang_vel_z: 2.3565
    Episode_Reward/pen_base_height: -0.3256
      Episode_Reward/pen_lin_vel_z: -0.0497
     Episode_Reward/pen_ang_vel_xy: -0.1783
   Episode_Reward/pen_joint_torque: -0.2091
    Episode_Reward/pen_joint_accel: -0.1098
    Episode_Reward/pen_action_rate: -0.1087
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0506
   Episode_Reward/pen_joint_powers: -0.0786
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2450
Episode_Reward/pen_flat_orientation: -0.1314
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3429
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.8881
Metrics/base_velocity/error_vel_xy: 1.7347
Metrics/base_velocity/error_vel_yaw: 1.2597
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 1.08s
                        Total time: 1067.77s
                               ETA: 2195.3s

################################################################################
                     [1m Learning iteration 982/3000 [0m                      

                       Computation: 90150 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 1.0301
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9051
                     Learning rate: 0.0004
                       Mean reward: 98.44
               Mean episode length: 945.88
       Episode_Reward/keep_balance: 0.9582
     Episode_Reward/rew_lin_vel_xy: 4.6621
      Episode_Reward/rew_ang_vel_z: 2.4109
    Episode_Reward/pen_base_height: -0.3236
      Episode_Reward/pen_lin_vel_z: -0.0513
     Episode_Reward/pen_ang_vel_xy: -0.1800
   Episode_Reward/pen_joint_torque: -0.2186
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.1102
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0502
   Episode_Reward/pen_joint_powers: -0.0789
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2455
Episode_Reward/pen_flat_orientation: -0.1347
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3348
   Episode_Reward/foot_landing_vel: -0.1380
   Episode_Reward/test_gait_reward: -0.8963
Metrics/base_velocity/error_vel_xy: 1.6201
Metrics/base_velocity/error_vel_yaw: 1.2643
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 1.09s
                        Total time: 1068.86s
                               ETA: 2194.3s

################################################################################
                     [1m Learning iteration 983/3000 [0m                      

                       Computation: 90634 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 1.0208
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9045
                     Learning rate: 0.0004
                       Mean reward: 97.33
               Mean episode length: 953.25
       Episode_Reward/keep_balance: 0.9297
     Episode_Reward/rew_lin_vel_xy: 4.1601
      Episode_Reward/rew_ang_vel_z: 2.3509
    Episode_Reward/pen_base_height: -0.3336
      Episode_Reward/pen_lin_vel_z: -0.0510
     Episode_Reward/pen_ang_vel_xy: -0.1803
   Episode_Reward/pen_joint_torque: -0.2148
    Episode_Reward/pen_joint_accel: -0.1126
    Episode_Reward/pen_action_rate: -0.1081
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0502
   Episode_Reward/pen_joint_powers: -0.0788
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.2411
Episode_Reward/pen_flat_orientation: -0.1346
  Episode_Reward/pen_feet_distance: -0.0112
Episode_Reward/pen_feet_regulation: -0.3242
   Episode_Reward/foot_landing_vel: -0.1414
   Episode_Reward/test_gait_reward: -0.8739
Metrics/base_velocity/error_vel_xy: 1.9377
Metrics/base_velocity/error_vel_yaw: 1.2110
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 1.08s
                        Total time: 1069.94s
                               ETA: 2193.2s

################################################################################
                     [1m Learning iteration 984/3000 [0m                      

                       Computation: 91065 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 1.0354
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9036
                     Learning rate: 0.0009
                       Mean reward: 104.19
               Mean episode length: 965.68
       Episode_Reward/keep_balance: 0.9703
     Episode_Reward/rew_lin_vel_xy: 4.7406
      Episode_Reward/rew_ang_vel_z: 2.4794
    Episode_Reward/pen_base_height: -0.3218
      Episode_Reward/pen_lin_vel_z: -0.0519
     Episode_Reward/pen_ang_vel_xy: -0.1844
   Episode_Reward/pen_joint_torque: -0.2173
    Episode_Reward/pen_joint_accel: -0.1174
    Episode_Reward/pen_action_rate: -0.1115
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0519
   Episode_Reward/pen_joint_powers: -0.0806
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2499
Episode_Reward/pen_flat_orientation: -0.1267
  Episode_Reward/pen_feet_distance: -0.0092
Episode_Reward/pen_feet_regulation: -0.3417
   Episode_Reward/foot_landing_vel: -0.1561
   Episode_Reward/test_gait_reward: -0.9075
Metrics/base_velocity/error_vel_xy: 1.6995
Metrics/base_velocity/error_vel_yaw: 1.2339
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 1.08s
                        Total time: 1071.02s
                               ETA: 2192.1s

################################################################################
                     [1m Learning iteration 985/3000 [0m                      

                       Computation: 90287 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.9596
                    Surrogate loss: -0.0026
             Mean action noise std: 0.9041
                     Learning rate: 0.0009
                       Mean reward: 95.13
               Mean episode length: 926.41
       Episode_Reward/keep_balance: 0.9063
     Episode_Reward/rew_lin_vel_xy: 4.2936
      Episode_Reward/rew_ang_vel_z: 2.2859
    Episode_Reward/pen_base_height: -0.3185
      Episode_Reward/pen_lin_vel_z: -0.0488
     Episode_Reward/pen_ang_vel_xy: -0.1801
   Episode_Reward/pen_joint_torque: -0.2030
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1070
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0501
   Episode_Reward/pen_joint_powers: -0.0768
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2376
Episode_Reward/pen_flat_orientation: -0.1306
  Episode_Reward/pen_feet_distance: -0.0077
Episode_Reward/pen_feet_regulation: -0.3300
   Episode_Reward/foot_landing_vel: -0.1394
   Episode_Reward/test_gait_reward: -0.8573
Metrics/base_velocity/error_vel_xy: 1.6399
Metrics/base_velocity/error_vel_yaw: 1.2008
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 1.09s
                        Total time: 1072.11s
                               ETA: 2191.0s

################################################################################
                     [1m Learning iteration 986/3000 [0m                      

                       Computation: 90394 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 1.0276
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9041
                     Learning rate: 0.0004
                       Mean reward: 94.14
               Mean episode length: 935.75
       Episode_Reward/keep_balance: 0.9148
     Episode_Reward/rew_lin_vel_xy: 4.1613
      Episode_Reward/rew_ang_vel_z: 2.2721
    Episode_Reward/pen_base_height: -0.3262
      Episode_Reward/pen_lin_vel_z: -0.0488
     Episode_Reward/pen_ang_vel_xy: -0.1780
   Episode_Reward/pen_joint_torque: -0.2047
    Episode_Reward/pen_joint_accel: -0.1021
    Episode_Reward/pen_action_rate: -0.1080
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0494
   Episode_Reward/pen_joint_powers: -0.0765
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2408
Episode_Reward/pen_flat_orientation: -0.1338
  Episode_Reward/pen_feet_distance: -0.0120
Episode_Reward/pen_feet_regulation: -0.3253
   Episode_Reward/foot_landing_vel: -0.1358
   Episode_Reward/test_gait_reward: -0.8593
Metrics/base_velocity/error_vel_xy: 1.8262
Metrics/base_velocity/error_vel_yaw: 1.2434
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 1.09s
                        Total time: 1073.20s
                               ETA: 2189.9s

################################################################################
                     [1m Learning iteration 987/3000 [0m                      

                       Computation: 90524 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.9865
                    Surrogate loss: -0.0046
             Mean action noise std: 0.9058
                     Learning rate: 0.0004
                       Mean reward: 89.94
               Mean episode length: 887.47
       Episode_Reward/keep_balance: 0.8975
     Episode_Reward/rew_lin_vel_xy: 4.1933
      Episode_Reward/rew_ang_vel_z: 2.2990
    Episode_Reward/pen_base_height: -0.3007
      Episode_Reward/pen_lin_vel_z: -0.0468
     Episode_Reward/pen_ang_vel_xy: -0.1743
   Episode_Reward/pen_joint_torque: -0.1981
    Episode_Reward/pen_joint_accel: -0.1012
    Episode_Reward/pen_action_rate: -0.1037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0476
   Episode_Reward/pen_joint_powers: -0.0738
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2325
Episode_Reward/pen_flat_orientation: -0.1286
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3011
   Episode_Reward/foot_landing_vel: -0.1346
   Episode_Reward/test_gait_reward: -0.8334
Metrics/base_velocity/error_vel_xy: 1.6946
Metrics/base_velocity/error_vel_yaw: 1.1509
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 1.09s
                        Total time: 1074.28s
                               ETA: 2188.8s

################################################################################
                     [1m Learning iteration 988/3000 [0m                      

                       Computation: 90278 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.9828
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9051
                     Learning rate: 0.0006
                       Mean reward: 97.37
               Mean episode length: 942.37
       Episode_Reward/keep_balance: 0.9442
     Episode_Reward/rew_lin_vel_xy: 4.4359
      Episode_Reward/rew_ang_vel_z: 2.4080
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0485
     Episode_Reward/pen_ang_vel_xy: -0.1802
   Episode_Reward/pen_joint_torque: -0.2127
    Episode_Reward/pen_joint_accel: -0.1095
    Episode_Reward/pen_action_rate: -0.1096
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0502
   Episode_Reward/pen_joint_powers: -0.0785
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2447
Episode_Reward/pen_flat_orientation: -0.1315
  Episode_Reward/pen_feet_distance: -0.0114
Episode_Reward/pen_feet_regulation: -0.3245
   Episode_Reward/foot_landing_vel: -0.1448
   Episode_Reward/test_gait_reward: -0.8761
Metrics/base_velocity/error_vel_xy: 1.7290
Metrics/base_velocity/error_vel_yaw: 1.2149
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 1.09s
                        Total time: 1075.37s
                               ETA: 2187.7s

################################################################################
                     [1m Learning iteration 989/3000 [0m                      

                       Computation: 91146 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.9682
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9054
                     Learning rate: 0.0003
                       Mean reward: 94.98
               Mean episode length: 919.78
       Episode_Reward/keep_balance: 0.9268
     Episode_Reward/rew_lin_vel_xy: 4.2445
      Episode_Reward/rew_ang_vel_z: 2.3271
    Episode_Reward/pen_base_height: -0.2987
      Episode_Reward/pen_lin_vel_z: -0.0456
     Episode_Reward/pen_ang_vel_xy: -0.1722
   Episode_Reward/pen_joint_torque: -0.1992
    Episode_Reward/pen_joint_accel: -0.0976
    Episode_Reward/pen_action_rate: -0.1060
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0479
   Episode_Reward/pen_joint_powers: -0.0744
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2394
Episode_Reward/pen_flat_orientation: -0.1223
  Episode_Reward/pen_feet_distance: -0.0116
Episode_Reward/pen_feet_regulation: -0.3076
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.8524
Metrics/base_velocity/error_vel_xy: 1.7826
Metrics/base_velocity/error_vel_yaw: 1.2239
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 1.08s
                        Total time: 1076.45s
                               ETA: 2186.6s

################################################################################
                     [1m Learning iteration 990/3000 [0m                      

                       Computation: 89795 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 1.0285
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9073
                     Learning rate: 0.0002
                       Mean reward: 97.49
               Mean episode length: 954.70
       Episode_Reward/keep_balance: 0.9583
     Episode_Reward/rew_lin_vel_xy: 4.4818
      Episode_Reward/rew_ang_vel_z: 2.4518
    Episode_Reward/pen_base_height: -0.3405
      Episode_Reward/pen_lin_vel_z: -0.0510
     Episode_Reward/pen_ang_vel_xy: -0.1879
   Episode_Reward/pen_joint_torque: -0.2231
    Episode_Reward/pen_joint_accel: -0.1138
    Episode_Reward/pen_action_rate: -0.1126
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0538
   Episode_Reward/pen_joint_powers: -0.0822
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2495
Episode_Reward/pen_flat_orientation: -0.1463
  Episode_Reward/pen_feet_distance: -0.0097
Episode_Reward/pen_feet_regulation: -0.3527
   Episode_Reward/foot_landing_vel: -0.1510
   Episode_Reward/test_gait_reward: -0.8990
Metrics/base_velocity/error_vel_xy: 1.8050
Metrics/base_velocity/error_vel_yaw: 1.2379
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 1.09s
                        Total time: 1077.55s
                               ETA: 2185.5s

################################################################################
                     [1m Learning iteration 991/3000 [0m                      

                       Computation: 89831 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 1.0097
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9073
                     Learning rate: 0.0004
                       Mean reward: 101.42
               Mean episode length: 958.84
       Episode_Reward/keep_balance: 0.9451
     Episode_Reward/rew_lin_vel_xy: 4.5120
      Episode_Reward/rew_ang_vel_z: 2.3869
    Episode_Reward/pen_base_height: -0.3160
      Episode_Reward/pen_lin_vel_z: -0.0505
     Episode_Reward/pen_ang_vel_xy: -0.1742
   Episode_Reward/pen_joint_torque: -0.2169
    Episode_Reward/pen_joint_accel: -0.1169
    Episode_Reward/pen_action_rate: -0.1097
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0517
   Episode_Reward/pen_joint_powers: -0.0796
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2441
Episode_Reward/pen_flat_orientation: -0.1333
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3362
   Episode_Reward/foot_landing_vel: -0.1473
   Episode_Reward/test_gait_reward: -0.8817
Metrics/base_velocity/error_vel_xy: 1.7494
Metrics/base_velocity/error_vel_yaw: 1.2299
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 1.09s
                        Total time: 1078.64s
                               ETA: 2184.5s

################################################################################
                     [1m Learning iteration 992/3000 [0m                      

                       Computation: 88655 steps/s (collection: 0.986s, learning 0.123s)
               Value function loss: 0.9466
                    Surrogate loss: -0.0032
             Mean action noise std: 0.9063
                     Learning rate: 0.0003
                       Mean reward: 97.16
               Mean episode length: 921.48
       Episode_Reward/keep_balance: 0.9351
     Episode_Reward/rew_lin_vel_xy: 4.4246
      Episode_Reward/rew_ang_vel_z: 2.3640
    Episode_Reward/pen_base_height: -0.3175
      Episode_Reward/pen_lin_vel_z: -0.0516
     Episode_Reward/pen_ang_vel_xy: -0.1772
   Episode_Reward/pen_joint_torque: -0.2211
    Episode_Reward/pen_joint_accel: -0.1119
    Episode_Reward/pen_action_rate: -0.1099
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0525
   Episode_Reward/pen_joint_powers: -0.0813
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2433
Episode_Reward/pen_flat_orientation: -0.1376
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.3486
   Episode_Reward/foot_landing_vel: -0.1455
   Episode_Reward/test_gait_reward: -0.8735
Metrics/base_velocity/error_vel_xy: 1.7620
Metrics/base_velocity/error_vel_yaw: 1.2248
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 1.11s
                        Total time: 1079.75s
                               ETA: 2183.4s

################################################################################
                     [1m Learning iteration 993/3000 [0m                      

                       Computation: 90560 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 0.9160
                    Surrogate loss: -0.0021
             Mean action noise std: 0.9078
                     Learning rate: 0.0003
                       Mean reward: 96.31
               Mean episode length: 933.18
       Episode_Reward/keep_balance: 0.9455
     Episode_Reward/rew_lin_vel_xy: 4.5048
      Episode_Reward/rew_ang_vel_z: 2.3602
    Episode_Reward/pen_base_height: -0.3262
      Episode_Reward/pen_lin_vel_z: -0.0483
     Episode_Reward/pen_ang_vel_xy: -0.1808
   Episode_Reward/pen_joint_torque: -0.2071
    Episode_Reward/pen_joint_accel: -0.1204
    Episode_Reward/pen_action_rate: -0.1127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0527
   Episode_Reward/pen_joint_powers: -0.0798
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2517
Episode_Reward/pen_flat_orientation: -0.1419
  Episode_Reward/pen_feet_distance: -0.0096
Episode_Reward/pen_feet_regulation: -0.3458
   Episode_Reward/foot_landing_vel: -0.1441
   Episode_Reward/test_gait_reward: -0.8910
Metrics/base_velocity/error_vel_xy: 1.7019
Metrics/base_velocity/error_vel_yaw: 1.2754
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 1.09s
                        Total time: 1080.83s
                               ETA: 2182.3s

################################################################################
                     [1m Learning iteration 994/3000 [0m                      

                       Computation: 90692 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.9395
                    Surrogate loss: -0.0046
             Mean action noise std: 0.9091
                     Learning rate: 0.0006
                       Mean reward: 101.05
               Mean episode length: 949.27
       Episode_Reward/keep_balance: 0.9483
     Episode_Reward/rew_lin_vel_xy: 4.4278
      Episode_Reward/rew_ang_vel_z: 2.3855
    Episode_Reward/pen_base_height: -0.3101
      Episode_Reward/pen_lin_vel_z: -0.0480
     Episode_Reward/pen_ang_vel_xy: -0.1783
   Episode_Reward/pen_joint_torque: -0.2095
    Episode_Reward/pen_joint_accel: -0.1163
    Episode_Reward/pen_action_rate: -0.1109
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0502
   Episode_Reward/pen_joint_powers: -0.0776
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2484
Episode_Reward/pen_flat_orientation: -0.1288
  Episode_Reward/pen_feet_distance: -0.0122
Episode_Reward/pen_feet_regulation: -0.3321
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.8809
Metrics/base_velocity/error_vel_xy: 1.8454
Metrics/base_velocity/error_vel_yaw: 1.2466
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 1.08s
                        Total time: 1081.92s
                               ETA: 2181.2s

################################################################################
                     [1m Learning iteration 995/3000 [0m                      

                       Computation: 89931 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 0.9447
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9081
                     Learning rate: 0.0009
                       Mean reward: 98.46
               Mean episode length: 946.70
       Episode_Reward/keep_balance: 0.9290
     Episode_Reward/rew_lin_vel_xy: 4.4934
      Episode_Reward/rew_ang_vel_z: 2.3303
    Episode_Reward/pen_base_height: -0.3306
      Episode_Reward/pen_lin_vel_z: -0.0524
     Episode_Reward/pen_ang_vel_xy: -0.1803
   Episode_Reward/pen_joint_torque: -0.2223
    Episode_Reward/pen_joint_accel: -0.1138
    Episode_Reward/pen_action_rate: -0.1105
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0531
   Episode_Reward/pen_joint_powers: -0.0821
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2432
Episode_Reward/pen_flat_orientation: -0.1354
  Episode_Reward/pen_feet_distance: -0.0090
Episode_Reward/pen_feet_regulation: -0.3656
   Episode_Reward/foot_landing_vel: -0.1535
   Episode_Reward/test_gait_reward: -0.8783
Metrics/base_velocity/error_vel_xy: 1.6317
Metrics/base_velocity/error_vel_yaw: 1.2288
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 1.09s
                        Total time: 1083.01s
                               ETA: 2180.2s

################################################################################
                     [1m Learning iteration 996/3000 [0m                      

                       Computation: 89600 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 1.0732
                    Surrogate loss: -0.0026
             Mean action noise std: 0.9066
                     Learning rate: 0.0006
                       Mean reward: 97.70
               Mean episode length: 953.40
       Episode_Reward/keep_balance: 0.9422
     Episode_Reward/rew_lin_vel_xy: 4.3825
      Episode_Reward/rew_ang_vel_z: 2.3878
    Episode_Reward/pen_base_height: -0.3216
      Episode_Reward/pen_lin_vel_z: -0.0495
     Episode_Reward/pen_ang_vel_xy: -0.1838
   Episode_Reward/pen_joint_torque: -0.2171
    Episode_Reward/pen_joint_accel: -0.1128
    Episode_Reward/pen_action_rate: -0.1118
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0529
   Episode_Reward/pen_joint_powers: -0.0813
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2488
Episode_Reward/pen_flat_orientation: -0.1325
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3488
   Episode_Reward/foot_landing_vel: -0.1522
   Episode_Reward/test_gait_reward: -0.8803
Metrics/base_velocity/error_vel_xy: 1.8461
Metrics/base_velocity/error_vel_yaw: 1.2222
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 1.10s
                        Total time: 1084.11s
                               ETA: 2179.1s

################################################################################
                     [1m Learning iteration 997/3000 [0m                      

                       Computation: 90530 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 1.0121
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9058
                     Learning rate: 0.0009
                       Mean reward: 97.26
               Mean episode length: 919.38
       Episode_Reward/keep_balance: 0.9352
     Episode_Reward/rew_lin_vel_xy: 4.6307
      Episode_Reward/rew_ang_vel_z: 2.3162
    Episode_Reward/pen_base_height: -0.3239
      Episode_Reward/pen_lin_vel_z: -0.0515
     Episode_Reward/pen_ang_vel_xy: -0.1894
   Episode_Reward/pen_joint_torque: -0.2109
    Episode_Reward/pen_joint_accel: -0.1205
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0816
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2539
Episode_Reward/pen_flat_orientation: -0.1395
  Episode_Reward/pen_feet_distance: -0.0117
Episode_Reward/pen_feet_regulation: -0.3707
   Episode_Reward/foot_landing_vel: -0.1581
   Episode_Reward/test_gait_reward: -0.8882
Metrics/base_velocity/error_vel_xy: 1.5594
Metrics/base_velocity/error_vel_yaw: 1.2843
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 1.09s
                        Total time: 1085.19s
                               ETA: 2178.0s

################################################################################
                     [1m Learning iteration 998/3000 [0m                      

                       Computation: 89571 steps/s (collection: 0.975s, learning 0.122s)
               Value function loss: 0.9424
                    Surrogate loss: -0.0022
             Mean action noise std: 0.9064
                     Learning rate: 0.0009
                       Mean reward: 96.48
               Mean episode length: 938.06
       Episode_Reward/keep_balance: 0.9435
     Episode_Reward/rew_lin_vel_xy: 4.5054
      Episode_Reward/rew_ang_vel_z: 2.3735
    Episode_Reward/pen_base_height: -0.3211
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.1826
   Episode_Reward/pen_joint_torque: -0.2168
    Episode_Reward/pen_joint_accel: -0.1158
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0526
   Episode_Reward/pen_joint_powers: -0.0812
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2497
Episode_Reward/pen_flat_orientation: -0.1322
  Episode_Reward/pen_feet_distance: -0.0092
Episode_Reward/pen_feet_regulation: -0.3512
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.8874
Metrics/base_velocity/error_vel_xy: 1.7295
Metrics/base_velocity/error_vel_yaw: 1.2466
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 1.10s
                        Total time: 1086.29s
                               ETA: 2176.9s

################################################################################
                     [1m Learning iteration 999/3000 [0m                      

                       Computation: 90223 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 1.0163
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9086
                     Learning rate: 0.0013
                       Mean reward: 104.20
               Mean episode length: 990.29
       Episode_Reward/keep_balance: 0.9910
     Episode_Reward/rew_lin_vel_xy: 4.7806
      Episode_Reward/rew_ang_vel_z: 2.4841
    Episode_Reward/pen_base_height: -0.3163
      Episode_Reward/pen_lin_vel_z: -0.0497
     Episode_Reward/pen_ang_vel_xy: -0.1935
   Episode_Reward/pen_joint_torque: -0.2218
    Episode_Reward/pen_joint_accel: -0.1184
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0830
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2617
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0100
Episode_Reward/pen_feet_regulation: -0.3565
   Episode_Reward/foot_landing_vel: -0.1543
   Episode_Reward/test_gait_reward: -0.9286
Metrics/base_velocity/error_vel_xy: 1.7436
Metrics/base_velocity/error_vel_yaw: 1.3102
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 1.09s
                        Total time: 1087.38s
                               ETA: 2175.9s

################################################################################
                     [1m Learning iteration 1000/3000 [0m                     

                       Computation: 91483 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.0036
                    Surrogate loss: -0.0014
             Mean action noise std: 0.9103
                     Learning rate: 0.0006
                       Mean reward: 104.84
               Mean episode length: 969.83
       Episode_Reward/keep_balance: 0.9532
     Episode_Reward/rew_lin_vel_xy: 4.5857
      Episode_Reward/rew_ang_vel_z: 2.3965
    Episode_Reward/pen_base_height: -0.3139
      Episode_Reward/pen_lin_vel_z: -0.0478
     Episode_Reward/pen_ang_vel_xy: -0.1837
   Episode_Reward/pen_joint_torque: -0.2160
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1129
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0518
   Episode_Reward/pen_joint_powers: -0.0805
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2513
Episode_Reward/pen_flat_orientation: -0.1270
  Episode_Reward/pen_feet_distance: -0.0072
Episode_Reward/pen_feet_regulation: -0.3546
   Episode_Reward/foot_landing_vel: -0.1394
   Episode_Reward/test_gait_reward: -0.8962
Metrics/base_velocity/error_vel_xy: 1.6844
Metrics/base_velocity/error_vel_yaw: 1.2502
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 1.07s
                        Total time: 1088.46s
                               ETA: 2174.7s

################################################################################
                     [1m Learning iteration 1001/3000 [0m                     

                       Computation: 91061 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 1.0022
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9110
                     Learning rate: 0.0009
                       Mean reward: 98.14
               Mean episode length: 947.22
       Episode_Reward/keep_balance: 0.9503
     Episode_Reward/rew_lin_vel_xy: 4.6329
      Episode_Reward/rew_ang_vel_z: 2.3987
    Episode_Reward/pen_base_height: -0.3323
      Episode_Reward/pen_lin_vel_z: -0.0533
     Episode_Reward/pen_ang_vel_xy: -0.1910
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.1143
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0556
   Episode_Reward/pen_joint_powers: -0.0854
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.2537
Episode_Reward/pen_flat_orientation: -0.1397
  Episode_Reward/pen_feet_distance: -0.0095
Episode_Reward/pen_feet_regulation: -0.3891
   Episode_Reward/foot_landing_vel: -0.1543
   Episode_Reward/test_gait_reward: -0.9008
Metrics/base_velocity/error_vel_xy: 1.6590
Metrics/base_velocity/error_vel_yaw: 1.2449
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 1.08s
                        Total time: 1089.54s
                               ETA: 2173.6s

################################################################################
                     [1m Learning iteration 1002/3000 [0m                     

                       Computation: 90766 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 1.0822
                    Surrogate loss: -0.0022
             Mean action noise std: 0.9107
                     Learning rate: 0.0009
                       Mean reward: 100.21
               Mean episode length: 941.49
       Episode_Reward/keep_balance: 0.9266
     Episode_Reward/rew_lin_vel_xy: 4.8396
      Episode_Reward/rew_ang_vel_z: 2.2762
    Episode_Reward/pen_base_height: -0.3153
      Episode_Reward/pen_lin_vel_z: -0.0505
     Episode_Reward/pen_ang_vel_xy: -0.1896
   Episode_Reward/pen_joint_torque: -0.2060
    Episode_Reward/pen_joint_accel: -0.1296
    Episode_Reward/pen_action_rate: -0.1135
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0813
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2532
Episode_Reward/pen_flat_orientation: -0.1312
  Episode_Reward/pen_feet_distance: -0.0095
Episode_Reward/pen_feet_regulation: -0.3653
   Episode_Reward/foot_landing_vel: -0.1528
   Episode_Reward/test_gait_reward: -0.8785
Metrics/base_velocity/error_vel_xy: 1.4030
Metrics/base_velocity/error_vel_yaw: 1.2722
      Episode_Termination/time_out: 2.7917
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 1.08s
                        Total time: 1090.62s
                               ETA: 2172.5s

################################################################################
                     [1m Learning iteration 1003/3000 [0m                     

                       Computation: 88849 steps/s (collection: 0.984s, learning 0.122s)
               Value function loss: 0.9003
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9106
                     Learning rate: 0.0009
                       Mean reward: 93.60
               Mean episode length: 926.77
       Episode_Reward/keep_balance: 0.9366
     Episode_Reward/rew_lin_vel_xy: 4.3773
      Episode_Reward/rew_ang_vel_z: 2.2901
    Episode_Reward/pen_base_height: -0.3222
      Episode_Reward/pen_lin_vel_z: -0.0511
     Episode_Reward/pen_ang_vel_xy: -0.1958
   Episode_Reward/pen_joint_torque: -0.2137
    Episode_Reward/pen_joint_accel: -0.1161
    Episode_Reward/pen_action_rate: -0.1162
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0556
   Episode_Reward/pen_joint_powers: -0.0830
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2556
Episode_Reward/pen_flat_orientation: -0.1382
  Episode_Reward/pen_feet_distance: -0.0086
Episode_Reward/pen_feet_regulation: -0.3613
   Episode_Reward/foot_landing_vel: -0.1490
   Episode_Reward/test_gait_reward: -0.8829
Metrics/base_velocity/error_vel_xy: 1.7881
Metrics/base_velocity/error_vel_yaw: 1.2956
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 1.11s
                        Total time: 1091.73s
                               ETA: 2171.5s

################################################################################
                     [1m Learning iteration 1004/3000 [0m                     

                       Computation: 89857 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 1.0591
                    Surrogate loss: -0.0039
             Mean action noise std: 0.9102
                     Learning rate: 0.0009
                       Mean reward: 100.42
               Mean episode length: 958.60
       Episode_Reward/keep_balance: 0.9619
     Episode_Reward/rew_lin_vel_xy: 4.6378
      Episode_Reward/rew_ang_vel_z: 2.3901
    Episode_Reward/pen_base_height: -0.3367
      Episode_Reward/pen_lin_vel_z: -0.0519
     Episode_Reward/pen_ang_vel_xy: -0.1912
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0843
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2583
Episode_Reward/pen_flat_orientation: -0.1360
  Episode_Reward/pen_feet_distance: -0.0066
Episode_Reward/pen_feet_regulation: -0.3654
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.9045
Metrics/base_velocity/error_vel_xy: 1.7064
Metrics/base_velocity/error_vel_yaw: 1.2983
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 1.09s
                        Total time: 1092.82s
                               ETA: 2170.4s

################################################################################
                     [1m Learning iteration 1005/3000 [0m                     

                       Computation: 90481 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 1.0932
                    Surrogate loss: -0.0022
             Mean action noise std: 0.9095
                     Learning rate: 0.0006
                       Mean reward: 94.05
               Mean episode length: 905.50
       Episode_Reward/keep_balance: 0.9155
     Episode_Reward/rew_lin_vel_xy: 4.4232
      Episode_Reward/rew_ang_vel_z: 2.3124
    Episode_Reward/pen_base_height: -0.3165
      Episode_Reward/pen_lin_vel_z: -0.0474
     Episode_Reward/pen_ang_vel_xy: -0.1786
   Episode_Reward/pen_joint_torque: -0.2099
    Episode_Reward/pen_joint_accel: -0.1111
    Episode_Reward/pen_action_rate: -0.1101
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0516
   Episode_Reward/pen_joint_powers: -0.0788
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2431
Episode_Reward/pen_flat_orientation: -0.1313
  Episode_Reward/pen_feet_distance: -0.0082
Episode_Reward/pen_feet_regulation: -0.3489
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.8633
Metrics/base_velocity/error_vel_xy: 1.6346
Metrics/base_velocity/error_vel_yaw: 1.2010
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 1.09s
                        Total time: 1093.91s
                               ETA: 2169.3s

################################################################################
                     [1m Learning iteration 1006/3000 [0m                     

                       Computation: 89158 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 1.0116
                    Surrogate loss: -0.0022
             Mean action noise std: 0.9092
                     Learning rate: 0.0004
                       Mean reward: 97.70
               Mean episode length: 929.93
       Episode_Reward/keep_balance: 0.9291
     Episode_Reward/rew_lin_vel_xy: 4.5303
      Episode_Reward/rew_ang_vel_z: 2.3238
    Episode_Reward/pen_base_height: -0.3079
      Episode_Reward/pen_lin_vel_z: -0.0483
     Episode_Reward/pen_ang_vel_xy: -0.1850
   Episode_Reward/pen_joint_torque: -0.2082
    Episode_Reward/pen_joint_accel: -0.1087
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0522
   Episode_Reward/pen_joint_powers: -0.0790
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2517
Episode_Reward/pen_flat_orientation: -0.1329
  Episode_Reward/pen_feet_distance: -0.0065
Episode_Reward/pen_feet_regulation: -0.3533
   Episode_Reward/foot_landing_vel: -0.1444
   Episode_Reward/test_gait_reward: -0.8740
Metrics/base_velocity/error_vel_xy: 1.6099
Metrics/base_velocity/error_vel_yaw: 1.2420
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 1.10s
                        Total time: 1095.01s
                               ETA: 2168.3s

################################################################################
                     [1m Learning iteration 1007/3000 [0m                     

                       Computation: 90020 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 0.8823
                    Surrogate loss: -0.0046
             Mean action noise std: 0.9075
                     Learning rate: 0.0006
                       Mean reward: 97.97
               Mean episode length: 937.98
       Episode_Reward/keep_balance: 0.9442
     Episode_Reward/rew_lin_vel_xy: 4.6530
      Episode_Reward/rew_ang_vel_z: 2.3747
    Episode_Reward/pen_base_height: -0.3072
      Episode_Reward/pen_lin_vel_z: -0.0474
     Episode_Reward/pen_ang_vel_xy: -0.1820
   Episode_Reward/pen_joint_torque: -0.2141
    Episode_Reward/pen_joint_accel: -0.1168
    Episode_Reward/pen_action_rate: -0.1131
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0524
   Episode_Reward/pen_joint_powers: -0.0799
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2515
Episode_Reward/pen_flat_orientation: -0.1336
  Episode_Reward/pen_feet_distance: -0.0065
Episode_Reward/pen_feet_regulation: -0.3397
   Episode_Reward/foot_landing_vel: -0.1472
   Episode_Reward/test_gait_reward: -0.8950
Metrics/base_velocity/error_vel_xy: 1.6187
Metrics/base_velocity/error_vel_yaw: 1.2446
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 1.09s
                        Total time: 1096.10s
                               ETA: 2167.2s

################################################################################
                     [1m Learning iteration 1008/3000 [0m                     

                       Computation: 89161 steps/s (collection: 0.980s, learning 0.122s)
               Value function loss: 0.9330
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9093
                     Learning rate: 0.0013
                       Mean reward: 104.26
               Mean episode length: 978.03
       Episode_Reward/keep_balance: 0.9677
     Episode_Reward/rew_lin_vel_xy: 4.7783
      Episode_Reward/rew_ang_vel_z: 2.4086
    Episode_Reward/pen_base_height: -0.3124
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.1943
   Episode_Reward/pen_joint_torque: -0.2272
    Episode_Reward/pen_joint_accel: -0.1176
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2625
Episode_Reward/pen_flat_orientation: -0.1270
  Episode_Reward/pen_feet_distance: -0.0121
Episode_Reward/pen_feet_regulation: -0.3769
   Episode_Reward/foot_landing_vel: -0.1537
   Episode_Reward/test_gait_reward: -0.9111
Metrics/base_velocity/error_vel_xy: 1.6632
Metrics/base_velocity/error_vel_yaw: 1.2962
      Episode_Termination/time_out: 4.8750
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 1.10s
                        Total time: 1097.20s
                               ETA: 2166.1s

################################################################################
                     [1m Learning iteration 1009/3000 [0m                     

                       Computation: 90629 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 1.0191
                    Surrogate loss: -0.0027
             Mean action noise std: 0.9104
                     Learning rate: 0.0013
                       Mean reward: 101.30
               Mean episode length: 964.96
       Episode_Reward/keep_balance: 0.9701
     Episode_Reward/rew_lin_vel_xy: 4.7130
      Episode_Reward/rew_ang_vel_z: 2.4232
    Episode_Reward/pen_base_height: -0.3099
      Episode_Reward/pen_lin_vel_z: -0.0473
     Episode_Reward/pen_ang_vel_xy: -0.1935
   Episode_Reward/pen_joint_torque: -0.2154
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0529
   Episode_Reward/pen_joint_powers: -0.0814
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2617
Episode_Reward/pen_flat_orientation: -0.1297
  Episode_Reward/pen_feet_distance: -0.0088
Episode_Reward/pen_feet_regulation: -0.3466
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.9121
Metrics/base_velocity/error_vel_xy: 1.7568
Metrics/base_velocity/error_vel_yaw: 1.2882
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 1.08s
                        Total time: 1098.29s
                               ETA: 2165.0s

################################################################################
                     [1m Learning iteration 1010/3000 [0m                     

                       Computation: 90013 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 1.1129
                    Surrogate loss: -0.0050
             Mean action noise std: 0.9115
                     Learning rate: 0.0019
                       Mean reward: 102.44
               Mean episode length: 952.92
       Episode_Reward/keep_balance: 0.9491
     Episode_Reward/rew_lin_vel_xy: 4.7064
      Episode_Reward/rew_ang_vel_z: 2.3869
    Episode_Reward/pen_base_height: -0.3107
      Episode_Reward/pen_lin_vel_z: -0.0506
     Episode_Reward/pen_ang_vel_xy: -0.1831
   Episode_Reward/pen_joint_torque: -0.2214
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.1143
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0540
   Episode_Reward/pen_joint_powers: -0.0831
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2524
Episode_Reward/pen_flat_orientation: -0.1313
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.3623
   Episode_Reward/foot_landing_vel: -0.1560
   Episode_Reward/test_gait_reward: -0.8918
Metrics/base_velocity/error_vel_xy: 1.6253
Metrics/base_velocity/error_vel_yaw: 1.2480
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 1.09s
                        Total time: 1099.38s
                               ETA: 2164.0s

################################################################################
                     [1m Learning iteration 1011/3000 [0m                     

                       Computation: 90641 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 1.1020
                    Surrogate loss: 0.0036
             Mean action noise std: 0.9122
                     Learning rate: 0.0001
                       Mean reward: 99.75
               Mean episode length: 962.44
       Episode_Reward/keep_balance: 0.9561
     Episode_Reward/rew_lin_vel_xy: 4.6791
      Episode_Reward/rew_ang_vel_z: 2.3236
    Episode_Reward/pen_base_height: -0.3329
      Episode_Reward/pen_lin_vel_z: -0.0485
     Episode_Reward/pen_ang_vel_xy: -0.1941
   Episode_Reward/pen_joint_torque: -0.2114
    Episode_Reward/pen_joint_accel: -0.1068
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0834
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2671
Episode_Reward/pen_flat_orientation: -0.1456
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3780
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.9120
Metrics/base_velocity/error_vel_xy: 1.6331
Metrics/base_velocity/error_vel_yaw: 1.3462
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 1.08s
                        Total time: 1100.46s
                               ETA: 2162.9s

################################################################################
                     [1m Learning iteration 1012/3000 [0m                     

                       Computation: 91524 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.0276
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9120
                     Learning rate: 0.0004
                       Mean reward: 99.19
               Mean episode length: 936.83
       Episode_Reward/keep_balance: 0.9427
     Episode_Reward/rew_lin_vel_xy: 4.5820
      Episode_Reward/rew_ang_vel_z: 2.3022
    Episode_Reward/pen_base_height: -0.3104
      Episode_Reward/pen_lin_vel_z: -0.0471
     Episode_Reward/pen_ang_vel_xy: -0.1881
   Episode_Reward/pen_joint_torque: -0.2158
    Episode_Reward/pen_joint_accel: -0.1144
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0824
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2569
Episode_Reward/pen_flat_orientation: -0.1325
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3629
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.8945
Metrics/base_velocity/error_vel_xy: 1.6035
Metrics/base_velocity/error_vel_yaw: 1.3018
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 1.07s
                        Total time: 1101.54s
                               ETA: 2161.8s

################################################################################
                     [1m Learning iteration 1013/3000 [0m                     

                       Computation: 90960 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 1.0283
                    Surrogate loss: -0.0026
             Mean action noise std: 0.9111
                     Learning rate: 0.0003
                       Mean reward: 103.45
               Mean episode length: 967.49
       Episode_Reward/keep_balance: 0.9708
     Episode_Reward/rew_lin_vel_xy: 4.8421
      Episode_Reward/rew_ang_vel_z: 2.4330
    Episode_Reward/pen_base_height: -0.3049
      Episode_Reward/pen_lin_vel_z: -0.0462
     Episode_Reward/pen_ang_vel_xy: -0.1927
   Episode_Reward/pen_joint_torque: -0.2192
    Episode_Reward/pen_joint_accel: -0.1220
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0539
   Episode_Reward/pen_joint_powers: -0.0824
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2643
Episode_Reward/pen_flat_orientation: -0.1337
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.3571
   Episode_Reward/foot_landing_vel: -0.1414
   Episode_Reward/test_gait_reward: -0.9158
Metrics/base_velocity/error_vel_xy: 1.7277
Metrics/base_velocity/error_vel_yaw: 1.2849
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 1.08s
                        Total time: 1102.62s
                               ETA: 2160.7s

################################################################################
                     [1m Learning iteration 1014/3000 [0m                     

                       Computation: 90733 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.9588
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9110
                     Learning rate: 0.0006
                       Mean reward: 102.93
               Mean episode length: 960.81
       Episode_Reward/keep_balance: 0.9647
     Episode_Reward/rew_lin_vel_xy: 4.7365
      Episode_Reward/rew_ang_vel_z: 2.3699
    Episode_Reward/pen_base_height: -0.3143
      Episode_Reward/pen_lin_vel_z: -0.0479
     Episode_Reward/pen_ang_vel_xy: -0.1948
   Episode_Reward/pen_joint_torque: -0.2153
    Episode_Reward/pen_joint_accel: -0.1202
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0833
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2656
Episode_Reward/pen_flat_orientation: -0.1324
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.3770
   Episode_Reward/foot_landing_vel: -0.1596
   Episode_Reward/test_gait_reward: -0.9072
Metrics/base_velocity/error_vel_xy: 1.6476
Metrics/base_velocity/error_vel_yaw: 1.3137
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 1.08s
                        Total time: 1103.70s
                               ETA: 2159.6s

################################################################################
                     [1m Learning iteration 1015/3000 [0m                     

                       Computation: 90884 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 1.0758
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9107
                     Learning rate: 0.0004
                       Mean reward: 99.12
               Mean episode length: 943.32
       Episode_Reward/keep_balance: 0.9328
     Episode_Reward/rew_lin_vel_xy: 4.6238
      Episode_Reward/rew_ang_vel_z: 2.3337
    Episode_Reward/pen_base_height: -0.2891
      Episode_Reward/pen_lin_vel_z: -0.0461
     Episode_Reward/pen_ang_vel_xy: -0.1769
   Episode_Reward/pen_joint_torque: -0.2084
    Episode_Reward/pen_joint_accel: -0.1028
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0516
   Episode_Reward/pen_joint_powers: -0.0788
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2508
Episode_Reward/pen_flat_orientation: -0.1230
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3399
   Episode_Reward/foot_landing_vel: -0.1462
   Episode_Reward/test_gait_reward: -0.8831
Metrics/base_velocity/error_vel_xy: 1.6235
Metrics/base_velocity/error_vel_yaw: 1.2390
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 1.08s
                        Total time: 1104.78s
                               ETA: 2158.5s

################################################################################
                     [1m Learning iteration 1016/3000 [0m                     

                       Computation: 89914 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 0.8832
                    Surrogate loss: -0.0038
             Mean action noise std: 0.9091
                     Learning rate: 0.0006
                       Mean reward: 101.14
               Mean episode length: 948.91
       Episode_Reward/keep_balance: 0.9542
     Episode_Reward/rew_lin_vel_xy: 4.7655
      Episode_Reward/rew_ang_vel_z: 2.3588
    Episode_Reward/pen_base_height: -0.3072
      Episode_Reward/pen_lin_vel_z: -0.0461
     Episode_Reward/pen_ang_vel_xy: -0.1907
   Episode_Reward/pen_joint_torque: -0.2150
    Episode_Reward/pen_joint_accel: -0.1141
    Episode_Reward/pen_action_rate: -0.1180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0831
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2605
Episode_Reward/pen_flat_orientation: -0.1334
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3625
   Episode_Reward/foot_landing_vel: -0.1497
   Episode_Reward/test_gait_reward: -0.9037
Metrics/base_velocity/error_vel_xy: 1.5634
Metrics/base_velocity/error_vel_yaw: 1.2981
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 1.09s
                        Total time: 1105.88s
                               ETA: 2157.4s

################################################################################
                     [1m Learning iteration 1017/3000 [0m                     

                       Computation: 91827 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.8603
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9081
                     Learning rate: 0.0006
                       Mean reward: 105.55
               Mean episode length: 966.77
       Episode_Reward/keep_balance: 0.9701
     Episode_Reward/rew_lin_vel_xy: 4.9576
      Episode_Reward/rew_ang_vel_z: 2.4407
    Episode_Reward/pen_base_height: -0.3098
      Episode_Reward/pen_lin_vel_z: -0.0477
     Episode_Reward/pen_ang_vel_xy: -0.1927
   Episode_Reward/pen_joint_torque: -0.2175
    Episode_Reward/pen_joint_accel: -0.1101
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0832
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2645
Episode_Reward/pen_flat_orientation: -0.1296
  Episode_Reward/pen_feet_distance: -0.0111
Episode_Reward/pen_feet_regulation: -0.3663
   Episode_Reward/foot_landing_vel: -0.1462
   Episode_Reward/test_gait_reward: -0.9145
Metrics/base_velocity/error_vel_xy: 1.5532
Metrics/base_velocity/error_vel_yaw: 1.2834
      Episode_Termination/time_out: 4.8333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 1.07s
                        Total time: 1106.95s
                               ETA: 2156.3s

################################################################################
                     [1m Learning iteration 1018/3000 [0m                     

                       Computation: 91241 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.8904
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9092
                     Learning rate: 0.0006
                       Mean reward: 105.74
               Mean episode length: 967.83
       Episode_Reward/keep_balance: 0.9704
     Episode_Reward/rew_lin_vel_xy: 4.8174
      Episode_Reward/rew_ang_vel_z: 2.4128
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0479
     Episode_Reward/pen_ang_vel_xy: -0.1994
   Episode_Reward/pen_joint_torque: -0.2211
    Episode_Reward/pen_joint_accel: -0.1206
    Episode_Reward/pen_action_rate: -0.1212
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2683
Episode_Reward/pen_flat_orientation: -0.1282
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.3789
   Episode_Reward/foot_landing_vel: -0.1588
   Episode_Reward/test_gait_reward: -0.9182
Metrics/base_velocity/error_vel_xy: 1.6697
Metrics/base_velocity/error_vel_yaw: 1.3010
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 1.08s
                        Total time: 1108.03s
                               ETA: 2155.2s

################################################################################
                     [1m Learning iteration 1019/3000 [0m                     

                       Computation: 90716 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.8996
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9096
                     Learning rate: 0.0006
                       Mean reward: 104.72
               Mean episode length: 973.48
       Episode_Reward/keep_balance: 0.9753
     Episode_Reward/rew_lin_vel_xy: 4.9400
      Episode_Reward/rew_ang_vel_z: 2.4563
    Episode_Reward/pen_base_height: -0.3195
      Episode_Reward/pen_lin_vel_z: -0.0478
     Episode_Reward/pen_ang_vel_xy: -0.1915
   Episode_Reward/pen_joint_torque: -0.2242
    Episode_Reward/pen_joint_accel: -0.1111
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0853
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2644
Episode_Reward/pen_flat_orientation: -0.1369
  Episode_Reward/pen_feet_distance: -0.0118
Episode_Reward/pen_feet_regulation: -0.3803
   Episode_Reward/foot_landing_vel: -0.1606
   Episode_Reward/test_gait_reward: -0.9256
Metrics/base_velocity/error_vel_xy: 1.5925
Metrics/base_velocity/error_vel_yaw: 1.2779
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 1.08s
                        Total time: 1109.11s
                               ETA: 2154.1s

################################################################################
                     [1m Learning iteration 1020/3000 [0m                     

                       Computation: 89370 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 1.0235
                    Surrogate loss: -0.0044
             Mean action noise std: 0.9097
                     Learning rate: 0.0006
                       Mean reward: 102.93
               Mean episode length: 967.23
       Episode_Reward/keep_balance: 0.9733
     Episode_Reward/rew_lin_vel_xy: 4.7543
      Episode_Reward/rew_ang_vel_z: 2.3940
    Episode_Reward/pen_base_height: -0.3095
      Episode_Reward/pen_lin_vel_z: -0.0451
     Episode_Reward/pen_ang_vel_xy: -0.2018
   Episode_Reward/pen_joint_torque: -0.2146
    Episode_Reward/pen_joint_accel: -0.1197
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0847
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2721
Episode_Reward/pen_flat_orientation: -0.1322
  Episode_Reward/pen_feet_distance: -0.0108
Episode_Reward/pen_feet_regulation: -0.3803
   Episode_Reward/foot_landing_vel: -0.1525
   Episode_Reward/test_gait_reward: -0.9165
Metrics/base_velocity/error_vel_xy: 1.7197
Metrics/base_velocity/error_vel_yaw: 1.3346
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 1.10s
                        Total time: 1110.21s
                               ETA: 2153.0s

################################################################################
                     [1m Learning iteration 1021/3000 [0m                     

                       Computation: 91351 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.9838
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9090
                     Learning rate: 0.0009
                       Mean reward: 92.85
               Mean episode length: 916.61
       Episode_Reward/keep_balance: 0.9173
     Episode_Reward/rew_lin_vel_xy: 4.3955
      Episode_Reward/rew_ang_vel_z: 2.2504
    Episode_Reward/pen_base_height: -0.3093
      Episode_Reward/pen_lin_vel_z: -0.0470
     Episode_Reward/pen_ang_vel_xy: -0.1877
   Episode_Reward/pen_joint_torque: -0.2200
    Episode_Reward/pen_joint_accel: -0.1135
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0844
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2533
Episode_Reward/pen_flat_orientation: -0.1426
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3732
   Episode_Reward/foot_landing_vel: -0.1421
   Episode_Reward/test_gait_reward: -0.8729
Metrics/base_velocity/error_vel_xy: 1.6759
Metrics/base_velocity/error_vel_yaw: 1.2714
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 1.08s
                        Total time: 1111.29s
                               ETA: 2151.9s

################################################################################
                     [1m Learning iteration 1022/3000 [0m                     

                       Computation: 90936 steps/s (collection: 0.955s, learning 0.126s)
               Value function loss: 1.0405
                    Surrogate loss: -0.0038
             Mean action noise std: 0.9095
                     Learning rate: 0.0013
                       Mean reward: 97.33
               Mean episode length: 946.05
       Episode_Reward/keep_balance: 0.9577
     Episode_Reward/rew_lin_vel_xy: 4.6833
      Episode_Reward/rew_ang_vel_z: 2.3538
    Episode_Reward/pen_base_height: -0.3146
      Episode_Reward/pen_lin_vel_z: -0.0479
     Episode_Reward/pen_ang_vel_xy: -0.2020
   Episode_Reward/pen_joint_torque: -0.2173
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.1211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2668
Episode_Reward/pen_flat_orientation: -0.1372
  Episode_Reward/pen_feet_distance: -0.0117
Episode_Reward/pen_feet_regulation: -0.3841
   Episode_Reward/foot_landing_vel: -0.1516
   Episode_Reward/test_gait_reward: -0.9066
Metrics/base_velocity/error_vel_xy: 1.6848
Metrics/base_velocity/error_vel_yaw: 1.3065
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 1.08s
                        Total time: 1112.37s
                               ETA: 2150.8s

################################################################################
                     [1m Learning iteration 1023/3000 [0m                     

                       Computation: 91273 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 1.1087
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9102
                     Learning rate: 0.0003
                       Mean reward: 101.71
               Mean episode length: 947.82
       Episode_Reward/keep_balance: 0.9396
     Episode_Reward/rew_lin_vel_xy: 4.7288
      Episode_Reward/rew_ang_vel_z: 2.3398
    Episode_Reward/pen_base_height: -0.2962
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.1863
   Episode_Reward/pen_joint_torque: -0.2077
    Episode_Reward/pen_joint_accel: -0.1068
    Episode_Reward/pen_action_rate: -0.1148
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0512
   Episode_Reward/pen_joint_powers: -0.0793
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2557
Episode_Reward/pen_flat_orientation: -0.1306
  Episode_Reward/pen_feet_distance: -0.0075
Episode_Reward/pen_feet_regulation: -0.3397
   Episode_Reward/foot_landing_vel: -0.1310
   Episode_Reward/test_gait_reward: -0.8871
Metrics/base_velocity/error_vel_xy: 1.5748
Metrics/base_velocity/error_vel_yaw: 1.2648
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 1.08s
                        Total time: 1113.44s
                               ETA: 2149.7s

################################################################################
                     [1m Learning iteration 1024/3000 [0m                     

                       Computation: 90848 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 1.0164
                    Surrogate loss: -0.0059
             Mean action noise std: 0.9105
                     Learning rate: 0.0009
                       Mean reward: 104.23
               Mean episode length: 964.15
       Episode_Reward/keep_balance: 0.9717
     Episode_Reward/rew_lin_vel_xy: 4.9471
      Episode_Reward/rew_ang_vel_z: 2.3737
    Episode_Reward/pen_base_height: -0.3114
      Episode_Reward/pen_lin_vel_z: -0.0469
     Episode_Reward/pen_ang_vel_xy: -0.1953
   Episode_Reward/pen_joint_torque: -0.2186
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0556
   Episode_Reward/pen_joint_powers: -0.0836
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2682
Episode_Reward/pen_flat_orientation: -0.1361
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.3615
   Episode_Reward/foot_landing_vel: -0.1445
   Episode_Reward/test_gait_reward: -0.9223
Metrics/base_velocity/error_vel_xy: 1.5783
Metrics/base_velocity/error_vel_yaw: 1.3429
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 1.08s
                        Total time: 1114.53s
                               ETA: 2148.6s

################################################################################
                     [1m Learning iteration 1025/3000 [0m                     

                       Computation: 91160 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.0677
                    Surrogate loss: -0.0030
             Mean action noise std: 0.9118
                     Learning rate: 0.0006
                       Mean reward: 110.33
               Mean episode length: 981.59
       Episode_Reward/keep_balance: 0.9748
     Episode_Reward/rew_lin_vel_xy: 5.0396
      Episode_Reward/rew_ang_vel_z: 2.4579
    Episode_Reward/pen_base_height: -0.3069
      Episode_Reward/pen_lin_vel_z: -0.0452
     Episode_Reward/pen_ang_vel_xy: -0.1910
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.1240
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0537
   Episode_Reward/pen_joint_powers: -0.0831
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2623
Episode_Reward/pen_flat_orientation: -0.1280
  Episode_Reward/pen_feet_distance: -0.0096
Episode_Reward/pen_feet_regulation: -0.3514
   Episode_Reward/foot_landing_vel: -0.1449
   Episode_Reward/test_gait_reward: -0.9217
Metrics/base_velocity/error_vel_xy: 1.5271
Metrics/base_velocity/error_vel_yaw: 1.2678
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 1.08s
                        Total time: 1115.60s
                               ETA: 2147.5s

################################################################################
                     [1m Learning iteration 1026/3000 [0m                     

                       Computation: 90948 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.9919
                    Surrogate loss: -0.0032
             Mean action noise std: 0.9118
                     Learning rate: 0.0009
                       Mean reward: 99.89
               Mean episode length: 920.83
       Episode_Reward/keep_balance: 0.9331
     Episode_Reward/rew_lin_vel_xy: 4.7481
      Episode_Reward/rew_ang_vel_z: 2.3333
    Episode_Reward/pen_base_height: -0.2943
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.1887
   Episode_Reward/pen_joint_torque: -0.2079
    Episode_Reward/pen_joint_accel: -0.1131
    Episode_Reward/pen_action_rate: -0.1147
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0534
   Episode_Reward/pen_joint_powers: -0.0812
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2540
Episode_Reward/pen_flat_orientation: -0.1293
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3493
   Episode_Reward/foot_landing_vel: -0.1448
   Episode_Reward/test_gait_reward: -0.8860
Metrics/base_velocity/error_vel_xy: 1.5451
Metrics/base_velocity/error_vel_yaw: 1.2435
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 1.08s
                        Total time: 1116.68s
                               ETA: 2146.4s

################################################################################
                     [1m Learning iteration 1027/3000 [0m                     

                       Computation: 89428 steps/s (collection: 0.977s, learning 0.122s)
               Value function loss: 0.9605
                    Surrogate loss: -0.0030
             Mean action noise std: 0.9106
                     Learning rate: 0.0006
                       Mean reward: 101.73
               Mean episode length: 950.34
       Episode_Reward/keep_balance: 0.9290
     Episode_Reward/rew_lin_vel_xy: 4.6664
      Episode_Reward/rew_ang_vel_z: 2.2724
    Episode_Reward/pen_base_height: -0.3078
      Episode_Reward/pen_lin_vel_z: -0.0432
     Episode_Reward/pen_ang_vel_xy: -0.1938
   Episode_Reward/pen_joint_torque: -0.2047
    Episode_Reward/pen_joint_accel: -0.1072
    Episode_Reward/pen_action_rate: -0.1168
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0529
   Episode_Reward/pen_joint_powers: -0.0801
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2587
Episode_Reward/pen_flat_orientation: -0.1354
  Episode_Reward/pen_feet_distance: -0.0100
Episode_Reward/pen_feet_regulation: -0.3495
   Episode_Reward/foot_landing_vel: -0.1360
   Episode_Reward/test_gait_reward: -0.8822
Metrics/base_velocity/error_vel_xy: 1.5468
Metrics/base_velocity/error_vel_yaw: 1.2963
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 1.10s
                        Total time: 1117.78s
                               ETA: 2145.3s

################################################################################
                     [1m Learning iteration 1028/3000 [0m                     

                       Computation: 89645 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 1.0928
                    Surrogate loss: -0.0018
             Mean action noise std: 0.9103
                     Learning rate: 0.0004
                       Mean reward: 99.09
               Mean episode length: 926.82
       Episode_Reward/keep_balance: 0.9353
     Episode_Reward/rew_lin_vel_xy: 4.6800
      Episode_Reward/rew_ang_vel_z: 2.3043
    Episode_Reward/pen_base_height: -0.3088
      Episode_Reward/pen_lin_vel_z: -0.0469
     Episode_Reward/pen_ang_vel_xy: -0.1961
   Episode_Reward/pen_joint_torque: -0.2132
    Episode_Reward/pen_joint_accel: -0.1172
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0838
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2608
Episode_Reward/pen_flat_orientation: -0.1317
  Episode_Reward/pen_feet_distance: -0.0088
Episode_Reward/pen_feet_regulation: -0.3714
   Episode_Reward/foot_landing_vel: -0.1458
   Episode_Reward/test_gait_reward: -0.8922
Metrics/base_velocity/error_vel_xy: 1.5599
Metrics/base_velocity/error_vel_yaw: 1.2932
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 1.10s
                        Total time: 1118.88s
                               ETA: 2144.2s

################################################################################
                     [1m Learning iteration 1029/3000 [0m                     

                       Computation: 89681 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.9954
                    Surrogate loss: -0.0030
             Mean action noise std: 0.9077
                     Learning rate: 0.0006
                       Mean reward: 99.54
               Mean episode length: 938.20
       Episode_Reward/keep_balance: 0.9413
     Episode_Reward/rew_lin_vel_xy: 4.7545
      Episode_Reward/rew_ang_vel_z: 2.3097
    Episode_Reward/pen_base_height: -0.3048
      Episode_Reward/pen_lin_vel_z: -0.0440
     Episode_Reward/pen_ang_vel_xy: -0.2032
   Episode_Reward/pen_joint_torque: -0.2000
    Episode_Reward/pen_joint_accel: -0.1196
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0824
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2650
Episode_Reward/pen_flat_orientation: -0.1335
  Episode_Reward/pen_feet_distance: -0.0108
Episode_Reward/pen_feet_regulation: -0.3669
   Episode_Reward/foot_landing_vel: -0.1502
   Episode_Reward/test_gait_reward: -0.8948
Metrics/base_velocity/error_vel_xy: 1.5193
Metrics/base_velocity/error_vel_yaw: 1.3043
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 1.10s
                        Total time: 1119.98s
                               ETA: 2143.2s

################################################################################
                     [1m Learning iteration 1030/3000 [0m                     

                       Computation: 90235 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.9224
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9075
                     Learning rate: 0.0004
                       Mean reward: 102.94
               Mean episode length: 940.43
       Episode_Reward/keep_balance: 0.9404
     Episode_Reward/rew_lin_vel_xy: 4.8208
      Episode_Reward/rew_ang_vel_z: 2.3096
    Episode_Reward/pen_base_height: -0.3030
      Episode_Reward/pen_lin_vel_z: -0.0459
     Episode_Reward/pen_ang_vel_xy: -0.1935
   Episode_Reward/pen_joint_torque: -0.2102
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0831
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2633
Episode_Reward/pen_flat_orientation: -0.1318
  Episode_Reward/pen_feet_distance: -0.0078
Episode_Reward/pen_feet_regulation: -0.3698
   Episode_Reward/foot_landing_vel: -0.1537
   Episode_Reward/test_gait_reward: -0.8868
Metrics/base_velocity/error_vel_xy: 1.5098
Metrics/base_velocity/error_vel_yaw: 1.2936
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 1.09s
                        Total time: 1121.07s
                               ETA: 2142.1s

################################################################################
                     [1m Learning iteration 1031/3000 [0m                     

                       Computation: 88443 steps/s (collection: 0.988s, learning 0.123s)
               Value function loss: 0.9959
                    Surrogate loss: -0.0050
             Mean action noise std: 0.9078
                     Learning rate: 0.0006
                       Mean reward: 101.75
               Mean episode length: 943.67
       Episode_Reward/keep_balance: 0.9376
     Episode_Reward/rew_lin_vel_xy: 4.7388
      Episode_Reward/rew_ang_vel_z: 2.2820
    Episode_Reward/pen_base_height: -0.3050
      Episode_Reward/pen_lin_vel_z: -0.0467
     Episode_Reward/pen_ang_vel_xy: -0.1927
   Episode_Reward/pen_joint_torque: -0.2116
    Episode_Reward/pen_joint_accel: -0.1122
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0839
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2626
Episode_Reward/pen_flat_orientation: -0.1328
  Episode_Reward/pen_feet_distance: -0.0093
Episode_Reward/pen_feet_regulation: -0.3752
   Episode_Reward/foot_landing_vel: -0.1463
   Episode_Reward/test_gait_reward: -0.8862
Metrics/base_velocity/error_vel_xy: 1.5424
Metrics/base_velocity/error_vel_yaw: 1.3181
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 1.11s
                        Total time: 1122.18s
                               ETA: 2141.1s

################################################################################
                     [1m Learning iteration 1032/3000 [0m                     

                       Computation: 91152 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.9490
                    Surrogate loss: -0.0018
             Mean action noise std: 0.9070
                     Learning rate: 0.0006
                       Mean reward: 103.72
               Mean episode length: 935.54
       Episode_Reward/keep_balance: 0.9421
     Episode_Reward/rew_lin_vel_xy: 4.8558
      Episode_Reward/rew_ang_vel_z: 2.3618
    Episode_Reward/pen_base_height: -0.3089
      Episode_Reward/pen_lin_vel_z: -0.0459
     Episode_Reward/pen_ang_vel_xy: -0.1916
   Episode_Reward/pen_joint_torque: -0.2211
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0839
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2585
Episode_Reward/pen_flat_orientation: -0.1304
  Episode_Reward/pen_feet_distance: -0.0104
Episode_Reward/pen_feet_regulation: -0.3610
   Episode_Reward/foot_landing_vel: -0.1451
   Episode_Reward/test_gait_reward: -0.8874
Metrics/base_velocity/error_vel_xy: 1.5019
Metrics/base_velocity/error_vel_yaw: 1.2567
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 1.08s
                        Total time: 1123.26s
                               ETA: 2139.9s

################################################################################
                     [1m Learning iteration 1033/3000 [0m                     

                       Computation: 90241 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.8849
                    Surrogate loss: -0.0024
             Mean action noise std: 0.9061
                     Learning rate: 0.0004
                       Mean reward: 95.28
               Mean episode length: 920.32
       Episode_Reward/keep_balance: 0.9341
     Episode_Reward/rew_lin_vel_xy: 4.6259
      Episode_Reward/rew_ang_vel_z: 2.3262
    Episode_Reward/pen_base_height: -0.3068
      Episode_Reward/pen_lin_vel_z: -0.0472
     Episode_Reward/pen_ang_vel_xy: -0.1846
   Episode_Reward/pen_joint_torque: -0.2198
    Episode_Reward/pen_joint_accel: -0.1190
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0846
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2546
Episode_Reward/pen_flat_orientation: -0.1313
  Episode_Reward/pen_feet_distance: -0.0090
Episode_Reward/pen_feet_regulation: -0.3600
   Episode_Reward/foot_landing_vel: -0.1506
   Episode_Reward/test_gait_reward: -0.8810
Metrics/base_velocity/error_vel_xy: 1.6135
Metrics/base_velocity/error_vel_yaw: 1.2532
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 1.09s
                        Total time: 1124.35s
                               ETA: 2138.9s

################################################################################
                     [1m Learning iteration 1034/3000 [0m                     

                       Computation: 91014 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.9689
                    Surrogate loss: -0.0053
             Mean action noise std: 0.9039
                     Learning rate: 0.0006
                       Mean reward: 106.95
               Mean episode length: 966.22
       Episode_Reward/keep_balance: 0.9725
     Episode_Reward/rew_lin_vel_xy: 5.1018
      Episode_Reward/rew_ang_vel_z: 2.3978
    Episode_Reward/pen_base_height: -0.3157
      Episode_Reward/pen_lin_vel_z: -0.0496
     Episode_Reward/pen_ang_vel_xy: -0.1978
   Episode_Reward/pen_joint_torque: -0.2256
    Episode_Reward/pen_joint_accel: -0.1192
    Episode_Reward/pen_action_rate: -0.1232
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2697
Episode_Reward/pen_flat_orientation: -0.1361
  Episode_Reward/pen_feet_distance: -0.0092
Episode_Reward/pen_feet_regulation: -0.3936
   Episode_Reward/foot_landing_vel: -0.1545
   Episode_Reward/test_gait_reward: -0.9224
Metrics/base_velocity/error_vel_xy: 1.4508
Metrics/base_velocity/error_vel_yaw: 1.3214
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 1.08s
                        Total time: 1125.43s
                               ETA: 2137.8s

################################################################################
                     [1m Learning iteration 1035/3000 [0m                     

                       Computation: 90897 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.9114
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9025
                     Learning rate: 0.0004
                       Mean reward: 103.67
               Mean episode length: 961.67
       Episode_Reward/keep_balance: 0.9632
     Episode_Reward/rew_lin_vel_xy: 4.9093
      Episode_Reward/rew_ang_vel_z: 2.3306
    Episode_Reward/pen_base_height: -0.3084
      Episode_Reward/pen_lin_vel_z: -0.0448
     Episode_Reward/pen_ang_vel_xy: -0.1961
   Episode_Reward/pen_joint_torque: -0.2105
    Episode_Reward/pen_joint_accel: -0.1222
    Episode_Reward/pen_action_rate: -0.1229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0848
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2724
Episode_Reward/pen_flat_orientation: -0.1357
  Episode_Reward/pen_feet_distance: -0.0089
Episode_Reward/pen_feet_regulation: -0.3800
   Episode_Reward/foot_landing_vel: -0.1505
   Episode_Reward/test_gait_reward: -0.9213
Metrics/base_velocity/error_vel_xy: 1.5667
Metrics/base_velocity/error_vel_yaw: 1.3692
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 1.08s
                        Total time: 1126.51s
                               ETA: 2136.7s

################################################################################
                     [1m Learning iteration 1036/3000 [0m                     

                       Computation: 91375 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.9742
                    Surrogate loss: -0.0030
             Mean action noise std: 0.9038
                     Learning rate: 0.0009
                       Mean reward: 108.03
               Mean episode length: 965.51
       Episode_Reward/keep_balance: 0.9541
     Episode_Reward/rew_lin_vel_xy: 4.8656
      Episode_Reward/rew_ang_vel_z: 2.3597
    Episode_Reward/pen_base_height: -0.2968
      Episode_Reward/pen_lin_vel_z: -0.0429
     Episode_Reward/pen_ang_vel_xy: -0.1918
   Episode_Reward/pen_joint_torque: -0.2078
    Episode_Reward/pen_joint_accel: -0.1228
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0819
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2644
Episode_Reward/pen_flat_orientation: -0.1288
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.3619
   Episode_Reward/foot_landing_vel: -0.1492
   Episode_Reward/test_gait_reward: -0.9049
Metrics/base_velocity/error_vel_xy: 1.5575
Metrics/base_velocity/error_vel_yaw: 1.2976
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 1.08s
                        Total time: 1127.58s
                               ETA: 2135.6s

################################################################################
                     [1m Learning iteration 1037/3000 [0m                     

                       Computation: 90440 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.9878
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9043
                     Learning rate: 0.0013
                       Mean reward: 101.92
               Mean episode length: 959.74
       Episode_Reward/keep_balance: 0.9697
     Episode_Reward/rew_lin_vel_xy: 4.7871
      Episode_Reward/rew_ang_vel_z: 2.3912
    Episode_Reward/pen_base_height: -0.3169
      Episode_Reward/pen_lin_vel_z: -0.0481
     Episode_Reward/pen_ang_vel_xy: -0.1949
   Episode_Reward/pen_joint_torque: -0.2318
    Episode_Reward/pen_joint_accel: -0.1189
    Episode_Reward/pen_action_rate: -0.1216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2671
Episode_Reward/pen_flat_orientation: -0.1307
  Episode_Reward/pen_feet_distance: -0.0085
Episode_Reward/pen_feet_regulation: -0.3762
   Episode_Reward/foot_landing_vel: -0.1493
   Episode_Reward/test_gait_reward: -0.9197
Metrics/base_velocity/error_vel_xy: 1.7361
Metrics/base_velocity/error_vel_yaw: 1.3188
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 1.09s
                        Total time: 1128.67s
                               ETA: 2134.5s

################################################################################
                     [1m Learning iteration 1038/3000 [0m                     

                       Computation: 89803 steps/s (collection: 0.969s, learning 0.126s)
               Value function loss: 1.0310
                    Surrogate loss: -0.0021
             Mean action noise std: 0.9039
                     Learning rate: 0.0006
                       Mean reward: 105.87
               Mean episode length: 954.96
       Episode_Reward/keep_balance: 0.9668
     Episode_Reward/rew_lin_vel_xy: 5.0513
      Episode_Reward/rew_ang_vel_z: 2.4393
    Episode_Reward/pen_base_height: -0.3086
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.1928
   Episode_Reward/pen_joint_torque: -0.2197
    Episode_Reward/pen_joint_accel: -0.1159
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0841
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2615
Episode_Reward/pen_flat_orientation: -0.1279
  Episode_Reward/pen_feet_distance: -0.0140
Episode_Reward/pen_feet_regulation: -0.3645
   Episode_Reward/foot_landing_vel: -0.1470
   Episode_Reward/test_gait_reward: -0.9147
Metrics/base_velocity/error_vel_xy: 1.5076
Metrics/base_velocity/error_vel_yaw: 1.2593
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 1.09s
                        Total time: 1129.76s
                               ETA: 2133.4s

################################################################################
                     [1m Learning iteration 1039/3000 [0m                     

                       Computation: 90846 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.8990
                    Surrogate loss: -0.0030
             Mean action noise std: 0.9038
                     Learning rate: 0.0006
                       Mean reward: 102.89
               Mean episode length: 943.89
       Episode_Reward/keep_balance: 0.9383
     Episode_Reward/rew_lin_vel_xy: 4.8418
      Episode_Reward/rew_ang_vel_z: 2.3039
    Episode_Reward/pen_base_height: -0.2953
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.1879
   Episode_Reward/pen_joint_torque: -0.2052
    Episode_Reward/pen_joint_accel: -0.1162
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0541
   Episode_Reward/pen_joint_powers: -0.0815
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2582
Episode_Reward/pen_flat_orientation: -0.1300
  Episode_Reward/pen_feet_distance: -0.0105
Episode_Reward/pen_feet_regulation: -0.3630
   Episode_Reward/foot_landing_vel: -0.1426
   Episode_Reward/test_gait_reward: -0.8947
Metrics/base_velocity/error_vel_xy: 1.4653
Metrics/base_velocity/error_vel_yaw: 1.2867
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 1.08s
                        Total time: 1130.85s
                               ETA: 2132.3s

################################################################################
                     [1m Learning iteration 1040/3000 [0m                     

                       Computation: 90687 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.9950
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9043
                     Learning rate: 0.0003
                       Mean reward: 103.56
               Mean episode length: 951.32
       Episode_Reward/keep_balance: 0.9624
     Episode_Reward/rew_lin_vel_xy: 4.8798
      Episode_Reward/rew_ang_vel_z: 2.3723
    Episode_Reward/pen_base_height: -0.3027
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.1928
   Episode_Reward/pen_joint_torque: -0.2129
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0827
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2675
Episode_Reward/pen_flat_orientation: -0.1190
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3509
   Episode_Reward/foot_landing_vel: -0.1444
   Episode_Reward/test_gait_reward: -0.9024
Metrics/base_velocity/error_vel_xy: 1.5964
Metrics/base_velocity/error_vel_yaw: 1.3126
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 1.08s
                        Total time: 1131.93s
                               ETA: 2131.2s

################################################################################
                     [1m Learning iteration 1041/3000 [0m                     

                       Computation: 90835 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.9256
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9039
                     Learning rate: 0.0004
                       Mean reward: 96.61
               Mean episode length: 957.46
       Episode_Reward/keep_balance: 0.9625
     Episode_Reward/rew_lin_vel_xy: 4.5170
      Episode_Reward/rew_ang_vel_z: 2.3470
    Episode_Reward/pen_base_height: -0.3234
      Episode_Reward/pen_lin_vel_z: -0.0474
     Episode_Reward/pen_ang_vel_xy: -0.1959
   Episode_Reward/pen_joint_torque: -0.2271
    Episode_Reward/pen_joint_accel: -0.1123
    Episode_Reward/pen_action_rate: -0.1225
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2689
Episode_Reward/pen_flat_orientation: -0.1358
  Episode_Reward/pen_feet_distance: -0.0124
Episode_Reward/pen_feet_regulation: -0.3920
   Episode_Reward/foot_landing_vel: -0.1510
   Episode_Reward/test_gait_reward: -0.9092
Metrics/base_velocity/error_vel_xy: 1.8494
Metrics/base_velocity/error_vel_yaw: 1.3433
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 1.08s
                        Total time: 1133.01s
                               ETA: 2130.1s

################################################################################
                     [1m Learning iteration 1042/3000 [0m                     

                       Computation: 89293 steps/s (collection: 0.977s, learning 0.124s)
               Value function loss: 0.8671
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9049
                     Learning rate: 0.0006
                       Mean reward: 105.70
               Mean episode length: 944.96
       Episode_Reward/keep_balance: 0.9479
     Episode_Reward/rew_lin_vel_xy: 4.9210
      Episode_Reward/rew_ang_vel_z: 2.3614
    Episode_Reward/pen_base_height: -0.3091
      Episode_Reward/pen_lin_vel_z: -0.0440
     Episode_Reward/pen_ang_vel_xy: -0.1867
   Episode_Reward/pen_joint_torque: -0.2092
    Episode_Reward/pen_joint_accel: -0.1106
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0824
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2599
Episode_Reward/pen_flat_orientation: -0.1327
  Episode_Reward/pen_feet_distance: -0.0108
Episode_Reward/pen_feet_regulation: -0.3646
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.8946
Metrics/base_velocity/error_vel_xy: 1.4808
Metrics/base_velocity/error_vel_yaw: 1.2727
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 1.10s
                        Total time: 1134.11s
                               ETA: 2129.0s

################################################################################
                     [1m Learning iteration 1043/3000 [0m                     

                       Computation: 90047 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.8872
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9062
                     Learning rate: 0.0009
                       Mean reward: 107.85
               Mean episode length: 975.55
       Episode_Reward/keep_balance: 0.9739
     Episode_Reward/rew_lin_vel_xy: 5.1507
      Episode_Reward/rew_ang_vel_z: 2.4057
    Episode_Reward/pen_base_height: -0.3160
      Episode_Reward/pen_lin_vel_z: -0.0483
     Episode_Reward/pen_ang_vel_xy: -0.2006
   Episode_Reward/pen_joint_torque: -0.2251
    Episode_Reward/pen_joint_accel: -0.1294
    Episode_Reward/pen_action_rate: -0.1243
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2739
Episode_Reward/pen_flat_orientation: -0.1250
  Episode_Reward/pen_feet_distance: -0.0090
Episode_Reward/pen_feet_regulation: -0.3985
   Episode_Reward/foot_landing_vel: -0.1546
   Episode_Reward/test_gait_reward: -0.9224
Metrics/base_velocity/error_vel_xy: 1.4261
Metrics/base_velocity/error_vel_yaw: 1.3267
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 1.09s
                        Total time: 1135.20s
                               ETA: 2128.0s

################################################################################
                     [1m Learning iteration 1044/3000 [0m                     

                       Computation: 90275 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.9348
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9076
                     Learning rate: 0.0004
                       Mean reward: 100.10
               Mean episode length: 943.83
       Episode_Reward/keep_balance: 0.9384
     Episode_Reward/rew_lin_vel_xy: 4.6147
      Episode_Reward/rew_ang_vel_z: 2.2264
    Episode_Reward/pen_base_height: -0.3019
      Episode_Reward/pen_lin_vel_z: -0.0429
     Episode_Reward/pen_ang_vel_xy: -0.1982
   Episode_Reward/pen_joint_torque: -0.2061
    Episode_Reward/pen_joint_accel: -0.1326
    Episode_Reward/pen_action_rate: -0.1217
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0849
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2687
Episode_Reward/pen_flat_orientation: -0.1301
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.3819
   Episode_Reward/foot_landing_vel: -0.1586
   Episode_Reward/test_gait_reward: -0.8888
Metrics/base_velocity/error_vel_xy: 1.6419
Metrics/base_velocity/error_vel_yaw: 1.3699
      Episode_Termination/time_out: 3.0833
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 1.09s
                        Total time: 1136.29s
                               ETA: 2126.9s

################################################################################
                     [1m Learning iteration 1045/3000 [0m                     

                       Computation: 89979 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.9807
                    Surrogate loss: -0.0028
             Mean action noise std: 0.9088
                     Learning rate: 0.0004
                       Mean reward: 105.25
               Mean episode length: 937.27
       Episode_Reward/keep_balance: 0.9296
     Episode_Reward/rew_lin_vel_xy: 4.7685
      Episode_Reward/rew_ang_vel_z: 2.2889
    Episode_Reward/pen_base_height: -0.2921
      Episode_Reward/pen_lin_vel_z: -0.0428
     Episode_Reward/pen_ang_vel_xy: -0.1832
   Episode_Reward/pen_joint_torque: -0.2122
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.1149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0524
   Episode_Reward/pen_joint_powers: -0.0811
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2549
Episode_Reward/pen_flat_orientation: -0.1199
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.3351
   Episode_Reward/foot_landing_vel: -0.1320
   Episode_Reward/test_gait_reward: -0.8780
Metrics/base_velocity/error_vel_xy: 1.4686
Metrics/base_velocity/error_vel_yaw: 1.2718
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 1.09s
                        Total time: 1137.39s
                               ETA: 2125.8s

################################################################################
                     [1m Learning iteration 1046/3000 [0m                     

                       Computation: 89708 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.9334
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9101
                     Learning rate: 0.0006
                       Mean reward: 105.08
               Mean episode length: 959.23
       Episode_Reward/keep_balance: 0.9630
     Episode_Reward/rew_lin_vel_xy: 4.8762
      Episode_Reward/rew_ang_vel_z: 2.3860
    Episode_Reward/pen_base_height: -0.3083
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.1939
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.1170
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0855
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2659
Episode_Reward/pen_flat_orientation: -0.1278
  Episode_Reward/pen_feet_distance: -0.0092
Episode_Reward/pen_feet_regulation: -0.3693
   Episode_Reward/foot_landing_vel: -0.1472
   Episode_Reward/test_gait_reward: -0.9059
Metrics/base_velocity/error_vel_xy: 1.6142
Metrics/base_velocity/error_vel_yaw: 1.3181
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 1.10s
                        Total time: 1138.48s
                               ETA: 2124.7s

################################################################################
                     [1m Learning iteration 1047/3000 [0m                     

                       Computation: 89646 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.9602
                    Surrogate loss: -0.0001
             Mean action noise std: 0.9108
                     Learning rate: 0.0002
                       Mean reward: 107.23
               Mean episode length: 957.17
       Episode_Reward/keep_balance: 0.9640
     Episode_Reward/rew_lin_vel_xy: 4.9419
      Episode_Reward/rew_ang_vel_z: 2.3872
    Episode_Reward/pen_base_height: -0.2970
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.1930
   Episode_Reward/pen_joint_torque: -0.2152
    Episode_Reward/pen_joint_accel: -0.1169
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0847
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2655
Episode_Reward/pen_flat_orientation: -0.1255
  Episode_Reward/pen_feet_distance: -0.0082
Episode_Reward/pen_feet_regulation: -0.3735
   Episode_Reward/foot_landing_vel: -0.1466
   Episode_Reward/test_gait_reward: -0.9119
Metrics/base_velocity/error_vel_xy: 1.5159
Metrics/base_velocity/error_vel_yaw: 1.3030
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 1.10s
                        Total time: 1139.58s
                               ETA: 2123.7s

################################################################################
                     [1m Learning iteration 1048/3000 [0m                     

                       Computation: 88611 steps/s (collection: 0.986s, learning 0.123s)
               Value function loss: 0.7951
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9110
                     Learning rate: 0.0003
                       Mean reward: 111.13
               Mean episode length: 970.67
       Episode_Reward/keep_balance: 0.9651
     Episode_Reward/rew_lin_vel_xy: 5.0864
      Episode_Reward/rew_ang_vel_z: 2.4326
    Episode_Reward/pen_base_height: -0.2947
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.1862
   Episode_Reward/pen_joint_torque: -0.2130
    Episode_Reward/pen_joint_accel: -0.1127
    Episode_Reward/pen_action_rate: -0.1177
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0533
   Episode_Reward/pen_joint_powers: -0.0812
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2633
Episode_Reward/pen_flat_orientation: -0.1156
  Episode_Reward/pen_feet_distance: -0.0084
Episode_Reward/pen_feet_regulation: -0.3511
   Episode_Reward/foot_landing_vel: -0.1473
   Episode_Reward/test_gait_reward: -0.9005
Metrics/base_velocity/error_vel_xy: 1.4858
Metrics/base_velocity/error_vel_yaw: 1.2616
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 1.11s
                        Total time: 1140.69s
                               ETA: 2122.6s

################################################################################
                     [1m Learning iteration 1049/3000 [0m                     

                       Computation: 90122 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 1.0137
                    Surrogate loss: -0.0056
             Mean action noise std: 0.9134
                     Learning rate: 0.0006
                       Mean reward: 105.47
               Mean episode length: 965.90
       Episode_Reward/keep_balance: 0.9687
     Episode_Reward/rew_lin_vel_xy: 4.8742
      Episode_Reward/rew_ang_vel_z: 2.3691
    Episode_Reward/pen_base_height: -0.3095
      Episode_Reward/pen_lin_vel_z: -0.0452
     Episode_Reward/pen_ang_vel_xy: -0.1962
   Episode_Reward/pen_joint_torque: -0.2183
    Episode_Reward/pen_joint_accel: -0.1219
    Episode_Reward/pen_action_rate: -0.1224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2688
Episode_Reward/pen_flat_orientation: -0.1286
  Episode_Reward/pen_feet_distance: -0.0119
Episode_Reward/pen_feet_regulation: -0.3709
   Episode_Reward/foot_landing_vel: -0.1541
   Episode_Reward/test_gait_reward: -0.9216
Metrics/base_velocity/error_vel_xy: 1.6069
Metrics/base_velocity/error_vel_yaw: 1.3413
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 1.09s
                        Total time: 1141.78s
                               ETA: 2121.5s

################################################################################
                     [1m Learning iteration 1050/3000 [0m                     

                       Computation: 90571 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.9681
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9155
                     Learning rate: 0.0006
                       Mean reward: 101.72
               Mean episode length: 935.06
       Episode_Reward/keep_balance: 0.9359
     Episode_Reward/rew_lin_vel_xy: 4.8379
      Episode_Reward/rew_ang_vel_z: 2.2737
    Episode_Reward/pen_base_height: -0.2978
      Episode_Reward/pen_lin_vel_z: -0.0441
     Episode_Reward/pen_ang_vel_xy: -0.1916
   Episode_Reward/pen_joint_torque: -0.2111
    Episode_Reward/pen_joint_accel: -0.1147
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0838
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2621
Episode_Reward/pen_flat_orientation: -0.1245
  Episode_Reward/pen_feet_distance: -0.0106
Episode_Reward/pen_feet_regulation: -0.3719
   Episode_Reward/foot_landing_vel: -0.1437
   Episode_Reward/test_gait_reward: -0.8886
Metrics/base_velocity/error_vel_xy: 1.4883
Metrics/base_velocity/error_vel_yaw: 1.3117
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 1.09s
                        Total time: 1142.86s
                               ETA: 2120.4s

################################################################################
                     [1m Learning iteration 1051/3000 [0m                     

                       Computation: 91787 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 1.0227
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9165
                     Learning rate: 0.0006
                       Mean reward: 106.65
               Mean episode length: 963.10
       Episode_Reward/keep_balance: 0.9640
     Episode_Reward/rew_lin_vel_xy: 4.9991
      Episode_Reward/rew_ang_vel_z: 2.3790
    Episode_Reward/pen_base_height: -0.3060
      Episode_Reward/pen_lin_vel_z: -0.0456
     Episode_Reward/pen_ang_vel_xy: -0.1963
   Episode_Reward/pen_joint_torque: -0.2202
    Episode_Reward/pen_joint_accel: -0.1072
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2669
Episode_Reward/pen_flat_orientation: -0.1250
  Episode_Reward/pen_feet_distance: -0.0139
Episode_Reward/pen_feet_regulation: -0.3714
   Episode_Reward/foot_landing_vel: -0.1492
   Episode_Reward/test_gait_reward: -0.9157
Metrics/base_velocity/error_vel_xy: 1.5303
Metrics/base_velocity/error_vel_yaw: 1.3177
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 1.07s
                        Total time: 1143.94s
                               ETA: 2119.3s

################################################################################
                     [1m Learning iteration 1052/3000 [0m                     

                       Computation: 90455 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.8424
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9156
                     Learning rate: 0.0004
                       Mean reward: 104.32
               Mean episode length: 951.29
       Episode_Reward/keep_balance: 0.9557
     Episode_Reward/rew_lin_vel_xy: 4.9243
      Episode_Reward/rew_ang_vel_z: 2.3622
    Episode_Reward/pen_base_height: -0.3054
      Episode_Reward/pen_lin_vel_z: -0.0454
     Episode_Reward/pen_ang_vel_xy: -0.1902
   Episode_Reward/pen_joint_torque: -0.2127
    Episode_Reward/pen_joint_accel: -0.1104
    Episode_Reward/pen_action_rate: -0.1190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0843
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2639
Episode_Reward/pen_flat_orientation: -0.1293
  Episode_Reward/pen_feet_distance: -0.0109
Episode_Reward/pen_feet_regulation: -0.3683
   Episode_Reward/foot_landing_vel: -0.1516
   Episode_Reward/test_gait_reward: -0.9039
Metrics/base_velocity/error_vel_xy: 1.5118
Metrics/base_velocity/error_vel_yaw: 1.3108
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 1.09s
                        Total time: 1145.02s
                               ETA: 2118.2s

################################################################################
                     [1m Learning iteration 1053/3000 [0m                     

                       Computation: 84023 steps/s (collection: 1.047s, learning 0.123s)
               Value function loss: 0.8951
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9181
                     Learning rate: 0.0006
                       Mean reward: 103.10
               Mean episode length: 919.27
       Episode_Reward/keep_balance: 0.8960
     Episode_Reward/rew_lin_vel_xy: 4.7209
      Episode_Reward/rew_ang_vel_z: 2.2033
    Episode_Reward/pen_base_height: -0.2917
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.1848
   Episode_Reward/pen_joint_torque: -0.1996
    Episode_Reward/pen_joint_accel: -0.1009
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0520
   Episode_Reward/pen_joint_powers: -0.0791
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2481
Episode_Reward/pen_flat_orientation: -0.1242
  Episode_Reward/pen_feet_distance: -0.0098
Episode_Reward/pen_feet_regulation: -0.3507
   Episode_Reward/foot_landing_vel: -0.1341
   Episode_Reward/test_gait_reward: -0.8453
Metrics/base_velocity/error_vel_xy: 1.3685
Metrics/base_velocity/error_vel_yaw: 1.2279
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 1.17s
                        Total time: 1146.19s
                               ETA: 2117.3s

################################################################################
                     [1m Learning iteration 1054/3000 [0m                     

                       Computation: 90557 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 1.0994
                    Surrogate loss: -0.0051
             Mean action noise std: 0.9178
                     Learning rate: 0.0009
                       Mean reward: 99.96
               Mean episode length: 908.19
       Episode_Reward/keep_balance: 0.9178
     Episode_Reward/rew_lin_vel_xy: 4.6478
      Episode_Reward/rew_ang_vel_z: 2.2910
    Episode_Reward/pen_base_height: -0.2932
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.1830
   Episode_Reward/pen_joint_torque: -0.2096
    Episode_Reward/pen_joint_accel: -0.1070
    Episode_Reward/pen_action_rate: -0.1140
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0530
   Episode_Reward/pen_joint_powers: -0.0809
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2517
Episode_Reward/pen_flat_orientation: -0.1212
  Episode_Reward/pen_feet_distance: -0.0113
Episode_Reward/pen_feet_regulation: -0.3447
   Episode_Reward/foot_landing_vel: -0.1400
   Episode_Reward/test_gait_reward: -0.8687
Metrics/base_velocity/error_vel_xy: 1.5349
Metrics/base_velocity/error_vel_yaw: 1.2343
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 1.09s
                        Total time: 1147.28s
                               ETA: 2116.2s

################################################################################
                     [1m Learning iteration 1055/3000 [0m                     

                       Computation: 91170 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.0070
                    Surrogate loss: -0.0015
             Mean action noise std: 0.9166
                     Learning rate: 0.0004
                       Mean reward: 103.74
               Mean episode length: 943.76
       Episode_Reward/keep_balance: 0.9563
     Episode_Reward/rew_lin_vel_xy: 4.8939
      Episode_Reward/rew_ang_vel_z: 2.3647
    Episode_Reward/pen_base_height: -0.3036
      Episode_Reward/pen_lin_vel_z: -0.0456
     Episode_Reward/pen_ang_vel_xy: -0.1952
   Episode_Reward/pen_joint_torque: -0.2163
    Episode_Reward/pen_joint_accel: -0.1207
    Episode_Reward/pen_action_rate: -0.1212
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2674
Episode_Reward/pen_flat_orientation: -0.1298
  Episode_Reward/pen_feet_distance: -0.0127
Episode_Reward/pen_feet_regulation: -0.3809
   Episode_Reward/foot_landing_vel: -0.1469
   Episode_Reward/test_gait_reward: -0.8989
Metrics/base_velocity/error_vel_xy: 1.5366
Metrics/base_velocity/error_vel_yaw: 1.3064
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 1.08s
                        Total time: 1148.36s
                               ETA: 2115.1s

################################################################################
                     [1m Learning iteration 1056/3000 [0m                     

                       Computation: 89628 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.9166
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9145
                     Learning rate: 0.0006
                       Mean reward: 97.23
               Mean episode length: 920.46
       Episode_Reward/keep_balance: 0.9296
     Episode_Reward/rew_lin_vel_xy: 4.6474
      Episode_Reward/rew_ang_vel_z: 2.2458
    Episode_Reward/pen_base_height: -0.3025
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.1948
   Episode_Reward/pen_joint_torque: -0.2038
    Episode_Reward/pen_joint_accel: -0.1107
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0830
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2656
Episode_Reward/pen_flat_orientation: -0.1266
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.3796
   Episode_Reward/foot_landing_vel: -0.1574
   Episode_Reward/test_gait_reward: -0.8761
Metrics/base_velocity/error_vel_xy: 1.5483
Metrics/base_velocity/error_vel_yaw: 1.3247
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 1.10s
                        Total time: 1149.45s
                               ETA: 2114.0s

################################################################################
                     [1m Learning iteration 1057/3000 [0m                     

                       Computation: 91816 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 0.8908
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9142
                     Learning rate: 0.0006
                       Mean reward: 101.52
               Mean episode length: 927.92
       Episode_Reward/keep_balance: 0.9426
     Episode_Reward/rew_lin_vel_xy: 4.9275
      Episode_Reward/rew_ang_vel_z: 2.3160
    Episode_Reward/pen_base_height: -0.2981
      Episode_Reward/pen_lin_vel_z: -0.0472
     Episode_Reward/pen_ang_vel_xy: -0.1928
   Episode_Reward/pen_joint_torque: -0.2156
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0853
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2642
Episode_Reward/pen_flat_orientation: -0.1219
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3799
   Episode_Reward/foot_landing_vel: -0.1590
   Episode_Reward/test_gait_reward: -0.8883
Metrics/base_velocity/error_vel_xy: 1.5071
Metrics/base_velocity/error_vel_yaw: 1.2962
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 1.07s
                        Total time: 1150.52s
                               ETA: 2112.9s

################################################################################
                     [1m Learning iteration 1058/3000 [0m                     

                       Computation: 89116 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.9120
                    Surrogate loss: -0.0018
             Mean action noise std: 0.9141
                     Learning rate: 0.0003
                       Mean reward: 106.17
               Mean episode length: 965.22
       Episode_Reward/keep_balance: 0.9641
     Episode_Reward/rew_lin_vel_xy: 4.9749
      Episode_Reward/rew_ang_vel_z: 2.3482
    Episode_Reward/pen_base_height: -0.3081
      Episode_Reward/pen_lin_vel_z: -0.0461
     Episode_Reward/pen_ang_vel_xy: -0.1978
   Episode_Reward/pen_joint_torque: -0.2156
    Episode_Reward/pen_joint_accel: -0.1177
    Episode_Reward/pen_action_rate: -0.1234
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2722
Episode_Reward/pen_flat_orientation: -0.1284
  Episode_Reward/pen_feet_distance: -0.0099
Episode_Reward/pen_feet_regulation: -0.3953
   Episode_Reward/foot_landing_vel: -0.1564
   Episode_Reward/test_gait_reward: -0.9188
Metrics/base_velocity/error_vel_xy: 1.5270
Metrics/base_velocity/error_vel_yaw: 1.3552
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 1.10s
                        Total time: 1151.63s
                               ETA: 2111.9s

################################################################################
                     [1m Learning iteration 1059/3000 [0m                     

                       Computation: 89217 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.9706
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9144
                     Learning rate: 0.0004
                       Mean reward: 100.83
               Mean episode length: 939.11
       Episode_Reward/keep_balance: 0.9299
     Episode_Reward/rew_lin_vel_xy: 4.7112
      Episode_Reward/rew_ang_vel_z: 2.2843
    Episode_Reward/pen_base_height: -0.3103
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.1912
   Episode_Reward/pen_joint_torque: -0.2088
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0831
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2616
Episode_Reward/pen_flat_orientation: -0.1280
  Episode_Reward/pen_feet_distance: -0.0162
Episode_Reward/pen_feet_regulation: -0.3727
   Episode_Reward/foot_landing_vel: -0.1367
   Episode_Reward/test_gait_reward: -0.8789
Metrics/base_velocity/error_vel_xy: 1.5247
Metrics/base_velocity/error_vel_yaw: 1.2824
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 1.10s
                        Total time: 1152.73s
                               ETA: 2110.8s

################################################################################
                     [1m Learning iteration 1060/3000 [0m                     

                       Computation: 87463 steps/s (collection: 0.999s, learning 0.124s)
               Value function loss: 0.9334
                    Surrogate loss: 0.0017
             Mean action noise std: 0.9144
                     Learning rate: 0.0001
                       Mean reward: 92.88
               Mean episode length: 898.50
       Episode_Reward/keep_balance: 0.8761
     Episode_Reward/rew_lin_vel_xy: 4.4110
      Episode_Reward/rew_ang_vel_z: 2.1150
    Episode_Reward/pen_base_height: -0.3060
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1905
   Episode_Reward/pen_joint_torque: -0.1988
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.1156
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0822
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2544
Episode_Reward/pen_flat_orientation: -0.1308
  Episode_Reward/pen_feet_distance: -0.0115
Episode_Reward/pen_feet_regulation: -0.3828
   Episode_Reward/foot_landing_vel: -0.1503
   Episode_Reward/test_gait_reward: -0.8370
Metrics/base_velocity/error_vel_xy: 1.4301
Metrics/base_velocity/error_vel_yaw: 1.2658
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 1.12s
                        Total time: 1153.85s
                               ETA: 2109.8s

################################################################################
                     [1m Learning iteration 1061/3000 [0m                     

                       Computation: 88520 steps/s (collection: 0.987s, learning 0.124s)
               Value function loss: 0.9810
                    Surrogate loss: -0.0053
             Mean action noise std: 0.9133
                     Learning rate: 0.0003
                       Mean reward: 103.73
               Mean episode length: 930.41
       Episode_Reward/keep_balance: 0.9336
     Episode_Reward/rew_lin_vel_xy: 4.9291
      Episode_Reward/rew_ang_vel_z: 2.2991
    Episode_Reward/pen_base_height: -0.2991
      Episode_Reward/pen_lin_vel_z: -0.0437
     Episode_Reward/pen_ang_vel_xy: -0.1954
   Episode_Reward/pen_joint_torque: -0.2168
    Episode_Reward/pen_joint_accel: -0.1142
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2619
Episode_Reward/pen_flat_orientation: -0.1264
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.3822
   Episode_Reward/foot_landing_vel: -0.1512
   Episode_Reward/test_gait_reward: -0.8831
Metrics/base_velocity/error_vel_xy: 1.4183
Metrics/base_velocity/error_vel_yaw: 1.2900
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 1.11s
                        Total time: 1154.96s
                               ETA: 2108.7s

################################################################################
                     [1m Learning iteration 1062/3000 [0m                     

                       Computation: 89790 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.8596
                    Surrogate loss: -0.0052
             Mean action noise std: 0.9137
                     Learning rate: 0.0006
                       Mean reward: 101.74
               Mean episode length: 915.76
       Episode_Reward/keep_balance: 0.9175
     Episode_Reward/rew_lin_vel_xy: 4.7498
      Episode_Reward/rew_ang_vel_z: 2.2387
    Episode_Reward/pen_base_height: -0.3005
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.1877
   Episode_Reward/pen_joint_torque: -0.2080
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0822
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2585
Episode_Reward/pen_flat_orientation: -0.1272
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.3756
   Episode_Reward/foot_landing_vel: -0.1389
   Episode_Reward/test_gait_reward: -0.8699
Metrics/base_velocity/error_vel_xy: 1.4520
Metrics/base_velocity/error_vel_yaw: 1.2875
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 1.09s
                        Total time: 1156.06s
                               ETA: 2107.7s

################################################################################
                     [1m Learning iteration 1063/3000 [0m                     

                       Computation: 89411 steps/s (collection: 0.975s, learning 0.125s)
               Value function loss: 0.8805
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9166
                     Learning rate: 0.0009
                       Mean reward: 107.09
               Mean episode length: 975.01
       Episode_Reward/keep_balance: 0.9755
     Episode_Reward/rew_lin_vel_xy: 5.0775
      Episode_Reward/rew_ang_vel_z: 2.4005
    Episode_Reward/pen_base_height: -0.3112
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.1939
   Episode_Reward/pen_joint_torque: -0.2218
    Episode_Reward/pen_joint_accel: -0.1262
    Episode_Reward/pen_action_rate: -0.1245
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0597
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2746
Episode_Reward/pen_flat_orientation: -0.1270
  Episode_Reward/pen_feet_distance: -0.0118
Episode_Reward/pen_feet_regulation: -0.4054
   Episode_Reward/foot_landing_vel: -0.1634
   Episode_Reward/test_gait_reward: -0.9251
Metrics/base_velocity/error_vel_xy: 1.5021
Metrics/base_velocity/error_vel_yaw: 1.3459
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 1.10s
                        Total time: 1157.16s
                               ETA: 2106.6s

################################################################################
                     [1m Learning iteration 1064/3000 [0m                     

                       Computation: 91772 steps/s (collection: 0.947s, learning 0.124s)
               Value function loss: 0.8652
                    Surrogate loss: -0.0039
             Mean action noise std: 0.9156
                     Learning rate: 0.0009
                       Mean reward: 107.21
               Mean episode length: 957.15
       Episode_Reward/keep_balance: 0.9550
     Episode_Reward/rew_lin_vel_xy: 5.0603
      Episode_Reward/rew_ang_vel_z: 2.3534
    Episode_Reward/pen_base_height: -0.2962
      Episode_Reward/pen_lin_vel_z: -0.0415
     Episode_Reward/pen_ang_vel_xy: -0.1940
   Episode_Reward/pen_joint_torque: -0.2126
    Episode_Reward/pen_joint_accel: -0.1058
    Episode_Reward/pen_action_rate: -0.1201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0847
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2667
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0117
Episode_Reward/pen_feet_regulation: -0.3691
   Episode_Reward/foot_landing_vel: -0.1352
   Episode_Reward/test_gait_reward: -0.9020
Metrics/base_velocity/error_vel_xy: 1.4271
Metrics/base_velocity/error_vel_yaw: 1.3065
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 1.07s
                        Total time: 1158.23s
                               ETA: 2105.5s

################################################################################
                     [1m Learning iteration 1065/3000 [0m                     

                       Computation: 90896 steps/s (collection: 0.956s, learning 0.126s)
               Value function loss: 0.9266
                    Surrogate loss: -0.0028
             Mean action noise std: 0.9160
                     Learning rate: 0.0009
                       Mean reward: 106.21
               Mean episode length: 974.18
       Episode_Reward/keep_balance: 0.9790
     Episode_Reward/rew_lin_vel_xy: 5.0303
      Episode_Reward/rew_ang_vel_z: 2.3726
    Episode_Reward/pen_base_height: -0.3081
      Episode_Reward/pen_lin_vel_z: -0.0459
     Episode_Reward/pen_ang_vel_xy: -0.1984
   Episode_Reward/pen_joint_torque: -0.2214
    Episode_Reward/pen_joint_accel: -0.1244
    Episode_Reward/pen_action_rate: -0.1258
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0595
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2775
Episode_Reward/pen_flat_orientation: -0.1282
  Episode_Reward/pen_feet_distance: -0.0107
Episode_Reward/pen_feet_regulation: -0.4060
   Episode_Reward/foot_landing_vel: -0.1526
   Episode_Reward/test_gait_reward: -0.9311
Metrics/base_velocity/error_vel_xy: 1.5817
Metrics/base_velocity/error_vel_yaw: 1.3884
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 1.08s
                        Total time: 1159.31s
                               ETA: 2104.4s

################################################################################
                     [1m Learning iteration 1066/3000 [0m                     

                       Computation: 88855 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 0.9134
                    Surrogate loss: -0.0026
             Mean action noise std: 0.9168
                     Learning rate: 0.0004
                       Mean reward: 108.06
               Mean episode length: 957.87
       Episode_Reward/keep_balance: 0.9398
     Episode_Reward/rew_lin_vel_xy: 5.0265
      Episode_Reward/rew_ang_vel_z: 2.2846
    Episode_Reward/pen_base_height: -0.3048
      Episode_Reward/pen_lin_vel_z: -0.0446
     Episode_Reward/pen_ang_vel_xy: -0.1964
   Episode_Reward/pen_joint_torque: -0.2095
    Episode_Reward/pen_joint_accel: -0.1111
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0856
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2680
Episode_Reward/pen_flat_orientation: -0.1308
  Episode_Reward/pen_feet_distance: -0.0094
Episode_Reward/pen_feet_regulation: -0.3937
   Episode_Reward/foot_landing_vel: -0.1485
   Episode_Reward/test_gait_reward: -0.8958
Metrics/base_velocity/error_vel_xy: 1.3669
Metrics/base_velocity/error_vel_yaw: 1.3188
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 1.11s
                        Total time: 1160.42s
                               ETA: 2103.3s

################################################################################
                     [1m Learning iteration 1067/3000 [0m                     

                       Computation: 89338 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 0.9207
                    Surrogate loss: -0.0011
             Mean action noise std: 0.9187
                     Learning rate: 0.0003
                       Mean reward: 103.71
               Mean episode length: 949.62
       Episode_Reward/keep_balance: 0.9610
     Episode_Reward/rew_lin_vel_xy: 4.9313
      Episode_Reward/rew_ang_vel_z: 2.3819
    Episode_Reward/pen_base_height: -0.3047
      Episode_Reward/pen_lin_vel_z: -0.0464
     Episode_Reward/pen_ang_vel_xy: -0.1969
   Episode_Reward/pen_joint_torque: -0.2257
    Episode_Reward/pen_joint_accel: -0.1271
    Episode_Reward/pen_action_rate: -0.1225
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2696
Episode_Reward/pen_flat_orientation: -0.1194
  Episode_Reward/pen_feet_distance: -0.0123
Episode_Reward/pen_feet_regulation: -0.3806
   Episode_Reward/foot_landing_vel: -0.1543
   Episode_Reward/test_gait_reward: -0.9083
Metrics/base_velocity/error_vel_xy: 1.6685
Metrics/base_velocity/error_vel_yaw: 1.3062
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 1.10s
                        Total time: 1161.52s
                               ETA: 2102.3s

################################################################################
                     [1m Learning iteration 1068/3000 [0m                     

                       Computation: 88803 steps/s (collection: 0.981s, learning 0.126s)
               Value function loss: 0.8863
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9205
                     Learning rate: 0.0006
                       Mean reward: 106.10
               Mean episode length: 942.41
       Episode_Reward/keep_balance: 0.9457
     Episode_Reward/rew_lin_vel_xy: 5.0004
      Episode_Reward/rew_ang_vel_z: 2.3433
    Episode_Reward/pen_base_height: -0.3097
      Episode_Reward/pen_lin_vel_z: -0.0437
     Episode_Reward/pen_ang_vel_xy: -0.1912
   Episode_Reward/pen_joint_torque: -0.2104
    Episode_Reward/pen_joint_accel: -0.1159
    Episode_Reward/pen_action_rate: -0.1205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0844
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2660
Episode_Reward/pen_flat_orientation: -0.1270
  Episode_Reward/pen_feet_distance: -0.0134
Episode_Reward/pen_feet_regulation: -0.3784
   Episode_Reward/foot_landing_vel: -0.1490
   Episode_Reward/test_gait_reward: -0.8987
Metrics/base_velocity/error_vel_xy: 1.4032
Metrics/base_velocity/error_vel_yaw: 1.2908
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 1.11s
                        Total time: 1162.62s
                               ETA: 2101.2s

################################################################################
                     [1m Learning iteration 1069/3000 [0m                     

                       Computation: 89157 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.9161
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9216
                     Learning rate: 0.0006
                       Mean reward: 103.38
               Mean episode length: 949.09
       Episode_Reward/keep_balance: 0.9370
     Episode_Reward/rew_lin_vel_xy: 4.9425
      Episode_Reward/rew_ang_vel_z: 2.2663
    Episode_Reward/pen_base_height: -0.3001
      Episode_Reward/pen_lin_vel_z: -0.0430
     Episode_Reward/pen_ang_vel_xy: -0.1985
   Episode_Reward/pen_joint_torque: -0.2053
    Episode_Reward/pen_joint_accel: -0.1102
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0835
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2706
Episode_Reward/pen_flat_orientation: -0.1254
  Episode_Reward/pen_feet_distance: -0.0101
Episode_Reward/pen_feet_regulation: -0.3707
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.8886
Metrics/base_velocity/error_vel_xy: 1.4169
Metrics/base_velocity/error_vel_yaw: 1.3438
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 1.10s
                        Total time: 1163.73s
                               ETA: 2100.1s

################################################################################
                     [1m Learning iteration 1070/3000 [0m                     

                       Computation: 89587 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.9501
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9236
                     Learning rate: 0.0013
                       Mean reward: 100.42
               Mean episode length: 921.56
       Episode_Reward/keep_balance: 0.9309
     Episode_Reward/rew_lin_vel_xy: 4.8752
      Episode_Reward/rew_ang_vel_z: 2.2834
    Episode_Reward/pen_base_height: -0.3001
      Episode_Reward/pen_lin_vel_z: -0.0430
     Episode_Reward/pen_ang_vel_xy: -0.1955
   Episode_Reward/pen_joint_torque: -0.2040
    Episode_Reward/pen_joint_accel: -0.1167
    Episode_Reward/pen_action_rate: -0.1213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0840
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2657
Episode_Reward/pen_flat_orientation: -0.1271
  Episode_Reward/pen_feet_distance: -0.0120
Episode_Reward/pen_feet_regulation: -0.3790
   Episode_Reward/foot_landing_vel: -0.1430
   Episode_Reward/test_gait_reward: -0.8851
Metrics/base_velocity/error_vel_xy: 1.4794
Metrics/base_velocity/error_vel_yaw: 1.3108
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 1.10s
                        Total time: 1164.82s
                               ETA: 2099.1s

################################################################################
                     [1m Learning iteration 1071/3000 [0m                     

                       Computation: 88401 steps/s (collection: 0.989s, learning 0.123s)
               Value function loss: 0.9666
                    Surrogate loss: -0.0014
             Mean action noise std: 0.9223
                     Learning rate: 0.0003
                       Mean reward: 108.33
               Mean episode length: 949.92
       Episode_Reward/keep_balance: 0.9408
     Episode_Reward/rew_lin_vel_xy: 5.0731
      Episode_Reward/rew_ang_vel_z: 2.2775
    Episode_Reward/pen_base_height: -0.2923
      Episode_Reward/pen_lin_vel_z: -0.0427
     Episode_Reward/pen_ang_vel_xy: -0.1967
   Episode_Reward/pen_joint_torque: -0.2108
    Episode_Reward/pen_joint_accel: -0.1185
    Episode_Reward/pen_action_rate: -0.1228
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2706
Episode_Reward/pen_flat_orientation: -0.1167
  Episode_Reward/pen_feet_distance: -0.0126
Episode_Reward/pen_feet_regulation: -0.3915
   Episode_Reward/foot_landing_vel: -0.1497
   Episode_Reward/test_gait_reward: -0.8973
Metrics/base_velocity/error_vel_xy: 1.3322
Metrics/base_velocity/error_vel_yaw: 1.3347
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 1.11s
                        Total time: 1165.94s
                               ETA: 2098.0s

################################################################################
                     [1m Learning iteration 1072/3000 [0m                     

                       Computation: 89025 steps/s (collection: 0.980s, learning 0.124s)
               Value function loss: 0.9113
                    Surrogate loss: -0.0038
             Mean action noise std: 0.9218
                     Learning rate: 0.0006
                       Mean reward: 104.02
               Mean episode length: 952.52
       Episode_Reward/keep_balance: 0.9507
     Episode_Reward/rew_lin_vel_xy: 4.9773
      Episode_Reward/rew_ang_vel_z: 2.2998
    Episode_Reward/pen_base_height: -0.3103
      Episode_Reward/pen_lin_vel_z: -0.0447
     Episode_Reward/pen_ang_vel_xy: -0.1934
   Episode_Reward/pen_joint_torque: -0.2077
    Episode_Reward/pen_joint_accel: -0.1122
    Episode_Reward/pen_action_rate: -0.1234
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0859
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2735
Episode_Reward/pen_flat_orientation: -0.1277
  Episode_Reward/pen_feet_distance: -0.0118
Episode_Reward/pen_feet_regulation: -0.4094
   Episode_Reward/foot_landing_vel: -0.1579
   Episode_Reward/test_gait_reward: -0.9047
Metrics/base_velocity/error_vel_xy: 1.4922
Metrics/base_velocity/error_vel_yaw: 1.3617
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 1.10s
                        Total time: 1167.04s
                               ETA: 2097.0s

################################################################################
                     [1m Learning iteration 1073/3000 [0m                     

                       Computation: 88560 steps/s (collection: 0.985s, learning 0.125s)
               Value function loss: 0.9137
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9225
                     Learning rate: 0.0004
                       Mean reward: 112.21
               Mean episode length: 964.91
       Episode_Reward/keep_balance: 0.9705
     Episode_Reward/rew_lin_vel_xy: 5.0901
      Episode_Reward/rew_ang_vel_z: 2.4187
    Episode_Reward/pen_base_height: -0.2855
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.1845
   Episode_Reward/pen_joint_torque: -0.2200
    Episode_Reward/pen_joint_accel: -0.1177
    Episode_Reward/pen_action_rate: -0.1217
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0854
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2701
Episode_Reward/pen_flat_orientation: -0.1149
  Episode_Reward/pen_feet_distance: -0.0099
Episode_Reward/pen_feet_regulation: -0.3619
   Episode_Reward/foot_landing_vel: -0.1461
   Episode_Reward/test_gait_reward: -0.9092
Metrics/base_velocity/error_vel_xy: 1.5283
Metrics/base_velocity/error_vel_yaw: 1.3136
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 1.11s
                        Total time: 1168.15s
                               ETA: 2095.9s

################################################################################
                     [1m Learning iteration 1074/3000 [0m                     

                       Computation: 88262 steps/s (collection: 0.988s, learning 0.125s)
               Value function loss: 0.8867
                    Surrogate loss: -0.0027
             Mean action noise std: 0.9230
                     Learning rate: 0.0004
                       Mean reward: 104.62
               Mean episode length: 944.82
       Episode_Reward/keep_balance: 0.9544
     Episode_Reward/rew_lin_vel_xy: 5.0758
      Episode_Reward/rew_ang_vel_z: 2.3482
    Episode_Reward/pen_base_height: -0.3115
      Episode_Reward/pen_lin_vel_z: -0.0485
     Episode_Reward/pen_ang_vel_xy: -0.1949
   Episode_Reward/pen_joint_torque: -0.2273
    Episode_Reward/pen_joint_accel: -0.1283
    Episode_Reward/pen_action_rate: -0.1238
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0598
   Episode_Reward/pen_joint_powers: -0.0899
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2701
Episode_Reward/pen_flat_orientation: -0.1228
  Episode_Reward/pen_feet_distance: -0.0090
Episode_Reward/pen_feet_regulation: -0.4152
   Episode_Reward/foot_landing_vel: -0.1559
   Episode_Reward/test_gait_reward: -0.9036
Metrics/base_velocity/error_vel_xy: 1.4179
Metrics/base_velocity/error_vel_yaw: 1.3168
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 1.11s
                        Total time: 1169.26s
                               ETA: 2094.9s

################################################################################
                     [1m Learning iteration 1075/3000 [0m                     

                       Computation: 89373 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.8932
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9235
                     Learning rate: 0.0003
                       Mean reward: 107.70
               Mean episode length: 954.23
       Episode_Reward/keep_balance: 0.9658
     Episode_Reward/rew_lin_vel_xy: 5.1679
      Episode_Reward/rew_ang_vel_z: 2.4190
    Episode_Reward/pen_base_height: -0.2930
      Episode_Reward/pen_lin_vel_z: -0.0452
     Episode_Reward/pen_ang_vel_xy: -0.1843
   Episode_Reward/pen_joint_torque: -0.2202
    Episode_Reward/pen_joint_accel: -0.1212
    Episode_Reward/pen_action_rate: -0.1220
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0858
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2687
Episode_Reward/pen_flat_orientation: -0.1173
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3689
   Episode_Reward/foot_landing_vel: -0.1453
   Episode_Reward/test_gait_reward: -0.9183
Metrics/base_velocity/error_vel_xy: 1.4385
Metrics/base_velocity/error_vel_yaw: 1.2947
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 1.10s
                        Total time: 1170.36s
                               ETA: 2093.8s

################################################################################
                     [1m Learning iteration 1076/3000 [0m                     

                       Computation: 89142 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.8728
                    Surrogate loss: -0.0028
             Mean action noise std: 0.9244
                     Learning rate: 0.0003
                       Mean reward: 105.18
               Mean episode length: 942.23
       Episode_Reward/keep_balance: 0.9459
     Episode_Reward/rew_lin_vel_xy: 5.0302
      Episode_Reward/rew_ang_vel_z: 2.2714
    Episode_Reward/pen_base_height: -0.3039
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.1966
   Episode_Reward/pen_joint_torque: -0.2111
    Episode_Reward/pen_joint_accel: -0.1369
    Episode_Reward/pen_action_rate: -0.1263
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0605
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2764
Episode_Reward/pen_flat_orientation: -0.1281
  Episode_Reward/pen_feet_distance: -0.0107
Episode_Reward/pen_feet_regulation: -0.4102
   Episode_Reward/foot_landing_vel: -0.1557
   Episode_Reward/test_gait_reward: -0.9136
Metrics/base_velocity/error_vel_xy: 1.3730
Metrics/base_velocity/error_vel_yaw: 1.3697
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 1.10s
                        Total time: 1171.47s
                               ETA: 2092.8s

################################################################################
                     [1m Learning iteration 1077/3000 [0m                     

                       Computation: 88686 steps/s (collection: 0.982s, learning 0.127s)
               Value function loss: 0.8643
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9260
                     Learning rate: 0.0006
                       Mean reward: 106.77
               Mean episode length: 930.15
       Episode_Reward/keep_balance: 0.9359
     Episode_Reward/rew_lin_vel_xy: 5.1046
      Episode_Reward/rew_ang_vel_z: 2.2668
    Episode_Reward/pen_base_height: -0.2894
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1838
   Episode_Reward/pen_joint_torque: -0.2015
    Episode_Reward/pen_joint_accel: -0.1232
    Episode_Reward/pen_action_rate: -0.1201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0814
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2684
Episode_Reward/pen_flat_orientation: -0.1154
  Episode_Reward/pen_feet_distance: -0.0098
Episode_Reward/pen_feet_regulation: -0.3680
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.8930
Metrics/base_velocity/error_vel_xy: 1.3231
Metrics/base_velocity/error_vel_yaw: 1.3380
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 1.11s
                        Total time: 1172.57s
                               ETA: 2091.7s

################################################################################
                     [1m Learning iteration 1078/3000 [0m                     

                       Computation: 89589 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.8852
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9279
                     Learning rate: 0.0004
                       Mean reward: 113.58
               Mean episode length: 978.68
       Episode_Reward/keep_balance: 0.9801
     Episode_Reward/rew_lin_vel_xy: 5.3851
      Episode_Reward/rew_ang_vel_z: 2.4509
    Episode_Reward/pen_base_height: -0.2977
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.1921
   Episode_Reward/pen_joint_torque: -0.2184
    Episode_Reward/pen_joint_accel: -0.1334
    Episode_Reward/pen_action_rate: -0.1251
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2773
Episode_Reward/pen_flat_orientation: -0.1161
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3890
   Episode_Reward/foot_landing_vel: -0.1598
   Episode_Reward/test_gait_reward: -0.9317
Metrics/base_velocity/error_vel_xy: 1.3742
Metrics/base_velocity/error_vel_yaw: 1.3211
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 1.10s
                        Total time: 1173.67s
                               ETA: 2090.6s

################################################################################
                     [1m Learning iteration 1079/3000 [0m                     

                       Computation: 89417 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.8414
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9271
                     Learning rate: 0.0001
                       Mean reward: 106.33
               Mean episode length: 954.88
       Episode_Reward/keep_balance: 0.9582
     Episode_Reward/rew_lin_vel_xy: 5.0140
      Episode_Reward/rew_ang_vel_z: 2.3465
    Episode_Reward/pen_base_height: -0.3029
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.1836
   Episode_Reward/pen_joint_torque: -0.2210
    Episode_Reward/pen_joint_accel: -0.1117
    Episode_Reward/pen_action_rate: -0.1220
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2696
Episode_Reward/pen_flat_orientation: -0.1231
  Episode_Reward/pen_feet_distance: -0.0117
Episode_Reward/pen_feet_regulation: -0.3837
   Episode_Reward/foot_landing_vel: -0.1427
   Episode_Reward/test_gait_reward: -0.9193
Metrics/base_velocity/error_vel_xy: 1.4606
Metrics/base_velocity/error_vel_yaw: 1.3312
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 1.10s
                        Total time: 1174.77s
                               ETA: 2089.6s

################################################################################
                     [1m Learning iteration 1080/3000 [0m                     

                       Computation: 90611 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.8540
                    Surrogate loss: -0.0013
             Mean action noise std: 0.9271
                     Learning rate: 0.0001
                       Mean reward: 106.58
               Mean episode length: 960.10
       Episode_Reward/keep_balance: 0.9502
     Episode_Reward/rew_lin_vel_xy: 5.0142
      Episode_Reward/rew_ang_vel_z: 2.3100
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0453
     Episode_Reward/pen_ang_vel_xy: -0.1961
   Episode_Reward/pen_joint_torque: -0.2181
    Episode_Reward/pen_joint_accel: -0.1237
    Episode_Reward/pen_action_rate: -0.1245
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0586
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2742
Episode_Reward/pen_flat_orientation: -0.1276
  Episode_Reward/pen_feet_distance: -0.0140
Episode_Reward/pen_feet_regulation: -0.4017
   Episode_Reward/foot_landing_vel: -0.1474
   Episode_Reward/test_gait_reward: -0.9054
Metrics/base_velocity/error_vel_xy: 1.4519
Metrics/base_velocity/error_vel_yaw: 1.3488
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 1.08s
                        Total time: 1175.86s
                               ETA: 2088.5s

################################################################################
                     [1m Learning iteration 1081/3000 [0m                     

                       Computation: 90357 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.9026
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9256
                     Learning rate: 0.0002
                       Mean reward: 108.41
               Mean episode length: 965.79
       Episode_Reward/keep_balance: 0.9653
     Episode_Reward/rew_lin_vel_xy: 5.2423
      Episode_Reward/rew_ang_vel_z: 2.3507
    Episode_Reward/pen_base_height: -0.3131
      Episode_Reward/pen_lin_vel_z: -0.0451
     Episode_Reward/pen_ang_vel_xy: -0.1924
   Episode_Reward/pen_joint_torque: -0.2180
    Episode_Reward/pen_joint_accel: -0.1226
    Episode_Reward/pen_action_rate: -0.1259
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2777
Episode_Reward/pen_flat_orientation: -0.1255
  Episode_Reward/pen_feet_distance: -0.0143
Episode_Reward/pen_feet_regulation: -0.4008
   Episode_Reward/foot_landing_vel: -0.1523
   Episode_Reward/test_gait_reward: -0.9242
Metrics/base_velocity/error_vel_xy: 1.3210
Metrics/base_velocity/error_vel_yaw: 1.3672
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 1.09s
                        Total time: 1176.94s
                               ETA: 2087.4s

################################################################################
                     [1m Learning iteration 1082/3000 [0m                     

                       Computation: 89636 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.7978
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9230
                     Learning rate: 0.0004
                       Mean reward: 102.45
               Mean episode length: 923.74
       Episode_Reward/keep_balance: 0.9279
     Episode_Reward/rew_lin_vel_xy: 4.9341
      Episode_Reward/rew_ang_vel_z: 2.2361
    Episode_Reward/pen_base_height: -0.2979
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.1867
   Episode_Reward/pen_joint_torque: -0.2090
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1219
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0853
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2721
Episode_Reward/pen_flat_orientation: -0.1225
  Episode_Reward/pen_feet_distance: -0.0104
Episode_Reward/pen_feet_regulation: -0.3842
   Episode_Reward/foot_landing_vel: -0.1431
   Episode_Reward/test_gait_reward: -0.8848
Metrics/base_velocity/error_vel_xy: 1.3773
Metrics/base_velocity/error_vel_yaw: 1.3295
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 1.10s
                        Total time: 1178.04s
                               ETA: 2086.3s

################################################################################
                     [1m Learning iteration 1083/3000 [0m                     

                       Computation: 89457 steps/s (collection: 0.974s, learning 0.125s)
               Value function loss: 0.7835
                    Surrogate loss: -0.0044
             Mean action noise std: 0.9234
                     Learning rate: 0.0006
                       Mean reward: 105.45
               Mean episode length: 938.38
       Episode_Reward/keep_balance: 0.9150
     Episode_Reward/rew_lin_vel_xy: 4.9017
      Episode_Reward/rew_ang_vel_z: 2.2105
    Episode_Reward/pen_base_height: -0.3012
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.1784
   Episode_Reward/pen_joint_torque: -0.2132
    Episode_Reward/pen_joint_accel: -0.1130
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0845
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2618
Episode_Reward/pen_flat_orientation: -0.1197
  Episode_Reward/pen_feet_distance: -0.0117
Episode_Reward/pen_feet_regulation: -0.3927
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.8810
Metrics/base_velocity/error_vel_xy: 1.3368
Metrics/base_velocity/error_vel_yaw: 1.3098
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 1.10s
                        Total time: 1179.14s
                               ETA: 2085.2s

################################################################################
                     [1m Learning iteration 1084/3000 [0m                     

                       Computation: 91035 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.8230
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9243
                     Learning rate: 0.0013
                       Mean reward: 110.55
               Mean episode length: 947.97
       Episode_Reward/keep_balance: 0.9489
     Episode_Reward/rew_lin_vel_xy: 5.2714
      Episode_Reward/rew_ang_vel_z: 2.3480
    Episode_Reward/pen_base_height: -0.3048
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.1932
   Episode_Reward/pen_joint_torque: -0.2162
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1239
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2724
Episode_Reward/pen_flat_orientation: -0.1203
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.4015
   Episode_Reward/foot_landing_vel: -0.1493
   Episode_Reward/test_gait_reward: -0.9102
Metrics/base_velocity/error_vel_xy: 1.3028
Metrics/base_velocity/error_vel_yaw: 1.3047
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 1.08s
                        Total time: 1180.22s
                               ETA: 2084.1s

################################################################################
                     [1m Learning iteration 1085/3000 [0m                     

                       Computation: 90068 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.8746
                    Surrogate loss: -0.0011
             Mean action noise std: 0.9234
                     Learning rate: 0.0004
                       Mean reward: 109.54
               Mean episode length: 959.40
       Episode_Reward/keep_balance: 0.9580
     Episode_Reward/rew_lin_vel_xy: 5.2481
      Episode_Reward/rew_ang_vel_z: 2.2692
    Episode_Reward/pen_base_height: -0.3113
      Episode_Reward/pen_lin_vel_z: -0.0456
     Episode_Reward/pen_ang_vel_xy: -0.2061
   Episode_Reward/pen_joint_torque: -0.2174
    Episode_Reward/pen_joint_accel: -0.1440
    Episode_Reward/pen_action_rate: -0.1297
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0620
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2864
Episode_Reward/pen_flat_orientation: -0.1238
  Episode_Reward/pen_feet_distance: -0.0104
Episode_Reward/pen_feet_regulation: -0.4247
   Episode_Reward/foot_landing_vel: -0.1611
   Episode_Reward/test_gait_reward: -0.9256
Metrics/base_velocity/error_vel_xy: 1.2934
Metrics/base_velocity/error_vel_yaw: 1.4210
      Episode_Termination/time_out: 2.9167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 1.09s
                        Total time: 1181.31s
                               ETA: 2083.1s

################################################################################
                     [1m Learning iteration 1086/3000 [0m                     

                       Computation: 91141 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.8917
                    Surrogate loss: -0.0054
             Mean action noise std: 0.9222
                     Learning rate: 0.0009
                       Mean reward: 107.05
               Mean episode length: 955.99
       Episode_Reward/keep_balance: 0.9506
     Episode_Reward/rew_lin_vel_xy: 5.0565
      Episode_Reward/rew_ang_vel_z: 2.2981
    Episode_Reward/pen_base_height: -0.3047
      Episode_Reward/pen_lin_vel_z: -0.0451
     Episode_Reward/pen_ang_vel_xy: -0.1959
   Episode_Reward/pen_joint_torque: -0.2159
    Episode_Reward/pen_joint_accel: -0.1210
    Episode_Reward/pen_action_rate: -0.1254
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0879
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2768
Episode_Reward/pen_flat_orientation: -0.1289
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.4011
   Episode_Reward/foot_landing_vel: -0.1432
   Episode_Reward/test_gait_reward: -0.9144
Metrics/base_velocity/error_vel_xy: 1.4111
Metrics/base_velocity/error_vel_yaw: 1.3698
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 1.08s
                        Total time: 1182.39s
                               ETA: 2082.0s

################################################################################
                     [1m Learning iteration 1087/3000 [0m                     

                       Computation: 90645 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.8867
                    Surrogate loss: -0.0039
             Mean action noise std: 0.9240
                     Learning rate: 0.0013
                       Mean reward: 101.16
               Mean episode length: 928.69
       Episode_Reward/keep_balance: 0.9372
     Episode_Reward/rew_lin_vel_xy: 4.9458
      Episode_Reward/rew_ang_vel_z: 2.2303
    Episode_Reward/pen_base_height: -0.2983
      Episode_Reward/pen_lin_vel_z: -0.0455
     Episode_Reward/pen_ang_vel_xy: -0.1905
   Episode_Reward/pen_joint_torque: -0.2202
    Episode_Reward/pen_joint_accel: -0.1173
    Episode_Reward/pen_action_rate: -0.1249
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2759
Episode_Reward/pen_flat_orientation: -0.1242
  Episode_Reward/pen_feet_distance: -0.0104
Episode_Reward/pen_feet_regulation: -0.3985
   Episode_Reward/foot_landing_vel: -0.1437
   Episode_Reward/test_gait_reward: -0.9020
Metrics/base_velocity/error_vel_xy: 1.4110
Metrics/base_velocity/error_vel_yaw: 1.3779
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 1.08s
                        Total time: 1183.47s
                               ETA: 2080.9s

################################################################################
                     [1m Learning iteration 1088/3000 [0m                     

                       Computation: 89083 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 1.0057
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9273
                     Learning rate: 0.0019
                       Mean reward: 107.91
               Mean episode length: 973.43
       Episode_Reward/keep_balance: 0.9692
     Episode_Reward/rew_lin_vel_xy: 5.1138
      Episode_Reward/rew_ang_vel_z: 2.3520
    Episode_Reward/pen_base_height: -0.3214
      Episode_Reward/pen_lin_vel_z: -0.0461
     Episode_Reward/pen_ang_vel_xy: -0.1973
   Episode_Reward/pen_joint_torque: -0.2282
    Episode_Reward/pen_joint_accel: -0.1259
    Episode_Reward/pen_action_rate: -0.1274
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2796
Episode_Reward/pen_flat_orientation: -0.1215
  Episode_Reward/pen_feet_distance: -0.0135
Episode_Reward/pen_feet_regulation: -0.4187
   Episode_Reward/foot_landing_vel: -0.1482
   Episode_Reward/test_gait_reward: -0.9341
Metrics/base_velocity/error_vel_xy: 1.4723
Metrics/base_velocity/error_vel_yaw: 1.3761
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 1.10s
                        Total time: 1184.58s
                               ETA: 2079.8s

################################################################################
                     [1m Learning iteration 1089/3000 [0m                     

                       Computation: 90112 steps/s (collection: 0.966s, learning 0.125s)
               Value function loss: 0.9110
                    Surrogate loss: -0.0024
             Mean action noise std: 0.9278
                     Learning rate: 0.0009
                       Mean reward: 101.66
               Mean episode length: 923.07
       Episode_Reward/keep_balance: 0.9420
     Episode_Reward/rew_lin_vel_xy: 5.0315
      Episode_Reward/rew_ang_vel_z: 2.2896
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.1997
   Episode_Reward/pen_joint_torque: -0.2183
    Episode_Reward/pen_joint_accel: -0.1217
    Episode_Reward/pen_action_rate: -0.1254
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0593
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2767
Episode_Reward/pen_flat_orientation: -0.1302
  Episode_Reward/pen_feet_distance: -0.0088
Episode_Reward/pen_feet_regulation: -0.4178
   Episode_Reward/foot_landing_vel: -0.1548
   Episode_Reward/test_gait_reward: -0.8996
Metrics/base_velocity/error_vel_xy: 1.4269
Metrics/base_velocity/error_vel_yaw: 1.3416
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 1.09s
                        Total time: 1185.67s
                               ETA: 2078.7s

################################################################################
                     [1m Learning iteration 1090/3000 [0m                     

                       Computation: 91123 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.8985
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9276
                     Learning rate: 0.0013
                       Mean reward: 108.87
               Mean episode length: 947.12
       Episode_Reward/keep_balance: 0.9444
     Episode_Reward/rew_lin_vel_xy: 5.1748
      Episode_Reward/rew_ang_vel_z: 2.3079
    Episode_Reward/pen_base_height: -0.3062
      Episode_Reward/pen_lin_vel_z: -0.0429
     Episode_Reward/pen_ang_vel_xy: -0.1885
   Episode_Reward/pen_joint_torque: -0.2232
    Episode_Reward/pen_joint_accel: -0.1201
    Episode_Reward/pen_action_rate: -0.1243
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2713
Episode_Reward/pen_flat_orientation: -0.1225
  Episode_Reward/pen_feet_distance: -0.0113
Episode_Reward/pen_feet_regulation: -0.3900
   Episode_Reward/foot_landing_vel: -0.1403
   Episode_Reward/test_gait_reward: -0.9083
Metrics/base_velocity/error_vel_xy: 1.3270
Metrics/base_velocity/error_vel_yaw: 1.3298
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 1.08s
                        Total time: 1186.75s
                               ETA: 2077.6s

################################################################################
                     [1m Learning iteration 1091/3000 [0m                     

                       Computation: 90376 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.8602
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9277
                     Learning rate: 0.0013
                       Mean reward: 107.30
               Mean episode length: 980.47
       Episode_Reward/keep_balance: 0.9751
     Episode_Reward/rew_lin_vel_xy: 5.2372
      Episode_Reward/rew_ang_vel_z: 2.3176
    Episode_Reward/pen_base_height: -0.3082
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.2021
   Episode_Reward/pen_joint_torque: -0.2194
    Episode_Reward/pen_joint_accel: -0.1243
    Episode_Reward/pen_action_rate: -0.1308
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0621
   Episode_Reward/pen_joint_powers: -0.0921
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2878
Episode_Reward/pen_flat_orientation: -0.1221
  Episode_Reward/pen_feet_distance: -0.0109
Episode_Reward/pen_feet_regulation: -0.4319
   Episode_Reward/foot_landing_vel: -0.1668
   Episode_Reward/test_gait_reward: -0.9330
Metrics/base_velocity/error_vel_xy: 1.4215
Metrics/base_velocity/error_vel_yaw: 1.4314
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 1.09s
                        Total time: 1187.83s
                               ETA: 2076.5s

################################################################################
                     [1m Learning iteration 1092/3000 [0m                     

                       Computation: 90208 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.8812
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9284
                     Learning rate: 0.0013
                       Mean reward: 108.44
               Mean episode length: 966.35
       Episode_Reward/keep_balance: 0.9743
     Episode_Reward/rew_lin_vel_xy: 5.3365
      Episode_Reward/rew_ang_vel_z: 2.3556
    Episode_Reward/pen_base_height: -0.3018
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.1999
   Episode_Reward/pen_joint_torque: -0.2301
    Episode_Reward/pen_joint_accel: -0.1261
    Episode_Reward/pen_action_rate: -0.1295
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0602
   Episode_Reward/pen_joint_powers: -0.0920
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2829
Episode_Reward/pen_flat_orientation: -0.1206
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.4206
   Episode_Reward/foot_landing_vel: -0.1540
   Episode_Reward/test_gait_reward: -0.9423
Metrics/base_velocity/error_vel_xy: 1.3400
Metrics/base_velocity/error_vel_yaw: 1.3912
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 1.09s
                        Total time: 1188.92s
                               ETA: 2075.5s

################################################################################
                     [1m Learning iteration 1093/3000 [0m                     

                       Computation: 89359 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.7885
                    Surrogate loss: -0.0007
             Mean action noise std: 0.9293
                     Learning rate: 0.0004
                       Mean reward: 111.46
               Mean episode length: 963.40
       Episode_Reward/keep_balance: 0.9543
     Episode_Reward/rew_lin_vel_xy: 5.2429
      Episode_Reward/rew_ang_vel_z: 2.3078
    Episode_Reward/pen_base_height: -0.2952
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.1911
   Episode_Reward/pen_joint_torque: -0.2196
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1256
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2764
Episode_Reward/pen_flat_orientation: -0.1169
  Episode_Reward/pen_feet_distance: -0.0084
Episode_Reward/pen_feet_regulation: -0.3974
   Episode_Reward/foot_landing_vel: -0.1469
   Episode_Reward/test_gait_reward: -0.9159
Metrics/base_velocity/error_vel_xy: 1.3183
Metrics/base_velocity/error_vel_yaw: 1.3620
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 1.10s
                        Total time: 1190.02s
                               ETA: 2074.4s

################################################################################
                     [1m Learning iteration 1094/3000 [0m                     

                       Computation: 89934 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.8523
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9307
                     Learning rate: 0.0004
                       Mean reward: 112.42
               Mean episode length: 970.83
       Episode_Reward/keep_balance: 0.9747
     Episode_Reward/rew_lin_vel_xy: 5.3302
      Episode_Reward/rew_ang_vel_z: 2.3779
    Episode_Reward/pen_base_height: -0.3049
      Episode_Reward/pen_lin_vel_z: -0.0446
     Episode_Reward/pen_ang_vel_xy: -0.1927
   Episode_Reward/pen_joint_torque: -0.2145
    Episode_Reward/pen_joint_accel: -0.1171
    Episode_Reward/pen_action_rate: -0.1276
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2828
Episode_Reward/pen_flat_orientation: -0.1218
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.4119
   Episode_Reward/foot_landing_vel: -0.1509
   Episode_Reward/test_gait_reward: -0.9334
Metrics/base_velocity/error_vel_xy: 1.3747
Metrics/base_velocity/error_vel_yaw: 1.3821
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 1.09s
                        Total time: 1191.12s
                               ETA: 2073.3s

################################################################################
                     [1m Learning iteration 1095/3000 [0m                     

                       Computation: 89144 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 0.8111
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9329
                     Learning rate: 0.0006
                       Mean reward: 108.95
               Mean episode length: 953.15
       Episode_Reward/keep_balance: 0.9453
     Episode_Reward/rew_lin_vel_xy: 5.1872
      Episode_Reward/rew_ang_vel_z: 2.2714
    Episode_Reward/pen_base_height: -0.3054
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.1967
   Episode_Reward/pen_joint_torque: -0.2162
    Episode_Reward/pen_joint_accel: -0.1126
    Episode_Reward/pen_action_rate: -0.1262
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2784
Episode_Reward/pen_flat_orientation: -0.1251
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.4106
   Episode_Reward/foot_landing_vel: -0.1458
   Episode_Reward/test_gait_reward: -0.9179
Metrics/base_velocity/error_vel_xy: 1.3264
Metrics/base_velocity/error_vel_yaw: 1.3730
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 1.10s
                        Total time: 1192.22s
                               ETA: 2072.2s

################################################################################
                     [1m Learning iteration 1096/3000 [0m                     

                       Computation: 90651 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.8266
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9329
                     Learning rate: 0.0006
                       Mean reward: 112.15
               Mean episode length: 980.22
       Episode_Reward/keep_balance: 0.9812
     Episode_Reward/rew_lin_vel_xy: 5.4007
      Episode_Reward/rew_ang_vel_z: 2.3808
    Episode_Reward/pen_base_height: -0.3071
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.2013
   Episode_Reward/pen_joint_torque: -0.2217
    Episode_Reward/pen_joint_accel: -0.1250
    Episode_Reward/pen_action_rate: -0.1300
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0911
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2867
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0099
Episode_Reward/pen_feet_regulation: -0.4200
   Episode_Reward/foot_landing_vel: -0.1451
   Episode_Reward/test_gait_reward: -0.9523
Metrics/base_velocity/error_vel_xy: 1.3279
Metrics/base_velocity/error_vel_yaw: 1.3972
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 1.08s
                        Total time: 1193.30s
                               ETA: 2071.2s

################################################################################
                     [1m Learning iteration 1097/3000 [0m                     

                       Computation: 91203 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.7577
                    Surrogate loss: 0.0023
             Mean action noise std: 0.9330
                     Learning rate: 0.0001
                       Mean reward: 108.25
               Mean episode length: 974.52
       Episode_Reward/keep_balance: 0.9705
     Episode_Reward/rew_lin_vel_xy: 5.1687
      Episode_Reward/rew_ang_vel_z: 2.3369
    Episode_Reward/pen_base_height: -0.3065
      Episode_Reward/pen_lin_vel_z: -0.0467
     Episode_Reward/pen_ang_vel_xy: -0.2003
   Episode_Reward/pen_joint_torque: -0.2273
    Episode_Reward/pen_joint_accel: -0.1250
    Episode_Reward/pen_action_rate: -0.1301
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0616
   Episode_Reward/pen_joint_powers: -0.0923
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2845
Episode_Reward/pen_flat_orientation: -0.1231
  Episode_Reward/pen_feet_distance: -0.0065
Episode_Reward/pen_feet_regulation: -0.4328
   Episode_Reward/foot_landing_vel: -0.1602
   Episode_Reward/test_gait_reward: -0.9365
Metrics/base_velocity/error_vel_xy: 1.4539
Metrics/base_velocity/error_vel_yaw: 1.3946
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 1.08s
                        Total time: 1194.38s
                               ETA: 2070.0s

################################################################################
                     [1m Learning iteration 1098/3000 [0m                     

                       Computation: 90048 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.7899
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9334
                     Learning rate: 0.0003
                       Mean reward: 109.11
               Mean episode length: 950.24
       Episode_Reward/keep_balance: 0.9523
     Episode_Reward/rew_lin_vel_xy: 5.2976
      Episode_Reward/rew_ang_vel_z: 2.2565
    Episode_Reward/pen_base_height: -0.2964
      Episode_Reward/pen_lin_vel_z: -0.0428
     Episode_Reward/pen_ang_vel_xy: -0.1911
   Episode_Reward/pen_joint_torque: -0.2089
    Episode_Reward/pen_joint_accel: -0.1184
    Episode_Reward/pen_action_rate: -0.1259
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2802
Episode_Reward/pen_flat_orientation: -0.1170
  Episode_Reward/pen_feet_distance: -0.0064
Episode_Reward/pen_feet_regulation: -0.4101
   Episode_Reward/foot_landing_vel: -0.1536
   Episode_Reward/test_gait_reward: -0.9140
Metrics/base_velocity/error_vel_xy: 1.2724
Metrics/base_velocity/error_vel_yaw: 1.4079
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 1.09s
                        Total time: 1195.47s
                               ETA: 2069.0s

################################################################################
                     [1m Learning iteration 1099/3000 [0m                     

                       Computation: 90791 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.7644
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9333
                     Learning rate: 0.0004
                       Mean reward: 109.77
               Mean episode length: 951.70
       Episode_Reward/keep_balance: 0.9484
     Episode_Reward/rew_lin_vel_xy: 5.2662
      Episode_Reward/rew_ang_vel_z: 2.2671
    Episode_Reward/pen_base_height: -0.2940
      Episode_Reward/pen_lin_vel_z: -0.0441
     Episode_Reward/pen_ang_vel_xy: -0.1943
   Episode_Reward/pen_joint_torque: -0.2175
    Episode_Reward/pen_joint_accel: -0.1194
    Episode_Reward/pen_action_rate: -0.1274
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2781
Episode_Reward/pen_flat_orientation: -0.1158
  Episode_Reward/pen_feet_distance: -0.0061
Episode_Reward/pen_feet_regulation: -0.4087
   Episode_Reward/foot_landing_vel: -0.1472
   Episode_Reward/test_gait_reward: -0.9263
Metrics/base_velocity/error_vel_xy: 1.2993
Metrics/base_velocity/error_vel_yaw: 1.3833
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 1.08s
                        Total time: 1196.56s
                               ETA: 2067.9s

################################################################################
                     [1m Learning iteration 1100/3000 [0m                     

                       Computation: 90361 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.7172
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9340
                     Learning rate: 0.0006
                       Mean reward: 106.92
               Mean episode length: 970.45
       Episode_Reward/keep_balance: 0.9605
     Episode_Reward/rew_lin_vel_xy: 5.2065
      Episode_Reward/rew_ang_vel_z: 2.2551
    Episode_Reward/pen_base_height: -0.3124
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.2052
   Episode_Reward/pen_joint_torque: -0.2194
    Episode_Reward/pen_joint_accel: -0.1176
    Episode_Reward/pen_action_rate: -0.1308
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0603
   Episode_Reward/pen_joint_powers: -0.0915
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2875
Episode_Reward/pen_flat_orientation: -0.1297
  Episode_Reward/pen_feet_distance: -0.0095
Episode_Reward/pen_feet_regulation: -0.4389
   Episode_Reward/foot_landing_vel: -0.1493
   Episode_Reward/test_gait_reward: -0.9324
Metrics/base_velocity/error_vel_xy: 1.3637
Metrics/base_velocity/error_vel_yaw: 1.4577
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 1.09s
                        Total time: 1197.64s
                               ETA: 2066.8s

################################################################################
                     [1m Learning iteration 1101/3000 [0m                     

                       Computation: 90772 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.7907
                    Surrogate loss: -0.0024
             Mean action noise std: 0.9347
                     Learning rate: 0.0009
                       Mean reward: 108.45
               Mean episode length: 954.58
       Episode_Reward/keep_balance: 0.9557
     Episode_Reward/rew_lin_vel_xy: 5.2698
      Episode_Reward/rew_ang_vel_z: 2.2937
    Episode_Reward/pen_base_height: -0.3168
      Episode_Reward/pen_lin_vel_z: -0.0453
     Episode_Reward/pen_ang_vel_xy: -0.1978
   Episode_Reward/pen_joint_torque: -0.2215
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1286
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0596
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2824
Episode_Reward/pen_flat_orientation: -0.1216
  Episode_Reward/pen_feet_distance: -0.0119
Episode_Reward/pen_feet_regulation: -0.4177
   Episode_Reward/foot_landing_vel: -0.1425
   Episode_Reward/test_gait_reward: -0.9220
Metrics/base_velocity/error_vel_xy: 1.3332
Metrics/base_velocity/error_vel_yaw: 1.3934
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 1.08s
                        Total time: 1198.73s
                               ETA: 2065.7s

################################################################################
                     [1m Learning iteration 1102/3000 [0m                     

                       Computation: 89377 steps/s (collection: 0.973s, learning 0.127s)
               Value function loss: 0.7625
                    Surrogate loss: -0.0006
             Mean action noise std: 0.9336
                     Learning rate: 0.0004
                       Mean reward: 107.15
               Mean episode length: 951.78
       Episode_Reward/keep_balance: 0.9521
     Episode_Reward/rew_lin_vel_xy: 5.2573
      Episode_Reward/rew_ang_vel_z: 2.2729
    Episode_Reward/pen_base_height: -0.3125
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.2007
   Episode_Reward/pen_joint_torque: -0.2210
    Episode_Reward/pen_joint_accel: -0.1167
    Episode_Reward/pen_action_rate: -0.1293
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0612
   Episode_Reward/pen_joint_powers: -0.0920
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2833
Episode_Reward/pen_flat_orientation: -0.1238
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.4433
   Episode_Reward/foot_landing_vel: -0.1605
   Episode_Reward/test_gait_reward: -0.9286
Metrics/base_velocity/error_vel_xy: 1.2687
Metrics/base_velocity/error_vel_yaw: 1.3855
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 1.10s
                        Total time: 1199.83s
                               ETA: 2064.6s

################################################################################
                     [1m Learning iteration 1103/3000 [0m                     

                       Computation: 89281 steps/s (collection: 0.975s, learning 0.126s)
               Value function loss: 0.7781
                    Surrogate loss: -0.0016
             Mean action noise std: 0.9342
                     Learning rate: 0.0003
                       Mean reward: 110.67
               Mean episode length: 961.62
       Episode_Reward/keep_balance: 0.9627
     Episode_Reward/rew_lin_vel_xy: 5.4698
      Episode_Reward/rew_ang_vel_z: 2.3165
    Episode_Reward/pen_base_height: -0.3043
      Episode_Reward/pen_lin_vel_z: -0.0447
     Episode_Reward/pen_ang_vel_xy: -0.2032
   Episode_Reward/pen_joint_torque: -0.2264
    Episode_Reward/pen_joint_accel: -0.1178
    Episode_Reward/pen_action_rate: -0.1278
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2801
Episode_Reward/pen_flat_orientation: -0.1191
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.4296
   Episode_Reward/foot_landing_vel: -0.1550
   Episode_Reward/test_gait_reward: -0.9258
Metrics/base_velocity/error_vel_xy: 1.2438
Metrics/base_velocity/error_vel_yaw: 1.3809
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 1.10s
                        Total time: 1200.93s
                               ETA: 2063.6s

################################################################################
                     [1m Learning iteration 1104/3000 [0m                     

                       Computation: 91124 steps/s (collection: 0.953s, learning 0.126s)
               Value function loss: 0.8208
                    Surrogate loss: 0.0050
             Mean action noise std: 0.9347
                     Learning rate: 0.0001
                       Mean reward: 111.11
               Mean episode length: 955.06
       Episode_Reward/keep_balance: 0.9278
     Episode_Reward/rew_lin_vel_xy: 5.1264
      Episode_Reward/rew_ang_vel_z: 2.2580
    Episode_Reward/pen_base_height: -0.2990
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.1865
   Episode_Reward/pen_joint_torque: -0.2205
    Episode_Reward/pen_joint_accel: -0.1127
    Episode_Reward/pen_action_rate: -0.1230
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2688
Episode_Reward/pen_flat_orientation: -0.1190
  Episode_Reward/pen_feet_distance: -0.0085
Episode_Reward/pen_feet_regulation: -0.3986
   Episode_Reward/foot_landing_vel: -0.1393
   Episode_Reward/test_gait_reward: -0.9013
Metrics/base_velocity/error_vel_xy: 1.2600
Metrics/base_velocity/error_vel_yaw: 1.3170
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 1.08s
                        Total time: 1202.01s
                               ETA: 2062.4s

################################################################################
                     [1m Learning iteration 1105/3000 [0m                     

                       Computation: 89336 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 0.7804
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9346
                     Learning rate: 0.0001
                       Mean reward: 107.29
               Mean episode length: 962.76
       Episode_Reward/keep_balance: 0.9611
     Episode_Reward/rew_lin_vel_xy: 5.2220
      Episode_Reward/rew_ang_vel_z: 2.3051
    Episode_Reward/pen_base_height: -0.3132
      Episode_Reward/pen_lin_vel_z: -0.0448
     Episode_Reward/pen_ang_vel_xy: -0.1968
   Episode_Reward/pen_joint_torque: -0.2245
    Episode_Reward/pen_joint_accel: -0.1082
    Episode_Reward/pen_action_rate: -0.1302
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0923
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2826
Episode_Reward/pen_flat_orientation: -0.1271
  Episode_Reward/pen_feet_distance: -0.0105
Episode_Reward/pen_feet_regulation: -0.4281
   Episode_Reward/foot_landing_vel: -0.1539
   Episode_Reward/test_gait_reward: -0.9345
Metrics/base_velocity/error_vel_xy: 1.3677
Metrics/base_velocity/error_vel_yaw: 1.4139
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 1.10s
                        Total time: 1203.11s
                               ETA: 2061.4s

################################################################################
                     [1m Learning iteration 1106/3000 [0m                     

                       Computation: 90311 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.7376
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9328
                     Learning rate: 0.0003
                       Mean reward: 108.62
               Mean episode length: 959.02
       Episode_Reward/keep_balance: 0.9645
     Episode_Reward/rew_lin_vel_xy: 5.2631
      Episode_Reward/rew_ang_vel_z: 2.2725
    Episode_Reward/pen_base_height: -0.3024
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.2030
   Episode_Reward/pen_joint_torque: -0.2199
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1300
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0598
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2862
Episode_Reward/pen_flat_orientation: -0.1209
  Episode_Reward/pen_feet_distance: -0.0100
Episode_Reward/pen_feet_regulation: -0.4273
   Episode_Reward/foot_landing_vel: -0.1454
   Episode_Reward/test_gait_reward: -0.9375
Metrics/base_velocity/error_vel_xy: 1.3330
Metrics/base_velocity/error_vel_yaw: 1.4396
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 1.09s
                        Total time: 1204.20s
                               ETA: 2060.3s

################################################################################
                     [1m Learning iteration 1107/3000 [0m                     

                       Computation: 90888 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.8005
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9323
                     Learning rate: 0.0006
                       Mean reward: 109.12
               Mean episode length: 972.34
       Episode_Reward/keep_balance: 0.9724
     Episode_Reward/rew_lin_vel_xy: 5.3525
      Episode_Reward/rew_ang_vel_z: 2.3097
    Episode_Reward/pen_base_height: -0.3166
      Episode_Reward/pen_lin_vel_z: -0.0457
     Episode_Reward/pen_ang_vel_xy: -0.2013
   Episode_Reward/pen_joint_torque: -0.2279
    Episode_Reward/pen_joint_accel: -0.1167
    Episode_Reward/pen_action_rate: -0.1324
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0608
   Episode_Reward/pen_joint_powers: -0.0922
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2877
Episode_Reward/pen_flat_orientation: -0.1208
  Episode_Reward/pen_feet_distance: -0.0096
Episode_Reward/pen_feet_regulation: -0.4399
   Episode_Reward/foot_landing_vel: -0.1475
   Episode_Reward/test_gait_reward: -0.9451
Metrics/base_velocity/error_vel_xy: 1.3141
Metrics/base_velocity/error_vel_yaw: 1.4479
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 1.08s
                        Total time: 1205.28s
                               ETA: 2059.2s

################################################################################
                     [1m Learning iteration 1108/3000 [0m                     

                       Computation: 91032 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.7747
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9316
                     Learning rate: 0.0004
                       Mean reward: 108.45
               Mean episode length: 958.32
       Episode_Reward/keep_balance: 0.9582
     Episode_Reward/rew_lin_vel_xy: 5.2785
      Episode_Reward/rew_ang_vel_z: 2.2876
    Episode_Reward/pen_base_height: -0.3138
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.2019
   Episode_Reward/pen_joint_torque: -0.2208
    Episode_Reward/pen_joint_accel: -0.1136
    Episode_Reward/pen_action_rate: -0.1299
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2829
Episode_Reward/pen_flat_orientation: -0.1222
  Episode_Reward/pen_feet_distance: -0.0069
Episode_Reward/pen_feet_regulation: -0.4032
   Episode_Reward/foot_landing_vel: -0.1484
   Episode_Reward/test_gait_reward: -0.9244
Metrics/base_velocity/error_vel_xy: 1.3444
Metrics/base_velocity/error_vel_yaw: 1.4184
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 1.08s
                        Total time: 1206.36s
                               ETA: 2058.1s

################################################################################
                     [1m Learning iteration 1109/3000 [0m                     

                       Computation: 89540 steps/s (collection: 0.972s, learning 0.125s)
               Value function loss: 0.7832
                    Surrogate loss: -0.0038
             Mean action noise std: 0.9318
                     Learning rate: 0.0006
                       Mean reward: 115.01
               Mean episode length: 970.56
       Episode_Reward/keep_balance: 0.9619
     Episode_Reward/rew_lin_vel_xy: 5.5024
      Episode_Reward/rew_ang_vel_z: 2.3248
    Episode_Reward/pen_base_height: -0.2984
      Episode_Reward/pen_lin_vel_z: -0.0427
     Episode_Reward/pen_ang_vel_xy: -0.1964
   Episode_Reward/pen_joint_torque: -0.2163
    Episode_Reward/pen_joint_accel: -0.1275
    Episode_Reward/pen_action_rate: -0.1281
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2836
Episode_Reward/pen_flat_orientation: -0.1146
  Episode_Reward/pen_feet_distance: -0.0095
Episode_Reward/pen_feet_regulation: -0.4057
   Episode_Reward/foot_landing_vel: -0.1505
   Episode_Reward/test_gait_reward: -0.9254
Metrics/base_velocity/error_vel_xy: 1.1992
Metrics/base_velocity/error_vel_yaw: 1.3728
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 1.10s
                        Total time: 1207.46s
                               ETA: 2057.0s

################################################################################
                     [1m Learning iteration 1110/3000 [0m                     

                       Computation: 90133 steps/s (collection: 0.966s, learning 0.125s)
               Value function loss: 0.7327
                    Surrogate loss: -0.0015
             Mean action noise std: 0.9312
                     Learning rate: 0.0002
                       Mean reward: 109.08
               Mean episode length: 968.16
       Episode_Reward/keep_balance: 0.9645
     Episode_Reward/rew_lin_vel_xy: 5.3535
      Episode_Reward/rew_ang_vel_z: 2.2916
    Episode_Reward/pen_base_height: -0.3129
      Episode_Reward/pen_lin_vel_z: -0.0433
     Episode_Reward/pen_ang_vel_xy: -0.2010
   Episode_Reward/pen_joint_torque: -0.2230
    Episode_Reward/pen_joint_accel: -0.1274
    Episode_Reward/pen_action_rate: -0.1308
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0605
   Episode_Reward/pen_joint_powers: -0.0916
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2847
Episode_Reward/pen_flat_orientation: -0.1248
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.4339
   Episode_Reward/foot_landing_vel: -0.1426
   Episode_Reward/test_gait_reward: -0.9420
Metrics/base_velocity/error_vel_xy: 1.3029
Metrics/base_velocity/error_vel_yaw: 1.4380
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 1.09s
                        Total time: 1208.55s
                               ETA: 2055.9s

################################################################################
                     [1m Learning iteration 1111/3000 [0m                     

                       Computation: 90850 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 0.7579
                    Surrogate loss: -0.0016
             Mean action noise std: 0.9301
                     Learning rate: 0.0003
                       Mean reward: 109.14
               Mean episode length: 961.85
       Episode_Reward/keep_balance: 0.9678
     Episode_Reward/rew_lin_vel_xy: 5.4558
      Episode_Reward/rew_ang_vel_z: 2.2789
    Episode_Reward/pen_base_height: -0.3223
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.2086
   Episode_Reward/pen_joint_torque: -0.2259
    Episode_Reward/pen_joint_accel: -0.1163
    Episode_Reward/pen_action_rate: -0.1332
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0611
   Episode_Reward/pen_joint_powers: -0.0930
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2904
Episode_Reward/pen_flat_orientation: -0.1223
  Episode_Reward/pen_feet_distance: -0.0086
Episode_Reward/pen_feet_regulation: -0.4455
   Episode_Reward/foot_landing_vel: -0.1478
   Episode_Reward/test_gait_reward: -0.9479
Metrics/base_velocity/error_vel_xy: 1.2754
Metrics/base_velocity/error_vel_yaw: 1.4573
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 1.08s
                        Total time: 1209.63s
                               ETA: 2054.8s

################################################################################
                     [1m Learning iteration 1112/3000 [0m                     

                       Computation: 86375 steps/s (collection: 1.006s, learning 0.132s)
               Value function loss: 0.7348
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9313
                     Learning rate: 0.0004
                       Mean reward: 108.95
               Mean episode length: 969.49
       Episode_Reward/keep_balance: 0.9698
     Episode_Reward/rew_lin_vel_xy: 5.3845
      Episode_Reward/rew_ang_vel_z: 2.3010
    Episode_Reward/pen_base_height: -0.3154
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.2095
   Episode_Reward/pen_joint_torque: -0.2179
    Episode_Reward/pen_joint_accel: -0.1238
    Episode_Reward/pen_action_rate: -0.1335
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0617
   Episode_Reward/pen_joint_powers: -0.0921
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2935
Episode_Reward/pen_flat_orientation: -0.1233
  Episode_Reward/pen_feet_distance: -0.0079
Episode_Reward/pen_feet_regulation: -0.4287
   Episode_Reward/foot_landing_vel: -0.1527
   Episode_Reward/test_gait_reward: -0.9447
Metrics/base_velocity/error_vel_xy: 1.3108
Metrics/base_velocity/error_vel_yaw: 1.4500
      Episode_Termination/time_out: 4.9583
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 1.14s
                        Total time: 1210.77s
                               ETA: 2053.8s

################################################################################
                     [1m Learning iteration 1113/3000 [0m                     

                       Computation: 89810 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.7565
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9336
                     Learning rate: 0.0009
                       Mean reward: 103.83
               Mean episode length: 951.18
       Episode_Reward/keep_balance: 0.9386
     Episode_Reward/rew_lin_vel_xy: 5.0736
      Episode_Reward/rew_ang_vel_z: 2.2034
    Episode_Reward/pen_base_height: -0.3070
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.2048
   Episode_Reward/pen_joint_torque: -0.2214
    Episode_Reward/pen_joint_accel: -0.1254
    Episode_Reward/pen_action_rate: -0.1301
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0610
   Episode_Reward/pen_joint_powers: -0.0921
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2826
Episode_Reward/pen_flat_orientation: -0.1265
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.4353
   Episode_Reward/foot_landing_vel: -0.1472
   Episode_Reward/test_gait_reward: -0.9072
Metrics/base_velocity/error_vel_xy: 1.3408
Metrics/base_velocity/error_vel_yaw: 1.4301
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 1.09s
                        Total time: 1211.86s
                               ETA: 2052.8s

################################################################################
                     [1m Learning iteration 1114/3000 [0m                     

                       Computation: 89720 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 0.8211
                    Surrogate loss: -0.0014
             Mean action noise std: 0.9348
                     Learning rate: 0.0004
                       Mean reward: 111.48
               Mean episode length: 968.85
       Episode_Reward/keep_balance: 0.9575
     Episode_Reward/rew_lin_vel_xy: 5.3704
      Episode_Reward/rew_ang_vel_z: 2.2400
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.1999
   Episode_Reward/pen_joint_torque: -0.2177
    Episode_Reward/pen_joint_accel: -0.1145
    Episode_Reward/pen_action_rate: -0.1311
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0613
   Episode_Reward/pen_joint_powers: -0.0917
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2867
Episode_Reward/pen_flat_orientation: -0.1213
  Episode_Reward/pen_feet_distance: -0.0094
Episode_Reward/pen_feet_regulation: -0.4472
   Episode_Reward/foot_landing_vel: -0.1598
   Episode_Reward/test_gait_reward: -0.9274
Metrics/base_velocity/error_vel_xy: 1.2444
Metrics/base_velocity/error_vel_yaw: 1.4574
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 1.10s
                        Total time: 1212.96s
                               ETA: 2051.7s

################################################################################
                     [1m Learning iteration 1115/3000 [0m                     

                       Computation: 89578 steps/s (collection: 0.972s, learning 0.125s)
               Value function loss: 0.7814
                    Surrogate loss: -0.0052
             Mean action noise std: 0.9345
                     Learning rate: 0.0009
                       Mean reward: 109.50
               Mean episode length: 958.02
       Episode_Reward/keep_balance: 0.9563
     Episode_Reward/rew_lin_vel_xy: 5.3894
      Episode_Reward/rew_ang_vel_z: 2.2700
    Episode_Reward/pen_base_height: -0.3280
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.2044
   Episode_Reward/pen_joint_torque: -0.2317
    Episode_Reward/pen_joint_accel: -0.1270
    Episode_Reward/pen_action_rate: -0.1330
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0625
   Episode_Reward/pen_joint_powers: -0.0950
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2870
Episode_Reward/pen_flat_orientation: -0.1285
  Episode_Reward/pen_feet_distance: -0.0087
Episode_Reward/pen_feet_regulation: -0.4486
   Episode_Reward/foot_landing_vel: -0.1562
   Episode_Reward/test_gait_reward: -0.9316
Metrics/base_velocity/error_vel_xy: 1.2807
Metrics/base_velocity/error_vel_yaw: 1.4303
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 1.10s
                        Total time: 1214.05s
                               ETA: 2050.6s

################################################################################
                     [1m Learning iteration 1116/3000 [0m                     

                       Computation: 90467 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.7627
                    Surrogate loss: -0.0045
             Mean action noise std: 0.9361
                     Learning rate: 0.0013
                       Mean reward: 105.62
               Mean episode length: 947.50
       Episode_Reward/keep_balance: 0.9555
     Episode_Reward/rew_lin_vel_xy: 5.2314
      Episode_Reward/rew_ang_vel_z: 2.2320
    Episode_Reward/pen_base_height: -0.3218
      Episode_Reward/pen_lin_vel_z: -0.0451
     Episode_Reward/pen_ang_vel_xy: -0.2002
   Episode_Reward/pen_joint_torque: -0.2292
    Episode_Reward/pen_joint_accel: -0.1273
    Episode_Reward/pen_action_rate: -0.1321
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0631
   Episode_Reward/pen_joint_powers: -0.0948
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2858
Episode_Reward/pen_flat_orientation: -0.1257
  Episode_Reward/pen_feet_distance: -0.0092
Episode_Reward/pen_feet_regulation: -0.4407
   Episode_Reward/foot_landing_vel: -0.1561
   Episode_Reward/test_gait_reward: -0.9258
Metrics/base_velocity/error_vel_xy: 1.3352
Metrics/base_velocity/error_vel_yaw: 1.4675
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 1.09s
                        Total time: 1215.14s
                               ETA: 2049.5s

################################################################################
                     [1m Learning iteration 1117/3000 [0m                     

                       Computation: 89629 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.7332
                    Surrogate loss: -0.0012
             Mean action noise std: 0.9356
                     Learning rate: 0.0006
                       Mean reward: 105.46
               Mean episode length: 943.67
       Episode_Reward/keep_balance: 0.9568
     Episode_Reward/rew_lin_vel_xy: 5.3093
      Episode_Reward/rew_ang_vel_z: 2.2176
    Episode_Reward/pen_base_height: -0.3076
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.2070
   Episode_Reward/pen_joint_torque: -0.2292
    Episode_Reward/pen_joint_accel: -0.1220
    Episode_Reward/pen_action_rate: -0.1340
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0636
   Episode_Reward/pen_joint_powers: -0.0960
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2876
Episode_Reward/pen_flat_orientation: -0.1266
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.4469
   Episode_Reward/foot_landing_vel: -0.1524
   Episode_Reward/test_gait_reward: -0.9325
Metrics/base_velocity/error_vel_xy: 1.2522
Metrics/base_velocity/error_vel_yaw: 1.4752
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 1.10s
                        Total time: 1216.24s
                               ETA: 2048.5s

################################################################################
                     [1m Learning iteration 1118/3000 [0m                     

                       Computation: 90090 steps/s (collection: 0.965s, learning 0.126s)
               Value function loss: 0.6567
                    Surrogate loss: -0.0054
             Mean action noise std: 0.9319
                     Learning rate: 0.0009
                       Mean reward: 110.72
               Mean episode length: 973.85
       Episode_Reward/keep_balance: 0.9774
     Episode_Reward/rew_lin_vel_xy: 5.4635
      Episode_Reward/rew_ang_vel_z: 2.3274
    Episode_Reward/pen_base_height: -0.3118
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.2006
   Episode_Reward/pen_joint_torque: -0.2196
    Episode_Reward/pen_joint_accel: -0.1343
    Episode_Reward/pen_action_rate: -0.1320
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0605
   Episode_Reward/pen_joint_powers: -0.0908
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2902
Episode_Reward/pen_flat_orientation: -0.1197
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.4326
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.9428
Metrics/base_velocity/error_vel_xy: 1.2799
Metrics/base_velocity/error_vel_yaw: 1.4456
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 1.09s
                        Total time: 1217.33s
                               ETA: 2047.4s

################################################################################
                     [1m Learning iteration 1119/3000 [0m                     

                       Computation: 89946 steps/s (collection: 0.968s, learning 0.125s)
               Value function loss: 0.7460
                    Surrogate loss: -0.0039
             Mean action noise std: 0.9321
                     Learning rate: 0.0006
                       Mean reward: 109.45
               Mean episode length: 959.48
       Episode_Reward/keep_balance: 0.9537
     Episode_Reward/rew_lin_vel_xy: 5.3455
      Episode_Reward/rew_ang_vel_z: 2.2001
    Episode_Reward/pen_base_height: -0.3063
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.2023
   Episode_Reward/pen_joint_torque: -0.2174
    Episode_Reward/pen_joint_accel: -0.1273
    Episode_Reward/pen_action_rate: -0.1334
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0606
   Episode_Reward/pen_joint_powers: -0.0910
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2917
Episode_Reward/pen_flat_orientation: -0.1176
  Episode_Reward/pen_feet_distance: -0.0079
Episode_Reward/pen_feet_regulation: -0.4310
   Episode_Reward/foot_landing_vel: -0.1429
   Episode_Reward/test_gait_reward: -0.9289
Metrics/base_velocity/error_vel_xy: 1.2336
Metrics/base_velocity/error_vel_yaw: 1.5009
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 1.09s
                        Total time: 1218.42s
                               ETA: 2046.3s

################################################################################
                     [1m Learning iteration 1120/3000 [0m                     

                       Computation: 92541 steps/s (collection: 0.936s, learning 0.126s)
               Value function loss: 0.6871
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9312
                     Learning rate: 0.0006
                       Mean reward: 110.97
               Mean episode length: 971.64
       Episode_Reward/keep_balance: 0.9736
     Episode_Reward/rew_lin_vel_xy: 5.4736
      Episode_Reward/rew_ang_vel_z: 2.2998
    Episode_Reward/pen_base_height: -0.3150
      Episode_Reward/pen_lin_vel_z: -0.0438
     Episode_Reward/pen_ang_vel_xy: -0.1972
   Episode_Reward/pen_joint_torque: -0.2377
    Episode_Reward/pen_joint_accel: -0.1274
    Episode_Reward/pen_action_rate: -0.1336
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0626
   Episode_Reward/pen_joint_powers: -0.0957
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2899
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.4521
   Episode_Reward/foot_landing_vel: -0.1504
   Episode_Reward/test_gait_reward: -0.9505
Metrics/base_velocity/error_vel_xy: 1.2570
Metrics/base_velocity/error_vel_yaw: 1.4631
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 1.06s
                        Total time: 1219.48s
                               ETA: 2045.2s

################################################################################
                     [1m Learning iteration 1121/3000 [0m                     

                       Computation: 89939 steps/s (collection: 0.968s, learning 0.125s)
               Value function loss: 0.8053
                    Surrogate loss: 0.0018
             Mean action noise std: 0.9313
                     Learning rate: 0.0001
                       Mean reward: 114.74
               Mean episode length: 982.25
       Episode_Reward/keep_balance: 0.9842
     Episode_Reward/rew_lin_vel_xy: 5.6054
      Episode_Reward/rew_ang_vel_z: 2.3650
    Episode_Reward/pen_base_height: -0.3174
      Episode_Reward/pen_lin_vel_z: -0.0432
     Episode_Reward/pen_ang_vel_xy: -0.2033
   Episode_Reward/pen_joint_torque: -0.2319
    Episode_Reward/pen_joint_accel: -0.1142
    Episode_Reward/pen_action_rate: -0.1314
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0610
   Episode_Reward/pen_joint_powers: -0.0936
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2880
Episode_Reward/pen_flat_orientation: -0.1197
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.4323
   Episode_Reward/foot_landing_vel: -0.1516
   Episode_Reward/test_gait_reward: -0.9540
Metrics/base_velocity/error_vel_xy: 1.2550
Metrics/base_velocity/error_vel_yaw: 1.4244
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 1.09s
                        Total time: 1220.58s
                               ETA: 2044.1s

################################################################################
                     [1m Learning iteration 1122/3000 [0m                     

                       Computation: 89312 steps/s (collection: 0.975s, learning 0.125s)
               Value function loss: 0.7219
                    Surrogate loss: -0.0045
             Mean action noise std: 0.9300
                     Learning rate: 0.0003
                       Mean reward: 109.50
               Mean episode length: 937.95
       Episode_Reward/keep_balance: 0.9294
     Episode_Reward/rew_lin_vel_xy: 5.2815
      Episode_Reward/rew_ang_vel_z: 2.1745
    Episode_Reward/pen_base_height: -0.2984
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1990
   Episode_Reward/pen_joint_torque: -0.2109
    Episode_Reward/pen_joint_accel: -0.1195
    Episode_Reward/pen_action_rate: -0.1273
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2790
Episode_Reward/pen_flat_orientation: -0.1178
  Episode_Reward/pen_feet_distance: -0.0072
Episode_Reward/pen_feet_regulation: -0.4162
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.8985
Metrics/base_velocity/error_vel_xy: 1.1548
Metrics/base_velocity/error_vel_yaw: 1.4152
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 1.10s
                        Total time: 1221.68s
                               ETA: 2043.0s

################################################################################
                     [1m Learning iteration 1123/3000 [0m                     

                       Computation: 90166 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.7963
                    Surrogate loss: -0.0039
             Mean action noise std: 0.9287
                     Learning rate: 0.0006
                       Mean reward: 106.88
               Mean episode length: 948.27
       Episode_Reward/keep_balance: 0.9557
     Episode_Reward/rew_lin_vel_xy: 5.4134
      Episode_Reward/rew_ang_vel_z: 2.2221
    Episode_Reward/pen_base_height: -0.3114
      Episode_Reward/pen_lin_vel_z: -0.0452
     Episode_Reward/pen_ang_vel_xy: -0.2020
   Episode_Reward/pen_joint_torque: -0.2299
    Episode_Reward/pen_joint_accel: -0.1276
    Episode_Reward/pen_action_rate: -0.1323
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0631
   Episode_Reward/pen_joint_powers: -0.0955
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2868
Episode_Reward/pen_flat_orientation: -0.1230
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.4666
   Episode_Reward/foot_landing_vel: -0.1553
   Episode_Reward/test_gait_reward: -0.9403
Metrics/base_velocity/error_vel_xy: 1.2224
Metrics/base_velocity/error_vel_yaw: 1.4665
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 1.09s
                        Total time: 1222.77s
                               ETA: 2041.9s

################################################################################
                     [1m Learning iteration 1124/3000 [0m                     

                       Computation: 89765 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 0.7767
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9293
                     Learning rate: 0.0003
                       Mean reward: 106.31
               Mean episode length: 947.06
       Episode_Reward/keep_balance: 0.9570
     Episode_Reward/rew_lin_vel_xy: 5.3360
      Episode_Reward/rew_ang_vel_z: 2.2422
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0448
     Episode_Reward/pen_ang_vel_xy: -0.1992
   Episode_Reward/pen_joint_torque: -0.2224
    Episode_Reward/pen_joint_accel: -0.1198
    Episode_Reward/pen_action_rate: -0.1302
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0613
   Episode_Reward/pen_joint_powers: -0.0924
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2844
Episode_Reward/pen_flat_orientation: -0.1180
  Episode_Reward/pen_feet_distance: -0.0073
Episode_Reward/pen_feet_regulation: -0.4511
   Episode_Reward/foot_landing_vel: -0.1481
   Episode_Reward/test_gait_reward: -0.9350
Metrics/base_velocity/error_vel_xy: 1.2633
Metrics/base_velocity/error_vel_yaw: 1.4454
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 1.10s
                        Total time: 1223.86s
                               ETA: 2040.9s

################################################################################
                     [1m Learning iteration 1125/3000 [0m                     

                       Computation: 89664 steps/s (collection: 0.966s, learning 0.130s)
               Value function loss: 0.8401
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9294
                     Learning rate: 0.0004
                       Mean reward: 109.05
               Mean episode length: 953.85
       Episode_Reward/keep_balance: 0.9619
     Episode_Reward/rew_lin_vel_xy: 5.4410
      Episode_Reward/rew_ang_vel_z: 2.2791
    Episode_Reward/pen_base_height: -0.3305
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.2005
   Episode_Reward/pen_joint_torque: -0.2287
    Episode_Reward/pen_joint_accel: -0.1181
    Episode_Reward/pen_action_rate: -0.1310
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0625
   Episode_Reward/pen_joint_powers: -0.0943
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2834
Episode_Reward/pen_flat_orientation: -0.1215
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.4631
   Episode_Reward/foot_landing_vel: -0.1514
   Episode_Reward/test_gait_reward: -0.9386
Metrics/base_velocity/error_vel_xy: 1.2310
Metrics/base_velocity/error_vel_yaw: 1.4278
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 1.10s
                        Total time: 1224.96s
                               ETA: 2039.8s

################################################################################
                     [1m Learning iteration 1126/3000 [0m                     

                       Computation: 91413 steps/s (collection: 0.950s, learning 0.125s)
               Value function loss: 0.9563
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9291
                     Learning rate: 0.0009
                       Mean reward: 109.39
               Mean episode length: 943.01
       Episode_Reward/keep_balance: 0.9138
     Episode_Reward/rew_lin_vel_xy: 5.1821
      Episode_Reward/rew_ang_vel_z: 2.1587
    Episode_Reward/pen_base_height: -0.3176
      Episode_Reward/pen_lin_vel_z: -0.0422
     Episode_Reward/pen_ang_vel_xy: -0.1938
   Episode_Reward/pen_joint_torque: -0.2160
    Episode_Reward/pen_joint_accel: -0.1169
    Episode_Reward/pen_action_rate: -0.1246
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2722
Episode_Reward/pen_flat_orientation: -0.1268
  Episode_Reward/pen_feet_distance: -0.0086
Episode_Reward/pen_feet_regulation: -0.4321
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.8940
Metrics/base_velocity/error_vel_xy: 1.1729
Metrics/base_velocity/error_vel_yaw: 1.3796
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 1.08s
                        Total time: 1226.03s
                               ETA: 2038.7s

################################################################################
                     [1m Learning iteration 1127/3000 [0m                     

                       Computation: 90690 steps/s (collection: 0.959s, learning 0.125s)
               Value function loss: 0.7825
                    Surrogate loss: 0.0005
             Mean action noise std: 0.9282
                     Learning rate: 0.0003
                       Mean reward: 103.88
               Mean episode length: 894.70
       Episode_Reward/keep_balance: 0.9261
     Episode_Reward/rew_lin_vel_xy: 5.3503
      Episode_Reward/rew_ang_vel_z: 2.1440
    Episode_Reward/pen_base_height: -0.3005
      Episode_Reward/pen_lin_vel_z: -0.0414
     Episode_Reward/pen_ang_vel_xy: -0.1988
   Episode_Reward/pen_joint_torque: -0.2127
    Episode_Reward/pen_joint_accel: -0.1283
    Episode_Reward/pen_action_rate: -0.1262
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0896
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2781
Episode_Reward/pen_flat_orientation: -0.1158
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.4260
   Episode_Reward/foot_landing_vel: -0.1513
   Episode_Reward/test_gait_reward: -0.8986
Metrics/base_velocity/error_vel_xy: 1.1187
Metrics/base_velocity/error_vel_yaw: 1.4249
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 1.08s
                        Total time: 1227.12s
                               ETA: 2037.6s

################################################################################
                     [1m Learning iteration 1128/3000 [0m                     

                       Computation: 91371 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.8033
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9272
                     Learning rate: 0.0006
                       Mean reward: 104.65
               Mean episode length: 928.76
       Episode_Reward/keep_balance: 0.9217
     Episode_Reward/rew_lin_vel_xy: 5.1435
      Episode_Reward/rew_ang_vel_z: 2.1158
    Episode_Reward/pen_base_height: -0.3186
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.2008
   Episode_Reward/pen_joint_torque: -0.2216
    Episode_Reward/pen_joint_accel: -0.1130
    Episode_Reward/pen_action_rate: -0.1292
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0928
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2797
Episode_Reward/pen_flat_orientation: -0.1259
  Episode_Reward/pen_feet_distance: -0.0084
Episode_Reward/pen_feet_regulation: -0.4419
   Episode_Reward/foot_landing_vel: -0.1364
   Episode_Reward/test_gait_reward: -0.9070
Metrics/base_velocity/error_vel_xy: 1.2088
Metrics/base_velocity/error_vel_yaw: 1.4516
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 1.08s
                        Total time: 1228.19s
                               ETA: 2036.5s

################################################################################
                     [1m Learning iteration 1129/3000 [0m                     

                       Computation: 91057 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.8282
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9276
                     Learning rate: 0.0009
                       Mean reward: 110.02
               Mean episode length: 951.57
       Episode_Reward/keep_balance: 0.9597
     Episode_Reward/rew_lin_vel_xy: 5.4422
      Episode_Reward/rew_ang_vel_z: 2.2454
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0429
     Episode_Reward/pen_ang_vel_xy: -0.1994
   Episode_Reward/pen_joint_torque: -0.2309
    Episode_Reward/pen_joint_accel: -0.1141
    Episode_Reward/pen_action_rate: -0.1322
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0609
   Episode_Reward/pen_joint_powers: -0.0938
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2889
Episode_Reward/pen_flat_orientation: -0.1200
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.4335
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.9352
Metrics/base_velocity/error_vel_xy: 1.2281
Metrics/base_velocity/error_vel_yaw: 1.4704
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 1.08s
                        Total time: 1229.27s
                               ETA: 2035.4s

################################################################################
                     [1m Learning iteration 1130/3000 [0m                     

                       Computation: 85636 steps/s (collection: 1.022s, learning 0.126s)
               Value function loss: 0.8132
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9289
                     Learning rate: 0.0013
                       Mean reward: 104.89
               Mean episode length: 927.39
       Episode_Reward/keep_balance: 0.9466
     Episode_Reward/rew_lin_vel_xy: 5.3387
      Episode_Reward/rew_ang_vel_z: 2.2306
    Episode_Reward/pen_base_height: -0.3232
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1994
   Episode_Reward/pen_joint_torque: -0.2274
    Episode_Reward/pen_joint_accel: -0.1203
    Episode_Reward/pen_action_rate: -0.1308
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0607
   Episode_Reward/pen_joint_powers: -0.0933
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2829
Episode_Reward/pen_flat_orientation: -0.1244
  Episode_Reward/pen_feet_distance: -0.0082
Episode_Reward/pen_feet_regulation: -0.4489
   Episode_Reward/foot_landing_vel: -0.1413
   Episode_Reward/test_gait_reward: -0.9273
Metrics/base_velocity/error_vel_xy: 1.2105
Metrics/base_velocity/error_vel_yaw: 1.4355
      Episode_Termination/time_out: 5.0417
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 1.15s
                        Total time: 1230.42s
                               ETA: 2034.4s

################################################################################
                     [1m Learning iteration 1131/3000 [0m                     

                       Computation: 88718 steps/s (collection: 0.982s, learning 0.126s)
               Value function loss: 0.8646
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9309
                     Learning rate: 0.0019
                       Mean reward: 114.46
               Mean episode length: 951.42
       Episode_Reward/keep_balance: 0.9477
     Episode_Reward/rew_lin_vel_xy: 5.5733
      Episode_Reward/rew_ang_vel_z: 2.2573
    Episode_Reward/pen_base_height: -0.3025
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1986
   Episode_Reward/pen_joint_torque: -0.2149
    Episode_Reward/pen_joint_accel: -0.1110
    Episode_Reward/pen_action_rate: -0.1266
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2796
Episode_Reward/pen_flat_orientation: -0.1144
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.4149
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.9120
Metrics/base_velocity/error_vel_xy: 1.1013
Metrics/base_velocity/error_vel_yaw: 1.4007
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 1.11s
                        Total time: 1231.53s
                               ETA: 2033.3s

################################################################################
                     [1m Learning iteration 1132/3000 [0m                     

                       Computation: 89042 steps/s (collection: 0.981s, learning 0.123s)
               Value function loss: 0.7702
                    Surrogate loss: -0.0012
             Mean action noise std: 0.9313
                     Learning rate: 0.0009
                       Mean reward: 111.23
               Mean episode length: 964.65
       Episode_Reward/keep_balance: 0.9651
     Episode_Reward/rew_lin_vel_xy: 5.4734
      Episode_Reward/rew_ang_vel_z: 2.3111
    Episode_Reward/pen_base_height: -0.3402
      Episode_Reward/pen_lin_vel_z: -0.0443
     Episode_Reward/pen_ang_vel_xy: -0.2003
   Episode_Reward/pen_joint_torque: -0.2413
    Episode_Reward/pen_joint_accel: -0.1210
    Episode_Reward/pen_action_rate: -0.1309
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0622
   Episode_Reward/pen_joint_powers: -0.0962
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2807
Episode_Reward/pen_flat_orientation: -0.1254
  Episode_Reward/pen_feet_distance: -0.0100
Episode_Reward/pen_feet_regulation: -0.4504
   Episode_Reward/foot_landing_vel: -0.1526
   Episode_Reward/test_gait_reward: -0.9374
Metrics/base_velocity/error_vel_xy: 1.2502
Metrics/base_velocity/error_vel_yaw: 1.4126
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 1.10s
                        Total time: 1232.63s
                               ETA: 2032.3s

################################################################################
                     [1m Learning iteration 1133/3000 [0m                     

                       Computation: 90649 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.8077
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9307
                     Learning rate: 0.0006
                       Mean reward: 111.24
               Mean episode length: 969.39
       Episode_Reward/keep_balance: 0.9745
     Episode_Reward/rew_lin_vel_xy: 5.5610
      Episode_Reward/rew_ang_vel_z: 2.2788
    Episode_Reward/pen_base_height: -0.3155
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.2109
   Episode_Reward/pen_joint_torque: -0.2302
    Episode_Reward/pen_joint_accel: -0.1143
    Episode_Reward/pen_action_rate: -0.1344
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0633
   Episode_Reward/pen_joint_powers: -0.0956
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2929
Episode_Reward/pen_flat_orientation: -0.1191
  Episode_Reward/pen_feet_distance: -0.0094
Episode_Reward/pen_feet_regulation: -0.4589
   Episode_Reward/foot_landing_vel: -0.1553
   Episode_Reward/test_gait_reward: -0.9446
Metrics/base_velocity/error_vel_xy: 1.2304
Metrics/base_velocity/error_vel_yaw: 1.4815
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 1.08s
                        Total time: 1233.72s
                               ETA: 2031.2s

################################################################################
                     [1m Learning iteration 1134/3000 [0m                     

                       Computation: 89840 steps/s (collection: 0.968s, learning 0.126s)
               Value function loss: 0.7771
                    Surrogate loss: -0.0046
             Mean action noise std: 0.9311
                     Learning rate: 0.0013
                       Mean reward: 106.80
               Mean episode length: 935.72
       Episode_Reward/keep_balance: 0.9172
     Episode_Reward/rew_lin_vel_xy: 5.2877
      Episode_Reward/rew_ang_vel_z: 2.1308
    Episode_Reward/pen_base_height: -0.3192
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.2027
   Episode_Reward/pen_joint_torque: -0.2162
    Episode_Reward/pen_joint_accel: -0.1194
    Episode_Reward/pen_action_rate: -0.1285
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0917
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2794
Episode_Reward/pen_flat_orientation: -0.1256
  Episode_Reward/pen_feet_distance: -0.0082
Episode_Reward/pen_feet_regulation: -0.4445
   Episode_Reward/foot_landing_vel: -0.1532
   Episode_Reward/test_gait_reward: -0.8965
Metrics/base_velocity/error_vel_xy: 1.1099
Metrics/base_velocity/error_vel_yaw: 1.4086
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 1.09s
                        Total time: 1234.81s
                               ETA: 2030.1s

################################################################################
                     [1m Learning iteration 1135/3000 [0m                     

                       Computation: 90551 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.9274
                    Surrogate loss: 0.0054
             Mean action noise std: 0.9317
                     Learning rate: 0.0000
                       Mean reward: 113.20
               Mean episode length: 964.58
       Episode_Reward/keep_balance: 0.9723
     Episode_Reward/rew_lin_vel_xy: 5.5858
      Episode_Reward/rew_ang_vel_z: 2.2971
    Episode_Reward/pen_base_height: -0.3201
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.1962
   Episode_Reward/pen_joint_torque: -0.2335
    Episode_Reward/pen_joint_accel: -0.1123
    Episode_Reward/pen_action_rate: -0.1317
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0606
   Episode_Reward/pen_joint_powers: -0.0942
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2863
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0075
Episode_Reward/pen_feet_regulation: -0.4470
   Episode_Reward/foot_landing_vel: -0.1433
   Episode_Reward/test_gait_reward: -0.9513
Metrics/base_velocity/error_vel_xy: 1.1967
Metrics/base_velocity/error_vel_yaw: 1.4515
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 1.09s
                        Total time: 1235.90s
                               ETA: 2029.0s

################################################################################
                     [1m Learning iteration 1136/3000 [0m                     

                       Computation: 89572 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.7213
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9322
                     Learning rate: 0.0002
                       Mean reward: 102.92
               Mean episode length: 921.26
       Episode_Reward/keep_balance: 0.9158
     Episode_Reward/rew_lin_vel_xy: 5.1033
      Episode_Reward/rew_ang_vel_z: 2.1177
    Episode_Reward/pen_base_height: -0.3199
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.2012
   Episode_Reward/pen_joint_torque: -0.2132
    Episode_Reward/pen_joint_accel: -0.1095
    Episode_Reward/pen_action_rate: -0.1279
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0612
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2770
Episode_Reward/pen_flat_orientation: -0.1239
  Episode_Reward/pen_feet_distance: -0.0094
Episode_Reward/pen_feet_regulation: -0.4469
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.8942
Metrics/base_velocity/error_vel_xy: 1.2100
Metrics/base_velocity/error_vel_yaw: 1.4211
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 1.10s
                        Total time: 1237.00s
                               ETA: 2027.9s

################################################################################
                     [1m Learning iteration 1137/3000 [0m                     

                       Computation: 90355 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.6954
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9315
                     Learning rate: 0.0004
                       Mean reward: 108.77
               Mean episode length: 952.93
       Episode_Reward/keep_balance: 0.9547
     Episode_Reward/rew_lin_vel_xy: 5.4285
      Episode_Reward/rew_ang_vel_z: 2.2452
    Episode_Reward/pen_base_height: -0.3277
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.2011
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.1152
    Episode_Reward/pen_action_rate: -0.1305
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0618
   Episode_Reward/pen_joint_powers: -0.0938
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2837
Episode_Reward/pen_flat_orientation: -0.1231
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.4582
   Episode_Reward/foot_landing_vel: -0.1393
   Episode_Reward/test_gait_reward: -0.9423
Metrics/base_velocity/error_vel_xy: 1.1840
Metrics/base_velocity/error_vel_yaw: 1.4438
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 1.09s
                        Total time: 1238.08s
                               ETA: 2026.8s

################################################################################
                     [1m Learning iteration 1138/3000 [0m                     

                       Computation: 91104 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.7377
                    Surrogate loss: -0.0022
             Mean action noise std: 0.9308
                     Learning rate: 0.0004
                       Mean reward: 117.48
               Mean episode length: 991.13
       Episode_Reward/keep_balance: 0.9926
     Episode_Reward/rew_lin_vel_xy: 5.8005
      Episode_Reward/rew_ang_vel_z: 2.3727
    Episode_Reward/pen_base_height: -0.3170
      Episode_Reward/pen_lin_vel_z: -0.0429
     Episode_Reward/pen_ang_vel_xy: -0.2042
   Episode_Reward/pen_joint_torque: -0.2307
    Episode_Reward/pen_joint_accel: -0.1261
    Episode_Reward/pen_action_rate: -0.1337
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0623
   Episode_Reward/pen_joint_powers: -0.0946
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2943
Episode_Reward/pen_flat_orientation: -0.1142
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.4502
   Episode_Reward/foot_landing_vel: -0.1474
   Episode_Reward/test_gait_reward: -0.9667
Metrics/base_velocity/error_vel_xy: 1.1678
Metrics/base_velocity/error_vel_yaw: 1.4639
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 1.08s
                        Total time: 1239.16s
                               ETA: 2025.7s

################################################################################
                     [1m Learning iteration 1139/3000 [0m                     

                       Computation: 88688 steps/s (collection: 0.982s, learning 0.127s)
               Value function loss: 0.7503
                    Surrogate loss: 0.0015
             Mean action noise std: 0.9296
                     Learning rate: 0.0001
                       Mean reward: 110.83
               Mean episode length: 967.49
       Episode_Reward/keep_balance: 0.9709
     Episode_Reward/rew_lin_vel_xy: 5.5064
      Episode_Reward/rew_ang_vel_z: 2.2427
    Episode_Reward/pen_base_height: -0.3244
      Episode_Reward/pen_lin_vel_z: -0.0425
     Episode_Reward/pen_ang_vel_xy: -0.2104
   Episode_Reward/pen_joint_torque: -0.2276
    Episode_Reward/pen_joint_accel: -0.1269
    Episode_Reward/pen_action_rate: -0.1361
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0656
   Episode_Reward/pen_joint_powers: -0.0970
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2962
Episode_Reward/pen_flat_orientation: -0.1266
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.4786
   Episode_Reward/foot_landing_vel: -0.1564
   Episode_Reward/test_gait_reward: -0.9522
Metrics/base_velocity/error_vel_xy: 1.2221
Metrics/base_velocity/error_vel_yaw: 1.5252
      Episode_Termination/time_out: 3.1250
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 1.11s
                        Total time: 1240.27s
                               ETA: 2024.7s

################################################################################
                     [1m Learning iteration 1140/3000 [0m                     

                       Computation: 89765 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.7248
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9287
                     Learning rate: 0.0003
                       Mean reward: 109.82
               Mean episode length: 978.45
       Episode_Reward/keep_balance: 0.9751
     Episode_Reward/rew_lin_vel_xy: 5.5728
      Episode_Reward/rew_ang_vel_z: 2.2856
    Episode_Reward/pen_base_height: -0.3221
      Episode_Reward/pen_lin_vel_z: -0.0465
     Episode_Reward/pen_ang_vel_xy: -0.2013
   Episode_Reward/pen_joint_torque: -0.2322
    Episode_Reward/pen_joint_accel: -0.1199
    Episode_Reward/pen_action_rate: -0.1333
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0634
   Episode_Reward/pen_joint_powers: -0.0959
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2896
Episode_Reward/pen_flat_orientation: -0.1180
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.4804
   Episode_Reward/foot_landing_vel: -0.1577
   Episode_Reward/test_gait_reward: -0.9553
Metrics/base_velocity/error_vel_xy: 1.2207
Metrics/base_velocity/error_vel_yaw: 1.4725
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 1.10s
                        Total time: 1241.37s
                               ETA: 2023.6s

################################################################################
                     [1m Learning iteration 1141/3000 [0m                     

                       Computation: 88060 steps/s (collection: 0.989s, learning 0.127s)
               Value function loss: 0.7491
                    Surrogate loss: -0.0045
             Mean action noise std: 0.9291
                     Learning rate: 0.0006
                       Mean reward: 106.81
               Mean episode length: 952.88
       Episode_Reward/keep_balance: 0.9581
     Episode_Reward/rew_lin_vel_xy: 5.3680
      Episode_Reward/rew_ang_vel_z: 2.1959
    Episode_Reward/pen_base_height: -0.3278
      Episode_Reward/pen_lin_vel_z: -0.0429
     Episode_Reward/pen_ang_vel_xy: -0.2107
   Episode_Reward/pen_joint_torque: -0.2246
    Episode_Reward/pen_joint_accel: -0.1205
    Episode_Reward/pen_action_rate: -0.1353
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0643
   Episode_Reward/pen_joint_powers: -0.0956
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2925
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.4828
   Episode_Reward/foot_landing_vel: -0.1526
   Episode_Reward/test_gait_reward: -0.9422
Metrics/base_velocity/error_vel_xy: 1.2362
Metrics/base_velocity/error_vel_yaw: 1.5162
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 1.12s
                        Total time: 1242.48s
                               ETA: 2022.6s

################################################################################
                     [1m Learning iteration 1142/3000 [0m                     

                       Computation: 89884 steps/s (collection: 0.967s, learning 0.126s)
               Value function loss: 0.6738
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9290
                     Learning rate: 0.0006
                       Mean reward: 115.04
               Mean episode length: 970.14
       Episode_Reward/keep_balance: 0.9669
     Episode_Reward/rew_lin_vel_xy: 5.5718
      Episode_Reward/rew_ang_vel_z: 2.2803
    Episode_Reward/pen_base_height: -0.3032
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1996
   Episode_Reward/pen_joint_torque: -0.2163
    Episode_Reward/pen_joint_accel: -0.1107
    Episode_Reward/pen_action_rate: -0.1296
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2875
Episode_Reward/pen_flat_orientation: -0.1139
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.4266
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.9338
Metrics/base_velocity/error_vel_xy: 1.1689
Metrics/base_velocity/error_vel_yaw: 1.4579
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 1.09s
                        Total time: 1243.58s
                               ETA: 2021.5s

################################################################################
                     [1m Learning iteration 1143/3000 [0m                     

                       Computation: 89915 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.6735
                    Surrogate loss: -0.0027
             Mean action noise std: 0.9288
                     Learning rate: 0.0009
                       Mean reward: 115.53
               Mean episode length: 981.79
       Episode_Reward/keep_balance: 0.9826
     Episode_Reward/rew_lin_vel_xy: 5.7029
      Episode_Reward/rew_ang_vel_z: 2.3081
    Episode_Reward/pen_base_height: -0.3453
      Episode_Reward/pen_lin_vel_z: -0.0449
     Episode_Reward/pen_ang_vel_xy: -0.2137
   Episode_Reward/pen_joint_torque: -0.2360
    Episode_Reward/pen_joint_accel: -0.1151
    Episode_Reward/pen_action_rate: -0.1358
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0640
   Episode_Reward/pen_joint_powers: -0.0969
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2965
Episode_Reward/pen_flat_orientation: -0.1235
  Episode_Reward/pen_feet_distance: -0.0086
Episode_Reward/pen_feet_regulation: -0.4818
   Episode_Reward/foot_landing_vel: -0.1520
   Episode_Reward/test_gait_reward: -0.9641
Metrics/base_velocity/error_vel_xy: 1.2104
Metrics/base_velocity/error_vel_yaw: 1.4890
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 1.09s
                        Total time: 1244.67s
                               ETA: 2020.4s

################################################################################
                     [1m Learning iteration 1144/3000 [0m                     

                       Computation: 90548 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.7097
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9295
                     Learning rate: 0.0009
                       Mean reward: 117.48
               Mean episode length: 999.23
       Episode_Reward/keep_balance: 0.9992
     Episode_Reward/rew_lin_vel_xy: 5.7860
      Episode_Reward/rew_ang_vel_z: 2.3803
    Episode_Reward/pen_base_height: -0.3286
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.2082
   Episode_Reward/pen_joint_torque: -0.2455
    Episode_Reward/pen_joint_accel: -0.1197
    Episode_Reward/pen_action_rate: -0.1352
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0648
   Episode_Reward/pen_joint_powers: -0.0991
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2949
Episode_Reward/pen_flat_orientation: -0.1167
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.4928
   Episode_Reward/foot_landing_vel: -0.1579
   Episode_Reward/test_gait_reward: -0.9751
Metrics/base_velocity/error_vel_xy: 1.2148
Metrics/base_velocity/error_vel_yaw: 1.4648
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 1.09s
                        Total time: 1245.76s
                               ETA: 2019.3s

################################################################################
                     [1m Learning iteration 1145/3000 [0m                     

                       Computation: 89125 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.6987
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9272
                     Learning rate: 0.0003
                       Mean reward: 115.43
               Mean episode length: 979.42
       Episode_Reward/keep_balance: 0.9676
     Episode_Reward/rew_lin_vel_xy: 5.5907
      Episode_Reward/rew_ang_vel_z: 2.2842
    Episode_Reward/pen_base_height: -0.3219
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.2086
   Episode_Reward/pen_joint_torque: -0.2315
    Episode_Reward/pen_joint_accel: -0.1222
    Episode_Reward/pen_action_rate: -0.1326
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0623
   Episode_Reward/pen_joint_powers: -0.0944
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2883
Episode_Reward/pen_flat_orientation: -0.1166
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.4715
   Episode_Reward/foot_landing_vel: -0.1544
   Episode_Reward/test_gait_reward: -0.9432
Metrics/base_velocity/error_vel_xy: 1.1772
Metrics/base_velocity/error_vel_yaw: 1.4440
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 1.10s
                        Total time: 1246.86s
                               ETA: 2018.3s

################################################################################
                     [1m Learning iteration 1146/3000 [0m                     

                       Computation: 90767 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.7288
                    Surrogate loss: -0.0027
             Mean action noise std: 0.9265
                     Learning rate: 0.0004
                       Mean reward: 109.57
               Mean episode length: 943.37
       Episode_Reward/keep_balance: 0.9531
     Episode_Reward/rew_lin_vel_xy: 5.5166
      Episode_Reward/rew_ang_vel_z: 2.2288
    Episode_Reward/pen_base_height: -0.3153
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1969
   Episode_Reward/pen_joint_torque: -0.2289
    Episode_Reward/pen_joint_accel: -0.1258
    Episode_Reward/pen_action_rate: -0.1315
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0624
   Episode_Reward/pen_joint_powers: -0.0944
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2852
Episode_Reward/pen_flat_orientation: -0.1188
  Episode_Reward/pen_feet_distance: -0.0111
Episode_Reward/pen_feet_regulation: -0.4482
   Episode_Reward/foot_landing_vel: -0.1518
   Episode_Reward/test_gait_reward: -0.9268
Metrics/base_velocity/error_vel_xy: 1.1515
Metrics/base_velocity/error_vel_yaw: 1.4592
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 1.08s
                        Total time: 1247.94s
                               ETA: 2017.2s

################################################################################
                     [1m Learning iteration 1147/3000 [0m                     

                       Computation: 90477 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.6813
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9266
                     Learning rate: 0.0004
                       Mean reward: 114.03
               Mean episode length: 971.79
       Episode_Reward/keep_balance: 0.9727
     Episode_Reward/rew_lin_vel_xy: 5.6924
      Episode_Reward/rew_ang_vel_z: 2.2566
    Episode_Reward/pen_base_height: -0.3118
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.2072
   Episode_Reward/pen_joint_torque: -0.2212
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1339
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0616
   Episode_Reward/pen_joint_powers: -0.0935
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2919
Episode_Reward/pen_flat_orientation: -0.1199
  Episode_Reward/pen_feet_distance: -0.0110
Episode_Reward/pen_feet_regulation: -0.4390
   Episode_Reward/foot_landing_vel: -0.1498
   Episode_Reward/test_gait_reward: -0.9428
Metrics/base_velocity/error_vel_xy: 1.1483
Metrics/base_velocity/error_vel_yaw: 1.5032
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 1.09s
                        Total time: 1249.03s
                               ETA: 2016.1s

################################################################################
                     [1m Learning iteration 1148/3000 [0m                     

                       Computation: 88264 steps/s (collection: 0.992s, learning 0.122s)
               Value function loss: 0.8003
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9270
                     Learning rate: 0.0003
                       Mean reward: 109.98
               Mean episode length: 961.04
       Episode_Reward/keep_balance: 0.9480
     Episode_Reward/rew_lin_vel_xy: 5.4965
      Episode_Reward/rew_ang_vel_z: 2.2183
    Episode_Reward/pen_base_height: -0.3242
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.2037
   Episode_Reward/pen_joint_torque: -0.2234
    Episode_Reward/pen_joint_accel: -0.1155
    Episode_Reward/pen_action_rate: -0.1311
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0621
   Episode_Reward/pen_joint_powers: -0.0937
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2854
Episode_Reward/pen_flat_orientation: -0.1246
  Episode_Reward/pen_feet_distance: -0.0122
Episode_Reward/pen_feet_regulation: -0.4767
   Episode_Reward/foot_landing_vel: -0.1480
   Episode_Reward/test_gait_reward: -0.9382
Metrics/base_velocity/error_vel_xy: 1.1537
Metrics/base_velocity/error_vel_yaw: 1.4416
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 1.11s
                        Total time: 1250.14s
                               ETA: 2015.0s

################################################################################
                     [1m Learning iteration 1149/3000 [0m                     

                       Computation: 90184 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.7076
                    Surrogate loss: -0.0015
             Mean action noise std: 0.9258
                     Learning rate: 0.0002
                       Mean reward: 109.47
               Mean episode length: 959.00
       Episode_Reward/keep_balance: 0.9552
     Episode_Reward/rew_lin_vel_xy: 5.4681
      Episode_Reward/rew_ang_vel_z: 2.2156
    Episode_Reward/pen_base_height: -0.3280
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.2013
   Episode_Reward/pen_joint_torque: -0.2271
    Episode_Reward/pen_joint_accel: -0.1184
    Episode_Reward/pen_action_rate: -0.1320
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0615
   Episode_Reward/pen_joint_powers: -0.0932
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2856
Episode_Reward/pen_flat_orientation: -0.1196
  Episode_Reward/pen_feet_distance: -0.0108
Episode_Reward/pen_feet_regulation: -0.4395
   Episode_Reward/foot_landing_vel: -0.1484
   Episode_Reward/test_gait_reward: -0.9321
Metrics/base_velocity/error_vel_xy: 1.2015
Metrics/base_velocity/error_vel_yaw: 1.4769
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 1.09s
                        Total time: 1251.23s
                               ETA: 2013.9s

################################################################################
                     [1m Learning iteration 1150/3000 [0m                     

                       Computation: 89749 steps/s (collection: 0.970s, learning 0.126s)
               Value function loss: 0.8315
                    Surrogate loss: -0.0044
             Mean action noise std: 0.9261
                     Learning rate: 0.0004
                       Mean reward: 108.56
               Mean episode length: 939.35
       Episode_Reward/keep_balance: 0.9424
     Episode_Reward/rew_lin_vel_xy: 5.4320
      Episode_Reward/rew_ang_vel_z: 2.2210
    Episode_Reward/pen_base_height: -0.3342
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.1997
   Episode_Reward/pen_joint_torque: -0.2304
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1296
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0609
   Episode_Reward/pen_joint_powers: -0.0934
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2810
Episode_Reward/pen_flat_orientation: -0.1277
  Episode_Reward/pen_feet_distance: -0.0123
Episode_Reward/pen_feet_regulation: -0.4469
   Episode_Reward/foot_landing_vel: -0.1483
   Episode_Reward/test_gait_reward: -0.9202
Metrics/base_velocity/error_vel_xy: 1.1400
Metrics/base_velocity/error_vel_yaw: 1.4226
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 1.10s
                        Total time: 1252.33s
                               ETA: 2012.9s

################################################################################
                     [1m Learning iteration 1151/3000 [0m                     

                       Computation: 86247 steps/s (collection: 1.017s, learning 0.123s)
               Value function loss: 0.7416
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9268
                     Learning rate: 0.0009
                       Mean reward: 111.57
               Mean episode length: 939.50
       Episode_Reward/keep_balance: 0.9474
     Episode_Reward/rew_lin_vel_xy: 5.5082
      Episode_Reward/rew_ang_vel_z: 2.2310
    Episode_Reward/pen_base_height: -0.3140
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.2017
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.1241
    Episode_Reward/pen_action_rate: -0.1303
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0617
   Episode_Reward/pen_joint_powers: -0.0932
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2840
Episode_Reward/pen_flat_orientation: -0.1182
  Episode_Reward/pen_feet_distance: -0.0112
Episode_Reward/pen_feet_regulation: -0.4410
   Episode_Reward/foot_landing_vel: -0.1475
   Episode_Reward/test_gait_reward: -0.9313
Metrics/base_velocity/error_vel_xy: 1.1507
Metrics/base_velocity/error_vel_yaw: 1.4347
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 1.14s
                        Total time: 1253.47s
                               ETA: 2011.9s

################################################################################
                     [1m Learning iteration 1152/3000 [0m                     

                       Computation: 88179 steps/s (collection: 0.991s, learning 0.124s)
               Value function loss: 0.7312
                    Surrogate loss: -0.0030
             Mean action noise std: 0.9267
                     Learning rate: 0.0009
                       Mean reward: 115.07
               Mean episode length: 972.77
       Episode_Reward/keep_balance: 0.9766
     Episode_Reward/rew_lin_vel_xy: 5.7972
      Episode_Reward/rew_ang_vel_z: 2.3064
    Episode_Reward/pen_base_height: -0.3120
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.2056
   Episode_Reward/pen_joint_torque: -0.2220
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1320
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0602
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2920
Episode_Reward/pen_flat_orientation: -0.1150
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.4452
   Episode_Reward/foot_landing_vel: -0.1420
   Episode_Reward/test_gait_reward: -0.9548
Metrics/base_velocity/error_vel_xy: 1.0892
Metrics/base_velocity/error_vel_yaw: 1.4553
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 1.11s
                        Total time: 1254.58s
                               ETA: 2010.8s

################################################################################
                     [1m Learning iteration 1153/3000 [0m                     

                       Computation: 89368 steps/s (collection: 0.974s, learning 0.126s)
               Value function loss: 0.7613
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9256
                     Learning rate: 0.0006
                       Mean reward: 118.88
               Mean episode length: 969.82
       Episode_Reward/keep_balance: 0.9771
     Episode_Reward/rew_lin_vel_xy: 5.7407
      Episode_Reward/rew_ang_vel_z: 2.3505
    Episode_Reward/pen_base_height: -0.3229
      Episode_Reward/pen_lin_vel_z: -0.0420
     Episode_Reward/pen_ang_vel_xy: -0.2018
   Episode_Reward/pen_joint_torque: -0.2315
    Episode_Reward/pen_joint_accel: -0.1154
    Episode_Reward/pen_action_rate: -0.1314
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0593
   Episode_Reward/pen_joint_powers: -0.0927
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2866
Episode_Reward/pen_flat_orientation: -0.1158
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.4417
   Episode_Reward/foot_landing_vel: -0.1360
   Episode_Reward/test_gait_reward: -0.9575
Metrics/base_velocity/error_vel_xy: 1.1354
Metrics/base_velocity/error_vel_yaw: 1.4246
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 1.10s
                        Total time: 1255.68s
                               ETA: 2009.7s

################################################################################
                     [1m Learning iteration 1154/3000 [0m                     

                       Computation: 89131 steps/s (collection: 0.981s, learning 0.122s)
               Value function loss: 0.7398
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9250
                     Learning rate: 0.0009
                       Mean reward: 110.20
               Mean episode length: 967.73
       Episode_Reward/keep_balance: 0.9756
     Episode_Reward/rew_lin_vel_xy: 5.6113
      Episode_Reward/rew_ang_vel_z: 2.2722
    Episode_Reward/pen_base_height: -0.3307
      Episode_Reward/pen_lin_vel_z: -0.0428
     Episode_Reward/pen_ang_vel_xy: -0.2196
   Episode_Reward/pen_joint_torque: -0.2215
    Episode_Reward/pen_joint_accel: -0.1219
    Episode_Reward/pen_action_rate: -0.1377
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0648
   Episode_Reward/pen_joint_powers: -0.0955
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2991
Episode_Reward/pen_flat_orientation: -0.1232
  Episode_Reward/pen_feet_distance: -0.0116
Episode_Reward/pen_feet_regulation: -0.4792
   Episode_Reward/foot_landing_vel: -0.1544
   Episode_Reward/test_gait_reward: -0.9551
Metrics/base_velocity/error_vel_xy: 1.2021
Metrics/base_velocity/error_vel_yaw: 1.5128
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 1.10s
                        Total time: 1256.78s
                               ETA: 2008.7s

################################################################################
                     [1m Learning iteration 1155/3000 [0m                     

                       Computation: 90602 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.7530
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9247
                     Learning rate: 0.0006
                       Mean reward: 113.40
               Mean episode length: 969.10
       Episode_Reward/keep_balance: 0.9757
     Episode_Reward/rew_lin_vel_xy: 5.6243
      Episode_Reward/rew_ang_vel_z: 2.3023
    Episode_Reward/pen_base_height: -0.3221
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.2045
   Episode_Reward/pen_joint_torque: -0.2300
    Episode_Reward/pen_joint_accel: -0.1221
    Episode_Reward/pen_action_rate: -0.1327
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0622
   Episode_Reward/pen_joint_powers: -0.0947
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2907
Episode_Reward/pen_flat_orientation: -0.1186
  Episode_Reward/pen_feet_distance: -0.0119
Episode_Reward/pen_feet_regulation: -0.4481
   Episode_Reward/foot_landing_vel: -0.1487
   Episode_Reward/test_gait_reward: -0.9512
Metrics/base_velocity/error_vel_xy: 1.1760
Metrics/base_velocity/error_vel_yaw: 1.4555
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 1.08s
                        Total time: 1257.87s
                               ETA: 2007.6s

################################################################################
                     [1m Learning iteration 1156/3000 [0m                     

                       Computation: 90215 steps/s (collection: 0.965s, learning 0.125s)
               Value function loss: 0.7083
                    Surrogate loss: -0.0032
             Mean action noise std: 0.9254
                     Learning rate: 0.0006
                       Mean reward: 114.53
               Mean episode length: 964.98
       Episode_Reward/keep_balance: 0.9633
     Episode_Reward/rew_lin_vel_xy: 5.6178
      Episode_Reward/rew_ang_vel_z: 2.2727
    Episode_Reward/pen_base_height: -0.3205
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.1959
   Episode_Reward/pen_joint_torque: -0.2260
    Episode_Reward/pen_joint_accel: -0.1172
    Episode_Reward/pen_action_rate: -0.1298
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0931
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2848
Episode_Reward/pen_flat_orientation: -0.1155
  Episode_Reward/pen_feet_distance: -0.0093
Episode_Reward/pen_feet_regulation: -0.4441
   Episode_Reward/foot_landing_vel: -0.1430
   Episode_Reward/test_gait_reward: -0.9392
Metrics/base_velocity/error_vel_xy: 1.1397
Metrics/base_velocity/error_vel_yaw: 1.4497
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 1.09s
                        Total time: 1258.96s
                               ETA: 2006.5s

################################################################################
                     [1m Learning iteration 1157/3000 [0m                     

                       Computation: 89272 steps/s (collection: 0.975s, learning 0.126s)
               Value function loss: 0.6616
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9261
                     Learning rate: 0.0004
                       Mean reward: 111.44
               Mean episode length: 952.22
       Episode_Reward/keep_balance: 0.9472
     Episode_Reward/rew_lin_vel_xy: 5.4489
      Episode_Reward/rew_ang_vel_z: 2.2484
    Episode_Reward/pen_base_height: -0.3411
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.2003
   Episode_Reward/pen_joint_torque: -0.2340
    Episode_Reward/pen_joint_accel: -0.1183
    Episode_Reward/pen_action_rate: -0.1301
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0612
   Episode_Reward/pen_joint_powers: -0.0945
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2801
Episode_Reward/pen_flat_orientation: -0.1266
  Episode_Reward/pen_feet_distance: -0.0120
Episode_Reward/pen_feet_regulation: -0.4454
   Episode_Reward/foot_landing_vel: -0.1464
   Episode_Reward/test_gait_reward: -0.9282
Metrics/base_velocity/error_vel_xy: 1.1541
Metrics/base_velocity/error_vel_yaw: 1.4232
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 1.10s
                        Total time: 1260.06s
                               ETA: 2005.4s

################################################################################
                     [1m Learning iteration 1158/3000 [0m                     

                       Computation: 89386 steps/s (collection: 0.973s, learning 0.127s)
               Value function loss: 0.6889
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9258
                     Learning rate: 0.0006
                       Mean reward: 115.26
               Mean episode length: 998.87
       Episode_Reward/keep_balance: 0.9992
     Episode_Reward/rew_lin_vel_xy: 5.7653
      Episode_Reward/rew_ang_vel_z: 2.3394
    Episode_Reward/pen_base_height: -0.3263
      Episode_Reward/pen_lin_vel_z: -0.0454
     Episode_Reward/pen_ang_vel_xy: -0.2088
   Episode_Reward/pen_joint_torque: -0.2459
    Episode_Reward/pen_joint_accel: -0.1276
    Episode_Reward/pen_action_rate: -0.1381
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0659
   Episode_Reward/pen_joint_powers: -0.0999
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2987
Episode_Reward/pen_flat_orientation: -0.1190
  Episode_Reward/pen_feet_distance: -0.0126
Episode_Reward/pen_feet_regulation: -0.4736
   Episode_Reward/foot_landing_vel: -0.1566
   Episode_Reward/test_gait_reward: -0.9838
Metrics/base_velocity/error_vel_xy: 1.2211
Metrics/base_velocity/error_vel_yaw: 1.5210
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 1.10s
                        Total time: 1261.16s
                               ETA: 2004.4s

################################################################################
                     [1m Learning iteration 1159/3000 [0m                     

                       Computation: 90852 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.7494
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9256
                     Learning rate: 0.0009
                       Mean reward: 116.09
               Mean episode length: 982.95
       Episode_Reward/keep_balance: 0.9793
     Episode_Reward/rew_lin_vel_xy: 5.6217
      Episode_Reward/rew_ang_vel_z: 2.3245
    Episode_Reward/pen_base_height: -0.3235
      Episode_Reward/pen_lin_vel_z: -0.0420
     Episode_Reward/pen_ang_vel_xy: -0.2039
   Episode_Reward/pen_joint_torque: -0.2288
    Episode_Reward/pen_joint_accel: -0.1264
    Episode_Reward/pen_action_rate: -0.1333
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0625
   Episode_Reward/pen_joint_powers: -0.0947
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2872
Episode_Reward/pen_flat_orientation: -0.1211
  Episode_Reward/pen_feet_distance: -0.0095
Episode_Reward/pen_feet_regulation: -0.4607
   Episode_Reward/foot_landing_vel: -0.1458
   Episode_Reward/test_gait_reward: -0.9607
Metrics/base_velocity/error_vel_xy: 1.2245
Metrics/base_velocity/error_vel_yaw: 1.4652
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 1.08s
                        Total time: 1262.24s
                               ETA: 2003.3s

################################################################################
                     [1m Learning iteration 1160/3000 [0m                     

                       Computation: 89858 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.7270
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9238
                     Learning rate: 0.0006
                       Mean reward: 114.05
               Mean episode length: 965.44
       Episode_Reward/keep_balance: 0.9692
     Episode_Reward/rew_lin_vel_xy: 5.6500
      Episode_Reward/rew_ang_vel_z: 2.3072
    Episode_Reward/pen_base_height: -0.3146
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.1957
   Episode_Reward/pen_joint_torque: -0.2202
    Episode_Reward/pen_joint_accel: -0.1243
    Episode_Reward/pen_action_rate: -0.1296
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0899
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2856
Episode_Reward/pen_flat_orientation: -0.1130
  Episode_Reward/pen_feet_distance: -0.0100
Episode_Reward/pen_feet_regulation: -0.4326
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.9508
Metrics/base_velocity/error_vel_xy: 1.1499
Metrics/base_velocity/error_vel_yaw: 1.4261
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 1.09s
                        Total time: 1263.34s
                               ETA: 2002.2s

################################################################################
                     [1m Learning iteration 1161/3000 [0m                     

                       Computation: 82574 steps/s (collection: 1.066s, learning 0.125s)
               Value function loss: 0.6808
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9219
                     Learning rate: 0.0009
                       Mean reward: 113.06
               Mean episode length: 953.17
       Episode_Reward/keep_balance: 0.9331
     Episode_Reward/rew_lin_vel_xy: 5.4976
      Episode_Reward/rew_ang_vel_z: 2.1899
    Episode_Reward/pen_base_height: -0.3077
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1988
   Episode_Reward/pen_joint_torque: -0.2151
    Episode_Reward/pen_joint_accel: -0.1290
    Episode_Reward/pen_action_rate: -0.1293
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2803
Episode_Reward/pen_flat_orientation: -0.1163
  Episode_Reward/pen_feet_distance: -0.0078
Episode_Reward/pen_feet_regulation: -0.4412
   Episode_Reward/foot_landing_vel: -0.1461
   Episode_Reward/test_gait_reward: -0.9184
Metrics/base_velocity/error_vel_xy: 1.1002
Metrics/base_velocity/error_vel_yaw: 1.4336
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 1.19s
                        Total time: 1264.53s
                               ETA: 2001.3s

################################################################################
                     [1m Learning iteration 1162/3000 [0m                     

                       Computation: 90747 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.6710
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9224
                     Learning rate: 0.0009
                       Mean reward: 110.87
               Mean episode length: 951.66
       Episode_Reward/keep_balance: 0.9623
     Episode_Reward/rew_lin_vel_xy: 5.6429
      Episode_Reward/rew_ang_vel_z: 2.2492
    Episode_Reward/pen_base_height: -0.3349
      Episode_Reward/pen_lin_vel_z: -0.0414
     Episode_Reward/pen_ang_vel_xy: -0.1934
   Episode_Reward/pen_joint_torque: -0.2354
    Episode_Reward/pen_joint_accel: -0.1141
    Episode_Reward/pen_action_rate: -0.1312
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0948
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2843
Episode_Reward/pen_flat_orientation: -0.1217
  Episode_Reward/pen_feet_distance: -0.0111
Episode_Reward/pen_feet_regulation: -0.4500
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.9458
Metrics/base_velocity/error_vel_xy: 1.1521
Metrics/base_velocity/error_vel_yaw: 1.4754
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 1.08s
                        Total time: 1265.61s
                               ETA: 2000.2s

################################################################################
                     [1m Learning iteration 1163/3000 [0m                     

                       Computation: 91921 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.7328
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9227
                     Learning rate: 0.0004
                       Mean reward: 117.53
               Mean episode length: 980.20
       Episode_Reward/keep_balance: 0.9825
     Episode_Reward/rew_lin_vel_xy: 5.6090
      Episode_Reward/rew_ang_vel_z: 2.3275
    Episode_Reward/pen_base_height: -0.3279
      Episode_Reward/pen_lin_vel_z: -0.0428
     Episode_Reward/pen_ang_vel_xy: -0.2038
   Episode_Reward/pen_joint_torque: -0.2324
    Episode_Reward/pen_joint_accel: -0.1208
    Episode_Reward/pen_action_rate: -0.1338
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0629
   Episode_Reward/pen_joint_powers: -0.0953
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2899
Episode_Reward/pen_flat_orientation: -0.1225
  Episode_Reward/pen_feet_distance: -0.0121
Episode_Reward/pen_feet_regulation: -0.4679
   Episode_Reward/foot_landing_vel: -0.1592
   Episode_Reward/test_gait_reward: -0.9622
Metrics/base_velocity/error_vel_xy: 1.2352
Metrics/base_velocity/error_vel_yaw: 1.4644
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 1.07s
                        Total time: 1266.68s
                               ETA: 1999.0s

################################################################################
                     [1m Learning iteration 1164/3000 [0m                     

                       Computation: 90703 steps/s (collection: 0.959s, learning 0.125s)
               Value function loss: 0.6512
                    Surrogate loss: -0.0019
             Mean action noise std: 0.9222
                     Learning rate: 0.0003
                       Mean reward: 110.11
               Mean episode length: 952.76
       Episode_Reward/keep_balance: 0.9367
     Episode_Reward/rew_lin_vel_xy: 5.3266
      Episode_Reward/rew_ang_vel_z: 2.1486
    Episode_Reward/pen_base_height: -0.3240
      Episode_Reward/pen_lin_vel_z: -0.0433
     Episode_Reward/pen_ang_vel_xy: -0.2018
   Episode_Reward/pen_joint_torque: -0.2207
    Episode_Reward/pen_joint_accel: -0.1239
    Episode_Reward/pen_action_rate: -0.1304
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0621
   Episode_Reward/pen_joint_powers: -0.0933
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2815
Episode_Reward/pen_flat_orientation: -0.1306
  Episode_Reward/pen_feet_distance: -0.0124
Episode_Reward/pen_feet_regulation: -0.4722
   Episode_Reward/foot_landing_vel: -0.1478
   Episode_Reward/test_gait_reward: -0.9230
Metrics/base_velocity/error_vel_xy: 1.1923
Metrics/base_velocity/error_vel_yaw: 1.4802
      Episode_Termination/time_out: 3.0000
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 1.08s
                        Total time: 1267.76s
                               ETA: 1998.0s

################################################################################
                     [1m Learning iteration 1165/3000 [0m                     

                       Computation: 88814 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 0.7881
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9244
                     Learning rate: 0.0006
                       Mean reward: 114.26
               Mean episode length: 964.53
       Episode_Reward/keep_balance: 0.9710
     Episode_Reward/rew_lin_vel_xy: 5.6910
      Episode_Reward/rew_ang_vel_z: 2.2886
    Episode_Reward/pen_base_height: -0.3089
      Episode_Reward/pen_lin_vel_z: -0.0427
     Episode_Reward/pen_ang_vel_xy: -0.2030
   Episode_Reward/pen_joint_torque: -0.2262
    Episode_Reward/pen_joint_accel: -0.1234
    Episode_Reward/pen_action_rate: -0.1322
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0622
   Episode_Reward/pen_joint_powers: -0.0941
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2898
Episode_Reward/pen_flat_orientation: -0.1147
  Episode_Reward/pen_feet_distance: -0.0133
Episode_Reward/pen_feet_regulation: -0.4487
   Episode_Reward/foot_landing_vel: -0.1557
   Episode_Reward/test_gait_reward: -0.9549
Metrics/base_velocity/error_vel_xy: 1.1479
Metrics/base_velocity/error_vel_yaw: 1.4553
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 1.11s
                        Total time: 1268.87s
                               ETA: 1996.9s

################################################################################
                     [1m Learning iteration 1166/3000 [0m                     

                       Computation: 88036 steps/s (collection: 0.991s, learning 0.126s)
               Value function loss: 0.7658
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9254
                     Learning rate: 0.0004
                       Mean reward: 111.06
               Mean episode length: 968.03
       Episode_Reward/keep_balance: 0.9493
     Episode_Reward/rew_lin_vel_xy: 5.4857
      Episode_Reward/rew_ang_vel_z: 2.2555
    Episode_Reward/pen_base_height: -0.3352
      Episode_Reward/pen_lin_vel_z: -0.0447
     Episode_Reward/pen_ang_vel_xy: -0.1893
   Episode_Reward/pen_joint_torque: -0.2311
    Episode_Reward/pen_joint_accel: -0.1118
    Episode_Reward/pen_action_rate: -0.1290
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0938
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2773
Episode_Reward/pen_flat_orientation: -0.1215
  Episode_Reward/pen_feet_distance: -0.0138
Episode_Reward/pen_feet_regulation: -0.4639
   Episode_Reward/foot_landing_vel: -0.1442
   Episode_Reward/test_gait_reward: -0.9376
Metrics/base_velocity/error_vel_xy: 1.1729
Metrics/base_velocity/error_vel_yaw: 1.4164
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 1.12s
                        Total time: 1269.99s
                               ETA: 1995.8s

################################################################################
                     [1m Learning iteration 1167/3000 [0m                     

                       Computation: 89710 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.7592
                    Surrogate loss: -0.0024
             Mean action noise std: 0.9248
                     Learning rate: 0.0004
                       Mean reward: 114.38
               Mean episode length: 965.21
       Episode_Reward/keep_balance: 0.9644
     Episode_Reward/rew_lin_vel_xy: 5.6229
      Episode_Reward/rew_ang_vel_z: 2.3038
    Episode_Reward/pen_base_height: -0.3360
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.1943
   Episode_Reward/pen_joint_torque: -0.2260
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1307
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0618
   Episode_Reward/pen_joint_powers: -0.0940
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2813
Episode_Reward/pen_flat_orientation: -0.1248
  Episode_Reward/pen_feet_distance: -0.0153
Episode_Reward/pen_feet_regulation: -0.4673
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.9479
Metrics/base_velocity/error_vel_xy: 1.1677
Metrics/base_velocity/error_vel_yaw: 1.4259
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 1.10s
                        Total time: 1271.08s
                               ETA: 1994.8s

################################################################################
                     [1m Learning iteration 1168/3000 [0m                     

                       Computation: 90292 steps/s (collection: 0.962s, learning 0.127s)
               Value function loss: 0.6608
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9249
                     Learning rate: 0.0006
                       Mean reward: 113.48
               Mean episode length: 979.05
       Episode_Reward/keep_balance: 0.9824
     Episode_Reward/rew_lin_vel_xy: 5.7606
      Episode_Reward/rew_ang_vel_z: 2.3191
    Episode_Reward/pen_base_height: -0.3132
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.2155
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1356
    Episode_Reward/pen_action_rate: -0.1343
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0640
   Episode_Reward/pen_joint_powers: -0.0957
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2946
Episode_Reward/pen_flat_orientation: -0.1210
  Episode_Reward/pen_feet_distance: -0.0125
Episode_Reward/pen_feet_regulation: -0.4624
   Episode_Reward/foot_landing_vel: -0.1548
   Episode_Reward/test_gait_reward: -0.9646
Metrics/base_velocity/error_vel_xy: 1.1446
Metrics/base_velocity/error_vel_yaw: 1.4816
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 1.09s
                        Total time: 1272.17s
                               ETA: 1993.7s

################################################################################
                     [1m Learning iteration 1169/3000 [0m                     

                       Computation: 89584 steps/s (collection: 0.973s, learning 0.125s)
               Value function loss: 0.6547
                    Surrogate loss: -0.0015
             Mean action noise std: 0.9258
                     Learning rate: 0.0003
                       Mean reward: 116.87
               Mean episode length: 981.51
       Episode_Reward/keep_balance: 0.9691
     Episode_Reward/rew_lin_vel_xy: 5.6641
      Episode_Reward/rew_ang_vel_z: 2.2769
    Episode_Reward/pen_base_height: -0.3252
      Episode_Reward/pen_lin_vel_z: -0.0440
     Episode_Reward/pen_ang_vel_xy: -0.2030
   Episode_Reward/pen_joint_torque: -0.2329
    Episode_Reward/pen_joint_accel: -0.1317
    Episode_Reward/pen_action_rate: -0.1319
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0636
   Episode_Reward/pen_joint_powers: -0.0964
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2870
Episode_Reward/pen_flat_orientation: -0.1250
  Episode_Reward/pen_feet_distance: -0.0149
Episode_Reward/pen_feet_regulation: -0.4790
   Episode_Reward/foot_landing_vel: -0.1510
   Episode_Reward/test_gait_reward: -0.9557
Metrics/base_velocity/error_vel_xy: 1.1331
Metrics/base_velocity/error_vel_yaw: 1.4677
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 1.10s
                        Total time: 1273.27s
                               ETA: 1992.6s

################################################################################
                     [1m Learning iteration 1170/3000 [0m                     

                       Computation: 89115 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.6387
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9245
                     Learning rate: 0.0006
                       Mean reward: 117.66
               Mean episode length: 970.26
       Episode_Reward/keep_balance: 0.9759
     Episode_Reward/rew_lin_vel_xy: 5.7094
      Episode_Reward/rew_ang_vel_z: 2.3362
    Episode_Reward/pen_base_height: -0.3205
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.2013
   Episode_Reward/pen_joint_torque: -0.2330
    Episode_Reward/pen_joint_accel: -0.1129
    Episode_Reward/pen_action_rate: -0.1307
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2853
Episode_Reward/pen_flat_orientation: -0.1109
  Episode_Reward/pen_feet_distance: -0.0097
Episode_Reward/pen_feet_regulation: -0.4275
   Episode_Reward/foot_landing_vel: -0.1394
   Episode_Reward/test_gait_reward: -0.9589
Metrics/base_velocity/error_vel_xy: 1.1412
Metrics/base_velocity/error_vel_yaw: 1.4253
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 1.10s
                        Total time: 1274.37s
                               ETA: 1991.5s

################################################################################
                     [1m Learning iteration 1171/3000 [0m                     

                       Computation: 89415 steps/s (collection: 0.973s, learning 0.126s)
               Value function loss: 0.7224
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9243
                     Learning rate: 0.0003
                       Mean reward: 116.87
               Mean episode length: 992.11
       Episode_Reward/keep_balance: 0.9944
     Episode_Reward/rew_lin_vel_xy: 5.8076
      Episode_Reward/rew_ang_vel_z: 2.3442
    Episode_Reward/pen_base_height: -0.3265
      Episode_Reward/pen_lin_vel_z: -0.0443
     Episode_Reward/pen_ang_vel_xy: -0.2046
   Episode_Reward/pen_joint_torque: -0.2364
    Episode_Reward/pen_joint_accel: -0.1307
    Episode_Reward/pen_action_rate: -0.1356
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0643
   Episode_Reward/pen_joint_powers: -0.0974
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2948
Episode_Reward/pen_flat_orientation: -0.1178
  Episode_Reward/pen_feet_distance: -0.0120
Episode_Reward/pen_feet_regulation: -0.4796
   Episode_Reward/foot_landing_vel: -0.1552
   Episode_Reward/test_gait_reward: -0.9793
Metrics/base_velocity/error_vel_xy: 1.1638
Metrics/base_velocity/error_vel_yaw: 1.4907
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 1.10s
                        Total time: 1275.47s
                               ETA: 1990.5s

################################################################################
                     [1m Learning iteration 1172/3000 [0m                     

                       Computation: 90712 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.6957
                    Surrogate loss: -0.0012
             Mean action noise std: 0.9250
                     Learning rate: 0.0002
                       Mean reward: 114.46
               Mean episode length: 953.46
       Episode_Reward/keep_balance: 0.9488
     Episode_Reward/rew_lin_vel_xy: 5.5357
      Episode_Reward/rew_ang_vel_z: 2.2688
    Episode_Reward/pen_base_height: -0.3281
      Episode_Reward/pen_lin_vel_z: -0.0429
     Episode_Reward/pen_ang_vel_xy: -0.1948
   Episode_Reward/pen_joint_torque: -0.2279
    Episode_Reward/pen_joint_accel: -0.1207
    Episode_Reward/pen_action_rate: -0.1272
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0920
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2736
Episode_Reward/pen_flat_orientation: -0.1228
  Episode_Reward/pen_feet_distance: -0.0122
Episode_Reward/pen_feet_regulation: -0.4496
   Episode_Reward/foot_landing_vel: -0.1405
   Episode_Reward/test_gait_reward: -0.9346
Metrics/base_velocity/error_vel_xy: 1.1506
Metrics/base_velocity/error_vel_yaw: 1.3831
      Episode_Termination/time_out: 5.1250
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 1.08s
                        Total time: 1276.55s
                               ETA: 1989.4s

################################################################################
                     [1m Learning iteration 1173/3000 [0m                     

                       Computation: 90496 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.6714
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9245
                     Learning rate: 0.0003
                       Mean reward: 118.96
               Mean episode length: 981.94
       Episode_Reward/keep_balance: 0.9820
     Episode_Reward/rew_lin_vel_xy: 5.7712
      Episode_Reward/rew_ang_vel_z: 2.3846
    Episode_Reward/pen_base_height: -0.3297
      Episode_Reward/pen_lin_vel_z: -0.0425
     Episode_Reward/pen_ang_vel_xy: -0.2049
   Episode_Reward/pen_joint_torque: -0.2333
    Episode_Reward/pen_joint_accel: -0.1194
    Episode_Reward/pen_action_rate: -0.1318
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0937
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2844
Episode_Reward/pen_flat_orientation: -0.1169
  Episode_Reward/pen_feet_distance: -0.0153
Episode_Reward/pen_feet_regulation: -0.4518
   Episode_Reward/foot_landing_vel: -0.1493
   Episode_Reward/test_gait_reward: -0.9599
Metrics/base_velocity/error_vel_xy: 1.1489
Metrics/base_velocity/error_vel_yaw: 1.4054
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 1.09s
                        Total time: 1277.64s
                               ETA: 1988.3s

################################################################################
                     [1m Learning iteration 1174/3000 [0m                     

                       Computation: 91057 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.6567
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9240
                     Learning rate: 0.0006
                       Mean reward: 112.73
               Mean episode length: 959.53
       Episode_Reward/keep_balance: 0.9593
     Episode_Reward/rew_lin_vel_xy: 5.6159
      Episode_Reward/rew_ang_vel_z: 2.2983
    Episode_Reward/pen_base_height: -0.3207
      Episode_Reward/pen_lin_vel_z: -0.0437
     Episode_Reward/pen_ang_vel_xy: -0.1987
   Episode_Reward/pen_joint_torque: -0.2316
    Episode_Reward/pen_joint_accel: -0.1165
    Episode_Reward/pen_action_rate: -0.1292
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0936
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2788
Episode_Reward/pen_flat_orientation: -0.1148
  Episode_Reward/pen_feet_distance: -0.0150
Episode_Reward/pen_feet_regulation: -0.4472
   Episode_Reward/foot_landing_vel: -0.1583
   Episode_Reward/test_gait_reward: -0.9426
Metrics/base_velocity/error_vel_xy: 1.1391
Metrics/base_velocity/error_vel_yaw: 1.4076
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 1.08s
                        Total time: 1278.72s
                               ETA: 1987.2s

################################################################################
                     [1m Learning iteration 1175/3000 [0m                     

                       Computation: 90391 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.7623
                    Surrogate loss: -0.0007
             Mean action noise std: 0.9245
                     Learning rate: 0.0002
                       Mean reward: 113.85
               Mean episode length: 967.40
       Episode_Reward/keep_balance: 0.9760
     Episode_Reward/rew_lin_vel_xy: 5.7831
      Episode_Reward/rew_ang_vel_z: 2.2859
    Episode_Reward/pen_base_height: -0.3234
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.2013
   Episode_Reward/pen_joint_torque: -0.2299
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1325
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0610
   Episode_Reward/pen_joint_powers: -0.0941
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2854
Episode_Reward/pen_flat_orientation: -0.1177
  Episode_Reward/pen_feet_distance: -0.0172
Episode_Reward/pen_feet_regulation: -0.4564
   Episode_Reward/foot_landing_vel: -0.1502
   Episode_Reward/test_gait_reward: -0.9522
Metrics/base_velocity/error_vel_xy: 1.1223
Metrics/base_velocity/error_vel_yaw: 1.4758
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 1.09s
                        Total time: 1279.81s
                               ETA: 1986.1s

################################################################################
                     [1m Learning iteration 1176/3000 [0m                     

                       Computation: 90782 steps/s (collection: 0.957s, learning 0.126s)
               Value function loss: 0.7103
                    Surrogate loss: -0.0046
             Mean action noise std: 0.9232
                     Learning rate: 0.0004
                       Mean reward: 115.31
               Mean episode length: 961.06
       Episode_Reward/keep_balance: 0.9489
     Episode_Reward/rew_lin_vel_xy: 5.5281
      Episode_Reward/rew_ang_vel_z: 2.2711
    Episode_Reward/pen_base_height: -0.3117
      Episode_Reward/pen_lin_vel_z: -0.0415
     Episode_Reward/pen_ang_vel_xy: -0.1976
   Episode_Reward/pen_joint_torque: -0.2246
    Episode_Reward/pen_joint_accel: -0.1172
    Episode_Reward/pen_action_rate: -0.1272
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0602
   Episode_Reward/pen_joint_powers: -0.0915
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2777
Episode_Reward/pen_flat_orientation: -0.1131
  Episode_Reward/pen_feet_distance: -0.0143
Episode_Reward/pen_feet_regulation: -0.4363
   Episode_Reward/foot_landing_vel: -0.1552
   Episode_Reward/test_gait_reward: -0.9312
Metrics/base_velocity/error_vel_xy: 1.1272
Metrics/base_velocity/error_vel_yaw: 1.3926
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 1.08s
                        Total time: 1280.89s
                               ETA: 1985.0s

################################################################################
                     [1m Learning iteration 1177/3000 [0m                     

                       Computation: 87759 steps/s (collection: 0.993s, learning 0.127s)
               Value function loss: 0.7049
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9221
                     Learning rate: 0.0009
                       Mean reward: 114.70
               Mean episode length: 967.25
       Episode_Reward/keep_balance: 0.9747
     Episode_Reward/rew_lin_vel_xy: 5.6714
      Episode_Reward/rew_ang_vel_z: 2.3382
    Episode_Reward/pen_base_height: -0.3246
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.1966
   Episode_Reward/pen_joint_torque: -0.2321
    Episode_Reward/pen_joint_accel: -0.1190
    Episode_Reward/pen_action_rate: -0.1305
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0628
   Episode_Reward/pen_joint_powers: -0.0951
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2816
Episode_Reward/pen_flat_orientation: -0.1204
  Episode_Reward/pen_feet_distance: -0.0138
Episode_Reward/pen_feet_regulation: -0.4597
   Episode_Reward/foot_landing_vel: -0.1542
   Episode_Reward/test_gait_reward: -0.9587
Metrics/base_velocity/error_vel_xy: 1.1613
Metrics/base_velocity/error_vel_yaw: 1.4165
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 1.12s
                        Total time: 1282.01s
                               ETA: 1984.0s

################################################################################
                     [1m Learning iteration 1178/3000 [0m                     

                       Computation: 89797 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.6431
                    Surrogate loss: 0.0004
             Mean action noise std: 0.9213
                     Learning rate: 0.0002
                       Mean reward: 116.87
               Mean episode length: 961.61
       Episode_Reward/keep_balance: 0.9645
     Episode_Reward/rew_lin_vel_xy: 5.7156
      Episode_Reward/rew_ang_vel_z: 2.3325
    Episode_Reward/pen_base_height: -0.3076
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.1894
   Episode_Reward/pen_joint_torque: -0.2194
    Episode_Reward/pen_joint_accel: -0.1128
    Episode_Reward/pen_action_rate: -0.1278
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2751
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0151
Episode_Reward/pen_feet_regulation: -0.4463
   Episode_Reward/foot_landing_vel: -0.1396
   Episode_Reward/test_gait_reward: -0.9445
Metrics/base_velocity/error_vel_xy: 1.1176
Metrics/base_velocity/error_vel_yaw: 1.3785
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 1.09s
                        Total time: 1283.11s
                               ETA: 1982.9s

################################################################################
                     [1m Learning iteration 1179/3000 [0m                     

                       Computation: 90104 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.6847
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9203
                     Learning rate: 0.0004
                       Mean reward: 116.80
               Mean episode length: 977.91
       Episode_Reward/keep_balance: 0.9816
     Episode_Reward/rew_lin_vel_xy: 5.6826
      Episode_Reward/rew_ang_vel_z: 2.3212
    Episode_Reward/pen_base_height: -0.3183
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.2017
   Episode_Reward/pen_joint_torque: -0.2334
    Episode_Reward/pen_joint_accel: -0.1265
    Episode_Reward/pen_action_rate: -0.1331
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0633
   Episode_Reward/pen_joint_powers: -0.0962
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2881
Episode_Reward/pen_flat_orientation: -0.1216
  Episode_Reward/pen_feet_distance: -0.0133
Episode_Reward/pen_feet_regulation: -0.4764
   Episode_Reward/foot_landing_vel: -0.1483
   Episode_Reward/test_gait_reward: -0.9711
Metrics/base_velocity/error_vel_xy: 1.1835
Metrics/base_velocity/error_vel_yaw: 1.4488
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 1.09s
                        Total time: 1284.20s
                               ETA: 1981.8s

################################################################################
                     [1m Learning iteration 1180/3000 [0m                     

                       Computation: 89749 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.7027
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9194
                     Learning rate: 0.0009
                       Mean reward: 115.79
               Mean episode length: 944.14
       Episode_Reward/keep_balance: 0.9263
     Episode_Reward/rew_lin_vel_xy: 5.4754
      Episode_Reward/rew_ang_vel_z: 2.2511
    Episode_Reward/pen_base_height: -0.3014
      Episode_Reward/pen_lin_vel_z: -0.0402
     Episode_Reward/pen_ang_vel_xy: -0.1888
   Episode_Reward/pen_joint_torque: -0.2154
    Episode_Reward/pen_joint_accel: -0.1119
    Episode_Reward/pen_action_rate: -0.1224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2654
Episode_Reward/pen_flat_orientation: -0.1134
  Episode_Reward/pen_feet_distance: -0.0140
Episode_Reward/pen_feet_regulation: -0.4143
   Episode_Reward/foot_landing_vel: -0.1324
   Episode_Reward/test_gait_reward: -0.9138
Metrics/base_velocity/error_vel_xy: 1.0629
Metrics/base_velocity/error_vel_yaw: 1.3155
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 1.10s
                        Total time: 1285.29s
                               ETA: 1980.7s

################################################################################
                     [1m Learning iteration 1181/3000 [0m                     

                       Computation: 89065 steps/s (collection: 0.977s, learning 0.126s)
               Value function loss: 0.8019
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9195
                     Learning rate: 0.0013
                       Mean reward: 110.52
               Mean episode length: 932.45
       Episode_Reward/keep_balance: 0.9390
     Episode_Reward/rew_lin_vel_xy: 5.4380
      Episode_Reward/rew_ang_vel_z: 2.2234
    Episode_Reward/pen_base_height: -0.2996
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1939
   Episode_Reward/pen_joint_torque: -0.2138
    Episode_Reward/pen_joint_accel: -0.1122
    Episode_Reward/pen_action_rate: -0.1265
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0602
   Episode_Reward/pen_joint_powers: -0.0900
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2738
Episode_Reward/pen_flat_orientation: -0.1178
  Episode_Reward/pen_feet_distance: -0.0149
Episode_Reward/pen_feet_regulation: -0.4526
   Episode_Reward/foot_landing_vel: -0.1456
   Episode_Reward/test_gait_reward: -0.9227
Metrics/base_velocity/error_vel_xy: 1.1336
Metrics/base_velocity/error_vel_yaw: 1.3919
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 1.10s
                        Total time: 1286.40s
                               ETA: 1979.7s

################################################################################
                     [1m Learning iteration 1182/3000 [0m                     

                       Computation: 90899 steps/s (collection: 0.955s, learning 0.126s)
               Value function loss: 0.7720
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9194
                     Learning rate: 0.0013
                       Mean reward: 110.64
               Mean episode length: 955.29
       Episode_Reward/keep_balance: 0.9692
     Episode_Reward/rew_lin_vel_xy: 5.6410
      Episode_Reward/rew_ang_vel_z: 2.2868
    Episode_Reward/pen_base_height: -0.3134
      Episode_Reward/pen_lin_vel_z: -0.0451
     Episode_Reward/pen_ang_vel_xy: -0.1997
   Episode_Reward/pen_joint_torque: -0.2280
    Episode_Reward/pen_joint_accel: -0.1352
    Episode_Reward/pen_action_rate: -0.1310
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0635
   Episode_Reward/pen_joint_powers: -0.0950
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2828
Episode_Reward/pen_flat_orientation: -0.1182
  Episode_Reward/pen_feet_distance: -0.0143
Episode_Reward/pen_feet_regulation: -0.4772
   Episode_Reward/foot_landing_vel: -0.1614
   Episode_Reward/test_gait_reward: -0.9512
Metrics/base_velocity/error_vel_xy: 1.1717
Metrics/base_velocity/error_vel_yaw: 1.4395
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 1.08s
                        Total time: 1287.48s
                               ETA: 1978.6s

################################################################################
                     [1m Learning iteration 1183/3000 [0m                     

                       Computation: 89607 steps/s (collection: 0.972s, learning 0.125s)
               Value function loss: 0.7549
                    Surrogate loss: 0.0018
             Mean action noise std: 0.9190
                     Learning rate: 0.0003
                       Mean reward: 122.11
               Mean episode length: 999.51
       Episode_Reward/keep_balance: 0.9993
     Episode_Reward/rew_lin_vel_xy: 5.8252
      Episode_Reward/rew_ang_vel_z: 2.3694
    Episode_Reward/pen_base_height: -0.3053
      Episode_Reward/pen_lin_vel_z: -0.0427
     Episode_Reward/pen_ang_vel_xy: -0.2039
   Episode_Reward/pen_joint_torque: -0.2204
    Episode_Reward/pen_joint_accel: -0.1213
    Episode_Reward/pen_action_rate: -0.1335
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0615
   Episode_Reward/pen_joint_powers: -0.0921
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2918
Episode_Reward/pen_flat_orientation: -0.1177
  Episode_Reward/pen_feet_distance: -0.0117
Episode_Reward/pen_feet_regulation: -0.4582
   Episode_Reward/foot_landing_vel: -0.1430
   Episode_Reward/test_gait_reward: -0.9768
Metrics/base_velocity/error_vel_xy: 1.1882
Metrics/base_velocity/error_vel_yaw: 1.4839
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 1.10s
                        Total time: 1288.57s
                               ETA: 1977.5s

################################################################################
                     [1m Learning iteration 1184/3000 [0m                     

                       Computation: 89123 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 0.6634
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9179
                     Learning rate: 0.0004
                       Mean reward: 112.74
               Mean episode length: 959.75
       Episode_Reward/keep_balance: 0.9418
     Episode_Reward/rew_lin_vel_xy: 5.4887
      Episode_Reward/rew_ang_vel_z: 2.2149
    Episode_Reward/pen_base_height: -0.3132
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.1994
   Episode_Reward/pen_joint_torque: -0.2239
    Episode_Reward/pen_joint_accel: -0.1151
    Episode_Reward/pen_action_rate: -0.1301
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0635
   Episode_Reward/pen_joint_powers: -0.0944
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2789
Episode_Reward/pen_flat_orientation: -0.1301
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.4893
   Episode_Reward/foot_landing_vel: -0.1458
   Episode_Reward/test_gait_reward: -0.9318
Metrics/base_velocity/error_vel_xy: 1.1424
Metrics/base_velocity/error_vel_yaw: 1.4235
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 1.10s
                        Total time: 1289.68s
                               ETA: 1976.4s

################################################################################
                     [1m Learning iteration 1185/3000 [0m                     

                       Computation: 89502 steps/s (collection: 0.972s, learning 0.126s)
               Value function loss: 0.6830
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9164
                     Learning rate: 0.0004
                       Mean reward: 117.62
               Mean episode length: 973.97
       Episode_Reward/keep_balance: 0.9771
     Episode_Reward/rew_lin_vel_xy: 5.8062
      Episode_Reward/rew_ang_vel_z: 2.3518
    Episode_Reward/pen_base_height: -0.3167
      Episode_Reward/pen_lin_vel_z: -0.0437
     Episode_Reward/pen_ang_vel_xy: -0.2017
   Episode_Reward/pen_joint_torque: -0.2278
    Episode_Reward/pen_joint_accel: -0.1242
    Episode_Reward/pen_action_rate: -0.1302
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0626
   Episode_Reward/pen_joint_powers: -0.0938
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2818
Episode_Reward/pen_flat_orientation: -0.1162
  Episode_Reward/pen_feet_distance: -0.0161
Episode_Reward/pen_feet_regulation: -0.4738
   Episode_Reward/foot_landing_vel: -0.1606
   Episode_Reward/test_gait_reward: -0.9618
Metrics/base_velocity/error_vel_xy: 1.1084
Metrics/base_velocity/error_vel_yaw: 1.4096
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 1.10s
                        Total time: 1290.78s
                               ETA: 1975.3s

################################################################################
                     [1m Learning iteration 1186/3000 [0m                     

                       Computation: 90243 steps/s (collection: 0.965s, learning 0.125s)
               Value function loss: 0.6971
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9159
                     Learning rate: 0.0003
                       Mean reward: 115.73
               Mean episode length: 967.70
       Episode_Reward/keep_balance: 0.9631
     Episode_Reward/rew_lin_vel_xy: 5.6350
      Episode_Reward/rew_ang_vel_z: 2.3103
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.2036
   Episode_Reward/pen_joint_torque: -0.2243
    Episode_Reward/pen_joint_accel: -0.1205
    Episode_Reward/pen_action_rate: -0.1288
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0621
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2788
Episode_Reward/pen_flat_orientation: -0.1226
  Episode_Reward/pen_feet_distance: -0.0154
Episode_Reward/pen_feet_regulation: -0.4744
   Episode_Reward/foot_landing_vel: -0.1534
   Episode_Reward/test_gait_reward: -0.9441
Metrics/base_velocity/error_vel_xy: 1.1454
Metrics/base_velocity/error_vel_yaw: 1.4010
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 1.09s
                        Total time: 1291.87s
                               ETA: 1974.3s

################################################################################
                     [1m Learning iteration 1187/3000 [0m                     

                       Computation: 90401 steps/s (collection: 0.960s, learning 0.127s)
               Value function loss: 0.6144
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9145
                     Learning rate: 0.0006
                       Mean reward: 116.07
               Mean episode length: 976.86
       Episode_Reward/keep_balance: 0.9699
     Episode_Reward/rew_lin_vel_xy: 5.6012
      Episode_Reward/rew_ang_vel_z: 2.3159
    Episode_Reward/pen_base_height: -0.3161
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.1988
   Episode_Reward/pen_joint_torque: -0.2336
    Episode_Reward/pen_joint_accel: -0.1293
    Episode_Reward/pen_action_rate: -0.1298
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0619
   Episode_Reward/pen_joint_powers: -0.0950
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2785
Episode_Reward/pen_flat_orientation: -0.1197
  Episode_Reward/pen_feet_distance: -0.0178
Episode_Reward/pen_feet_regulation: -0.4750
   Episode_Reward/foot_landing_vel: -0.1578
   Episode_Reward/test_gait_reward: -0.9533
Metrics/base_velocity/error_vel_xy: 1.1790
Metrics/base_velocity/error_vel_yaw: 1.4137
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 1.09s
                        Total time: 1292.95s
                               ETA: 1973.2s

################################################################################
                     [1m Learning iteration 1188/3000 [0m                     

                       Computation: 91026 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.6445
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9149
                     Learning rate: 0.0009
                       Mean reward: 114.55
               Mean episode length: 959.32
       Episode_Reward/keep_balance: 0.9614
     Episode_Reward/rew_lin_vel_xy: 5.6368
      Episode_Reward/rew_ang_vel_z: 2.3185
    Episode_Reward/pen_base_height: -0.3070
      Episode_Reward/pen_lin_vel_z: -0.0433
     Episode_Reward/pen_ang_vel_xy: -0.1906
   Episode_Reward/pen_joint_torque: -0.2298
    Episode_Reward/pen_joint_accel: -0.1182
    Episode_Reward/pen_action_rate: -0.1284
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0935
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2750
Episode_Reward/pen_flat_orientation: -0.1271
  Episode_Reward/pen_feet_distance: -0.0216
Episode_Reward/pen_feet_regulation: -0.4601
   Episode_Reward/foot_landing_vel: -0.1509
   Episode_Reward/test_gait_reward: -0.9459
Metrics/base_velocity/error_vel_xy: 1.1270
Metrics/base_velocity/error_vel_yaw: 1.3875
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 1.08s
                        Total time: 1294.03s
                               ETA: 1972.1s

################################################################################
                     [1m Learning iteration 1189/3000 [0m                     

                       Computation: 89056 steps/s (collection: 0.978s, learning 0.126s)
               Value function loss: 0.7406
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9160
                     Learning rate: 0.0004
                       Mean reward: 119.07
               Mean episode length: 976.00
       Episode_Reward/keep_balance: 0.9884
     Episode_Reward/rew_lin_vel_xy: 5.8714
      Episode_Reward/rew_ang_vel_z: 2.3648
    Episode_Reward/pen_base_height: -0.3079
      Episode_Reward/pen_lin_vel_z: -0.0422
     Episode_Reward/pen_ang_vel_xy: -0.1993
   Episode_Reward/pen_joint_torque: -0.2274
    Episode_Reward/pen_joint_accel: -0.1105
    Episode_Reward/pen_action_rate: -0.1314
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0620
   Episode_Reward/pen_joint_powers: -0.0948
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2842
Episode_Reward/pen_flat_orientation: -0.1111
  Episode_Reward/pen_feet_distance: -0.0194
Episode_Reward/pen_feet_regulation: -0.4722
   Episode_Reward/foot_landing_vel: -0.1491
   Episode_Reward/test_gait_reward: -0.9663
Metrics/base_velocity/error_vel_xy: 1.1229
Metrics/base_velocity/error_vel_yaw: 1.4330
      Episode_Termination/time_out: 2.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 1.10s
                        Total time: 1295.14s
                               ETA: 1971.0s

################################################################################
                     [1m Learning iteration 1190/3000 [0m                     

                       Computation: 90283 steps/s (collection: 0.963s, learning 0.126s)
               Value function loss: 0.7146
                    Surrogate loss: -0.0050
             Mean action noise std: 0.9151
                     Learning rate: 0.0006
                       Mean reward: 112.25
               Mean episode length: 959.11
       Episode_Reward/keep_balance: 0.9631
     Episode_Reward/rew_lin_vel_xy: 5.6356
      Episode_Reward/rew_ang_vel_z: 2.2832
    Episode_Reward/pen_base_height: -0.3093
      Episode_Reward/pen_lin_vel_z: -0.0415
     Episode_Reward/pen_ang_vel_xy: -0.1959
   Episode_Reward/pen_joint_torque: -0.2291
    Episode_Reward/pen_joint_accel: -0.1210
    Episode_Reward/pen_action_rate: -0.1296
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0619
   Episode_Reward/pen_joint_powers: -0.0944
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2775
Episode_Reward/pen_flat_orientation: -0.1187
  Episode_Reward/pen_feet_distance: -0.0210
Episode_Reward/pen_feet_regulation: -0.4723
   Episode_Reward/foot_landing_vel: -0.1455
   Episode_Reward/test_gait_reward: -0.9563
Metrics/base_velocity/error_vel_xy: 1.1440
Metrics/base_velocity/error_vel_yaw: 1.4288
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 1.09s
                        Total time: 1296.23s
                               ETA: 1969.9s

################################################################################
                     [1m Learning iteration 1191/3000 [0m                     

                       Computation: 91057 steps/s (collection: 0.954s, learning 0.126s)
               Value function loss: 0.6902
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9149
                     Learning rate: 0.0006
                       Mean reward: 113.72
               Mean episode length: 956.11
       Episode_Reward/keep_balance: 0.9629
     Episode_Reward/rew_lin_vel_xy: 5.7206
      Episode_Reward/rew_ang_vel_z: 2.2777
    Episode_Reward/pen_base_height: -0.3008
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.1971
   Episode_Reward/pen_joint_torque: -0.2245
    Episode_Reward/pen_joint_accel: -0.1261
    Episode_Reward/pen_action_rate: -0.1290
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0611
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2778
Episode_Reward/pen_flat_orientation: -0.1173
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4586
   Episode_Reward/foot_landing_vel: -0.1528
   Episode_Reward/test_gait_reward: -0.9498
Metrics/base_velocity/error_vel_xy: 1.0852
Metrics/base_velocity/error_vel_yaw: 1.4281
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 1.08s
                        Total time: 1297.30s
                               ETA: 1968.8s

################################################################################
                     [1m Learning iteration 1192/3000 [0m                     

                       Computation: 87007 steps/s (collection: 1.001s, learning 0.128s)
               Value function loss: 0.7715
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9140
                     Learning rate: 0.0004
                       Mean reward: 118.37
               Mean episode length: 975.73
       Episode_Reward/keep_balance: 0.9714
     Episode_Reward/rew_lin_vel_xy: 5.7901
      Episode_Reward/rew_ang_vel_z: 2.3298
    Episode_Reward/pen_base_height: -0.3145
      Episode_Reward/pen_lin_vel_z: -0.0419
     Episode_Reward/pen_ang_vel_xy: -0.2020
   Episode_Reward/pen_joint_torque: -0.2314
    Episode_Reward/pen_joint_accel: -0.1254
    Episode_Reward/pen_action_rate: -0.1303
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0618
   Episode_Reward/pen_joint_powers: -0.0947
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2795
Episode_Reward/pen_flat_orientation: -0.1186
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4782
   Episode_Reward/foot_landing_vel: -0.1429
   Episode_Reward/test_gait_reward: -0.9596
Metrics/base_velocity/error_vel_xy: 1.1056
Metrics/base_velocity/error_vel_yaw: 1.4094
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 1.13s
                        Total time: 1298.43s
                               ETA: 1967.8s

################################################################################
                     [1m Learning iteration 1193/3000 [0m                     

                       Computation: 88821 steps/s (collection: 0.982s, learning 0.125s)
               Value function loss: 0.6724
                    Surrogate loss: -0.0055
             Mean action noise std: 0.9135
                     Learning rate: 0.0006
                       Mean reward: 117.97
               Mean episode length: 948.53
       Episode_Reward/keep_balance: 0.9431
     Episode_Reward/rew_lin_vel_xy: 5.5934
      Episode_Reward/rew_ang_vel_z: 2.3015
    Episode_Reward/pen_base_height: -0.3069
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1891
   Episode_Reward/pen_joint_torque: -0.2173
    Episode_Reward/pen_joint_accel: -0.1243
    Episode_Reward/pen_action_rate: -0.1246
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0591
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2688
Episode_Reward/pen_flat_orientation: -0.1166
  Episode_Reward/pen_feet_distance: -0.0184
Episode_Reward/pen_feet_regulation: -0.4339
   Episode_Reward/foot_landing_vel: -0.1537
   Episode_Reward/test_gait_reward: -0.9216
Metrics/base_velocity/error_vel_xy: 1.0764
Metrics/base_velocity/error_vel_yaw: 1.3412
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 1.11s
                        Total time: 1299.54s
                               ETA: 1966.7s

################################################################################
                     [1m Learning iteration 1194/3000 [0m                     

                       Computation: 90001 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.7363
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9138
                     Learning rate: 0.0006
                       Mean reward: 118.14
               Mean episode length: 974.55
       Episode_Reward/keep_balance: 0.9833
     Episode_Reward/rew_lin_vel_xy: 5.8586
      Episode_Reward/rew_ang_vel_z: 2.3545
    Episode_Reward/pen_base_height: -0.3016
      Episode_Reward/pen_lin_vel_z: -0.0428
     Episode_Reward/pen_ang_vel_xy: -0.1992
   Episode_Reward/pen_joint_torque: -0.2225
    Episode_Reward/pen_joint_accel: -0.1166
    Episode_Reward/pen_action_rate: -0.1290
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0910
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2805
Episode_Reward/pen_flat_orientation: -0.1161
  Episode_Reward/pen_feet_distance: -0.0131
Episode_Reward/pen_feet_regulation: -0.4582
   Episode_Reward/foot_landing_vel: -0.1374
   Episode_Reward/test_gait_reward: -0.9631
Metrics/base_velocity/error_vel_xy: 1.0988
Metrics/base_velocity/error_vel_yaw: 1.4289
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 1.09s
                        Total time: 1300.63s
                               ETA: 1965.6s

################################################################################
                     [1m Learning iteration 1195/3000 [0m                     

                       Computation: 89362 steps/s (collection: 0.974s, learning 0.126s)
               Value function loss: 0.7445
                    Surrogate loss: -0.0051
             Mean action noise std: 0.9120
                     Learning rate: 0.0009
                       Mean reward: 112.60
               Mean episode length: 957.97
       Episode_Reward/keep_balance: 0.9629
     Episode_Reward/rew_lin_vel_xy: 5.6087
      Episode_Reward/rew_ang_vel_z: 2.2857
    Episode_Reward/pen_base_height: -0.3081
      Episode_Reward/pen_lin_vel_z: -0.0419
     Episode_Reward/pen_ang_vel_xy: -0.2066
   Episode_Reward/pen_joint_torque: -0.2211
    Episode_Reward/pen_joint_accel: -0.1183
    Episode_Reward/pen_action_rate: -0.1321
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0632
   Episode_Reward/pen_joint_powers: -0.0948
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2797
Episode_Reward/pen_flat_orientation: -0.1252
  Episode_Reward/pen_feet_distance: -0.0226
Episode_Reward/pen_feet_regulation: -0.4933
   Episode_Reward/foot_landing_vel: -0.1511
   Episode_Reward/test_gait_reward: -0.9572
Metrics/base_velocity/error_vel_xy: 1.1642
Metrics/base_velocity/error_vel_yaw: 1.4371
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 1.10s
                        Total time: 1301.73s
                               ETA: 1964.6s

################################################################################
                     [1m Learning iteration 1196/3000 [0m                     

                       Computation: 83075 steps/s (collection: 1.059s, learning 0.124s)
               Value function loss: 0.6528
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9123
                     Learning rate: 0.0006
                       Mean reward: 114.81
               Mean episode length: 956.37
       Episode_Reward/keep_balance: 0.9627
     Episode_Reward/rew_lin_vel_xy: 5.6949
      Episode_Reward/rew_ang_vel_z: 2.3112
    Episode_Reward/pen_base_height: -0.3026
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1977
   Episode_Reward/pen_joint_torque: -0.2250
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1281
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0613
   Episode_Reward/pen_joint_powers: -0.0929
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2764
Episode_Reward/pen_flat_orientation: -0.1156
  Episode_Reward/pen_feet_distance: -0.0173
Episode_Reward/pen_feet_regulation: -0.4642
   Episode_Reward/foot_landing_vel: -0.1477
   Episode_Reward/test_gait_reward: -0.9455
Metrics/base_velocity/error_vel_xy: 1.1065
Metrics/base_velocity/error_vel_yaw: 1.4015
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 1.18s
                        Total time: 1302.92s
                               ETA: 1963.6s

################################################################################
                     [1m Learning iteration 1197/3000 [0m                     

                       Computation: 89383 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.7067
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9118
                     Learning rate: 0.0006
                       Mean reward: 115.91
               Mean episode length: 968.16
       Episode_Reward/keep_balance: 0.9651
     Episode_Reward/rew_lin_vel_xy: 5.6513
      Episode_Reward/rew_ang_vel_z: 2.3093
    Episode_Reward/pen_base_height: -0.3047
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1989
   Episode_Reward/pen_joint_torque: -0.2212
    Episode_Reward/pen_joint_accel: -0.1142
    Episode_Reward/pen_action_rate: -0.1281
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2749
Episode_Reward/pen_flat_orientation: -0.1251
  Episode_Reward/pen_feet_distance: -0.0184
Episode_Reward/pen_feet_regulation: -0.4733
   Episode_Reward/foot_landing_vel: -0.1452
   Episode_Reward/test_gait_reward: -0.9522
Metrics/base_velocity/error_vel_xy: 1.1356
Metrics/base_velocity/error_vel_yaw: 1.4077
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 1.10s
                        Total time: 1304.02s
                               ETA: 1962.6s

################################################################################
                     [1m Learning iteration 1198/3000 [0m                     

                       Computation: 88454 steps/s (collection: 0.987s, learning 0.124s)
               Value function loss: 0.6200
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9109
                     Learning rate: 0.0006
                       Mean reward: 110.53
               Mean episode length: 946.18
       Episode_Reward/keep_balance: 0.9448
     Episode_Reward/rew_lin_vel_xy: 5.5253
      Episode_Reward/rew_ang_vel_z: 2.2685
    Episode_Reward/pen_base_height: -0.3125
      Episode_Reward/pen_lin_vel_z: -0.0430
     Episode_Reward/pen_ang_vel_xy: -0.1943
   Episode_Reward/pen_joint_torque: -0.2328
    Episode_Reward/pen_joint_accel: -0.1234
    Episode_Reward/pen_action_rate: -0.1274
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0633
   Episode_Reward/pen_joint_powers: -0.0960
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2705
Episode_Reward/pen_flat_orientation: -0.1228
  Episode_Reward/pen_feet_distance: -0.0223
Episode_Reward/pen_feet_regulation: -0.4777
   Episode_Reward/foot_landing_vel: -0.1609
   Episode_Reward/test_gait_reward: -0.9286
Metrics/base_velocity/error_vel_xy: 1.1275
Metrics/base_velocity/error_vel_yaw: 1.3811
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 1.11s
                        Total time: 1305.13s
                               ETA: 1961.5s

################################################################################
                     [1m Learning iteration 1199/3000 [0m                     

                       Computation: 89165 steps/s (collection: 0.978s, learning 0.125s)
               Value function loss: 0.7635
                    Surrogate loss: -0.0032
             Mean action noise std: 0.9112
                     Learning rate: 0.0006
                       Mean reward: 116.97
               Mean episode length: 942.57
       Episode_Reward/keep_balance: 0.9374
     Episode_Reward/rew_lin_vel_xy: 5.5978
      Episode_Reward/rew_ang_vel_z: 2.2677
    Episode_Reward/pen_base_height: -0.2945
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1866
   Episode_Reward/pen_joint_torque: -0.2225
    Episode_Reward/pen_joint_accel: -0.1092
    Episode_Reward/pen_action_rate: -0.1223
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2622
Episode_Reward/pen_flat_orientation: -0.1138
  Episode_Reward/pen_feet_distance: -0.0168
Episode_Reward/pen_feet_regulation: -0.4354
   Episode_Reward/foot_landing_vel: -0.1415
   Episode_Reward/test_gait_reward: -0.9172
Metrics/base_velocity/error_vel_xy: 1.0657
Metrics/base_velocity/error_vel_yaw: 1.3447
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 1.10s
                        Total time: 1306.23s
                               ETA: 1960.4s

################################################################################
                     [1m Learning iteration 1200/3000 [0m                     

                       Computation: 89229 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.6861
                    Surrogate loss: -0.0045
             Mean action noise std: 0.9100
                     Learning rate: 0.0009
                       Mean reward: 117.91
               Mean episode length: 963.07
       Episode_Reward/keep_balance: 0.9720
     Episode_Reward/rew_lin_vel_xy: 5.7603
      Episode_Reward/rew_ang_vel_z: 2.3265
    Episode_Reward/pen_base_height: -0.3017
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.1947
   Episode_Reward/pen_joint_torque: -0.2295
    Episode_Reward/pen_joint_accel: -0.1220
    Episode_Reward/pen_action_rate: -0.1288
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0610
   Episode_Reward/pen_joint_powers: -0.0932
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2746
Episode_Reward/pen_flat_orientation: -0.1230
  Episode_Reward/pen_feet_distance: -0.0128
Episode_Reward/pen_feet_regulation: -0.4558
   Episode_Reward/foot_landing_vel: -0.1436
   Episode_Reward/test_gait_reward: -0.9584
Metrics/base_velocity/error_vel_xy: 1.1269
Metrics/base_velocity/error_vel_yaw: 1.4315
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 1.10s
                        Total time: 1307.33s
                               ETA: 1959.4s

################################################################################
                     [1m Learning iteration 1201/3000 [0m                     

                       Computation: 89265 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 0.6951
                    Surrogate loss: 0.0010
             Mean action noise std: 0.9098
                     Learning rate: 0.0002
                       Mean reward: 113.21
               Mean episode length: 956.46
       Episode_Reward/keep_balance: 0.9347
     Episode_Reward/rew_lin_vel_xy: 5.5493
      Episode_Reward/rew_ang_vel_z: 2.2520
    Episode_Reward/pen_base_height: -0.2988
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.1908
   Episode_Reward/pen_joint_torque: -0.2144
    Episode_Reward/pen_joint_accel: -0.1242
    Episode_Reward/pen_action_rate: -0.1236
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2647
Episode_Reward/pen_flat_orientation: -0.1177
  Episode_Reward/pen_feet_distance: -0.0182
Episode_Reward/pen_feet_regulation: -0.4603
   Episode_Reward/foot_landing_vel: -0.1436
   Episode_Reward/test_gait_reward: -0.9236
Metrics/base_velocity/error_vel_xy: 1.0615
Metrics/base_velocity/error_vel_yaw: 1.3384
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 1.10s
                        Total time: 1308.43s
                               ETA: 1958.3s

################################################################################
                     [1m Learning iteration 1202/3000 [0m                     

                       Computation: 89195 steps/s (collection: 0.978s, learning 0.124s)
               Value function loss: 0.7341
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9104
                     Learning rate: 0.0006
                       Mean reward: 118.14
               Mean episode length: 965.80
       Episode_Reward/keep_balance: 0.9732
     Episode_Reward/rew_lin_vel_xy: 5.7445
      Episode_Reward/rew_ang_vel_z: 2.2945
    Episode_Reward/pen_base_height: -0.3036
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1971
   Episode_Reward/pen_joint_torque: -0.2173
    Episode_Reward/pen_joint_accel: -0.1354
    Episode_Reward/pen_action_rate: -0.1294
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0605
   Episode_Reward/pen_joint_powers: -0.0911
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2815
Episode_Reward/pen_flat_orientation: -0.1183
  Episode_Reward/pen_feet_distance: -0.0177
Episode_Reward/pen_feet_regulation: -0.4573
   Episode_Reward/foot_landing_vel: -0.1368
   Episode_Reward/test_gait_reward: -0.9597
Metrics/base_velocity/error_vel_xy: 1.1304
Metrics/base_velocity/error_vel_yaw: 1.4579
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 1.10s
                        Total time: 1309.54s
                               ETA: 1957.2s

################################################################################
                     [1m Learning iteration 1203/3000 [0m                     

                       Computation: 89893 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.6837
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9112
                     Learning rate: 0.0009
                       Mean reward: 115.58
               Mean episode length: 958.13
       Episode_Reward/keep_balance: 0.9405
     Episode_Reward/rew_lin_vel_xy: 5.5915
      Episode_Reward/rew_ang_vel_z: 2.2745
    Episode_Reward/pen_base_height: -0.3064
      Episode_Reward/pen_lin_vel_z: -0.0428
     Episode_Reward/pen_ang_vel_xy: -0.1909
   Episode_Reward/pen_joint_torque: -0.2304
    Episode_Reward/pen_joint_accel: -0.1281
    Episode_Reward/pen_action_rate: -0.1252
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0923
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2661
Episode_Reward/pen_flat_orientation: -0.1283
  Episode_Reward/pen_feet_distance: -0.0180
Episode_Reward/pen_feet_regulation: -0.4711
   Episode_Reward/foot_landing_vel: -0.1480
   Episode_Reward/test_gait_reward: -0.9248
Metrics/base_velocity/error_vel_xy: 1.0683
Metrics/base_velocity/error_vel_yaw: 1.3525
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 1.09s
                        Total time: 1310.63s
                               ETA: 1956.1s

################################################################################
                     [1m Learning iteration 1204/3000 [0m                     

                       Computation: 91384 steps/s (collection: 0.948s, learning 0.128s)
               Value function loss: 0.6914
                    Surrogate loss: -0.0018
             Mean action noise std: 0.9112
                     Learning rate: 0.0004
                       Mean reward: 117.01
               Mean episode length: 972.62
       Episode_Reward/keep_balance: 0.9690
     Episode_Reward/rew_lin_vel_xy: 5.7548
      Episode_Reward/rew_ang_vel_z: 2.2728
    Episode_Reward/pen_base_height: -0.3068
      Episode_Reward/pen_lin_vel_z: -0.0427
     Episode_Reward/pen_ang_vel_xy: -0.1970
   Episode_Reward/pen_joint_torque: -0.2285
    Episode_Reward/pen_joint_accel: -0.1171
    Episode_Reward/pen_action_rate: -0.1281
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0616
   Episode_Reward/pen_joint_powers: -0.0931
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2754
Episode_Reward/pen_flat_orientation: -0.1211
  Episode_Reward/pen_feet_distance: -0.0190
Episode_Reward/pen_feet_regulation: -0.4718
   Episode_Reward/foot_landing_vel: -0.1486
   Episode_Reward/test_gait_reward: -0.9585
Metrics/base_velocity/error_vel_xy: 1.1020
Metrics/base_velocity/error_vel_yaw: 1.4510
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 1.08s
                        Total time: 1311.70s
                               ETA: 1955.0s

################################################################################
                     [1m Learning iteration 1205/3000 [0m                     

                       Computation: 91059 steps/s (collection: 0.955s, learning 0.125s)
               Value function loss: 0.7186
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9099
                     Learning rate: 0.0009
                       Mean reward: 118.87
               Mean episode length: 976.43
       Episode_Reward/keep_balance: 0.9617
     Episode_Reward/rew_lin_vel_xy: 5.6848
      Episode_Reward/rew_ang_vel_z: 2.3396
    Episode_Reward/pen_base_height: -0.3045
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.1911
   Episode_Reward/pen_joint_torque: -0.2304
    Episode_Reward/pen_joint_accel: -0.1303
    Episode_Reward/pen_action_rate: -0.1272
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0608
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2715
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4767
   Episode_Reward/foot_landing_vel: -0.1479
   Episode_Reward/test_gait_reward: -0.9505
Metrics/base_velocity/error_vel_xy: 1.1193
Metrics/base_velocity/error_vel_yaw: 1.3601
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 1.08s
                        Total time: 1312.78s
                               ETA: 1953.9s

################################################################################
                     [1m Learning iteration 1206/3000 [0m                     

                       Computation: 91142 steps/s (collection: 0.953s, learning 0.125s)
               Value function loss: 0.6714
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9096
                     Learning rate: 0.0009
                       Mean reward: 110.04
               Mean episode length: 929.22
       Episode_Reward/keep_balance: 0.9336
     Episode_Reward/rew_lin_vel_xy: 5.4495
      Episode_Reward/rew_ang_vel_z: 2.2237
    Episode_Reward/pen_base_height: -0.2981
      Episode_Reward/pen_lin_vel_z: -0.0453
     Episode_Reward/pen_ang_vel_xy: -0.1952
   Episode_Reward/pen_joint_torque: -0.2233
    Episode_Reward/pen_joint_accel: -0.1335
    Episode_Reward/pen_action_rate: -0.1243
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0618
   Episode_Reward/pen_joint_powers: -0.0919
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2670
Episode_Reward/pen_flat_orientation: -0.1248
  Episode_Reward/pen_feet_distance: -0.0186
Episode_Reward/pen_feet_regulation: -0.4731
   Episode_Reward/foot_landing_vel: -0.1567
   Episode_Reward/test_gait_reward: -0.9186
Metrics/base_velocity/error_vel_xy: 1.1166
Metrics/base_velocity/error_vel_yaw: 1.3663
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 1.08s
                        Total time: 1313.86s
                               ETA: 1952.8s

################################################################################
                     [1m Learning iteration 1207/3000 [0m                     

                       Computation: 91242 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.6489
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9101
                     Learning rate: 0.0009
                       Mean reward: 120.65
               Mean episode length: 981.29
       Episode_Reward/keep_balance: 0.9868
     Episode_Reward/rew_lin_vel_xy: 5.8629
      Episode_Reward/rew_ang_vel_z: 2.3641
    Episode_Reward/pen_base_height: -0.3025
      Episode_Reward/pen_lin_vel_z: -0.0430
     Episode_Reward/pen_ang_vel_xy: -0.1991
   Episode_Reward/pen_joint_torque: -0.2296
    Episode_Reward/pen_joint_accel: -0.1206
    Episode_Reward/pen_action_rate: -0.1304
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0622
   Episode_Reward/pen_joint_powers: -0.0946
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2815
Episode_Reward/pen_flat_orientation: -0.1198
  Episode_Reward/pen_feet_distance: -0.0172
Episode_Reward/pen_feet_regulation: -0.4811
   Episode_Reward/foot_landing_vel: -0.1512
   Episode_Reward/test_gait_reward: -0.9718
Metrics/base_velocity/error_vel_xy: 1.1034
Metrics/base_velocity/error_vel_yaw: 1.4415
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 1.08s
                        Total time: 1314.94s
                               ETA: 1951.7s

################################################################################
                     [1m Learning iteration 1208/3000 [0m                     

                       Computation: 90504 steps/s (collection: 0.961s, learning 0.125s)
               Value function loss: 0.7348
                    Surrogate loss: -0.0018
             Mean action noise std: 0.9108
                     Learning rate: 0.0009
                       Mean reward: 119.74
               Mean episode length: 969.77
       Episode_Reward/keep_balance: 0.9739
     Episode_Reward/rew_lin_vel_xy: 5.8087
      Episode_Reward/rew_ang_vel_z: 2.3557
    Episode_Reward/pen_base_height: -0.3071
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1917
   Episode_Reward/pen_joint_torque: -0.2244
    Episode_Reward/pen_joint_accel: -0.1135
    Episode_Reward/pen_action_rate: -0.1275
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0593
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2729
Episode_Reward/pen_flat_orientation: -0.1180
  Episode_Reward/pen_feet_distance: -0.0194
Episode_Reward/pen_feet_regulation: -0.4655
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.9495
Metrics/base_velocity/error_vel_xy: 1.0839
Metrics/base_velocity/error_vel_yaw: 1.4052
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 1.09s
                        Total time: 1316.03s
                               ETA: 1950.6s

################################################################################
                     [1m Learning iteration 1209/3000 [0m                     

                       Computation: 89381 steps/s (collection: 0.977s, learning 0.122s)
               Value function loss: 0.7140
                    Surrogate loss: -0.0026
             Mean action noise std: 0.9097
                     Learning rate: 0.0006
                       Mean reward: 118.35
               Mean episode length: 962.53
       Episode_Reward/keep_balance: 0.9583
     Episode_Reward/rew_lin_vel_xy: 5.6752
      Episode_Reward/rew_ang_vel_z: 2.3181
    Episode_Reward/pen_base_height: -0.3150
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.1928
   Episode_Reward/pen_joint_torque: -0.2255
    Episode_Reward/pen_joint_accel: -0.1148
    Episode_Reward/pen_action_rate: -0.1258
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0612
   Episode_Reward/pen_joint_powers: -0.0928
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2696
Episode_Reward/pen_flat_orientation: -0.1280
  Episode_Reward/pen_feet_distance: -0.0161
Episode_Reward/pen_feet_regulation: -0.4721
   Episode_Reward/foot_landing_vel: -0.1440
   Episode_Reward/test_gait_reward: -0.9447
Metrics/base_velocity/error_vel_xy: 1.1012
Metrics/base_velocity/error_vel_yaw: 1.3772
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 1.10s
                        Total time: 1317.13s
                               ETA: 1949.6s

################################################################################
                     [1m Learning iteration 1210/3000 [0m                     

                       Computation: 91724 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.7359
                    Surrogate loss: -0.0003
             Mean action noise std: 0.9094
                     Learning rate: 0.0002
                       Mean reward: 115.43
               Mean episode length: 948.27
       Episode_Reward/keep_balance: 0.9585
     Episode_Reward/rew_lin_vel_xy: 5.6446
      Episode_Reward/rew_ang_vel_z: 2.2480
    Episode_Reward/pen_base_height: -0.2958
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.2061
   Episode_Reward/pen_joint_torque: -0.2252
    Episode_Reward/pen_joint_accel: -0.1242
    Episode_Reward/pen_action_rate: -0.1292
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0626
   Episode_Reward/pen_joint_powers: -0.0950
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2784
Episode_Reward/pen_flat_orientation: -0.1214
  Episode_Reward/pen_feet_distance: -0.0138
Episode_Reward/pen_feet_regulation: -0.4809
   Episode_Reward/foot_landing_vel: -0.1445
   Episode_Reward/test_gait_reward: -0.9467
Metrics/base_velocity/error_vel_xy: 1.1081
Metrics/base_velocity/error_vel_yaw: 1.4564
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 1.07s
                        Total time: 1318.20s
                               ETA: 1948.5s

################################################################################
                     [1m Learning iteration 1211/3000 [0m                     

                       Computation: 90645 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.6774
                    Surrogate loss: -0.0049
             Mean action noise std: 0.9084
                     Learning rate: 0.0004
                       Mean reward: 115.02
               Mean episode length: 954.15
       Episode_Reward/keep_balance: 0.9474
     Episode_Reward/rew_lin_vel_xy: 5.5803
      Episode_Reward/rew_ang_vel_z: 2.2369
    Episode_Reward/pen_base_height: -0.2972
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1931
   Episode_Reward/pen_joint_torque: -0.2190
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1255
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0610
   Episode_Reward/pen_joint_powers: -0.0922
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2691
Episode_Reward/pen_flat_orientation: -0.1288
  Episode_Reward/pen_feet_distance: -0.0197
Episode_Reward/pen_feet_regulation: -0.4827
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9402
Metrics/base_velocity/error_vel_xy: 1.1046
Metrics/base_velocity/error_vel_yaw: 1.4176
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 1.08s
                        Total time: 1319.28s
                               ETA: 1947.4s

################################################################################
                     [1m Learning iteration 1212/3000 [0m                     

                       Computation: 90196 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.6721
                    Surrogate loss: -0.0038
             Mean action noise std: 0.9077
                     Learning rate: 0.0006
                       Mean reward: 115.68
               Mean episode length: 969.26
       Episode_Reward/keep_balance: 0.9622
     Episode_Reward/rew_lin_vel_xy: 5.6535
      Episode_Reward/rew_ang_vel_z: 2.2471
    Episode_Reward/pen_base_height: -0.3092
      Episode_Reward/pen_lin_vel_z: -0.0438
     Episode_Reward/pen_ang_vel_xy: -0.2044
   Episode_Reward/pen_joint_torque: -0.2297
    Episode_Reward/pen_joint_accel: -0.1207
    Episode_Reward/pen_action_rate: -0.1293
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0629
   Episode_Reward/pen_joint_powers: -0.0949
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2797
Episode_Reward/pen_flat_orientation: -0.1214
  Episode_Reward/pen_feet_distance: -0.0174
Episode_Reward/pen_feet_regulation: -0.4727
   Episode_Reward/foot_landing_vel: -0.1482
   Episode_Reward/test_gait_reward: -0.9541
Metrics/base_velocity/error_vel_xy: 1.1110
Metrics/base_velocity/error_vel_yaw: 1.4614
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 1.09s
                        Total time: 1320.37s
                               ETA: 1946.3s

################################################################################
                     [1m Learning iteration 1213/3000 [0m                     

                       Computation: 90546 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.7140
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9074
                     Learning rate: 0.0006
                       Mean reward: 115.99
               Mean episode length: 973.00
       Episode_Reward/keep_balance: 0.9756
     Episode_Reward/rew_lin_vel_xy: 5.8001
      Episode_Reward/rew_ang_vel_z: 2.3197
    Episode_Reward/pen_base_height: -0.3100
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1910
   Episode_Reward/pen_joint_torque: -0.2266
    Episode_Reward/pen_joint_accel: -0.1207
    Episode_Reward/pen_action_rate: -0.1277
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0618
   Episode_Reward/pen_joint_powers: -0.0938
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2750
Episode_Reward/pen_flat_orientation: -0.1190
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4781
   Episode_Reward/foot_landing_vel: -0.1416
   Episode_Reward/test_gait_reward: -0.9613
Metrics/base_velocity/error_vel_xy: 1.1050
Metrics/base_velocity/error_vel_yaw: 1.4334
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 1.09s
                        Total time: 1321.46s
                               ETA: 1945.2s

################################################################################
                     [1m Learning iteration 1214/3000 [0m                     

                       Computation: 88893 steps/s (collection: 0.983s, learning 0.123s)
               Value function loss: 0.6740
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9088
                     Learning rate: 0.0009
                       Mean reward: 111.87
               Mean episode length: 949.76
       Episode_Reward/keep_balance: 0.9565
     Episode_Reward/rew_lin_vel_xy: 5.5935
      Episode_Reward/rew_ang_vel_z: 2.2908
    Episode_Reward/pen_base_height: -0.3103
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1978
   Episode_Reward/pen_joint_torque: -0.2330
    Episode_Reward/pen_joint_accel: -0.1205
    Episode_Reward/pen_action_rate: -0.1265
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0619
   Episode_Reward/pen_joint_powers: -0.0944
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2703
Episode_Reward/pen_flat_orientation: -0.1261
  Episode_Reward/pen_feet_distance: -0.0179
Episode_Reward/pen_feet_regulation: -0.4849
   Episode_Reward/foot_landing_vel: -0.1452
   Episode_Reward/test_gait_reward: -0.9382
Metrics/base_velocity/error_vel_xy: 1.1435
Metrics/base_velocity/error_vel_yaw: 1.3908
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 1.11s
                        Total time: 1322.56s
                               ETA: 1944.1s

################################################################################
                     [1m Learning iteration 1215/3000 [0m                     

                       Computation: 90168 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.6180
                    Surrogate loss: -0.0005
             Mean action noise std: 0.9098
                     Learning rate: 0.0004
                       Mean reward: 117.32
               Mean episode length: 958.47
       Episode_Reward/keep_balance: 0.9759
     Episode_Reward/rew_lin_vel_xy: 5.8365
      Episode_Reward/rew_ang_vel_z: 2.3804
    Episode_Reward/pen_base_height: -0.3082
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.1951
   Episode_Reward/pen_joint_torque: -0.2418
    Episode_Reward/pen_joint_accel: -0.1165
    Episode_Reward/pen_action_rate: -0.1270
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0611
   Episode_Reward/pen_joint_powers: -0.0950
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2705
Episode_Reward/pen_flat_orientation: -0.1141
  Episode_Reward/pen_feet_distance: -0.0156
Episode_Reward/pen_feet_regulation: -0.4817
   Episode_Reward/foot_landing_vel: -0.1439
   Episode_Reward/test_gait_reward: -0.9604
Metrics/base_velocity/error_vel_xy: 1.0938
Metrics/base_velocity/error_vel_yaw: 1.3758
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 1.09s
                        Total time: 1323.65s
                               ETA: 1943.0s

################################################################################
                     [1m Learning iteration 1216/3000 [0m                     

                       Computation: 90167 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.6967
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9106
                     Learning rate: 0.0009
                       Mean reward: 115.87
               Mean episode length: 965.67
       Episode_Reward/keep_balance: 0.9699
     Episode_Reward/rew_lin_vel_xy: 5.7391
      Episode_Reward/rew_ang_vel_z: 2.3266
    Episode_Reward/pen_base_height: -0.3001
      Episode_Reward/pen_lin_vel_z: -0.0428
     Episode_Reward/pen_ang_vel_xy: -0.1961
   Episode_Reward/pen_joint_torque: -0.2237
    Episode_Reward/pen_joint_accel: -0.1165
    Episode_Reward/pen_action_rate: -0.1269
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0617
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2747
Episode_Reward/pen_flat_orientation: -0.1200
  Episode_Reward/pen_feet_distance: -0.0161
Episode_Reward/pen_feet_regulation: -0.4629
   Episode_Reward/foot_landing_vel: -0.1543
   Episode_Reward/test_gait_reward: -0.9405
Metrics/base_velocity/error_vel_xy: 1.1255
Metrics/base_velocity/error_vel_yaw: 1.4101
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 1.09s
                        Total time: 1324.74s
                               ETA: 1941.9s

################################################################################
                     [1m Learning iteration 1217/3000 [0m                     

                       Computation: 91768 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.6219
                    Surrogate loss: -0.0015
             Mean action noise std: 0.9117
                     Learning rate: 0.0004
                       Mean reward: 119.48
               Mean episode length: 972.12
       Episode_Reward/keep_balance: 0.9853
     Episode_Reward/rew_lin_vel_xy: 5.8602
      Episode_Reward/rew_ang_vel_z: 2.3512
    Episode_Reward/pen_base_height: -0.2985
      Episode_Reward/pen_lin_vel_z: -0.0423
     Episode_Reward/pen_ang_vel_xy: -0.1949
   Episode_Reward/pen_joint_torque: -0.2353
    Episode_Reward/pen_joint_accel: -0.1111
    Episode_Reward/pen_action_rate: -0.1288
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0615
   Episode_Reward/pen_joint_powers: -0.0955
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2760
Episode_Reward/pen_flat_orientation: -0.1186
  Episode_Reward/pen_feet_distance: -0.0184
Episode_Reward/pen_feet_regulation: -0.4827
   Episode_Reward/foot_landing_vel: -0.1487
   Episode_Reward/test_gait_reward: -0.9659
Metrics/base_velocity/error_vel_xy: 1.1208
Metrics/base_velocity/error_vel_yaw: 1.4415
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 1.07s
                        Total time: 1325.82s
                               ETA: 1940.8s

################################################################################
                     [1m Learning iteration 1218/3000 [0m                     

                       Computation: 89994 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.6212
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9116
                     Learning rate: 0.0003
                       Mean reward: 124.85
               Mean episode length: 993.56
       Episode_Reward/keep_balance: 0.9871
     Episode_Reward/rew_lin_vel_xy: 5.9649
      Episode_Reward/rew_ang_vel_z: 2.4019
    Episode_Reward/pen_base_height: -0.3030
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1925
   Episode_Reward/pen_joint_torque: -0.2346
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1273
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0930
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2734
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0174
Episode_Reward/pen_feet_regulation: -0.4632
   Episode_Reward/foot_landing_vel: -0.1468
   Episode_Reward/test_gait_reward: -0.9621
Metrics/base_velocity/error_vel_xy: 1.0768
Metrics/base_velocity/error_vel_yaw: 1.3976
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 1.09s
                        Total time: 1326.91s
                               ETA: 1939.7s

################################################################################
                     [1m Learning iteration 1219/3000 [0m                     

                       Computation: 90763 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.6476
                    Surrogate loss: -0.0052
             Mean action noise std: 0.9119
                     Learning rate: 0.0006
                       Mean reward: 118.24
               Mean episode length: 986.04
       Episode_Reward/keep_balance: 0.9874
     Episode_Reward/rew_lin_vel_xy: 5.7682
      Episode_Reward/rew_ang_vel_z: 2.3553
    Episode_Reward/pen_base_height: -0.3080
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.1982
   Episode_Reward/pen_joint_torque: -0.2319
    Episode_Reward/pen_joint_accel: -0.1169
    Episode_Reward/pen_action_rate: -0.1304
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0639
   Episode_Reward/pen_joint_powers: -0.0962
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2783
Episode_Reward/pen_flat_orientation: -0.1265
  Episode_Reward/pen_feet_distance: -0.0148
Episode_Reward/pen_feet_regulation: -0.4958
   Episode_Reward/foot_landing_vel: -0.1487
   Episode_Reward/test_gait_reward: -0.9732
Metrics/base_velocity/error_vel_xy: 1.1736
Metrics/base_velocity/error_vel_yaw: 1.4528
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 1.08s
                        Total time: 1327.99s
                               ETA: 1938.6s

################################################################################
                     [1m Learning iteration 1220/3000 [0m                     

                       Computation: 90761 steps/s (collection: 0.958s, learning 0.125s)
               Value function loss: 0.7380
                    Surrogate loss: -0.0045
             Mean action noise std: 0.9126
                     Learning rate: 0.0009
                       Mean reward: 117.92
               Mean episode length: 971.12
       Episode_Reward/keep_balance: 0.9749
     Episode_Reward/rew_lin_vel_xy: 5.8072
      Episode_Reward/rew_ang_vel_z: 2.3204
    Episode_Reward/pen_base_height: -0.2962
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1902
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1264
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0908
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2705
Episode_Reward/pen_flat_orientation: -0.1194
  Episode_Reward/pen_feet_distance: -0.0164
Episode_Reward/pen_feet_regulation: -0.4696
   Episode_Reward/foot_landing_vel: -0.1388
   Episode_Reward/test_gait_reward: -0.9656
Metrics/base_velocity/error_vel_xy: 1.0994
Metrics/base_velocity/error_vel_yaw: 1.4304
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 1.08s
                        Total time: 1329.07s
                               ETA: 1937.6s

################################################################################
                     [1m Learning iteration 1221/3000 [0m                     

                       Computation: 90526 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.6052
                    Surrogate loss: -0.0003
             Mean action noise std: 0.9117
                     Learning rate: 0.0004
                       Mean reward: 115.16
               Mean episode length: 952.84
       Episode_Reward/keep_balance: 0.9602
     Episode_Reward/rew_lin_vel_xy: 5.7245
      Episode_Reward/rew_ang_vel_z: 2.3003
    Episode_Reward/pen_base_height: -0.3102
      Episode_Reward/pen_lin_vel_z: -0.0427
     Episode_Reward/pen_ang_vel_xy: -0.1931
   Episode_Reward/pen_joint_torque: -0.2289
    Episode_Reward/pen_joint_accel: -0.1200
    Episode_Reward/pen_action_rate: -0.1259
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0618
   Episode_Reward/pen_joint_powers: -0.0936
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2700
Episode_Reward/pen_flat_orientation: -0.1230
  Episode_Reward/pen_feet_distance: -0.0165
Episode_Reward/pen_feet_regulation: -0.4805
   Episode_Reward/foot_landing_vel: -0.1435
   Episode_Reward/test_gait_reward: -0.9540
Metrics/base_velocity/error_vel_xy: 1.0843
Metrics/base_velocity/error_vel_yaw: 1.3989
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 1.09s
                        Total time: 1330.16s
                               ETA: 1936.5s

################################################################################
                     [1m Learning iteration 1222/3000 [0m                     

                       Computation: 90726 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.6550
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9102
                     Learning rate: 0.0003
                       Mean reward: 119.92
               Mean episode length: 970.76
       Episode_Reward/keep_balance: 0.9736
     Episode_Reward/rew_lin_vel_xy: 5.8288
      Episode_Reward/rew_ang_vel_z: 2.3964
    Episode_Reward/pen_base_height: -0.2976
      Episode_Reward/pen_lin_vel_z: -0.0447
     Episode_Reward/pen_ang_vel_xy: -0.1951
   Episode_Reward/pen_joint_torque: -0.2443
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1259
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0613
   Episode_Reward/pen_joint_powers: -0.0952
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2673
Episode_Reward/pen_flat_orientation: -0.1207
  Episode_Reward/pen_feet_distance: -0.0172
Episode_Reward/pen_feet_regulation: -0.4739
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.9557
Metrics/base_velocity/error_vel_xy: 1.0900
Metrics/base_velocity/error_vel_yaw: 1.3548
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 1.08s
                        Total time: 1331.24s
                               ETA: 1935.4s

################################################################################
                     [1m Learning iteration 1223/3000 [0m                     

                       Computation: 88927 steps/s (collection: 0.983s, learning 0.122s)
               Value function loss: 0.6847
                    Surrogate loss: -0.0049
             Mean action noise std: 0.9100
                     Learning rate: 0.0006
                       Mean reward: 123.90
               Mean episode length: 968.50
       Episode_Reward/keep_balance: 0.9654
     Episode_Reward/rew_lin_vel_xy: 5.9347
      Episode_Reward/rew_ang_vel_z: 2.3498
    Episode_Reward/pen_base_height: -0.2699
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1870
   Episode_Reward/pen_joint_torque: -0.2129
    Episode_Reward/pen_joint_accel: -0.1069
    Episode_Reward/pen_action_rate: -0.1212
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2662
Episode_Reward/pen_flat_orientation: -0.1096
  Episode_Reward/pen_feet_distance: -0.0168
Episode_Reward/pen_feet_regulation: -0.4306
   Episode_Reward/foot_landing_vel: -0.1362
   Episode_Reward/test_gait_reward: -0.9386
Metrics/base_velocity/error_vel_xy: 0.9844
Metrics/base_velocity/error_vel_yaw: 1.3615
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 1.11s
                        Total time: 1332.35s
                               ETA: 1934.3s

################################################################################
                     [1m Learning iteration 1224/3000 [0m                     

                       Computation: 90176 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.7388
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9100
                     Learning rate: 0.0006
                       Mean reward: 114.53
               Mean episode length: 942.54
       Episode_Reward/keep_balance: 0.9428
     Episode_Reward/rew_lin_vel_xy: 5.6239
      Episode_Reward/rew_ang_vel_z: 2.2341
    Episode_Reward/pen_base_height: -0.2858
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1925
   Episode_Reward/pen_joint_torque: -0.2180
    Episode_Reward/pen_joint_accel: -0.1162
    Episode_Reward/pen_action_rate: -0.1243
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2680
Episode_Reward/pen_flat_orientation: -0.1194
  Episode_Reward/pen_feet_distance: -0.0169
Episode_Reward/pen_feet_regulation: -0.4727
   Episode_Reward/foot_landing_vel: -0.1403
   Episode_Reward/test_gait_reward: -0.9325
Metrics/base_velocity/error_vel_xy: 1.0592
Metrics/base_velocity/error_vel_yaw: 1.4136
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 1.09s
                        Total time: 1333.44s
                               ETA: 1933.2s

################################################################################
                     [1m Learning iteration 1225/3000 [0m                     

                       Computation: 89938 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.6304
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9082
                     Learning rate: 0.0003
                       Mean reward: 117.34
               Mean episode length: 961.78
       Episode_Reward/keep_balance: 0.9568
     Episode_Reward/rew_lin_vel_xy: 5.7035
      Episode_Reward/rew_ang_vel_z: 2.2720
    Episode_Reward/pen_base_height: -0.2906
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.1925
   Episode_Reward/pen_joint_torque: -0.2191
    Episode_Reward/pen_joint_accel: -0.1126
    Episode_Reward/pen_action_rate: -0.1250
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0595
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2713
Episode_Reward/pen_flat_orientation: -0.1207
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4709
   Episode_Reward/foot_landing_vel: -0.1368
   Episode_Reward/test_gait_reward: -0.9367
Metrics/base_velocity/error_vel_xy: 1.0786
Metrics/base_velocity/error_vel_yaw: 1.4181
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 1.09s
                        Total time: 1334.53s
                               ETA: 1932.1s

################################################################################
                     [1m Learning iteration 1226/3000 [0m                     

                       Computation: 90033 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.6365
                    Surrogate loss: -0.0053
             Mean action noise std: 0.9084
                     Learning rate: 0.0006
                       Mean reward: 117.43
               Mean episode length: 953.89
       Episode_Reward/keep_balance: 0.9498
     Episode_Reward/rew_lin_vel_xy: 5.7572
      Episode_Reward/rew_ang_vel_z: 2.2815
    Episode_Reward/pen_base_height: -0.2887
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1899
   Episode_Reward/pen_joint_torque: -0.2239
    Episode_Reward/pen_joint_accel: -0.1057
    Episode_Reward/pen_action_rate: -0.1226
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0597
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2665
Episode_Reward/pen_flat_orientation: -0.1168
  Episode_Reward/pen_feet_distance: -0.0158
Episode_Reward/pen_feet_regulation: -0.4628
   Episode_Reward/foot_landing_vel: -0.1368
   Episode_Reward/test_gait_reward: -0.9284
Metrics/base_velocity/error_vel_xy: 1.0419
Metrics/base_velocity/error_vel_yaw: 1.3794
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 1.09s
                        Total time: 1335.62s
                               ETA: 1931.0s

################################################################################
                     [1m Learning iteration 1227/3000 [0m                     

                       Computation: 89477 steps/s (collection: 0.974s, learning 0.125s)
               Value function loss: 0.6901
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9095
                     Learning rate: 0.0006
                       Mean reward: 118.49
               Mean episode length: 970.80
       Episode_Reward/keep_balance: 0.9703
     Episode_Reward/rew_lin_vel_xy: 5.8299
      Episode_Reward/rew_ang_vel_z: 2.3367
    Episode_Reward/pen_base_height: -0.3006
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.1962
   Episode_Reward/pen_joint_torque: -0.2270
    Episode_Reward/pen_joint_accel: -0.1172
    Episode_Reward/pen_action_rate: -0.1263
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0623
   Episode_Reward/pen_joint_powers: -0.0942
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2728
Episode_Reward/pen_flat_orientation: -0.1214
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.4870
   Episode_Reward/foot_landing_vel: -0.1473
   Episode_Reward/test_gait_reward: -0.9591
Metrics/base_velocity/error_vel_xy: 1.0881
Metrics/base_velocity/error_vel_yaw: 1.4051
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 1.10s
                        Total time: 1336.72s
                               ETA: 1930.0s

################################################################################
                     [1m Learning iteration 1228/3000 [0m                     

                       Computation: 90709 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.6863
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9107
                     Learning rate: 0.0009
                       Mean reward: 120.41
               Mean episode length: 977.17
       Episode_Reward/keep_balance: 0.9767
     Episode_Reward/rew_lin_vel_xy: 5.8402
      Episode_Reward/rew_ang_vel_z: 2.3575
    Episode_Reward/pen_base_height: -0.2970
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1964
   Episode_Reward/pen_joint_torque: -0.2272
    Episode_Reward/pen_joint_accel: -0.1165
    Episode_Reward/pen_action_rate: -0.1270
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0612
   Episode_Reward/pen_joint_powers: -0.0932
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2756
Episode_Reward/pen_flat_orientation: -0.1193
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4884
   Episode_Reward/foot_landing_vel: -0.1467
   Episode_Reward/test_gait_reward: -0.9536
Metrics/base_velocity/error_vel_xy: 1.0997
Metrics/base_velocity/error_vel_yaw: 1.4035
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 1.08s
                        Total time: 1337.81s
                               ETA: 1928.9s

################################################################################
                     [1m Learning iteration 1229/3000 [0m                     

                       Computation: 89247 steps/s (collection: 0.978s, learning 0.124s)
               Value function loss: 0.6999
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9112
                     Learning rate: 0.0006
                       Mean reward: 117.06
               Mean episode length: 947.63
       Episode_Reward/keep_balance: 0.9366
     Episode_Reward/rew_lin_vel_xy: 5.6352
      Episode_Reward/rew_ang_vel_z: 2.3039
    Episode_Reward/pen_base_height: -0.2943
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.1855
   Episode_Reward/pen_joint_torque: -0.2286
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2578
Episode_Reward/pen_flat_orientation: -0.1200
  Episode_Reward/pen_feet_distance: -0.0151
Episode_Reward/pen_feet_regulation: -0.4553
   Episode_Reward/foot_landing_vel: -0.1420
   Episode_Reward/test_gait_reward: -0.9167
Metrics/base_velocity/error_vel_xy: 1.0339
Metrics/base_velocity/error_vel_yaw: 1.3042
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 1.10s
                        Total time: 1338.91s
                               ETA: 1927.8s

################################################################################
                     [1m Learning iteration 1230/3000 [0m                     

                       Computation: 89358 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.7147
                    Surrogate loss: -0.0024
             Mean action noise std: 0.9116
                     Learning rate: 0.0006
                       Mean reward: 120.99
               Mean episode length: 973.14
       Episode_Reward/keep_balance: 0.9767
     Episode_Reward/rew_lin_vel_xy: 5.8248
      Episode_Reward/rew_ang_vel_z: 2.3486
    Episode_Reward/pen_base_height: -0.2980
      Episode_Reward/pen_lin_vel_z: -0.0420
     Episode_Reward/pen_ang_vel_xy: -0.1911
   Episode_Reward/pen_joint_torque: -0.2300
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.1266
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0607
   Episode_Reward/pen_joint_powers: -0.0935
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2714
Episode_Reward/pen_flat_orientation: -0.1243
  Episode_Reward/pen_feet_distance: -0.0193
Episode_Reward/pen_feet_regulation: -0.4674
   Episode_Reward/foot_landing_vel: -0.1439
   Episode_Reward/test_gait_reward: -0.9542
Metrics/base_velocity/error_vel_xy: 1.0902
Metrics/base_velocity/error_vel_yaw: 1.4215
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 1.10s
                        Total time: 1340.01s
                               ETA: 1926.7s

################################################################################
                     [1m Learning iteration 1231/3000 [0m                     

                       Computation: 90531 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.6010
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9105
                     Learning rate: 0.0006
                       Mean reward: 118.05
               Mean episode length: 973.07
       Episode_Reward/keep_balance: 0.9749
     Episode_Reward/rew_lin_vel_xy: 5.8593
      Episode_Reward/rew_ang_vel_z: 2.3203
    Episode_Reward/pen_base_height: -0.3040
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.1952
   Episode_Reward/pen_joint_torque: -0.2289
    Episode_Reward/pen_joint_accel: -0.1140
    Episode_Reward/pen_action_rate: -0.1281
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0619
   Episode_Reward/pen_joint_powers: -0.0951
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2761
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0181
Episode_Reward/pen_feet_regulation: -0.4882
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.9644
Metrics/base_velocity/error_vel_xy: 1.0821
Metrics/base_velocity/error_vel_yaw: 1.4463
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 1.09s
                        Total time: 1341.09s
                               ETA: 1925.6s

################################################################################
                     [1m Learning iteration 1232/3000 [0m                     

                       Computation: 89657 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.6498
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9092
                     Learning rate: 0.0004
                       Mean reward: 119.74
               Mean episode length: 980.69
       Episode_Reward/keep_balance: 0.9897
     Episode_Reward/rew_lin_vel_xy: 5.8399
      Episode_Reward/rew_ang_vel_z: 2.3573
    Episode_Reward/pen_base_height: -0.3029
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.1969
   Episode_Reward/pen_joint_torque: -0.2444
    Episode_Reward/pen_joint_accel: -0.1093
    Episode_Reward/pen_action_rate: -0.1305
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0611
   Episode_Reward/pen_joint_powers: -0.0971
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2783
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0185
Episode_Reward/pen_feet_regulation: -0.4794
   Episode_Reward/foot_landing_vel: -0.1372
   Episode_Reward/test_gait_reward: -0.9781
Metrics/base_velocity/error_vel_xy: 1.1504
Metrics/base_velocity/error_vel_yaw: 1.4582
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 1.10s
                        Total time: 1342.19s
                               ETA: 1924.6s

################################################################################
                     [1m Learning iteration 1233/3000 [0m                     

                       Computation: 89943 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.6263
                    Surrogate loss: -0.0051
             Mean action noise std: 0.9107
                     Learning rate: 0.0009
                       Mean reward: 123.86
               Mean episode length: 988.35
       Episode_Reward/keep_balance: 0.9887
     Episode_Reward/rew_lin_vel_xy: 5.9748
      Episode_Reward/rew_ang_vel_z: 2.4141
    Episode_Reward/pen_base_height: -0.3134
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.1942
   Episode_Reward/pen_joint_torque: -0.2367
    Episode_Reward/pen_joint_accel: -0.1078
    Episode_Reward/pen_action_rate: -0.1264
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0932
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2718
Episode_Reward/pen_flat_orientation: -0.1193
  Episode_Reward/pen_feet_distance: -0.0211
Episode_Reward/pen_feet_regulation: -0.4686
   Episode_Reward/foot_landing_vel: -0.1430
   Episode_Reward/test_gait_reward: -0.9618
Metrics/base_velocity/error_vel_xy: 1.0780
Metrics/base_velocity/error_vel_yaw: 1.3848
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 1.09s
                        Total time: 1343.28s
                               ETA: 1923.5s

################################################################################
                     [1m Learning iteration 1234/3000 [0m                     

                       Computation: 88015 steps/s (collection: 0.991s, learning 0.126s)
               Value function loss: 0.6373
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9098
                     Learning rate: 0.0006
                       Mean reward: 122.39
               Mean episode length: 989.51
       Episode_Reward/keep_balance: 0.9907
     Episode_Reward/rew_lin_vel_xy: 5.9542
      Episode_Reward/rew_ang_vel_z: 2.3793
    Episode_Reward/pen_base_height: -0.3050
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1970
   Episode_Reward/pen_joint_torque: -0.2356
    Episode_Reward/pen_joint_accel: -0.1217
    Episode_Reward/pen_action_rate: -0.1296
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0620
   Episode_Reward/pen_joint_powers: -0.0961
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2790
Episode_Reward/pen_flat_orientation: -0.1213
  Episode_Reward/pen_feet_distance: -0.0188
Episode_Reward/pen_feet_regulation: -0.4787
   Episode_Reward/foot_landing_vel: -0.1354
   Episode_Reward/test_gait_reward: -0.9749
Metrics/base_velocity/error_vel_xy: 1.1046
Metrics/base_velocity/error_vel_yaw: 1.4342
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 1.12s
                        Total time: 1344.40s
                               ETA: 1922.4s

################################################################################
                     [1m Learning iteration 1235/3000 [0m                     

                       Computation: 88710 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 0.6385
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9100
                     Learning rate: 0.0006
                       Mean reward: 123.87
               Mean episode length: 992.26
       Episode_Reward/keep_balance: 0.9893
     Episode_Reward/rew_lin_vel_xy: 5.9287
      Episode_Reward/rew_ang_vel_z: 2.3961
    Episode_Reward/pen_base_height: -0.2920
      Episode_Reward/pen_lin_vel_z: -0.0419
     Episode_Reward/pen_ang_vel_xy: -0.1926
   Episode_Reward/pen_joint_torque: -0.2332
    Episode_Reward/pen_joint_accel: -0.1214
    Episode_Reward/pen_action_rate: -0.1277
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0611
   Episode_Reward/pen_joint_powers: -0.0943
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2733
Episode_Reward/pen_flat_orientation: -0.1182
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4917
   Episode_Reward/foot_landing_vel: -0.1413
   Episode_Reward/test_gait_reward: -0.9769
Metrics/base_velocity/error_vel_xy: 1.0987
Metrics/base_velocity/error_vel_yaw: 1.4095
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 1.11s
                        Total time: 1345.51s
                               ETA: 1921.4s

################################################################################
                     [1m Learning iteration 1236/3000 [0m                     

                       Computation: 89944 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 0.6154
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9104
                     Learning rate: 0.0004
                       Mean reward: 120.84
               Mean episode length: 978.53
       Episode_Reward/keep_balance: 0.9793
     Episode_Reward/rew_lin_vel_xy: 5.9139
      Episode_Reward/rew_ang_vel_z: 2.3627
    Episode_Reward/pen_base_height: -0.3059
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.1933
   Episode_Reward/pen_joint_torque: -0.2271
    Episode_Reward/pen_joint_accel: -0.1182
    Episode_Reward/pen_action_rate: -0.1267
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0607
   Episode_Reward/pen_joint_powers: -0.0935
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2721
Episode_Reward/pen_flat_orientation: -0.1241
  Episode_Reward/pen_feet_distance: -0.0178
Episode_Reward/pen_feet_regulation: -0.4753
   Episode_Reward/foot_landing_vel: -0.1399
   Episode_Reward/test_gait_reward: -0.9618
Metrics/base_velocity/error_vel_xy: 1.0560
Metrics/base_velocity/error_vel_yaw: 1.4205
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 1.09s
                        Total time: 1346.60s
                               ETA: 1920.3s

################################################################################
                     [1m Learning iteration 1237/3000 [0m                     

                       Computation: 89124 steps/s (collection: 0.978s, learning 0.125s)
               Value function loss: 0.6844
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9093
                     Learning rate: 0.0004
                       Mean reward: 119.86
               Mean episode length: 982.44
       Episode_Reward/keep_balance: 0.9820
     Episode_Reward/rew_lin_vel_xy: 5.8615
      Episode_Reward/rew_ang_vel_z: 2.3414
    Episode_Reward/pen_base_height: -0.3029
      Episode_Reward/pen_lin_vel_z: -0.0440
     Episode_Reward/pen_ang_vel_xy: -0.2032
   Episode_Reward/pen_joint_torque: -0.2352
    Episode_Reward/pen_joint_accel: -0.1189
    Episode_Reward/pen_action_rate: -0.1309
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0631
   Episode_Reward/pen_joint_powers: -0.0959
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2787
Episode_Reward/pen_flat_orientation: -0.1231
  Episode_Reward/pen_feet_distance: -0.0191
Episode_Reward/pen_feet_regulation: -0.5005
   Episode_Reward/foot_landing_vel: -0.1495
   Episode_Reward/test_gait_reward: -0.9689
Metrics/base_velocity/error_vel_xy: 1.0954
Metrics/base_velocity/error_vel_yaw: 1.4506
      Episode_Termination/time_out: 4.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 1.10s
                        Total time: 1347.70s
                               ETA: 1919.2s

################################################################################
                     [1m Learning iteration 1238/3000 [0m                     

                       Computation: 90487 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.6226
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9074
                     Learning rate: 0.0003
                       Mean reward: 121.37
               Mean episode length: 969.66
       Episode_Reward/keep_balance: 0.9765
     Episode_Reward/rew_lin_vel_xy: 5.8195
      Episode_Reward/rew_ang_vel_z: 2.3934
    Episode_Reward/pen_base_height: -0.3037
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.1931
   Episode_Reward/pen_joint_torque: -0.2328
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1256
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2704
Episode_Reward/pen_flat_orientation: -0.1155
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4685
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.9557
Metrics/base_velocity/error_vel_xy: 1.0916
Metrics/base_velocity/error_vel_yaw: 1.3576
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 1.09s
                        Total time: 1348.79s
                               ETA: 1918.1s

################################################################################
                     [1m Learning iteration 1239/3000 [0m                     

                       Computation: 89606 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.6201
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9075
                     Learning rate: 0.0004
                       Mean reward: 122.36
               Mean episode length: 974.58
       Episode_Reward/keep_balance: 0.9797
     Episode_Reward/rew_lin_vel_xy: 5.9032
      Episode_Reward/rew_ang_vel_z: 2.3744
    Episode_Reward/pen_base_height: -0.3003
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1868
   Episode_Reward/pen_joint_torque: -0.2296
    Episode_Reward/pen_joint_accel: -0.1122
    Episode_Reward/pen_action_rate: -0.1255
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0595
   Episode_Reward/pen_joint_powers: -0.0924
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2714
Episode_Reward/pen_flat_orientation: -0.1140
  Episode_Reward/pen_feet_distance: -0.0208
Episode_Reward/pen_feet_regulation: -0.4629
   Episode_Reward/foot_landing_vel: -0.1393
   Episode_Reward/test_gait_reward: -0.9471
Metrics/base_velocity/error_vel_xy: 1.0748
Metrics/base_velocity/error_vel_yaw: 1.3889
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 1.10s
                        Total time: 1349.89s
                               ETA: 1917.1s

################################################################################
                     [1m Learning iteration 1240/3000 [0m                     

                       Computation: 89404 steps/s (collection: 0.975s, learning 0.125s)
               Value function loss: 0.6112
                    Surrogate loss: -0.0052
             Mean action noise std: 0.9057
                     Learning rate: 0.0004
                       Mean reward: 120.99
               Mean episode length: 975.08
       Episode_Reward/keep_balance: 0.9795
     Episode_Reward/rew_lin_vel_xy: 5.9285
      Episode_Reward/rew_ang_vel_z: 2.4041
    Episode_Reward/pen_base_height: -0.3123
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.1908
   Episode_Reward/pen_joint_torque: -0.2357
    Episode_Reward/pen_joint_accel: -0.1161
    Episode_Reward/pen_action_rate: -0.1260
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0945
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2690
Episode_Reward/pen_flat_orientation: -0.1242
  Episode_Reward/pen_feet_distance: -0.0243
Episode_Reward/pen_feet_regulation: -0.4722
   Episode_Reward/foot_landing_vel: -0.1392
   Episode_Reward/test_gait_reward: -0.9562
Metrics/base_velocity/error_vel_xy: 1.0542
Metrics/base_velocity/error_vel_yaw: 1.3826
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 1.10s
                        Total time: 1350.99s
                               ETA: 1916.0s

################################################################################
                     [1m Learning iteration 1241/3000 [0m                     

                       Computation: 88730 steps/s (collection: 0.984s, learning 0.123s)
               Value function loss: 0.6373
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9042
                     Learning rate: 0.0006
                       Mean reward: 118.77
               Mean episode length: 962.87
       Episode_Reward/keep_balance: 0.9660
     Episode_Reward/rew_lin_vel_xy: 5.8148
      Episode_Reward/rew_ang_vel_z: 2.3227
    Episode_Reward/pen_base_height: -0.2980
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.1877
   Episode_Reward/pen_joint_torque: -0.2324
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1251
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0605
   Episode_Reward/pen_joint_powers: -0.0936
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2675
Episode_Reward/pen_flat_orientation: -0.1163
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4610
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9460
Metrics/base_velocity/error_vel_xy: 1.0578
Metrics/base_velocity/error_vel_yaw: 1.4014
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 1.11s
                        Total time: 1352.10s
                               ETA: 1914.9s

################################################################################
                     [1m Learning iteration 1242/3000 [0m                     

                       Computation: 90542 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.7392
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9052
                     Learning rate: 0.0006
                       Mean reward: 119.69
               Mean episode length: 962.69
       Episode_Reward/keep_balance: 0.9517
     Episode_Reward/rew_lin_vel_xy: 5.7371
      Episode_Reward/rew_ang_vel_z: 2.2991
    Episode_Reward/pen_base_height: -0.2864
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.1881
   Episode_Reward/pen_joint_torque: -0.2263
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1231
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2623
Episode_Reward/pen_flat_orientation: -0.1187
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4568
   Episode_Reward/foot_landing_vel: -0.1318
   Episode_Reward/test_gait_reward: -0.9303
Metrics/base_velocity/error_vel_xy: 1.0429
Metrics/base_velocity/error_vel_yaw: 1.3664
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 1.09s
                        Total time: 1353.18s
                               ETA: 1913.8s

################################################################################
                     [1m Learning iteration 1243/3000 [0m                     

                       Computation: 90111 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.6078
                    Surrogate loss: -0.0021
             Mean action noise std: 0.9053
                     Learning rate: 0.0003
                       Mean reward: 116.18
               Mean episode length: 943.67
       Episode_Reward/keep_balance: 0.9441
     Episode_Reward/rew_lin_vel_xy: 5.6787
      Episode_Reward/rew_ang_vel_z: 2.2746
    Episode_Reward/pen_base_height: -0.2898
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1858
   Episode_Reward/pen_joint_torque: -0.2156
    Episode_Reward/pen_joint_accel: -0.1205
    Episode_Reward/pen_action_rate: -0.1215
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2633
Episode_Reward/pen_flat_orientation: -0.1199
  Episode_Reward/pen_feet_distance: -0.0163
Episode_Reward/pen_feet_regulation: -0.4481
   Episode_Reward/foot_landing_vel: -0.1319
   Episode_Reward/test_gait_reward: -0.9200
Metrics/base_velocity/error_vel_xy: 1.0296
Metrics/base_velocity/error_vel_yaw: 1.3649
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 1.09s
                        Total time: 1354.27s
                               ETA: 1912.7s

################################################################################
                     [1m Learning iteration 1244/3000 [0m                     

                       Computation: 90227 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.7221
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9050
                     Learning rate: 0.0006
                       Mean reward: 125.94
               Mean episode length: 999.38
       Episode_Reward/keep_balance: 0.9992
     Episode_Reward/rew_lin_vel_xy: 6.0192
      Episode_Reward/rew_ang_vel_z: 2.3883
    Episode_Reward/pen_base_height: -0.2993
      Episode_Reward/pen_lin_vel_z: -0.0423
     Episode_Reward/pen_ang_vel_xy: -0.1978
   Episode_Reward/pen_joint_torque: -0.2280
    Episode_Reward/pen_joint_accel: -0.1257
    Episode_Reward/pen_action_rate: -0.1292
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0619
   Episode_Reward/pen_joint_powers: -0.0939
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2806
Episode_Reward/pen_flat_orientation: -0.1114
  Episode_Reward/pen_feet_distance: -0.0165
Episode_Reward/pen_feet_regulation: -0.4869
   Episode_Reward/foot_landing_vel: -0.1448
   Episode_Reward/test_gait_reward: -0.9832
Metrics/base_velocity/error_vel_xy: 1.1067
Metrics/base_velocity/error_vel_yaw: 1.4645
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 1.09s
                        Total time: 1355.36s
                               ETA: 1911.7s

################################################################################
                     [1m Learning iteration 1245/3000 [0m                     

                       Computation: 90070 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.6004
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9071
                     Learning rate: 0.0006
                       Mean reward: 118.03
               Mean episode length: 966.27
       Episode_Reward/keep_balance: 0.9710
     Episode_Reward/rew_lin_vel_xy: 5.7752
      Episode_Reward/rew_ang_vel_z: 2.3053
    Episode_Reward/pen_base_height: -0.3156
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.1877
   Episode_Reward/pen_joint_torque: -0.2459
    Episode_Reward/pen_joint_accel: -0.1226
    Episode_Reward/pen_action_rate: -0.1282
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0632
   Episode_Reward/pen_joint_powers: -0.0975
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2726
Episode_Reward/pen_flat_orientation: -0.1233
  Episode_Reward/pen_feet_distance: -0.0159
Episode_Reward/pen_feet_regulation: -0.4989
   Episode_Reward/foot_landing_vel: -0.1429
   Episode_Reward/test_gait_reward: -0.9605
Metrics/base_velocity/error_vel_xy: 1.0991
Metrics/base_velocity/error_vel_yaw: 1.4299
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 1.09s
                        Total time: 1356.45s
                               ETA: 1910.6s

################################################################################
                     [1m Learning iteration 1246/3000 [0m                     

                       Computation: 89834 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.6135
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9091
                     Learning rate: 0.0004
                       Mean reward: 117.73
               Mean episode length: 979.48
       Episode_Reward/keep_balance: 0.9801
     Episode_Reward/rew_lin_vel_xy: 5.8261
      Episode_Reward/rew_ang_vel_z: 2.3555
    Episode_Reward/pen_base_height: -0.3124
      Episode_Reward/pen_lin_vel_z: -0.0430
     Episode_Reward/pen_ang_vel_xy: -0.1998
   Episode_Reward/pen_joint_torque: -0.2322
    Episode_Reward/pen_joint_accel: -0.1277
    Episode_Reward/pen_action_rate: -0.1285
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0642
   Episode_Reward/pen_joint_powers: -0.0969
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2767
Episode_Reward/pen_flat_orientation: -0.1226
  Episode_Reward/pen_feet_distance: -0.0216
Episode_Reward/pen_feet_regulation: -0.5105
   Episode_Reward/foot_landing_vel: -0.1534
   Episode_Reward/test_gait_reward: -0.9590
Metrics/base_velocity/error_vel_xy: 1.1153
Metrics/base_velocity/error_vel_yaw: 1.4243
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 1.09s
                        Total time: 1357.55s
                               ETA: 1909.5s

################################################################################
                     [1m Learning iteration 1247/3000 [0m                     

                       Computation: 89488 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.5616
                    Surrogate loss: -0.0056
             Mean action noise std: 0.9093
                     Learning rate: 0.0006
                       Mean reward: 120.43
               Mean episode length: 973.95
       Episode_Reward/keep_balance: 0.9803
     Episode_Reward/rew_lin_vel_xy: 5.8214
      Episode_Reward/rew_ang_vel_z: 2.3473
    Episode_Reward/pen_base_height: -0.2984
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1904
   Episode_Reward/pen_joint_torque: -0.2308
    Episode_Reward/pen_joint_accel: -0.1137
    Episode_Reward/pen_action_rate: -0.1262
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0597
   Episode_Reward/pen_joint_powers: -0.0923
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2734
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4757
   Episode_Reward/foot_landing_vel: -0.1346
   Episode_Reward/test_gait_reward: -0.9587
Metrics/base_velocity/error_vel_xy: 1.0955
Metrics/base_velocity/error_vel_yaw: 1.4215
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 1.10s
                        Total time: 1358.65s
                               ETA: 1908.4s

################################################################################
                     [1m Learning iteration 1248/3000 [0m                     

                       Computation: 88567 steps/s (collection: 0.984s, learning 0.126s)
               Value function loss: 0.6105
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9095
                     Learning rate: 0.0009
                       Mean reward: 121.23
               Mean episode length: 991.11
       Episode_Reward/keep_balance: 0.9919
     Episode_Reward/rew_lin_vel_xy: 5.9050
      Episode_Reward/rew_ang_vel_z: 2.3649
    Episode_Reward/pen_base_height: -0.3042
      Episode_Reward/pen_lin_vel_z: -0.0443
     Episode_Reward/pen_ang_vel_xy: -0.1970
   Episode_Reward/pen_joint_torque: -0.2379
    Episode_Reward/pen_joint_accel: -0.1254
    Episode_Reward/pen_action_rate: -0.1305
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0643
   Episode_Reward/pen_joint_powers: -0.0974
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2799
Episode_Reward/pen_flat_orientation: -0.1218
  Episode_Reward/pen_feet_distance: -0.0202
Episode_Reward/pen_feet_regulation: -0.5172
   Episode_Reward/foot_landing_vel: -0.1559
   Episode_Reward/test_gait_reward: -0.9792
Metrics/base_velocity/error_vel_xy: 1.1092
Metrics/base_velocity/error_vel_yaw: 1.4540
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 1.11s
                        Total time: 1359.76s
                               ETA: 1907.4s

################################################################################
                     [1m Learning iteration 1249/3000 [0m                     

                       Computation: 89384 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.6581
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9099
                     Learning rate: 0.0006
                       Mean reward: 121.78
               Mean episode length: 982.16
       Episode_Reward/keep_balance: 0.9833
     Episode_Reward/rew_lin_vel_xy: 5.8688
      Episode_Reward/rew_ang_vel_z: 2.3656
    Episode_Reward/pen_base_height: -0.3069
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.1931
   Episode_Reward/pen_joint_torque: -0.2269
    Episode_Reward/pen_joint_accel: -0.1143
    Episode_Reward/pen_action_rate: -0.1271
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0602
   Episode_Reward/pen_joint_powers: -0.0924
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2747
Episode_Reward/pen_flat_orientation: -0.1154
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4616
   Episode_Reward/foot_landing_vel: -0.1380
   Episode_Reward/test_gait_reward: -0.9519
Metrics/base_velocity/error_vel_xy: 1.0825
Metrics/base_velocity/error_vel_yaw: 1.4157
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 1.10s
                        Total time: 1360.86s
                               ETA: 1906.3s

################################################################################
                     [1m Learning iteration 1250/3000 [0m                     

                       Computation: 88420 steps/s (collection: 0.986s, learning 0.126s)
               Value function loss: 0.6030
                    Surrogate loss: -0.0038
             Mean action noise std: 0.9085
                     Learning rate: 0.0009
                       Mean reward: 125.82
               Mean episode length: 970.62
       Episode_Reward/keep_balance: 0.9668
     Episode_Reward/rew_lin_vel_xy: 5.9189
      Episode_Reward/rew_ang_vel_z: 2.3976
    Episode_Reward/pen_base_height: -0.2927
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1803
   Episode_Reward/pen_joint_torque: -0.2242
    Episode_Reward/pen_joint_accel: -0.1011
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2612
Episode_Reward/pen_flat_orientation: -0.1088
  Episode_Reward/pen_feet_distance: -0.0193
Episode_Reward/pen_feet_regulation: -0.4372
   Episode_Reward/foot_landing_vel: -0.1242
   Episode_Reward/test_gait_reward: -0.9311
Metrics/base_velocity/error_vel_xy: 1.0059
Metrics/base_velocity/error_vel_yaw: 1.3262
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 1.11s
                        Total time: 1361.97s
                               ETA: 1905.2s

################################################################################
                     [1m Learning iteration 1251/3000 [0m                     

                       Computation: 89413 steps/s (collection: 0.977s, learning 0.122s)
               Value function loss: 0.6657
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9083
                     Learning rate: 0.0006
                       Mean reward: 123.02
               Mean episode length: 973.88
       Episode_Reward/keep_balance: 0.9338
     Episode_Reward/rew_lin_vel_xy: 5.5543
      Episode_Reward/rew_ang_vel_z: 2.2299
    Episode_Reward/pen_base_height: -0.2930
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1851
   Episode_Reward/pen_joint_torque: -0.2194
    Episode_Reward/pen_joint_accel: -0.1141
    Episode_Reward/pen_action_rate: -0.1225
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2631
Episode_Reward/pen_flat_orientation: -0.1194
  Episode_Reward/pen_feet_distance: -0.0170
Episode_Reward/pen_feet_regulation: -0.4534
   Episode_Reward/foot_landing_vel: -0.1346
   Episode_Reward/test_gait_reward: -0.9087
Metrics/base_velocity/error_vel_xy: 1.0471
Metrics/base_velocity/error_vel_yaw: 1.3810
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 1.10s
                        Total time: 1363.07s
                               ETA: 1904.2s

################################################################################
                     [1m Learning iteration 1252/3000 [0m                     

                       Computation: 89349 steps/s (collection: 0.978s, learning 0.122s)
               Value function loss: 0.6106
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9070
                     Learning rate: 0.0006
                       Mean reward: 117.35
               Mean episode length: 948.50
       Episode_Reward/keep_balance: 0.9486
     Episode_Reward/rew_lin_vel_xy: 5.7611
      Episode_Reward/rew_ang_vel_z: 2.3079
    Episode_Reward/pen_base_height: -0.2896
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1898
   Episode_Reward/pen_joint_torque: -0.2284
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2671
Episode_Reward/pen_flat_orientation: -0.1127
  Episode_Reward/pen_feet_distance: -0.0184
Episode_Reward/pen_feet_regulation: -0.4587
   Episode_Reward/foot_landing_vel: -0.1361
   Episode_Reward/test_gait_reward: -0.9214
Metrics/base_velocity/error_vel_xy: 1.0191
Metrics/base_velocity/error_vel_yaw: 1.3507
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 1.10s
                        Total time: 1364.17s
                               ETA: 1903.1s

################################################################################
                     [1m Learning iteration 1253/3000 [0m                     

                       Computation: 90419 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.6331
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9054
                     Learning rate: 0.0003
                       Mean reward: 123.12
               Mean episode length: 982.81
       Episode_Reward/keep_balance: 0.9900
     Episode_Reward/rew_lin_vel_xy: 5.8788
      Episode_Reward/rew_ang_vel_z: 2.3784
    Episode_Reward/pen_base_height: -0.3038
      Episode_Reward/pen_lin_vel_z: -0.0399
     Episode_Reward/pen_ang_vel_xy: -0.1958
   Episode_Reward/pen_joint_torque: -0.2314
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.1272
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2756
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0208
Episode_Reward/pen_feet_regulation: -0.4531
   Episode_Reward/foot_landing_vel: -0.1286
   Episode_Reward/test_gait_reward: -0.9653
Metrics/base_velocity/error_vel_xy: 1.1169
Metrics/base_velocity/error_vel_yaw: 1.4305
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 1.09s
                        Total time: 1365.25s
                               ETA: 1902.0s

################################################################################
                     [1m Learning iteration 1254/3000 [0m                     

                       Computation: 89785 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 0.7004
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9054
                     Learning rate: 0.0004
                       Mean reward: 119.53
               Mean episode length: 974.49
       Episode_Reward/keep_balance: 0.9659
     Episode_Reward/rew_lin_vel_xy: 5.7594
      Episode_Reward/rew_ang_vel_z: 2.2989
    Episode_Reward/pen_base_height: -0.3067
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1957
   Episode_Reward/pen_joint_torque: -0.2251
    Episode_Reward/pen_joint_accel: -0.1136
    Episode_Reward/pen_action_rate: -0.1254
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0606
   Episode_Reward/pen_joint_powers: -0.0929
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2724
Episode_Reward/pen_flat_orientation: -0.1157
  Episode_Reward/pen_feet_distance: -0.0188
Episode_Reward/pen_feet_regulation: -0.4639
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.9377
Metrics/base_velocity/error_vel_xy: 1.0911
Metrics/base_velocity/error_vel_yaw: 1.4237
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 1.09s
                        Total time: 1366.35s
                               ETA: 1900.9s

################################################################################
                     [1m Learning iteration 1255/3000 [0m                     

                       Computation: 88519 steps/s (collection: 0.986s, learning 0.124s)
               Value function loss: 0.6088
                    Surrogate loss: -0.0050
             Mean action noise std: 0.9047
                     Learning rate: 0.0006
                       Mean reward: 118.93
               Mean episode length: 972.58
       Episode_Reward/keep_balance: 0.9804
     Episode_Reward/rew_lin_vel_xy: 5.8210
      Episode_Reward/rew_ang_vel_z: 2.3648
    Episode_Reward/pen_base_height: -0.3120
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1883
   Episode_Reward/pen_joint_torque: -0.2316
    Episode_Reward/pen_joint_accel: -0.1128
    Episode_Reward/pen_action_rate: -0.1256
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0598
   Episode_Reward/pen_joint_powers: -0.0924
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2715
Episode_Reward/pen_flat_orientation: -0.1192
  Episode_Reward/pen_feet_distance: -0.0224
Episode_Reward/pen_feet_regulation: -0.4840
   Episode_Reward/foot_landing_vel: -0.1373
   Episode_Reward/test_gait_reward: -0.9589
Metrics/base_velocity/error_vel_xy: 1.1173
Metrics/base_velocity/error_vel_yaw: 1.4070
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 1.11s
                        Total time: 1367.46s
                               ETA: 1899.9s

################################################################################
                     [1m Learning iteration 1256/3000 [0m                     

                       Computation: 89682 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 0.6337
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9047
                     Learning rate: 0.0003
                       Mean reward: 120.13
               Mean episode length: 966.40
       Episode_Reward/keep_balance: 0.9723
     Episode_Reward/rew_lin_vel_xy: 5.8625
      Episode_Reward/rew_ang_vel_z: 2.3701
    Episode_Reward/pen_base_height: -0.3069
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.1873
   Episode_Reward/pen_joint_torque: -0.2330
    Episode_Reward/pen_joint_accel: -0.1130
    Episode_Reward/pen_action_rate: -0.1235
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0586
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2674
Episode_Reward/pen_flat_orientation: -0.1143
  Episode_Reward/pen_feet_distance: -0.0206
Episode_Reward/pen_feet_regulation: -0.4587
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.9434
Metrics/base_velocity/error_vel_xy: 1.0511
Metrics/base_velocity/error_vel_yaw: 1.3695
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 1.10s
                        Total time: 1368.56s
                               ETA: 1898.8s

################################################################################
                     [1m Learning iteration 1257/3000 [0m                     

                       Computation: 88995 steps/s (collection: 0.982s, learning 0.123s)
               Value function loss: 0.6819
                    Surrogate loss: -0.0044
             Mean action noise std: 0.9045
                     Learning rate: 0.0004
                       Mean reward: 117.61
               Mean episode length: 946.65
       Episode_Reward/keep_balance: 0.9484
     Episode_Reward/rew_lin_vel_xy: 5.6692
      Episode_Reward/rew_ang_vel_z: 2.3149
    Episode_Reward/pen_base_height: -0.3099
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1803
   Episode_Reward/pen_joint_torque: -0.2308
    Episode_Reward/pen_joint_accel: -0.1112
    Episode_Reward/pen_action_rate: -0.1209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2604
Episode_Reward/pen_flat_orientation: -0.1090
  Episode_Reward/pen_feet_distance: -0.0170
Episode_Reward/pen_feet_regulation: -0.4505
   Episode_Reward/foot_landing_vel: -0.1340
   Episode_Reward/test_gait_reward: -0.9271
Metrics/base_velocity/error_vel_xy: 1.0557
Metrics/base_velocity/error_vel_yaw: 1.3335
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 1.10s
                        Total time: 1369.66s
                               ETA: 1897.7s

################################################################################
                     [1m Learning iteration 1258/3000 [0m                     

                       Computation: 90268 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.5536
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9029
                     Learning rate: 0.0006
                       Mean reward: 122.30
               Mean episode length: 984.45
       Episode_Reward/keep_balance: 0.9799
     Episode_Reward/rew_lin_vel_xy: 5.8925
      Episode_Reward/rew_ang_vel_z: 2.3811
    Episode_Reward/pen_base_height: -0.3086
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.1946
   Episode_Reward/pen_joint_torque: -0.2343
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1259
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0597
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2736
Episode_Reward/pen_flat_orientation: -0.1102
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4685
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9501
Metrics/base_velocity/error_vel_xy: 1.0758
Metrics/base_velocity/error_vel_yaw: 1.3896
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 1.09s
                        Total time: 1370.75s
                               ETA: 1896.6s

################################################################################
                     [1m Learning iteration 1259/3000 [0m                     

                       Computation: 91108 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.6221
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9011
                     Learning rate: 0.0006
                       Mean reward: 124.46
               Mean episode length: 998.93
       Episode_Reward/keep_balance: 0.9989
     Episode_Reward/rew_lin_vel_xy: 5.9827
      Episode_Reward/rew_ang_vel_z: 2.4092
    Episode_Reward/pen_base_height: -0.3065
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.1935
   Episode_Reward/pen_joint_torque: -0.2335
    Episode_Reward/pen_joint_accel: -0.1227
    Episode_Reward/pen_action_rate: -0.1276
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0931
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2777
Episode_Reward/pen_flat_orientation: -0.1101
  Episode_Reward/pen_feet_distance: -0.0203
Episode_Reward/pen_feet_regulation: -0.4709
   Episode_Reward/foot_landing_vel: -0.1471
   Episode_Reward/test_gait_reward: -0.9671
Metrics/base_velocity/error_vel_xy: 1.0917
Metrics/base_velocity/error_vel_yaw: 1.4186
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 1.08s
                        Total time: 1371.83s
                               ETA: 1895.5s

################################################################################
                     [1m Learning iteration 1260/3000 [0m                     

                       Computation: 89242 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.6342
                    Surrogate loss: -0.0044
             Mean action noise std: 0.9000
                     Learning rate: 0.0006
                       Mean reward: 120.87
               Mean episode length: 982.28
       Episode_Reward/keep_balance: 0.9881
     Episode_Reward/rew_lin_vel_xy: 5.8927
      Episode_Reward/rew_ang_vel_z: 2.3858
    Episode_Reward/pen_base_height: -0.3146
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.1854
   Episode_Reward/pen_joint_torque: -0.2413
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1267
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0607
   Episode_Reward/pen_joint_powers: -0.0956
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2708
Episode_Reward/pen_flat_orientation: -0.1131
  Episode_Reward/pen_feet_distance: -0.0200
Episode_Reward/pen_feet_regulation: -0.4851
   Episode_Reward/foot_landing_vel: -0.1406
   Episode_Reward/test_gait_reward: -0.9653
Metrics/base_velocity/error_vel_xy: 1.1220
Metrics/base_velocity/error_vel_yaw: 1.4197
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 1.10s
                        Total time: 1372.93s
                               ETA: 1894.4s

################################################################################
                     [1m Learning iteration 1261/3000 [0m                     

                       Computation: 89588 steps/s (collection: 0.972s, learning 0.125s)
               Value function loss: 0.6221
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8993
                     Learning rate: 0.0004
                       Mean reward: 123.59
               Mean episode length: 973.78
       Episode_Reward/keep_balance: 0.9756
     Episode_Reward/rew_lin_vel_xy: 5.8458
      Episode_Reward/rew_ang_vel_z: 2.3728
    Episode_Reward/pen_base_height: -0.3046
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1896
   Episode_Reward/pen_joint_torque: -0.2194
    Episode_Reward/pen_joint_accel: -0.1052
    Episode_Reward/pen_action_rate: -0.1237
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0897
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2684
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0211
Episode_Reward/pen_feet_regulation: -0.4684
   Episode_Reward/foot_landing_vel: -0.1367
   Episode_Reward/test_gait_reward: -0.9506
Metrics/base_velocity/error_vel_xy: 1.0729
Metrics/base_velocity/error_vel_yaw: 1.3830
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 1.10s
                        Total time: 1374.03s
                               ETA: 1893.4s

################################################################################
                     [1m Learning iteration 1262/3000 [0m                     

                       Computation: 90902 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.5721
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8984
                     Learning rate: 0.0004
                       Mean reward: 123.20
               Mean episode length: 979.36
       Episode_Reward/keep_balance: 0.9832
     Episode_Reward/rew_lin_vel_xy: 5.9864
      Episode_Reward/rew_ang_vel_z: 2.4318
    Episode_Reward/pen_base_height: -0.3091
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1802
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1059
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2650
Episode_Reward/pen_flat_orientation: -0.1103
  Episode_Reward/pen_feet_distance: -0.0205
Episode_Reward/pen_feet_regulation: -0.4408
   Episode_Reward/foot_landing_vel: -0.1246
   Episode_Reward/test_gait_reward: -0.9591
Metrics/base_velocity/error_vel_xy: 1.0416
Metrics/base_velocity/error_vel_yaw: 1.3468
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 1.08s
                        Total time: 1375.11s
                               ETA: 1892.3s

################################################################################
                     [1m Learning iteration 1263/3000 [0m                     

                       Computation: 91141 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.6375
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8976
                     Learning rate: 0.0006
                       Mean reward: 128.66
               Mean episode length: 991.82
       Episode_Reward/keep_balance: 0.9932
     Episode_Reward/rew_lin_vel_xy: 6.0807
      Episode_Reward/rew_ang_vel_z: 2.4530
    Episode_Reward/pen_base_height: -0.2973
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1831
   Episode_Reward/pen_joint_torque: -0.2312
    Episode_Reward/pen_joint_accel: -0.1089
    Episode_Reward/pen_action_rate: -0.1244
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2715
Episode_Reward/pen_flat_orientation: -0.1046
  Episode_Reward/pen_feet_distance: -0.0187
Episode_Reward/pen_feet_regulation: -0.4508
   Episode_Reward/foot_landing_vel: -0.1296
   Episode_Reward/test_gait_reward: -0.9683
Metrics/base_velocity/error_vel_xy: 1.0335
Metrics/base_velocity/error_vel_yaw: 1.3707
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 1.08s
                        Total time: 1376.19s
                               ETA: 1891.2s

################################################################################
                     [1m Learning iteration 1264/3000 [0m                     

                       Computation: 89985 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 0.6405
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8973
                     Learning rate: 0.0004
                       Mean reward: 119.06
               Mean episode length: 967.70
       Episode_Reward/keep_balance: 0.9690
     Episode_Reward/rew_lin_vel_xy: 5.8119
      Episode_Reward/rew_ang_vel_z: 2.3337
    Episode_Reward/pen_base_height: -0.2990
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.1886
   Episode_Reward/pen_joint_torque: -0.2326
    Episode_Reward/pen_joint_accel: -0.1100
    Episode_Reward/pen_action_rate: -0.1234
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0597
   Episode_Reward/pen_joint_powers: -0.0920
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2678
Episode_Reward/pen_flat_orientation: -0.1083
  Episode_Reward/pen_feet_distance: -0.0206
Episode_Reward/pen_feet_regulation: -0.4743
   Episode_Reward/foot_landing_vel: -0.1329
   Episode_Reward/test_gait_reward: -0.9469
Metrics/base_velocity/error_vel_xy: 1.0796
Metrics/base_velocity/error_vel_yaw: 1.3886
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 1.09s
                        Total time: 1377.28s
                               ETA: 1890.1s

################################################################################
                     [1m Learning iteration 1265/3000 [0m                     

                       Computation: 90109 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.6251
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8965
                     Learning rate: 0.0006
                       Mean reward: 122.56
               Mean episode length: 973.46
       Episode_Reward/keep_balance: 0.9818
     Episode_Reward/rew_lin_vel_xy: 5.9528
      Episode_Reward/rew_ang_vel_z: 2.3745
    Episode_Reward/pen_base_height: -0.2962
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1840
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1130
    Episode_Reward/pen_action_rate: -0.1237
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0586
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2688
Episode_Reward/pen_flat_orientation: -0.1103
  Episode_Reward/pen_feet_distance: -0.0218
Episode_Reward/pen_feet_regulation: -0.4598
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.9513
Metrics/base_velocity/error_vel_xy: 1.0383
Metrics/base_velocity/error_vel_yaw: 1.4009
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 1.09s
                        Total time: 1378.37s
                               ETA: 1889.0s

################################################################################
                     [1m Learning iteration 1266/3000 [0m                     

                       Computation: 90775 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.6200
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8962
                     Learning rate: 0.0004
                       Mean reward: 125.94
               Mean episode length: 988.26
       Episode_Reward/keep_balance: 0.9892
     Episode_Reward/rew_lin_vel_xy: 5.9433
      Episode_Reward/rew_ang_vel_z: 2.4272
    Episode_Reward/pen_base_height: -0.2967
      Episode_Reward/pen_lin_vel_z: -0.0414
     Episode_Reward/pen_ang_vel_xy: -0.1935
   Episode_Reward/pen_joint_torque: -0.2180
    Episode_Reward/pen_joint_accel: -0.1118
    Episode_Reward/pen_action_rate: -0.1241
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2745
Episode_Reward/pen_flat_orientation: -0.1085
  Episode_Reward/pen_feet_distance: -0.0176
Episode_Reward/pen_feet_regulation: -0.4629
   Episode_Reward/foot_landing_vel: -0.1325
   Episode_Reward/test_gait_reward: -0.9581
Metrics/base_velocity/error_vel_xy: 1.0737
Metrics/base_velocity/error_vel_yaw: 1.3789
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 1.08s
                        Total time: 1379.45s
                               ETA: 1887.9s

################################################################################
                     [1m Learning iteration 1267/3000 [0m                     

                       Computation: 90053 steps/s (collection: 0.966s, learning 0.126s)
               Value function loss: 0.6969
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8958
                     Learning rate: 0.0006
                       Mean reward: 119.45
               Mean episode length: 976.49
       Episode_Reward/keep_balance: 0.9699
     Episode_Reward/rew_lin_vel_xy: 5.7682
      Episode_Reward/rew_ang_vel_z: 2.3175
    Episode_Reward/pen_base_height: -0.3058
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1928
   Episode_Reward/pen_joint_torque: -0.2276
    Episode_Reward/pen_joint_accel: -0.1192
    Episode_Reward/pen_action_rate: -0.1258
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0616
   Episode_Reward/pen_joint_powers: -0.0930
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2733
Episode_Reward/pen_flat_orientation: -0.1197
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4870
   Episode_Reward/foot_landing_vel: -0.1367
   Episode_Reward/test_gait_reward: -0.9456
Metrics/base_velocity/error_vel_xy: 1.1056
Metrics/base_velocity/error_vel_yaw: 1.4232
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 1.09s
                        Total time: 1380.54s
                               ETA: 1886.8s

################################################################################
                     [1m Learning iteration 1268/3000 [0m                     

                       Computation: 90176 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.6207
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8953
                     Learning rate: 0.0006
                       Mean reward: 120.06
               Mean episode length: 959.78
       Episode_Reward/keep_balance: 0.9415
     Episode_Reward/rew_lin_vel_xy: 5.7229
      Episode_Reward/rew_ang_vel_z: 2.2874
    Episode_Reward/pen_base_height: -0.3019
      Episode_Reward/pen_lin_vel_z: -0.0406
     Episode_Reward/pen_ang_vel_xy: -0.1847
   Episode_Reward/pen_joint_torque: -0.2225
    Episode_Reward/pen_joint_accel: -0.1043
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0892
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2651
Episode_Reward/pen_flat_orientation: -0.1138
  Episode_Reward/pen_feet_distance: -0.0168
Episode_Reward/pen_feet_regulation: -0.4719
   Episode_Reward/foot_landing_vel: -0.1390
   Episode_Reward/test_gait_reward: -0.9178
Metrics/base_velocity/error_vel_xy: 1.0295
Metrics/base_velocity/error_vel_yaw: 1.3352
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 1.09s
                        Total time: 1381.63s
                               ETA: 1885.7s

################################################################################
                     [1m Learning iteration 1269/3000 [0m                     

                       Computation: 90379 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.6355
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8945
                     Learning rate: 0.0006
                       Mean reward: 124.27
               Mean episode length: 992.16
       Episode_Reward/keep_balance: 0.9942
     Episode_Reward/rew_lin_vel_xy: 6.0232
      Episode_Reward/rew_ang_vel_z: 2.4180
    Episode_Reward/pen_base_height: -0.3165
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1929
   Episode_Reward/pen_joint_torque: -0.2361
    Episode_Reward/pen_joint_accel: -0.1152
    Episode_Reward/pen_action_rate: -0.1263
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0609
   Episode_Reward/pen_joint_powers: -0.0936
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2752
Episode_Reward/pen_flat_orientation: -0.1101
  Episode_Reward/pen_feet_distance: -0.0235
Episode_Reward/pen_feet_regulation: -0.4877
   Episode_Reward/foot_landing_vel: -0.1441
   Episode_Reward/test_gait_reward: -0.9729
Metrics/base_velocity/error_vel_xy: 1.0693
Metrics/base_velocity/error_vel_yaw: 1.3992
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 1.09s
                        Total time: 1382.72s
                               ETA: 1884.6s

################################################################################
                     [1m Learning iteration 1270/3000 [0m                     

                       Computation: 88496 steps/s (collection: 0.989s, learning 0.122s)
               Value function loss: 0.6677
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8951
                     Learning rate: 0.0009
                       Mean reward: 122.87
               Mean episode length: 979.08
       Episode_Reward/keep_balance: 0.9835
     Episode_Reward/rew_lin_vel_xy: 5.9481
      Episode_Reward/rew_ang_vel_z: 2.4231
    Episode_Reward/pen_base_height: -0.3035
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1891
   Episode_Reward/pen_joint_torque: -0.2298
    Episode_Reward/pen_joint_accel: -0.1173
    Episode_Reward/pen_action_rate: -0.1229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2687
Episode_Reward/pen_flat_orientation: -0.1086
  Episode_Reward/pen_feet_distance: -0.0232
Episode_Reward/pen_feet_regulation: -0.4673
   Episode_Reward/foot_landing_vel: -0.1401
   Episode_Reward/test_gait_reward: -0.9501
Metrics/base_velocity/error_vel_xy: 1.0478
Metrics/base_velocity/error_vel_yaw: 1.3602
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 1.11s
                        Total time: 1383.83s
                               ETA: 1883.6s

################################################################################
                     [1m Learning iteration 1271/3000 [0m                     

                       Computation: 91185 steps/s (collection: 0.952s, learning 0.126s)
               Value function loss: 0.6789
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8952
                     Learning rate: 0.0004
                       Mean reward: 126.65
               Mean episode length: 981.71
       Episode_Reward/keep_balance: 0.9833
     Episode_Reward/rew_lin_vel_xy: 5.9649
      Episode_Reward/rew_ang_vel_z: 2.4416
    Episode_Reward/pen_base_height: -0.2972
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.1801
   Episode_Reward/pen_joint_torque: -0.2331
    Episode_Reward/pen_joint_accel: -0.1237
    Episode_Reward/pen_action_rate: -0.1236
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2693
Episode_Reward/pen_flat_orientation: -0.1072
  Episode_Reward/pen_feet_distance: -0.0201
Episode_Reward/pen_feet_regulation: -0.4693
   Episode_Reward/foot_landing_vel: -0.1427
   Episode_Reward/test_gait_reward: -0.9556
Metrics/base_velocity/error_vel_xy: 1.0466
Metrics/base_velocity/error_vel_yaw: 1.3344
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 1.08s
                        Total time: 1384.91s
                               ETA: 1882.5s

################################################################################
                     [1m Learning iteration 1272/3000 [0m                     

                       Computation: 90444 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.5644
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8950
                     Learning rate: 0.0004
                       Mean reward: 124.07
               Mean episode length: 977.21
       Episode_Reward/keep_balance: 0.9751
     Episode_Reward/rew_lin_vel_xy: 5.8929
      Episode_Reward/rew_ang_vel_z: 2.3921
    Episode_Reward/pen_base_height: -0.3083
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1773
   Episode_Reward/pen_joint_torque: -0.2249
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2639
Episode_Reward/pen_flat_orientation: -0.1058
  Episode_Reward/pen_feet_distance: -0.0230
Episode_Reward/pen_feet_regulation: -0.4576
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.9453
Metrics/base_velocity/error_vel_xy: 1.0544
Metrics/base_velocity/error_vel_yaw: 1.3556
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 1.09s
                        Total time: 1386.00s
                               ETA: 1881.4s

################################################################################
                     [1m Learning iteration 1273/3000 [0m                     

                       Computation: 82940 steps/s (collection: 1.052s, learning 0.133s)
               Value function loss: 0.6086
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8949
                     Learning rate: 0.0003
                       Mean reward: 120.92
               Mean episode length: 966.70
       Episode_Reward/keep_balance: 0.9764
     Episode_Reward/rew_lin_vel_xy: 5.9024
      Episode_Reward/rew_ang_vel_z: 2.3666
    Episode_Reward/pen_base_height: -0.3232
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1881
   Episode_Reward/pen_joint_torque: -0.2300
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1244
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0917
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2717
Episode_Reward/pen_flat_orientation: -0.1095
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4780
   Episode_Reward/foot_landing_vel: -0.1342
   Episode_Reward/test_gait_reward: -0.9629
Metrics/base_velocity/error_vel_xy: 1.0592
Metrics/base_velocity/error_vel_yaw: 1.3882
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 1.19s
                        Total time: 1387.18s
                               ETA: 1880.4s

################################################################################
                     [1m Learning iteration 1274/3000 [0m                     

                       Computation: 85854 steps/s (collection: 1.017s, learning 0.128s)
               Value function loss: 0.6116
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8957
                     Learning rate: 0.0006
                       Mean reward: 117.33
               Mean episode length: 962.15
       Episode_Reward/keep_balance: 0.9567
     Episode_Reward/rew_lin_vel_xy: 5.7201
      Episode_Reward/rew_ang_vel_z: 2.3008
    Episode_Reward/pen_base_height: -0.3317
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1832
   Episode_Reward/pen_joint_torque: -0.2388
    Episode_Reward/pen_joint_accel: -0.1068
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0924
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2611
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0218
Episode_Reward/pen_feet_regulation: -0.4728
   Episode_Reward/foot_landing_vel: -0.1301
   Episode_Reward/test_gait_reward: -0.9488
Metrics/base_velocity/error_vel_xy: 1.0857
Metrics/base_velocity/error_vel_yaw: 1.3676
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 1.15s
                        Total time: 1388.33s
                               ETA: 1879.4s

################################################################################
                     [1m Learning iteration 1275/3000 [0m                     

                       Computation: 85930 steps/s (collection: 1.018s, learning 0.126s)
               Value function loss: 0.6185
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8976
                     Learning rate: 0.0006
                       Mean reward: 124.78
               Mean episode length: 982.26
       Episode_Reward/keep_balance: 0.9846
     Episode_Reward/rew_lin_vel_xy: 5.9551
      Episode_Reward/rew_ang_vel_z: 2.3940
    Episode_Reward/pen_base_height: -0.3232
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1932
   Episode_Reward/pen_joint_torque: -0.2370
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1255
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0591
   Episode_Reward/pen_joint_powers: -0.0924
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2723
Episode_Reward/pen_flat_orientation: -0.1112
  Episode_Reward/pen_feet_distance: -0.0215
Episode_Reward/pen_feet_regulation: -0.4828
   Episode_Reward/foot_landing_vel: -0.1324
   Episode_Reward/test_gait_reward: -0.9578
Metrics/base_velocity/error_vel_xy: 1.0929
Metrics/base_velocity/error_vel_yaw: 1.3933
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 1.14s
                        Total time: 1389.47s
                               ETA: 1878.4s

################################################################################
                     [1m Learning iteration 1276/3000 [0m                     

                       Computation: 84950 steps/s (collection: 1.026s, learning 0.131s)
               Value function loss: 0.6580
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8978
                     Learning rate: 0.0003
                       Mean reward: 122.44
               Mean episode length: 990.53
       Episode_Reward/keep_balance: 0.9894
     Episode_Reward/rew_lin_vel_xy: 5.9182
      Episode_Reward/rew_ang_vel_z: 2.3918
    Episode_Reward/pen_base_height: -0.3234
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1864
   Episode_Reward/pen_joint_torque: -0.2410
    Episode_Reward/pen_joint_accel: -0.1208
    Episode_Reward/pen_action_rate: -0.1272
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0949
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2741
Episode_Reward/pen_flat_orientation: -0.1091
  Episode_Reward/pen_feet_distance: -0.0232
Episode_Reward/pen_feet_regulation: -0.4816
   Episode_Reward/foot_landing_vel: -0.1319
   Episode_Reward/test_gait_reward: -0.9797
Metrics/base_velocity/error_vel_xy: 1.1033
Metrics/base_velocity/error_vel_yaw: 1.4174
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 1.16s
                        Total time: 1390.63s
                               ETA: 1877.4s

################################################################################
                     [1m Learning iteration 1277/3000 [0m                     

                       Computation: 87409 steps/s (collection: 0.999s, learning 0.125s)
               Value function loss: 0.6361
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8992
                     Learning rate: 0.0006
                       Mean reward: 120.97
               Mean episode length: 974.12
       Episode_Reward/keep_balance: 0.9790
     Episode_Reward/rew_lin_vel_xy: 5.8607
      Episode_Reward/rew_ang_vel_z: 2.3835
    Episode_Reward/pen_base_height: -0.3264
      Episode_Reward/pen_lin_vel_z: -0.0415
     Episode_Reward/pen_ang_vel_xy: -0.1915
   Episode_Reward/pen_joint_torque: -0.2239
    Episode_Reward/pen_joint_accel: -0.1158
    Episode_Reward/pen_action_rate: -0.1243
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2722
Episode_Reward/pen_flat_orientation: -0.1067
  Episode_Reward/pen_feet_distance: -0.0214
Episode_Reward/pen_feet_regulation: -0.4916
   Episode_Reward/foot_landing_vel: -0.1435
   Episode_Reward/test_gait_reward: -0.9611
Metrics/base_velocity/error_vel_xy: 1.0878
Metrics/base_velocity/error_vel_yaw: 1.3770
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 1.12s
                        Total time: 1391.75s
                               ETA: 1876.4s

################################################################################
                     [1m Learning iteration 1278/3000 [0m                     

                       Computation: 87890 steps/s (collection: 0.995s, learning 0.123s)
               Value function loss: 0.6823
                    Surrogate loss: -0.0022
             Mean action noise std: 0.9000
                     Learning rate: 0.0004
                       Mean reward: 121.40
               Mean episode length: 968.33
       Episode_Reward/keep_balance: 0.9732
     Episode_Reward/rew_lin_vel_xy: 5.9113
      Episode_Reward/rew_ang_vel_z: 2.3970
    Episode_Reward/pen_base_height: -0.3267
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1861
   Episode_Reward/pen_joint_torque: -0.2320
    Episode_Reward/pen_joint_accel: -0.1084
    Episode_Reward/pen_action_rate: -0.1233
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2654
Episode_Reward/pen_flat_orientation: -0.1096
  Episode_Reward/pen_feet_distance: -0.0235
Episode_Reward/pen_feet_regulation: -0.4691
   Episode_Reward/foot_landing_vel: -0.1257
   Episode_Reward/test_gait_reward: -0.9489
Metrics/base_velocity/error_vel_xy: 1.0461
Metrics/base_velocity/error_vel_yaw: 1.3542
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 1.12s
                        Total time: 1392.87s
                               ETA: 1875.3s

################################################################################
                     [1m Learning iteration 1279/3000 [0m                     

                       Computation: 84186 steps/s (collection: 1.036s, learning 0.132s)
               Value function loss: 0.6836
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8979
                     Learning rate: 0.0009
                       Mean reward: 124.42
               Mean episode length: 974.30
       Episode_Reward/keep_balance: 0.9633
     Episode_Reward/rew_lin_vel_xy: 5.8836
      Episode_Reward/rew_ang_vel_z: 2.3860
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1896
   Episode_Reward/pen_joint_torque: -0.2250
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2657
Episode_Reward/pen_flat_orientation: -0.1101
  Episode_Reward/pen_feet_distance: -0.0179
Episode_Reward/pen_feet_regulation: -0.4530
   Episode_Reward/foot_landing_vel: -0.1337
   Episode_Reward/test_gait_reward: -0.9390
Metrics/base_velocity/error_vel_xy: 1.0100
Metrics/base_velocity/error_vel_yaw: 1.3305
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 1.17s
                        Total time: 1394.04s
                               ETA: 1874.3s

################################################################################
                     [1m Learning iteration 1280/3000 [0m                     

                       Computation: 83475 steps/s (collection: 1.046s, learning 0.132s)
               Value function loss: 0.7021
                    Surrogate loss: 0.0002
             Mean action noise std: 0.8984
                     Learning rate: 0.0003
                       Mean reward: 122.40
               Mean episode length: 974.80
       Episode_Reward/keep_balance: 0.9804
     Episode_Reward/rew_lin_vel_xy: 5.9771
      Episode_Reward/rew_ang_vel_z: 2.4260
    Episode_Reward/pen_base_height: -0.3078
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1853
   Episode_Reward/pen_joint_torque: -0.2368
    Episode_Reward/pen_joint_accel: -0.1083
    Episode_Reward/pen_action_rate: -0.1238
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2691
Episode_Reward/pen_flat_orientation: -0.1054
  Episode_Reward/pen_feet_distance: -0.0246
Episode_Reward/pen_feet_regulation: -0.4754
   Episode_Reward/foot_landing_vel: -0.1406
   Episode_Reward/test_gait_reward: -0.9616
Metrics/base_velocity/error_vel_xy: 1.0378
Metrics/base_velocity/error_vel_yaw: 1.3419
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 1.18s
                        Total time: 1395.22s
                               ETA: 1873.4s

################################################################################
                     [1m Learning iteration 1281/3000 [0m                     

                       Computation: 90447 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.6407
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8994
                     Learning rate: 0.0006
                       Mean reward: 122.98
               Mean episode length: 969.77
       Episode_Reward/keep_balance: 0.9602
     Episode_Reward/rew_lin_vel_xy: 5.7714
      Episode_Reward/rew_ang_vel_z: 2.3533
    Episode_Reward/pen_base_height: -0.3177
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1809
   Episode_Reward/pen_joint_torque: -0.2302
    Episode_Reward/pen_joint_accel: -0.1087
    Episode_Reward/pen_action_rate: -0.1211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0911
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2639
Episode_Reward/pen_flat_orientation: -0.1082
  Episode_Reward/pen_feet_distance: -0.0198
Episode_Reward/pen_feet_regulation: -0.4713
   Episode_Reward/foot_landing_vel: -0.1319
   Episode_Reward/test_gait_reward: -0.9348
Metrics/base_velocity/error_vel_xy: 1.0615
Metrics/base_velocity/error_vel_yaw: 1.3492
      Episode_Termination/time_out: 4.9167
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 1.09s
                        Total time: 1396.31s
                               ETA: 1872.3s

################################################################################
                     [1m Learning iteration 1282/3000 [0m                     

                       Computation: 89862 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 0.7365
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8989
                     Learning rate: 0.0009
                       Mean reward: 124.02
               Mean episode length: 974.36
       Episode_Reward/keep_balance: 0.9653
     Episode_Reward/rew_lin_vel_xy: 5.8670
      Episode_Reward/rew_ang_vel_z: 2.4146
    Episode_Reward/pen_base_height: -0.3171
      Episode_Reward/pen_lin_vel_z: -0.0399
     Episode_Reward/pen_ang_vel_xy: -0.1807
   Episode_Reward/pen_joint_torque: -0.2310
    Episode_Reward/pen_joint_accel: -0.1102
    Episode_Reward/pen_action_rate: -0.1209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0892
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2622
Episode_Reward/pen_flat_orientation: -0.1087
  Episode_Reward/pen_feet_distance: -0.0242
Episode_Reward/pen_feet_regulation: -0.4612
   Episode_Reward/foot_landing_vel: -0.1385
   Episode_Reward/test_gait_reward: -0.9373
Metrics/base_velocity/error_vel_xy: 1.0293
Metrics/base_velocity/error_vel_yaw: 1.3049
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 1.09s
                        Total time: 1397.40s
                               ETA: 1871.2s

################################################################################
                     [1m Learning iteration 1283/3000 [0m                     

                       Computation: 89193 steps/s (collection: 0.981s, learning 0.121s)
               Value function loss: 0.6466
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8987
                     Learning rate: 0.0006
                       Mean reward: 116.07
               Mean episode length: 912.87
       Episode_Reward/keep_balance: 0.9068
     Episode_Reward/rew_lin_vel_xy: 5.5282
      Episode_Reward/rew_ang_vel_z: 2.2299
    Episode_Reward/pen_base_height: -0.3007
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.1676
   Episode_Reward/pen_joint_torque: -0.2159
    Episode_Reward/pen_joint_accel: -0.1079
    Episode_Reward/pen_action_rate: -0.1138
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0853
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2463
Episode_Reward/pen_flat_orientation: -0.1135
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4391
   Episode_Reward/foot_landing_vel: -0.1263
   Episode_Reward/test_gait_reward: -0.8895
Metrics/base_velocity/error_vel_xy: 0.9664
Metrics/base_velocity/error_vel_yaw: 1.2763
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 1.10s
                        Total time: 1398.50s
                               ETA: 1870.1s

################################################################################
                     [1m Learning iteration 1284/3000 [0m                     

                       Computation: 89924 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 0.6182
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8967
                     Learning rate: 0.0009
                       Mean reward: 119.69
               Mean episode length: 955.48
       Episode_Reward/keep_balance: 0.9633
     Episode_Reward/rew_lin_vel_xy: 5.7677
      Episode_Reward/rew_ang_vel_z: 2.3695
    Episode_Reward/pen_base_height: -0.3149
      Episode_Reward/pen_lin_vel_z: -0.0389
     Episode_Reward/pen_ang_vel_xy: -0.1832
   Episode_Reward/pen_joint_torque: -0.2269
    Episode_Reward/pen_joint_accel: -0.1130
    Episode_Reward/pen_action_rate: -0.1224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2657
Episode_Reward/pen_flat_orientation: -0.1133
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4789
   Episode_Reward/foot_landing_vel: -0.1317
   Episode_Reward/test_gait_reward: -0.9364
Metrics/base_velocity/error_vel_xy: 1.0746
Metrics/base_velocity/error_vel_yaw: 1.3381
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 1.09s
                        Total time: 1399.59s
                               ETA: 1869.0s

################################################################################
                     [1m Learning iteration 1285/3000 [0m                     

                       Computation: 87149 steps/s (collection: 1.002s, learning 0.126s)
               Value function loss: 0.6526
                    Surrogate loss: -0.0012
             Mean action noise std: 0.8962
                     Learning rate: 0.0004
                       Mean reward: 119.53
               Mean episode length: 961.49
       Episode_Reward/keep_balance: 0.9694
     Episode_Reward/rew_lin_vel_xy: 5.7752
      Episode_Reward/rew_ang_vel_z: 2.3457
    Episode_Reward/pen_base_height: -0.3156
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1863
   Episode_Reward/pen_joint_torque: -0.2219
    Episode_Reward/pen_joint_accel: -0.1235
    Episode_Reward/pen_action_rate: -0.1228
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2691
Episode_Reward/pen_flat_orientation: -0.1071
  Episode_Reward/pen_feet_distance: -0.0206
Episode_Reward/pen_feet_regulation: -0.4718
   Episode_Reward/foot_landing_vel: -0.1337
   Episode_Reward/test_gait_reward: -0.9442
Metrics/base_velocity/error_vel_xy: 1.1048
Metrics/base_velocity/error_vel_yaw: 1.3911
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 1.13s
                        Total time: 1400.72s
                               ETA: 1868.0s

################################################################################
                     [1m Learning iteration 1286/3000 [0m                     

                       Computation: 87344 steps/s (collection: 1.002s, learning 0.123s)
               Value function loss: 0.6928
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8968
                     Learning rate: 0.0004
                       Mean reward: 121.98
               Mean episode length: 967.60
       Episode_Reward/keep_balance: 0.9600
     Episode_Reward/rew_lin_vel_xy: 5.8314
      Episode_Reward/rew_ang_vel_z: 2.3551
    Episode_Reward/pen_base_height: -0.3122
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1841
   Episode_Reward/pen_joint_torque: -0.2247
    Episode_Reward/pen_joint_accel: -0.1197
    Episode_Reward/pen_action_rate: -0.1224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2664
Episode_Reward/pen_flat_orientation: -0.1062
  Episode_Reward/pen_feet_distance: -0.0230
Episode_Reward/pen_feet_regulation: -0.4707
   Episode_Reward/foot_landing_vel: -0.1304
   Episode_Reward/test_gait_reward: -0.9400
Metrics/base_velocity/error_vel_xy: 1.0405
Metrics/base_velocity/error_vel_yaw: 1.3512
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 1.13s
                        Total time: 1401.85s
                               ETA: 1867.0s

################################################################################
                     [1m Learning iteration 1287/3000 [0m                     

                       Computation: 90928 steps/s (collection: 0.954s, learning 0.128s)
               Value function loss: 0.6721
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8969
                     Learning rate: 0.0006
                       Mean reward: 121.47
               Mean episode length: 957.94
       Episode_Reward/keep_balance: 0.9502
     Episode_Reward/rew_lin_vel_xy: 5.8029
      Episode_Reward/rew_ang_vel_z: 2.3152
    Episode_Reward/pen_base_height: -0.3074
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1779
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0882
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2590
Episode_Reward/pen_flat_orientation: -0.1072
  Episode_Reward/pen_feet_distance: -0.0193
Episode_Reward/pen_feet_regulation: -0.4488
   Episode_Reward/foot_landing_vel: -0.1324
   Episode_Reward/test_gait_reward: -0.9227
Metrics/base_velocity/error_vel_xy: 1.0113
Metrics/base_velocity/error_vel_yaw: 1.3447
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 1.08s
                        Total time: 1402.93s
                               ETA: 1865.9s

################################################################################
                     [1m Learning iteration 1288/3000 [0m                     

                       Computation: 88039 steps/s (collection: 0.992s, learning 0.125s)
               Value function loss: 0.6850
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8982
                     Learning rate: 0.0006
                       Mean reward: 119.29
               Mean episode length: 955.41
       Episode_Reward/keep_balance: 0.9537
     Episode_Reward/rew_lin_vel_xy: 5.6871
      Episode_Reward/rew_ang_vel_z: 2.3294
    Episode_Reward/pen_base_height: -0.3239
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.1840
   Episode_Reward/pen_joint_torque: -0.2315
    Episode_Reward/pen_joint_accel: -0.1125
    Episode_Reward/pen_action_rate: -0.1217
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0911
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2626
Episode_Reward/pen_flat_orientation: -0.1110
  Episode_Reward/pen_feet_distance: -0.0247
Episode_Reward/pen_feet_regulation: -0.4849
   Episode_Reward/foot_landing_vel: -0.1356
   Episode_Reward/test_gait_reward: -0.9347
Metrics/base_velocity/error_vel_xy: 1.0745
Metrics/base_velocity/error_vel_yaw: 1.3419
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 1.12s
                        Total time: 1404.05s
                               ETA: 1864.8s

################################################################################
                     [1m Learning iteration 1289/3000 [0m                     

                       Computation: 84842 steps/s (collection: 1.024s, learning 0.135s)
               Value function loss: 0.5790
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8980
                     Learning rate: 0.0004
                       Mean reward: 114.79
               Mean episode length: 908.61
       Episode_Reward/keep_balance: 0.8633
     Episode_Reward/rew_lin_vel_xy: 5.1958
      Episode_Reward/rew_ang_vel_z: 2.1198
    Episode_Reward/pen_base_height: -0.2773
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1705
   Episode_Reward/pen_joint_torque: -0.1960
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1083
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0516
   Episode_Reward/pen_joint_powers: -0.0791
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2382
Episode_Reward/pen_flat_orientation: -0.1092
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4263
   Episode_Reward/foot_landing_vel: -0.1188
   Episode_Reward/test_gait_reward: -0.8456
Metrics/base_velocity/error_vel_xy: 0.9538
Metrics/base_velocity/error_vel_yaw: 1.2003
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 1.16s
                        Total time: 1405.20s
                               ETA: 1863.8s

################################################################################
                     [1m Learning iteration 1290/3000 [0m                     

                       Computation: 85258 steps/s (collection: 1.028s, learning 0.125s)
               Value function loss: 0.6173
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8970
                     Learning rate: 0.0006
                       Mean reward: 126.65
               Mean episode length: 981.70
       Episode_Reward/keep_balance: 0.9852
     Episode_Reward/rew_lin_vel_xy: 5.9965
      Episode_Reward/rew_ang_vel_z: 2.4497
    Episode_Reward/pen_base_height: -0.3002
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1874
   Episode_Reward/pen_joint_torque: -0.2266
    Episode_Reward/pen_joint_accel: -0.1077
    Episode_Reward/pen_action_rate: -0.1233
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0908
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2701
Episode_Reward/pen_flat_orientation: -0.1034
  Episode_Reward/pen_feet_distance: -0.0267
Episode_Reward/pen_feet_regulation: -0.4668
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.9583
Metrics/base_velocity/error_vel_xy: 1.0455
Metrics/base_velocity/error_vel_yaw: 1.3342
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 1.15s
                        Total time: 1406.36s
                               ETA: 1862.8s

################################################################################
                     [1m Learning iteration 1291/3000 [0m                     

                       Computation: 87885 steps/s (collection: 0.990s, learning 0.128s)
               Value function loss: 0.6614
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8970
                     Learning rate: 0.0006
                       Mean reward: 123.59
               Mean episode length: 978.62
       Episode_Reward/keep_balance: 0.9788
     Episode_Reward/rew_lin_vel_xy: 5.9325
      Episode_Reward/rew_ang_vel_z: 2.3878
    Episode_Reward/pen_base_height: -0.3285
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1835
   Episode_Reward/pen_joint_torque: -0.2356
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1237
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0921
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2671
Episode_Reward/pen_flat_orientation: -0.1070
  Episode_Reward/pen_feet_distance: -0.0223
Episode_Reward/pen_feet_regulation: -0.4797
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.9591
Metrics/base_velocity/error_vel_xy: 1.0476
Metrics/base_velocity/error_vel_yaw: 1.3699
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 1.12s
                        Total time: 1407.48s
                               ETA: 1861.7s

################################################################################
                     [1m Learning iteration 1292/3000 [0m                     

                       Computation: 88461 steps/s (collection: 0.989s, learning 0.122s)
               Value function loss: 0.5519
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8971
                     Learning rate: 0.0004
                       Mean reward: 123.19
               Mean episode length: 960.59
       Episode_Reward/keep_balance: 0.9607
     Episode_Reward/rew_lin_vel_xy: 5.8230
      Episode_Reward/rew_ang_vel_z: 2.3772
    Episode_Reward/pen_base_height: -0.3082
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1753
   Episode_Reward/pen_joint_torque: -0.2180
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2607
Episode_Reward/pen_flat_orientation: -0.1082
  Episode_Reward/pen_feet_distance: -0.0190
Episode_Reward/pen_feet_regulation: -0.4673
   Episode_Reward/foot_landing_vel: -0.1273
   Episode_Reward/test_gait_reward: -0.9360
Metrics/base_velocity/error_vel_xy: 1.0411
Metrics/base_velocity/error_vel_yaw: 1.3185
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 1.11s
                        Total time: 1408.59s
                               ETA: 1860.7s

################################################################################
                     [1m Learning iteration 1293/3000 [0m                     

                       Computation: 90821 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.6417
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8971
                     Learning rate: 0.0006
                       Mean reward: 126.30
               Mean episode length: 985.35
       Episode_Reward/keep_balance: 0.9933
     Episode_Reward/rew_lin_vel_xy: 6.0142
      Episode_Reward/rew_ang_vel_z: 2.4103
    Episode_Reward/pen_base_height: -0.3253
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1949
   Episode_Reward/pen_joint_torque: -0.2351
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1268
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0603
   Episode_Reward/pen_joint_powers: -0.0920
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2768
Episode_Reward/pen_flat_orientation: -0.1103
  Episode_Reward/pen_feet_distance: -0.0169
Episode_Reward/pen_feet_regulation: -0.4831
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9666
Metrics/base_velocity/error_vel_xy: 1.0611
Metrics/base_velocity/error_vel_yaw: 1.4171
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 1.08s
                        Total time: 1409.67s
                               ETA: 1859.6s

################################################################################
                     [1m Learning iteration 1294/3000 [0m                     

                       Computation: 90670 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.6089
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8957
                     Learning rate: 0.0003
                       Mean reward: 122.45
               Mean episode length: 967.69
       Episode_Reward/keep_balance: 0.9788
     Episode_Reward/rew_lin_vel_xy: 5.9009
      Episode_Reward/rew_ang_vel_z: 2.4407
    Episode_Reward/pen_base_height: -0.3165
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.1829
   Episode_Reward/pen_joint_torque: -0.2339
    Episode_Reward/pen_joint_accel: -0.1227
    Episode_Reward/pen_action_rate: -0.1225
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0915
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2672
Episode_Reward/pen_flat_orientation: -0.1034
  Episode_Reward/pen_feet_distance: -0.0267
Episode_Reward/pen_feet_regulation: -0.4769
   Episode_Reward/foot_landing_vel: -0.1381
   Episode_Reward/test_gait_reward: -0.9551
Metrics/base_velocity/error_vel_xy: 1.0722
Metrics/base_velocity/error_vel_yaw: 1.3246
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 1.08s
                        Total time: 1410.75s
                               ETA: 1858.5s

################################################################################
                     [1m Learning iteration 1295/3000 [0m                     

                       Computation: 86158 steps/s (collection: 1.015s, learning 0.126s)
               Value function loss: 0.6706
                    Surrogate loss: -0.0056
             Mean action noise std: 0.8959
                     Learning rate: 0.0004
                       Mean reward: 125.71
               Mean episode length: 974.88
       Episode_Reward/keep_balance: 0.9789
     Episode_Reward/rew_lin_vel_xy: 5.8982
      Episode_Reward/rew_ang_vel_z: 2.3947
    Episode_Reward/pen_base_height: -0.3175
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1909
   Episode_Reward/pen_joint_torque: -0.2298
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.1224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2663
Episode_Reward/pen_flat_orientation: -0.1093
  Episode_Reward/pen_feet_distance: -0.0173
Episode_Reward/pen_feet_regulation: -0.4542
   Episode_Reward/foot_landing_vel: -0.1285
   Episode_Reward/test_gait_reward: -0.9537
Metrics/base_velocity/error_vel_xy: 1.0775
Metrics/base_velocity/error_vel_yaw: 1.3842
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 1.14s
                        Total time: 1411.89s
                               ETA: 1857.5s

################################################################################
                     [1m Learning iteration 1296/3000 [0m                     

                       Computation: 90810 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.6741
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8955
                     Learning rate: 0.0009
                       Mean reward: 118.84
               Mean episode length: 951.85
       Episode_Reward/keep_balance: 0.9490
     Episode_Reward/rew_lin_vel_xy: 5.7333
      Episode_Reward/rew_ang_vel_z: 2.2959
    Episode_Reward/pen_base_height: -0.3204
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1851
   Episode_Reward/pen_joint_torque: -0.2208
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0591
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2619
Episode_Reward/pen_flat_orientation: -0.1083
  Episode_Reward/pen_feet_distance: -0.0187
Episode_Reward/pen_feet_regulation: -0.4781
   Episode_Reward/foot_landing_vel: -0.1360
   Episode_Reward/test_gait_reward: -0.9319
Metrics/base_velocity/error_vel_xy: 1.0423
Metrics/base_velocity/error_vel_yaw: 1.3616
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 1.08s
                        Total time: 1412.98s
                               ETA: 1856.4s

################################################################################
                     [1m Learning iteration 1297/3000 [0m                     

                       Computation: 92026 steps/s (collection: 0.947s, learning 0.121s)
               Value function loss: 0.7299
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8955
                     Learning rate: 0.0004
                       Mean reward: 124.59
               Mean episode length: 965.96
       Episode_Reward/keep_balance: 0.9765
     Episode_Reward/rew_lin_vel_xy: 5.9879
      Episode_Reward/rew_ang_vel_z: 2.4317
    Episode_Reward/pen_base_height: -0.3104
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1843
   Episode_Reward/pen_joint_torque: -0.2326
    Episode_Reward/pen_joint_accel: -0.1110
    Episode_Reward/pen_action_rate: -0.1209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2639
Episode_Reward/pen_flat_orientation: -0.1067
  Episode_Reward/pen_feet_distance: -0.0163
Episode_Reward/pen_feet_regulation: -0.4667
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.9530
Metrics/base_velocity/error_vel_xy: 1.0147
Metrics/base_velocity/error_vel_yaw: 1.3232
      Episode_Termination/time_out: 4.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 1.07s
                        Total time: 1414.05s
                               ETA: 1855.3s

################################################################################
                     [1m Learning iteration 1298/3000 [0m                     

                       Computation: 88420 steps/s (collection: 0.989s, learning 0.123s)
               Value function loss: 0.5719
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8968
                     Learning rate: 0.0002
                       Mean reward: 123.08
               Mean episode length: 956.12
       Episode_Reward/keep_balance: 0.9361
     Episode_Reward/rew_lin_vel_xy: 5.7140
      Episode_Reward/rew_ang_vel_z: 2.3339
    Episode_Reward/pen_base_height: -0.3057
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1801
   Episode_Reward/pen_joint_torque: -0.2202
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0869
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2528
Episode_Reward/pen_flat_orientation: -0.1098
  Episode_Reward/pen_feet_distance: -0.0211
Episode_Reward/pen_feet_regulation: -0.4434
   Episode_Reward/foot_landing_vel: -0.1286
   Episode_Reward/test_gait_reward: -0.9073
Metrics/base_velocity/error_vel_xy: 0.9773
Metrics/base_velocity/error_vel_yaw: 1.2708
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 1.11s
                        Total time: 1415.16s
                               ETA: 1854.2s

################################################################################
                     [1m Learning iteration 1299/3000 [0m                     

                       Computation: 89786 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.6278
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8977
                     Learning rate: 0.0004
                       Mean reward: 124.60
               Mean episode length: 974.93
       Episode_Reward/keep_balance: 0.9752
     Episode_Reward/rew_lin_vel_xy: 5.9039
      Episode_Reward/rew_ang_vel_z: 2.4247
    Episode_Reward/pen_base_height: -0.3133
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1791
   Episode_Reward/pen_joint_torque: -0.2351
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.1201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2608
Episode_Reward/pen_flat_orientation: -0.1067
  Episode_Reward/pen_feet_distance: -0.0185
Episode_Reward/pen_feet_regulation: -0.4528
   Episode_Reward/foot_landing_vel: -0.1370
   Episode_Reward/test_gait_reward: -0.9460
Metrics/base_velocity/error_vel_xy: 1.0564
Metrics/base_velocity/error_vel_yaw: 1.3215
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 1.09s
                        Total time: 1416.25s
                               ETA: 1853.1s

################################################################################
                     [1m Learning iteration 1300/3000 [0m                     

                       Computation: 89504 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.5786
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8970
                     Learning rate: 0.0004
                       Mean reward: 125.48
               Mean episode length: 987.63
       Episode_Reward/keep_balance: 0.9893
     Episode_Reward/rew_lin_vel_xy: 5.9694
      Episode_Reward/rew_ang_vel_z: 2.3926
    Episode_Reward/pen_base_height: -0.3269
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1880
   Episode_Reward/pen_joint_torque: -0.2327
    Episode_Reward/pen_joint_accel: -0.1070
    Episode_Reward/pen_action_rate: -0.1245
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2685
Episode_Reward/pen_flat_orientation: -0.1093
  Episode_Reward/pen_feet_distance: -0.0191
Episode_Reward/pen_feet_regulation: -0.4842
   Episode_Reward/foot_landing_vel: -0.1399
   Episode_Reward/test_gait_reward: -0.9661
Metrics/base_velocity/error_vel_xy: 1.0917
Metrics/base_velocity/error_vel_yaw: 1.4160
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 1.10s
                        Total time: 1417.35s
                               ETA: 1852.0s

################################################################################
                     [1m Learning iteration 1301/3000 [0m                     

                       Computation: 86673 steps/s (collection: 0.977s, learning 0.157s)
               Value function loss: 0.5689
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8980
                     Learning rate: 0.0006
                       Mean reward: 121.97
               Mean episode length: 974.33
       Episode_Reward/keep_balance: 0.9685
     Episode_Reward/rew_lin_vel_xy: 5.8124
      Episode_Reward/rew_ang_vel_z: 2.3692
    Episode_Reward/pen_base_height: -0.3243
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1917
   Episode_Reward/pen_joint_torque: -0.2317
    Episode_Reward/pen_joint_accel: -0.1198
    Episode_Reward/pen_action_rate: -0.1222
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2647
Episode_Reward/pen_flat_orientation: -0.1114
  Episode_Reward/pen_feet_distance: -0.0246
Episode_Reward/pen_feet_regulation: -0.4830
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9426
Metrics/base_velocity/error_vel_xy: 1.0784
Metrics/base_velocity/error_vel_yaw: 1.3550
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 1.13s
                        Total time: 1418.48s
                               ETA: 1851.0s

################################################################################
                     [1m Learning iteration 1302/3000 [0m                     

                       Computation: 88864 steps/s (collection: 0.983s, learning 0.123s)
               Value function loss: 0.6431
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8963
                     Learning rate: 0.0006
                       Mean reward: 123.74
               Mean episode length: 972.36
       Episode_Reward/keep_balance: 0.9762
     Episode_Reward/rew_lin_vel_xy: 5.8987
      Episode_Reward/rew_ang_vel_z: 2.4258
    Episode_Reward/pen_base_height: -0.3118
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1809
   Episode_Reward/pen_joint_torque: -0.2322
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2640
Episode_Reward/pen_flat_orientation: -0.1043
  Episode_Reward/pen_feet_distance: -0.0229
Episode_Reward/pen_feet_regulation: -0.4704
   Episode_Reward/foot_landing_vel: -0.1331
   Episode_Reward/test_gait_reward: -0.9556
Metrics/base_velocity/error_vel_xy: 1.0361
Metrics/base_velocity/error_vel_yaw: 1.3268
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 1.11s
                        Total time: 1419.59s
                               ETA: 1849.9s

################################################################################
                     [1m Learning iteration 1303/3000 [0m                     

                       Computation: 90668 steps/s (collection: 0.959s, learning 0.126s)
               Value function loss: 0.6134
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8944
                     Learning rate: 0.0009
                       Mean reward: 121.59
               Mean episode length: 958.06
       Episode_Reward/keep_balance: 0.9390
     Episode_Reward/rew_lin_vel_xy: 5.6871
      Episode_Reward/rew_ang_vel_z: 2.2936
    Episode_Reward/pen_base_height: -0.3133
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1729
   Episode_Reward/pen_joint_torque: -0.2113
    Episode_Reward/pen_joint_accel: -0.0954
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0852
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2523
Episode_Reward/pen_flat_orientation: -0.1105
  Episode_Reward/pen_feet_distance: -0.0194
Episode_Reward/pen_feet_regulation: -0.4512
   Episode_Reward/foot_landing_vel: -0.1172
   Episode_Reward/test_gait_reward: -0.9099
Metrics/base_velocity/error_vel_xy: 1.0153
Metrics/base_velocity/error_vel_yaw: 1.3357
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 1.08s
                        Total time: 1420.67s
                               ETA: 1848.8s

################################################################################
                     [1m Learning iteration 1304/3000 [0m                     

                       Computation: 89970 steps/s (collection: 0.964s, learning 0.129s)
               Value function loss: 0.6319
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8955
                     Learning rate: 0.0006
                       Mean reward: 124.08
               Mean episode length: 981.68
       Episode_Reward/keep_balance: 0.9933
     Episode_Reward/rew_lin_vel_xy: 5.9933
      Episode_Reward/rew_ang_vel_z: 2.4477
    Episode_Reward/pen_base_height: -0.3161
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1843
   Episode_Reward/pen_joint_torque: -0.2354
    Episode_Reward/pen_joint_accel: -0.1181
    Episode_Reward/pen_action_rate: -0.1241
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0606
   Episode_Reward/pen_joint_powers: -0.0933
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2704
Episode_Reward/pen_flat_orientation: -0.1076
  Episode_Reward/pen_feet_distance: -0.0157
Episode_Reward/pen_feet_regulation: -0.4947
   Episode_Reward/foot_landing_vel: -0.1373
   Episode_Reward/test_gait_reward: -0.9740
Metrics/base_velocity/error_vel_xy: 1.0808
Metrics/base_velocity/error_vel_yaw: 1.3735
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 1.09s
                        Total time: 1421.77s
                               ETA: 1847.8s

################################################################################
                     [1m Learning iteration 1305/3000 [0m                     

                       Computation: 90002 steps/s (collection: 0.964s, learning 0.129s)
               Value function loss: 0.6328
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8955
                     Learning rate: 0.0004
                       Mean reward: 123.01
               Mean episode length: 960.71
       Episode_Reward/keep_balance: 0.9675
     Episode_Reward/rew_lin_vel_xy: 5.8861
      Episode_Reward/rew_ang_vel_z: 2.4042
    Episode_Reward/pen_base_height: -0.3055
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1818
   Episode_Reward/pen_joint_torque: -0.2259
    Episode_Reward/pen_joint_accel: -0.1095
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2608
Episode_Reward/pen_flat_orientation: -0.1077
  Episode_Reward/pen_feet_distance: -0.0192
Episode_Reward/pen_feet_regulation: -0.4626
   Episode_Reward/foot_landing_vel: -0.1294
   Episode_Reward/test_gait_reward: -0.9348
Metrics/base_velocity/error_vel_xy: 1.0353
Metrics/base_velocity/error_vel_yaw: 1.3289
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 1.09s
                        Total time: 1422.86s
                               ETA: 1846.7s

################################################################################
                     [1m Learning iteration 1306/3000 [0m                     

                       Computation: 88914 steps/s (collection: 0.982s, learning 0.124s)
               Value function loss: 0.5715
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8953
                     Learning rate: 0.0006
                       Mean reward: 120.61
               Mean episode length: 952.96
       Episode_Reward/keep_balance: 0.9686
     Episode_Reward/rew_lin_vel_xy: 5.8414
      Episode_Reward/rew_ang_vel_z: 2.3744
    Episode_Reward/pen_base_height: -0.3000
      Episode_Reward/pen_lin_vel_z: -0.0415
     Episode_Reward/pen_ang_vel_xy: -0.1830
   Episode_Reward/pen_joint_torque: -0.2253
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.1208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2635
Episode_Reward/pen_flat_orientation: -0.1092
  Episode_Reward/pen_feet_distance: -0.0178
Episode_Reward/pen_feet_regulation: -0.4949
   Episode_Reward/foot_landing_vel: -0.1363
   Episode_Reward/test_gait_reward: -0.9397
Metrics/base_velocity/error_vel_xy: 1.0545
Metrics/base_velocity/error_vel_yaw: 1.3481
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 1.11s
                        Total time: 1423.97s
                               ETA: 1845.6s

################################################################################
                     [1m Learning iteration 1307/3000 [0m                     

                       Computation: 89629 steps/s (collection: 0.972s, learning 0.125s)
               Value function loss: 0.6397
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8942
                     Learning rate: 0.0004
                       Mean reward: 121.07
               Mean episode length: 973.16
       Episode_Reward/keep_balance: 0.9726
     Episode_Reward/rew_lin_vel_xy: 5.8627
      Episode_Reward/rew_ang_vel_z: 2.3439
    Episode_Reward/pen_base_height: -0.3016
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1851
   Episode_Reward/pen_joint_torque: -0.2273
    Episode_Reward/pen_joint_accel: -0.1225
    Episode_Reward/pen_action_rate: -0.1229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0609
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2660
Episode_Reward/pen_flat_orientation: -0.1096
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4939
   Episode_Reward/foot_landing_vel: -0.1445
   Episode_Reward/test_gait_reward: -0.9454
Metrics/base_velocity/error_vel_xy: 1.0726
Metrics/base_velocity/error_vel_yaw: 1.3991
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 1.10s
                        Total time: 1425.06s
                               ETA: 1844.5s

################################################################################
                     [1m Learning iteration 1308/3000 [0m                     

                       Computation: 89145 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.5724
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8924
                     Learning rate: 0.0004
                       Mean reward: 125.04
               Mean episode length: 971.19
       Episode_Reward/keep_balance: 0.9466
     Episode_Reward/rew_lin_vel_xy: 5.7889
      Episode_Reward/rew_ang_vel_z: 2.3234
    Episode_Reward/pen_base_height: -0.2929
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1826
   Episode_Reward/pen_joint_torque: -0.2093
    Episode_Reward/pen_joint_accel: -0.1069
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2570
Episode_Reward/pen_flat_orientation: -0.1080
  Episode_Reward/pen_feet_distance: -0.0182
Episode_Reward/pen_feet_regulation: -0.4599
   Episode_Reward/foot_landing_vel: -0.1269
   Episode_Reward/test_gait_reward: -0.9192
Metrics/base_velocity/error_vel_xy: 0.9958
Metrics/base_velocity/error_vel_yaw: 1.3261
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 1.10s
                        Total time: 1426.16s
                               ETA: 1843.4s

################################################################################
                     [1m Learning iteration 1309/3000 [0m                     

                       Computation: 89945 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.7018
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8914
                     Learning rate: 0.0006
                       Mean reward: 128.68
               Mean episode length: 991.72
       Episode_Reward/keep_balance: 0.9822
     Episode_Reward/rew_lin_vel_xy: 6.0614
      Episode_Reward/rew_ang_vel_z: 2.4127
    Episode_Reward/pen_base_height: -0.3028
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1834
   Episode_Reward/pen_joint_torque: -0.2300
    Episode_Reward/pen_joint_accel: -0.1134
    Episode_Reward/pen_action_rate: -0.1213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2651
Episode_Reward/pen_flat_orientation: -0.1073
  Episode_Reward/pen_feet_distance: -0.0202
Episode_Reward/pen_feet_regulation: -0.4681
   Episode_Reward/foot_landing_vel: -0.1341
   Episode_Reward/test_gait_reward: -0.9526
Metrics/base_velocity/error_vel_xy: 1.0073
Metrics/base_velocity/error_vel_yaw: 1.3621
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 1.09s
                        Total time: 1427.26s
                               ETA: 1842.4s

################################################################################
                     [1m Learning iteration 1310/3000 [0m                     

                       Computation: 89356 steps/s (collection: 0.978s, learning 0.122s)
               Value function loss: 0.6169
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8908
                     Learning rate: 0.0006
                       Mean reward: 123.83
               Mean episode length: 962.86
       Episode_Reward/keep_balance: 0.9559
     Episode_Reward/rew_lin_vel_xy: 5.8647
      Episode_Reward/rew_ang_vel_z: 2.3841
    Episode_Reward/pen_base_height: -0.3006
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1833
   Episode_Reward/pen_joint_torque: -0.2282
    Episode_Reward/pen_joint_accel: -0.1082
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2575
Episode_Reward/pen_flat_orientation: -0.1069
  Episode_Reward/pen_feet_distance: -0.0182
Episode_Reward/pen_feet_regulation: -0.4768
   Episode_Reward/foot_landing_vel: -0.1445
   Episode_Reward/test_gait_reward: -0.9339
Metrics/base_velocity/error_vel_xy: 0.9913
Metrics/base_velocity/error_vel_yaw: 1.2902
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 1.10s
                        Total time: 1428.36s
                               ETA: 1841.3s

################################################################################
                     [1m Learning iteration 1311/3000 [0m                     

                       Computation: 89470 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.6199
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8898
                     Learning rate: 0.0009
                       Mean reward: 119.59
               Mean episode length: 946.82
       Episode_Reward/keep_balance: 0.9536
     Episode_Reward/rew_lin_vel_xy: 5.8051
      Episode_Reward/rew_ang_vel_z: 2.3250
    Episode_Reward/pen_base_height: -0.3121
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.1818
   Episode_Reward/pen_joint_torque: -0.2185
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.1180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2576
Episode_Reward/pen_flat_orientation: -0.1111
  Episode_Reward/pen_feet_distance: -0.0189
Episode_Reward/pen_feet_regulation: -0.4703
   Episode_Reward/foot_landing_vel: -0.1370
   Episode_Reward/test_gait_reward: -0.9186
Metrics/base_velocity/error_vel_xy: 1.0285
Metrics/base_velocity/error_vel_yaw: 1.3497
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 1.10s
                        Total time: 1429.46s
                               ETA: 1840.2s

################################################################################
                     [1m Learning iteration 1312/3000 [0m                     

                       Computation: 88414 steps/s (collection: 0.987s, learning 0.125s)
               Value function loss: 0.6698
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8893
                     Learning rate: 0.0006
                       Mean reward: 120.94
               Mean episode length: 958.63
       Episode_Reward/keep_balance: 0.9620
     Episode_Reward/rew_lin_vel_xy: 5.7726
      Episode_Reward/rew_ang_vel_z: 2.3656
    Episode_Reward/pen_base_height: -0.3242
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.1768
   Episode_Reward/pen_joint_torque: -0.2288
    Episode_Reward/pen_joint_accel: -0.1261
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0917
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2599
Episode_Reward/pen_flat_orientation: -0.1087
  Episode_Reward/pen_feet_distance: -0.0206
Episode_Reward/pen_feet_regulation: -0.4890
   Episode_Reward/foot_landing_vel: -0.1462
   Episode_Reward/test_gait_reward: -0.9358
Metrics/base_velocity/error_vel_xy: 1.0776
Metrics/base_velocity/error_vel_yaw: 1.3341
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 1.11s
                        Total time: 1430.57s
                               ETA: 1839.1s

################################################################################
                     [1m Learning iteration 1313/3000 [0m                     

                       Computation: 89643 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.6551
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8898
                     Learning rate: 0.0004
                       Mean reward: 119.45
               Mean episode length: 950.05
       Episode_Reward/keep_balance: 0.9716
     Episode_Reward/rew_lin_vel_xy: 5.8676
      Episode_Reward/rew_ang_vel_z: 2.3744
    Episode_Reward/pen_base_height: -0.3098
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1757
   Episode_Reward/pen_joint_torque: -0.2370
    Episode_Reward/pen_joint_accel: -0.1103
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0602
   Episode_Reward/pen_joint_powers: -0.0932
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2632
Episode_Reward/pen_flat_orientation: -0.1155
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4858
   Episode_Reward/foot_landing_vel: -0.1398
   Episode_Reward/test_gait_reward: -0.9462
Metrics/base_velocity/error_vel_xy: 1.0507
Metrics/base_velocity/error_vel_yaw: 1.3665
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 1.10s
                        Total time: 1431.67s
                               ETA: 1838.1s

################################################################################
                     [1m Learning iteration 1314/3000 [0m                     

                       Computation: 89697 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 0.6364
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8890
                     Learning rate: 0.0003
                       Mean reward: 115.50
               Mean episode length: 919.54
       Episode_Reward/keep_balance: 0.9212
     Episode_Reward/rew_lin_vel_xy: 5.5986
      Episode_Reward/rew_ang_vel_z: 2.2228
    Episode_Reward/pen_base_height: -0.3067
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1802
   Episode_Reward/pen_joint_torque: -0.2119
    Episode_Reward/pen_joint_accel: -0.1041
    Episode_Reward/pen_action_rate: -0.1157
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2520
Episode_Reward/pen_flat_orientation: -0.1195
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.4623
   Episode_Reward/foot_landing_vel: -0.1274
   Episode_Reward/test_gait_reward: -0.8889
Metrics/base_velocity/error_vel_xy: 0.9944
Metrics/base_velocity/error_vel_yaw: 1.3378
      Episode_Termination/time_out: 3.0833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 1.10s
                        Total time: 1432.76s
                               ETA: 1837.0s

################################################################################
                     [1m Learning iteration 1315/3000 [0m                     

                       Computation: 88688 steps/s (collection: 0.986s, learning 0.123s)
               Value function loss: 0.6691
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8902
                     Learning rate: 0.0006
                       Mean reward: 121.98
               Mean episode length: 974.95
       Episode_Reward/keep_balance: 0.9722
     Episode_Reward/rew_lin_vel_xy: 5.8542
      Episode_Reward/rew_ang_vel_z: 2.3748
    Episode_Reward/pen_base_height: -0.3204
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1795
   Episode_Reward/pen_joint_torque: -0.2346
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1215
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0921
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2619
Episode_Reward/pen_flat_orientation: -0.1152
  Episode_Reward/pen_feet_distance: -0.0191
Episode_Reward/pen_feet_regulation: -0.4741
   Episode_Reward/foot_landing_vel: -0.1398
   Episode_Reward/test_gait_reward: -0.9509
Metrics/base_velocity/error_vel_xy: 1.0779
Metrics/base_velocity/error_vel_yaw: 1.3682
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 1.11s
                        Total time: 1433.87s
                               ETA: 1835.9s

################################################################################
                     [1m Learning iteration 1316/3000 [0m                     

                       Computation: 89277 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.6457
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8920
                     Learning rate: 0.0009
                       Mean reward: 119.23
               Mean episode length: 945.40
       Episode_Reward/keep_balance: 0.9234
     Episode_Reward/rew_lin_vel_xy: 5.5965
      Episode_Reward/rew_ang_vel_z: 2.2789
    Episode_Reward/pen_base_height: -0.3211
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1758
   Episode_Reward/pen_joint_torque: -0.2276
    Episode_Reward/pen_joint_accel: -0.1059
    Episode_Reward/pen_action_rate: -0.1139
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2445
Episode_Reward/pen_flat_orientation: -0.1117
  Episode_Reward/pen_feet_distance: -0.0204
Episode_Reward/pen_feet_regulation: -0.4557
   Episode_Reward/foot_landing_vel: -0.1250
   Episode_Reward/test_gait_reward: -0.9004
Metrics/base_velocity/error_vel_xy: 1.0044
Metrics/base_velocity/error_vel_yaw: 1.2744
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 1.10s
                        Total time: 1434.97s
                               ETA: 1834.8s

################################################################################
                     [1m Learning iteration 1317/3000 [0m                     

                       Computation: 89286 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.6398
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8901
                     Learning rate: 0.0009
                       Mean reward: 126.19
               Mean episode length: 981.22
       Episode_Reward/keep_balance: 0.9838
     Episode_Reward/rew_lin_vel_xy: 6.0293
      Episode_Reward/rew_ang_vel_z: 2.4224
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1820
   Episode_Reward/pen_joint_torque: -0.2313
    Episode_Reward/pen_joint_accel: -0.1128
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0586
   Episode_Reward/pen_joint_powers: -0.0911
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2639
Episode_Reward/pen_flat_orientation: -0.1091
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4731
   Episode_Reward/foot_landing_vel: -0.1330
   Episode_Reward/test_gait_reward: -0.9551
Metrics/base_velocity/error_vel_xy: 1.0306
Metrics/base_velocity/error_vel_yaw: 1.3640
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 1.10s
                        Total time: 1436.07s
                               ETA: 1833.8s

################################################################################
                     [1m Learning iteration 1318/3000 [0m                     

                       Computation: 90108 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.5977
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8890
                     Learning rate: 0.0006
                       Mean reward: 122.54
               Mean episode length: 961.93
       Episode_Reward/keep_balance: 0.9727
     Episode_Reward/rew_lin_vel_xy: 5.9622
      Episode_Reward/rew_ang_vel_z: 2.4323
    Episode_Reward/pen_base_height: -0.3068
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1783
   Episode_Reward/pen_joint_torque: -0.2294
    Episode_Reward/pen_joint_accel: -0.1191
    Episode_Reward/pen_action_rate: -0.1198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0900
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2588
Episode_Reward/pen_flat_orientation: -0.1143
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4679
   Episode_Reward/foot_landing_vel: -0.1447
   Episode_Reward/test_gait_reward: -0.9415
Metrics/base_velocity/error_vel_xy: 1.0161
Metrics/base_velocity/error_vel_yaw: 1.3183
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 1.09s
                        Total time: 1437.16s
                               ETA: 1832.7s

################################################################################
                     [1m Learning iteration 1319/3000 [0m                     

                       Computation: 88370 steps/s (collection: 0.990s, learning 0.122s)
               Value function loss: 0.5493
                    Surrogate loss: -0.0009
             Mean action noise std: 0.8882
                     Learning rate: 0.0001
                       Mean reward: 127.38
               Mean episode length: 987.83
       Episode_Reward/keep_balance: 0.9747
     Episode_Reward/rew_lin_vel_xy: 5.9831
      Episode_Reward/rew_ang_vel_z: 2.4195
    Episode_Reward/pen_base_height: -0.2991
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1756
   Episode_Reward/pen_joint_torque: -0.2236
    Episode_Reward/pen_joint_accel: -0.1140
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2582
Episode_Reward/pen_flat_orientation: -0.1092
  Episode_Reward/pen_feet_distance: -0.0188
Episode_Reward/pen_feet_regulation: -0.4619
   Episode_Reward/foot_landing_vel: -0.1297
   Episode_Reward/test_gait_reward: -0.9415
Metrics/base_velocity/error_vel_xy: 1.0140
Metrics/base_velocity/error_vel_yaw: 1.3301
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 1.11s
                        Total time: 1438.27s
                               ETA: 1831.6s

################################################################################
                     [1m Learning iteration 1320/3000 [0m                     

                       Computation: 88963 steps/s (collection: 0.981s, learning 0.124s)
               Value function loss: 0.6273
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8891
                     Learning rate: 0.0003
                       Mean reward: 123.49
               Mean episode length: 959.26
       Episode_Reward/keep_balance: 0.9683
     Episode_Reward/rew_lin_vel_xy: 5.8954
      Episode_Reward/rew_ang_vel_z: 2.4219
    Episode_Reward/pen_base_height: -0.3101
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1814
   Episode_Reward/pen_joint_torque: -0.2248
    Episode_Reward/pen_joint_accel: -0.1076
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0892
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2569
Episode_Reward/pen_flat_orientation: -0.1082
  Episode_Reward/pen_feet_distance: -0.0226
Episode_Reward/pen_feet_regulation: -0.4687
   Episode_Reward/foot_landing_vel: -0.1316
   Episode_Reward/test_gait_reward: -0.9381
Metrics/base_velocity/error_vel_xy: 1.0306
Metrics/base_velocity/error_vel_yaw: 1.3084
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 1.10s
                        Total time: 1439.38s
                               ETA: 1830.6s

################################################################################
                     [1m Learning iteration 1321/3000 [0m                     

                       Computation: 89484 steps/s (collection: 0.977s, learning 0.122s)
               Value function loss: 0.6307
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8891
                     Learning rate: 0.0006
                       Mean reward: 125.37
               Mean episode length: 982.46
       Episode_Reward/keep_balance: 0.9824
     Episode_Reward/rew_lin_vel_xy: 5.9996
      Episode_Reward/rew_ang_vel_z: 2.4581
    Episode_Reward/pen_base_height: -0.3109
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1821
   Episode_Reward/pen_joint_torque: -0.2345
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0920
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2615
Episode_Reward/pen_flat_orientation: -0.1070
  Episode_Reward/pen_feet_distance: -0.0189
Episode_Reward/pen_feet_regulation: -0.4702
   Episode_Reward/foot_landing_vel: -0.1400
   Episode_Reward/test_gait_reward: -0.9474
Metrics/base_velocity/error_vel_xy: 1.0353
Metrics/base_velocity/error_vel_yaw: 1.3189
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 1.10s
                        Total time: 1440.48s
                               ETA: 1829.5s

################################################################################
                     [1m Learning iteration 1322/3000 [0m                     

                       Computation: 89039 steps/s (collection: 0.979s, learning 0.125s)
               Value function loss: 0.6577
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8891
                     Learning rate: 0.0006
                       Mean reward: 125.17
               Mean episode length: 980.84
       Episode_Reward/keep_balance: 0.9735
     Episode_Reward/rew_lin_vel_xy: 5.9159
      Episode_Reward/rew_ang_vel_z: 2.3991
    Episode_Reward/pen_base_height: -0.3035
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1774
   Episode_Reward/pen_joint_torque: -0.2238
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2580
Episode_Reward/pen_flat_orientation: -0.1088
  Episode_Reward/pen_feet_distance: -0.0201
Episode_Reward/pen_feet_regulation: -0.4695
   Episode_Reward/foot_landing_vel: -0.1377
   Episode_Reward/test_gait_reward: -0.9432
Metrics/base_velocity/error_vel_xy: 1.0282
Metrics/base_velocity/error_vel_yaw: 1.3491
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 1.10s
                        Total time: 1441.58s
                               ETA: 1828.4s

################################################################################
                     [1m Learning iteration 1323/3000 [0m                     

                       Computation: 89750 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.5735
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8888
                     Learning rate: 0.0006
                       Mean reward: 121.74
               Mean episode length: 959.15
       Episode_Reward/keep_balance: 0.9709
     Episode_Reward/rew_lin_vel_xy: 5.9052
      Episode_Reward/rew_ang_vel_z: 2.4153
    Episode_Reward/pen_base_height: -0.3232
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.1745
   Episode_Reward/pen_joint_torque: -0.2393
    Episode_Reward/pen_joint_accel: -0.1186
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0596
   Episode_Reward/pen_joint_powers: -0.0936
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2573
Episode_Reward/pen_flat_orientation: -0.1140
  Episode_Reward/pen_feet_distance: -0.0248
Episode_Reward/pen_feet_regulation: -0.4941
   Episode_Reward/foot_landing_vel: -0.1468
   Episode_Reward/test_gait_reward: -0.9410
Metrics/base_velocity/error_vel_xy: 1.0340
Metrics/base_velocity/error_vel_yaw: 1.3175
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 1.10s
                        Total time: 1442.68s
                               ETA: 1827.3s

################################################################################
                     [1m Learning iteration 1324/3000 [0m                     

                       Computation: 90205 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.6047
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8903
                     Learning rate: 0.0003
                       Mean reward: 125.76
               Mean episode length: 980.60
       Episode_Reward/keep_balance: 0.9863
     Episode_Reward/rew_lin_vel_xy: 6.0194
      Episode_Reward/rew_ang_vel_z: 2.4037
    Episode_Reward/pen_base_height: -0.3132
      Episode_Reward/pen_lin_vel_z: -0.0402
     Episode_Reward/pen_ang_vel_xy: -0.1770
   Episode_Reward/pen_joint_torque: -0.2321
    Episode_Reward/pen_joint_accel: -0.1125
    Episode_Reward/pen_action_rate: -0.1227
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0593
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2632
Episode_Reward/pen_flat_orientation: -0.1116
  Episode_Reward/pen_feet_distance: -0.0218
Episode_Reward/pen_feet_regulation: -0.4874
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.9558
Metrics/base_velocity/error_vel_xy: 1.0511
Metrics/base_velocity/error_vel_yaw: 1.3942
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 1.09s
                        Total time: 1443.77s
                               ETA: 1826.2s

################################################################################
                     [1m Learning iteration 1325/3000 [0m                     

                       Computation: 88483 steps/s (collection: 0.986s, learning 0.125s)
               Value function loss: 0.6174
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8875
                     Learning rate: 0.0004
                       Mean reward: 125.00
               Mean episode length: 986.57
       Episode_Reward/keep_balance: 0.9921
     Episode_Reward/rew_lin_vel_xy: 6.0177
      Episode_Reward/rew_ang_vel_z: 2.4531
    Episode_Reward/pen_base_height: -0.3099
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1765
   Episode_Reward/pen_joint_torque: -0.2375
    Episode_Reward/pen_joint_accel: -0.1230
    Episode_Reward/pen_action_rate: -0.1227
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0927
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2634
Episode_Reward/pen_flat_orientation: -0.1131
  Episode_Reward/pen_feet_distance: -0.0207
Episode_Reward/pen_feet_regulation: -0.4888
   Episode_Reward/foot_landing_vel: -0.1350
   Episode_Reward/test_gait_reward: -0.9616
Metrics/base_velocity/error_vel_xy: 1.0666
Metrics/base_velocity/error_vel_yaw: 1.3580
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 1.11s
                        Total time: 1444.88s
                               ETA: 1825.2s

################################################################################
                     [1m Learning iteration 1326/3000 [0m                     

                       Computation: 89599 steps/s (collection: 0.971s, learning 0.126s)
               Value function loss: 0.5476
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8860
                     Learning rate: 0.0003
                       Mean reward: 124.16
               Mean episode length: 990.22
       Episode_Reward/keep_balance: 0.9815
     Episode_Reward/rew_lin_vel_xy: 5.9175
      Episode_Reward/rew_ang_vel_z: 2.4129
    Episode_Reward/pen_base_height: -0.3183
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1834
   Episode_Reward/pen_joint_torque: -0.2302
    Episode_Reward/pen_joint_accel: -0.1207
    Episode_Reward/pen_action_rate: -0.1220
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2620
Episode_Reward/pen_flat_orientation: -0.1177
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4921
   Episode_Reward/foot_landing_vel: -0.1395
   Episode_Reward/test_gait_reward: -0.9532
Metrics/base_velocity/error_vel_xy: 1.0738
Metrics/base_velocity/error_vel_yaw: 1.3676
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 1.10s
                        Total time: 1445.98s
                               ETA: 1824.1s

################################################################################
                     [1m Learning iteration 1327/3000 [0m                     

                       Computation: 80929 steps/s (collection: 1.088s, learning 0.126s)
               Value function loss: 0.5985
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8846
                     Learning rate: 0.0004
                       Mean reward: 120.84
               Mean episode length: 979.92
       Episode_Reward/keep_balance: 0.9811
     Episode_Reward/rew_lin_vel_xy: 5.8756
      Episode_Reward/rew_ang_vel_z: 2.3388
    Episode_Reward/pen_base_height: -0.3250
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1901
   Episode_Reward/pen_joint_torque: -0.2273
    Episode_Reward/pen_joint_accel: -0.1261
    Episode_Reward/pen_action_rate: -0.1262
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0626
   Episode_Reward/pen_joint_powers: -0.0947
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2722
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0219
Episode_Reward/pen_feet_regulation: -0.5281
   Episode_Reward/foot_landing_vel: -0.1361
   Episode_Reward/test_gait_reward: -0.9674
Metrics/base_velocity/error_vel_xy: 1.1184
Metrics/base_velocity/error_vel_yaw: 1.4537
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 1.21s
                        Total time: 1447.19s
                               ETA: 1823.2s

################################################################################
                     [1m Learning iteration 1328/3000 [0m                     

                       Computation: 89600 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.6091
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8839
                     Learning rate: 0.0006
                       Mean reward: 128.18
               Mean episode length: 966.62
       Episode_Reward/keep_balance: 0.9556
     Episode_Reward/rew_lin_vel_xy: 5.9219
      Episode_Reward/rew_ang_vel_z: 2.4217
    Episode_Reward/pen_base_height: -0.2980
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1679
   Episode_Reward/pen_joint_torque: -0.2256
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2483
Episode_Reward/pen_flat_orientation: -0.1073
  Episode_Reward/pen_feet_distance: -0.0210
Episode_Reward/pen_feet_regulation: -0.4324
   Episode_Reward/foot_landing_vel: -0.1357
   Episode_Reward/test_gait_reward: -0.9121
Metrics/base_velocity/error_vel_xy: 0.9734
Metrics/base_velocity/error_vel_yaw: 1.2591
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 1.10s
                        Total time: 1448.29s
                               ETA: 1822.1s

################################################################################
                     [1m Learning iteration 1329/3000 [0m                     

                       Computation: 90501 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.6649
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8834
                     Learning rate: 0.0002
                       Mean reward: 125.99
               Mean episode length: 968.81
       Episode_Reward/keep_balance: 0.9657
     Episode_Reward/rew_lin_vel_xy: 5.9266
      Episode_Reward/rew_ang_vel_z: 2.3628
    Episode_Reward/pen_base_height: -0.3022
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1717
   Episode_Reward/pen_joint_torque: -0.2253
    Episode_Reward/pen_joint_accel: -0.1074
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2559
Episode_Reward/pen_flat_orientation: -0.1043
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4526
   Episode_Reward/foot_landing_vel: -0.1362
   Episode_Reward/test_gait_reward: -0.9260
Metrics/base_velocity/error_vel_xy: 1.0058
Metrics/base_velocity/error_vel_yaw: 1.3458
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 1.09s
                        Total time: 1449.37s
                               ETA: 1821.0s

################################################################################
                     [1m Learning iteration 1330/3000 [0m                     

                       Computation: 90279 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.5867
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8824
                     Learning rate: 0.0006
                       Mean reward: 124.38
               Mean episode length: 978.71
       Episode_Reward/keep_balance: 0.9745
     Episode_Reward/rew_lin_vel_xy: 5.8946
      Episode_Reward/rew_ang_vel_z: 2.4083
    Episode_Reward/pen_base_height: -0.3154
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1748
   Episode_Reward/pen_joint_torque: -0.2321
    Episode_Reward/pen_joint_accel: -0.1193
    Episode_Reward/pen_action_rate: -0.1202
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2580
Episode_Reward/pen_flat_orientation: -0.1085
  Episode_Reward/pen_feet_distance: -0.0216
Episode_Reward/pen_feet_regulation: -0.4797
   Episode_Reward/foot_landing_vel: -0.1449
   Episode_Reward/test_gait_reward: -0.9343
Metrics/base_velocity/error_vel_xy: 1.0520
Metrics/base_velocity/error_vel_yaw: 1.3285
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 1.09s
                        Total time: 1450.46s
                               ETA: 1819.9s

################################################################################
                     [1m Learning iteration 1331/3000 [0m                     

                       Computation: 90978 steps/s (collection: 0.955s, learning 0.126s)
               Value function loss: 0.6299
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8826
                     Learning rate: 0.0006
                       Mean reward: 125.71
               Mean episode length: 982.16
       Episode_Reward/keep_balance: 0.9842
     Episode_Reward/rew_lin_vel_xy: 6.0174
      Episode_Reward/rew_ang_vel_z: 2.4350
    Episode_Reward/pen_base_height: -0.2955
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1753
   Episode_Reward/pen_joint_torque: -0.2195
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.1198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2611
Episode_Reward/pen_flat_orientation: -0.1086
  Episode_Reward/pen_feet_distance: -0.0237
Episode_Reward/pen_feet_regulation: -0.4647
   Episode_Reward/foot_landing_vel: -0.1528
   Episode_Reward/test_gait_reward: -0.9385
Metrics/base_velocity/error_vel_xy: 1.0381
Metrics/base_velocity/error_vel_yaw: 1.3512
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 1.08s
                        Total time: 1451.54s
                               ETA: 1818.8s

################################################################################
                     [1m Learning iteration 1332/3000 [0m                     

                       Computation: 88653 steps/s (collection: 0.986s, learning 0.123s)
               Value function loss: 0.6306
                    Surrogate loss: 0.0005
             Mean action noise std: 0.8819
                     Learning rate: 0.0001
                       Mean reward: 129.47
               Mean episode length: 991.49
       Episode_Reward/keep_balance: 0.9880
     Episode_Reward/rew_lin_vel_xy: 6.0765
      Episode_Reward/rew_ang_vel_z: 2.4486
    Episode_Reward/pen_base_height: -0.3223
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1707
   Episode_Reward/pen_joint_torque: -0.2353
    Episode_Reward/pen_joint_accel: -0.1081
    Episode_Reward/pen_action_rate: -0.1215
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0916
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2615
Episode_Reward/pen_flat_orientation: -0.1122
  Episode_Reward/pen_feet_distance: -0.0211
Episode_Reward/pen_feet_regulation: -0.4722
   Episode_Reward/foot_landing_vel: -0.1362
   Episode_Reward/test_gait_reward: -0.9575
Metrics/base_velocity/error_vel_xy: 1.0170
Metrics/base_velocity/error_vel_yaw: 1.3612
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 1.11s
                        Total time: 1452.65s
                               ETA: 1817.7s

################################################################################
                     [1m Learning iteration 1333/3000 [0m                     

                       Computation: 86971 steps/s (collection: 1.006s, learning 0.125s)
               Value function loss: 0.5573
                    Surrogate loss: -0.0006
             Mean action noise std: 0.8820
                     Learning rate: 0.0001
                       Mean reward: 128.77
               Mean episode length: 979.35
       Episode_Reward/keep_balance: 0.9851
     Episode_Reward/rew_lin_vel_xy: 6.0668
      Episode_Reward/rew_ang_vel_z: 2.4505
    Episode_Reward/pen_base_height: -0.3240
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1748
   Episode_Reward/pen_joint_torque: -0.2250
    Episode_Reward/pen_joint_accel: -0.1066
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2594
Episode_Reward/pen_flat_orientation: -0.1061
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4671
   Episode_Reward/foot_landing_vel: -0.1264
   Episode_Reward/test_gait_reward: -0.9415
Metrics/base_velocity/error_vel_xy: 1.0174
Metrics/base_velocity/error_vel_yaw: 1.3474
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 1.13s
                        Total time: 1453.78s
                               ETA: 1816.7s

################################################################################
                     [1m Learning iteration 1334/3000 [0m                     

                       Computation: 89191 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.6435
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8819
                     Learning rate: 0.0001
                       Mean reward: 127.78
               Mean episode length: 986.18
       Episode_Reward/keep_balance: 0.9920
     Episode_Reward/rew_lin_vel_xy: 6.0715
      Episode_Reward/rew_ang_vel_z: 2.5088
    Episode_Reward/pen_base_height: -0.3261
      Episode_Reward/pen_lin_vel_z: -0.0425
     Episode_Reward/pen_ang_vel_xy: -0.1760
   Episode_Reward/pen_joint_torque: -0.2311
    Episode_Reward/pen_joint_accel: -0.1241
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0918
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2607
Episode_Reward/pen_flat_orientation: -0.1081
  Episode_Reward/pen_feet_distance: -0.0195
Episode_Reward/pen_feet_regulation: -0.4851
   Episode_Reward/foot_landing_vel: -0.1490
   Episode_Reward/test_gait_reward: -0.9583
Metrics/base_velocity/error_vel_xy: 1.0489
Metrics/base_velocity/error_vel_yaw: 1.3130
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 1.10s
                        Total time: 1454.88s
                               ETA: 1815.6s

################################################################################
                     [1m Learning iteration 1335/3000 [0m                     

                       Computation: 89763 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.5785
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8802
                     Learning rate: 0.0003
                       Mean reward: 126.44
               Mean episode length: 978.08
       Episode_Reward/keep_balance: 0.9752
     Episode_Reward/rew_lin_vel_xy: 5.9981
      Episode_Reward/rew_ang_vel_z: 2.3749
    Episode_Reward/pen_base_height: -0.2975
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1787
   Episode_Reward/pen_joint_torque: -0.2217
    Episode_Reward/pen_joint_accel: -0.1086
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2598
Episode_Reward/pen_flat_orientation: -0.1124
  Episode_Reward/pen_feet_distance: -0.0153
Episode_Reward/pen_feet_regulation: -0.4693
   Episode_Reward/foot_landing_vel: -0.1422
   Episode_Reward/test_gait_reward: -0.9371
Metrics/base_velocity/error_vel_xy: 1.0123
Metrics/base_velocity/error_vel_yaw: 1.3928
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 1.10s
                        Total time: 1455.98s
                               ETA: 1814.5s

################################################################################
                     [1m Learning iteration 1336/3000 [0m                     

                       Computation: 87973 steps/s (collection: 0.995s, learning 0.122s)
               Value function loss: 0.5722
                    Surrogate loss: -0.0055
             Mean action noise std: 0.8796
                     Learning rate: 0.0006
                       Mean reward: 128.49
               Mean episode length: 990.33
       Episode_Reward/keep_balance: 0.9875
     Episode_Reward/rew_lin_vel_xy: 6.0288
      Episode_Reward/rew_ang_vel_z: 2.4253
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1759
   Episode_Reward/pen_joint_torque: -0.2305
    Episode_Reward/pen_joint_accel: -0.1144
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2600
Episode_Reward/pen_flat_orientation: -0.1090
  Episode_Reward/pen_feet_distance: -0.0255
Episode_Reward/pen_feet_regulation: -0.4834
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9501
Metrics/base_velocity/error_vel_xy: 1.0432
Metrics/base_velocity/error_vel_yaw: 1.3700
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 1.12s
                        Total time: 1457.10s
                               ETA: 1813.5s

################################################################################
                     [1m Learning iteration 1337/3000 [0m                     

                       Computation: 88541 steps/s (collection: 0.986s, learning 0.124s)
               Value function loss: 0.6232
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8814
                     Learning rate: 0.0004
                       Mean reward: 124.89
               Mean episode length: 979.39
       Episode_Reward/keep_balance: 0.9838
     Episode_Reward/rew_lin_vel_xy: 6.0162
      Episode_Reward/rew_ang_vel_z: 2.3826
    Episode_Reward/pen_base_height: -0.3100
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.1808
   Episode_Reward/pen_joint_torque: -0.2252
    Episode_Reward/pen_joint_accel: -0.1138
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2612
Episode_Reward/pen_flat_orientation: -0.1077
  Episode_Reward/pen_feet_distance: -0.0182
Episode_Reward/pen_feet_regulation: -0.4547
   Episode_Reward/foot_landing_vel: -0.1351
   Episode_Reward/test_gait_reward: -0.9522
Metrics/base_velocity/error_vel_xy: 1.0365
Metrics/base_velocity/error_vel_yaw: 1.4003
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 1.11s
                        Total time: 1458.21s
                               ETA: 1812.4s

################################################################################
                     [1m Learning iteration 1338/3000 [0m                     

                       Computation: 89446 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.5799
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8812
                     Learning rate: 0.0004
                       Mean reward: 129.11
               Mean episode length: 985.53
       Episode_Reward/keep_balance: 0.9789
     Episode_Reward/rew_lin_vel_xy: 6.0453
      Episode_Reward/rew_ang_vel_z: 2.4262
    Episode_Reward/pen_base_height: -0.3147
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1757
   Episode_Reward/pen_joint_torque: -0.2252
    Episode_Reward/pen_joint_accel: -0.1163
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0595
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2552
Episode_Reward/pen_flat_orientation: -0.1061
  Episode_Reward/pen_feet_distance: -0.0227
Episode_Reward/pen_feet_regulation: -0.4734
   Episode_Reward/foot_landing_vel: -0.1400
   Episode_Reward/test_gait_reward: -0.9367
Metrics/base_velocity/error_vel_xy: 1.0131
Metrics/base_velocity/error_vel_yaw: 1.3353
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 1.10s
                        Total time: 1459.31s
                               ETA: 1811.3s

################################################################################
                     [1m Learning iteration 1339/3000 [0m                     

                       Computation: 90193 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.5570
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8801
                     Learning rate: 0.0006
                       Mean reward: 125.04
               Mean episode length: 975.36
       Episode_Reward/keep_balance: 0.9864
     Episode_Reward/rew_lin_vel_xy: 6.0020
      Episode_Reward/rew_ang_vel_z: 2.4315
    Episode_Reward/pen_base_height: -0.3198
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1766
   Episode_Reward/pen_joint_torque: -0.2361
    Episode_Reward/pen_joint_accel: -0.1220
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2597
Episode_Reward/pen_flat_orientation: -0.1096
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4821
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9475
Metrics/base_velocity/error_vel_xy: 1.0540
Metrics/base_velocity/error_vel_yaw: 1.3553
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 1.09s
                        Total time: 1460.40s
                               ETA: 1810.2s

################################################################################
                     [1m Learning iteration 1340/3000 [0m                     

                       Computation: 89895 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.5653
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8792
                     Learning rate: 0.0006
                       Mean reward: 124.50
               Mean episode length: 975.98
       Episode_Reward/keep_balance: 0.9719
     Episode_Reward/rew_lin_vel_xy: 5.9378
      Episode_Reward/rew_ang_vel_z: 2.4129
    Episode_Reward/pen_base_height: -0.3164
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1777
   Episode_Reward/pen_joint_torque: -0.2352
    Episode_Reward/pen_joint_accel: -0.1058
    Episode_Reward/pen_action_rate: -0.1178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0593
   Episode_Reward/pen_joint_powers: -0.0922
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2520
Episode_Reward/pen_flat_orientation: -0.1112
  Episode_Reward/pen_feet_distance: -0.0230
Episode_Reward/pen_feet_regulation: -0.4863
   Episode_Reward/foot_landing_vel: -0.1426
   Episode_Reward/test_gait_reward: -0.9335
Metrics/base_velocity/error_vel_xy: 1.0289
Metrics/base_velocity/error_vel_yaw: 1.3244
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 1.09s
                        Total time: 1461.49s
                               ETA: 1809.2s

################################################################################
                     [1m Learning iteration 1341/3000 [0m                     

                       Computation: 88995 steps/s (collection: 0.979s, learning 0.125s)
               Value function loss: 0.6398
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8792
                     Learning rate: 0.0003
                       Mean reward: 124.55
               Mean episode length: 979.48
       Episode_Reward/keep_balance: 0.9836
     Episode_Reward/rew_lin_vel_xy: 5.9788
      Episode_Reward/rew_ang_vel_z: 2.3980
    Episode_Reward/pen_base_height: -0.3101
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1796
   Episode_Reward/pen_joint_torque: -0.2333
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1230
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0617
   Episode_Reward/pen_joint_powers: -0.0936
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2632
Episode_Reward/pen_flat_orientation: -0.1161
  Episode_Reward/pen_feet_distance: -0.0233
Episode_Reward/pen_feet_regulation: -0.4958
   Episode_Reward/foot_landing_vel: -0.1555
   Episode_Reward/test_gait_reward: -0.9533
Metrics/base_velocity/error_vel_xy: 1.0545
Metrics/base_velocity/error_vel_yaw: 1.3917
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 1.10s
                        Total time: 1462.59s
                               ETA: 1808.1s

################################################################################
                     [1m Learning iteration 1342/3000 [0m                     

                       Computation: 88815 steps/s (collection: 0.984s, learning 0.123s)
               Value function loss: 0.6451
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8793
                     Learning rate: 0.0006
                       Mean reward: 125.08
               Mean episode length: 976.16
       Episode_Reward/keep_balance: 0.9793
     Episode_Reward/rew_lin_vel_xy: 5.9968
      Episode_Reward/rew_ang_vel_z: 2.4256
    Episode_Reward/pen_base_height: -0.3197
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.1717
   Episode_Reward/pen_joint_torque: -0.2348
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2545
Episode_Reward/pen_flat_orientation: -0.1064
  Episode_Reward/pen_feet_distance: -0.0197
Episode_Reward/pen_feet_regulation: -0.4755
   Episode_Reward/foot_landing_vel: -0.1349
   Episode_Reward/test_gait_reward: -0.9386
Metrics/base_velocity/error_vel_xy: 1.0306
Metrics/base_velocity/error_vel_yaw: 1.3434
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 1.11s
                        Total time: 1463.70s
                               ETA: 1807.0s

################################################################################
                     [1m Learning iteration 1343/3000 [0m                     

                       Computation: 90083 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.5147
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8803
                     Learning rate: 0.0003
                       Mean reward: 129.28
               Mean episode length: 989.41
       Episode_Reward/keep_balance: 0.9890
     Episode_Reward/rew_lin_vel_xy: 6.1272
      Episode_Reward/rew_ang_vel_z: 2.4613
    Episode_Reward/pen_base_height: -0.3143
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1777
   Episode_Reward/pen_joint_torque: -0.2321
    Episode_Reward/pen_joint_accel: -0.1131
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2578
Episode_Reward/pen_flat_orientation: -0.1109
  Episode_Reward/pen_feet_distance: -0.0210
Episode_Reward/pen_feet_regulation: -0.4708
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.9492
Metrics/base_velocity/error_vel_xy: 0.9944
Metrics/base_velocity/error_vel_yaw: 1.3392
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 1.09s
                        Total time: 1464.79s
                               ETA: 1805.9s

################################################################################
                     [1m Learning iteration 1344/3000 [0m                     

                       Computation: 89195 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.5758
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8793
                     Learning rate: 0.0006
                       Mean reward: 122.02
               Mean episode length: 967.26
       Episode_Reward/keep_balance: 0.9438
     Episode_Reward/rew_lin_vel_xy: 5.6772
      Episode_Reward/rew_ang_vel_z: 2.3232
    Episode_Reward/pen_base_height: -0.3042
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1698
   Episode_Reward/pen_joint_torque: -0.2195
    Episode_Reward/pen_joint_accel: -0.1072
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2481
Episode_Reward/pen_flat_orientation: -0.1082
  Episode_Reward/pen_feet_distance: -0.0186
Episode_Reward/pen_feet_regulation: -0.4665
   Episode_Reward/foot_landing_vel: -0.1352
   Episode_Reward/test_gait_reward: -0.9120
Metrics/base_velocity/error_vel_xy: 1.0442
Metrics/base_velocity/error_vel_yaw: 1.3126
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 1.10s
                        Total time: 1465.89s
                               ETA: 1804.8s

################################################################################
                     [1m Learning iteration 1345/3000 [0m                     

                       Computation: 90423 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.5613
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8780
                     Learning rate: 0.0004
                       Mean reward: 128.21
               Mean episode length: 994.27
       Episode_Reward/keep_balance: 0.9927
     Episode_Reward/rew_lin_vel_xy: 6.0742
      Episode_Reward/rew_ang_vel_z: 2.4479
    Episode_Reward/pen_base_height: -0.3253
      Episode_Reward/pen_lin_vel_z: -0.0399
     Episode_Reward/pen_ang_vel_xy: -0.1733
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.1213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2597
Episode_Reward/pen_flat_orientation: -0.1112
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4901
   Episode_Reward/foot_landing_vel: -0.1374
   Episode_Reward/test_gait_reward: -0.9601
Metrics/base_velocity/error_vel_xy: 1.0467
Metrics/base_velocity/error_vel_yaw: 1.3586
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 1.09s
                        Total time: 1466.98s
                               ETA: 1803.8s

################################################################################
                     [1m Learning iteration 1346/3000 [0m                     

                       Computation: 89372 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.5470
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8777
                     Learning rate: 0.0006
                       Mean reward: 131.87
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.2005
      Episode_Reward/rew_ang_vel_z: 2.4816
    Episode_Reward/pen_base_height: -0.3151
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1729
   Episode_Reward/pen_joint_torque: -0.2328
    Episode_Reward/pen_joint_accel: -0.1148
    Episode_Reward/pen_action_rate: -0.1198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2591
Episode_Reward/pen_flat_orientation: -0.1016
  Episode_Reward/pen_feet_distance: -0.0180
Episode_Reward/pen_feet_regulation: -0.4679
   Episode_Reward/foot_landing_vel: -0.1394
   Episode_Reward/test_gait_reward: -0.9537
Metrics/base_velocity/error_vel_xy: 1.0147
Metrics/base_velocity/error_vel_yaw: 1.3578
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 1.10s
                        Total time: 1468.08s
                               ETA: 1802.7s

################################################################################
                     [1m Learning iteration 1347/3000 [0m                     

                       Computation: 90514 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.6248
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8778
                     Learning rate: 0.0004
                       Mean reward: 123.04
               Mean episode length: 953.88
       Episode_Reward/keep_balance: 0.9673
     Episode_Reward/rew_lin_vel_xy: 5.9559
      Episode_Reward/rew_ang_vel_z: 2.4312
    Episode_Reward/pen_base_height: -0.2960
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1727
   Episode_Reward/pen_joint_torque: -0.2336
    Episode_Reward/pen_joint_accel: -0.1005
    Episode_Reward/pen_action_rate: -0.1170
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2494
Episode_Reward/pen_flat_orientation: -0.1098
  Episode_Reward/pen_feet_distance: -0.0212
Episode_Reward/pen_feet_regulation: -0.4626
   Episode_Reward/foot_landing_vel: -0.1293
   Episode_Reward/test_gait_reward: -0.9258
Metrics/base_velocity/error_vel_xy: 0.9956
Metrics/base_velocity/error_vel_yaw: 1.2992
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 1.09s
                        Total time: 1469.17s
                               ETA: 1801.6s

################################################################################
                     [1m Learning iteration 1348/3000 [0m                     

                       Computation: 90980 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.5567
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8763
                     Learning rate: 0.0004
                       Mean reward: 128.75
               Mean episode length: 976.82
       Episode_Reward/keep_balance: 0.9693
     Episode_Reward/rew_lin_vel_xy: 5.9917
      Episode_Reward/rew_ang_vel_z: 2.3904
    Episode_Reward/pen_base_height: -0.2951
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1683
   Episode_Reward/pen_joint_torque: -0.2176
    Episode_Reward/pen_joint_accel: -0.1105
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2525
Episode_Reward/pen_flat_orientation: -0.1056
  Episode_Reward/pen_feet_distance: -0.0180
Episode_Reward/pen_feet_regulation: -0.4523
   Episode_Reward/foot_landing_vel: -0.1387
   Episode_Reward/test_gait_reward: -0.9250
Metrics/base_velocity/error_vel_xy: 0.9859
Metrics/base_velocity/error_vel_yaw: 1.3438
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 1.08s
                        Total time: 1470.25s
                               ETA: 1800.5s

################################################################################
                     [1m Learning iteration 1349/3000 [0m                     

                       Computation: 88801 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 0.5616
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8759
                     Learning rate: 0.0001
                       Mean reward: 125.87
               Mean episode length: 970.15
       Episode_Reward/keep_balance: 0.9347
     Episode_Reward/rew_lin_vel_xy: 5.7024
      Episode_Reward/rew_ang_vel_z: 2.3005
    Episode_Reward/pen_base_height: -0.2862
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1722
   Episode_Reward/pen_joint_torque: -0.2109
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.1134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0848
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2451
Episode_Reward/pen_flat_orientation: -0.1078
  Episode_Reward/pen_feet_distance: -0.0191
Episode_Reward/pen_feet_regulation: -0.4634
   Episode_Reward/foot_landing_vel: -0.1317
   Episode_Reward/test_gait_reward: -0.8942
Metrics/base_velocity/error_vel_xy: 0.9864
Metrics/base_velocity/error_vel_yaw: 1.3044
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 1.11s
                        Total time: 1471.36s
                               ETA: 1799.4s

################################################################################
                     [1m Learning iteration 1350/3000 [0m                     

                       Computation: 87876 steps/s (collection: 0.996s, learning 0.123s)
               Value function loss: 0.6037
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8765
                     Learning rate: 0.0003
                       Mean reward: 127.90
               Mean episode length: 975.95
       Episode_Reward/keep_balance: 0.9822
     Episode_Reward/rew_lin_vel_xy: 6.0297
      Episode_Reward/rew_ang_vel_z: 2.4696
    Episode_Reward/pen_base_height: -0.3033
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1775
   Episode_Reward/pen_joint_torque: -0.2222
    Episode_Reward/pen_joint_accel: -0.1161
    Episode_Reward/pen_action_rate: -0.1172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2548
Episode_Reward/pen_flat_orientation: -0.1050
  Episode_Reward/pen_feet_distance: -0.0173
Episode_Reward/pen_feet_regulation: -0.4657
   Episode_Reward/foot_landing_vel: -0.1385
   Episode_Reward/test_gait_reward: -0.9313
Metrics/base_velocity/error_vel_xy: 1.0251
Metrics/base_velocity/error_vel_yaw: 1.3106
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 1.12s
                        Total time: 1472.47s
                               ETA: 1798.4s

################################################################################
                     [1m Learning iteration 1351/3000 [0m                     

                       Computation: 91066 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.5254
                    Surrogate loss: -0.0056
             Mean action noise std: 0.8751
                     Learning rate: 0.0004
                       Mean reward: 127.55
               Mean episode length: 979.28
       Episode_Reward/keep_balance: 0.9774
     Episode_Reward/rew_lin_vel_xy: 6.0400
      Episode_Reward/rew_ang_vel_z: 2.4444
    Episode_Reward/pen_base_height: -0.3050
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1733
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1066
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2536
Episode_Reward/pen_flat_orientation: -0.1062
  Episode_Reward/pen_feet_distance: -0.0194
Episode_Reward/pen_feet_regulation: -0.4739
   Episode_Reward/foot_landing_vel: -0.1398
   Episode_Reward/test_gait_reward: -0.9321
Metrics/base_velocity/error_vel_xy: 1.0061
Metrics/base_velocity/error_vel_yaw: 1.3201
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 1.08s
                        Total time: 1473.55s
                               ETA: 1797.3s

################################################################################
                     [1m Learning iteration 1352/3000 [0m                     

                       Computation: 90682 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.6270
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8754
                     Learning rate: 0.0009
                       Mean reward: 128.50
               Mean episode length: 981.81
       Episode_Reward/keep_balance: 0.9807
     Episode_Reward/rew_lin_vel_xy: 6.0071
      Episode_Reward/rew_ang_vel_z: 2.4628
    Episode_Reward/pen_base_height: -0.3118
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1762
   Episode_Reward/pen_joint_torque: -0.2298
    Episode_Reward/pen_joint_accel: -0.1130
    Episode_Reward/pen_action_rate: -0.1179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2527
Episode_Reward/pen_flat_orientation: -0.1086
  Episode_Reward/pen_feet_distance: -0.0247
Episode_Reward/pen_feet_regulation: -0.4871
   Episode_Reward/foot_landing_vel: -0.1439
   Episode_Reward/test_gait_reward: -0.9429
Metrics/base_velocity/error_vel_xy: 1.0291
Metrics/base_velocity/error_vel_yaw: 1.3069
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 1.08s
                        Total time: 1474.64s
                               ETA: 1796.2s

################################################################################
                     [1m Learning iteration 1353/3000 [0m                     

                       Computation: 92125 steps/s (collection: 0.946s, learning 0.121s)
               Value function loss: 0.6486
                    Surrogate loss: 0.0042
             Mean action noise std: 0.8758
                     Learning rate: 0.0001
                       Mean reward: 123.97
               Mean episode length: 952.31
       Episode_Reward/keep_balance: 0.9582
     Episode_Reward/rew_lin_vel_xy: 5.9120
      Episode_Reward/rew_ang_vel_z: 2.3295
    Episode_Reward/pen_base_height: -0.3026
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1718
   Episode_Reward/pen_joint_torque: -0.2207
    Episode_Reward/pen_joint_accel: -0.1180
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2515
Episode_Reward/pen_flat_orientation: -0.1087
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4844
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.9146
Metrics/base_velocity/error_vel_xy: 0.9894
Metrics/base_velocity/error_vel_yaw: 1.3594
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 1.07s
                        Total time: 1475.70s
                               ETA: 1795.0s

################################################################################
                     [1m Learning iteration 1354/3000 [0m                     

                       Computation: 90606 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.5761
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8752
                     Learning rate: 0.0003
                       Mean reward: 122.57
               Mean episode length: 934.90
       Episode_Reward/keep_balance: 0.9368
     Episode_Reward/rew_lin_vel_xy: 5.7750
      Episode_Reward/rew_ang_vel_z: 2.3723
    Episode_Reward/pen_base_height: -0.2986
      Episode_Reward/pen_lin_vel_z: -0.0389
     Episode_Reward/pen_ang_vel_xy: -0.1623
   Episode_Reward/pen_joint_torque: -0.2267
    Episode_Reward/pen_joint_accel: -0.1200
    Episode_Reward/pen_action_rate: -0.1128
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2401
Episode_Reward/pen_flat_orientation: -0.1021
  Episode_Reward/pen_feet_distance: -0.0169
Episode_Reward/pen_feet_regulation: -0.4522
   Episode_Reward/foot_landing_vel: -0.1436
   Episode_Reward/test_gait_reward: -0.8903
Metrics/base_velocity/error_vel_xy: 0.9644
Metrics/base_velocity/error_vel_yaw: 1.2377
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 1.08s
                        Total time: 1476.79s
                               ETA: 1793.9s

################################################################################
                     [1m Learning iteration 1355/3000 [0m                     

                       Computation: 90989 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.6901
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8746
                     Learning rate: 0.0006
                       Mean reward: 128.08
               Mean episode length: 983.54
       Episode_Reward/keep_balance: 0.9866
     Episode_Reward/rew_lin_vel_xy: 6.0142
      Episode_Reward/rew_ang_vel_z: 2.4355
    Episode_Reward/pen_base_height: -0.3093
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1704
   Episode_Reward/pen_joint_torque: -0.2318
    Episode_Reward/pen_joint_accel: -0.1074
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2560
Episode_Reward/pen_flat_orientation: -0.1084
  Episode_Reward/pen_feet_distance: -0.0203
Episode_Reward/pen_feet_regulation: -0.4780
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.9418
Metrics/base_velocity/error_vel_xy: 1.0467
Metrics/base_velocity/error_vel_yaw: 1.3587
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 1.08s
                        Total time: 1477.87s
                               ETA: 1792.8s

################################################################################
                     [1m Learning iteration 1356/3000 [0m                     

                       Computation: 89372 steps/s (collection: 0.978s, learning 0.122s)
               Value function loss: 0.5534
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8729
                     Learning rate: 0.0004
                       Mean reward: 127.23
               Mean episode length: 981.78
       Episode_Reward/keep_balance: 0.9833
     Episode_Reward/rew_lin_vel_xy: 6.0991
      Episode_Reward/rew_ang_vel_z: 2.4227
    Episode_Reward/pen_base_height: -0.3123
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1792
   Episode_Reward/pen_joint_torque: -0.2251
    Episode_Reward/pen_joint_accel: -0.1123
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2587
Episode_Reward/pen_flat_orientation: -0.1045
  Episode_Reward/pen_feet_distance: -0.0181
Episode_Reward/pen_feet_regulation: -0.4576
   Episode_Reward/foot_landing_vel: -0.1396
   Episode_Reward/test_gait_reward: -0.9402
Metrics/base_velocity/error_vel_xy: 0.9815
Metrics/base_velocity/error_vel_yaw: 1.3609
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 1.10s
                        Total time: 1478.97s
                               ETA: 1791.8s

################################################################################
                     [1m Learning iteration 1357/3000 [0m                     

                       Computation: 91086 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.6086
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8713
                     Learning rate: 0.0004
                       Mean reward: 128.02
               Mean episode length: 993.97
       Episode_Reward/keep_balance: 0.9937
     Episode_Reward/rew_lin_vel_xy: 6.0477
      Episode_Reward/rew_ang_vel_z: 2.4505
    Episode_Reward/pen_base_height: -0.3291
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1682
   Episode_Reward/pen_joint_torque: -0.2474
    Episode_Reward/pen_joint_accel: -0.1083
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0950
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2545
Episode_Reward/pen_flat_orientation: -0.1115
  Episode_Reward/pen_feet_distance: -0.0260
Episode_Reward/pen_feet_regulation: -0.4888
   Episode_Reward/foot_landing_vel: -0.1409
   Episode_Reward/test_gait_reward: -0.9545
Metrics/base_velocity/error_vel_xy: 1.0643
Metrics/base_velocity/error_vel_yaw: 1.3765
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 1.08s
                        Total time: 1480.05s
                               ETA: 1790.7s

################################################################################
                     [1m Learning iteration 1358/3000 [0m                     

                       Computation: 91410 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.5732
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8711
                     Learning rate: 0.0004
                       Mean reward: 127.31
               Mean episode length: 979.87
       Episode_Reward/keep_balance: 0.9868
     Episode_Reward/rew_lin_vel_xy: 6.0060
      Episode_Reward/rew_ang_vel_z: 2.4601
    Episode_Reward/pen_base_height: -0.3266
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1797
   Episode_Reward/pen_joint_torque: -0.2401
    Episode_Reward/pen_joint_accel: -0.1197
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0595
   Episode_Reward/pen_joint_powers: -0.0920
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2556
Episode_Reward/pen_flat_orientation: -0.1072
  Episode_Reward/pen_feet_distance: -0.0192
Episode_Reward/pen_feet_regulation: -0.4888
   Episode_Reward/foot_landing_vel: -0.1377
   Episode_Reward/test_gait_reward: -0.9483
Metrics/base_velocity/error_vel_xy: 1.0820
Metrics/base_velocity/error_vel_yaw: 1.3351
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 1.08s
                        Total time: 1481.12s
                               ETA: 1789.6s

################################################################################
                     [1m Learning iteration 1359/3000 [0m                     

                       Computation: 89307 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 0.6148
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8726
                     Learning rate: 0.0006
                       Mean reward: 128.33
               Mean episode length: 977.75
       Episode_Reward/keep_balance: 0.9668
     Episode_Reward/rew_lin_vel_xy: 5.9638
      Episode_Reward/rew_ang_vel_z: 2.4060
    Episode_Reward/pen_base_height: -0.3192
      Episode_Reward/pen_lin_vel_z: -0.0415
     Episode_Reward/pen_ang_vel_xy: -0.1741
   Episode_Reward/pen_joint_torque: -0.2308
    Episode_Reward/pen_joint_accel: -0.1228
    Episode_Reward/pen_action_rate: -0.1177
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0591
   Episode_Reward/pen_joint_powers: -0.0910
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2525
Episode_Reward/pen_flat_orientation: -0.1076
  Episode_Reward/pen_feet_distance: -0.0211
Episode_Reward/pen_feet_regulation: -0.4720
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.9296
Metrics/base_velocity/error_vel_xy: 0.9904
Metrics/base_velocity/error_vel_yaw: 1.3185
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 1.10s
                        Total time: 1482.23s
                               ETA: 1788.5s

################################################################################
                     [1m Learning iteration 1360/3000 [0m                     

                       Computation: 89088 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.5923
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8735
                     Learning rate: 0.0006
                       Mean reward: 129.59
               Mean episode length: 966.37
       Episode_Reward/keep_balance: 0.9548
     Episode_Reward/rew_lin_vel_xy: 5.9127
      Episode_Reward/rew_ang_vel_z: 2.4462
    Episode_Reward/pen_base_height: -0.2963
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1669
   Episode_Reward/pen_joint_torque: -0.2233
    Episode_Reward/pen_joint_accel: -0.1155
    Episode_Reward/pen_action_rate: -0.1138
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2434
Episode_Reward/pen_flat_orientation: -0.1048
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4502
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.9124
Metrics/base_velocity/error_vel_xy: 0.9759
Metrics/base_velocity/error_vel_yaw: 1.2311
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 1.10s
                        Total time: 1483.33s
                               ETA: 1787.4s

################################################################################
                     [1m Learning iteration 1361/3000 [0m                     

                       Computation: 90734 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.6921
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8727
                     Learning rate: 0.0006
                       Mean reward: 129.47
               Mean episode length: 990.80
       Episode_Reward/keep_balance: 0.9923
     Episode_Reward/rew_lin_vel_xy: 6.1863
      Episode_Reward/rew_ang_vel_z: 2.4802
    Episode_Reward/pen_base_height: -0.3131
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1751
   Episode_Reward/pen_joint_torque: -0.2274
    Episode_Reward/pen_joint_accel: -0.1151
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2552
Episode_Reward/pen_flat_orientation: -0.1031
  Episode_Reward/pen_feet_distance: -0.0163
Episode_Reward/pen_feet_regulation: -0.4813
   Episode_Reward/foot_landing_vel: -0.1398
   Episode_Reward/test_gait_reward: -0.9462
Metrics/base_velocity/error_vel_xy: 0.9987
Metrics/base_velocity/error_vel_yaw: 1.3380
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 1.08s
                        Total time: 1484.41s
                               ETA: 1786.3s

################################################################################
                     [1m Learning iteration 1362/3000 [0m                     

                       Computation: 90796 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.5595
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8713
                     Learning rate: 0.0009
                       Mean reward: 126.41
               Mean episode length: 979.94
       Episode_Reward/keep_balance: 0.9812
     Episode_Reward/rew_lin_vel_xy: 6.0125
      Episode_Reward/rew_ang_vel_z: 2.4361
    Episode_Reward/pen_base_height: -0.3108
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1791
   Episode_Reward/pen_joint_torque: -0.2348
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0608
   Episode_Reward/pen_joint_powers: -0.0932
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2573
Episode_Reward/pen_flat_orientation: -0.1119
  Episode_Reward/pen_feet_distance: -0.0204
Episode_Reward/pen_feet_regulation: -0.4990
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.9470
Metrics/base_velocity/error_vel_xy: 1.0420
Metrics/base_velocity/error_vel_yaw: 1.3440
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 1.08s
                        Total time: 1485.49s
                               ETA: 1785.2s

################################################################################
                     [1m Learning iteration 1363/3000 [0m                     

                       Computation: 89817 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.5468
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8722
                     Learning rate: 0.0006
                       Mean reward: 132.17
               Mean episode length: 992.47
       Episode_Reward/keep_balance: 0.9896
     Episode_Reward/rew_lin_vel_xy: 6.1113
      Episode_Reward/rew_ang_vel_z: 2.4974
    Episode_Reward/pen_base_height: -0.3017
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1734
   Episode_Reward/pen_joint_torque: -0.2303
    Episode_Reward/pen_joint_accel: -0.1104
    Episode_Reward/pen_action_rate: -0.1179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2519
Episode_Reward/pen_flat_orientation: -0.0984
  Episode_Reward/pen_feet_distance: -0.0181
Episode_Reward/pen_feet_regulation: -0.4593
   Episode_Reward/foot_landing_vel: -0.1395
   Episode_Reward/test_gait_reward: -0.9360
Metrics/base_velocity/error_vel_xy: 1.0138
Metrics/base_velocity/error_vel_yaw: 1.3051
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 1.09s
                        Total time: 1486.59s
                               ETA: 1784.1s

################################################################################
                     [1m Learning iteration 1364/3000 [0m                     

                       Computation: 90229 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.6532
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8746
                     Learning rate: 0.0009
                       Mean reward: 128.01
               Mean episode length: 983.28
       Episode_Reward/keep_balance: 0.9877
     Episode_Reward/rew_lin_vel_xy: 6.1084
      Episode_Reward/rew_ang_vel_z: 2.4914
    Episode_Reward/pen_base_height: -0.3149
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1691
   Episode_Reward/pen_joint_torque: -0.2339
    Episode_Reward/pen_joint_accel: -0.1071
    Episode_Reward/pen_action_rate: -0.1174
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0899
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2517
Episode_Reward/pen_flat_orientation: -0.1067
  Episode_Reward/pen_feet_distance: -0.0189
Episode_Reward/pen_feet_regulation: -0.4629
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9376
Metrics/base_velocity/error_vel_xy: 1.0203
Metrics/base_velocity/error_vel_yaw: 1.3048
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 1.09s
                        Total time: 1487.68s
                               ETA: 1783.0s

################################################################################
                     [1m Learning iteration 1365/3000 [0m                     

                       Computation: 90097 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.6845
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8749
                     Learning rate: 0.0006
                       Mean reward: 128.36
               Mean episode length: 978.09
       Episode_Reward/keep_balance: 0.9852
     Episode_Reward/rew_lin_vel_xy: 6.0445
      Episode_Reward/rew_ang_vel_z: 2.4898
    Episode_Reward/pen_base_height: -0.3204
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1714
   Episode_Reward/pen_joint_torque: -0.2360
    Episode_Reward/pen_joint_accel: -0.1185
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2527
Episode_Reward/pen_flat_orientation: -0.1051
  Episode_Reward/pen_feet_distance: -0.0222
Episode_Reward/pen_feet_regulation: -0.4700
   Episode_Reward/foot_landing_vel: -0.1440
   Episode_Reward/test_gait_reward: -0.9353
Metrics/base_velocity/error_vel_xy: 1.0292
Metrics/base_velocity/error_vel_yaw: 1.3076
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 1.09s
                        Total time: 1488.77s
                               ETA: 1781.9s

################################################################################
                     [1m Learning iteration 1366/3000 [0m                     

                       Computation: 88654 steps/s (collection: 0.984s, learning 0.125s)
               Value function loss: 0.5704
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8765
                     Learning rate: 0.0006
                       Mean reward: 124.14
               Mean episode length: 936.62
       Episode_Reward/keep_balance: 0.9479
     Episode_Reward/rew_lin_vel_xy: 5.8470
      Episode_Reward/rew_ang_vel_z: 2.3756
    Episode_Reward/pen_base_height: -0.3022
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1666
   Episode_Reward/pen_joint_torque: -0.2293
    Episode_Reward/pen_joint_accel: -0.1122
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2451
Episode_Reward/pen_flat_orientation: -0.1080
  Episode_Reward/pen_feet_distance: -0.0160
Episode_Reward/pen_feet_regulation: -0.4456
   Episode_Reward/foot_landing_vel: -0.1356
   Episode_Reward/test_gait_reward: -0.9071
Metrics/base_velocity/error_vel_xy: 0.9768
Metrics/base_velocity/error_vel_yaw: 1.2784
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 1.11s
                        Total time: 1489.88s
                               ETA: 1780.9s

################################################################################
                     [1m Learning iteration 1367/3000 [0m                     

                       Computation: 90654 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.6493
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8767
                     Learning rate: 0.0004
                       Mean reward: 133.79
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.2238
      Episode_Reward/rew_ang_vel_z: 2.5372
    Episode_Reward/pen_base_height: -0.2879
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1687
   Episode_Reward/pen_joint_torque: -0.2353
    Episode_Reward/pen_joint_accel: -0.1238
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2552
Episode_Reward/pen_flat_orientation: -0.1015
  Episode_Reward/pen_feet_distance: -0.0173
Episode_Reward/pen_feet_regulation: -0.4667
   Episode_Reward/foot_landing_vel: -0.1397
   Episode_Reward/test_gait_reward: -0.9401
Metrics/base_velocity/error_vel_xy: 1.0007
Metrics/base_velocity/error_vel_yaw: 1.3072
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 1.08s
                        Total time: 1490.96s
                               ETA: 1779.8s

################################################################################
                     [1m Learning iteration 1368/3000 [0m                     

                       Computation: 90391 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.6200
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8763
                     Learning rate: 0.0006
                       Mean reward: 123.78
               Mean episode length: 957.52
       Episode_Reward/keep_balance: 0.9554
     Episode_Reward/rew_lin_vel_xy: 5.8614
      Episode_Reward/rew_ang_vel_z: 2.3815
    Episode_Reward/pen_base_height: -0.2864
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1700
   Episode_Reward/pen_joint_torque: -0.2125
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0855
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2494
Episode_Reward/pen_flat_orientation: -0.1078
  Episode_Reward/pen_feet_distance: -0.0187
Episode_Reward/pen_feet_regulation: -0.4507
   Episode_Reward/foot_landing_vel: -0.1341
   Episode_Reward/test_gait_reward: -0.9117
Metrics/base_velocity/error_vel_xy: 0.9989
Metrics/base_velocity/error_vel_yaw: 1.3067
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 1.09s
                        Total time: 1492.05s
                               ETA: 1778.7s

################################################################################
                     [1m Learning iteration 1369/3000 [0m                     

                       Computation: 89569 steps/s (collection: 0.976s, learning 0.122s)
               Value function loss: 0.5972
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8763
                     Learning rate: 0.0006
                       Mean reward: 130.32
               Mean episode length: 990.57
       Episode_Reward/keep_balance: 0.9869
     Episode_Reward/rew_lin_vel_xy: 6.0771
      Episode_Reward/rew_ang_vel_z: 2.4480
    Episode_Reward/pen_base_height: -0.3017
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1782
   Episode_Reward/pen_joint_torque: -0.2219
    Episode_Reward/pen_joint_accel: -0.1182
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2585
Episode_Reward/pen_flat_orientation: -0.1029
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.4745
   Episode_Reward/foot_landing_vel: -0.1320
   Episode_Reward/test_gait_reward: -0.9423
Metrics/base_velocity/error_vel_xy: 1.0239
Metrics/base_velocity/error_vel_yaw: 1.3636
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 1.10s
                        Total time: 1493.15s
                               ETA: 1777.6s

################################################################################
                     [1m Learning iteration 1370/3000 [0m                     

                       Computation: 91044 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.6769
                    Surrogate loss: -0.0013
             Mean action noise std: 0.8771
                     Learning rate: 0.0001
                       Mean reward: 129.48
               Mean episode length: 975.55
       Episode_Reward/keep_balance: 0.9728
     Episode_Reward/rew_lin_vel_xy: 6.0561
      Episode_Reward/rew_ang_vel_z: 2.4436
    Episode_Reward/pen_base_height: -0.3024
      Episode_Reward/pen_lin_vel_z: -0.0399
     Episode_Reward/pen_ang_vel_xy: -0.1638
   Episode_Reward/pen_joint_torque: -0.2416
    Episode_Reward/pen_joint_accel: -0.1113
    Episode_Reward/pen_action_rate: -0.1172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2493
Episode_Reward/pen_flat_orientation: -0.1050
  Episode_Reward/pen_feet_distance: -0.0202
Episode_Reward/pen_feet_regulation: -0.4649
   Episode_Reward/foot_landing_vel: -0.1470
   Episode_Reward/test_gait_reward: -0.9275
Metrics/base_velocity/error_vel_xy: 0.9912
Metrics/base_velocity/error_vel_yaw: 1.3074
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 1.08s
                        Total time: 1494.23s
                               ETA: 1776.5s

################################################################################
                     [1m Learning iteration 1371/3000 [0m                     

                       Computation: 91535 steps/s (collection: 0.949s, learning 0.125s)
               Value function loss: 0.6750
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8774
                     Learning rate: 0.0001
                       Mean reward: 122.42
               Mean episode length: 957.01
       Episode_Reward/keep_balance: 0.9326
     Episode_Reward/rew_lin_vel_xy: 5.6310
      Episode_Reward/rew_ang_vel_z: 2.3108
    Episode_Reward/pen_base_height: -0.3048
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1701
   Episode_Reward/pen_joint_torque: -0.2179
    Episode_Reward/pen_joint_accel: -0.1095
    Episode_Reward/pen_action_rate: -0.1133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2425
Episode_Reward/pen_flat_orientation: -0.1093
  Episode_Reward/pen_feet_distance: -0.0181
Episode_Reward/pen_feet_regulation: -0.4571
   Episode_Reward/foot_landing_vel: -0.1350
   Episode_Reward/test_gait_reward: -0.8969
Metrics/base_velocity/error_vel_xy: 1.0435
Metrics/base_velocity/error_vel_yaw: 1.3026
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 1.07s
                        Total time: 1495.30s
                               ETA: 1775.4s

################################################################################
                     [1m Learning iteration 1372/3000 [0m                     

                       Computation: 89623 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.6014
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8772
                     Learning rate: 0.0003
                       Mean reward: 126.50
               Mean episode length: 963.45
       Episode_Reward/keep_balance: 0.9660
     Episode_Reward/rew_lin_vel_xy: 5.9552
      Episode_Reward/rew_ang_vel_z: 2.3974
    Episode_Reward/pen_base_height: -0.2859
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1720
   Episode_Reward/pen_joint_torque: -0.2170
    Episode_Reward/pen_joint_accel: -0.1110
    Episode_Reward/pen_action_rate: -0.1167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2515
Episode_Reward/pen_flat_orientation: -0.1106
  Episode_Reward/pen_feet_distance: -0.0173
Episode_Reward/pen_feet_regulation: -0.4572
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.9163
Metrics/base_velocity/error_vel_xy: 0.9831
Metrics/base_velocity/error_vel_yaw: 1.3208
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 1.10s
                        Total time: 1496.40s
                               ETA: 1774.3s

################################################################################
                     [1m Learning iteration 1373/3000 [0m                     

                       Computation: 90807 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.5966
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8762
                     Learning rate: 0.0003
                       Mean reward: 126.79
               Mean episode length: 977.23
       Episode_Reward/keep_balance: 0.9689
     Episode_Reward/rew_lin_vel_xy: 5.9065
      Episode_Reward/rew_ang_vel_z: 2.4080
    Episode_Reward/pen_base_height: -0.2965
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.1779
   Episode_Reward/pen_joint_torque: -0.2275
    Episode_Reward/pen_joint_accel: -0.1133
    Episode_Reward/pen_action_rate: -0.1184
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0910
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2523
Episode_Reward/pen_flat_orientation: -0.1121
  Episode_Reward/pen_feet_distance: -0.0185
Episode_Reward/pen_feet_regulation: -0.4820
   Episode_Reward/foot_landing_vel: -0.1491
   Episode_Reward/test_gait_reward: -0.9242
Metrics/base_velocity/error_vel_xy: 1.0647
Metrics/base_velocity/error_vel_yaw: 1.3452
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 1.08s
                        Total time: 1497.48s
                               ETA: 1773.2s

################################################################################
                     [1m Learning iteration 1374/3000 [0m                     

                       Computation: 89433 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.6068
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8762
                     Learning rate: 0.0004
                       Mean reward: 124.28
               Mean episode length: 967.39
       Episode_Reward/keep_balance: 0.9749
     Episode_Reward/rew_lin_vel_xy: 6.0050
      Episode_Reward/rew_ang_vel_z: 2.4122
    Episode_Reward/pen_base_height: -0.3039
      Episode_Reward/pen_lin_vel_z: -0.0422
     Episode_Reward/pen_ang_vel_xy: -0.1720
   Episode_Reward/pen_joint_torque: -0.2353
    Episode_Reward/pen_joint_accel: -0.1083
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2535
Episode_Reward/pen_flat_orientation: -0.1077
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4803
   Episode_Reward/foot_landing_vel: -0.1373
   Episode_Reward/test_gait_reward: -0.9326
Metrics/base_velocity/error_vel_xy: 1.0166
Metrics/base_velocity/error_vel_yaw: 1.3377
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 1.10s
                        Total time: 1498.58s
                               ETA: 1772.1s

################################################################################
                     [1m Learning iteration 1375/3000 [0m                     

                       Computation: 90307 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 0.5721
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8756
                     Learning rate: 0.0006
                       Mean reward: 127.44
               Mean episode length: 980.59
       Episode_Reward/keep_balance: 0.9814
     Episode_Reward/rew_lin_vel_xy: 6.0515
      Episode_Reward/rew_ang_vel_z: 2.4738
    Episode_Reward/pen_base_height: -0.3071
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1725
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2524
Episode_Reward/pen_flat_orientation: -0.1047
  Episode_Reward/pen_feet_distance: -0.0181
Episode_Reward/pen_feet_regulation: -0.4929
   Episode_Reward/foot_landing_vel: -0.1364
   Episode_Reward/test_gait_reward: -0.9340
Metrics/base_velocity/error_vel_xy: 1.0209
Metrics/base_velocity/error_vel_yaw: 1.3135
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 1.09s
                        Total time: 1499.67s
                               ETA: 1771.0s

################################################################################
                     [1m Learning iteration 1376/3000 [0m                     

                       Computation: 91647 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.5608
                    Surrogate loss: -0.0005
             Mean action noise std: 0.8761
                     Learning rate: 0.0002
                       Mean reward: 128.43
               Mean episode length: 982.92
       Episode_Reward/keep_balance: 0.9800
     Episode_Reward/rew_lin_vel_xy: 5.9908
      Episode_Reward/rew_ang_vel_z: 2.4279
    Episode_Reward/pen_base_height: -0.2999
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1773
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1239
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0617
   Episode_Reward/pen_joint_powers: -0.0917
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2564
Episode_Reward/pen_flat_orientation: -0.1044
  Episode_Reward/pen_feet_distance: -0.0178
Episode_Reward/pen_feet_regulation: -0.4927
   Episode_Reward/foot_landing_vel: -0.1515
   Episode_Reward/test_gait_reward: -0.9356
Metrics/base_velocity/error_vel_xy: 1.0461
Metrics/base_velocity/error_vel_yaw: 1.3610
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 1.07s
                        Total time: 1500.74s
                               ETA: 1769.9s

################################################################################
                     [1m Learning iteration 1377/3000 [0m                     

                       Computation: 89489 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.5524
                    Surrogate loss: -0.0055
             Mean action noise std: 0.8746
                     Learning rate: 0.0004
                       Mean reward: 131.35
               Mean episode length: 990.29
       Episode_Reward/keep_balance: 0.9940
     Episode_Reward/rew_lin_vel_xy: 6.1894
      Episode_Reward/rew_ang_vel_z: 2.4723
    Episode_Reward/pen_base_height: -0.2950
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.1768
   Episode_Reward/pen_joint_torque: -0.2320
    Episode_Reward/pen_joint_accel: -0.1166
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0596
   Episode_Reward/pen_joint_powers: -0.0908
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2601
Episode_Reward/pen_flat_orientation: -0.1014
  Episode_Reward/pen_feet_distance: -0.0159
Episode_Reward/pen_feet_regulation: -0.4818
   Episode_Reward/foot_landing_vel: -0.1465
   Episode_Reward/test_gait_reward: -0.9467
Metrics/base_velocity/error_vel_xy: 1.0050
Metrics/base_velocity/error_vel_yaw: 1.3534
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 1.10s
                        Total time: 1501.84s
                               ETA: 1768.9s

################################################################################
                     [1m Learning iteration 1378/3000 [0m                     

                       Computation: 89022 steps/s (collection: 0.981s, learning 0.123s)
               Value function loss: 0.6148
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8742
                     Learning rate: 0.0002
                       Mean reward: 127.12
               Mean episode length: 977.60
       Episode_Reward/keep_balance: 0.9831
     Episode_Reward/rew_lin_vel_xy: 6.0187
      Episode_Reward/rew_ang_vel_z: 2.4510
    Episode_Reward/pen_base_height: -0.3037
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.1797
   Episode_Reward/pen_joint_torque: -0.2321
    Episode_Reward/pen_joint_accel: -0.1096
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0917
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2560
Episode_Reward/pen_flat_orientation: -0.1066
  Episode_Reward/pen_feet_distance: -0.0148
Episode_Reward/pen_feet_regulation: -0.4772
   Episode_Reward/foot_landing_vel: -0.1429
   Episode_Reward/test_gait_reward: -0.9361
Metrics/base_velocity/error_vel_xy: 1.0402
Metrics/base_velocity/error_vel_yaw: 1.3407
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 1.10s
                        Total time: 1502.94s
                               ETA: 1767.8s

################################################################################
                     [1m Learning iteration 1379/3000 [0m                     

                       Computation: 89623 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 0.6680
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8736
                     Learning rate: 0.0003
                       Mean reward: 129.72
               Mean episode length: 989.14
       Episode_Reward/keep_balance: 0.9914
     Episode_Reward/rew_lin_vel_xy: 6.1769
      Episode_Reward/rew_ang_vel_z: 2.4137
    Episode_Reward/pen_base_height: -0.2988
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1779
   Episode_Reward/pen_joint_torque: -0.2247
    Episode_Reward/pen_joint_accel: -0.1190
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0603
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2604
Episode_Reward/pen_flat_orientation: -0.1017
  Episode_Reward/pen_feet_distance: -0.0168
Episode_Reward/pen_feet_regulation: -0.4826
   Episode_Reward/foot_landing_vel: -0.1446
   Episode_Reward/test_gait_reward: -0.9446
Metrics/base_velocity/error_vel_xy: 0.9910
Metrics/base_velocity/error_vel_yaw: 1.3935
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 1.10s
                        Total time: 1504.04s
                               ETA: 1766.7s

################################################################################
                     [1m Learning iteration 1380/3000 [0m                     

                       Computation: 89985 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.6336
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8741
                     Learning rate: 0.0004
                       Mean reward: 127.88
               Mean episode length: 974.46
       Episode_Reward/keep_balance: 0.9574
     Episode_Reward/rew_lin_vel_xy: 5.8782
      Episode_Reward/rew_ang_vel_z: 2.4115
    Episode_Reward/pen_base_height: -0.2973
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1703
   Episode_Reward/pen_joint_torque: -0.2243
    Episode_Reward/pen_joint_accel: -0.1122
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2488
Episode_Reward/pen_flat_orientation: -0.1064
  Episode_Reward/pen_feet_distance: -0.0148
Episode_Reward/pen_feet_regulation: -0.4658
   Episode_Reward/foot_landing_vel: -0.1343
   Episode_Reward/test_gait_reward: -0.9107
Metrics/base_velocity/error_vel_xy: 1.0085
Metrics/base_velocity/error_vel_yaw: 1.2808
      Episode_Termination/time_out: 4.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 1.09s
                        Total time: 1505.13s
                               ETA: 1765.6s

################################################################################
                     [1m Learning iteration 1381/3000 [0m                     

                       Computation: 90062 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 0.6966
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8755
                     Learning rate: 0.0003
                       Mean reward: 128.95
               Mean episode length: 976.00
       Episode_Reward/keep_balance: 0.9787
     Episode_Reward/rew_lin_vel_xy: 6.0348
      Episode_Reward/rew_ang_vel_z: 2.4464
    Episode_Reward/pen_base_height: -0.3041
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1725
   Episode_Reward/pen_joint_torque: -0.2331
    Episode_Reward/pen_joint_accel: -0.1167
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2540
Episode_Reward/pen_flat_orientation: -0.1091
  Episode_Reward/pen_feet_distance: -0.0162
Episode_Reward/pen_feet_regulation: -0.4711
   Episode_Reward/foot_landing_vel: -0.1430
   Episode_Reward/test_gait_reward: -0.9266
Metrics/base_velocity/error_vel_xy: 1.0187
Metrics/base_velocity/error_vel_yaw: 1.3196
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 1.09s
                        Total time: 1506.23s
                               ETA: 1764.5s

################################################################################
                     [1m Learning iteration 1382/3000 [0m                     

                       Computation: 90492 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.5891
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8752
                     Learning rate: 0.0001
                       Mean reward: 121.12
               Mean episode length: 939.55
       Episode_Reward/keep_balance: 0.9496
     Episode_Reward/rew_lin_vel_xy: 5.8519
      Episode_Reward/rew_ang_vel_z: 2.3752
    Episode_Reward/pen_base_height: -0.3004
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1684
   Episode_Reward/pen_joint_torque: -0.2333
    Episode_Reward/pen_joint_accel: -0.1060
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2453
Episode_Reward/pen_flat_orientation: -0.1104
  Episode_Reward/pen_feet_distance: -0.0177
Episode_Reward/pen_feet_regulation: -0.4607
   Episode_Reward/foot_landing_vel: -0.1419
   Episode_Reward/test_gait_reward: -0.9040
Metrics/base_velocity/error_vel_xy: 0.9952
Metrics/base_velocity/error_vel_yaw: 1.2905
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 1.09s
                        Total time: 1507.31s
                               ETA: 1763.4s

################################################################################
                     [1m Learning iteration 1383/3000 [0m                     

                       Computation: 91090 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.6505
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8764
                     Learning rate: 0.0004
                       Mean reward: 126.43
               Mean episode length: 988.08
       Episode_Reward/keep_balance: 0.9870
     Episode_Reward/rew_lin_vel_xy: 5.9945
      Episode_Reward/rew_ang_vel_z: 2.4469
    Episode_Reward/pen_base_height: -0.3060
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.1792
   Episode_Reward/pen_joint_torque: -0.2391
    Episode_Reward/pen_joint_accel: -0.1097
    Episode_Reward/pen_action_rate: -0.1213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0937
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2575
Episode_Reward/pen_flat_orientation: -0.1073
  Episode_Reward/pen_feet_distance: -0.0172
Episode_Reward/pen_feet_regulation: -0.4940
   Episode_Reward/foot_landing_vel: -0.1517
   Episode_Reward/test_gait_reward: -0.9439
Metrics/base_velocity/error_vel_xy: 1.0708
Metrics/base_velocity/error_vel_yaw: 1.3545
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 1.08s
                        Total time: 1508.39s
                               ETA: 1762.3s

################################################################################
                     [1m Learning iteration 1384/3000 [0m                     

                       Computation: 89410 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.6949
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8775
                     Learning rate: 0.0009
                       Mean reward: 125.11
               Mean episode length: 957.70
       Episode_Reward/keep_balance: 0.9526
     Episode_Reward/rew_lin_vel_xy: 5.7712
      Episode_Reward/rew_ang_vel_z: 2.3491
    Episode_Reward/pen_base_height: -0.2900
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1728
   Episode_Reward/pen_joint_torque: -0.2267
    Episode_Reward/pen_joint_accel: -0.1102
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0897
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2480
Episode_Reward/pen_flat_orientation: -0.1109
  Episode_Reward/pen_feet_distance: -0.0163
Episode_Reward/pen_feet_regulation: -0.4760
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.9050
Metrics/base_velocity/error_vel_xy: 1.0380
Metrics/base_velocity/error_vel_yaw: 1.3160
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 1.10s
                        Total time: 1509.49s
                               ETA: 1761.3s

################################################################################
                     [1m Learning iteration 1385/3000 [0m                     

                       Computation: 89747 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.6866
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8775
                     Learning rate: 0.0004
                       Mean reward: 126.89
               Mean episode length: 967.96
       Episode_Reward/keep_balance: 0.9718
     Episode_Reward/rew_lin_vel_xy: 5.9373
      Episode_Reward/rew_ang_vel_z: 2.4284
    Episode_Reward/pen_base_height: -0.2960
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1665
   Episode_Reward/pen_joint_torque: -0.2387
    Episode_Reward/pen_joint_accel: -0.1016
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2502
Episode_Reward/pen_flat_orientation: -0.1055
  Episode_Reward/pen_feet_distance: -0.0168
Episode_Reward/pen_feet_regulation: -0.4669
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.9223
Metrics/base_velocity/error_vel_xy: 1.0366
Metrics/base_velocity/error_vel_yaw: 1.3258
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 1.10s
                        Total time: 1510.59s
                               ETA: 1760.2s

################################################################################
                     [1m Learning iteration 1386/3000 [0m                     

                       Computation: 89272 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.6668
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8764
                     Learning rate: 0.0009
                       Mean reward: 128.01
               Mean episode length: 968.02
       Episode_Reward/keep_balance: 0.9725
     Episode_Reward/rew_lin_vel_xy: 6.0353
      Episode_Reward/rew_ang_vel_z: 2.4490
    Episode_Reward/pen_base_height: -0.2875
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1669
   Episode_Reward/pen_joint_torque: -0.2174
    Episode_Reward/pen_joint_accel: -0.1077
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2494
Episode_Reward/pen_flat_orientation: -0.1012
  Episode_Reward/pen_feet_distance: -0.0160
Episode_Reward/pen_feet_regulation: -0.4577
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.9237
Metrics/base_velocity/error_vel_xy: 0.9932
Metrics/base_velocity/error_vel_yaw: 1.2997
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 1.10s
                        Total time: 1511.69s
                               ETA: 1759.1s

################################################################################
                     [1m Learning iteration 1387/3000 [0m                     

                       Computation: 91036 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.5987
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8756
                     Learning rate: 0.0006
                       Mean reward: 122.54
               Mean episode length: 950.09
       Episode_Reward/keep_balance: 0.9644
     Episode_Reward/rew_lin_vel_xy: 5.8759
      Episode_Reward/rew_ang_vel_z: 2.3866
    Episode_Reward/pen_base_height: -0.3061
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1679
   Episode_Reward/pen_joint_torque: -0.2251
    Episode_Reward/pen_joint_accel: -0.1081
    Episode_Reward/pen_action_rate: -0.1176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2503
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0182
Episode_Reward/pen_feet_regulation: -0.4730
   Episode_Reward/foot_landing_vel: -0.1302
   Episode_Reward/test_gait_reward: -0.9225
Metrics/base_velocity/error_vel_xy: 1.0274
Metrics/base_velocity/error_vel_yaw: 1.3421
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 1.08s
                        Total time: 1512.77s
                               ETA: 1758.0s

################################################################################
                     [1m Learning iteration 1388/3000 [0m                     

                       Computation: 88634 steps/s (collection: 0.985s, learning 0.124s)
               Value function loss: 0.6631
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8762
                     Learning rate: 0.0006
                       Mean reward: 128.33
               Mean episode length: 977.08
       Episode_Reward/keep_balance: 0.9784
     Episode_Reward/rew_lin_vel_xy: 6.0764
      Episode_Reward/rew_ang_vel_z: 2.4511
    Episode_Reward/pen_base_height: -0.2976
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1700
   Episode_Reward/pen_joint_torque: -0.2339
    Episode_Reward/pen_joint_accel: -0.1077
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2554
Episode_Reward/pen_flat_orientation: -0.1051
  Episode_Reward/pen_feet_distance: -0.0160
Episode_Reward/pen_feet_regulation: -0.4794
   Episode_Reward/foot_landing_vel: -0.1361
   Episode_Reward/test_gait_reward: -0.9340
Metrics/base_velocity/error_vel_xy: 0.9941
Metrics/base_velocity/error_vel_yaw: 1.3279
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 1.11s
                        Total time: 1513.88s
                               ETA: 1756.9s

################################################################################
                     [1m Learning iteration 1389/3000 [0m                     

                       Computation: 89020 steps/s (collection: 0.982s, learning 0.122s)
               Value function loss: 0.6285
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8762
                     Learning rate: 0.0004
                       Mean reward: 123.78
               Mean episode length: 955.23
       Episode_Reward/keep_balance: 0.9205
     Episode_Reward/rew_lin_vel_xy: 5.6205
      Episode_Reward/rew_ang_vel_z: 2.2851
    Episode_Reward/pen_base_height: -0.3058
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.1689
   Episode_Reward/pen_joint_torque: -0.2281
    Episode_Reward/pen_joint_accel: -0.1035
    Episode_Reward/pen_action_rate: -0.1130
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.2420
Episode_Reward/pen_flat_orientation: -0.1184
  Episode_Reward/pen_feet_distance: -0.0170
Episode_Reward/pen_feet_regulation: -0.4444
   Episode_Reward/foot_landing_vel: -0.1311
   Episode_Reward/test_gait_reward: -0.8760
Metrics/base_velocity/error_vel_xy: 0.9900
Metrics/base_velocity/error_vel_yaw: 1.2786
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 1.10s
                        Total time: 1514.98s
                               ETA: 1755.9s

################################################################################
                     [1m Learning iteration 1390/3000 [0m                     

                       Computation: 88564 steps/s (collection: 0.986s, learning 0.124s)
               Value function loss: 0.5911
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8757
                     Learning rate: 0.0009
                       Mean reward: 130.39
               Mean episode length: 988.40
       Episode_Reward/keep_balance: 0.9948
     Episode_Reward/rew_lin_vel_xy: 6.1336
      Episode_Reward/rew_ang_vel_z: 2.4602
    Episode_Reward/pen_base_height: -0.2981
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1715
   Episode_Reward/pen_joint_torque: -0.2315
    Episode_Reward/pen_joint_accel: -0.1077
    Episode_Reward/pen_action_rate: -0.1214
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0595
   Episode_Reward/pen_joint_powers: -0.0912
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2596
Episode_Reward/pen_flat_orientation: -0.1086
  Episode_Reward/pen_feet_distance: -0.0167
Episode_Reward/pen_feet_regulation: -0.4878
   Episode_Reward/foot_landing_vel: -0.1434
   Episode_Reward/test_gait_reward: -0.9416
Metrics/base_velocity/error_vel_xy: 1.0271
Metrics/base_velocity/error_vel_yaw: 1.3904
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 1.11s
                        Total time: 1516.09s
                               ETA: 1754.8s

################################################################################
                     [1m Learning iteration 1391/3000 [0m                     

                       Computation: 88279 steps/s (collection: 0.989s, learning 0.125s)
               Value function loss: 0.6536
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8762
                     Learning rate: 0.0006
                       Mean reward: 130.48
               Mean episode length: 991.91
       Episode_Reward/keep_balance: 0.9946
     Episode_Reward/rew_lin_vel_xy: 6.1342
      Episode_Reward/rew_ang_vel_z: 2.4882
    Episode_Reward/pen_base_height: -0.2833
      Episode_Reward/pen_lin_vel_z: -0.0406
     Episode_Reward/pen_ang_vel_xy: -0.1771
   Episode_Reward/pen_joint_torque: -0.2180
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1189
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2594
Episode_Reward/pen_flat_orientation: -0.0959
  Episode_Reward/pen_feet_distance: -0.0142
Episode_Reward/pen_feet_regulation: -0.4582
   Episode_Reward/foot_landing_vel: -0.1384
   Episode_Reward/test_gait_reward: -0.9387
Metrics/base_velocity/error_vel_xy: 1.0280
Metrics/base_velocity/error_vel_yaw: 1.3503
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 1.11s
                        Total time: 1517.20s
                               ETA: 1753.7s

################################################################################
                     [1m Learning iteration 1392/3000 [0m                     

                       Computation: 89487 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.5513
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8757
                     Learning rate: 0.0009
                       Mean reward: 130.63
               Mean episode length: 976.61
       Episode_Reward/keep_balance: 0.9772
     Episode_Reward/rew_lin_vel_xy: 6.0769
      Episode_Reward/rew_ang_vel_z: 2.4416
    Episode_Reward/pen_base_height: -0.2820
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1661
   Episode_Reward/pen_joint_torque: -0.2230
    Episode_Reward/pen_joint_accel: -0.1187
    Episode_Reward/pen_action_rate: -0.1174
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2542
Episode_Reward/pen_flat_orientation: -0.0995
  Episode_Reward/pen_feet_distance: -0.0135
Episode_Reward/pen_feet_regulation: -0.4655
   Episode_Reward/foot_landing_vel: -0.1371
   Episode_Reward/test_gait_reward: -0.9241
Metrics/base_velocity/error_vel_xy: 0.9812
Metrics/base_velocity/error_vel_yaw: 1.3334
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 1.10s
                        Total time: 1518.30s
                               ETA: 1752.6s

################################################################################
                     [1m Learning iteration 1393/3000 [0m                     

                       Computation: 82685 steps/s (collection: 1.064s, learning 0.125s)
               Value function loss: 0.7052
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8756
                     Learning rate: 0.0004
                       Mean reward: 125.23
               Mean episode length: 963.17
       Episode_Reward/keep_balance: 0.9545
     Episode_Reward/rew_lin_vel_xy: 5.9252
      Episode_Reward/rew_ang_vel_z: 2.3901
    Episode_Reward/pen_base_height: -0.3036
      Episode_Reward/pen_lin_vel_z: -0.0420
     Episode_Reward/pen_ang_vel_xy: -0.1731
   Episode_Reward/pen_joint_torque: -0.2291
    Episode_Reward/pen_joint_accel: -0.1044
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2512
Episode_Reward/pen_flat_orientation: -0.1088
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4898
   Episode_Reward/foot_landing_vel: -0.1481
   Episode_Reward/test_gait_reward: -0.9120
Metrics/base_velocity/error_vel_xy: 0.9839
Metrics/base_velocity/error_vel_yaw: 1.2982
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 1.19s
                        Total time: 1519.49s
                               ETA: 1751.7s

################################################################################
                     [1m Learning iteration 1394/3000 [0m                     

                       Computation: 89413 steps/s (collection: 0.977s, learning 0.122s)
               Value function loss: 0.6281
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8750
                     Learning rate: 0.0003
                       Mean reward: 126.87
               Mean episode length: 972.02
       Episode_Reward/keep_balance: 0.9883
     Episode_Reward/rew_lin_vel_xy: 6.1024
      Episode_Reward/rew_ang_vel_z: 2.4688
    Episode_Reward/pen_base_height: -0.3150
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1711
   Episode_Reward/pen_joint_torque: -0.2500
    Episode_Reward/pen_joint_accel: -0.1179
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0605
   Episode_Reward/pen_joint_powers: -0.0940
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2558
Episode_Reward/pen_flat_orientation: -0.1079
  Episode_Reward/pen_feet_distance: -0.0181
Episode_Reward/pen_feet_regulation: -0.5028
   Episode_Reward/foot_landing_vel: -0.1447
   Episode_Reward/test_gait_reward: -0.9477
Metrics/base_velocity/error_vel_xy: 1.0174
Metrics/base_velocity/error_vel_yaw: 1.3282
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 1.10s
                        Total time: 1520.59s
                               ETA: 1750.6s

################################################################################
                     [1m Learning iteration 1395/3000 [0m                     

                       Computation: 89147 steps/s (collection: 0.976s, learning 0.127s)
               Value function loss: 0.7233
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8761
                     Learning rate: 0.0004
                       Mean reward: 129.86
               Mean episode length: 983.51
       Episode_Reward/keep_balance: 0.9738
     Episode_Reward/rew_lin_vel_xy: 6.0159
      Episode_Reward/rew_ang_vel_z: 2.4376
    Episode_Reward/pen_base_height: -0.2881
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.1723
   Episode_Reward/pen_joint_torque: -0.2303
    Episode_Reward/pen_joint_accel: -0.1252
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2536
Episode_Reward/pen_flat_orientation: -0.0999
  Episode_Reward/pen_feet_distance: -0.0162
Episode_Reward/pen_feet_regulation: -0.4762
   Episode_Reward/foot_landing_vel: -0.1500
   Episode_Reward/test_gait_reward: -0.9130
Metrics/base_velocity/error_vel_xy: 0.9880
Metrics/base_velocity/error_vel_yaw: 1.3197
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 1.10s
                        Total time: 1521.69s
                               ETA: 1749.5s

################################################################################
                     [1m Learning iteration 1396/3000 [0m                     

                       Computation: 89545 steps/s (collection: 0.972s, learning 0.126s)
               Value function loss: 0.6157
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8768
                     Learning rate: 0.0004
                       Mean reward: 128.97
               Mean episode length: 956.62
       Episode_Reward/keep_balance: 0.9446
     Episode_Reward/rew_lin_vel_xy: 5.9008
      Episode_Reward/rew_ang_vel_z: 2.3768
    Episode_Reward/pen_base_height: -0.2889
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1595
   Episode_Reward/pen_joint_torque: -0.2210
    Episode_Reward/pen_joint_accel: -0.1070
    Episode_Reward/pen_action_rate: -0.1150
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2452
Episode_Reward/pen_flat_orientation: -0.1058
  Episode_Reward/pen_feet_distance: -0.0184
Episode_Reward/pen_feet_regulation: -0.4703
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.8992
Metrics/base_velocity/error_vel_xy: 0.9487
Metrics/base_velocity/error_vel_yaw: 1.2726
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 1.10s
                        Total time: 1522.79s
                               ETA: 1748.4s

################################################################################
                     [1m Learning iteration 1397/3000 [0m                     

                       Computation: 88892 steps/s (collection: 0.979s, learning 0.127s)
               Value function loss: 0.6469
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8757
                     Learning rate: 0.0009
                       Mean reward: 128.70
               Mean episode length: 978.50
       Episode_Reward/keep_balance: 0.9790
     Episode_Reward/rew_lin_vel_xy: 6.0706
      Episode_Reward/rew_ang_vel_z: 2.4246
    Episode_Reward/pen_base_height: -0.2966
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1664
   Episode_Reward/pen_joint_torque: -0.2310
    Episode_Reward/pen_joint_accel: -0.1146
    Episode_Reward/pen_action_rate: -0.1192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2563
Episode_Reward/pen_flat_orientation: -0.1004
  Episode_Reward/pen_feet_distance: -0.0172
Episode_Reward/pen_feet_regulation: -0.4686
   Episode_Reward/foot_landing_vel: -0.1435
   Episode_Reward/test_gait_reward: -0.9277
Metrics/base_velocity/error_vel_xy: 1.0010
Metrics/base_velocity/error_vel_yaw: 1.3512
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 1.11s
                        Total time: 1523.90s
                               ETA: 1747.4s

################################################################################
                     [1m Learning iteration 1398/3000 [0m                     

                       Computation: 89533 steps/s (collection: 0.973s, learning 0.125s)
               Value function loss: 0.7194
                    Surrogate loss: 0.0020
             Mean action noise std: 0.8759
                     Learning rate: 0.0001
                       Mean reward: 127.52
               Mean episode length: 988.05
       Episode_Reward/keep_balance: 0.9904
     Episode_Reward/rew_lin_vel_xy: 6.1384
      Episode_Reward/rew_ang_vel_z: 2.4380
    Episode_Reward/pen_base_height: -0.2948
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1736
   Episode_Reward/pen_joint_torque: -0.2337
    Episode_Reward/pen_joint_accel: -0.1106
    Episode_Reward/pen_action_rate: -0.1215
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0915
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2623
Episode_Reward/pen_flat_orientation: -0.1047
  Episode_Reward/pen_feet_distance: -0.0205
Episode_Reward/pen_feet_regulation: -0.4832
   Episode_Reward/foot_landing_vel: -0.1401
   Episode_Reward/test_gait_reward: -0.9506
Metrics/base_velocity/error_vel_xy: 1.0024
Metrics/base_velocity/error_vel_yaw: 1.3784
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 1.10s
                        Total time: 1524.99s
                               ETA: 1746.3s

################################################################################
                     [1m Learning iteration 1399/3000 [0m                     

                       Computation: 88712 steps/s (collection: 0.982s, learning 0.126s)
               Value function loss: 0.6573
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8762
                     Learning rate: 0.0003
                       Mean reward: 125.09
               Mean episode length: 953.25
       Episode_Reward/keep_balance: 0.9532
     Episode_Reward/rew_lin_vel_xy: 5.8292
      Episode_Reward/rew_ang_vel_z: 2.3905
    Episode_Reward/pen_base_height: -0.2952
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1609
   Episode_Reward/pen_joint_torque: -0.2438
    Episode_Reward/pen_joint_accel: -0.1134
    Episode_Reward/pen_action_rate: -0.1160
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2447
Episode_Reward/pen_flat_orientation: -0.1096
  Episode_Reward/pen_feet_distance: -0.0184
Episode_Reward/pen_feet_regulation: -0.4561
   Episode_Reward/foot_landing_vel: -0.1326
   Episode_Reward/test_gait_reward: -0.9014
Metrics/base_velocity/error_vel_xy: 0.9966
Metrics/base_velocity/error_vel_yaw: 1.2919
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 1.11s
                        Total time: 1526.10s
                               ETA: 1745.2s

################################################################################
                     [1m Learning iteration 1400/3000 [0m                     

                       Computation: 89276 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 0.6912
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8767
                     Learning rate: 0.0006
                       Mean reward: 128.05
               Mean episode length: 967.13
       Episode_Reward/keep_balance: 0.9667
     Episode_Reward/rew_lin_vel_xy: 6.0159
      Episode_Reward/rew_ang_vel_z: 2.4105
    Episode_Reward/pen_base_height: -0.3013
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1687
   Episode_Reward/pen_joint_torque: -0.2286
    Episode_Reward/pen_joint_accel: -0.1132
    Episode_Reward/pen_action_rate: -0.1176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2523
Episode_Reward/pen_flat_orientation: -0.1051
  Episode_Reward/pen_feet_distance: -0.0198
Episode_Reward/pen_feet_regulation: -0.4623
   Episode_Reward/foot_landing_vel: -0.1260
   Episode_Reward/test_gait_reward: -0.9158
Metrics/base_velocity/error_vel_xy: 0.9731
Metrics/base_velocity/error_vel_yaw: 1.3188
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 1.10s
                        Total time: 1527.20s
                               ETA: 1744.1s

################################################################################
                     [1m Learning iteration 1401/3000 [0m                     

                       Computation: 89836 steps/s (collection: 0.968s, learning 0.126s)
               Value function loss: 0.6946
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8782
                     Learning rate: 0.0006
                       Mean reward: 124.14
               Mean episode length: 950.03
       Episode_Reward/keep_balance: 0.9365
     Episode_Reward/rew_lin_vel_xy: 5.7777
      Episode_Reward/rew_ang_vel_z: 2.3559
    Episode_Reward/pen_base_height: -0.2908
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1635
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.1168
    Episode_Reward/pen_action_rate: -0.1143
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2433
Episode_Reward/pen_flat_orientation: -0.1092
  Episode_Reward/pen_feet_distance: -0.0206
Episode_Reward/pen_feet_regulation: -0.4549
   Episode_Reward/foot_landing_vel: -0.1351
   Episode_Reward/test_gait_reward: -0.8893
Metrics/base_velocity/error_vel_xy: 0.9848
Metrics/base_velocity/error_vel_yaw: 1.2733
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 1.09s
                        Total time: 1528.30s
                               ETA: 1743.0s

################################################################################
                     [1m Learning iteration 1402/3000 [0m                     

                       Computation: 89813 steps/s (collection: 0.967s, learning 0.127s)
               Value function loss: 0.6594
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8776
                     Learning rate: 0.0009
                       Mean reward: 125.44
               Mean episode length: 966.15
       Episode_Reward/keep_balance: 0.9683
     Episode_Reward/rew_lin_vel_xy: 5.9315
      Episode_Reward/rew_ang_vel_z: 2.4154
    Episode_Reward/pen_base_height: -0.3009
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.1666
   Episode_Reward/pen_joint_torque: -0.2256
    Episode_Reward/pen_joint_accel: -0.1123
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2541
Episode_Reward/pen_flat_orientation: -0.1111
  Episode_Reward/pen_feet_distance: -0.0174
Episode_Reward/pen_feet_regulation: -0.4978
   Episode_Reward/foot_landing_vel: -0.1436
   Episode_Reward/test_gait_reward: -0.9240
Metrics/base_velocity/error_vel_xy: 1.0296
Metrics/base_velocity/error_vel_yaw: 1.3255
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 1.09s
                        Total time: 1529.39s
                               ETA: 1742.0s

################################################################################
                     [1m Learning iteration 1403/3000 [0m                     

                       Computation: 90650 steps/s (collection: 0.960s, learning 0.125s)
               Value function loss: 0.6141
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8757
                     Learning rate: 0.0009
                       Mean reward: 129.75
               Mean episode length: 988.92
       Episode_Reward/keep_balance: 0.9929
     Episode_Reward/rew_lin_vel_xy: 6.1580
      Episode_Reward/rew_ang_vel_z: 2.5263
    Episode_Reward/pen_base_height: -0.2985
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.1664
   Episode_Reward/pen_joint_torque: -0.2382
    Episode_Reward/pen_joint_accel: -0.1070
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2548
Episode_Reward/pen_flat_orientation: -0.1014
  Episode_Reward/pen_feet_distance: -0.0190
Episode_Reward/pen_feet_regulation: -0.4789
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9383
Metrics/base_velocity/error_vel_xy: 1.0186
Metrics/base_velocity/error_vel_yaw: 1.3173
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 1.08s
                        Total time: 1530.48s
                               ETA: 1740.9s

################################################################################
                     [1m Learning iteration 1404/3000 [0m                     

                       Computation: 90288 steps/s (collection: 0.964s, learning 0.125s)
               Value function loss: 0.6239
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8757
                     Learning rate: 0.0006
                       Mean reward: 128.52
               Mean episode length: 978.40
       Episode_Reward/keep_balance: 0.9819
     Episode_Reward/rew_lin_vel_xy: 6.0937
      Episode_Reward/rew_ang_vel_z: 2.4952
    Episode_Reward/pen_base_height: -0.2972
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1757
   Episode_Reward/pen_joint_torque: -0.2299
    Episode_Reward/pen_joint_accel: -0.1143
    Episode_Reward/pen_action_rate: -0.1202
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0900
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2575
Episode_Reward/pen_flat_orientation: -0.1003
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4748
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.9330
Metrics/base_velocity/error_vel_xy: 0.9920
Metrics/base_velocity/error_vel_yaw: 1.3041
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 1.09s
                        Total time: 1531.57s
                               ETA: 1739.8s

################################################################################
                     [1m Learning iteration 1405/3000 [0m                     

                       Computation: 90240 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.6340
                    Surrogate loss: -0.0061
             Mean action noise std: 0.8761
                     Learning rate: 0.0009
                       Mean reward: 127.68
               Mean episode length: 983.79
       Episode_Reward/keep_balance: 0.9860
     Episode_Reward/rew_lin_vel_xy: 6.0086
      Episode_Reward/rew_ang_vel_z: 2.4730
    Episode_Reward/pen_base_height: -0.3056
      Episode_Reward/pen_lin_vel_z: -0.0406
     Episode_Reward/pen_ang_vel_xy: -0.1700
   Episode_Reward/pen_joint_torque: -0.2359
    Episode_Reward/pen_joint_accel: -0.1100
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0922
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2594
Episode_Reward/pen_flat_orientation: -0.1066
  Episode_Reward/pen_feet_distance: -0.0224
Episode_Reward/pen_feet_regulation: -0.4810
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.9394
Metrics/base_velocity/error_vel_xy: 1.0604
Metrics/base_velocity/error_vel_yaw: 1.3338
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 1.09s
                        Total time: 1532.66s
                               ETA: 1738.7s

################################################################################
                     [1m Learning iteration 1406/3000 [0m                     

                       Computation: 91009 steps/s (collection: 0.954s, learning 0.126s)
               Value function loss: 0.6448
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8776
                     Learning rate: 0.0004
                       Mean reward: 128.79
               Mean episode length: 982.38
       Episode_Reward/keep_balance: 0.9861
     Episode_Reward/rew_lin_vel_xy: 6.0786
      Episode_Reward/rew_ang_vel_z: 2.4565
    Episode_Reward/pen_base_height: -0.2909
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1649
   Episode_Reward/pen_joint_torque: -0.2404
    Episode_Reward/pen_joint_accel: -0.1171
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0931
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2569
Episode_Reward/pen_flat_orientation: -0.1013
  Episode_Reward/pen_feet_distance: -0.0209
Episode_Reward/pen_feet_regulation: -0.4873
   Episode_Reward/foot_landing_vel: -0.1450
   Episode_Reward/test_gait_reward: -0.9371
Metrics/base_velocity/error_vel_xy: 1.0110
Metrics/base_velocity/error_vel_yaw: 1.3497
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 1.08s
                        Total time: 1533.74s
                               ETA: 1737.6s

################################################################################
                     [1m Learning iteration 1407/3000 [0m                     

                       Computation: 89436 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.6416
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8777
                     Learning rate: 0.0006
                       Mean reward: 128.22
               Mean episode length: 965.55
       Episode_Reward/keep_balance: 0.9698
     Episode_Reward/rew_lin_vel_xy: 6.0306
      Episode_Reward/rew_ang_vel_z: 2.4500
    Episode_Reward/pen_base_height: -0.2931
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1608
   Episode_Reward/pen_joint_torque: -0.2332
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2517
Episode_Reward/pen_flat_orientation: -0.0976
  Episode_Reward/pen_feet_distance: -0.0203
Episode_Reward/pen_feet_regulation: -0.4654
   Episode_Reward/foot_landing_vel: -0.1370
   Episode_Reward/test_gait_reward: -0.9231
Metrics/base_velocity/error_vel_xy: 0.9859
Metrics/base_velocity/error_vel_yaw: 1.2979
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 1.10s
                        Total time: 1534.83s
                               ETA: 1736.5s

################################################################################
                     [1m Learning iteration 1408/3000 [0m                     

                       Computation: 89611 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.6211
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8788
                     Learning rate: 0.0006
                       Mean reward: 132.58
               Mean episode length: 993.74
       Episode_Reward/keep_balance: 0.9943
     Episode_Reward/rew_lin_vel_xy: 6.1488
      Episode_Reward/rew_ang_vel_z: 2.5143
    Episode_Reward/pen_base_height: -0.2910
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.1610
   Episode_Reward/pen_joint_torque: -0.2413
    Episode_Reward/pen_joint_accel: -0.1173
    Episode_Reward/pen_action_rate: -0.1211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0591
   Episode_Reward/pen_joint_powers: -0.0923
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2579
Episode_Reward/pen_flat_orientation: -0.1025
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4734
   Episode_Reward/foot_landing_vel: -0.1446
   Episode_Reward/test_gait_reward: -0.9465
Metrics/base_velocity/error_vel_xy: 1.0192
Metrics/base_velocity/error_vel_yaw: 1.3243
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 1.10s
                        Total time: 1535.93s
                               ETA: 1735.4s

################################################################################
                     [1m Learning iteration 1409/3000 [0m                     

                       Computation: 89981 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.6392
                    Surrogate loss: -0.0056
             Mean action noise std: 0.8811
                     Learning rate: 0.0009
                       Mean reward: 130.29
               Mean episode length: 973.97
       Episode_Reward/keep_balance: 0.9732
     Episode_Reward/rew_lin_vel_xy: 6.0130
      Episode_Reward/rew_ang_vel_z: 2.4728
    Episode_Reward/pen_base_height: -0.2846
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1635
   Episode_Reward/pen_joint_torque: -0.2287
    Episode_Reward/pen_joint_accel: -0.1097
    Episode_Reward/pen_action_rate: -0.1176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0882
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2505
Episode_Reward/pen_flat_orientation: -0.0968
  Episode_Reward/pen_feet_distance: -0.0160
Episode_Reward/pen_feet_regulation: -0.4609
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.9228
Metrics/base_velocity/error_vel_xy: 1.0035
Metrics/base_velocity/error_vel_yaw: 1.2796
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 1.09s
                        Total time: 1537.02s
                               ETA: 1734.3s

################################################################################
                     [1m Learning iteration 1410/3000 [0m                     

                       Computation: 90425 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.6365
                    Surrogate loss: -0.0009
             Mean action noise std: 0.8825
                     Learning rate: 0.0003
                       Mean reward: 125.50
               Mean episode length: 971.91
       Episode_Reward/keep_balance: 0.9687
     Episode_Reward/rew_lin_vel_xy: 5.9191
      Episode_Reward/rew_ang_vel_z: 2.4079
    Episode_Reward/pen_base_height: -0.3073
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1679
   Episode_Reward/pen_joint_torque: -0.2210
    Episode_Reward/pen_joint_accel: -0.1120
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2571
Episode_Reward/pen_flat_orientation: -0.1097
  Episode_Reward/pen_feet_distance: -0.0178
Episode_Reward/pen_feet_regulation: -0.4742
   Episode_Reward/foot_landing_vel: -0.1346
   Episode_Reward/test_gait_reward: -0.9256
Metrics/base_velocity/error_vel_xy: 1.0421
Metrics/base_velocity/error_vel_yaw: 1.3717
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 1.09s
                        Total time: 1538.11s
                               ETA: 1733.2s

################################################################################
                     [1m Learning iteration 1411/3000 [0m                     

                       Computation: 88709 steps/s (collection: 0.986s, learning 0.122s)
               Value function loss: 0.7145
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8832
                     Learning rate: 0.0003
                       Mean reward: 127.71
               Mean episode length: 977.63
       Episode_Reward/keep_balance: 0.9821
     Episode_Reward/rew_lin_vel_xy: 6.1302
      Episode_Reward/rew_ang_vel_z: 2.4433
    Episode_Reward/pen_base_height: -0.3009
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1672
   Episode_Reward/pen_joint_torque: -0.2323
    Episode_Reward/pen_joint_accel: -0.1175
    Episode_Reward/pen_action_rate: -0.1213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0892
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2583
Episode_Reward/pen_flat_orientation: -0.0974
  Episode_Reward/pen_feet_distance: -0.0178
Episode_Reward/pen_feet_regulation: -0.4889
   Episode_Reward/foot_landing_vel: -0.1364
   Episode_Reward/test_gait_reward: -0.9335
Metrics/base_velocity/error_vel_xy: 0.9960
Metrics/base_velocity/error_vel_yaw: 1.3470
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 1.11s
                        Total time: 1539.22s
                               ETA: 1732.2s

################################################################################
                     [1m Learning iteration 1412/3000 [0m                     

                       Computation: 90605 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 0.5805
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8830
                     Learning rate: 0.0004
                       Mean reward: 121.94
               Mean episode length: 956.32
       Episode_Reward/keep_balance: 0.9624
     Episode_Reward/rew_lin_vel_xy: 5.9084
      Episode_Reward/rew_ang_vel_z: 2.3549
    Episode_Reward/pen_base_height: -0.3003
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1645
   Episode_Reward/pen_joint_torque: -0.2367
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0915
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2534
Episode_Reward/pen_flat_orientation: -0.1081
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.4814
   Episode_Reward/foot_landing_vel: -0.1401
   Episode_Reward/test_gait_reward: -0.9278
Metrics/base_velocity/error_vel_xy: 1.0170
Metrics/base_velocity/error_vel_yaw: 1.3614
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 1.08s
                        Total time: 1540.30s
                               ETA: 1731.1s

################################################################################
                     [1m Learning iteration 1413/3000 [0m                     

                       Computation: 90551 steps/s (collection: 0.961s, learning 0.125s)
               Value function loss: 0.5641
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8820
                     Learning rate: 0.0001
                       Mean reward: 128.88
               Mean episode length: 978.18
       Episode_Reward/keep_balance: 0.9857
     Episode_Reward/rew_lin_vel_xy: 6.0513
      Episode_Reward/rew_ang_vel_z: 2.4978
    Episode_Reward/pen_base_height: -0.3108
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.1660
   Episode_Reward/pen_joint_torque: -0.2377
    Episode_Reward/pen_joint_accel: -0.1113
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2548
Episode_Reward/pen_flat_orientation: -0.0999
  Episode_Reward/pen_feet_distance: -0.0170
Episode_Reward/pen_feet_regulation: -0.4731
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9379
Metrics/base_velocity/error_vel_xy: 1.0330
Metrics/base_velocity/error_vel_yaw: 1.3005
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 1.09s
                        Total time: 1541.39s
                               ETA: 1730.0s

################################################################################
                     [1m Learning iteration 1414/3000 [0m                     

                       Computation: 89390 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 0.6213
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8816
                     Learning rate: 0.0003
                       Mean reward: 132.02
               Mean episode length: 991.67
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.2216
      Episode_Reward/rew_ang_vel_z: 2.4884
    Episode_Reward/pen_base_height: -0.2819
      Episode_Reward/pen_lin_vel_z: -0.0399
     Episode_Reward/pen_ang_vel_xy: -0.1673
   Episode_Reward/pen_joint_torque: -0.2218
    Episode_Reward/pen_joint_accel: -0.1095
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2612
Episode_Reward/pen_flat_orientation: -0.0953
  Episode_Reward/pen_feet_distance: -0.0158
Episode_Reward/pen_feet_regulation: -0.4773
   Episode_Reward/foot_landing_vel: -0.1446
   Episode_Reward/test_gait_reward: -0.9422
Metrics/base_velocity/error_vel_xy: 1.0112
Metrics/base_velocity/error_vel_yaw: 1.3642
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 1.10s
                        Total time: 1542.49s
                               ETA: 1728.9s

################################################################################
                     [1m Learning iteration 1415/3000 [0m                     

                       Computation: 91359 steps/s (collection: 0.951s, learning 0.125s)
               Value function loss: 0.6207
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8813
                     Learning rate: 0.0006
                       Mean reward: 126.14
               Mean episode length: 961.01
       Episode_Reward/keep_balance: 0.9670
     Episode_Reward/rew_lin_vel_xy: 5.9635
      Episode_Reward/rew_ang_vel_z: 2.4107
    Episode_Reward/pen_base_height: -0.2928
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1702
   Episode_Reward/pen_joint_torque: -0.2292
    Episode_Reward/pen_joint_accel: -0.1168
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2553
Episode_Reward/pen_flat_orientation: -0.1048
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4676
   Episode_Reward/foot_landing_vel: -0.1426
   Episode_Reward/test_gait_reward: -0.9212
Metrics/base_velocity/error_vel_xy: 1.0105
Metrics/base_velocity/error_vel_yaw: 1.3175
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 1.08s
                        Total time: 1543.57s
                               ETA: 1727.8s

################################################################################
                     [1m Learning iteration 1416/3000 [0m                     

                       Computation: 90111 steps/s (collection: 0.969s, learning 0.121s)
               Value function loss: 0.6407
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8812
                     Learning rate: 0.0004
                       Mean reward: 129.64
               Mean episode length: 992.00
       Episode_Reward/keep_balance: 0.9933
     Episode_Reward/rew_lin_vel_xy: 6.1525
      Episode_Reward/rew_ang_vel_z: 2.4927
    Episode_Reward/pen_base_height: -0.3039
      Episode_Reward/pen_lin_vel_z: -0.0422
     Episode_Reward/pen_ang_vel_xy: -0.1639
   Episode_Reward/pen_joint_torque: -0.2424
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1217
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0919
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2587
Episode_Reward/pen_flat_orientation: -0.1007
  Episode_Reward/pen_feet_distance: -0.0170
Episode_Reward/pen_feet_regulation: -0.4834
   Episode_Reward/foot_landing_vel: -0.1376
   Episode_Reward/test_gait_reward: -0.9489
Metrics/base_velocity/error_vel_xy: 1.0101
Metrics/base_velocity/error_vel_yaw: 1.3369
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 1.09s
                        Total time: 1544.66s
                               ETA: 1726.7s

################################################################################
                     [1m Learning iteration 1417/3000 [0m                     

                       Computation: 88615 steps/s (collection: 0.987s, learning 0.123s)
               Value function loss: 0.5450
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8812
                     Learning rate: 0.0006
                       Mean reward: 131.45
               Mean episode length: 969.74
       Episode_Reward/keep_balance: 0.9775
     Episode_Reward/rew_lin_vel_xy: 6.1531
      Episode_Reward/rew_ang_vel_z: 2.4968
    Episode_Reward/pen_base_height: -0.3024
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1624
   Episode_Reward/pen_joint_torque: -0.2243
    Episode_Reward/pen_joint_accel: -0.1032
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2512
Episode_Reward/pen_flat_orientation: -0.1039
  Episode_Reward/pen_feet_distance: -0.0165
Episode_Reward/pen_feet_regulation: -0.4576
   Episode_Reward/foot_landing_vel: -0.1272
   Episode_Reward/test_gait_reward: -0.9232
Metrics/base_velocity/error_vel_xy: 0.9467
Metrics/base_velocity/error_vel_yaw: 1.2855
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 1.11s
                        Total time: 1545.77s
                               ETA: 1725.6s

################################################################################
                     [1m Learning iteration 1418/3000 [0m                     

                       Computation: 91143 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.6044
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8812
                     Learning rate: 0.0006
                       Mean reward: 129.37
               Mean episode length: 972.89
       Episode_Reward/keep_balance: 0.9728
     Episode_Reward/rew_lin_vel_xy: 6.0288
      Episode_Reward/rew_ang_vel_z: 2.3806
    Episode_Reward/pen_base_height: -0.2941
      Episode_Reward/pen_lin_vel_z: -0.0402
     Episode_Reward/pen_ang_vel_xy: -0.1729
   Episode_Reward/pen_joint_torque: -0.2273
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2589
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0189
Episode_Reward/pen_feet_regulation: -0.4821
   Episode_Reward/foot_landing_vel: -0.1414
   Episode_Reward/test_gait_reward: -0.9325
Metrics/base_velocity/error_vel_xy: 1.0045
Metrics/base_velocity/error_vel_yaw: 1.3838
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 1.08s
                        Total time: 1546.84s
                               ETA: 1724.5s

################################################################################
                     [1m Learning iteration 1419/3000 [0m                     

                       Computation: 89983 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.5876
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8814
                     Learning rate: 0.0004
                       Mean reward: 130.91
               Mean episode length: 974.98
       Episode_Reward/keep_balance: 0.9823
     Episode_Reward/rew_lin_vel_xy: 6.1098
      Episode_Reward/rew_ang_vel_z: 2.4996
    Episode_Reward/pen_base_height: -0.2912
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1638
   Episode_Reward/pen_joint_torque: -0.2321
    Episode_Reward/pen_joint_accel: -0.1144
    Episode_Reward/pen_action_rate: -0.1172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2543
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0161
Episode_Reward/pen_feet_regulation: -0.4504
   Episode_Reward/foot_landing_vel: -0.1304
   Episode_Reward/test_gait_reward: -0.9266
Metrics/base_velocity/error_vel_xy: 0.9732
Metrics/base_velocity/error_vel_yaw: 1.2896
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 1.09s
                        Total time: 1547.94s
                               ETA: 1723.4s

################################################################################
                     [1m Learning iteration 1420/3000 [0m                     

                       Computation: 84729 steps/s (collection: 1.036s, learning 0.125s)
               Value function loss: 0.5968
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8795
                     Learning rate: 0.0009
                       Mean reward: 129.45
               Mean episode length: 983.96
       Episode_Reward/keep_balance: 0.9788
     Episode_Reward/rew_lin_vel_xy: 6.0791
      Episode_Reward/rew_ang_vel_z: 2.4430
    Episode_Reward/pen_base_height: -0.2990
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1774
   Episode_Reward/pen_joint_torque: -0.2303
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2588
Episode_Reward/pen_flat_orientation: -0.1017
  Episode_Reward/pen_feet_distance: -0.0205
Episode_Reward/pen_feet_regulation: -0.4714
   Episode_Reward/foot_landing_vel: -0.1381
   Episode_Reward/test_gait_reward: -0.9274
Metrics/base_velocity/error_vel_xy: 1.0098
Metrics/base_velocity/error_vel_yaw: 1.3444
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 1.16s
                        Total time: 1549.10s
                               ETA: 1722.4s

################################################################################
                     [1m Learning iteration 1421/3000 [0m                     

                       Computation: 89648 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 0.5868
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8806
                     Learning rate: 0.0006
                       Mean reward: 127.89
               Mean episode length: 979.17
       Episode_Reward/keep_balance: 0.9846
     Episode_Reward/rew_lin_vel_xy: 6.0916
      Episode_Reward/rew_ang_vel_z: 2.4575
    Episode_Reward/pen_base_height: -0.3039
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1723
   Episode_Reward/pen_joint_torque: -0.2285
    Episode_Reward/pen_joint_accel: -0.1171
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2596
Episode_Reward/pen_flat_orientation: -0.1071
  Episode_Reward/pen_feet_distance: -0.0172
Episode_Reward/pen_feet_regulation: -0.4746
   Episode_Reward/foot_landing_vel: -0.1371
   Episode_Reward/test_gait_reward: -0.9365
Metrics/base_velocity/error_vel_xy: 1.0022
Metrics/base_velocity/error_vel_yaw: 1.3417
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 1.10s
                        Total time: 1550.19s
                               ETA: 1721.3s

################################################################################
                     [1m Learning iteration 1422/3000 [0m                     

                       Computation: 89250 steps/s (collection: 0.976s, learning 0.126s)
               Value function loss: 0.5748
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8810
                     Learning rate: 0.0004
                       Mean reward: 126.94
               Mean episode length: 990.46
       Episode_Reward/keep_balance: 0.9879
     Episode_Reward/rew_lin_vel_xy: 6.0735
      Episode_Reward/rew_ang_vel_z: 2.4518
    Episode_Reward/pen_base_height: -0.3033
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.1744
   Episode_Reward/pen_joint_torque: -0.2366
    Episode_Reward/pen_joint_accel: -0.1130
    Episode_Reward/pen_action_rate: -0.1228
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0605
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2626
Episode_Reward/pen_flat_orientation: -0.1033
  Episode_Reward/pen_feet_distance: -0.0167
Episode_Reward/pen_feet_regulation: -0.5135
   Episode_Reward/foot_landing_vel: -0.1461
   Episode_Reward/test_gait_reward: -0.9366
Metrics/base_velocity/error_vel_xy: 1.0418
Metrics/base_velocity/error_vel_yaw: 1.3557
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 1.10s
                        Total time: 1551.29s
                               ETA: 1720.3s

################################################################################
                     [1m Learning iteration 1423/3000 [0m                     

                       Computation: 90608 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.5762
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8821
                     Learning rate: 0.0006
                       Mean reward: 128.60
               Mean episode length: 980.36
       Episode_Reward/keep_balance: 0.9880
     Episode_Reward/rew_lin_vel_xy: 6.1020
      Episode_Reward/rew_ang_vel_z: 2.4492
    Episode_Reward/pen_base_height: -0.3185
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.1741
   Episode_Reward/pen_joint_torque: -0.2431
    Episode_Reward/pen_joint_accel: -0.1110
    Episode_Reward/pen_action_rate: -0.1232
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0609
   Episode_Reward/pen_joint_powers: -0.0940
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2628
Episode_Reward/pen_flat_orientation: -0.1106
  Episode_Reward/pen_feet_distance: -0.0176
Episode_Reward/pen_feet_regulation: -0.5000
   Episode_Reward/foot_landing_vel: -0.1451
   Episode_Reward/test_gait_reward: -0.9426
Metrics/base_velocity/error_vel_xy: 1.0194
Metrics/base_velocity/error_vel_yaw: 1.3627
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 1.08s
                        Total time: 1552.38s
                               ETA: 1719.2s

################################################################################
                     [1m Learning iteration 1424/3000 [0m                     

                       Computation: 88989 steps/s (collection: 0.980s, learning 0.124s)
               Value function loss: 0.6222
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8816
                     Learning rate: 0.0004
                       Mean reward: 130.56
               Mean episode length: 980.91
       Episode_Reward/keep_balance: 0.9809
     Episode_Reward/rew_lin_vel_xy: 6.0954
      Episode_Reward/rew_ang_vel_z: 2.4809
    Episode_Reward/pen_base_height: -0.2968
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1637
   Episode_Reward/pen_joint_torque: -0.2378
    Episode_Reward/pen_joint_accel: -0.1112
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2537
Episode_Reward/pen_flat_orientation: -0.1033
  Episode_Reward/pen_feet_distance: -0.0197
Episode_Reward/pen_feet_regulation: -0.4541
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.9300
Metrics/base_velocity/error_vel_xy: 0.9925
Metrics/base_velocity/error_vel_yaw: 1.3161
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 1.10s
                        Total time: 1553.48s
                               ETA: 1718.1s

################################################################################
                     [1m Learning iteration 1425/3000 [0m                     

                       Computation: 89802 steps/s (collection: 0.967s, learning 0.128s)
               Value function loss: 0.5827
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8801
                     Learning rate: 0.0006
                       Mean reward: 131.55
               Mean episode length: 983.94
       Episode_Reward/keep_balance: 0.9873
     Episode_Reward/rew_lin_vel_xy: 6.1459
      Episode_Reward/rew_ang_vel_z: 2.4722
    Episode_Reward/pen_base_height: -0.3051
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1667
   Episode_Reward/pen_joint_torque: -0.2332
    Episode_Reward/pen_joint_accel: -0.1015
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2552
Episode_Reward/pen_flat_orientation: -0.1019
  Episode_Reward/pen_feet_distance: -0.0190
Episode_Reward/pen_feet_regulation: -0.4842
   Episode_Reward/foot_landing_vel: -0.1411
   Episode_Reward/test_gait_reward: -0.9390
Metrics/base_velocity/error_vel_xy: 0.9937
Metrics/base_velocity/error_vel_yaw: 1.3468
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 1.09s
                        Total time: 1554.58s
                               ETA: 1717.0s

################################################################################
                     [1m Learning iteration 1426/3000 [0m                     

                       Computation: 88937 steps/s (collection: 0.982s, learning 0.123s)
               Value function loss: 0.6060
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8822
                     Learning rate: 0.0004
                       Mean reward: 131.69
               Mean episode length: 988.75
       Episode_Reward/keep_balance: 0.9903
     Episode_Reward/rew_lin_vel_xy: 6.0859
      Episode_Reward/rew_ang_vel_z: 2.5212
    Episode_Reward/pen_base_height: -0.3027
      Episode_Reward/pen_lin_vel_z: -0.0419
     Episode_Reward/pen_ang_vel_xy: -0.1724
   Episode_Reward/pen_joint_torque: -0.2441
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.1209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0916
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2580
Episode_Reward/pen_flat_orientation: -0.1029
  Episode_Reward/pen_feet_distance: -0.0187
Episode_Reward/pen_feet_regulation: -0.4831
   Episode_Reward/foot_landing_vel: -0.1380
   Episode_Reward/test_gait_reward: -0.9389
Metrics/base_velocity/error_vel_xy: 1.0260
Metrics/base_velocity/error_vel_yaw: 1.2963
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 1.11s
                        Total time: 1555.68s
                               ETA: 1715.9s

################################################################################
                     [1m Learning iteration 1427/3000 [0m                     

                       Computation: 90838 steps/s (collection: 0.956s, learning 0.126s)
               Value function loss: 0.6027
                    Surrogate loss: -0.0057
             Mean action noise std: 0.8829
                     Learning rate: 0.0006
                       Mean reward: 130.54
               Mean episode length: 980.52
       Episode_Reward/keep_balance: 0.9561
     Episode_Reward/rew_lin_vel_xy: 5.9199
      Episode_Reward/rew_ang_vel_z: 2.4248
    Episode_Reward/pen_base_height: -0.2860
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1609
   Episode_Reward/pen_joint_torque: -0.2313
    Episode_Reward/pen_joint_accel: -0.1035
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2460
Episode_Reward/pen_flat_orientation: -0.1045
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4657
   Episode_Reward/foot_landing_vel: -0.1375
   Episode_Reward/test_gait_reward: -0.9058
Metrics/base_velocity/error_vel_xy: 0.9764
Metrics/base_velocity/error_vel_yaw: 1.2724
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 1.08s
                        Total time: 1556.77s
                               ETA: 1714.8s

################################################################################
                     [1m Learning iteration 1428/3000 [0m                     

                       Computation: 91279 steps/s (collection: 0.951s, learning 0.126s)
               Value function loss: 0.6042
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8820
                     Learning rate: 0.0009
                       Mean reward: 129.97
               Mean episode length: 986.55
       Episode_Reward/keep_balance: 0.9906
     Episode_Reward/rew_lin_vel_xy: 6.1294
      Episode_Reward/rew_ang_vel_z: 2.4918
    Episode_Reward/pen_base_height: -0.3186
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.1645
   Episode_Reward/pen_joint_torque: -0.2305
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2542
Episode_Reward/pen_flat_orientation: -0.1040
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.4869
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9431
Metrics/base_velocity/error_vel_xy: 1.0196
Metrics/base_velocity/error_vel_yaw: 1.3377
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 1.08s
                        Total time: 1557.84s
                               ETA: 1713.7s

################################################################################
                     [1m Learning iteration 1429/3000 [0m                     

                       Computation: 89126 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 0.5775
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8792
                     Learning rate: 0.0013
                       Mean reward: 130.32
               Mean episode length: 979.94
       Episode_Reward/keep_balance: 0.9725
     Episode_Reward/rew_lin_vel_xy: 6.0603
      Episode_Reward/rew_ang_vel_z: 2.4514
    Episode_Reward/pen_base_height: -0.2954
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.1617
   Episode_Reward/pen_joint_torque: -0.2351
    Episode_Reward/pen_joint_accel: -0.1070
    Episode_Reward/pen_action_rate: -0.1172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2516
Episode_Reward/pen_flat_orientation: -0.1019
  Episode_Reward/pen_feet_distance: -0.0198
Episode_Reward/pen_feet_regulation: -0.4687
   Episode_Reward/foot_landing_vel: -0.1308
   Episode_Reward/test_gait_reward: -0.9298
Metrics/base_velocity/error_vel_xy: 0.9735
Metrics/base_velocity/error_vel_yaw: 1.3058
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 1.10s
                        Total time: 1558.95s
                               ETA: 1712.7s

################################################################################
                     [1m Learning iteration 1430/3000 [0m                     

                       Computation: 92025 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.6659
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8799
                     Learning rate: 0.0013
                       Mean reward: 132.11
               Mean episode length: 981.39
       Episode_Reward/keep_balance: 0.9807
     Episode_Reward/rew_lin_vel_xy: 6.1488
      Episode_Reward/rew_ang_vel_z: 2.5048
    Episode_Reward/pen_base_height: -0.3002
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1594
   Episode_Reward/pen_joint_torque: -0.2291
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1164
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2508
Episode_Reward/pen_flat_orientation: -0.0971
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4428
   Episode_Reward/foot_landing_vel: -0.1269
   Episode_Reward/test_gait_reward: -0.9256
Metrics/base_velocity/error_vel_xy: 0.9511
Metrics/base_velocity/error_vel_yaw: 1.2835
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 1.07s
                        Total time: 1560.01s
                               ETA: 1711.5s

################################################################################
                     [1m Learning iteration 1431/3000 [0m                     

                       Computation: 90299 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.5674
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8807
                     Learning rate: 0.0004
                       Mean reward: 127.80
               Mean episode length: 963.94
       Episode_Reward/keep_balance: 0.9449
     Episode_Reward/rew_lin_vel_xy: 5.8170
      Episode_Reward/rew_ang_vel_z: 2.3581
    Episode_Reward/pen_base_height: -0.2851
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1660
   Episode_Reward/pen_joint_torque: -0.2176
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.1157
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2491
Episode_Reward/pen_flat_orientation: -0.1050
  Episode_Reward/pen_feet_distance: -0.0166
Episode_Reward/pen_feet_regulation: -0.4550
   Episode_Reward/foot_landing_vel: -0.1350
   Episode_Reward/test_gait_reward: -0.9035
Metrics/base_velocity/error_vel_xy: 0.9712
Metrics/base_velocity/error_vel_yaw: 1.2927
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 1.09s
                        Total time: 1561.10s
                               ETA: 1710.5s

################################################################################
                     [1m Learning iteration 1432/3000 [0m                     

                       Computation: 90709 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.6055
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8791
                     Learning rate: 0.0004
                       Mean reward: 129.05
               Mean episode length: 983.91
       Episode_Reward/keep_balance: 0.9806
     Episode_Reward/rew_lin_vel_xy: 6.0286
      Episode_Reward/rew_ang_vel_z: 2.4296
    Episode_Reward/pen_base_height: -0.2916
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.1685
   Episode_Reward/pen_joint_torque: -0.2314
    Episode_Reward/pen_joint_accel: -0.1150
    Episode_Reward/pen_action_rate: -0.1198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0916
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2576
Episode_Reward/pen_flat_orientation: -0.0982
  Episode_Reward/pen_feet_distance: -0.0224
Episode_Reward/pen_feet_regulation: -0.5014
   Episode_Reward/foot_landing_vel: -0.1446
   Episode_Reward/test_gait_reward: -0.9395
Metrics/base_velocity/error_vel_xy: 1.0398
Metrics/base_velocity/error_vel_yaw: 1.3534
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 1.08s
                        Total time: 1562.19s
                               ETA: 1709.4s

################################################################################
                     [1m Learning iteration 1433/3000 [0m                     

                       Computation: 89609 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.5875
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8791
                     Learning rate: 0.0003
                       Mean reward: 129.52
               Mean episode length: 979.50
       Episode_Reward/keep_balance: 0.9756
     Episode_Reward/rew_lin_vel_xy: 5.9902
      Episode_Reward/rew_ang_vel_z: 2.4246
    Episode_Reward/pen_base_height: -0.3023
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1762
   Episode_Reward/pen_joint_torque: -0.2185
    Episode_Reward/pen_joint_accel: -0.1127
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0603
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2586
Episode_Reward/pen_flat_orientation: -0.1056
  Episode_Reward/pen_feet_distance: -0.0221
Episode_Reward/pen_feet_regulation: -0.4929
   Episode_Reward/foot_landing_vel: -0.1352
   Episode_Reward/test_gait_reward: -0.9297
Metrics/base_velocity/error_vel_xy: 1.0267
Metrics/base_velocity/error_vel_yaw: 1.3442
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 1.10s
                        Total time: 1563.28s
                               ETA: 1708.3s

################################################################################
                     [1m Learning iteration 1434/3000 [0m                     

                       Computation: 89457 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.5770
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8787
                     Learning rate: 0.0004
                       Mean reward: 133.39
               Mean episode length: 991.91
       Episode_Reward/keep_balance: 0.9871
     Episode_Reward/rew_lin_vel_xy: 6.1372
      Episode_Reward/rew_ang_vel_z: 2.4883
    Episode_Reward/pen_base_height: -0.2894
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1680
   Episode_Reward/pen_joint_torque: -0.2312
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0900
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2579
Episode_Reward/pen_flat_orientation: -0.1027
  Episode_Reward/pen_feet_distance: -0.0219
Episode_Reward/pen_feet_regulation: -0.4778
   Episode_Reward/foot_landing_vel: -0.1359
   Episode_Reward/test_gait_reward: -0.9308
Metrics/base_velocity/error_vel_xy: 1.0046
Metrics/base_velocity/error_vel_yaw: 1.3187
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 1.10s
                        Total time: 1564.38s
                               ETA: 1707.2s

################################################################################
                     [1m Learning iteration 1435/3000 [0m                     

                       Computation: 90561 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.5795
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8788
                     Learning rate: 0.0006
                       Mean reward: 132.49
               Mean episode length: 982.94
       Episode_Reward/keep_balance: 0.9763
     Episode_Reward/rew_lin_vel_xy: 6.0611
      Episode_Reward/rew_ang_vel_z: 2.4928
    Episode_Reward/pen_base_height: -0.3151
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1640
   Episode_Reward/pen_joint_torque: -0.2406
    Episode_Reward/pen_joint_accel: -0.1050
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0908
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2528
Episode_Reward/pen_flat_orientation: -0.0995
  Episode_Reward/pen_feet_distance: -0.0219
Episode_Reward/pen_feet_regulation: -0.4637
   Episode_Reward/foot_landing_vel: -0.1442
   Episode_Reward/test_gait_reward: -0.9287
Metrics/base_velocity/error_vel_xy: 0.9925
Metrics/base_velocity/error_vel_yaw: 1.2828
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 1.09s
                        Total time: 1565.47s
                               ETA: 1706.1s

################################################################################
                     [1m Learning iteration 1436/3000 [0m                     

                       Computation: 90135 steps/s (collection: 0.965s, learning 0.126s)
               Value function loss: 0.6626
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8793
                     Learning rate: 0.0006
                       Mean reward: 127.57
               Mean episode length: 968.85
       Episode_Reward/keep_balance: 0.9681
     Episode_Reward/rew_lin_vel_xy: 6.0071
      Episode_Reward/rew_ang_vel_z: 2.4117
    Episode_Reward/pen_base_height: -0.2922
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1700
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1125
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0891
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2559
Episode_Reward/pen_flat_orientation: -0.0990
  Episode_Reward/pen_feet_distance: -0.0200
Episode_Reward/pen_feet_regulation: -0.4803
   Episode_Reward/foot_landing_vel: -0.1409
   Episode_Reward/test_gait_reward: -0.9174
Metrics/base_velocity/error_vel_xy: 0.9831
Metrics/base_velocity/error_vel_yaw: 1.3261
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 1.09s
                        Total time: 1566.56s
                               ETA: 1705.0s

################################################################################
                     [1m Learning iteration 1437/3000 [0m                     

                       Computation: 90505 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.6620
                    Surrogate loss: -0.0005
             Mean action noise std: 0.8786
                     Learning rate: 0.0002
                       Mean reward: 127.65
               Mean episode length: 967.08
       Episode_Reward/keep_balance: 0.9482
     Episode_Reward/rew_lin_vel_xy: 5.8759
      Episode_Reward/rew_ang_vel_z: 2.3845
    Episode_Reward/pen_base_height: -0.2924
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1626
   Episode_Reward/pen_joint_torque: -0.2230
    Episode_Reward/pen_joint_accel: -0.1190
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2490
Episode_Reward/pen_flat_orientation: -0.0983
  Episode_Reward/pen_feet_distance: -0.0191
Episode_Reward/pen_feet_regulation: -0.4715
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.9004
Metrics/base_velocity/error_vel_xy: 0.9668
Metrics/base_velocity/error_vel_yaw: 1.2683
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 1.09s
                        Total time: 1567.65s
                               ETA: 1703.9s

################################################################################
                     [1m Learning iteration 1438/3000 [0m                     

                       Computation: 90966 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 0.5882
                    Surrogate loss: -0.0055
             Mean action noise std: 0.8765
                     Learning rate: 0.0004
                       Mean reward: 128.04
               Mean episode length: 980.09
       Episode_Reward/keep_balance: 0.9850
     Episode_Reward/rew_lin_vel_xy: 6.0635
      Episode_Reward/rew_ang_vel_z: 2.4425
    Episode_Reward/pen_base_height: -0.3072
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1609
   Episode_Reward/pen_joint_torque: -0.2334
    Episode_Reward/pen_joint_accel: -0.1030
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2564
Episode_Reward/pen_flat_orientation: -0.1064
  Episode_Reward/pen_feet_distance: -0.0270
Episode_Reward/pen_feet_regulation: -0.4950
   Episode_Reward/foot_landing_vel: -0.1302
   Episode_Reward/test_gait_reward: -0.9492
Metrics/base_velocity/error_vel_xy: 1.0303
Metrics/base_velocity/error_vel_yaw: 1.3595
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 1.08s
                        Total time: 1568.73s
                               ETA: 1702.8s

################################################################################
                     [1m Learning iteration 1439/3000 [0m                     

                       Computation: 88898 steps/s (collection: 0.980s, learning 0.126s)
               Value function loss: 0.5954
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8774
                     Learning rate: 0.0006
                       Mean reward: 126.90
               Mean episode length: 994.31
       Episode_Reward/keep_balance: 0.9957
     Episode_Reward/rew_lin_vel_xy: 6.1331
      Episode_Reward/rew_ang_vel_z: 2.4545
    Episode_Reward/pen_base_height: -0.3191
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1805
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.1111
    Episode_Reward/pen_action_rate: -0.1226
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0919
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2659
Episode_Reward/pen_flat_orientation: -0.1127
  Episode_Reward/pen_feet_distance: -0.0222
Episode_Reward/pen_feet_regulation: -0.4909
   Episode_Reward/foot_landing_vel: -0.1411
   Episode_Reward/test_gait_reward: -0.9544
Metrics/base_velocity/error_vel_xy: 1.0493
Metrics/base_velocity/error_vel_yaw: 1.3888
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 1.11s
                        Total time: 1569.83s
                               ETA: 1701.7s

################################################################################
                     [1m Learning iteration 1440/3000 [0m                     

                       Computation: 90436 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.5349
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8775
                     Learning rate: 0.0003
                       Mean reward: 129.51
               Mean episode length: 984.89
       Episode_Reward/keep_balance: 0.9694
     Episode_Reward/rew_lin_vel_xy: 5.9819
      Episode_Reward/rew_ang_vel_z: 2.3986
    Episode_Reward/pen_base_height: -0.3064
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.1650
   Episode_Reward/pen_joint_torque: -0.2363
    Episode_Reward/pen_joint_accel: -0.1092
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0922
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2549
Episode_Reward/pen_flat_orientation: -0.1064
  Episode_Reward/pen_feet_distance: -0.0232
Episode_Reward/pen_feet_regulation: -0.4866
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9259
Metrics/base_velocity/error_vel_xy: 1.0071
Metrics/base_velocity/error_vel_yaw: 1.3469
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 1.09s
                        Total time: 1570.92s
                               ETA: 1700.6s

################################################################################
                     [1m Learning iteration 1441/3000 [0m                     

                       Computation: 89309 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.5753
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8757
                     Learning rate: 0.0006
                       Mean reward: 131.89
               Mean episode length: 995.98
       Episode_Reward/keep_balance: 0.9958
     Episode_Reward/rew_lin_vel_xy: 6.1773
      Episode_Reward/rew_ang_vel_z: 2.5190
    Episode_Reward/pen_base_height: -0.3281
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1688
   Episode_Reward/pen_joint_torque: -0.2459
    Episode_Reward/pen_joint_accel: -0.1122
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0586
   Episode_Reward/pen_joint_powers: -0.0929
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2576
Episode_Reward/pen_flat_orientation: -0.1009
  Episode_Reward/pen_feet_distance: -0.0274
Episode_Reward/pen_feet_regulation: -0.4878
   Episode_Reward/foot_landing_vel: -0.1351
   Episode_Reward/test_gait_reward: -0.9480
Metrics/base_velocity/error_vel_xy: 1.0142
Metrics/base_velocity/error_vel_yaw: 1.3152
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 1.10s
                        Total time: 1572.02s
                               ETA: 1699.6s

################################################################################
                     [1m Learning iteration 1442/3000 [0m                     

                       Computation: 89696 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 0.5803
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8744
                     Learning rate: 0.0004
                       Mean reward: 130.06
               Mean episode length: 991.88
       Episode_Reward/keep_balance: 0.9921
     Episode_Reward/rew_lin_vel_xy: 6.1409
      Episode_Reward/rew_ang_vel_z: 2.4510
    Episode_Reward/pen_base_height: -0.3257
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1755
   Episode_Reward/pen_joint_torque: -0.2377
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0611
   Episode_Reward/pen_joint_powers: -0.0934
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2633
Episode_Reward/pen_flat_orientation: -0.1074
  Episode_Reward/pen_feet_distance: -0.0270
Episode_Reward/pen_feet_regulation: -0.5032
   Episode_Reward/foot_landing_vel: -0.1357
   Episode_Reward/test_gait_reward: -0.9493
Metrics/base_velocity/error_vel_xy: 1.0246
Metrics/base_velocity/error_vel_yaw: 1.3768
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 1.10s
                        Total time: 1573.12s
                               ETA: 1698.5s

################################################################################
                     [1m Learning iteration 1443/3000 [0m                     

                       Computation: 90486 steps/s (collection: 0.960s, learning 0.126s)
               Value function loss: 0.6463
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8754
                     Learning rate: 0.0002
                       Mean reward: 135.75
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 0.9953
     Episode_Reward/rew_lin_vel_xy: 6.2864
      Episode_Reward/rew_ang_vel_z: 2.5483
    Episode_Reward/pen_base_height: -0.2947
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1629
   Episode_Reward/pen_joint_torque: -0.2302
    Episode_Reward/pen_joint_accel: -0.1191
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2549
Episode_Reward/pen_flat_orientation: -0.0944
  Episode_Reward/pen_feet_distance: -0.0218
Episode_Reward/pen_feet_regulation: -0.4658
   Episode_Reward/foot_landing_vel: -0.1483
   Episode_Reward/test_gait_reward: -0.9393
Metrics/base_velocity/error_vel_xy: 0.9521
Metrics/base_velocity/error_vel_yaw: 1.2915
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 1.09s
                        Total time: 1574.20s
                               ETA: 1697.4s

################################################################################
                     [1m Learning iteration 1444/3000 [0m                     

                       Computation: 88870 steps/s (collection: 0.980s, learning 0.126s)
               Value function loss: 0.6311
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8765
                     Learning rate: 0.0002
                       Mean reward: 132.61
               Mean episode length: 988.23
       Episode_Reward/keep_balance: 0.9887
     Episode_Reward/rew_lin_vel_xy: 6.1976
      Episode_Reward/rew_ang_vel_z: 2.4851
    Episode_Reward/pen_base_height: -0.3066
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1654
   Episode_Reward/pen_joint_torque: -0.2305
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2561
Episode_Reward/pen_flat_orientation: -0.1043
  Episode_Reward/pen_feet_distance: -0.0207
Episode_Reward/pen_feet_regulation: -0.4928
   Episode_Reward/foot_landing_vel: -0.1309
   Episode_Reward/test_gait_reward: -0.9506
Metrics/base_velocity/error_vel_xy: 0.9737
Metrics/base_velocity/error_vel_yaw: 1.3375
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 1.11s
                        Total time: 1575.31s
                               ETA: 1696.3s

################################################################################
                     [1m Learning iteration 1445/3000 [0m                     

                       Computation: 89595 steps/s (collection: 0.972s, learning 0.125s)
               Value function loss: 0.6535
                    Surrogate loss: -0.0012
             Mean action noise std: 0.8775
                     Learning rate: 0.0002
                       Mean reward: 132.03
               Mean episode length: 980.78
       Episode_Reward/keep_balance: 0.9563
     Episode_Reward/rew_lin_vel_xy: 5.9952
      Episode_Reward/rew_ang_vel_z: 2.4560
    Episode_Reward/pen_base_height: -0.3109
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1679
   Episode_Reward/pen_joint_torque: -0.2272
    Episode_Reward/pen_joint_accel: -0.1028
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2470
Episode_Reward/pen_flat_orientation: -0.0954
  Episode_Reward/pen_feet_distance: -0.0176
Episode_Reward/pen_feet_regulation: -0.4556
   Episode_Reward/foot_landing_vel: -0.1303
   Episode_Reward/test_gait_reward: -0.9040
Metrics/base_velocity/error_vel_xy: 0.9499
Metrics/base_velocity/error_vel_yaw: 1.2414
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 1.10s
                        Total time: 1576.41s
                               ETA: 1695.2s

################################################################################
                     [1m Learning iteration 1446/3000 [0m                     

                       Computation: 90526 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.5986
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8773
                     Learning rate: 0.0004
                       Mean reward: 130.23
               Mean episode length: 980.12
       Episode_Reward/keep_balance: 0.9799
     Episode_Reward/rew_lin_vel_xy: 6.1013
      Episode_Reward/rew_ang_vel_z: 2.4762
    Episode_Reward/pen_base_height: -0.3144
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1683
   Episode_Reward/pen_joint_torque: -0.2357
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1195
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0911
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2537
Episode_Reward/pen_flat_orientation: -0.1014
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4777
   Episode_Reward/foot_landing_vel: -0.1357
   Episode_Reward/test_gait_reward: -0.9307
Metrics/base_velocity/error_vel_xy: 0.9935
Metrics/base_velocity/error_vel_yaw: 1.3114
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 1.09s
                        Total time: 1577.49s
                               ETA: 1694.1s

################################################################################
                     [1m Learning iteration 1447/3000 [0m                     

                       Computation: 89980 steps/s (collection: 0.967s, learning 0.125s)
               Value function loss: 0.5987
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8773
                     Learning rate: 0.0003
                       Mean reward: 127.97
               Mean episode length: 971.72
       Episode_Reward/keep_balance: 0.9762
     Episode_Reward/rew_lin_vel_xy: 6.0822
      Episode_Reward/rew_ang_vel_z: 2.4468
    Episode_Reward/pen_base_height: -0.3078
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1667
   Episode_Reward/pen_joint_torque: -0.2308
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.1187
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0593
   Episode_Reward/pen_joint_powers: -0.0915
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2537
Episode_Reward/pen_flat_orientation: -0.1059
  Episode_Reward/pen_feet_distance: -0.0255
Episode_Reward/pen_feet_regulation: -0.5004
   Episode_Reward/foot_landing_vel: -0.1425
   Episode_Reward/test_gait_reward: -0.9335
Metrics/base_velocity/error_vel_xy: 0.9866
Metrics/base_velocity/error_vel_yaw: 1.3321
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 1.09s
                        Total time: 1578.58s
                               ETA: 1693.1s

################################################################################
                     [1m Learning iteration 1448/3000 [0m                     

                       Computation: 89576 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.6298
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8768
                     Learning rate: 0.0006
                       Mean reward: 129.06
               Mean episode length: 988.82
       Episode_Reward/keep_balance: 0.9904
     Episode_Reward/rew_lin_vel_xy: 6.0750
      Episode_Reward/rew_ang_vel_z: 2.5034
    Episode_Reward/pen_base_height: -0.3259
      Episode_Reward/pen_lin_vel_z: -0.0406
     Episode_Reward/pen_ang_vel_xy: -0.1644
   Episode_Reward/pen_joint_torque: -0.2517
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1219
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0951
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2579
Episode_Reward/pen_flat_orientation: -0.1055
  Episode_Reward/pen_feet_distance: -0.0261
Episode_Reward/pen_feet_regulation: -0.4925
   Episode_Reward/foot_landing_vel: -0.1505
   Episode_Reward/test_gait_reward: -0.9415
Metrics/base_velocity/error_vel_xy: 1.0431
Metrics/base_velocity/error_vel_yaw: 1.3214
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 1.10s
                        Total time: 1579.68s
                               ETA: 1692.0s

################################################################################
                     [1m Learning iteration 1449/3000 [0m                     

                       Computation: 91843 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.5801
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8769
                     Learning rate: 0.0003
                       Mean reward: 129.21
               Mean episode length: 978.92
       Episode_Reward/keep_balance: 0.9882
     Episode_Reward/rew_lin_vel_xy: 6.1891
      Episode_Reward/rew_ang_vel_z: 2.4877
    Episode_Reward/pen_base_height: -0.3153
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1651
   Episode_Reward/pen_joint_torque: -0.2355
    Episode_Reward/pen_joint_accel: -0.1071
    Episode_Reward/pen_action_rate: -0.1202
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2562
Episode_Reward/pen_flat_orientation: -0.0981
  Episode_Reward/pen_feet_distance: -0.0222
Episode_Reward/pen_feet_regulation: -0.4810
   Episode_Reward/foot_landing_vel: -0.1417
   Episode_Reward/test_gait_reward: -0.9388
Metrics/base_velocity/error_vel_xy: 0.9896
Metrics/base_velocity/error_vel_yaw: 1.3283
      Episode_Termination/time_out: 4.8333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 1.07s
                        Total time: 1580.75s
                               ETA: 1690.9s

################################################################################
                     [1m Learning iteration 1450/3000 [0m                     

                       Computation: 91226 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.6943
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8751
                     Learning rate: 0.0009
                       Mean reward: 127.73
               Mean episode length: 964.24
       Episode_Reward/keep_balance: 0.9771
     Episode_Reward/rew_lin_vel_xy: 6.0924
      Episode_Reward/rew_ang_vel_z: 2.5004
    Episode_Reward/pen_base_height: -0.3023
      Episode_Reward/pen_lin_vel_z: -0.0419
     Episode_Reward/pen_ang_vel_xy: -0.1636
   Episode_Reward/pen_joint_torque: -0.2357
    Episode_Reward/pen_joint_accel: -0.1089
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2514
Episode_Reward/pen_flat_orientation: -0.0973
  Episode_Reward/pen_feet_distance: -0.0151
Episode_Reward/pen_feet_regulation: -0.4730
   Episode_Reward/foot_landing_vel: -0.1416
   Episode_Reward/test_gait_reward: -0.9264
Metrics/base_velocity/error_vel_xy: 0.9845
Metrics/base_velocity/error_vel_yaw: 1.2661
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 1.08s
                        Total time: 1581.83s
                               ETA: 1689.8s

################################################################################
                     [1m Learning iteration 1451/3000 [0m                     

                       Computation: 88760 steps/s (collection: 0.984s, learning 0.124s)
               Value function loss: 0.6373
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8745
                     Learning rate: 0.0004
                       Mean reward: 130.02
               Mean episode length: 978.35
       Episode_Reward/keep_balance: 0.9752
     Episode_Reward/rew_lin_vel_xy: 6.0125
      Episode_Reward/rew_ang_vel_z: 2.4486
    Episode_Reward/pen_base_height: -0.3090
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1654
   Episode_Reward/pen_joint_torque: -0.2213
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2509
Episode_Reward/pen_flat_orientation: -0.1027
  Episode_Reward/pen_feet_distance: -0.0217
Episode_Reward/pen_feet_regulation: -0.4765
   Episode_Reward/foot_landing_vel: -0.1407
   Episode_Reward/test_gait_reward: -0.9226
Metrics/base_velocity/error_vel_xy: 1.0047
Metrics/base_velocity/error_vel_yaw: 1.3128
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 1.11s
                        Total time: 1582.94s
                               ETA: 1688.7s

################################################################################
                     [1m Learning iteration 1452/3000 [0m                     

                       Computation: 91425 steps/s (collection: 0.951s, learning 0.124s)
               Value function loss: 0.5141
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8734
                     Learning rate: 0.0006
                       Mean reward: 130.27
               Mean episode length: 973.04
       Episode_Reward/keep_balance: 0.9587
     Episode_Reward/rew_lin_vel_xy: 5.9650
      Episode_Reward/rew_ang_vel_z: 2.4028
    Episode_Reward/pen_base_height: -0.3170
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1684
   Episode_Reward/pen_joint_torque: -0.2289
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2522
Episode_Reward/pen_flat_orientation: -0.1047
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4787
   Episode_Reward/foot_landing_vel: -0.1294
   Episode_Reward/test_gait_reward: -0.9183
Metrics/base_velocity/error_vel_xy: 0.9786
Metrics/base_velocity/error_vel_yaw: 1.3137
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 1.08s
                        Total time: 1584.01s
                               ETA: 1687.6s

################################################################################
                     [1m Learning iteration 1453/3000 [0m                     

                       Computation: 89242 steps/s (collection: 0.974s, learning 0.128s)
               Value function loss: 0.6655
                    Surrogate loss: 0.0005
             Mean action noise std: 0.8733
                     Learning rate: 0.0002
                       Mean reward: 128.43
               Mean episode length: 975.00
       Episode_Reward/keep_balance: 0.9721
     Episode_Reward/rew_lin_vel_xy: 6.0965
      Episode_Reward/rew_ang_vel_z: 2.4509
    Episode_Reward/pen_base_height: -0.3242
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1635
   Episode_Reward/pen_joint_torque: -0.2335
    Episode_Reward/pen_joint_accel: -0.1078
    Episode_Reward/pen_action_rate: -0.1187
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0896
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2518
Episode_Reward/pen_flat_orientation: -0.1013
  Episode_Reward/pen_feet_distance: -0.0193
Episode_Reward/pen_feet_regulation: -0.4922
   Episode_Reward/foot_landing_vel: -0.1452
   Episode_Reward/test_gait_reward: -0.9182
Metrics/base_velocity/error_vel_xy: 0.9820
Metrics/base_velocity/error_vel_yaw: 1.3240
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 1.10s
                        Total time: 1585.11s
                               ETA: 1686.5s

################################################################################
                     [1m Learning iteration 1454/3000 [0m                     

                       Computation: 90005 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.5289
                    Surrogate loss: -0.0055
             Mean action noise std: 0.8728
                     Learning rate: 0.0004
                       Mean reward: 128.09
               Mean episode length: 975.88
       Episode_Reward/keep_balance: 0.9684
     Episode_Reward/rew_lin_vel_xy: 6.0432
      Episode_Reward/rew_ang_vel_z: 2.3848
    Episode_Reward/pen_base_height: -0.3166
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1653
   Episode_Reward/pen_joint_torque: -0.2330
    Episode_Reward/pen_joint_accel: -0.1033
    Episode_Reward/pen_action_rate: -0.1178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2536
Episode_Reward/pen_flat_orientation: -0.1038
  Episode_Reward/pen_feet_distance: -0.0231
Episode_Reward/pen_feet_regulation: -0.4772
   Episode_Reward/foot_landing_vel: -0.1342
   Episode_Reward/test_gait_reward: -0.9214
Metrics/base_velocity/error_vel_xy: 0.9774
Metrics/base_velocity/error_vel_yaw: 1.3552
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 1.09s
                        Total time: 1586.21s
                               ETA: 1685.4s

################################################################################
                     [1m Learning iteration 1455/3000 [0m                     

                       Computation: 92841 steps/s (collection: 0.936s, learning 0.122s)
               Value function loss: 0.6552
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8724
                     Learning rate: 0.0006
                       Mean reward: 131.05
               Mean episode length: 981.33
       Episode_Reward/keep_balance: 0.9634
     Episode_Reward/rew_lin_vel_xy: 6.0235
      Episode_Reward/rew_ang_vel_z: 2.4284
    Episode_Reward/pen_base_height: -0.3205
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1621
   Episode_Reward/pen_joint_torque: -0.2344
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2495
Episode_Reward/pen_flat_orientation: -0.1038
  Episode_Reward/pen_feet_distance: -0.0224
Episode_Reward/pen_feet_regulation: -0.4766
   Episode_Reward/foot_landing_vel: -0.1314
   Episode_Reward/test_gait_reward: -0.9224
Metrics/base_velocity/error_vel_xy: 0.9610
Metrics/base_velocity/error_vel_yaw: 1.2947
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 1.06s
                        Total time: 1587.26s
                               ETA: 1684.3s

################################################################################
                     [1m Learning iteration 1456/3000 [0m                     

                       Computation: 90416 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.6061
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8722
                     Learning rate: 0.0004
                       Mean reward: 130.31
               Mean episode length: 967.23
       Episode_Reward/keep_balance: 0.9303
     Episode_Reward/rew_lin_vel_xy: 5.7869
      Episode_Reward/rew_ang_vel_z: 2.3571
    Episode_Reward/pen_base_height: -0.2990
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1624
   Episode_Reward/pen_joint_torque: -0.2132
    Episode_Reward/pen_joint_accel: -0.1017
    Episode_Reward/pen_action_rate: -0.1122
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2413
Episode_Reward/pen_flat_orientation: -0.1133
  Episode_Reward/pen_feet_distance: -0.0228
Episode_Reward/pen_feet_regulation: -0.4401
   Episode_Reward/foot_landing_vel: -0.1476
   Episode_Reward/test_gait_reward: -0.8711
Metrics/base_velocity/error_vel_xy: 0.9348
Metrics/base_velocity/error_vel_yaw: 1.2494
      Episode_Termination/time_out: 3.0833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 1.09s
                        Total time: 1588.35s
                               ETA: 1683.2s

################################################################################
                     [1m Learning iteration 1457/3000 [0m                     

                       Computation: 90758 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.6573
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8733
                     Learning rate: 0.0004
                       Mean reward: 129.96
               Mean episode length: 979.51
       Episode_Reward/keep_balance: 0.9852
     Episode_Reward/rew_lin_vel_xy: 6.1153
      Episode_Reward/rew_ang_vel_z: 2.4649
    Episode_Reward/pen_base_height: -0.3247
      Episode_Reward/pen_lin_vel_z: -0.0415
     Episode_Reward/pen_ang_vel_xy: -0.1669
   Episode_Reward/pen_joint_torque: -0.2406
    Episode_Reward/pen_joint_accel: -0.1050
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0915
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2569
Episode_Reward/pen_flat_orientation: -0.0989
  Episode_Reward/pen_feet_distance: -0.0213
Episode_Reward/pen_feet_regulation: -0.4921
   Episode_Reward/foot_landing_vel: -0.1387
   Episode_Reward/test_gait_reward: -0.9384
Metrics/base_velocity/error_vel_xy: 1.0011
Metrics/base_velocity/error_vel_yaw: 1.3268
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 1.08s
                        Total time: 1589.43s
                               ETA: 1682.1s

################################################################################
                     [1m Learning iteration 1458/3000 [0m                     

                       Computation: 90309 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.5831
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8733
                     Learning rate: 0.0009
                       Mean reward: 128.99
               Mean episode length: 966.43
       Episode_Reward/keep_balance: 0.9753
     Episode_Reward/rew_lin_vel_xy: 6.0975
      Episode_Reward/rew_ang_vel_z: 2.4718
    Episode_Reward/pen_base_height: -0.3267
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1632
   Episode_Reward/pen_joint_torque: -0.2326
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.1178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2511
Episode_Reward/pen_flat_orientation: -0.0972
  Episode_Reward/pen_feet_distance: -0.0226
Episode_Reward/pen_feet_regulation: -0.4928
   Episode_Reward/foot_landing_vel: -0.1349
   Episode_Reward/test_gait_reward: -0.9256
Metrics/base_velocity/error_vel_xy: 0.9788
Metrics/base_velocity/error_vel_yaw: 1.2953
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 1.09s
                        Total time: 1590.52s
                               ETA: 1681.0s

################################################################################
                     [1m Learning iteration 1459/3000 [0m                     

                       Computation: 90914 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.5699
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8728
                     Learning rate: 0.0006
                       Mean reward: 128.59
               Mean episode length: 973.70
       Episode_Reward/keep_balance: 0.9694
     Episode_Reward/rew_lin_vel_xy: 6.0223
      Episode_Reward/rew_ang_vel_z: 2.4449
    Episode_Reward/pen_base_height: -0.3240
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1646
   Episode_Reward/pen_joint_torque: -0.2226
    Episode_Reward/pen_joint_accel: -0.1005
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2482
Episode_Reward/pen_flat_orientation: -0.1009
  Episode_Reward/pen_feet_distance: -0.0220
Episode_Reward/pen_feet_regulation: -0.4666
   Episode_Reward/foot_landing_vel: -0.1326
   Episode_Reward/test_gait_reward: -0.9203
Metrics/base_velocity/error_vel_xy: 1.0033
Metrics/base_velocity/error_vel_yaw: 1.2946
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 1.08s
                        Total time: 1591.60s
                               ETA: 1679.9s

################################################################################
                     [1m Learning iteration 1460/3000 [0m                     

                       Computation: 91975 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.6110
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8739
                     Learning rate: 0.0004
                       Mean reward: 125.88
               Mean episode length: 961.95
       Episode_Reward/keep_balance: 0.9527
     Episode_Reward/rew_lin_vel_xy: 5.9511
      Episode_Reward/rew_ang_vel_z: 2.3484
    Episode_Reward/pen_base_height: -0.3057
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1719
   Episode_Reward/pen_joint_torque: -0.2247
    Episode_Reward/pen_joint_accel: -0.1052
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2507
Episode_Reward/pen_flat_orientation: -0.0986
  Episode_Reward/pen_feet_distance: -0.0174
Episode_Reward/pen_feet_regulation: -0.4558
   Episode_Reward/foot_landing_vel: -0.1413
   Episode_Reward/test_gait_reward: -0.8977
Metrics/base_velocity/error_vel_xy: 0.9557
Metrics/base_velocity/error_vel_yaw: 1.3410
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 1.07s
                        Total time: 1592.67s
                               ETA: 1678.8s

################################################################################
                     [1m Learning iteration 1461/3000 [0m                     

                       Computation: 90197 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.6094
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8744
                     Learning rate: 0.0003
                       Mean reward: 130.30
               Mean episode length: 975.40
       Episode_Reward/keep_balance: 0.9662
     Episode_Reward/rew_lin_vel_xy: 6.0164
      Episode_Reward/rew_ang_vel_z: 2.4485
    Episode_Reward/pen_base_height: -0.3202
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.1640
   Episode_Reward/pen_joint_torque: -0.2301
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.1168
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2491
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0200
Episode_Reward/pen_feet_regulation: -0.4744
   Episode_Reward/foot_landing_vel: -0.1268
   Episode_Reward/test_gait_reward: -0.9161
Metrics/base_velocity/error_vel_xy: 0.9773
Metrics/base_velocity/error_vel_yaw: 1.2946
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 1.09s
                        Total time: 1593.76s
                               ETA: 1677.7s

################################################################################
                     [1m Learning iteration 1462/3000 [0m                     

                       Computation: 89042 steps/s (collection: 0.981s, learning 0.123s)
               Value function loss: 0.6143
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8745
                     Learning rate: 0.0004
                       Mean reward: 132.08
               Mean episode length: 978.86
       Episode_Reward/keep_balance: 0.9832
     Episode_Reward/rew_lin_vel_xy: 6.2065
      Episode_Reward/rew_ang_vel_z: 2.4780
    Episode_Reward/pen_base_height: -0.3046
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1701
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.1082
    Episode_Reward/pen_action_rate: -0.1180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2557
Episode_Reward/pen_flat_orientation: -0.0929
  Episode_Reward/pen_feet_distance: -0.0167
Episode_Reward/pen_feet_regulation: -0.4412
   Episode_Reward/foot_landing_vel: -0.1377
   Episode_Reward/test_gait_reward: -0.9228
Metrics/base_velocity/error_vel_xy: 0.9423
Metrics/base_velocity/error_vel_yaw: 1.3160
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 1.10s
                        Total time: 1594.87s
                               ETA: 1676.6s

################################################################################
                     [1m Learning iteration 1463/3000 [0m                     

                       Computation: 89899 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 0.7133
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8746
                     Learning rate: 0.0003
                       Mean reward: 131.18
               Mean episode length: 977.95
       Episode_Reward/keep_balance: 0.9719
     Episode_Reward/rew_lin_vel_xy: 6.0771
      Episode_Reward/rew_ang_vel_z: 2.4611
    Episode_Reward/pen_base_height: -0.3198
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1634
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1163
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2509
Episode_Reward/pen_flat_orientation: -0.0955
  Episode_Reward/pen_feet_distance: -0.0195
Episode_Reward/pen_feet_regulation: -0.4677
   Episode_Reward/foot_landing_vel: -0.1328
   Episode_Reward/test_gait_reward: -0.9214
Metrics/base_velocity/error_vel_xy: 0.9560
Metrics/base_velocity/error_vel_yaw: 1.2865
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 1.09s
                        Total time: 1595.96s
                               ETA: 1675.5s

################################################################################
                     [1m Learning iteration 1464/3000 [0m                     

                       Computation: 89632 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 0.6531
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8756
                     Learning rate: 0.0003
                       Mean reward: 129.09
               Mean episode length: 952.79
       Episode_Reward/keep_balance: 0.9480
     Episode_Reward/rew_lin_vel_xy: 5.9230
      Episode_Reward/rew_ang_vel_z: 2.3880
    Episode_Reward/pen_base_height: -0.3157
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1611
   Episode_Reward/pen_joint_torque: -0.2239
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.1133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0846
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2448
Episode_Reward/pen_flat_orientation: -0.0972
  Episode_Reward/pen_feet_distance: -0.0169
Episode_Reward/pen_feet_regulation: -0.4383
   Episode_Reward/foot_landing_vel: -0.1320
   Episode_Reward/test_gait_reward: -0.8942
Metrics/base_velocity/error_vel_xy: 0.9499
Metrics/base_velocity/error_vel_yaw: 1.2854
      Episode_Termination/time_out: 4.9583
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 1.10s
                        Total time: 1597.06s
                               ETA: 1674.5s

################################################################################
                     [1m Learning iteration 1465/3000 [0m                     

                       Computation: 90053 steps/s (collection: 0.966s, learning 0.125s)
               Value function loss: 0.6024
                    Surrogate loss: -0.0056
             Mean action noise std: 0.8752
                     Learning rate: 0.0006
                       Mean reward: 126.83
               Mean episode length: 954.49
       Episode_Reward/keep_balance: 0.9480
     Episode_Reward/rew_lin_vel_xy: 5.9208
      Episode_Reward/rew_ang_vel_z: 2.3749
    Episode_Reward/pen_base_height: -0.3414
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1638
   Episode_Reward/pen_joint_torque: -0.2385
    Episode_Reward/pen_joint_accel: -0.1015
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2477
Episode_Reward/pen_flat_orientation: -0.1070
  Episode_Reward/pen_feet_distance: -0.0202
Episode_Reward/pen_feet_regulation: -0.4724
   Episode_Reward/foot_landing_vel: -0.1428
   Episode_Reward/test_gait_reward: -0.9080
Metrics/base_velocity/error_vel_xy: 0.9434
Metrics/base_velocity/error_vel_yaw: 1.2971
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 1.09s
                        Total time: 1598.15s
                               ETA: 1673.4s

################################################################################
                     [1m Learning iteration 1466/3000 [0m                     

                       Computation: 89532 steps/s (collection: 0.972s, learning 0.126s)
               Value function loss: 0.6251
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8745
                     Learning rate: 0.0004
                       Mean reward: 128.58
               Mean episode length: 967.87
       Episode_Reward/keep_balance: 0.9785
     Episode_Reward/rew_lin_vel_xy: 6.0793
      Episode_Reward/rew_ang_vel_z: 2.4766
    Episode_Reward/pen_base_height: -0.3136
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1639
   Episode_Reward/pen_joint_torque: -0.2304
    Episode_Reward/pen_joint_accel: -0.1029
    Episode_Reward/pen_action_rate: -0.1179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2529
Episode_Reward/pen_flat_orientation: -0.0998
  Episode_Reward/pen_feet_distance: -0.0208
Episode_Reward/pen_feet_regulation: -0.4693
   Episode_Reward/foot_landing_vel: -0.1510
   Episode_Reward/test_gait_reward: -0.9216
Metrics/base_velocity/error_vel_xy: 0.9970
Metrics/base_velocity/error_vel_yaw: 1.3033
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 1.10s
                        Total time: 1599.25s
                               ETA: 1672.3s

################################################################################
                     [1m Learning iteration 1467/3000 [0m                     

                       Computation: 91701 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.6476
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8758
                     Learning rate: 0.0006
                       Mean reward: 129.93
               Mean episode length: 980.45
       Episode_Reward/keep_balance: 0.9762
     Episode_Reward/rew_lin_vel_xy: 5.9899
      Episode_Reward/rew_ang_vel_z: 2.4639
    Episode_Reward/pen_base_height: -0.3415
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1680
   Episode_Reward/pen_joint_torque: -0.2370
    Episode_Reward/pen_joint_accel: -0.0983
    Episode_Reward/pen_action_rate: -0.1184
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2510
Episode_Reward/pen_flat_orientation: -0.1000
  Episode_Reward/pen_feet_distance: -0.0217
Episode_Reward/pen_feet_regulation: -0.4802
   Episode_Reward/foot_landing_vel: -0.1328
   Episode_Reward/test_gait_reward: -0.9256
Metrics/base_velocity/error_vel_xy: 1.0298
Metrics/base_velocity/error_vel_yaw: 1.2982
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 1.07s
                        Total time: 1600.32s
                               ETA: 1671.2s

################################################################################
                     [1m Learning iteration 1468/3000 [0m                     

                       Computation: 89600 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.5224
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8768
                     Learning rate: 0.0006
                       Mean reward: 130.97
               Mean episode length: 982.13
       Episode_Reward/keep_balance: 0.9865
     Episode_Reward/rew_lin_vel_xy: 6.2159
      Episode_Reward/rew_ang_vel_z: 2.4847
    Episode_Reward/pen_base_height: -0.3424
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1664
   Episode_Reward/pen_joint_torque: -0.2422
    Episode_Reward/pen_joint_accel: -0.1017
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2543
Episode_Reward/pen_flat_orientation: -0.1027
  Episode_Reward/pen_feet_distance: -0.0231
Episode_Reward/pen_feet_regulation: -0.4873
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.9323
Metrics/base_velocity/error_vel_xy: 0.9790
Metrics/base_velocity/error_vel_yaw: 1.3199
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 1.10s
                        Total time: 1601.42s
                               ETA: 1670.1s

################################################################################
                     [1m Learning iteration 1469/3000 [0m                     

                       Computation: 90292 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.6553
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8768
                     Learning rate: 0.0004
                       Mean reward: 128.59
               Mean episode length: 973.20
       Episode_Reward/keep_balance: 0.9782
     Episode_Reward/rew_lin_vel_xy: 6.0827
      Episode_Reward/rew_ang_vel_z: 2.4544
    Episode_Reward/pen_base_height: -0.3231
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.1598
   Episode_Reward/pen_joint_torque: -0.2360
    Episode_Reward/pen_joint_accel: -0.1098
    Episode_Reward/pen_action_rate: -0.1182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2515
Episode_Reward/pen_flat_orientation: -0.0998
  Episode_Reward/pen_feet_distance: -0.0204
Episode_Reward/pen_feet_regulation: -0.4816
   Episode_Reward/foot_landing_vel: -0.1411
   Episode_Reward/test_gait_reward: -0.9298
Metrics/base_velocity/error_vel_xy: 0.9914
Metrics/base_velocity/error_vel_yaw: 1.3220
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 1.09s
                        Total time: 1602.50s
                               ETA: 1669.0s

################################################################################
                     [1m Learning iteration 1470/3000 [0m                     

                       Computation: 92105 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 0.6565
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8762
                     Learning rate: 0.0003
                       Mean reward: 130.08
               Mean episode length: 985.40
       Episode_Reward/keep_balance: 0.9872
     Episode_Reward/rew_lin_vel_xy: 6.1675
      Episode_Reward/rew_ang_vel_z: 2.5071
    Episode_Reward/pen_base_height: -0.3260
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1637
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.1059
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2535
Episode_Reward/pen_flat_orientation: -0.0980
  Episode_Reward/pen_feet_distance: -0.0219
Episode_Reward/pen_feet_regulation: -0.4779
   Episode_Reward/foot_landing_vel: -0.1343
   Episode_Reward/test_gait_reward: -0.9325
Metrics/base_velocity/error_vel_xy: 0.9874
Metrics/base_velocity/error_vel_yaw: 1.3074
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 1.07s
                        Total time: 1603.57s
                               ETA: 1667.9s

################################################################################
                     [1m Learning iteration 1471/3000 [0m                     

                       Computation: 90638 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.5413
                    Surrogate loss: -0.0007
             Mean action noise std: 0.8763
                     Learning rate: 0.0002
                       Mean reward: 122.23
               Mean episode length: 942.56
       Episode_Reward/keep_balance: 0.9404
     Episode_Reward/rew_lin_vel_xy: 5.8244
      Episode_Reward/rew_ang_vel_z: 2.3461
    Episode_Reward/pen_base_height: -0.3239
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1548
   Episode_Reward/pen_joint_torque: -0.2341
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.1142
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2441
Episode_Reward/pen_flat_orientation: -0.0984
  Episode_Reward/pen_feet_distance: -0.0202
Episode_Reward/pen_feet_regulation: -0.4614
   Episode_Reward/foot_landing_vel: -0.1334
   Episode_Reward/test_gait_reward: -0.8961
Metrics/base_velocity/error_vel_xy: 0.9750
Metrics/base_velocity/error_vel_yaw: 1.2890
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 1.08s
                        Total time: 1604.66s
                               ETA: 1666.8s

################################################################################
                     [1m Learning iteration 1472/3000 [0m                     

                       Computation: 89326 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.6377
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8767
                     Learning rate: 0.0004
                       Mean reward: 131.65
               Mean episode length: 994.84
       Episode_Reward/keep_balance: 0.9810
     Episode_Reward/rew_lin_vel_xy: 6.1089
      Episode_Reward/rew_ang_vel_z: 2.4570
    Episode_Reward/pen_base_height: -0.3351
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.1620
   Episode_Reward/pen_joint_torque: -0.2430
    Episode_Reward/pen_joint_accel: -0.1037
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2545
Episode_Reward/pen_flat_orientation: -0.0996
  Episode_Reward/pen_feet_distance: -0.0215
Episode_Reward/pen_feet_regulation: -0.4826
   Episode_Reward/foot_landing_vel: -0.1351
   Episode_Reward/test_gait_reward: -0.9338
Metrics/base_velocity/error_vel_xy: 0.9956
Metrics/base_velocity/error_vel_yaw: 1.3340
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 1.10s
                        Total time: 1605.76s
                               ETA: 1665.7s

################################################################################
                     [1m Learning iteration 1473/3000 [0m                     

                       Computation: 90087 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 0.5208
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8752
                     Learning rate: 0.0006
                       Mean reward: 130.32
               Mean episode length: 987.44
       Episode_Reward/keep_balance: 0.9855
     Episode_Reward/rew_lin_vel_xy: 6.1311
      Episode_Reward/rew_ang_vel_z: 2.4458
    Episode_Reward/pen_base_height: -0.3072
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1654
   Episode_Reward/pen_joint_torque: -0.2271
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2577
Episode_Reward/pen_flat_orientation: -0.0975
  Episode_Reward/pen_feet_distance: -0.0236
Episode_Reward/pen_feet_regulation: -0.4957
   Episode_Reward/foot_landing_vel: -0.1433
   Episode_Reward/test_gait_reward: -0.9415
Metrics/base_velocity/error_vel_xy: 1.0005
Metrics/base_velocity/error_vel_yaw: 1.3574
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 1.09s
                        Total time: 1606.85s
                               ETA: 1664.6s

################################################################################
                     [1m Learning iteration 1474/3000 [0m                     

                       Computation: 91136 steps/s (collection: 0.957s, learning 0.121s)
               Value function loss: 0.5846
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8752
                     Learning rate: 0.0006
                       Mean reward: 131.81
               Mean episode length: 987.16
       Episode_Reward/keep_balance: 0.9869
     Episode_Reward/rew_lin_vel_xy: 6.2317
      Episode_Reward/rew_ang_vel_z: 2.4606
    Episode_Reward/pen_base_height: -0.3136
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1687
   Episode_Reward/pen_joint_torque: -0.2272
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2583
Episode_Reward/pen_flat_orientation: -0.0948
  Episode_Reward/pen_feet_distance: -0.0198
Episode_Reward/pen_feet_regulation: -0.4895
   Episode_Reward/foot_landing_vel: -0.1380
   Episode_Reward/test_gait_reward: -0.9436
Metrics/base_velocity/error_vel_xy: 0.9607
Metrics/base_velocity/error_vel_yaw: 1.3417
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 1.08s
                        Total time: 1607.93s
                               ETA: 1663.5s

################################################################################
                     [1m Learning iteration 1475/3000 [0m                     

                       Computation: 91327 steps/s (collection: 0.952s, learning 0.125s)
               Value function loss: 0.5745
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8751
                     Learning rate: 0.0006
                       Mean reward: 132.45
               Mean episode length: 992.18
       Episode_Reward/keep_balance: 0.9954
     Episode_Reward/rew_lin_vel_xy: 6.2179
      Episode_Reward/rew_ang_vel_z: 2.4919
    Episode_Reward/pen_base_height: -0.3184
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1673
   Episode_Reward/pen_joint_torque: -0.2293
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2586
Episode_Reward/pen_flat_orientation: -0.0954
  Episode_Reward/pen_feet_distance: -0.0185
Episode_Reward/pen_feet_regulation: -0.4908
   Episode_Reward/foot_landing_vel: -0.1381
   Episode_Reward/test_gait_reward: -0.9473
Metrics/base_velocity/error_vel_xy: 0.9927
Metrics/base_velocity/error_vel_yaw: 1.3540
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 1.08s
                        Total time: 1609.00s
                               ETA: 1662.4s

################################################################################
                     [1m Learning iteration 1476/3000 [0m                     

                       Computation: 89295 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.6503
                    Surrogate loss: -0.0059
             Mean action noise std: 0.8747
                     Learning rate: 0.0009
                       Mean reward: 131.02
               Mean episode length: 989.20
       Episode_Reward/keep_balance: 0.9899
     Episode_Reward/rew_lin_vel_xy: 6.1590
      Episode_Reward/rew_ang_vel_z: 2.4911
    Episode_Reward/pen_base_height: -0.3318
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.1680
   Episode_Reward/pen_joint_torque: -0.2399
    Episode_Reward/pen_joint_accel: -0.1113
    Episode_Reward/pen_action_rate: -0.1207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2582
Episode_Reward/pen_flat_orientation: -0.1028
  Episode_Reward/pen_feet_distance: -0.0236
Episode_Reward/pen_feet_regulation: -0.5010
   Episode_Reward/foot_landing_vel: -0.1470
   Episode_Reward/test_gait_reward: -0.9455
Metrics/base_velocity/error_vel_xy: 1.0148
Metrics/base_velocity/error_vel_yaw: 1.3387
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 1.10s
                        Total time: 1610.10s
                               ETA: 1661.3s

################################################################################
                     [1m Learning iteration 1477/3000 [0m                     

                       Computation: 91390 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.6646
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8747
                     Learning rate: 0.0013
                       Mean reward: 128.87
               Mean episode length: 972.17
       Episode_Reward/keep_balance: 0.9770
     Episode_Reward/rew_lin_vel_xy: 6.0981
      Episode_Reward/rew_ang_vel_z: 2.4535
    Episode_Reward/pen_base_height: -0.3373
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1624
   Episode_Reward/pen_joint_torque: -0.2412
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2522
Episode_Reward/pen_flat_orientation: -0.1011
  Episode_Reward/pen_feet_distance: -0.0218
Episode_Reward/pen_feet_regulation: -0.4815
   Episode_Reward/foot_landing_vel: -0.1402
   Episode_Reward/test_gait_reward: -0.9354
Metrics/base_velocity/error_vel_xy: 0.9821
Metrics/base_velocity/error_vel_yaw: 1.3291
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 1.08s
                        Total time: 1611.18s
                               ETA: 1660.2s

################################################################################
                     [1m Learning iteration 1478/3000 [0m                     

                       Computation: 90907 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.6353
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8748
                     Learning rate: 0.0009
                       Mean reward: 131.07
               Mean episode length: 980.15
       Episode_Reward/keep_balance: 0.9742
     Episode_Reward/rew_lin_vel_xy: 6.1250
      Episode_Reward/rew_ang_vel_z: 2.4369
    Episode_Reward/pen_base_height: -0.3194
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1669
   Episode_Reward/pen_joint_torque: -0.2246
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1163
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2539
Episode_Reward/pen_flat_orientation: -0.0967
  Episode_Reward/pen_feet_distance: -0.0207
Episode_Reward/pen_feet_regulation: -0.4764
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9248
Metrics/base_velocity/error_vel_xy: 0.9605
Metrics/base_velocity/error_vel_yaw: 1.3218
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 1.08s
                        Total time: 1612.26s
                               ETA: 1659.1s

################################################################################
                     [1m Learning iteration 1479/3000 [0m                     

                       Computation: 90977 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.6503
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8766
                     Learning rate: 0.0004
                       Mean reward: 130.51
               Mean episode length: 978.57
       Episode_Reward/keep_balance: 0.9772
     Episode_Reward/rew_lin_vel_xy: 6.1367
      Episode_Reward/rew_ang_vel_z: 2.4630
    Episode_Reward/pen_base_height: -0.3275
      Episode_Reward/pen_lin_vel_z: -0.0389
     Episode_Reward/pen_ang_vel_xy: -0.1640
   Episode_Reward/pen_joint_torque: -0.2365
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.1189
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2536
Episode_Reward/pen_flat_orientation: -0.0991
  Episode_Reward/pen_feet_distance: -0.0218
Episode_Reward/pen_feet_regulation: -0.4821
   Episode_Reward/foot_landing_vel: -0.1414
   Episode_Reward/test_gait_reward: -0.9371
Metrics/base_velocity/error_vel_xy: 0.9611
Metrics/base_velocity/error_vel_yaw: 1.3058
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 1.08s
                        Total time: 1613.34s
                               ETA: 1658.0s

################################################################################
                     [1m Learning iteration 1480/3000 [0m                     

                       Computation: 92270 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 0.6060
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8769
                     Learning rate: 0.0004
                       Mean reward: 131.40
               Mean episode length: 971.40
       Episode_Reward/keep_balance: 0.9716
     Episode_Reward/rew_lin_vel_xy: 6.1058
      Episode_Reward/rew_ang_vel_z: 2.4552
    Episode_Reward/pen_base_height: -0.3277
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1588
   Episode_Reward/pen_joint_torque: -0.2292
    Episode_Reward/pen_joint_accel: -0.1008
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2502
Episode_Reward/pen_flat_orientation: -0.0985
  Episode_Reward/pen_feet_distance: -0.0207
Episode_Reward/pen_feet_regulation: -0.4668
   Episode_Reward/foot_landing_vel: -0.1300
   Episode_Reward/test_gait_reward: -0.9255
Metrics/base_velocity/error_vel_xy: 0.9473
Metrics/base_velocity/error_vel_yaw: 1.2981
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 1.07s
                        Total time: 1614.41s
                               ETA: 1656.9s

################################################################################
                     [1m Learning iteration 1481/3000 [0m                     

                       Computation: 88640 steps/s (collection: 0.987s, learning 0.122s)
               Value function loss: 0.5945
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8767
                     Learning rate: 0.0004
                       Mean reward: 131.16
               Mean episode length: 989.35
       Episode_Reward/keep_balance: 0.9892
     Episode_Reward/rew_lin_vel_xy: 6.2498
      Episode_Reward/rew_ang_vel_z: 2.4707
    Episode_Reward/pen_base_height: -0.3313
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1695
   Episode_Reward/pen_joint_torque: -0.2273
    Episode_Reward/pen_joint_accel: -0.1049
    Episode_Reward/pen_action_rate: -0.1189
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2586
Episode_Reward/pen_flat_orientation: -0.0967
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4750
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.9413
Metrics/base_velocity/error_vel_xy: 0.9531
Metrics/base_velocity/error_vel_yaw: 1.3535
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 1.11s
                        Total time: 1615.52s
                               ETA: 1655.8s

################################################################################
                     [1m Learning iteration 1482/3000 [0m                     

                       Computation: 90693 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.5316
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8770
                     Learning rate: 0.0006
                       Mean reward: 129.82
               Mean episode length: 979.97
       Episode_Reward/keep_balance: 0.9895
     Episode_Reward/rew_lin_vel_xy: 6.1842
      Episode_Reward/rew_ang_vel_z: 2.4642
    Episode_Reward/pen_base_height: -0.3522
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1584
   Episode_Reward/pen_joint_torque: -0.2487
    Episode_Reward/pen_joint_accel: -0.1078
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0912
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2550
Episode_Reward/pen_flat_orientation: -0.0961
  Episode_Reward/pen_feet_distance: -0.0257
Episode_Reward/pen_feet_regulation: -0.4949
   Episode_Reward/foot_landing_vel: -0.1395
   Episode_Reward/test_gait_reward: -0.9465
Metrics/base_velocity/error_vel_xy: 0.9905
Metrics/base_velocity/error_vel_yaw: 1.3504
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 1.08s
                        Total time: 1616.60s
                               ETA: 1654.8s

################################################################################
                     [1m Learning iteration 1483/3000 [0m                     

                       Computation: 90698 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.5470
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8774
                     Learning rate: 0.0001
                       Mean reward: 135.92
               Mean episode length: 991.66
       Episode_Reward/keep_balance: 0.9911
     Episode_Reward/rew_lin_vel_xy: 6.2863
      Episode_Reward/rew_ang_vel_z: 2.5189
    Episode_Reward/pen_base_height: -0.3430
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1625
   Episode_Reward/pen_joint_torque: -0.2383
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.1178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2538
Episode_Reward/pen_flat_orientation: -0.0934
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4662
   Episode_Reward/foot_landing_vel: -0.1291
   Episode_Reward/test_gait_reward: -0.9445
Metrics/base_velocity/error_vel_xy: 0.9325
Metrics/base_velocity/error_vel_yaw: 1.2986
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 1.08s
                        Total time: 1617.68s
                               ETA: 1653.7s

################################################################################
                     [1m Learning iteration 1484/3000 [0m                     

                       Computation: 91214 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.5629
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8766
                     Learning rate: 0.0002
                       Mean reward: 131.71
               Mean episode length: 982.91
       Episode_Reward/keep_balance: 0.9880
     Episode_Reward/rew_lin_vel_xy: 6.2796
      Episode_Reward/rew_ang_vel_z: 2.4558
    Episode_Reward/pen_base_height: -0.3170
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1626
   Episode_Reward/pen_joint_torque: -0.2299
    Episode_Reward/pen_joint_accel: -0.1191
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2600
Episode_Reward/pen_flat_orientation: -0.0954
  Episode_Reward/pen_feet_distance: -0.0232
Episode_Reward/pen_feet_regulation: -0.4828
   Episode_Reward/foot_landing_vel: -0.1371
   Episode_Reward/test_gait_reward: -0.9451
Metrics/base_velocity/error_vel_xy: 0.9389
Metrics/base_velocity/error_vel_yaw: 1.3587
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 1.08s
                        Total time: 1618.76s
                               ETA: 1652.6s

################################################################################
                     [1m Learning iteration 1485/3000 [0m                     

                       Computation: 89372 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.6749
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8765
                     Learning rate: 0.0004
                       Mean reward: 130.08
               Mean episode length: 971.42
       Episode_Reward/keep_balance: 0.9675
     Episode_Reward/rew_lin_vel_xy: 6.0970
      Episode_Reward/rew_ang_vel_z: 2.4806
    Episode_Reward/pen_base_height: -0.3238
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1600
   Episode_Reward/pen_joint_torque: -0.2248
    Episode_Reward/pen_joint_accel: -0.1079
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0856
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2482
Episode_Reward/pen_flat_orientation: -0.0959
  Episode_Reward/pen_feet_distance: -0.0215
Episode_Reward/pen_feet_regulation: -0.4635
   Episode_Reward/foot_landing_vel: -0.1343
   Episode_Reward/test_gait_reward: -0.9238
Metrics/base_velocity/error_vel_xy: 0.9485
Metrics/base_velocity/error_vel_yaw: 1.2667
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 1.10s
                        Total time: 1619.86s
                               ETA: 1651.5s

################################################################################
                     [1m Learning iteration 1486/3000 [0m                     

                       Computation: 90174 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.6387
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8755
                     Learning rate: 0.0003
                       Mean reward: 133.93
               Mean episode length: 990.60
       Episode_Reward/keep_balance: 0.9898
     Episode_Reward/rew_lin_vel_xy: 6.2652
      Episode_Reward/rew_ang_vel_z: 2.5098
    Episode_Reward/pen_base_height: -0.3353
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1583
   Episode_Reward/pen_joint_torque: -0.2293
    Episode_Reward/pen_joint_accel: -0.1049
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2541
Episode_Reward/pen_flat_orientation: -0.0915
  Episode_Reward/pen_feet_distance: -0.0207
Episode_Reward/pen_feet_regulation: -0.4711
   Episode_Reward/foot_landing_vel: -0.1259
   Episode_Reward/test_gait_reward: -0.9467
Metrics/base_velocity/error_vel_xy: 0.9458
Metrics/base_velocity/error_vel_yaw: 1.3212
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 1.09s
                        Total time: 1620.95s
                               ETA: 1650.4s

################################################################################
                     [1m Learning iteration 1487/3000 [0m                     

                       Computation: 89686 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.6840
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8760
                     Learning rate: 0.0006
                       Mean reward: 134.55
               Mean episode length: 986.24
       Episode_Reward/keep_balance: 0.9797
     Episode_Reward/rew_lin_vel_xy: 6.1824
      Episode_Reward/rew_ang_vel_z: 2.4760
    Episode_Reward/pen_base_height: -0.3393
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1671
   Episode_Reward/pen_joint_torque: -0.2353
    Episode_Reward/pen_joint_accel: -0.1123
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2576
Episode_Reward/pen_flat_orientation: -0.0969
  Episode_Reward/pen_feet_distance: -0.0219
Episode_Reward/pen_feet_regulation: -0.4733
   Episode_Reward/foot_landing_vel: -0.1316
   Episode_Reward/test_gait_reward: -0.9356
Metrics/base_velocity/error_vel_xy: 0.9466
Metrics/base_velocity/error_vel_yaw: 1.3091
      Episode_Termination/time_out: 4.8333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 1.10s
                        Total time: 1622.05s
                               ETA: 1649.3s

################################################################################
                     [1m Learning iteration 1488/3000 [0m                     

                       Computation: 90132 steps/s (collection: 0.966s, learning 0.125s)
               Value function loss: 0.5630
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8785
                     Learning rate: 0.0009
                       Mean reward: 131.42
               Mean episode length: 978.12
       Episode_Reward/keep_balance: 0.9824
     Episode_Reward/rew_lin_vel_xy: 6.1784
      Episode_Reward/rew_ang_vel_z: 2.4925
    Episode_Reward/pen_base_height: -0.3259
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1643
   Episode_Reward/pen_joint_torque: -0.2352
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0891
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2546
Episode_Reward/pen_flat_orientation: -0.0900
  Episode_Reward/pen_feet_distance: -0.0180
Episode_Reward/pen_feet_regulation: -0.4647
   Episode_Reward/foot_landing_vel: -0.1387
   Episode_Reward/test_gait_reward: -0.9265
Metrics/base_velocity/error_vel_xy: 0.9584
Metrics/base_velocity/error_vel_yaw: 1.2938
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 1.09s
                        Total time: 1623.14s
                               ETA: 1648.2s

################################################################################
                     [1m Learning iteration 1489/3000 [0m                     

                       Computation: 88891 steps/s (collection: 0.983s, learning 0.123s)
               Value function loss: 0.5589
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8790
                     Learning rate: 0.0006
                       Mean reward: 127.76
               Mean episode length: 955.68
       Episode_Reward/keep_balance: 0.9638
     Episode_Reward/rew_lin_vel_xy: 6.0962
      Episode_Reward/rew_ang_vel_z: 2.4420
    Episode_Reward/pen_base_height: -0.3251
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1545
   Episode_Reward/pen_joint_torque: -0.2322
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.1156
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2465
Episode_Reward/pen_flat_orientation: -0.0925
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4697
   Episode_Reward/foot_landing_vel: -0.1373
   Episode_Reward/test_gait_reward: -0.9190
Metrics/base_velocity/error_vel_xy: 0.9272
Metrics/base_velocity/error_vel_yaw: 1.2761
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 1.11s
                        Total time: 1624.24s
                               ETA: 1647.1s

################################################################################
                     [1m Learning iteration 1490/3000 [0m                     

                       Computation: 90577 steps/s (collection: 0.964s, learning 0.121s)
               Value function loss: 0.6092
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8791
                     Learning rate: 0.0009
                       Mean reward: 132.54
               Mean episode length: 989.73
       Episode_Reward/keep_balance: 0.9940
     Episode_Reward/rew_lin_vel_xy: 6.2576
      Episode_Reward/rew_ang_vel_z: 2.5296
    Episode_Reward/pen_base_height: -0.3587
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1587
   Episode_Reward/pen_joint_torque: -0.2471
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2549
Episode_Reward/pen_flat_orientation: -0.0944
  Episode_Reward/pen_feet_distance: -0.0262
Episode_Reward/pen_feet_regulation: -0.4863
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.9466
Metrics/base_velocity/error_vel_xy: 0.9693
Metrics/base_velocity/error_vel_yaw: 1.3109
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 1.09s
                        Total time: 1625.33s
                               ETA: 1646.0s

################################################################################
                     [1m Learning iteration 1491/3000 [0m                     

                       Computation: 89794 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.5341
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8782
                     Learning rate: 0.0004
                       Mean reward: 129.18
               Mean episode length: 966.76
       Episode_Reward/keep_balance: 0.9597
     Episode_Reward/rew_lin_vel_xy: 5.9877
      Episode_Reward/rew_ang_vel_z: 2.4427
    Episode_Reward/pen_base_height: -0.3266
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1537
   Episode_Reward/pen_joint_torque: -0.2333
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1160
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2471
Episode_Reward/pen_flat_orientation: -0.0943
  Episode_Reward/pen_feet_distance: -0.0208
Episode_Reward/pen_feet_regulation: -0.4480
   Episode_Reward/foot_landing_vel: -0.1421
   Episode_Reward/test_gait_reward: -0.9052
Metrics/base_velocity/error_vel_xy: 0.9602
Metrics/base_velocity/error_vel_yaw: 1.2571
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 1.09s
                        Total time: 1626.42s
                               ETA: 1645.0s

################################################################################
                     [1m Learning iteration 1492/3000 [0m                     

                       Computation: 90589 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.5592
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8797
                     Learning rate: 0.0004
                       Mean reward: 130.76
               Mean episode length: 983.67
       Episode_Reward/keep_balance: 0.9789
     Episode_Reward/rew_lin_vel_xy: 6.1063
      Episode_Reward/rew_ang_vel_z: 2.4510
    Episode_Reward/pen_base_height: -0.3237
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1638
   Episode_Reward/pen_joint_torque: -0.2389
    Episode_Reward/pen_joint_accel: -0.1093
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2551
Episode_Reward/pen_flat_orientation: -0.0947
  Episode_Reward/pen_feet_distance: -0.0172
Episode_Reward/pen_feet_regulation: -0.5004
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.9369
Metrics/base_velocity/error_vel_xy: 0.9903
Metrics/base_velocity/error_vel_yaw: 1.3146
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 1.09s
                        Total time: 1627.51s
                               ETA: 1643.9s

################################################################################
                     [1m Learning iteration 1493/3000 [0m                     

                       Computation: 91226 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.5611
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8805
                     Learning rate: 0.0006
                       Mean reward: 132.49
               Mean episode length: 974.64
       Episode_Reward/keep_balance: 0.9768
     Episode_Reward/rew_lin_vel_xy: 6.1358
      Episode_Reward/rew_ang_vel_z: 2.4788
    Episode_Reward/pen_base_height: -0.3161
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.1587
   Episode_Reward/pen_joint_torque: -0.2214
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.1164
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0852
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2521
Episode_Reward/pen_flat_orientation: -0.0939
  Episode_Reward/pen_feet_distance: -0.0249
Episode_Reward/pen_feet_regulation: -0.4656
   Episode_Reward/foot_landing_vel: -0.1269
   Episode_Reward/test_gait_reward: -0.9328
Metrics/base_velocity/error_vel_xy: 0.9549
Metrics/base_velocity/error_vel_yaw: 1.2930
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 1.08s
                        Total time: 1628.59s
                               ETA: 1642.8s

################################################################################
                     [1m Learning iteration 1494/3000 [0m                     

                       Computation: 91718 steps/s (collection: 0.950s, learning 0.121s)
               Value function loss: 0.5545
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8805
                     Learning rate: 0.0004
                       Mean reward: 133.21
               Mean episode length: 990.75
       Episode_Reward/keep_balance: 0.9965
     Episode_Reward/rew_lin_vel_xy: 6.2351
      Episode_Reward/rew_ang_vel_z: 2.4828
    Episode_Reward/pen_base_height: -0.3511
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1673
   Episode_Reward/pen_joint_torque: -0.2337
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1223
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2619
Episode_Reward/pen_flat_orientation: -0.0932
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4906
   Episode_Reward/foot_landing_vel: -0.1336
   Episode_Reward/test_gait_reward: -0.9560
Metrics/base_velocity/error_vel_xy: 0.9889
Metrics/base_velocity/error_vel_yaw: 1.3713
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 1.07s
                        Total time: 1629.66s
                               ETA: 1641.7s

################################################################################
                     [1m Learning iteration 1495/3000 [0m                     

                       Computation: 91370 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.5397
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8792
                     Learning rate: 0.0004
                       Mean reward: 129.72
               Mean episode length: 966.13
       Episode_Reward/keep_balance: 0.9529
     Episode_Reward/rew_lin_vel_xy: 6.0480
      Episode_Reward/rew_ang_vel_z: 2.4112
    Episode_Reward/pen_base_height: -0.3163
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1536
   Episode_Reward/pen_joint_torque: -0.2328
    Episode_Reward/pen_joint_accel: -0.1052
    Episode_Reward/pen_action_rate: -0.1157
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2483
Episode_Reward/pen_flat_orientation: -0.0880
  Episode_Reward/pen_feet_distance: -0.0202
Episode_Reward/pen_feet_regulation: -0.4672
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.9072
Metrics/base_velocity/error_vel_xy: 0.9131
Metrics/base_velocity/error_vel_yaw: 1.2648
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 1.08s
                        Total time: 1630.74s
                               ETA: 1640.5s

################################################################################
                     [1m Learning iteration 1496/3000 [0m                     

                       Computation: 91033 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.6344
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8790
                     Learning rate: 0.0006
                       Mean reward: 130.88
               Mean episode length: 982.58
       Episode_Reward/keep_balance: 0.9824
     Episode_Reward/rew_lin_vel_xy: 6.1279
      Episode_Reward/rew_ang_vel_z: 2.4963
    Episode_Reward/pen_base_height: -0.3452
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1608
   Episode_Reward/pen_joint_torque: -0.2344
    Episode_Reward/pen_joint_accel: -0.1061
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2554
Episode_Reward/pen_flat_orientation: -0.0910
  Episode_Reward/pen_feet_distance: -0.0233
Episode_Reward/pen_feet_regulation: -0.4640
   Episode_Reward/foot_landing_vel: -0.1335
   Episode_Reward/test_gait_reward: -0.9342
Metrics/base_velocity/error_vel_xy: 0.9810
Metrics/base_velocity/error_vel_yaw: 1.2886
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 1.08s
                        Total time: 1631.82s
                               ETA: 1639.4s

################################################################################
                     [1m Learning iteration 1497/3000 [0m                     

                       Computation: 91022 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.6145
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8795
                     Learning rate: 0.0006
                       Mean reward: 130.14
               Mean episode length: 974.90
       Episode_Reward/keep_balance: 0.9745
     Episode_Reward/rew_lin_vel_xy: 6.1409
      Episode_Reward/rew_ang_vel_z: 2.4625
    Episode_Reward/pen_base_height: -0.3208
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1651
   Episode_Reward/pen_joint_torque: -0.2229
    Episode_Reward/pen_joint_accel: -0.1058
    Episode_Reward/pen_action_rate: -0.1177
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2537
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0222
Episode_Reward/pen_feet_regulation: -0.4679
   Episode_Reward/foot_landing_vel: -0.1380
   Episode_Reward/test_gait_reward: -0.9320
Metrics/base_velocity/error_vel_xy: 0.9467
Metrics/base_velocity/error_vel_yaw: 1.2992
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 1.08s
                        Total time: 1632.90s
                               ETA: 1638.3s

################################################################################
                     [1m Learning iteration 1498/3000 [0m                     

                       Computation: 90784 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.5710
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8788
                     Learning rate: 0.0004
                       Mean reward: 135.00
               Mean episode length: 994.25
       Episode_Reward/keep_balance: 0.9954
     Episode_Reward/rew_lin_vel_xy: 6.2943
      Episode_Reward/rew_ang_vel_z: 2.5470
    Episode_Reward/pen_base_height: -0.3088
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1616
   Episode_Reward/pen_joint_torque: -0.2338
    Episode_Reward/pen_joint_accel: -0.1106
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2585
Episode_Reward/pen_flat_orientation: -0.0911
  Episode_Reward/pen_feet_distance: -0.0209
Episode_Reward/pen_feet_regulation: -0.4618
   Episode_Reward/foot_landing_vel: -0.1532
   Episode_Reward/test_gait_reward: -0.9380
Metrics/base_velocity/error_vel_xy: 0.9518
Metrics/base_velocity/error_vel_yaw: 1.2899
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 1.08s
                        Total time: 1633.98s
                               ETA: 1637.2s

################################################################################
                     [1m Learning iteration 1499/3000 [0m                     

                       Computation: 89811 steps/s (collection: 0.969s, learning 0.126s)
               Value function loss: 0.5943
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8778
                     Learning rate: 0.0006
                       Mean reward: 126.45
               Mean episode length: 969.42
       Episode_Reward/keep_balance: 0.9708
     Episode_Reward/rew_lin_vel_xy: 6.0082
      Episode_Reward/rew_ang_vel_z: 2.4484
    Episode_Reward/pen_base_height: -0.3427
      Episode_Reward/pen_lin_vel_z: -0.0389
     Episode_Reward/pen_ang_vel_xy: -0.1572
   Episode_Reward/pen_joint_torque: -0.2364
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1189
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2547
Episode_Reward/pen_flat_orientation: -0.0954
  Episode_Reward/pen_feet_distance: -0.0187
Episode_Reward/pen_feet_regulation: -0.4820
   Episode_Reward/foot_landing_vel: -0.1313
   Episode_Reward/test_gait_reward: -0.9271
Metrics/base_velocity/error_vel_xy: 1.0081
Metrics/base_velocity/error_vel_yaw: 1.2937
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 1.09s
                        Total time: 1635.07s
                               ETA: 1636.2s

################################################################################
                     [1m Learning iteration 1500/3000 [0m                     

                       Computation: 91665 steps/s (collection: 0.946s, learning 0.126s)
               Value function loss: 0.5719
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8765
                     Learning rate: 0.0006
                       Mean reward: 131.97
               Mean episode length: 994.68
       Episode_Reward/keep_balance: 0.9965
     Episode_Reward/rew_lin_vel_xy: 6.2282
      Episode_Reward/rew_ang_vel_z: 2.5487
    Episode_Reward/pen_base_height: -0.3524
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1643
   Episode_Reward/pen_joint_torque: -0.2404
    Episode_Reward/pen_joint_accel: -0.1089
    Episode_Reward/pen_action_rate: -0.1209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2592
Episode_Reward/pen_flat_orientation: -0.0925
  Episode_Reward/pen_feet_distance: -0.0245
Episode_Reward/pen_feet_regulation: -0.5006
   Episode_Reward/foot_landing_vel: -0.1300
   Episode_Reward/test_gait_reward: -0.9533
Metrics/base_velocity/error_vel_xy: 0.9977
Metrics/base_velocity/error_vel_yaw: 1.2938
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 147554304
                    Iteration time: 1.07s
                        Total time: 1636.14s
                               ETA: 1635.1s

################################################################################
                     [1m Learning iteration 1501/3000 [0m                     

                       Computation: 91758 steps/s (collection: 0.947s, learning 0.125s)
               Value function loss: 0.5650
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8764
                     Learning rate: 0.0004
                       Mean reward: 132.56
               Mean episode length: 972.98
       Episode_Reward/keep_balance: 0.9476
     Episode_Reward/rew_lin_vel_xy: 5.9961
      Episode_Reward/rew_ang_vel_z: 2.3815
    Episode_Reward/pen_base_height: -0.2971
      Episode_Reward/pen_lin_vel_z: -0.0343
     Episode_Reward/pen_ang_vel_xy: -0.1551
   Episode_Reward/pen_joint_torque: -0.2118
    Episode_Reward/pen_joint_accel: -0.0997
    Episode_Reward/pen_action_rate: -0.1143
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0537
   Episode_Reward/pen_joint_powers: -0.0828
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2483
Episode_Reward/pen_flat_orientation: -0.0913
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4426
   Episode_Reward/foot_landing_vel: -0.1332
   Episode_Reward/test_gait_reward: -0.8996
Metrics/base_velocity/error_vel_xy: 0.8998
Metrics/base_velocity/error_vel_yaw: 1.2964
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 147652608
                    Iteration time: 1.07s
                        Total time: 1637.22s
                               ETA: 1633.9s

################################################################################
                     [1m Learning iteration 1502/3000 [0m                     

                       Computation: 90974 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.5801
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8760
                     Learning rate: 0.0004
                       Mean reward: 131.80
               Mean episode length: 990.31
       Episode_Reward/keep_balance: 0.9906
     Episode_Reward/rew_lin_vel_xy: 6.1864
      Episode_Reward/rew_ang_vel_z: 2.4819
    Episode_Reward/pen_base_height: -0.3288
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.1647
   Episode_Reward/pen_joint_torque: -0.2355
    Episode_Reward/pen_joint_accel: -0.1193
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2607
Episode_Reward/pen_flat_orientation: -0.0936
  Episode_Reward/pen_feet_distance: -0.0263
Episode_Reward/pen_feet_regulation: -0.4902
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9467
Metrics/base_velocity/error_vel_xy: 1.0080
Metrics/base_velocity/error_vel_yaw: 1.3281
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 147750912
                    Iteration time: 1.08s
                        Total time: 1638.30s
                               ETA: 1632.8s

################################################################################
                     [1m Learning iteration 1503/3000 [0m                     

                       Computation: 88118 steps/s (collection: 0.988s, learning 0.127s)
               Value function loss: 0.6413
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8764
                     Learning rate: 0.0006
                       Mean reward: 133.34
               Mean episode length: 988.85
       Episode_Reward/keep_balance: 0.9906
     Episode_Reward/rew_lin_vel_xy: 6.2176
      Episode_Reward/rew_ang_vel_z: 2.5035
    Episode_Reward/pen_base_height: -0.3192
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1688
   Episode_Reward/pen_joint_torque: -0.2324
    Episode_Reward/pen_joint_accel: -0.1057
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2584
Episode_Reward/pen_flat_orientation: -0.0948
  Episode_Reward/pen_feet_distance: -0.0229
Episode_Reward/pen_feet_regulation: -0.4671
   Episode_Reward/foot_landing_vel: -0.1406
   Episode_Reward/test_gait_reward: -0.9326
Metrics/base_velocity/error_vel_xy: 0.9664
Metrics/base_velocity/error_vel_yaw: 1.3191
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 147849216
                    Iteration time: 1.12s
                        Total time: 1639.41s
                               ETA: 1631.8s

################################################################################
                     [1m Learning iteration 1504/3000 [0m                     

                       Computation: 89304 steps/s (collection: 0.974s, learning 0.127s)
               Value function loss: 0.5461
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8770
                     Learning rate: 0.0004
                       Mean reward: 131.54
               Mean episode length: 964.07
       Episode_Reward/keep_balance: 0.9722
     Episode_Reward/rew_lin_vel_xy: 6.2166
      Episode_Reward/rew_ang_vel_z: 2.4386
    Episode_Reward/pen_base_height: -0.3159
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.1602
   Episode_Reward/pen_joint_torque: -0.2193
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0848
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2531
Episode_Reward/pen_flat_orientation: -0.0873
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4418
   Episode_Reward/foot_landing_vel: -0.1368
   Episode_Reward/test_gait_reward: -0.9194
Metrics/base_velocity/error_vel_xy: 0.9110
Metrics/base_velocity/error_vel_yaw: 1.3131
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147947520
                    Iteration time: 1.10s
                        Total time: 1640.51s
                               ETA: 1630.7s

################################################################################
                     [1m Learning iteration 1505/3000 [0m                     

                       Computation: 89865 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.5229
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8776
                     Learning rate: 0.0004
                       Mean reward: 136.16
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.3249
      Episode_Reward/rew_ang_vel_z: 2.5776
    Episode_Reward/pen_base_height: -0.3335
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1589
   Episode_Reward/pen_joint_torque: -0.2346
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.1184
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2556
Episode_Reward/pen_flat_orientation: -0.0861
  Episode_Reward/pen_feet_distance: -0.0212
Episode_Reward/pen_feet_regulation: -0.4625
   Episode_Reward/foot_landing_vel: -0.1306
   Episode_Reward/test_gait_reward: -0.9449
Metrics/base_velocity/error_vel_xy: 0.9636
Metrics/base_velocity/error_vel_yaw: 1.2840
      Episode_Termination/time_out: 5.0417
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 148045824
                    Iteration time: 1.09s
                        Total time: 1641.61s
                               ETA: 1629.6s

################################################################################
                     [1m Learning iteration 1506/3000 [0m                     

                       Computation: 87150 steps/s (collection: 1.001s, learning 0.127s)
               Value function loss: 0.5380
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8788
                     Learning rate: 0.0006
                       Mean reward: 136.57
               Mean episode length: 988.84
       Episode_Reward/keep_balance: 0.9933
     Episode_Reward/rew_lin_vel_xy: 6.3094
      Episode_Reward/rew_ang_vel_z: 2.5301
    Episode_Reward/pen_base_height: -0.3247
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1613
   Episode_Reward/pen_joint_torque: -0.2345
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2571
Episode_Reward/pen_flat_orientation: -0.0883
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4583
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.9409
Metrics/base_velocity/error_vel_xy: 0.9348
Metrics/base_velocity/error_vel_yaw: 1.2916
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 148144128
                    Iteration time: 1.13s
                        Total time: 1642.73s
                               ETA: 1628.6s

################################################################################
                     [1m Learning iteration 1507/3000 [0m                     

                       Computation: 89936 steps/s (collection: 0.968s, learning 0.125s)
               Value function loss: 0.5976
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8803
                     Learning rate: 0.0006
                       Mean reward: 130.26
               Mean episode length: 989.48
       Episode_Reward/keep_balance: 0.9945
     Episode_Reward/rew_lin_vel_xy: 6.1926
      Episode_Reward/rew_ang_vel_z: 2.4975
    Episode_Reward/pen_base_height: -0.3407
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1654
   Episode_Reward/pen_joint_torque: -0.2435
    Episode_Reward/pen_joint_accel: -0.1076
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2628
Episode_Reward/pen_flat_orientation: -0.0975
  Episode_Reward/pen_feet_distance: -0.0217
Episode_Reward/pen_feet_regulation: -0.4942
   Episode_Reward/foot_landing_vel: -0.1442
   Episode_Reward/test_gait_reward: -0.9476
Metrics/base_velocity/error_vel_xy: 1.0102
Metrics/base_velocity/error_vel_yaw: 1.3538
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 148242432
                    Iteration time: 1.09s
                        Total time: 1643.83s
                               ETA: 1627.5s

################################################################################
                     [1m Learning iteration 1508/3000 [0m                     

                       Computation: 90633 steps/s (collection: 0.960s, learning 0.125s)
               Value function loss: 0.5591
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8797
                     Learning rate: 0.0009
                       Mean reward: 129.95
               Mean episode length: 977.69
       Episode_Reward/keep_balance: 0.9743
     Episode_Reward/rew_lin_vel_xy: 6.0812
      Episode_Reward/rew_ang_vel_z: 2.4331
    Episode_Reward/pen_base_height: -0.3202
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1655
   Episode_Reward/pen_joint_torque: -0.2340
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.1192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0896
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2561
Episode_Reward/pen_flat_orientation: -0.0950
  Episode_Reward/pen_feet_distance: -0.0212
Episode_Reward/pen_feet_regulation: -0.4833
   Episode_Reward/foot_landing_vel: -0.1483
   Episode_Reward/test_gait_reward: -0.9227
Metrics/base_velocity/error_vel_xy: 0.9809
Metrics/base_velocity/error_vel_yaw: 1.3278
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 148340736
                    Iteration time: 1.08s
                        Total time: 1644.91s
                               ETA: 1626.4s

################################################################################
                     [1m Learning iteration 1509/3000 [0m                     

                       Computation: 91145 steps/s (collection: 0.952s, learning 0.126s)
               Value function loss: 0.5295
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8788
                     Learning rate: 0.0003
                       Mean reward: 132.17
               Mean episode length: 994.84
       Episode_Reward/keep_balance: 0.9936
     Episode_Reward/rew_lin_vel_xy: 6.0963
      Episode_Reward/rew_ang_vel_z: 2.5137
    Episode_Reward/pen_base_height: -0.3338
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1633
   Episode_Reward/pen_joint_torque: -0.2388
    Episode_Reward/pen_joint_accel: -0.1016
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2582
Episode_Reward/pen_flat_orientation: -0.0891
  Episode_Reward/pen_feet_distance: -0.0241
Episode_Reward/pen_feet_regulation: -0.4739
   Episode_Reward/foot_landing_vel: -0.1393
   Episode_Reward/test_gait_reward: -0.9373
Metrics/base_velocity/error_vel_xy: 1.0242
Metrics/base_velocity/error_vel_yaw: 1.3143
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 148439040
                    Iteration time: 1.08s
                        Total time: 1645.99s
                               ETA: 1625.3s

################################################################################
                     [1m Learning iteration 1510/3000 [0m                     

                       Computation: 91172 steps/s (collection: 0.954s, learning 0.125s)
               Value function loss: 0.5573
                    Surrogate loss: -0.0006
             Mean action noise std: 0.8782
                     Learning rate: 0.0002
                       Mean reward: 133.99
               Mean episode length: 986.14
       Episode_Reward/keep_balance: 0.9910
     Episode_Reward/rew_lin_vel_xy: 6.2051
      Episode_Reward/rew_ang_vel_z: 2.5289
    Episode_Reward/pen_base_height: -0.3274
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1608
   Episode_Reward/pen_joint_torque: -0.2385
    Episode_Reward/pen_joint_accel: -0.0999
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2533
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0207
Episode_Reward/pen_feet_regulation: -0.4638
   Episode_Reward/foot_landing_vel: -0.1338
   Episode_Reward/test_gait_reward: -0.9324
Metrics/base_velocity/error_vel_xy: 0.9752
Metrics/base_velocity/error_vel_yaw: 1.2997
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 148537344
                    Iteration time: 1.08s
                        Total time: 1647.07s
                               ETA: 1624.2s

################################################################################
                     [1m Learning iteration 1511/3000 [0m                     

                       Computation: 91348 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.4630
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8762
                     Learning rate: 0.0004
                       Mean reward: 130.52
               Mean episode length: 974.86
       Episode_Reward/keep_balance: 0.9768
     Episode_Reward/rew_lin_vel_xy: 6.0818
      Episode_Reward/rew_ang_vel_z: 2.4597
    Episode_Reward/pen_base_height: -0.3081
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.1575
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.1155
    Episode_Reward/pen_action_rate: -0.1180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2534
Episode_Reward/pen_flat_orientation: -0.0931
  Episode_Reward/pen_feet_distance: -0.0204
Episode_Reward/pen_feet_regulation: -0.4910
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.9221
Metrics/base_velocity/error_vel_xy: 0.9787
Metrics/base_velocity/error_vel_yaw: 1.3088
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 148635648
                    Iteration time: 1.08s
                        Total time: 1648.15s
                               ETA: 1623.1s

################################################################################
                     [1m Learning iteration 1512/3000 [0m                     

                       Computation: 91694 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.5253
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8755
                     Learning rate: 0.0003
                       Mean reward: 132.65
               Mean episode length: 997.91
       Episode_Reward/keep_balance: 0.9971
     Episode_Reward/rew_lin_vel_xy: 6.2425
      Episode_Reward/rew_ang_vel_z: 2.5349
    Episode_Reward/pen_base_height: -0.3269
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.1631
   Episode_Reward/pen_joint_torque: -0.2346
    Episode_Reward/pen_joint_accel: -0.1111
    Episode_Reward/pen_action_rate: -0.1201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2603
Episode_Reward/pen_flat_orientation: -0.0959
  Episode_Reward/pen_feet_distance: -0.0186
Episode_Reward/pen_feet_regulation: -0.4721
   Episode_Reward/foot_landing_vel: -0.1378
   Episode_Reward/test_gait_reward: -0.9505
Metrics/base_velocity/error_vel_xy: 0.9934
Metrics/base_velocity/error_vel_yaw: 1.3197
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 148733952
                    Iteration time: 1.07s
                        Total time: 1649.22s
                               ETA: 1622.0s

################################################################################
                     [1m Learning iteration 1513/3000 [0m                     

                       Computation: 89255 steps/s (collection: 0.978s, learning 0.124s)
               Value function loss: 0.5237
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8740
                     Learning rate: 0.0006
                       Mean reward: 133.59
               Mean episode length: 976.85
       Episode_Reward/keep_balance: 0.9570
     Episode_Reward/rew_lin_vel_xy: 5.9977
      Episode_Reward/rew_ang_vel_z: 2.4684
    Episode_Reward/pen_base_height: -0.3131
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1519
   Episode_Reward/pen_joint_torque: -0.2325
    Episode_Reward/pen_joint_accel: -0.1049
    Episode_Reward/pen_action_rate: -0.1144
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0859
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2460
Episode_Reward/pen_flat_orientation: -0.0981
  Episode_Reward/pen_feet_distance: -0.0179
Episode_Reward/pen_feet_regulation: -0.4506
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.9018
Metrics/base_velocity/error_vel_xy: 0.9507
Metrics/base_velocity/error_vel_yaw: 1.2277
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 148832256
                    Iteration time: 1.10s
                        Total time: 1650.32s
                               ETA: 1620.9s

