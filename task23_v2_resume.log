nohup: ignoring input
/isaac-sim/extscache/omni.isaac.ml_archive-2.1.2+106.5.0.lx64.cp310/pip_prebundle/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: '/isaac-sim/extscache/omni.isaac.ml_archive-2.1.2+106.5.0.lx64.cp310/pip_prebundle/torchvision/image.so: ELF load command address/offset not page-aligned'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
Loading user config located at: '/isaac-sim/kit/data/Kit/Isaac-Sim/4.5/user.config.json'
[Info] [carb] Logging to file: /isaac-sim/kit/logs/Kit/Isaac-Sim/4.5/kit_20260105_101437.log
2026-01-05 02:14:37 [0ms] [Warning] [omni.kit.app.plugin] No crash reporter present, dumps uploading isn't available.
2026-01-05 02:14:37 [4ms] [Warning] [omni.ext.plugin] [ext: rendering_modes] Extensions config 'extension.toml' doesn't exist '/workspace/isaaclab/apps/rendering_modes' or '/workspace/isaaclab/apps/rendering_modes/config'
2026-01-05 02:14:40 [3,066ms] [Warning] [omni.usd_config.extension] Enable omni.materialx.libs extension to use MaterialX
2026-01-05 02:14:43 [6,136ms] [Warning] [omni.datastore] OmniHub is inaccessible
2026-01-05 02:14:47 [9,816ms] [Warning] [omni.platforminfo.plugin] failed to open the default display.  Can't verify X Server version.
2026-01-05 02:14:48 [11,316ms] [Warning] [omni.isaac.dynamic_control] omni.isaac.dynamic_control is deprecated as of Isaac Sim 4.5. No action is needed from end-users.

|---------------------------------------------------------------------------------------------|
| Driver Version: 535.154.05    | Graphics API: Vulkan
|=============================================================================================|
| GPU | Name                             | Active | LDA | GPU Memory | Vendor-ID | LUID       |
|     |                                  |        |     |            | Device-ID | UUID       |
|     |                                  |        |     |            | Bus-ID    |            |
|---------------------------------------------------------------------------------------------|
| 0   | NVIDIA GeForce RTX 4090 D        | Yes: 0 |     | 24810   MB | 10de      | 0          |
|     |                                  |        |     |            | 2685      | 91c4a5c2.. |
|     |                                  |        |     |            | 65        |            |
|=============================================================================================|
| OS: 22.04.5 LTS (Jammy Jellyfish) ubuntu, Version: 22.04.5, Kernel: 5.4.250-9-velinux1u1-amd64
| Processor: Intel(R) Xeon(R) Platinum 8457C
| Cores: 22 | Logical Cores: 44
|---------------------------------------------------------------------------------------------|
| Total Memory (MB): 180751 | Free Memory: 79197
| Total Page/Swap (MB): 0 | Free Page/Swap: 0
|---------------------------------------------------------------------------------------------|
2026-01-05 02:15:19 [41,930ms] [Warning] [isaaclab.terrains.terrain_importer] Visual material specified for ground plane but no diffuse color found. Using default color: (0.0, 0.0, 0.0)
2026-01-05 02:15:21 [44,252ms] [Warning] [isaaclab.actuators.actuator_pd] The <ImplicitActuatorCfg> object has a value for 'effort_limit'. This parameter will be removed in the future. To set the effort limit, please use 'effort_limit_sim' instead.
2026-01-05 02:15:21 [44,252ms] [Warning] [isaaclab.actuators.actuator_pd] The <ImplicitActuatorCfg> object has a value for 'velocity_limit'. Previously, although this value was specified, it was not getting used by implicit actuators. Since this parameter affects the simulation behavior, we continue to not use it. This parameter will be removed in the future. To set the velocity limit, please use 'velocity_limit_sim' instead.
2026-01-05 02:15:24 [46,743ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPreviewSurface.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-05 02:15:24 [46,791ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdUVTexture.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-05 02:15:24 [46,835ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_float.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-05 02:15:24 [46,870ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_float2.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-05 02:15:24 [46,905ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_float3.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-05 02:15:24 [46,939ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_float4.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-05 02:15:24 [46,972ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_int.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-05 02:15:24 [47,104ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_string.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-05 02:15:24 [47,137ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_normal.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-05 02:15:24 [47,168ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_point.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-05 02:15:24 [47,203ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_vector.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-05 02:15:24 [47,235ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdPrimvarReader_matrix.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

2026-01-05 02:15:24 [47,268ms] [Warning] [omni.usd] Warning: in GetNodeDiscoveryResults at line 136 of /builds/omniverse/usd-ci/USD/pxr/usd/usdShade/shaderDefUtils.cpp -- Unable to resolve info:sourceAsset </UsdTransform2d.info:mdl:sourceAsset> with value @UsdPreviewSurface.mdl@.

[INFO][AppLauncher]: Using device: cuda:0
[INFO][AppLauncher]: Loading experience file: /workspace/isaaclab/apps/isaaclab.python.headless.kit
[INFO]: Parsing configuration from: <class 'bipedal_locomotion.tasks.locomotion.robots.limx_pointfoot_env_cfg.PFBlindFlatEnvCfg'>
[INFO]: Parsing configuration from: PF_TRON1AFlatPPORunnerCfg(seed=42, device='cuda:0', num_steps_per_env=24, max_iterations=3000, empirical_normalization=False, policy=RslRlPpoActorCriticCfg(class_name='ActorCritic', init_noise_std=1.0, noise_std_type='scalar', actor_hidden_dims=[512, 256, 128], critic_hidden_dims=[512, 256, 128], activation='elu'), algorithm=RslRlPpoAlgorithmMlpCfg(class_name='PPO', num_learning_epochs=5, num_mini_batches=4, learning_rate=0.001, schedule='adaptive', gamma=0.99, lam=0.95, entropy_coef=0.01, desired_kl=0.01, max_grad_norm=1.0, value_loss_coef=1.0, use_clipped_value_loss=True, clip_param=0.2, normalize_advantage_per_mini_batch=False, symmetry_cfg=None, rnd_cfg=None, obs_history_len=10), clip_actions=None, save_interval=200, experiment_name='pf_tron_1a_flat', run_name='', logger='tensorboard', neptune_project='isaaclab', wandb_project='isaaclab', resume=False, load_run='.*', load_checkpoint='model_.*.pt', encoder=EncoderCfg(output_detach=True, num_input_dim=<dataclasses._MISSING_TYPE object at 0x7fcc629f9960>, num_output_dim=3, hidden_dims=[256, 128], activation='elu', orthogonal_init=False))
[INFO] Logging experiment in directory: /personal/limxtron1lab-main/logs/rsl_rl/pf_tron_1a_flat
Setting seed: 42
[INFO]: Base environment:
	Environment device    : cuda:0
	Environment seed      : 42
	Physics step-size     : 0.005
	Rendering step-size   : 0.04
	Environment step-size : 0.02
[INFO]: Time taken for scene creation : 1.461946 seconds
[INFO]: Scene manager:  <class InteractiveScene>
	Number of environments: 4096
	Environment spacing   : 2.5
	Source prim name      : /World/envs/env_0
	Global prim paths     : ['/World/ground']
	Replicate physics     : True
[INFO]: Starting the simulation. This may take a few seconds. Please wait...
[INFO]: Time taken for simulation start : 3.597599 seconds
[INFO] Command Manager:  <CommandManager> contains 2 active terms.
+------------------------------------------------+
|              Active Command Terms              |
+-------+---------------+------------------------+
| Index | Name          |          Type          |
+-------+---------------+------------------------+
|   0   | base_velocity | UniformVelocityCommand |
|   1   | gait_command  |      GaitCommand       |
+-------+---------------+------------------------+

[INFO] Event Manager:  <EventManager> contains 3 active terms.
+-------------------------------------------+
|   Active Event Terms in Mode: 'startup'   |
+-------+-----------------------------------+
| Index | Name                              |
+-------+-----------------------------------+
|   0   | add_base_mass                     |
|   1   | add_link_mass                     |
|   2   | radomize_rigid_body_mass_inertia  |
|   3   | robot_physics_material            |
|   4   | robot_joint_stiffness_and_damping |
|   5   | robot_center_of_mass              |
+-------+-----------------------------------+
+-------------------------------------+
| Active Event Terms in Mode: 'reset' |
+---------+---------------------------+
|  Index  | Name                      |
+---------+---------------------------+
|    0    | reset_robot_base          |
|    1    | reset_robot_joints        |
+---------+---------------------------+
+----------------------------------------------+
|    Active Event Terms in Mode: 'interval'    |
+-------+------------+-------------------------+
| Index | Name       | Interval time range (s) |
+-------+------------+-------------------------+
|   0   | push_robot |       (5.0, 10.0)       |
+-------+------------+-------------------------+

[INFO] Recorder Manager:  <RecorderManager> contains 0 active terms.
+---------------------+
| Active Recorder Terms |
+-----------+---------+
|   Index   | Name    |
+-----------+---------+
+-----------+---------+

[INFO] Action Manager:  <ActionManager> contains 1 active terms.
+----------------------------------+
|  Active Action Terms (shape: 6)  |
+--------+------------+------------+
| Index  | Name       |  Dimension |
+--------+------------+------------+
|   0    | joint_pos  |          6 |
+--------+------------+------------+

[INFO] Observation Manager: <ObservationManager> contains 4 groups.
+-------------------------------------------------------+
| Active Observation Terms in Group: 'policy' (shape: (30,)) |
+-------------+---------------------------+-------------+
|    Index    | Name                      |    Shape    |
+-------------+---------------------------+-------------+
|      0      | base_ang_vel              |     (3,)    |
|      1      | proj_gravity              |     (3,)    |
|      2      | joint_pos                 |     (6,)    |
|      3      | joint_vel                 |     (6,)    |
|      4      | last_action               |     (6,)    |
|      5      | gait_phase                |     (2,)    |
|      6      | gait_command              |     (4,)    |
+-------------+---------------------------+-------------+
+-------------------------------------------------------------+
| Active Observation Terms in Group: 'critic' (shape: (360,)) |
+----------+--------------------------------------+-----------+
|  Index   | Name                                 |   Shape   |
+----------+--------------------------------------+-----------+
|    0     | base_lin_vel                         |    (3,)   |
|    1     | base_ang_vel                         |    (3,)   |
|    2     | proj_gravity                         |    (3,)   |
|    3     | joint_pos                            |    (6,)   |
|    4     | joint_vel                            |    (6,)   |
|    5     | last_action                          |    (6,)   |
|    6     | gait_phase                           |    (2,)   |
|    7     | gait_command                         |    (4,)   |
|    8     | robot_joint_torque                   |    (6,)   |
|    9     | robot_joint_acc                      |    (6,)   |
|    10    | robot_feet_contact_force             |   (144,)  |
|    11    | robot_mass                           |   (12,)   |
|    12    | robot_inertia                        |   (108,)  |
|    13    | robot_joint_stiffness                |    (6,)   |
|    14    | robot_joint_damping                  |    (6,)   |
|    15    | robot_pos                            |    (3,)   |
|    16    | robot_vel                            |    (6,)   |
|    17    | robot_material_propertirs            |   (27,)   |
|    18    | robot_base_pose                      |    (3,)   |
+----------+--------------------------------------+-----------+
+---------------------------------------------------------+
| Active Observation Terms in Group: 'commands' (shape: (3,)) |
+-----------+---------------------------------+-----------+
|   Index   | Name                            |   Shape   |
+-----------+---------------------------------+-----------+
|     0     | velocity_commands               |    (3,)   |
+-----------+---------------------------------+-----------+
+-------------------------------------------------------------+
| Active Observation Terms in Group: 'obsHistory' (shape: (70, 30)) |
+-------------+----------------------------+------------------+
|    Index    | Name                       |      Shape       |
+-------------+----------------------------+------------------+
|      0      | base_ang_vel               |     (10, 3)      |
|      1      | proj_gravity               |     (10, 3)      |
|      2      | joint_pos                  |     (10, 6)      |
|      3      | joint_vel                  |     (10, 6)      |
|      4      | last_action                |     (10, 6)      |
|      5      | gait_phase                 |     (10, 2)      |
|      6      | gait_command               |     (10, 4)      |
+-------------+----------------------------+------------------+

[INFO] Termination Manager:  <TerminationManager> contains 2 active terms.
+---------------------------------+
|     Active Termination Terms    |
+-------+--------------+----------+
| Index | Name         | Time Out |
+-------+--------------+----------+
|   0   | time_out     |   True   |
|   1   | base_contact |  False   |
+-------+--------------+----------+

[INFO] Reward Manager:  <RewardManager> contains 19 active terms.
+-------------------------------------------+
|            Active Reward Terms            |
+-------+------------------------+----------+
| Index | Name                   |   Weight |
+-------+------------------------+----------+
|   0   | keep_balance           |      1.0 |
|   1   | rew_lin_vel_xy         |      8.0 |
|   2   | rew_ang_vel_z          |      4.0 |
|   3   | pen_base_height        |    -20.0 |
|   4   | pen_lin_vel_z          |     -0.5 |
|   5   | pen_ang_vel_xy         |    -0.05 |
|   6   | pen_joint_torque       |   -8e-05 |
|   7   | pen_joint_accel        | -2.5e-07 |
|   8   | pen_action_rate        |   -0.005 |
|   9   | pen_joint_pos_limits   |     -2.0 |
|   10  | pen_joint_vel_l2       |   -0.001 |
|   11  | pen_joint_powers       |  -0.0005 |
|   12  | pen_undesired_contacts |     -0.5 |
|   13  | pen_action_smoothness  |   -0.005 |
|   14  | pen_flat_orientation   |    -10.0 |
|   15  | pen_feet_distance      |     -100 |
|   16  | pen_feet_regulation    |     -0.1 |
|   17  | foot_landing_vel       |     -0.5 |
|   18  | test_gait_reward       |      1.0 |
+-------+------------------------+----------+

[INFO] Curriculum Manager:  <CurriculumManager> contains 0 active terms.
+----------------------+
| Active Curriculum Terms |
+-----------+----------+
|   Index   | Name     |
+-----------+----------+
+-----------+----------+

[INFO]: Completed setting up the environment...
encoder cfg: dict_keys(['seed', 'device', 'num_steps_per_env', 'max_iterations', 'empirical_normalization', 'policy', 'algorithm', 'clip_actions', 'save_interval', 'experiment_name', 'run_name', 'logger', 'neptune_project', 'wandb_project', 'resume', 'load_run', 'load_checkpoint', 'encoder'])
Encoder MLP: Sequential(
  (0): Linear(in_features=300, out_features=256, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=256, out_features=128, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=128, out_features=3, bias=True)
)
ActorCritic.__init__ got unexpected arguments, which will be ignored: ['class_name', 'noise_std_type']
Actor MLP: Sequential(
  (0): Linear(in_features=36, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=6, bias=True)
)
Critic MLP: Sequential(
  (0): Linear(in_features=363, out_features=512, bias=True)
  (1): ELU(alpha=1.0)
  (2): Linear(in_features=512, out_features=256, bias=True)
  (3): ELU(alpha=1.0)
  (4): Linear(in_features=256, out_features=128, bias=True)
  (5): ELU(alpha=1.0)
  (6): Linear(in_features=128, out_features=1, bias=True)
)
Setting seed: 42
################################################################################
                      [1m Learning iteration 0/3000 [0m                       

                       Computation: 30435 steps/s (collection: 3.029s, learning 0.201s)
               Value function loss: 6.5784
                    Surrogate loss: 0.0122
             Mean action noise std: 1.0046
                     Learning rate: 0.0004
                       Mean reward: -4.15
               Mean episode length: 23.91
       Episode_Reward/keep_balance: 0.0125
     Episode_Reward/rew_lin_vel_xy: 0.0107
      Episode_Reward/rew_ang_vel_z: 0.0210
    Episode_Reward/pen_base_height: -0.0408
      Episode_Reward/pen_lin_vel_z: -0.0090
     Episode_Reward/pen_ang_vel_xy: -0.0075
   Episode_Reward/pen_joint_torque: -0.0013
    Episode_Reward/pen_joint_accel: -0.0020
    Episode_Reward/pen_action_rate: -0.0007
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0008
   Episode_Reward/pen_joint_powers: -0.0010
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.0019
Episode_Reward/pen_flat_orientation: -0.0164
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0021
   Episode_Reward/foot_landing_vel: -0.0048
   Episode_Reward/test_gait_reward: -0.0134
Metrics/base_velocity/error_vel_xy: 0.0539
Metrics/base_velocity/error_vel_yaw: 0.0274
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 3.23s
                        Total time: 3.23s
                               ETA: 9689.6s

################################################################################
                      [1m Learning iteration 1/3000 [0m                       

                       Computation: 86817 steps/s (collection: 1.006s, learning 0.127s)
               Value function loss: 4.5519
                    Surrogate loss: 0.0043
             Mean action noise std: 1.0081
                     Learning rate: 0.0004
                       Mean reward: -7.12
               Mean episode length: 42.06
       Episode_Reward/keep_balance: 0.0358
     Episode_Reward/rew_lin_vel_xy: 0.0296
      Episode_Reward/rew_ang_vel_z: 0.0456
    Episode_Reward/pen_base_height: -0.1794
      Episode_Reward/pen_lin_vel_z: -0.0195
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0062
Episode_Reward/pen_flat_orientation: -0.1287
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0401
Metrics/base_velocity/error_vel_xy: 0.1703
Metrics/base_velocity/error_vel_yaw: 0.1233
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 137.7917
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 1.13s
                        Total time: 4.36s
                               ETA: 6541.1s

################################################################################
                      [1m Learning iteration 2/3000 [0m                       

                       Computation: 90231 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 1.9426
                    Surrogate loss: 0.0022
             Mean action noise std: 1.0069
                     Learning rate: 0.0015
                       Mean reward: -6.49
               Mean episode length: 34.96
       Episode_Reward/keep_balance: 0.0362
     Episode_Reward/rew_lin_vel_xy: 0.0327
      Episode_Reward/rew_ang_vel_z: 0.0462
    Episode_Reward/pen_base_height: -0.1783
      Episode_Reward/pen_lin_vel_z: -0.0193
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0063
Episode_Reward/pen_flat_orientation: -0.1293
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0404
Metrics/base_velocity/error_vel_xy: 0.1719
Metrics/base_velocity/error_vel_yaw: 0.1258
      Episode_Termination/time_out: 0.2083
  Episode_Termination/base_contact: 104.5833
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 1.09s
                        Total time: 5.45s
                               ETA: 5448.0s

################################################################################
                      [1m Learning iteration 3/3000 [0m                       

                       Computation: 87891 steps/s (collection: 0.993s, learning 0.126s)
               Value function loss: 1.8016
                    Surrogate loss: 0.0015
             Mean action noise std: 1.0067
                     Learning rate: 0.0051
                       Mean reward: -6.71
               Mean episode length: 37.82
       Episode_Reward/keep_balance: 0.0370
     Episode_Reward/rew_lin_vel_xy: 0.0328
      Episode_Reward/rew_ang_vel_z: 0.0457
    Episode_Reward/pen_base_height: -0.1838
      Episode_Reward/pen_lin_vel_z: -0.0197
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0065
Episode_Reward/pen_flat_orientation: -0.1321
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0414
Metrics/base_velocity/error_vel_xy: 0.1787
Metrics/base_velocity/error_vel_yaw: 0.1344
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 118.3333
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 1.12s
                        Total time: 6.57s
                               ETA: 4922.7s

################################################################################
                      [1m Learning iteration 4/3000 [0m                       

                       Computation: 84670 steps/s (collection: 1.035s, learning 0.126s)
               Value function loss: 1.6148
                    Surrogate loss: 0.0077
             Mean action noise std: 1.0093
                     Learning rate: 0.0022
                       Mean reward: -6.80
               Mean episode length: 37.35
       Episode_Reward/keep_balance: 0.0366
     Episode_Reward/rew_lin_vel_xy: 0.0314
      Episode_Reward/rew_ang_vel_z: 0.0462
    Episode_Reward/pen_base_height: -0.1813
      Episode_Reward/pen_lin_vel_z: -0.0195
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0064
Episode_Reward/pen_flat_orientation: -0.1300
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0410
Metrics/base_velocity/error_vel_xy: 0.1775
Metrics/base_velocity/error_vel_yaw: 0.1299
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 106.9167
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 1.16s
                        Total time: 7.73s
                               ETA: 4632.5s

################################################################################
                      [1m Learning iteration 5/3000 [0m                       

                       Computation: 89755 steps/s (collection: 0.968s, learning 0.128s)
               Value function loss: 1.4459
                    Surrogate loss: 0.0130
             Mean action noise std: 1.0127
                     Learning rate: 0.0004
                       Mean reward: -6.60
               Mean episode length: 36.18
       Episode_Reward/keep_balance: 0.0375
     Episode_Reward/rew_lin_vel_xy: 0.0317
      Episode_Reward/rew_ang_vel_z: 0.0474
    Episode_Reward/pen_base_height: -0.1846
      Episode_Reward/pen_lin_vel_z: -0.0198
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0058
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0066
Episode_Reward/pen_flat_orientation: -0.1313
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0417
Metrics/base_velocity/error_vel_xy: 0.1830
Metrics/base_velocity/error_vel_yaw: 0.1321
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 108.9583
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 1.10s
                        Total time: 8.83s
                               ETA: 4405.8s

################################################################################
                      [1m Learning iteration 6/3000 [0m                       

                       Computation: 90462 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 1.1551
                    Surrogate loss: 0.0027
             Mean action noise std: 1.0159
                     Learning rate: 0.0022
                       Mean reward: -6.72
               Mean episode length: 38.22
       Episode_Reward/keep_balance: 0.0371
     Episode_Reward/rew_lin_vel_xy: 0.0311
      Episode_Reward/rew_ang_vel_z: 0.0467
    Episode_Reward/pen_base_height: -0.1814
      Episode_Reward/pen_lin_vel_z: -0.0195
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0067
Episode_Reward/pen_flat_orientation: -0.1301
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0414
Metrics/base_velocity/error_vel_xy: 0.1824
Metrics/base_velocity/error_vel_yaw: 0.1288
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 110.5833
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 1.09s
                        Total time: 9.91s
                               ETA: 4240.0s

################################################################################
                      [1m Learning iteration 7/3000 [0m                       

                       Computation: 89932 steps/s (collection: 0.968s, learning 0.125s)
               Value function loss: 1.0753
                    Surrogate loss: 0.0046
             Mean action noise std: 1.0228
                     Learning rate: 0.0034
                       Mean reward: -6.26
               Mean episode length: 36.05
       Episode_Reward/keep_balance: 0.0370
     Episode_Reward/rew_lin_vel_xy: 0.0326
      Episode_Reward/rew_ang_vel_z: 0.0476
    Episode_Reward/pen_base_height: -0.1806
      Episode_Reward/pen_lin_vel_z: -0.0193
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0067
Episode_Reward/pen_flat_orientation: -0.1294
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0413
Metrics/base_velocity/error_vel_xy: 0.1766
Metrics/base_velocity/error_vel_yaw: 0.1280
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 111.1250
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 1.09s
                        Total time: 11.01s
                               ETA: 4117.7s

################################################################################
                      [1m Learning iteration 8/3000 [0m                       

                       Computation: 90678 steps/s (collection: 0.959s, learning 0.125s)
               Value function loss: 0.9832
                    Surrogate loss: 0.0105
             Mean action noise std: 1.0263
                     Learning rate: 0.0004
                       Mean reward: -6.15
               Mean episode length: 35.41
       Episode_Reward/keep_balance: 0.0369
     Episode_Reward/rew_lin_vel_xy: 0.0309
      Episode_Reward/rew_ang_vel_z: 0.0479
    Episode_Reward/pen_base_height: -0.1796
      Episode_Reward/pen_lin_vel_z: -0.0189
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0039
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0067
Episode_Reward/pen_flat_orientation: -0.1277
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0411
Metrics/base_velocity/error_vel_xy: 0.1814
Metrics/base_velocity/error_vel_yaw: 0.1265
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 112.1667
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 1.08s
                        Total time: 12.09s
                               ETA: 4019.3s

################################################################################
                      [1m Learning iteration 9/3000 [0m                       

                       Computation: 90723 steps/s (collection: 0.955s, learning 0.129s)
               Value function loss: 0.8602
                    Surrogate loss: 0.0065
             Mean action noise std: 1.0296
                     Learning rate: 0.0010
                       Mean reward: -6.75
               Mean episode length: 37.53
       Episode_Reward/keep_balance: 0.0367
     Episode_Reward/rew_lin_vel_xy: 0.0309
      Episode_Reward/rew_ang_vel_z: 0.0470
    Episode_Reward/pen_base_height: -0.1790
      Episode_Reward/pen_lin_vel_z: -0.0189
     Episode_Reward/pen_ang_vel_xy: -0.0221
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0068
Episode_Reward/pen_flat_orientation: -0.1275
  Episode_Reward/pen_feet_distance: -0.0050
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0411
Metrics/base_velocity/error_vel_xy: 0.1781
Metrics/base_velocity/error_vel_yaw: 0.1271
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 111.3333
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.08s
                        Total time: 13.17s
                               ETA: 3940.3s

################################################################################
                      [1m Learning iteration 10/3000 [0m                      

                       Computation: 89592 steps/s (collection: 0.975s, learning 0.122s)
               Value function loss: 0.8072
                    Surrogate loss: 0.0016
             Mean action noise std: 1.0296
                     Learning rate: 0.0051
                       Mean reward: -6.38
               Mean episode length: 36.08
       Episode_Reward/keep_balance: 0.0368
     Episode_Reward/rew_lin_vel_xy: 0.0325
      Episode_Reward/rew_ang_vel_z: 0.0472
    Episode_Reward/pen_base_height: -0.1790
      Episode_Reward/pen_lin_vel_z: -0.0189
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0068
Episode_Reward/pen_flat_orientation: -0.1278
  Episode_Reward/pen_feet_distance: -0.0044
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0411
Metrics/base_velocity/error_vel_xy: 0.1778
Metrics/base_velocity/error_vel_yaw: 0.1263
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 113.8750
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.10s
                        Total time: 14.27s
                               ETA: 3879.1s

################################################################################
                      [1m Learning iteration 11/3000 [0m                      

                       Computation: 87957 steps/s (collection: 0.990s, learning 0.128s)
               Value function loss: 0.8867
                    Surrogate loss: 0.0008
             Mean action noise std: 1.0337
                     Learning rate: 0.0100
                       Mean reward: -5.97
               Mean episode length: 34.23
       Episode_Reward/keep_balance: 0.0365
     Episode_Reward/rew_lin_vel_xy: 0.0317
      Episode_Reward/rew_ang_vel_z: 0.0463
    Episode_Reward/pen_base_height: -0.1774
      Episode_Reward/pen_lin_vel_z: -0.0187
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0068
Episode_Reward/pen_flat_orientation: -0.1272
  Episode_Reward/pen_feet_distance: -0.0047
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0408
Metrics/base_velocity/error_vel_xy: 0.1774
Metrics/base_velocity/error_vel_yaw: 0.1264
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 110.0833
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.12s
                        Total time: 15.39s
                               ETA: 3833.1s

################################################################################
                      [1m Learning iteration 12/3000 [0m                      

                       Computation: 88498 steps/s (collection: 0.988s, learning 0.123s)
               Value function loss: 0.7762
                    Surrogate loss: -0.0001
             Mean action noise std: 1.0374
                     Learning rate: 0.0100
                       Mean reward: -6.18
               Mean episode length: 36.80
       Episode_Reward/keep_balance: 0.0365
     Episode_Reward/rew_lin_vel_xy: 0.0311
      Episode_Reward/rew_ang_vel_z: 0.0474
    Episode_Reward/pen_base_height: -0.1775
      Episode_Reward/pen_lin_vel_z: -0.0186
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0040
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0069
Episode_Reward/pen_flat_orientation: -0.1261
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0408
Metrics/base_velocity/error_vel_xy: 0.1776
Metrics/base_velocity/error_vel_yaw: 0.1242
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 112.3750
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.11s
                        Total time: 16.50s
                               ETA: 3792.3s

################################################################################
                      [1m Learning iteration 13/3000 [0m                      

                       Computation: 89172 steps/s (collection: 0.981s, learning 0.122s)
               Value function loss: 0.7932
                    Surrogate loss: 0.0027
             Mean action noise std: 1.0445
                     Learning rate: 0.0044
                       Mean reward: -5.99
               Mean episode length: 36.04
       Episode_Reward/keep_balance: 0.0363
     Episode_Reward/rew_lin_vel_xy: 0.0322
      Episode_Reward/rew_ang_vel_z: 0.0472
    Episode_Reward/pen_base_height: -0.1749
      Episode_Reward/pen_lin_vel_z: -0.0182
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0069
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0043
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0404
Metrics/base_velocity/error_vel_xy: 0.1754
Metrics/base_velocity/error_vel_yaw: 0.1222
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 114.8333
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.10s
                        Total time: 17.60s
                               ETA: 3755.5s

################################################################################
                      [1m Learning iteration 14/3000 [0m                      

                       Computation: 88776 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 0.7321
                    Surrogate loss: 0.0005
             Mean action noise std: 1.0515
                     Learning rate: 0.0100
                       Mean reward: -6.23
               Mean episode length: 36.17
       Episode_Reward/keep_balance: 0.0359
     Episode_Reward/rew_lin_vel_xy: 0.0309
      Episode_Reward/rew_ang_vel_z: 0.0470
    Episode_Reward/pen_base_height: -0.1724
      Episode_Reward/pen_lin_vel_z: -0.0178
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0069
Episode_Reward/pen_flat_orientation: -0.1234
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0401
Metrics/base_velocity/error_vel_xy: 0.1771
Metrics/base_velocity/error_vel_yaw: 0.1194
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 112.2500
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.11s
                        Total time: 18.71s
                               ETA: 3724.4s

################################################################################
                      [1m Learning iteration 15/3000 [0m                      

                       Computation: 90501 steps/s (collection: 0.967s, learning 0.120s)
               Value function loss: 0.8095
                    Surrogate loss: 0.0024
             Mean action noise std: 1.0529
                     Learning rate: 0.0067
                       Mean reward: -6.25
               Mean episode length: 35.90
       Episode_Reward/keep_balance: 0.0361
     Episode_Reward/rew_lin_vel_xy: 0.0306
      Episode_Reward/rew_ang_vel_z: 0.0473
    Episode_Reward/pen_base_height: -0.1726
      Episode_Reward/pen_lin_vel_z: -0.0176
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0070
Episode_Reward/pen_flat_orientation: -0.1235
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.0063
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0403
Metrics/base_velocity/error_vel_xy: 0.1769
Metrics/base_velocity/error_vel_yaw: 0.1205
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.4167
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.09s
                        Total time: 19.80s
                               ETA: 3693.1s

################################################################################
                      [1m Learning iteration 16/3000 [0m                      

                       Computation: 89994 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.5658
                    Surrogate loss: 0.0013
             Mean action noise std: 1.0599
                     Learning rate: 0.0067
                       Mean reward: -6.12
               Mean episode length: 36.91
       Episode_Reward/keep_balance: 0.0356
     Episode_Reward/rew_lin_vel_xy: 0.0315
      Episode_Reward/rew_ang_vel_z: 0.0467
    Episode_Reward/pen_base_height: -0.1685
      Episode_Reward/pen_lin_vel_z: -0.0172
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0041
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0070
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0037
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0398
Metrics/base_velocity/error_vel_xy: 0.1729
Metrics/base_velocity/error_vel_yaw: 0.1164
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.8750
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.09s
                        Total time: 20.89s
                               ETA: 3666.4s

################################################################################
                      [1m Learning iteration 17/3000 [0m                      

                       Computation: 90349 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.6609
                    Surrogate loss: 0.0032
             Mean action noise std: 1.0650
                     Learning rate: 0.0067
                       Mean reward: -5.77
               Mean episode length: 35.26
       Episode_Reward/keep_balance: 0.0355
     Episode_Reward/rew_lin_vel_xy: 0.0304
      Episode_Reward/rew_ang_vel_z: 0.0478
    Episode_Reward/pen_base_height: -0.1668
      Episode_Reward/pen_lin_vel_z: -0.0166
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0042
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0071
Episode_Reward/pen_flat_orientation: -0.1191
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0396
Metrics/base_velocity/error_vel_xy: 0.1748
Metrics/base_velocity/error_vel_yaw: 0.1126
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.9583
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.09s
                        Total time: 21.98s
                               ETA: 3641.9s

################################################################################
                      [1m Learning iteration 18/3000 [0m                      

                       Computation: 90197 steps/s (collection: 0.965s, learning 0.125s)
               Value function loss: 0.4154
                    Surrogate loss: 0.0017
             Mean action noise std: 1.0646
                     Learning rate: 0.0044
                       Mean reward: -6.07
               Mean episode length: 37.90
       Episode_Reward/keep_balance: 0.0353
     Episode_Reward/rew_lin_vel_xy: 0.0306
      Episode_Reward/rew_ang_vel_z: 0.0484
    Episode_Reward/pen_base_height: -0.1649
      Episode_Reward/pen_lin_vel_z: -0.0163
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0072
Episode_Reward/pen_flat_orientation: -0.1182
  Episode_Reward/pen_feet_distance: -0.0035
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0393
Metrics/base_velocity/error_vel_xy: 0.1733
Metrics/base_velocity/error_vel_yaw: 0.1089
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 113.1667
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.09s
                        Total time: 23.07s
                               ETA: 3620.1s

################################################################################
                      [1m Learning iteration 19/3000 [0m                      

                       Computation: 90141 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.3460
                    Surrogate loss: 0.0065
             Mean action noise std: 1.0673
                     Learning rate: 0.0020
                       Mean reward: -5.99
               Mean episode length: 36.02
       Episode_Reward/keep_balance: 0.0358
     Episode_Reward/rew_lin_vel_xy: 0.0313
      Episode_Reward/rew_ang_vel_z: 0.0498
    Episode_Reward/pen_base_height: -0.1671
      Episode_Reward/pen_lin_vel_z: -0.0164
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0042
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0074
Episode_Reward/pen_flat_orientation: -0.1188
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0400
Metrics/base_velocity/error_vel_xy: 0.1757
Metrics/base_velocity/error_vel_yaw: 0.1089
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 117.5833
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.09s
                        Total time: 24.16s
                               ETA: 3600.5s

################################################################################
                      [1m Learning iteration 20/3000 [0m                      

                       Computation: 90613 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.3207
                    Surrogate loss: -0.0001
             Mean action noise std: 1.0694
                     Learning rate: 0.0044
                       Mean reward: -5.35
               Mean episode length: 33.95
       Episode_Reward/keep_balance: 0.0353
     Episode_Reward/rew_lin_vel_xy: 0.0307
      Episode_Reward/rew_ang_vel_z: 0.0503
    Episode_Reward/pen_base_height: -0.1644
      Episode_Reward/pen_lin_vel_z: -0.0161
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0043
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0073
Episode_Reward/pen_flat_orientation: -0.1171
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0392
Metrics/base_velocity/error_vel_xy: 0.1745
Metrics/base_velocity/error_vel_yaw: 0.1048
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.0833
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.08s
                        Total time: 25.24s
                               ETA: 3581.8s

################################################################################
                      [1m Learning iteration 21/3000 [0m                      

                       Computation: 89730 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 0.5221
                    Surrogate loss: 0.0049
             Mean action noise std: 1.0731
                     Learning rate: 0.0013
                       Mean reward: -5.92
               Mean episode length: 37.61
       Episode_Reward/keep_balance: 0.0352
     Episode_Reward/rew_lin_vel_xy: 0.0305
      Episode_Reward/rew_ang_vel_z: 0.0506
    Episode_Reward/pen_base_height: -0.1629
      Episode_Reward/pen_lin_vel_z: -0.0159
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0042
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0073
Episode_Reward/pen_flat_orientation: -0.1161
  Episode_Reward/pen_feet_distance: -0.0027
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0391
Metrics/base_velocity/error_vel_xy: 0.1735
Metrics/base_velocity/error_vel_yaw: 0.1021
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 117.6250
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.10s
                        Total time: 26.34s
                               ETA: 3566.2s

################################################################################
                      [1m Learning iteration 22/3000 [0m                      

                       Computation: 90200 steps/s (collection: 0.969s, learning 0.121s)
               Value function loss: 0.4719
                    Surrogate loss: 0.0099
             Mean action noise std: 1.0717
                     Learning rate: 0.0000
                       Mean reward: -5.64
               Mean episode length: 35.44
       Episode_Reward/keep_balance: 0.0348
     Episode_Reward/rew_lin_vel_xy: 0.0312
      Episode_Reward/rew_ang_vel_z: 0.0514
    Episode_Reward/pen_base_height: -0.1609
      Episode_Reward/pen_lin_vel_z: -0.0156
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0073
Episode_Reward/pen_flat_orientation: -0.1152
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0387
Metrics/base_velocity/error_vel_xy: 0.1704
Metrics/base_velocity/error_vel_yaw: 0.0974
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 119.5833
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.09s
                        Total time: 27.43s
                               ETA: 3551.1s

################################################################################
                      [1m Learning iteration 23/3000 [0m                      

                       Computation: 89892 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.4258
                    Surrogate loss: -0.0007
             Mean action noise std: 1.0755
                     Learning rate: 0.0013
                       Mean reward: -5.02
               Mean episode length: 33.05
       Episode_Reward/keep_balance: 0.0343
     Episode_Reward/rew_lin_vel_xy: 0.0299
      Episode_Reward/rew_ang_vel_z: 0.0508
    Episode_Reward/pen_base_height: -0.1558
      Episode_Reward/pen_lin_vel_z: -0.0147
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0047
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0072
Episode_Reward/pen_flat_orientation: -0.1109
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0382
Metrics/base_velocity/error_vel_xy: 0.1703
Metrics/base_velocity/error_vel_yaw: 0.0957
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 122.2500
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 1.09s
                        Total time: 28.52s
                               ETA: 3537.7s

################################################################################
                      [1m Learning iteration 24/3000 [0m                      

                       Computation: 90002 steps/s (collection: 0.967s, learning 0.125s)
               Value function loss: 0.2917
                    Surrogate loss: -0.0011
             Mean action noise std: 1.0760
                     Learning rate: 0.0019
                       Mean reward: -5.18
               Mean episode length: 32.83
       Episode_Reward/keep_balance: 0.0335
     Episode_Reward/rew_lin_vel_xy: 0.0294
      Episode_Reward/rew_ang_vel_z: 0.0507
    Episode_Reward/pen_base_height: -0.1505
      Episode_Reward/pen_lin_vel_z: -0.0142
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0071
Episode_Reward/pen_flat_orientation: -0.1072
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0371
Metrics/base_velocity/error_vel_xy: 0.1660
Metrics/base_velocity/error_vel_yaw: 0.0907
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 123.3333
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 1.09s
                        Total time: 29.61s
                               ETA: 3525.0s

################################################################################
                      [1m Learning iteration 25/3000 [0m                      

                       Computation: 90664 steps/s (collection: 0.964s, learning 0.120s)
               Value function loss: 0.2478
                    Surrogate loss: -0.0020
             Mean action noise std: 1.0746
                     Learning rate: 0.0029
                       Mean reward: -5.17
               Mean episode length: 32.86
       Episode_Reward/keep_balance: 0.0331
     Episode_Reward/rew_lin_vel_xy: 0.0282
      Episode_Reward/rew_ang_vel_z: 0.0509
    Episode_Reward/pen_base_height: -0.1484
      Episode_Reward/pen_lin_vel_z: -0.0140
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0070
Episode_Reward/pen_flat_orientation: -0.1050
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0367
Metrics/base_velocity/error_vel_xy: 0.1647
Metrics/base_velocity/error_vel_yaw: 0.0871
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 125.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 1.08s
                        Total time: 30.70s
                               ETA: 3512.4s

################################################################################
                      [1m Learning iteration 26/3000 [0m                      

                       Computation: 89436 steps/s (collection: 0.977s, learning 0.122s)
               Value function loss: 0.2781
                    Surrogate loss: 0.0029
             Mean action noise std: 1.0758
                     Learning rate: 0.0009
                       Mean reward: -4.83
               Mean episode length: 32.28
       Episode_Reward/keep_balance: 0.0329
     Episode_Reward/rew_lin_vel_xy: 0.0280
      Episode_Reward/rew_ang_vel_z: 0.0517
    Episode_Reward/pen_base_height: -0.1455
      Episode_Reward/pen_lin_vel_z: -0.0137
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0070
Episode_Reward/pen_flat_orientation: -0.1022
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0364
Metrics/base_velocity/error_vel_xy: 0.1639
Metrics/base_velocity/error_vel_yaw: 0.0843
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 124.7917
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 1.10s
                        Total time: 31.80s
                               ETA: 3502.2s

################################################################################
                      [1m Learning iteration 27/3000 [0m                      

                       Computation: 89536 steps/s (collection: 0.971s, learning 0.126s)
               Value function loss: 0.2449
                    Surrogate loss: 0.0002
             Mean action noise std: 1.0790
                     Learning rate: 0.0013
                       Mean reward: -4.71
               Mean episode length: 32.75
       Episode_Reward/keep_balance: 0.0325
     Episode_Reward/rew_lin_vel_xy: 0.0280
      Episode_Reward/rew_ang_vel_z: 0.0523
    Episode_Reward/pen_base_height: -0.1416
      Episode_Reward/pen_lin_vel_z: -0.0134
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0070
Episode_Reward/pen_flat_orientation: -0.0988
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0359
Metrics/base_velocity/error_vel_xy: 0.1633
Metrics/base_velocity/error_vel_yaw: 0.0804
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 128.0417
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 1.10s
                        Total time: 32.89s
                               ETA: 3492.6s

################################################################################
                      [1m Learning iteration 28/3000 [0m                      

                       Computation: 90186 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.2632
                    Surrogate loss: 0.0047
             Mean action noise std: 1.0789
                     Learning rate: 0.0004
                       Mean reward: -4.53
               Mean episode length: 31.55
       Episode_Reward/keep_balance: 0.0320
     Episode_Reward/rew_lin_vel_xy: 0.0273
      Episode_Reward/rew_ang_vel_z: 0.0525
    Episode_Reward/pen_base_height: -0.1377
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0069
Episode_Reward/pen_flat_orientation: -0.0954
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0351
Metrics/base_velocity/error_vel_xy: 0.1624
Metrics/base_velocity/error_vel_yaw: 0.0764
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 128.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 1.09s
                        Total time: 33.98s
                               ETA: 3482.7s

################################################################################
                      [1m Learning iteration 29/3000 [0m                      

                       Computation: 90272 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.2532
                    Surrogate loss: 0.0069
             Mean action noise std: 1.0795
                     Learning rate: 0.0000
                       Mean reward: -4.55
               Mean episode length: 31.61
       Episode_Reward/keep_balance: 0.0313
     Episode_Reward/rew_lin_vel_xy: 0.0275
      Episode_Reward/rew_ang_vel_z: 0.0519
    Episode_Reward/pen_base_height: -0.1350
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0037
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0068
Episode_Reward/pen_flat_orientation: -0.0938
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0345
Metrics/base_velocity/error_vel_xy: 0.1585
Metrics/base_velocity/error_vel_yaw: 0.0740
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 131.4583
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 1.09s
                        Total time: 35.07s
                               ETA: 3473.4s

################################################################################
                      [1m Learning iteration 30/3000 [0m                      

                       Computation: 89236 steps/s (collection: 0.975s, learning 0.127s)
               Value function loss: 0.2221
                    Surrogate loss: 0.0032
             Mean action noise std: 1.0797
                     Learning rate: 0.0001
                       Mean reward: -4.48
               Mean episode length: 30.91
       Episode_Reward/keep_balance: 0.0310
     Episode_Reward/rew_lin_vel_xy: 0.0265
      Episode_Reward/rew_ang_vel_z: 0.0522
    Episode_Reward/pen_base_height: -0.1347
      Episode_Reward/pen_lin_vel_z: -0.0133
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0037
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0067
Episode_Reward/pen_flat_orientation: -0.0929
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0343
Metrics/base_velocity/error_vel_xy: 0.1560
Metrics/base_velocity/error_vel_yaw: 0.0715
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 133.1667
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 1.10s
                        Total time: 36.17s
                               ETA: 3465.7s

################################################################################
                      [1m Learning iteration 31/3000 [0m                      

                       Computation: 89817 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.2069
                    Surrogate loss: 0.0063
             Mean action noise std: 1.0803
                     Learning rate: 0.0001
                       Mean reward: -4.05
               Mean episode length: 30.05
       Episode_Reward/keep_balance: 0.0308
     Episode_Reward/rew_lin_vel_xy: 0.0266
      Episode_Reward/rew_ang_vel_z: 0.0523
    Episode_Reward/pen_base_height: -0.1308
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0035
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0067
Episode_Reward/pen_flat_orientation: -0.0896
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0339
Metrics/base_velocity/error_vel_xy: 0.1563
Metrics/base_velocity/error_vel_yaw: 0.0696
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 137.5833
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 1.09s
                        Total time: 37.27s
                               ETA: 3457.8s

################################################################################
                      [1m Learning iteration 32/3000 [0m                      

                       Computation: 90854 steps/s (collection: 0.962s, learning 0.120s)
               Value function loss: 0.1867
                    Surrogate loss: 0.0098
             Mean action noise std: 1.0810
                     Learning rate: 0.0000
                       Mean reward: -3.84
               Mean episode length: 29.69
       Episode_Reward/keep_balance: 0.0299
     Episode_Reward/rew_lin_vel_xy: 0.0251
      Episode_Reward/rew_ang_vel_z: 0.0527
    Episode_Reward/pen_base_height: -0.1231
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0064
Episode_Reward/pen_flat_orientation: -0.0839
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0063
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0325
Metrics/base_velocity/error_vel_xy: 0.1550
Metrics/base_velocity/error_vel_yaw: 0.0639
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 139.0417
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 1.08s
                        Total time: 38.35s
                               ETA: 3449.2s

################################################################################
                      [1m Learning iteration 33/3000 [0m                      

                       Computation: 90949 steps/s (collection: 0.960s, learning 0.121s)
               Value function loss: 0.1644
                    Surrogate loss: 0.0019
             Mean action noise std: 1.0804
                     Learning rate: 0.0001
                       Mean reward: -3.70
               Mean episode length: 27.61
       Episode_Reward/keep_balance: 0.0289
     Episode_Reward/rew_lin_vel_xy: 0.0244
      Episode_Reward/rew_ang_vel_z: 0.0524
    Episode_Reward/pen_base_height: -0.1166
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0027
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0061
Episode_Reward/pen_flat_orientation: -0.0788
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0064
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0312
Metrics/base_velocity/error_vel_xy: 0.1518
Metrics/base_velocity/error_vel_yaw: 0.0593
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 144.2917
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 1.08s
                        Total time: 39.43s
                               ETA: 3441.0s

################################################################################
                      [1m Learning iteration 34/3000 [0m                      

                       Computation: 89023 steps/s (collection: 0.983s, learning 0.122s)
               Value function loss: 0.1793
                    Surrogate loss: -0.0019
             Mean action noise std: 1.0764
                     Learning rate: 0.0006
                       Mean reward: -3.54
               Mean episode length: 28.28
       Episode_Reward/keep_balance: 0.0286
     Episode_Reward/rew_lin_vel_xy: 0.0239
      Episode_Reward/rew_ang_vel_z: 0.0535
    Episode_Reward/pen_base_height: -0.1138
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0025
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0060
Episode_Reward/pen_flat_orientation: -0.0754
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0068
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0308
Metrics/base_velocity/error_vel_xy: 0.1510
Metrics/base_velocity/error_vel_yaw: 0.0569
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 145.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 1.10s
                        Total time: 40.54s
                               ETA: 3435.1s

################################################################################
                      [1m Learning iteration 35/3000 [0m                      

                       Computation: 89956 steps/s (collection: 0.972s, learning 0.121s)
               Value function loss: 0.1654
                    Surrogate loss: -0.0033
             Mean action noise std: 1.0665
                     Learning rate: 0.0009
                       Mean reward: -3.50
               Mean episode length: 29.12
       Episode_Reward/keep_balance: 0.0281
     Episode_Reward/rew_lin_vel_xy: 0.0236
      Episode_Reward/rew_ang_vel_z: 0.0526
    Episode_Reward/pen_base_height: -0.1095
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0023
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0059
Episode_Reward/pen_flat_orientation: -0.0721
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.0071
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0299
Metrics/base_velocity/error_vel_xy: 0.1494
Metrics/base_velocity/error_vel_yaw: 0.0558
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 146.1250
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 1.09s
                        Total time: 41.63s
                               ETA: 3428.6s

################################################################################
                      [1m Learning iteration 36/3000 [0m                      

                       Computation: 89243 steps/s (collection: 0.980s, learning 0.121s)
               Value function loss: 0.1458
                    Surrogate loss: -0.0020
             Mean action noise std: 1.0591
                     Learning rate: 0.0013
                       Mean reward: -3.23
               Mean episode length: 27.26
       Episode_Reward/keep_balance: 0.0277
     Episode_Reward/rew_lin_vel_xy: 0.0241
      Episode_Reward/rew_ang_vel_z: 0.0520
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0057
Episode_Reward/pen_flat_orientation: -0.0698
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.0072
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0295
Metrics/base_velocity/error_vel_xy: 0.1469
Metrics/base_velocity/error_vel_yaw: 0.0552
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 149.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 1.10s
                        Total time: 42.73s
                               ETA: 3423.0s

################################################################################
                      [1m Learning iteration 37/3000 [0m                      

                       Computation: 88378 steps/s (collection: 0.992s, learning 0.120s)
               Value function loss: 0.1467
                    Surrogate loss: -0.0016
             Mean action noise std: 1.0534
                     Learning rate: 0.0013
                       Mean reward: -3.25
               Mean episode length: 27.11
       Episode_Reward/keep_balance: 0.0274
     Episode_Reward/rew_lin_vel_xy: 0.0223
      Episode_Reward/rew_ang_vel_z: 0.0525
    Episode_Reward/pen_base_height: -0.1048
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0056
Episode_Reward/pen_flat_orientation: -0.0680
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0072
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0288
Metrics/base_velocity/error_vel_xy: 0.1493
Metrics/base_velocity/error_vel_yaw: 0.0532
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 149.3333
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 1.11s
                        Total time: 43.84s
                               ETA: 3418.6s

################################################################################
                      [1m Learning iteration 38/3000 [0m                      

                       Computation: 87673 steps/s (collection: 1.000s, learning 0.122s)
               Value function loss: 0.1180
                    Surrogate loss: -0.0029
             Mean action noise std: 1.0448
                     Learning rate: 0.0019
                       Mean reward: -3.25
               Mean episode length: 27.12
       Episode_Reward/keep_balance: 0.0272
     Episode_Reward/rew_lin_vel_xy: 0.0227
      Episode_Reward/rew_ang_vel_z: 0.0525
    Episode_Reward/pen_base_height: -0.1036
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0055
Episode_Reward/pen_flat_orientation: -0.0666
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0072
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0283
Metrics/base_velocity/error_vel_xy: 0.1475
Metrics/base_velocity/error_vel_yaw: 0.0521
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 151.7917
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 1.12s
                        Total time: 44.96s
                               ETA: 3414.9s

################################################################################
                      [1m Learning iteration 39/3000 [0m                      

                       Computation: 89759 steps/s (collection: 0.977s, learning 0.119s)
               Value function loss: 0.1020
                    Surrogate loss: 0.0002
             Mean action noise std: 1.0328
                     Learning rate: 0.0019
                       Mean reward: -3.23
               Mean episode length: 26.73
       Episode_Reward/keep_balance: 0.0269
     Episode_Reward/rew_lin_vel_xy: 0.0226
      Episode_Reward/rew_ang_vel_z: 0.0530
    Episode_Reward/pen_base_height: -0.1021
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0056
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0054
Episode_Reward/pen_flat_orientation: -0.0656
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0070
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0280
Metrics/base_velocity/error_vel_xy: 0.1459
Metrics/base_velocity/error_vel_yaw: 0.0499
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 151.0417
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 1.10s
                        Total time: 46.06s
                               ETA: 3409.5s

################################################################################
                      [1m Learning iteration 40/3000 [0m                      

                       Computation: 89645 steps/s (collection: 0.977s, learning 0.120s)
               Value function loss: 0.0991
                    Surrogate loss: -0.0009
             Mean action noise std: 1.0159
                     Learning rate: 0.0009
                       Mean reward: -3.18
               Mean episode length: 26.64
       Episode_Reward/keep_balance: 0.0270
     Episode_Reward/rew_lin_vel_xy: 0.0229
      Episode_Reward/rew_ang_vel_z: 0.0536
    Episode_Reward/pen_base_height: -0.1013
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0053
Episode_Reward/pen_flat_orientation: -0.0648
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0070
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0280
Metrics/base_velocity/error_vel_xy: 0.1461
Metrics/base_velocity/error_vel_yaw: 0.0493
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 152.9167
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 1.10s
                        Total time: 47.16s
                               ETA: 3404.4s

################################################################################
                      [1m Learning iteration 41/3000 [0m                      

                       Computation: 89943 steps/s (collection: 0.968s, learning 0.125s)
               Value function loss: 0.1015
                    Surrogate loss: -0.0032
             Mean action noise std: 1.0064
                     Learning rate: 0.0019
                       Mean reward: -2.98
               Mean episode length: 27.05
       Episode_Reward/keep_balance: 0.0270
     Episode_Reward/rew_lin_vel_xy: 0.0226
      Episode_Reward/rew_ang_vel_z: 0.0547
    Episode_Reward/pen_base_height: -0.1008
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0056
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0052
Episode_Reward/pen_flat_orientation: -0.0643
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0069
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0279
Metrics/base_velocity/error_vel_xy: 0.1471
Metrics/base_velocity/error_vel_yaw: 0.0487
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 151.9167
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 1.09s
                        Total time: 48.25s
                               ETA: 3399.2s

################################################################################
                      [1m Learning iteration 42/3000 [0m                      

                       Computation: 89847 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 0.0818
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9915
                     Learning rate: 0.0019
                       Mean reward: -2.98
               Mean episode length: 26.77
       Episode_Reward/keep_balance: 0.0271
     Episode_Reward/rew_lin_vel_xy: 0.0226
      Episode_Reward/rew_ang_vel_z: 0.0560
    Episode_Reward/pen_base_height: -0.1004
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0057
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0051
Episode_Reward/pen_flat_orientation: -0.0632
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0069
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0278
Metrics/base_velocity/error_vel_xy: 0.1474
Metrics/base_velocity/error_vel_yaw: 0.0469
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 151.5000
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 1.09s
                        Total time: 49.34s
                               ETA: 3394.3s

################################################################################
                      [1m Learning iteration 43/3000 [0m                      

                       Computation: 89118 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.0793
                    Surrogate loss: -0.0012
             Mean action noise std: 0.9778
                     Learning rate: 0.0019
                       Mean reward: -3.09
               Mean episode length: 26.64
       Episode_Reward/keep_balance: 0.0271
     Episode_Reward/rew_lin_vel_xy: 0.0226
      Episode_Reward/rew_ang_vel_z: 0.0568
    Episode_Reward/pen_base_height: -0.1005
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0050
Episode_Reward/pen_flat_orientation: -0.0633
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0066
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0283
Metrics/base_velocity/error_vel_xy: 0.1473
Metrics/base_velocity/error_vel_yaw: 0.0463
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 149.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 1.10s
                        Total time: 50.45s
                               ETA: 3390.2s

################################################################################
                      [1m Learning iteration 44/3000 [0m                      

                       Computation: 89078 steps/s (collection: 0.982s, learning 0.122s)
               Value function loss: 0.0876
                    Surrogate loss: -0.0021
             Mean action noise std: 0.9653
                     Learning rate: 0.0019
                       Mean reward: -3.01
               Mean episode length: 27.32
       Episode_Reward/keep_balance: 0.0274
     Episode_Reward/rew_lin_vel_xy: 0.0231
      Episode_Reward/rew_ang_vel_z: 0.0588
    Episode_Reward/pen_base_height: -0.1012
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0049
Episode_Reward/pen_flat_orientation: -0.0634
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0064
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0285
Metrics/base_velocity/error_vel_xy: 0.1485
Metrics/base_velocity/error_vel_yaw: 0.0454
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 146.4167
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 1.10s
                        Total time: 51.55s
                               ETA: 3386.2s

################################################################################
                      [1m Learning iteration 45/3000 [0m                      

                       Computation: 89726 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.0780
                    Surrogate loss: -0.0005
             Mean action noise std: 0.9543
                     Learning rate: 0.0019
                       Mean reward: -2.83
               Mean episode length: 26.87
       Episode_Reward/keep_balance: 0.0277
     Episode_Reward/rew_lin_vel_xy: 0.0230
      Episode_Reward/rew_ang_vel_z: 0.0608
    Episode_Reward/pen_base_height: -0.1012
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0048
Episode_Reward/pen_flat_orientation: -0.0635
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0063
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0288
Metrics/base_velocity/error_vel_xy: 0.1493
Metrics/base_velocity/error_vel_yaw: 0.0442
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 149.3750
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 1.10s
                        Total time: 52.64s
                               ETA: 3381.9s

################################################################################
                      [1m Learning iteration 46/3000 [0m                      

                       Computation: 90115 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.0835
                    Surrogate loss: -0.0016
             Mean action noise std: 0.9445
                     Learning rate: 0.0009
                       Mean reward: -2.81
               Mean episode length: 26.84
       Episode_Reward/keep_balance: 0.0277
     Episode_Reward/rew_lin_vel_xy: 0.0240
      Episode_Reward/rew_ang_vel_z: 0.0616
    Episode_Reward/pen_base_height: -0.1010
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0047
Episode_Reward/pen_flat_orientation: -0.0631
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0289
Metrics/base_velocity/error_vel_xy: 0.1489
Metrics/base_velocity/error_vel_yaw: 0.0434
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 148.5833
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 1.09s
                        Total time: 53.74s
                               ETA: 3377.3s

################################################################################
                      [1m Learning iteration 47/3000 [0m                      

                       Computation: 90341 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 0.0747
                    Surrogate loss: -0.0030
             Mean action noise std: 0.9281
                     Learning rate: 0.0013
                       Mean reward: -2.74
               Mean episode length: 28.35
       Episode_Reward/keep_balance: 0.0278
     Episode_Reward/rew_lin_vel_xy: 0.0234
      Episode_Reward/rew_ang_vel_z: 0.0624
    Episode_Reward/pen_base_height: -0.1012
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0046
Episode_Reward/pen_flat_orientation: -0.0621
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0289
Metrics/base_velocity/error_vel_xy: 0.1507
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 143.7917
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 1.09s
                        Total time: 54.82s
                               ETA: 3372.8s

################################################################################
                      [1m Learning iteration 48/3000 [0m                      

                       Computation: 90277 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.0678
                    Surrogate loss: -0.0026
             Mean action noise std: 0.9147
                     Learning rate: 0.0019
                       Mean reward: -2.67
               Mean episode length: 28.59
       Episode_Reward/keep_balance: 0.0281
     Episode_Reward/rew_lin_vel_xy: 0.0237
      Episode_Reward/rew_ang_vel_z: 0.0640
    Episode_Reward/pen_base_height: -0.1010
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0045
Episode_Reward/pen_flat_orientation: -0.0620
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0059
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0291
Metrics/base_velocity/error_vel_xy: 0.1504
Metrics/base_velocity/error_vel_yaw: 0.0423
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 148.0417
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 1.09s
                        Total time: 55.91s
                               ETA: 3368.4s

################################################################################
                      [1m Learning iteration 49/3000 [0m                      

                       Computation: 90538 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.0687
                    Surrogate loss: -0.0016
             Mean action noise std: 0.9038
                     Learning rate: 0.0013
                       Mean reward: -2.76
               Mean episode length: 27.56
       Episode_Reward/keep_balance: 0.0280
     Episode_Reward/rew_lin_vel_xy: 0.0236
      Episode_Reward/rew_ang_vel_z: 0.0648
    Episode_Reward/pen_base_height: -0.1008
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0044
Episode_Reward/pen_flat_orientation: -0.0615
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0057
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0288
Metrics/base_velocity/error_vel_xy: 0.1515
Metrics/base_velocity/error_vel_yaw: 0.0412
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 146.2500
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 1.09s
                        Total time: 57.00s
                               ETA: 3364.0s

################################################################################
                      [1m Learning iteration 50/3000 [0m                      

                       Computation: 90242 steps/s (collection: 0.970s, learning 0.119s)
               Value function loss: 0.0744
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8913
                     Learning rate: 0.0019
                       Mean reward: -2.61
               Mean episode length: 28.91
       Episode_Reward/keep_balance: 0.0283
     Episode_Reward/rew_lin_vel_xy: 0.0237
      Episode_Reward/rew_ang_vel_z: 0.0668
    Episode_Reward/pen_base_height: -0.1011
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0043
Episode_Reward/pen_flat_orientation: -0.0611
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0290
Metrics/base_velocity/error_vel_xy: 0.1533
Metrics/base_velocity/error_vel_yaw: 0.0406
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 145.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 1.09s
                        Total time: 58.09s
                               ETA: 3360.0s

################################################################################
                      [1m Learning iteration 51/3000 [0m                      

                       Computation: 90007 steps/s (collection: 0.968s, learning 0.125s)
               Value function loss: 0.0834
                    Surrogate loss: 0.0005
             Mean action noise std: 0.8821
                     Learning rate: 0.0009
                       Mean reward: -2.59
               Mean episode length: 27.90
       Episode_Reward/keep_balance: 0.0283
     Episode_Reward/rew_lin_vel_xy: 0.0235
      Episode_Reward/rew_ang_vel_z: 0.0671
    Episode_Reward/pen_base_height: -0.1006
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0043
Episode_Reward/pen_flat_orientation: -0.0606
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0288
Metrics/base_velocity/error_vel_xy: 0.1523
Metrics/base_velocity/error_vel_yaw: 0.0405
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 142.9167
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 1.09s
                        Total time: 59.18s
                               ETA: 3356.2s

################################################################################
                      [1m Learning iteration 52/3000 [0m                      

                       Computation: 89657 steps/s (collection: 0.970s, learning 0.127s)
               Value function loss: 0.0690
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8706
                     Learning rate: 0.0009
                       Mean reward: -2.66
               Mean episode length: 28.93
       Episode_Reward/keep_balance: 0.0283
     Episode_Reward/rew_lin_vel_xy: 0.0242
      Episode_Reward/rew_ang_vel_z: 0.0686
    Episode_Reward/pen_base_height: -0.1006
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0042
Episode_Reward/pen_flat_orientation: -0.0601
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0054
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0289
Metrics/base_velocity/error_vel_xy: 0.1507
Metrics/base_velocity/error_vel_yaw: 0.0390
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 142.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 1.10s
                        Total time: 60.28s
                               ETA: 3352.7s

################################################################################
                      [1m Learning iteration 53/3000 [0m                      

                       Computation: 88056 steps/s (collection: 0.993s, learning 0.124s)
               Value function loss: 0.0788
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8593
                     Learning rate: 0.0019
                       Mean reward: -2.58
               Mean episode length: 28.66
       Episode_Reward/keep_balance: 0.0285
     Episode_Reward/rew_lin_vel_xy: 0.0247
      Episode_Reward/rew_ang_vel_z: 0.0692
    Episode_Reward/pen_base_height: -0.1010
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0017
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0602
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0292
Metrics/base_velocity/error_vel_xy: 0.1517
Metrics/base_velocity/error_vel_yaw: 0.0394
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 143.9583
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 1.12s
                        Total time: 61.39s
                               ETA: 3350.4s

################################################################################
                      [1m Learning iteration 54/3000 [0m                      

                       Computation: 89373 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 0.0703
                    Surrogate loss: 0.0034
             Mean action noise std: 0.8497
                     Learning rate: 0.0009
                       Mean reward: -2.61
               Mean episode length: 28.81
       Episode_Reward/keep_balance: 0.0288
     Episode_Reward/rew_lin_vel_xy: 0.0252
      Episode_Reward/rew_ang_vel_z: 0.0716
    Episode_Reward/pen_base_height: -0.1011
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0597
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0296
Metrics/base_velocity/error_vel_xy: 0.1531
Metrics/base_velocity/error_vel_yaw: 0.0386
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 141.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 1.10s
                        Total time: 62.49s
                               ETA: 3347.3s

################################################################################
                      [1m Learning iteration 55/3000 [0m                      

                       Computation: 88642 steps/s (collection: 0.986s, learning 0.123s)
               Value function loss: 0.0710
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8388
                     Learning rate: 0.0013
                       Mean reward: -2.43
               Mean episode length: 29.40
       Episode_Reward/keep_balance: 0.0290
     Episode_Reward/rew_lin_vel_xy: 0.0253
      Episode_Reward/rew_ang_vel_z: 0.0722
    Episode_Reward/pen_base_height: -0.1010
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0591
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0297
Metrics/base_velocity/error_vel_xy: 0.1544
Metrics/base_velocity/error_vel_yaw: 0.0381
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 139.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 1.11s
                        Total time: 63.60s
                               ETA: 3344.8s

################################################################################
                      [1m Learning iteration 56/3000 [0m                      

                       Computation: 89618 steps/s (collection: 0.975s, learning 0.122s)
               Value function loss: 0.0774
                    Surrogate loss: -0.0011
             Mean action noise std: 0.8304
                     Learning rate: 0.0013
                       Mean reward: -2.33
               Mean episode length: 29.98
       Episode_Reward/keep_balance: 0.0293
     Episode_Reward/rew_lin_vel_xy: 0.0259
      Episode_Reward/rew_ang_vel_z: 0.0743
    Episode_Reward/pen_base_height: -0.1022
      Episode_Reward/pen_lin_vel_z: -0.0112
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0018
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0593
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0049
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0301
Metrics/base_velocity/error_vel_xy: 0.1543
Metrics/base_velocity/error_vel_yaw: 0.0377
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 139.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 1.10s
                        Total time: 64.70s
                               ETA: 3341.6s

################################################################################
                      [1m Learning iteration 57/3000 [0m                      

                       Computation: 90098 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.0739
                    Surrogate loss: -0.0010
             Mean action noise std: 0.8190
                     Learning rate: 0.0013
                       Mean reward: -2.39
               Mean episode length: 30.09
       Episode_Reward/keep_balance: 0.0297
     Episode_Reward/rew_lin_vel_xy: 0.0266
      Episode_Reward/rew_ang_vel_z: 0.0757
    Episode_Reward/pen_base_height: -0.1019
      Episode_Reward/pen_lin_vel_z: -0.0110
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0306
Metrics/base_velocity/error_vel_xy: 0.1569
Metrics/base_velocity/error_vel_yaw: 0.0378
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 138.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 1.09s
                        Total time: 65.79s
                               ETA: 3338.3s

################################################################################
                      [1m Learning iteration 58/3000 [0m                      

                       Computation: 91032 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.0844
                    Surrogate loss: 0.0018
             Mean action noise std: 0.8136
                     Learning rate: 0.0006
                       Mean reward: -2.23
               Mean episode length: 29.37
       Episode_Reward/keep_balance: 0.0299
     Episode_Reward/rew_lin_vel_xy: 0.0259
      Episode_Reward/rew_ang_vel_z: 0.0769
    Episode_Reward/pen_base_height: -0.1020
      Episode_Reward/pen_lin_vel_z: -0.0110
     Episode_Reward/pen_ang_vel_xy: -0.0201
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0306
Metrics/base_velocity/error_vel_xy: 0.1583
Metrics/base_velocity/error_vel_yaw: 0.0377
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 135.4167
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 1.08s
                        Total time: 66.87s
                               ETA: 3334.4s

################################################################################
                      [1m Learning iteration 59/3000 [0m                      

                       Computation: 90575 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.0876
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8045
                     Learning rate: 0.0009
                       Mean reward: -2.35
               Mean episode length: 30.66
       Episode_Reward/keep_balance: 0.0302
     Episode_Reward/rew_lin_vel_xy: 0.0266
      Episode_Reward/rew_ang_vel_z: 0.0784
    Episode_Reward/pen_base_height: -0.1024
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0582
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0307
Metrics/base_velocity/error_vel_xy: 0.1578
Metrics/base_velocity/error_vel_yaw: 0.0374
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 133.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 1.09s
                        Total time: 67.95s
                               ETA: 3330.9s

################################################################################
                      [1m Learning iteration 60/3000 [0m                      

                       Computation: 91344 steps/s (collection: 0.955s, learning 0.121s)
               Value function loss: 0.0889
                    Surrogate loss: -0.0002
             Mean action noise std: 0.7960
                     Learning rate: 0.0013
                       Mean reward: -2.12
               Mean episode length: 30.39
       Episode_Reward/keep_balance: 0.0305
     Episode_Reward/rew_lin_vel_xy: 0.0267
      Episode_Reward/rew_ang_vel_z: 0.0802
    Episode_Reward/pen_base_height: -0.1024
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0310
Metrics/base_velocity/error_vel_xy: 0.1630
Metrics/base_velocity/error_vel_yaw: 0.0373
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 134.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 1.08s
                        Total time: 69.03s
                               ETA: 3327.1s

################################################################################
                      [1m Learning iteration 61/3000 [0m                      

                       Computation: 89646 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.0919
                    Surrogate loss: 0.0003
             Mean action noise std: 0.7910
                     Learning rate: 0.0006
                       Mean reward: -2.06
               Mean episode length: 30.45
       Episode_Reward/keep_balance: 0.0305
     Episode_Reward/rew_lin_vel_xy: 0.0263
      Episode_Reward/rew_ang_vel_z: 0.0809
    Episode_Reward/pen_base_height: -0.1028
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0019
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0579
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0309
Metrics/base_velocity/error_vel_xy: 0.1620
Metrics/base_velocity/error_vel_yaw: 0.0363
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 133.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 1.10s
                        Total time: 70.13s
                               ETA: 3324.3s

################################################################################
                      [1m Learning iteration 62/3000 [0m                      

                       Computation: 90827 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.0947
                    Surrogate loss: -0.0011
             Mean action noise std: 0.7828
                     Learning rate: 0.0009
                       Mean reward: -2.13
               Mean episode length: 31.80
       Episode_Reward/keep_balance: 0.0308
     Episode_Reward/rew_lin_vel_xy: 0.0258
      Episode_Reward/rew_ang_vel_z: 0.0824
    Episode_Reward/pen_base_height: -0.1028
      Episode_Reward/pen_lin_vel_z: -0.0107
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0313
Metrics/base_velocity/error_vel_xy: 0.1638
Metrics/base_velocity/error_vel_yaw: 0.0363
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 131.8333
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 1.08s
                        Total time: 71.21s
                               ETA: 3320.9s

################################################################################
                      [1m Learning iteration 63/3000 [0m                      

                       Computation: 90436 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.0941
                    Surrogate loss: -0.0031
             Mean action noise std: 0.7770
                     Learning rate: 0.0009
                       Mean reward: -2.21
               Mean episode length: 30.63
       Episode_Reward/keep_balance: 0.0311
     Episode_Reward/rew_lin_vel_xy: 0.0271
      Episode_Reward/rew_ang_vel_z: 0.0834
    Episode_Reward/pen_base_height: -0.1032
      Episode_Reward/pen_lin_vel_z: -0.0106
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0043
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0316
Metrics/base_velocity/error_vel_xy: 0.1638
Metrics/base_velocity/error_vel_yaw: 0.0367
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 131.2083
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 1.09s
                        Total time: 72.30s
                               ETA: 3317.7s

################################################################################
                      [1m Learning iteration 64/3000 [0m                      

                       Computation: 91633 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.0941
                    Surrogate loss: 0.0010
             Mean action noise std: 0.7691
                     Learning rate: 0.0009
                       Mean reward: -2.07
               Mean episode length: 30.67
       Episode_Reward/keep_balance: 0.0313
     Episode_Reward/rew_lin_vel_xy: 0.0271
      Episode_Reward/rew_ang_vel_z: 0.0845
    Episode_Reward/pen_base_height: -0.1036
      Episode_Reward/pen_lin_vel_z: -0.0105
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0020
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0318
Metrics/base_velocity/error_vel_xy: 0.1656
Metrics/base_velocity/error_vel_yaw: 0.0362
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 128.5000
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 1.07s
                        Total time: 73.37s
                               ETA: 3314.1s

################################################################################
                      [1m Learning iteration 65/3000 [0m                      

                       Computation: 91232 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.0915
                    Surrogate loss: -0.0013
             Mean action noise std: 0.7637
                     Learning rate: 0.0013
                       Mean reward: -2.06
               Mean episode length: 31.40
       Episode_Reward/keep_balance: 0.0316
     Episode_Reward/rew_lin_vel_xy: 0.0271
      Episode_Reward/rew_ang_vel_z: 0.0856
    Episode_Reward/pen_base_height: -0.1036
      Episode_Reward/pen_lin_vel_z: -0.0104
     Episode_Reward/pen_ang_vel_xy: -0.0190
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0589
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0320
Metrics/base_velocity/error_vel_xy: 0.1665
Metrics/base_velocity/error_vel_yaw: 0.0364
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 130.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 1.08s
                        Total time: 74.45s
                               ETA: 3310.6s

################################################################################
                      [1m Learning iteration 66/3000 [0m                      

                       Computation: 90621 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.0997
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7591
                     Learning rate: 0.0009
                       Mean reward: -2.06
               Mean episode length: 32.78
       Episode_Reward/keep_balance: 0.0316
     Episode_Reward/rew_lin_vel_xy: 0.0266
      Episode_Reward/rew_ang_vel_z: 0.0861
    Episode_Reward/pen_base_height: -0.1037
      Episode_Reward/pen_lin_vel_z: -0.0105
     Episode_Reward/pen_ang_vel_xy: -0.0193
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0592
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0320
Metrics/base_velocity/error_vel_xy: 0.1671
Metrics/base_velocity/error_vel_yaw: 0.0359
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 131.2083
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 1.08s
                        Total time: 75.53s
                               ETA: 3307.6s

################################################################################
                      [1m Learning iteration 67/3000 [0m                      

                       Computation: 90374 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.0972
                    Surrogate loss: -0.0001
             Mean action noise std: 0.7527
                     Learning rate: 0.0013
                       Mean reward: -2.16
               Mean episode length: 30.25
       Episode_Reward/keep_balance: 0.0316
     Episode_Reward/rew_lin_vel_xy: 0.0276
      Episode_Reward/rew_ang_vel_z: 0.0866
    Episode_Reward/pen_base_height: -0.1033
      Episode_Reward/pen_lin_vel_z: -0.0105
     Episode_Reward/pen_ang_vel_xy: -0.0191
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0319
Metrics/base_velocity/error_vel_xy: 0.1668
Metrics/base_velocity/error_vel_yaw: 0.0354
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 127.0417
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 1.09s
                        Total time: 76.62s
                               ETA: 3304.8s

################################################################################
                      [1m Learning iteration 68/3000 [0m                      

                       Computation: 90464 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.0905
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7476
                     Learning rate: 0.0006
                       Mean reward: -1.96
               Mean episode length: 32.84
       Episode_Reward/keep_balance: 0.0321
     Episode_Reward/rew_lin_vel_xy: 0.0289
      Episode_Reward/rew_ang_vel_z: 0.0885
    Episode_Reward/pen_base_height: -0.1043
      Episode_Reward/pen_lin_vel_z: -0.0104
     Episode_Reward/pen_ang_vel_xy: -0.0191
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0590
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0325
Metrics/base_velocity/error_vel_xy: 0.1676
Metrics/base_velocity/error_vel_yaw: 0.0357
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 125.1250
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 1.09s
                        Total time: 77.71s
                               ETA: 3302.0s

################################################################################
                      [1m Learning iteration 69/3000 [0m                      

                       Computation: 90142 steps/s (collection: 0.965s, learning 0.126s)
               Value function loss: 0.0860
                    Surrogate loss: -0.0026
             Mean action noise std: 0.7423
                     Learning rate: 0.0009
                       Mean reward: -2.00
               Mean episode length: 32.03
       Episode_Reward/keep_balance: 0.0322
     Episode_Reward/rew_lin_vel_xy: 0.0277
      Episode_Reward/rew_ang_vel_z: 0.0894
    Episode_Reward/pen_base_height: -0.1034
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0190
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0323
Metrics/base_velocity/error_vel_xy: 0.1690
Metrics/base_velocity/error_vel_yaw: 0.0347
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 129.8333
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 1.09s
                        Total time: 78.80s
                               ETA: 3299.3s

################################################################################
                      [1m Learning iteration 70/3000 [0m                      

                       Computation: 89861 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.0999
                    Surrogate loss: -0.0019
             Mean action noise std: 0.7359
                     Learning rate: 0.0009
                       Mean reward: -1.92
               Mean episode length: 31.58
       Episode_Reward/keep_balance: 0.0321
     Episode_Reward/rew_lin_vel_xy: 0.0284
      Episode_Reward/rew_ang_vel_z: 0.0893
    Episode_Reward/pen_base_height: -0.1033
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0190
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0589
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0322
Metrics/base_velocity/error_vel_xy: 0.1678
Metrics/base_velocity/error_vel_yaw: 0.0347
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 125.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 1.09s
                        Total time: 79.89s
                               ETA: 3296.9s

################################################################################
                      [1m Learning iteration 71/3000 [0m                      

                       Computation: 90137 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.1023
                    Surrogate loss: -0.0006
             Mean action noise std: 0.7311
                     Learning rate: 0.0009
                       Mean reward: -1.92
               Mean episode length: 32.39
       Episode_Reward/keep_balance: 0.0325
     Episode_Reward/rew_lin_vel_xy: 0.0280
      Episode_Reward/rew_ang_vel_z: 0.0906
    Episode_Reward/pen_base_height: -0.1035
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0189
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0590
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0327
Metrics/base_velocity/error_vel_xy: 0.1722
Metrics/base_velocity/error_vel_yaw: 0.0352
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 124.6667
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 1.09s
                        Total time: 80.98s
                               ETA: 3294.4s

################################################################################
                      [1m Learning iteration 72/3000 [0m                      

                       Computation: 89662 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 0.0989
                    Surrogate loss: -0.0032
             Mean action noise std: 0.7247
                     Learning rate: 0.0013
                       Mean reward: -1.82
               Mean episode length: 33.23
       Episode_Reward/keep_balance: 0.0328
     Episode_Reward/rew_lin_vel_xy: 0.0279
      Episode_Reward/rew_ang_vel_z: 0.0918
    Episode_Reward/pen_base_height: -0.1038
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0188
   Episode_Reward/pen_joint_torque: -0.0022
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0328
Metrics/base_velocity/error_vel_xy: 0.1720
Metrics/base_velocity/error_vel_yaw: 0.0352
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 127.1250
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 1.10s
                        Total time: 82.08s
                               ETA: 3292.1s

################################################################################
                      [1m Learning iteration 73/3000 [0m                      

                       Computation: 89235 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.1086
                    Surrogate loss: 0.0002
             Mean action noise std: 0.7203
                     Learning rate: 0.0019
                       Mean reward: -1.95
               Mean episode length: 33.41
       Episode_Reward/keep_balance: 0.0326
     Episode_Reward/rew_lin_vel_xy: 0.0293
      Episode_Reward/rew_ang_vel_z: 0.0917
    Episode_Reward/pen_base_height: -0.1029
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0188
   Episode_Reward/pen_joint_torque: -0.0021
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0325
Metrics/base_velocity/error_vel_xy: 0.1699
Metrics/base_velocity/error_vel_yaw: 0.0347
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 124.5000
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 1.10s
                        Total time: 83.18s
                               ETA: 3290.1s

################################################################################
                      [1m Learning iteration 74/3000 [0m                      

                       Computation: 88869 steps/s (collection: 0.983s, learning 0.123s)
               Value function loss: 0.1238
                    Surrogate loss: -0.0000
             Mean action noise std: 0.7150
                     Learning rate: 0.0013
                       Mean reward: -1.87
               Mean episode length: 32.11
       Episode_Reward/keep_balance: 0.0329
     Episode_Reward/rew_lin_vel_xy: 0.0292
      Episode_Reward/rew_ang_vel_z: 0.0928
    Episode_Reward/pen_base_height: -0.1031
      Episode_Reward/pen_lin_vel_z: -0.0103
     Episode_Reward/pen_ang_vel_xy: -0.0187
   Episode_Reward/pen_joint_torque: -0.0022
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0327
Metrics/base_velocity/error_vel_xy: 0.1721
Metrics/base_velocity/error_vel_yaw: 0.0348
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 123.1250
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 1.11s
                        Total time: 84.29s
                               ETA: 3288.3s

################################################################################
                      [1m Learning iteration 75/3000 [0m                      

                       Computation: 90822 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.1114
                    Surrogate loss: -0.0031
             Mean action noise std: 0.7089
                     Learning rate: 0.0019
                       Mean reward: -1.77
               Mean episode length: 34.15
       Episode_Reward/keep_balance: 0.0331
     Episode_Reward/rew_lin_vel_xy: 0.0290
      Episode_Reward/rew_ang_vel_z: 0.0931
    Episode_Reward/pen_base_height: -0.1030
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0187
   Episode_Reward/pen_joint_torque: -0.0022
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0582
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0330
Metrics/base_velocity/error_vel_xy: 0.1740
Metrics/base_velocity/error_vel_yaw: 0.0350
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 121.5417
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 1.08s
                        Total time: 85.37s
                               ETA: 3285.5s

################################################################################
                      [1m Learning iteration 76/3000 [0m                      

                       Computation: 89611 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.0945
                    Surrogate loss: -0.0008
             Mean action noise std: 0.7051
                     Learning rate: 0.0013
                       Mean reward: -1.80
               Mean episode length: 33.81
       Episode_Reward/keep_balance: 0.0337
     Episode_Reward/rew_lin_vel_xy: 0.0303
      Episode_Reward/rew_ang_vel_z: 0.0953
    Episode_Reward/pen_base_height: -0.1031
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0187
   Episode_Reward/pen_joint_torque: -0.0022
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0335
Metrics/base_velocity/error_vel_xy: 0.1760
Metrics/base_velocity/error_vel_yaw: 0.0354
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 124.5833
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 1.10s
                        Total time: 86.47s
                               ETA: 3283.4s

################################################################################
                      [1m Learning iteration 77/3000 [0m                      

                       Computation: 91248 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.0935
                    Surrogate loss: 0.0000
             Mean action noise std: 0.7010
                     Learning rate: 0.0013
                       Mean reward: -1.87
               Mean episode length: 33.29
       Episode_Reward/keep_balance: 0.0335
     Episode_Reward/rew_lin_vel_xy: 0.0291
      Episode_Reward/rew_ang_vel_z: 0.0951
    Episode_Reward/pen_base_height: -0.1028
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0188
   Episode_Reward/pen_joint_torque: -0.0022
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0033
Episode_Reward/pen_flat_orientation: -0.0578
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0334
Metrics/base_velocity/error_vel_xy: 0.1780
Metrics/base_velocity/error_vel_yaw: 0.0347
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 119.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 1.08s
                        Total time: 87.54s
                               ETA: 3280.6s

################################################################################
                      [1m Learning iteration 78/3000 [0m                      

                       Computation: 91289 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.1076
                    Surrogate loss: 0.0027
             Mean action noise std: 0.6987
                     Learning rate: 0.0006
                       Mean reward: -1.87
               Mean episode length: 34.95
       Episode_Reward/keep_balance: 0.0341
     Episode_Reward/rew_lin_vel_xy: 0.0299
      Episode_Reward/rew_ang_vel_z: 0.0970
    Episode_Reward/pen_base_height: -0.1033
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0186
   Episode_Reward/pen_joint_torque: -0.0023
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0062
   Episode_Reward/test_gait_reward: -0.0341
Metrics/base_velocity/error_vel_xy: 0.1808
Metrics/base_velocity/error_vel_yaw: 0.0355
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 117.3333
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 1.08s
                        Total time: 88.62s
                               ETA: 3277.8s

################################################################################
                      [1m Learning iteration 79/3000 [0m                      

                       Computation: 91970 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.1139
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6945
                     Learning rate: 0.0009
                       Mean reward: -1.60
               Mean episode length: 35.19
       Episode_Reward/keep_balance: 0.0346
     Episode_Reward/rew_lin_vel_xy: 0.0301
      Episode_Reward/rew_ang_vel_z: 0.0985
    Episode_Reward/pen_base_height: -0.1033
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0187
   Episode_Reward/pen_joint_torque: -0.0023
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0587
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0346
Metrics/base_velocity/error_vel_xy: 0.1834
Metrics/base_velocity/error_vel_yaw: 0.0361
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 119.8333
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 1.07s
                        Total time: 89.69s
                               ETA: 3274.7s

################################################################################
                      [1m Learning iteration 80/3000 [0m                      

                       Computation: 91055 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.1203
                    Surrogate loss: -0.0001
             Mean action noise std: 0.6919
                     Learning rate: 0.0006
                       Mean reward: -1.82
               Mean episode length: 34.40
       Episode_Reward/keep_balance: 0.0345
     Episode_Reward/rew_lin_vel_xy: 0.0316
      Episode_Reward/rew_ang_vel_z: 0.0985
    Episode_Reward/pen_base_height: -0.1030
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0190
   Episode_Reward/pen_joint_torque: -0.0023
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0578
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0343
Metrics/base_velocity/error_vel_xy: 0.1803
Metrics/base_velocity/error_vel_yaw: 0.0356
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 118.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 1.08s
                        Total time: 90.77s
                               ETA: 3272.1s

################################################################################
                      [1m Learning iteration 81/3000 [0m                      

                       Computation: 91177 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.1119
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6877
                     Learning rate: 0.0009
                       Mean reward: -1.79
               Mean episode length: 34.59
       Episode_Reward/keep_balance: 0.0345
     Episode_Reward/rew_lin_vel_xy: 0.0312
      Episode_Reward/rew_ang_vel_z: 0.0989
    Episode_Reward/pen_base_height: -0.1027
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0189
   Episode_Reward/pen_joint_torque: -0.0023
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0033
Episode_Reward/pen_flat_orientation: -0.0576
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0343
Metrics/base_velocity/error_vel_xy: 0.1808
Metrics/base_velocity/error_vel_yaw: 0.0348
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 1.08s
                        Total time: 91.85s
                               ETA: 3269.5s

################################################################################
                      [1m Learning iteration 82/3000 [0m                      

                       Computation: 90340 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 0.1137
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6845
                     Learning rate: 0.0009
                       Mean reward: -1.45
               Mean episode length: 35.89
       Episode_Reward/keep_balance: 0.0351
     Episode_Reward/rew_lin_vel_xy: 0.0309
      Episode_Reward/rew_ang_vel_z: 0.1007
    Episode_Reward/pen_base_height: -0.1026
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0191
   Episode_Reward/pen_joint_torque: -0.0024
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0579
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0349
Metrics/base_velocity/error_vel_xy: 0.1845
Metrics/base_velocity/error_vel_yaw: 0.0356
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 116.7083
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 1.09s
                        Total time: 92.93s
                               ETA: 3267.2s

################################################################################
                      [1m Learning iteration 83/3000 [0m                      

                       Computation: 90461 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.1184
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6804
                     Learning rate: 0.0009
                       Mean reward: -1.58
               Mean episode length: 35.76
       Episode_Reward/keep_balance: 0.0354
     Episode_Reward/rew_lin_vel_xy: 0.0333
      Episode_Reward/rew_ang_vel_z: 0.1021
    Episode_Reward/pen_base_height: -0.1025
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0190
   Episode_Reward/pen_joint_torque: -0.0025
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0353
Metrics/base_velocity/error_vel_xy: 0.1827
Metrics/base_velocity/error_vel_yaw: 0.0357
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 117.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 1.09s
                        Total time: 94.02s
                               ETA: 3265.0s

################################################################################
                      [1m Learning iteration 84/3000 [0m                      

                       Computation: 90981 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.1147
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6772
                     Learning rate: 0.0009
                       Mean reward: -1.71
               Mean episode length: 34.20
       Episode_Reward/keep_balance: 0.0354
     Episode_Reward/rew_lin_vel_xy: 0.0315
      Episode_Reward/rew_ang_vel_z: 0.1017
    Episode_Reward/pen_base_height: -0.1022
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0192
   Episode_Reward/pen_joint_torque: -0.0025
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0015
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0033
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0353
Metrics/base_velocity/error_vel_xy: 0.1866
Metrics/base_velocity/error_vel_yaw: 0.0357
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 109.7083
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 1.08s
                        Total time: 95.10s
                               ETA: 3262.5s

################################################################################
                      [1m Learning iteration 85/3000 [0m                      

                       Computation: 91228 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.1205
                    Surrogate loss: 0.0038
             Mean action noise std: 0.6752
                     Learning rate: 0.0003
                       Mean reward: -1.61
               Mean episode length: 34.23
       Episode_Reward/keep_balance: 0.0362
     Episode_Reward/rew_lin_vel_xy: 0.0337
      Episode_Reward/rew_ang_vel_z: 0.1046
    Episode_Reward/pen_base_height: -0.1030
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0189
   Episode_Reward/pen_joint_torque: -0.0026
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0361
Metrics/base_velocity/error_vel_xy: 0.1871
Metrics/base_velocity/error_vel_yaw: 0.0365
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 115.2500
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 1.08s
                        Total time: 96.18s
                               ETA: 3260.0s

################################################################################
                      [1m Learning iteration 86/3000 [0m                      

                       Computation: 91879 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 0.1166
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6727
                     Learning rate: 0.0006
                       Mean reward: -1.65
               Mean episode length: 35.91
       Episode_Reward/keep_balance: 0.0362
     Episode_Reward/rew_lin_vel_xy: 0.0337
      Episode_Reward/rew_ang_vel_z: 0.1051
    Episode_Reward/pen_base_height: -0.1031
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0188
   Episode_Reward/pen_joint_torque: -0.0026
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.0033
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0360
Metrics/base_velocity/error_vel_xy: 0.1881
Metrics/base_velocity/error_vel_yaw: 0.0358
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 111.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 1.07s
                        Total time: 97.25s
                               ETA: 3257.3s

################################################################################
                      [1m Learning iteration 87/3000 [0m                      

                       Computation: 92180 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 0.1204
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6687
                     Learning rate: 0.0013
                       Mean reward: -1.48
               Mean episode length: 37.63
       Episode_Reward/keep_balance: 0.0368
     Episode_Reward/rew_lin_vel_xy: 0.0335
      Episode_Reward/rew_ang_vel_z: 0.1067
    Episode_Reward/pen_base_height: -0.1038
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0187
   Episode_Reward/pen_joint_torque: -0.0027
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0588
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0366
Metrics/base_velocity/error_vel_xy: 0.1913
Metrics/base_velocity/error_vel_yaw: 0.0366
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 110.6250
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 1.07s
                        Total time: 98.32s
                               ETA: 3254.5s

################################################################################
                      [1m Learning iteration 88/3000 [0m                      

                       Computation: 91044 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.1347
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6663
                     Learning rate: 0.0009
                       Mean reward: -1.52
               Mean episode length: 37.23
       Episode_Reward/keep_balance: 0.0368
     Episode_Reward/rew_lin_vel_xy: 0.0331
      Episode_Reward/rew_ang_vel_z: 0.1067
    Episode_Reward/pen_base_height: -0.1033
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0188
   Episode_Reward/pen_joint_torque: -0.0027
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0366
Metrics/base_velocity/error_vel_xy: 0.1911
Metrics/base_velocity/error_vel_yaw: 0.0366
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 110.3333
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 1.08s
                        Total time: 99.39s
                               ETA: 3252.1s

################################################################################
                      [1m Learning iteration 89/3000 [0m                      

                       Computation: 90628 steps/s (collection: 0.963s, learning 0.121s)
               Value function loss: 0.1415
                    Surrogate loss: 0.0004
             Mean action noise std: 0.6639
                     Learning rate: 0.0013
                       Mean reward: -1.43
               Mean episode length: 36.91
       Episode_Reward/keep_balance: 0.0371
     Episode_Reward/rew_lin_vel_xy: 0.0328
      Episode_Reward/rew_ang_vel_z: 0.1075
    Episode_Reward/pen_base_height: -0.1032
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0188
   Episode_Reward/pen_joint_torque: -0.0028
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0584
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0063
   Episode_Reward/test_gait_reward: -0.0370
Metrics/base_velocity/error_vel_xy: 0.1945
Metrics/base_velocity/error_vel_yaw: 0.0370
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 111.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 1.08s
                        Total time: 100.48s
                               ETA: 3250.0s

################################################################################
                      [1m Learning iteration 90/3000 [0m                      

                       Computation: 89682 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.1627
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6618
                     Learning rate: 0.0019
                       Mean reward: -1.46
               Mean episode length: 37.46
       Episode_Reward/keep_balance: 0.0374
     Episode_Reward/rew_lin_vel_xy: 0.0343
      Episode_Reward/rew_ang_vel_z: 0.1090
    Episode_Reward/pen_base_height: -0.1032
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0189
   Episode_Reward/pen_joint_torque: -0.0028
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0575
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0373
Metrics/base_velocity/error_vel_xy: 0.1947
Metrics/base_velocity/error_vel_yaw: 0.0366
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 105.2500
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 1.10s
                        Total time: 101.58s
                               ETA: 3248.2s

################################################################################
                      [1m Learning iteration 91/3000 [0m                      

                       Computation: 90463 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.1249
                    Surrogate loss: 0.0020
             Mean action noise std: 0.6601
                     Learning rate: 0.0006
                       Mean reward: -1.49
               Mean episode length: 38.65
       Episode_Reward/keep_balance: 0.0379
     Episode_Reward/rew_lin_vel_xy: 0.0362
      Episode_Reward/rew_ang_vel_z: 0.1107
    Episode_Reward/pen_base_height: -0.1038
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0190
   Episode_Reward/pen_joint_torque: -0.0028
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0016
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0587
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0379
Metrics/base_velocity/error_vel_xy: 0.1945
Metrics/base_velocity/error_vel_yaw: 0.0375
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 109.0417
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 1.09s
                        Total time: 102.66s
                               ETA: 3246.1s

################################################################################
                      [1m Learning iteration 92/3000 [0m                      

                       Computation: 90420 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.1308
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6564
                     Learning rate: 0.0013
                       Mean reward: -1.51
               Mean episode length: 37.99
       Episode_Reward/keep_balance: 0.0380
     Episode_Reward/rew_lin_vel_xy: 0.0357
      Episode_Reward/rew_ang_vel_z: 0.1114
    Episode_Reward/pen_base_height: -0.1039
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0192
   Episode_Reward/pen_joint_torque: -0.0029
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0380
Metrics/base_velocity/error_vel_xy: 0.1950
Metrics/base_velocity/error_vel_yaw: 0.0368
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 107.4583
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 1.09s
                        Total time: 103.75s
                               ETA: 3244.1s

################################################################################
                      [1m Learning iteration 93/3000 [0m                      

                       Computation: 91083 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.1603
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6533
                     Learning rate: 0.0013
                       Mean reward: -1.47
               Mean episode length: 37.18
       Episode_Reward/keep_balance: 0.0382
     Episode_Reward/rew_lin_vel_xy: 0.0355
      Episode_Reward/rew_ang_vel_z: 0.1120
    Episode_Reward/pen_base_height: -0.1036
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0192
   Episode_Reward/pen_joint_torque: -0.0029
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0588
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0381
Metrics/base_velocity/error_vel_xy: 0.1975
Metrics/base_velocity/error_vel_yaw: 0.0368
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 106.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 1.08s
                        Total time: 104.83s
                               ETA: 3241.9s

################################################################################
                      [1m Learning iteration 94/3000 [0m                      

                       Computation: 89439 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.1539
                    Surrogate loss: 0.0015
             Mean action noise std: 0.6520
                     Learning rate: 0.0006
                       Mean reward: -1.23
               Mean episode length: 39.52
       Episode_Reward/keep_balance: 0.0383
     Episode_Reward/rew_lin_vel_xy: 0.0353
      Episode_Reward/rew_ang_vel_z: 0.1130
    Episode_Reward/pen_base_height: -0.1037
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0192
   Episode_Reward/pen_joint_torque: -0.0029
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0013
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0582
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0038
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0382
Metrics/base_velocity/error_vel_xy: 0.1994
Metrics/base_velocity/error_vel_yaw: 0.0368
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 104.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 1.10s
                        Total time: 105.93s
                               ETA: 3240.3s

################################################################################
                      [1m Learning iteration 95/3000 [0m                      

                       Computation: 89527 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.1333
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6514
                     Learning rate: 0.0009
                       Mean reward: -1.39
               Mean episode length: 37.74
       Episode_Reward/keep_balance: 0.0388
     Episode_Reward/rew_lin_vel_xy: 0.0357
      Episode_Reward/rew_ang_vel_z: 0.1140
    Episode_Reward/pen_base_height: -0.1038
      Episode_Reward/pen_lin_vel_z: -0.0100
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0387
Metrics/base_velocity/error_vel_xy: 0.2007
Metrics/base_velocity/error_vel_yaw: 0.0372
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 106.2917
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 1.10s
                        Total time: 107.03s
                               ETA: 3238.6s

################################################################################
                      [1m Learning iteration 96/3000 [0m                      

                       Computation: 91158 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.1338
                    Surrogate loss: -0.0010
             Mean action noise std: 0.6485
                     Learning rate: 0.0013
                       Mean reward: -1.30
               Mean episode length: 38.77
       Episode_Reward/keep_balance: 0.0391
     Episode_Reward/rew_lin_vel_xy: 0.0378
      Episode_Reward/rew_ang_vel_z: 0.1153
    Episode_Reward/pen_base_height: -0.1040
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0391
Metrics/base_velocity/error_vel_xy: 0.2023
Metrics/base_velocity/error_vel_yaw: 0.0372
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 104.0417
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 1.08s
                        Total time: 108.10s
                               ETA: 3236.4s

################################################################################
                      [1m Learning iteration 97/3000 [0m                      

                       Computation: 89405 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.1446
                    Surrogate loss: -0.0000
             Mean action noise std: 0.6465
                     Learning rate: 0.0013
                       Mean reward: -1.33
               Mean episode length: 39.95
       Episode_Reward/keep_balance: 0.0395
     Episode_Reward/rew_lin_vel_xy: 0.0371
      Episode_Reward/rew_ang_vel_z: 0.1157
    Episode_Reward/pen_base_height: -0.1038
      Episode_Reward/pen_lin_vel_z: -0.0099
     Episode_Reward/pen_ang_vel_xy: -0.0194
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0588
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0397
Metrics/base_velocity/error_vel_xy: 0.2047
Metrics/base_velocity/error_vel_yaw: 0.0381
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 103.8750
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 1.10s
                        Total time: 109.20s
                               ETA: 3234.9s

################################################################################
                      [1m Learning iteration 98/3000 [0m                      

                       Computation: 89836 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.1452
                    Surrogate loss: 0.0017
             Mean action noise std: 0.6444
                     Learning rate: 0.0009
                       Mean reward: -1.17
               Mean episode length: 39.94
       Episode_Reward/keep_balance: 0.0394
     Episode_Reward/rew_lin_vel_xy: 0.0364
      Episode_Reward/rew_ang_vel_z: 0.1155
    Episode_Reward/pen_base_height: -0.1035
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0031
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0396
Metrics/base_velocity/error_vel_xy: 0.2066
Metrics/base_velocity/error_vel_yaw: 0.0383
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 102.4583
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 1.09s
                        Total time: 110.30s
                               ETA: 3233.2s

################################################################################
                      [1m Learning iteration 99/3000 [0m                      

                       Computation: 90277 steps/s (collection: 0.964s, learning 0.125s)
               Value function loss: 0.1284
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6420
                     Learning rate: 0.0013
                       Mean reward: -1.53
               Mean episode length: 39.38
       Episode_Reward/keep_balance: 0.0397
     Episode_Reward/rew_lin_vel_xy: 0.0376
      Episode_Reward/rew_ang_vel_z: 0.1164
    Episode_Reward/pen_base_height: -0.1030
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0031
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0591
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0398
Metrics/base_velocity/error_vel_xy: 0.2062
Metrics/base_velocity/error_vel_yaw: 0.0383
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 104.7083
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 1.09s
                        Total time: 111.39s
                               ETA: 3231.3s

################################################################################
                     [1m Learning iteration 100/3000 [0m                      

                       Computation: 90838 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.1708
                    Surrogate loss: -0.0006
             Mean action noise std: 0.6399
                     Learning rate: 0.0029
                       Mean reward: -1.21
               Mean episode length: 41.43
       Episode_Reward/keep_balance: 0.0394
     Episode_Reward/rew_lin_vel_xy: 0.0358
      Episode_Reward/rew_ang_vel_z: 0.1160
    Episode_Reward/pen_base_height: -0.1023
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0030
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0582
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0393
Metrics/base_velocity/error_vel_xy: 0.2070
Metrics/base_velocity/error_vel_yaw: 0.0372
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 102.5000
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 1.08s
                        Total time: 112.47s
                               ETA: 3229.3s

################################################################################
                     [1m Learning iteration 101/3000 [0m                      

                       Computation: 89318 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.1738
                    Surrogate loss: 0.0037
             Mean action noise std: 0.6394
                     Learning rate: 0.0006
                       Mean reward: -1.26
               Mean episode length: 38.03
       Episode_Reward/keep_balance: 0.0400
     Episode_Reward/rew_lin_vel_xy: 0.0390
      Episode_Reward/rew_ang_vel_z: 0.1182
    Episode_Reward/pen_base_height: -0.1032
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0031
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0017
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0596
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0401
Metrics/base_velocity/error_vel_xy: 0.2065
Metrics/base_velocity/error_vel_yaw: 0.0376
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 102.4167
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 1.10s
                        Total time: 113.57s
                               ETA: 3227.8s

################################################################################
                     [1m Learning iteration 102/3000 [0m                      

                       Computation: 89747 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.1347
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6380
                     Learning rate: 0.0006
                       Mean reward: -1.25
               Mean episode length: 40.51
       Episode_Reward/keep_balance: 0.0398
     Episode_Reward/rew_lin_vel_xy: 0.0367
      Episode_Reward/rew_ang_vel_z: 0.1170
    Episode_Reward/pen_base_height: -0.1031
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0031
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0034
Episode_Reward/pen_flat_orientation: -0.0584
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0396
Metrics/base_velocity/error_vel_xy: 0.2077
Metrics/base_velocity/error_vel_yaw: 0.0378
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 101.0417
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 1.10s
                        Total time: 114.67s
                               ETA: 3226.2s

################################################################################
                     [1m Learning iteration 103/3000 [0m                      

                       Computation: 92310 steps/s (collection: 0.945s, learning 0.120s)
               Value function loss: 0.1355
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6362
                     Learning rate: 0.0009
                       Mean reward: -1.24
               Mean episode length: 38.88
       Episode_Reward/keep_balance: 0.0404
     Episode_Reward/rew_lin_vel_xy: 0.0386
      Episode_Reward/rew_ang_vel_z: 0.1195
    Episode_Reward/pen_base_height: -0.1037
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0032
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0591
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0064
   Episode_Reward/test_gait_reward: -0.0403
Metrics/base_velocity/error_vel_xy: 0.2101
Metrics/base_velocity/error_vel_yaw: 0.0382
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 101.4583
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 1.06s
                        Total time: 115.73s
                               ETA: 3223.7s

################################################################################
                     [1m Learning iteration 104/3000 [0m                      

                       Computation: 92288 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.1364
                    Surrogate loss: -0.0003
             Mean action noise std: 0.6334
                     Learning rate: 0.0006
                       Mean reward: -1.07
               Mean episode length: 41.27
       Episode_Reward/keep_balance: 0.0407
     Episode_Reward/rew_lin_vel_xy: 0.0371
      Episode_Reward/rew_ang_vel_z: 0.1209
    Episode_Reward/pen_base_height: -0.1043
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0196
   Episode_Reward/pen_joint_torque: -0.0032
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0594
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0408
Metrics/base_velocity/error_vel_xy: 0.2126
Metrics/base_velocity/error_vel_yaw: 0.0382
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 100.3333
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 1.07s
                        Total time: 116.80s
                               ETA: 3221.3s

################################################################################
                     [1m Learning iteration 105/3000 [0m                      

                       Computation: 91122 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.1430
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6315
                     Learning rate: 0.0006
                       Mean reward: -1.09
               Mean episode length: 41.87
       Episode_Reward/keep_balance: 0.0410
     Episode_Reward/rew_lin_vel_xy: 0.0414
      Episode_Reward/rew_ang_vel_z: 0.1211
    Episode_Reward/pen_base_height: -0.1043
      Episode_Reward/pen_lin_vel_z: -0.0101
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0033
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0593
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0411
Metrics/base_velocity/error_vel_xy: 0.2092
Metrics/base_velocity/error_vel_yaw: 0.0384
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 98.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 1.08s
                        Total time: 117.87s
                               ETA: 3219.3s

################################################################################
                     [1m Learning iteration 106/3000 [0m                      

                       Computation: 90262 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.1469
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6294
                     Learning rate: 0.0013
                       Mean reward: -1.14
               Mean episode length: 43.07
       Episode_Reward/keep_balance: 0.0411
     Episode_Reward/rew_lin_vel_xy: 0.0383
      Episode_Reward/rew_ang_vel_z: 0.1221
    Episode_Reward/pen_base_height: -0.1043
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0034
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0018
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0589
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0410
Metrics/base_velocity/error_vel_xy: 0.2125
Metrics/base_velocity/error_vel_yaw: 0.0384
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 99.6667
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 1.09s
                        Total time: 118.96s
                               ETA: 3217.6s

################################################################################
                     [1m Learning iteration 107/3000 [0m                      

                       Computation: 91986 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.1454
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6280
                     Learning rate: 0.0019
                       Mean reward: -1.08
               Mean episode length: 41.70
       Episode_Reward/keep_balance: 0.0416
     Episode_Reward/rew_lin_vel_xy: 0.0404
      Episode_Reward/rew_ang_vel_z: 0.1233
    Episode_Reward/pen_base_height: -0.1050
      Episode_Reward/pen_lin_vel_z: -0.0102
     Episode_Reward/pen_ang_vel_xy: -0.0193
   Episode_Reward/pen_joint_torque: -0.0034
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0592
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0039
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0415
Metrics/base_velocity/error_vel_xy: 0.2140
Metrics/base_velocity/error_vel_yaw: 0.0393
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 96.5000
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 1.07s
                        Total time: 120.03s
                               ETA: 3215.3s

################################################################################
                     [1m Learning iteration 108/3000 [0m                      

                       Computation: 91178 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.1732
                    Surrogate loss: 0.0032
             Mean action noise std: 0.6274
                     Learning rate: 0.0006
                       Mean reward: -1.22
               Mean episode length: 43.71
       Episode_Reward/keep_balance: 0.0423
     Episode_Reward/rew_lin_vel_xy: 0.0428
      Episode_Reward/rew_ang_vel_z: 0.1254
    Episode_Reward/pen_base_height: -0.1062
      Episode_Reward/pen_lin_vel_z: -0.0103
     Episode_Reward/pen_ang_vel_xy: -0.0193
   Episode_Reward/pen_joint_torque: -0.0036
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0601
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0425
Metrics/base_velocity/error_vel_xy: 0.2145
Metrics/base_velocity/error_vel_yaw: 0.0401
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 97.2500
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 1.08s
                        Total time: 121.11s
                               ETA: 3213.3s

################################################################################
                     [1m Learning iteration 109/3000 [0m                      

                       Computation: 90753 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.1858
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6270
                     Learning rate: 0.0013
                       Mean reward: -1.09
               Mean episode length: 43.18
       Episode_Reward/keep_balance: 0.0424
     Episode_Reward/rew_lin_vel_xy: 0.0399
      Episode_Reward/rew_ang_vel_z: 0.1252
    Episode_Reward/pen_base_height: -0.1058
      Episode_Reward/pen_lin_vel_z: -0.0104
     Episode_Reward/pen_ang_vel_xy: -0.0196
   Episode_Reward/pen_joint_torque: -0.0036
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0596
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0425
Metrics/base_velocity/error_vel_xy: 0.2208
Metrics/base_velocity/error_vel_yaw: 0.0408
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 95.5833
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 1.08s
                        Total time: 122.19s
                               ETA: 3211.5s

################################################################################
                     [1m Learning iteration 110/3000 [0m                      

                       Computation: 91100 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.1424
                    Surrogate loss: 0.0044
             Mean action noise std: 0.6265
                     Learning rate: 0.0003
                       Mean reward: -1.39
               Mean episode length: 42.32
       Episode_Reward/keep_balance: 0.0427
     Episode_Reward/rew_lin_vel_xy: 0.0403
      Episode_Reward/rew_ang_vel_z: 0.1270
    Episode_Reward/pen_base_height: -0.1057
      Episode_Reward/pen_lin_vel_z: -0.0105
     Episode_Reward/pen_ang_vel_xy: -0.0195
   Episode_Reward/pen_joint_torque: -0.0037
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0019
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0591
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0429
Metrics/base_velocity/error_vel_xy: 0.2200
Metrics/base_velocity/error_vel_yaw: 0.0403
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 95.7500
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 1.08s
                        Total time: 123.27s
                               ETA: 3209.5s

################################################################################
                     [1m Learning iteration 111/3000 [0m                      

                       Computation: 91607 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.1409
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6256
                     Learning rate: 0.0006
                       Mean reward: -1.20
               Mean episode length: 43.09
       Episode_Reward/keep_balance: 0.0426
     Episode_Reward/rew_lin_vel_xy: 0.0397
      Episode_Reward/rew_ang_vel_z: 0.1263
    Episode_Reward/pen_base_height: -0.1050
      Episode_Reward/pen_lin_vel_z: -0.0105
     Episode_Reward/pen_ang_vel_xy: -0.0197
   Episode_Reward/pen_joint_torque: -0.0037
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0014
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0035
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0040
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0425
Metrics/base_velocity/error_vel_xy: 0.2212
Metrics/base_velocity/error_vel_yaw: 0.0402
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 95.1667
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 1.07s
                        Total time: 124.35s
                               ETA: 3207.4s

################################################################################
                     [1m Learning iteration 112/3000 [0m                      

                       Computation: 90379 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.1549
                    Surrogate loss: 0.0018
             Mean action noise std: 0.6249
                     Learning rate: 0.0003
                       Mean reward: -1.01
               Mean episode length: 42.05
       Episode_Reward/keep_balance: 0.0429
     Episode_Reward/rew_lin_vel_xy: 0.0405
      Episode_Reward/rew_ang_vel_z: 0.1278
    Episode_Reward/pen_base_height: -0.1050
      Episode_Reward/pen_lin_vel_z: -0.0105
     Episode_Reward/pen_ang_vel_xy: -0.0196
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0587
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0430
Metrics/base_velocity/error_vel_xy: 0.2222
Metrics/base_velocity/error_vel_yaw: 0.0400
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 93.1250
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 1.09s
                        Total time: 125.43s
                               ETA: 3205.8s

################################################################################
                     [1m Learning iteration 113/3000 [0m                      

                       Computation: 91273 steps/s (collection: 0.952s, learning 0.125s)
               Value function loss: 0.1485
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6238
                     Learning rate: 0.0009
                       Mean reward: -0.77
               Mean episode length: 43.47
       Episode_Reward/keep_balance: 0.0434
     Episode_Reward/rew_lin_vel_xy: 0.0415
      Episode_Reward/rew_ang_vel_z: 0.1288
    Episode_Reward/pen_base_height: -0.1059
      Episode_Reward/pen_lin_vel_z: -0.0106
     Episode_Reward/pen_ang_vel_xy: -0.0198
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0593
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0041
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0437
Metrics/base_velocity/error_vel_xy: 0.2243
Metrics/base_velocity/error_vel_yaw: 0.0410
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 94.4583
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 1.08s
                        Total time: 126.51s
                               ETA: 3203.8s

################################################################################
                     [1m Learning iteration 114/3000 [0m                      

                       Computation: 91502 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.1606
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6224
                     Learning rate: 0.0009
                       Mean reward: -1.13
               Mean episode length: 42.98
       Episode_Reward/keep_balance: 0.0437
     Episode_Reward/rew_lin_vel_xy: 0.0430
      Episode_Reward/rew_ang_vel_z: 0.1296
    Episode_Reward/pen_base_height: -0.1056
      Episode_Reward/pen_lin_vel_z: -0.0106
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0589
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0065
   Episode_Reward/test_gait_reward: -0.0437
Metrics/base_velocity/error_vel_xy: 0.2264
Metrics/base_velocity/error_vel_yaw: 0.0413
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 95.2500
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 1.07s
                        Total time: 127.58s
                               ETA: 3201.8s

################################################################################
                     [1m Learning iteration 115/3000 [0m                      

                       Computation: 92054 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.1623
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6199
                     Learning rate: 0.0013
                       Mean reward: -1.04
               Mean episode length: 44.37
       Episode_Reward/keep_balance: 0.0433
     Episode_Reward/rew_lin_vel_xy: 0.0414
      Episode_Reward/rew_ang_vel_z: 0.1295
    Episode_Reward/pen_base_height: -0.1046
      Episode_Reward/pen_lin_vel_z: -0.0106
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0577
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0437
Metrics/base_velocity/error_vel_xy: 0.2257
Metrics/base_velocity/error_vel_yaw: 0.0396
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 93.7917
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 1.07s
                        Total time: 128.65s
                               ETA: 3199.7s

################################################################################
                     [1m Learning iteration 116/3000 [0m                      

                       Computation: 91215 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.1700
                    Surrogate loss: 0.0014
             Mean action noise std: 0.6184
                     Learning rate: 0.0009
                       Mean reward: -1.10
               Mean episode length: 45.54
       Episode_Reward/keep_balance: 0.0433
     Episode_Reward/rew_lin_vel_xy: 0.0426
      Episode_Reward/rew_ang_vel_z: 0.1287
    Episode_Reward/pen_base_height: -0.1056
      Episode_Reward/pen_lin_vel_z: -0.0107
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0038
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0435
Metrics/base_velocity/error_vel_xy: 0.2235
Metrics/base_velocity/error_vel_yaw: 0.0405
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 94.5417
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 1.08s
                        Total time: 129.73s
                               ETA: 3197.8s

################################################################################
                     [1m Learning iteration 117/3000 [0m                      

                       Computation: 90856 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.1776
                    Surrogate loss: 0.0013
             Mean action noise std: 0.6181
                     Learning rate: 0.0013
                       Mean reward: -0.98
               Mean episode length: 43.51
       Episode_Reward/keep_balance: 0.0440
     Episode_Reward/rew_lin_vel_xy: 0.0454
      Episode_Reward/rew_ang_vel_z: 0.1311
    Episode_Reward/pen_base_height: -0.1062
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0020
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0036
Episode_Reward/pen_flat_orientation: -0.0582
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0443
Metrics/base_velocity/error_vel_xy: 0.2220
Metrics/base_velocity/error_vel_yaw: 0.0413
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 1.08s
                        Total time: 130.81s
                               ETA: 3196.0s

################################################################################
                     [1m Learning iteration 118/3000 [0m                      

                       Computation: 91534 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 0.2201
                    Surrogate loss: 0.0047
             Mean action noise std: 0.6180
                     Learning rate: 0.0003
                       Mean reward: -0.94
               Mean episode length: 46.05
       Episode_Reward/keep_balance: 0.0447
     Episode_Reward/rew_lin_vel_xy: 0.0437
      Episode_Reward/rew_ang_vel_z: 0.1334
    Episode_Reward/pen_base_height: -0.1067
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0594
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0450
Metrics/base_velocity/error_vel_xy: 0.2301
Metrics/base_velocity/error_vel_yaw: 0.0412
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 93.1250
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 1.07s
                        Total time: 131.89s
                               ETA: 3194.1s

################################################################################
                     [1m Learning iteration 119/3000 [0m                      

                       Computation: 91157 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.1714
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6172
                     Learning rate: 0.0006
                       Mean reward: -0.94
               Mean episode length: 45.49
       Episode_Reward/keep_balance: 0.0446
     Episode_Reward/rew_lin_vel_xy: 0.0447
      Episode_Reward/rew_ang_vel_z: 0.1332
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0591
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0445
Metrics/base_velocity/error_vel_xy: 0.2258
Metrics/base_velocity/error_vel_yaw: 0.0414
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 1.08s
                        Total time: 132.96s
                               ETA: 3192.3s

################################################################################
                     [1m Learning iteration 120/3000 [0m                      

                       Computation: 91940 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 0.1759
                    Surrogate loss: 0.0014
             Mean action noise std: 0.6165
                     Learning rate: 0.0006
                       Mean reward: -1.06
               Mean episode length: 44.56
       Episode_Reward/keep_balance: 0.0443
     Episode_Reward/rew_lin_vel_xy: 0.0424
      Episode_Reward/rew_ang_vel_z: 0.1321
    Episode_Reward/pen_base_height: -0.1062
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0201
   Episode_Reward/pen_joint_torque: -0.0040
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0445
Metrics/base_velocity/error_vel_xy: 0.2276
Metrics/base_velocity/error_vel_yaw: 0.0410
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 1.07s
                        Total time: 134.03s
                               ETA: 3190.2s

################################################################################
                     [1m Learning iteration 121/3000 [0m                      

                       Computation: 92436 steps/s (collection: 0.942s, learning 0.121s)
               Value function loss: 0.1680
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6150
                     Learning rate: 0.0009
                       Mean reward: -1.02
               Mean episode length: 44.05
       Episode_Reward/keep_balance: 0.0450
     Episode_Reward/rew_lin_vel_xy: 0.0441
      Episode_Reward/rew_ang_vel_z: 0.1338
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0041
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0597
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0453
Metrics/base_velocity/error_vel_xy: 0.2330
Metrics/base_velocity/error_vel_yaw: 0.0420
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.9583
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 1.06s
                        Total time: 135.10s
                               ETA: 3188.1s

################################################################################
                     [1m Learning iteration 122/3000 [0m                      

                       Computation: 92025 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 0.1876
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6145
                     Learning rate: 0.0013
                       Mean reward: -1.28
               Mean episode length: 42.86
       Episode_Reward/keep_balance: 0.0451
     Episode_Reward/rew_lin_vel_xy: 0.0452
      Episode_Reward/rew_ang_vel_z: 0.1340
    Episode_Reward/pen_base_height: -0.1067
      Episode_Reward/pen_lin_vel_z: -0.0107
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0041
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0595
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0455
Metrics/base_velocity/error_vel_xy: 0.2291
Metrics/base_velocity/error_vel_yaw: 0.0422
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.7917
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 1.07s
                        Total time: 136.17s
                               ETA: 3186.0s

################################################################################
                     [1m Learning iteration 123/3000 [0m                      

                       Computation: 87497 steps/s (collection: 1.002s, learning 0.121s)
               Value function loss: 0.2055
                    Surrogate loss: 0.0012
             Mean action noise std: 0.6149
                     Learning rate: 0.0009
                       Mean reward: -0.76
               Mean episode length: 46.53
       Episode_Reward/keep_balance: 0.0455
     Episode_Reward/rew_lin_vel_xy: 0.0458
      Episode_Reward/rew_ang_vel_z: 0.1358
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0107
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0593
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0460
Metrics/base_velocity/error_vel_xy: 0.2344
Metrics/base_velocity/error_vel_yaw: 0.0421
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 92.5417
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 1.12s
                        Total time: 137.29s
                               ETA: 3185.3s

################################################################################
                     [1m Learning iteration 124/3000 [0m                      

                       Computation: 93285 steps/s (collection: 0.933s, learning 0.121s)
               Value function loss: 0.1978
                    Surrogate loss: 0.0017
             Mean action noise std: 0.6150
                     Learning rate: 0.0006
                       Mean reward: -1.18
               Mean episode length: 43.39
       Episode_Reward/keep_balance: 0.0448
     Episode_Reward/rew_lin_vel_xy: 0.0436
      Episode_Reward/rew_ang_vel_z: 0.1335
    Episode_Reward/pen_base_height: -0.1065
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0582
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0042
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0453
Metrics/base_velocity/error_vel_xy: 0.2321
Metrics/base_velocity/error_vel_yaw: 0.0415
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 89.2083
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 1.05s
                        Total time: 138.34s
                               ETA: 3183.0s

################################################################################
                     [1m Learning iteration 125/3000 [0m                      

                       Computation: 90479 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.1741
                    Surrogate loss: -0.0007
             Mean action noise std: 0.6147
                     Learning rate: 0.0006
                       Mean reward: -0.69
               Mean episode length: 47.68
       Episode_Reward/keep_balance: 0.0455
     Episode_Reward/rew_lin_vel_xy: 0.0466
      Episode_Reward/rew_ang_vel_z: 0.1352
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0108
     Episode_Reward/pen_ang_vel_xy: -0.0201
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0587
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0043
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0457
Metrics/base_velocity/error_vel_xy: 0.2317
Metrics/base_velocity/error_vel_yaw: 0.0426
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.1667
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 1.09s
                        Total time: 139.43s
                               ETA: 3181.4s

################################################################################
                     [1m Learning iteration 126/3000 [0m                      

                       Computation: 91805 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.1704
                    Surrogate loss: 0.0002
             Mean action noise std: 0.6141
                     Learning rate: 0.0009
                       Mean reward: -0.85
               Mean episode length: 45.16
       Episode_Reward/keep_balance: 0.0459
     Episode_Reward/rew_lin_vel_xy: 0.0480
      Episode_Reward/rew_ang_vel_z: 0.1367
    Episode_Reward/pen_base_height: -0.1065
      Episode_Reward/pen_lin_vel_z: -0.0110
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0578
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0043
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2322
Metrics/base_velocity/error_vel_yaw: 0.0420
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 93.2083
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 1.07s
                        Total time: 140.50s
                               ETA: 3179.5s

################################################################################
                     [1m Learning iteration 127/3000 [0m                      

                       Computation: 91349 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.1698
                    Surrogate loss: -0.0001
             Mean action noise std: 0.6127
                     Learning rate: 0.0009
                       Mean reward: -0.76
               Mean episode length: 44.34
       Episode_Reward/keep_balance: 0.0451
     Episode_Reward/rew_lin_vel_xy: 0.0428
      Episode_Reward/rew_ang_vel_z: 0.1338
    Episode_Reward/pen_base_height: -0.1060
      Episode_Reward/pen_lin_vel_z: -0.0110
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0575
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0066
   Episode_Reward/test_gait_reward: -0.0456
Metrics/base_velocity/error_vel_xy: 0.2344
Metrics/base_velocity/error_vel_yaw: 0.0421
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 1.08s
                        Total time: 141.58s
                               ETA: 3177.7s

################################################################################
                     [1m Learning iteration 128/3000 [0m                      

                       Computation: 91014 steps/s (collection: 0.956s, learning 0.125s)
               Value function loss: 0.1713
                    Surrogate loss: 0.0004
             Mean action noise std: 0.6119
                     Learning rate: 0.0004
                       Mean reward: -1.02
               Mean episode length: 47.09
       Episode_Reward/keep_balance: 0.0459
     Episode_Reward/rew_lin_vel_xy: 0.0430
      Episode_Reward/rew_ang_vel_z: 0.1365
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0109
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0585
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0465
Metrics/base_velocity/error_vel_xy: 0.2346
Metrics/base_velocity/error_vel_yaw: 0.0422
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.5000
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 1.08s
                        Total time: 142.66s
                               ETA: 3176.0s

################################################################################
                     [1m Learning iteration 129/3000 [0m                      

                       Computation: 92757 steps/s (collection: 0.936s, learning 0.124s)
               Value function loss: 0.1511
                    Surrogate loss: 0.0054
             Mean action noise std: 0.6120
                     Learning rate: 0.0002
                       Mean reward: -0.89
               Mean episode length: 47.27
       Episode_Reward/keep_balance: 0.0458
     Episode_Reward/rew_lin_vel_xy: 0.0452
      Episode_Reward/rew_ang_vel_z: 0.1362
    Episode_Reward/pen_base_height: -0.1062
      Episode_Reward/pen_lin_vel_z: -0.0110
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0584
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0463
Metrics/base_velocity/error_vel_xy: 0.2367
Metrics/base_velocity/error_vel_yaw: 0.0420
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.1667
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 1.06s
                        Total time: 143.72s
                               ETA: 3173.9s

################################################################################
                     [1m Learning iteration 130/3000 [0m                      

                       Computation: 91397 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.1542
                    Surrogate loss: 0.0003
             Mean action noise std: 0.6115
                     Learning rate: 0.0004
                       Mean reward: -1.13
               Mean episode length: 45.15
       Episode_Reward/keep_balance: 0.0464
     Episode_Reward/rew_lin_vel_xy: 0.0438
      Episode_Reward/rew_ang_vel_z: 0.1378
    Episode_Reward/pen_base_height: -0.1063
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0580
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2383
Metrics/base_velocity/error_vel_yaw: 0.0427
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 91.1250
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 1.08s
                        Total time: 144.79s
                               ETA: 3172.1s

################################################################################
                     [1m Learning iteration 131/3000 [0m                      

                       Computation: 91837 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.1540
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6097
                     Learning rate: 0.0009
                       Mean reward: -0.77
               Mean episode length: 43.99
       Episode_Reward/keep_balance: 0.0457
     Episode_Reward/rew_lin_vel_xy: 0.0451
      Episode_Reward/rew_ang_vel_z: 0.1354
    Episode_Reward/pen_base_height: -0.1062
      Episode_Reward/pen_lin_vel_z: -0.0112
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0462
Metrics/base_velocity/error_vel_xy: 0.2341
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 91.3333
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 1.07s
                        Total time: 145.86s
                               ETA: 3170.3s

################################################################################
                     [1m Learning iteration 132/3000 [0m                      

                       Computation: 92488 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 0.1828
                    Surrogate loss: 0.0014
             Mean action noise std: 0.6090
                     Learning rate: 0.0013
                       Mean reward: -0.93
               Mean episode length: 46.29
       Episode_Reward/keep_balance: 0.0450
     Episode_Reward/rew_lin_vel_xy: 0.0428
      Episode_Reward/rew_ang_vel_z: 0.1341
    Episode_Reward/pen_base_height: -0.1054
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0576
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0455
Metrics/base_velocity/error_vel_xy: 0.2324
Metrics/base_velocity/error_vel_yaw: 0.0408
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 1.06s
                        Total time: 146.92s
                               ETA: 3168.3s

################################################################################
                     [1m Learning iteration 133/3000 [0m                      

                       Computation: 92349 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.1663
                    Surrogate loss: 0.0021
             Mean action noise std: 0.6089
                     Learning rate: 0.0006
                       Mean reward: -0.77
               Mean episode length: 46.91
       Episode_Reward/keep_balance: 0.0450
     Episode_Reward/rew_lin_vel_xy: 0.0444
      Episode_Reward/rew_ang_vel_z: 0.1343
    Episode_Reward/pen_base_height: -0.1046
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0041
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0576
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0455
Metrics/base_velocity/error_vel_xy: 0.2310
Metrics/base_velocity/error_vel_yaw: 0.0408
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.7500
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 1.06s
                        Total time: 147.99s
                               ETA: 3166.3s

################################################################################
                     [1m Learning iteration 134/3000 [0m                      

                       Computation: 93200 steps/s (collection: 0.932s, learning 0.123s)
               Value function loss: 0.1623
                    Surrogate loss: 0.0058
             Mean action noise std: 0.6084
                     Learning rate: 0.0003
                       Mean reward: -1.07
               Mean episode length: 45.42
       Episode_Reward/keep_balance: 0.0459
     Episode_Reward/rew_lin_vel_xy: 0.0467
      Episode_Reward/rew_ang_vel_z: 0.1368
    Episode_Reward/pen_base_height: -0.1060
      Episode_Reward/pen_lin_vel_z: -0.0112
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0592
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0463
Metrics/base_velocity/error_vel_xy: 0.2342
Metrics/base_velocity/error_vel_yaw: 0.0421
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.5417
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 1.05s
                        Total time: 149.04s
                               ETA: 3164.1s

################################################################################
                     [1m Learning iteration 135/3000 [0m                      

                       Computation: 92556 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 0.1574
                    Surrogate loss: 0.0038
             Mean action noise std: 0.6078
                     Learning rate: 0.0006
                       Mean reward: -0.88
               Mean episode length: 46.08
       Episode_Reward/keep_balance: 0.0457
     Episode_Reward/rew_lin_vel_xy: 0.0469
      Episode_Reward/rew_ang_vel_z: 0.1363
    Episode_Reward/pen_base_height: -0.1056
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0015
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0579
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0461
Metrics/base_velocity/error_vel_xy: 0.2307
Metrics/base_velocity/error_vel_yaw: 0.0419
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 1.06s
                        Total time: 150.11s
                               ETA: 3162.2s

################################################################################
                     [1m Learning iteration 136/3000 [0m                      

                       Computation: 92503 steps/s (collection: 0.939s, learning 0.124s)
               Value function loss: 0.1511
                    Surrogate loss: 0.0089
             Mean action noise std: 0.6075
                     Learning rate: 0.0001
                       Mean reward: -0.79
               Mean episode length: 46.54
       Episode_Reward/keep_balance: 0.0457
     Episode_Reward/rew_lin_vel_xy: 0.0455
      Episode_Reward/rew_ang_vel_z: 0.1369
    Episode_Reward/pen_base_height: -0.1059
      Episode_Reward/pen_lin_vel_z: -0.0111
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0576
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0461
Metrics/base_velocity/error_vel_xy: 0.2349
Metrics/base_velocity/error_vel_yaw: 0.0412
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 89.1667
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 1.06s
                        Total time: 151.17s
                               ETA: 3160.2s

################################################################################
                     [1m Learning iteration 137/3000 [0m                      

                       Computation: 93018 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 0.1461
                    Surrogate loss: 0.0038
             Mean action noise std: 0.6070
                     Learning rate: 0.0001
                       Mean reward: -0.98
               Mean episode length: 47.20
       Episode_Reward/keep_balance: 0.0458
     Episode_Reward/rew_lin_vel_xy: 0.0446
      Episode_Reward/rew_ang_vel_z: 0.1369
    Episode_Reward/pen_base_height: -0.1059
      Episode_Reward/pen_lin_vel_z: -0.0112
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0579
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2366
Metrics/base_velocity/error_vel_yaw: 0.0414
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 91.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 1.06s
                        Total time: 152.23s
                               ETA: 3158.1s

################################################################################
                     [1m Learning iteration 138/3000 [0m                      

                       Computation: 92661 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 0.1527
                    Surrogate loss: 0.0036
             Mean action noise std: 0.6066
                     Learning rate: 0.0001
                       Mean reward: -0.65
               Mean episode length: 45.17
       Episode_Reward/keep_balance: 0.0456
     Episode_Reward/rew_lin_vel_xy: 0.0452
      Episode_Reward/rew_ang_vel_z: 0.1359
    Episode_Reward/pen_base_height: -0.1052
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0044
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0461
Metrics/base_velocity/error_vel_xy: 0.2339
Metrics/base_velocity/error_vel_yaw: 0.0418
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 89.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 1.06s
                        Total time: 153.29s
                               ETA: 3156.2s

################################################################################
                     [1m Learning iteration 139/3000 [0m                      

                       Computation: 91683 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.1509
                    Surrogate loss: 0.0021
             Mean action noise std: 0.6060
                     Learning rate: 0.0003
                       Mean reward: -1.00
               Mean episode length: 45.01
       Episode_Reward/keep_balance: 0.0457
     Episode_Reward/rew_lin_vel_xy: 0.0451
      Episode_Reward/rew_ang_vel_z: 0.1362
    Episode_Reward/pen_base_height: -0.1053
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0042
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0460
Metrics/base_velocity/error_vel_xy: 0.2390
Metrics/base_velocity/error_vel_yaw: 0.0417
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.9167
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 1.07s
                        Total time: 154.36s
                               ETA: 3154.4s

################################################################################
                     [1m Learning iteration 140/3000 [0m                      

                       Computation: 91489 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.1602
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6049
                     Learning rate: 0.0004
                       Mean reward: -0.57
               Mean episode length: 47.24
       Episode_Reward/keep_balance: 0.0462
     Episode_Reward/rew_lin_vel_xy: 0.0469
      Episode_Reward/rew_ang_vel_z: 0.1374
    Episode_Reward/pen_base_height: -0.1051
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0571
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0465
Metrics/base_velocity/error_vel_xy: 0.2356
Metrics/base_velocity/error_vel_yaw: 0.0422
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 90.6250
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 1.07s
                        Total time: 155.43s
                               ETA: 3152.8s

################################################################################
                     [1m Learning iteration 141/3000 [0m                      

                       Computation: 93190 steps/s (collection: 0.931s, learning 0.123s)
               Value function loss: 0.1732
                    Surrogate loss: -0.0012
             Mean action noise std: 0.6035
                     Learning rate: 0.0013
                       Mean reward: -0.85
               Mean episode length: 44.31
       Episode_Reward/keep_balance: 0.0460
     Episode_Reward/rew_lin_vel_xy: 0.0464
      Episode_Reward/rew_ang_vel_z: 0.1369
    Episode_Reward/pen_base_height: -0.1049
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0021
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0574
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0463
Metrics/base_velocity/error_vel_xy: 0.2355
Metrics/base_velocity/error_vel_yaw: 0.0419
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.9167
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 1.05s
                        Total time: 156.49s
                               ETA: 3150.7s

################################################################################
                     [1m Learning iteration 142/3000 [0m                      

                       Computation: 91266 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.1777
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6019
                     Learning rate: 0.0013
                       Mean reward: -0.96
               Mean episode length: 44.66
       Episode_Reward/keep_balance: 0.0462
     Episode_Reward/rew_lin_vel_xy: 0.0462
      Episode_Reward/rew_ang_vel_z: 0.1375
    Episode_Reward/pen_base_height: -0.1051
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2383
Metrics/base_velocity/error_vel_yaw: 0.0421
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 91.2500
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 1.08s
                        Total time: 157.57s
                               ETA: 3149.1s

################################################################################
                     [1m Learning iteration 143/3000 [0m                      

                       Computation: 92115 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 0.2070
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6004
                     Learning rate: 0.0019
                       Mean reward: -0.91
               Mean episode length: 45.90
       Episode_Reward/keep_balance: 0.0462
     Episode_Reward/rew_lin_vel_xy: 0.0480
      Episode_Reward/rew_ang_vel_z: 0.1379
    Episode_Reward/pen_base_height: -0.1049
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0043
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2371
Metrics/base_velocity/error_vel_yaw: 0.0420
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.7083
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 1.07s
                        Total time: 158.63s
                               ETA: 3147.3s

################################################################################
                     [1m Learning iteration 144/3000 [0m                      

                       Computation: 92237 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.1987
                    Surrogate loss: 0.0020
             Mean action noise std: 0.6001
                     Learning rate: 0.0009
                       Mean reward: -0.59
               Mean episode length: 47.25
       Episode_Reward/keep_balance: 0.0467
     Episode_Reward/rew_lin_vel_xy: 0.0491
      Episode_Reward/rew_ang_vel_z: 0.1393
    Episode_Reward/pen_base_height: -0.1055
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0583
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0067
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2365
Metrics/base_velocity/error_vel_yaw: 0.0426
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.5833
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 1.07s
                        Total time: 159.70s
                               ETA: 3145.5s

################################################################################
                     [1m Learning iteration 145/3000 [0m                      

                       Computation: 92898 steps/s (collection: 0.937s, learning 0.121s)
               Value function loss: 0.1747
                    Surrogate loss: 0.0001
             Mean action noise std: 0.5990
                     Learning rate: 0.0009
                       Mean reward: -0.98
               Mean episode length: 43.35
       Episode_Reward/keep_balance: 0.0462
     Episode_Reward/rew_lin_vel_xy: 0.0442
      Episode_Reward/rew_ang_vel_z: 0.1378
    Episode_Reward/pen_base_height: -0.1045
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0574
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2386
Metrics/base_velocity/error_vel_yaw: 0.0418
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 1.06s
                        Total time: 160.76s
                               ETA: 3143.6s

################################################################################
                     [1m Learning iteration 146/3000 [0m                      

                       Computation: 93309 steps/s (collection: 0.932s, learning 0.122s)
               Value function loss: 0.1995
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5967
                     Learning rate: 0.0019
                       Mean reward: -0.81
               Mean episode length: 47.30
       Episode_Reward/keep_balance: 0.0468
     Episode_Reward/rew_lin_vel_xy: 0.0462
      Episode_Reward/rew_ang_vel_z: 0.1400
    Episode_Reward/pen_base_height: -0.1051
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0575
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2391
Metrics/base_velocity/error_vel_yaw: 0.0422
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 1.05s
                        Total time: 161.81s
                               ETA: 3141.5s

################################################################################
                     [1m Learning iteration 147/3000 [0m                      

                       Computation: 93220 steps/s (collection: 0.933s, learning 0.121s)
               Value function loss: 0.2375
                    Surrogate loss: 0.0010
             Mean action noise std: 0.5961
                     Learning rate: 0.0013
                       Mean reward: -0.39
               Mean episode length: 48.29
       Episode_Reward/keep_balance: 0.0465
     Episode_Reward/rew_lin_vel_xy: 0.0458
      Episode_Reward/rew_ang_vel_z: 0.1389
    Episode_Reward/pen_base_height: -0.1047
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0044
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0569
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0045
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2391
Metrics/base_velocity/error_vel_yaw: 0.0420
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 88.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 1.05s
                        Total time: 162.86s
                               ETA: 3139.5s

################################################################################
                     [1m Learning iteration 148/3000 [0m                      

                       Computation: 92690 steps/s (collection: 0.937s, learning 0.123s)
               Value function loss: 0.1647
                    Surrogate loss: 0.0013
             Mean action noise std: 0.5957
                     Learning rate: 0.0009
                       Mean reward: -0.77
               Mean episode length: 45.75
       Episode_Reward/keep_balance: 0.0464
     Episode_Reward/rew_lin_vel_xy: 0.0462
      Episode_Reward/rew_ang_vel_z: 0.1388
    Episode_Reward/pen_base_height: -0.1057
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0574
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0462
Metrics/base_velocity/error_vel_xy: 0.2390
Metrics/base_velocity/error_vel_yaw: 0.0414
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.8333
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 1.06s
                        Total time: 163.92s
                               ETA: 3137.7s

################################################################################
                     [1m Learning iteration 149/3000 [0m                      

                       Computation: 92797 steps/s (collection: 0.937s, learning 0.122s)
               Value function loss: 0.2247
                    Surrogate loss: 0.0009
             Mean action noise std: 0.5952
                     Learning rate: 0.0009
                       Mean reward: -0.88
               Mean episode length: 47.32
       Episode_Reward/keep_balance: 0.0474
     Episode_Reward/rew_lin_vel_xy: 0.0489
      Episode_Reward/rew_ang_vel_z: 0.1422
    Episode_Reward/pen_base_height: -0.1058
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0046
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0575
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2419
Metrics/base_velocity/error_vel_yaw: 0.0423
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 1.06s
                        Total time: 164.98s
                               ETA: 3135.8s

################################################################################
                     [1m Learning iteration 150/3000 [0m                      

                       Computation: 93330 steps/s (collection: 0.931s, learning 0.122s)
               Value function loss: 0.1727
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5940
                     Learning rate: 0.0019
                       Mean reward: -0.98
               Mean episode length: 46.52
       Episode_Reward/keep_balance: 0.0471
     Episode_Reward/rew_lin_vel_xy: 0.0482
      Episode_Reward/rew_ang_vel_z: 0.1411
    Episode_Reward/pen_base_height: -0.1059
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0046
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0570
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2387
Metrics/base_velocity/error_vel_yaw: 0.0424
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.7083
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 1.05s
                        Total time: 166.04s
                               ETA: 3133.8s

################################################################################
                     [1m Learning iteration 151/3000 [0m                      

                       Computation: 92061 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.1793
                    Surrogate loss: 0.0039
             Mean action noise std: 0.5936
                     Learning rate: 0.0009
                       Mean reward: -0.48
               Mean episode length: 48.76
       Episode_Reward/keep_balance: 0.0474
     Episode_Reward/rew_lin_vel_xy: 0.0488
      Episode_Reward/rew_ang_vel_z: 0.1416
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0045
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0573
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2411
Metrics/base_velocity/error_vel_yaw: 0.0429
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 1.07s
                        Total time: 167.11s
                               ETA: 3132.1s

################################################################################
                     [1m Learning iteration 152/3000 [0m                      

                       Computation: 92102 steps/s (collection: 0.943s, learning 0.124s)
               Value function loss: 0.1441
                    Surrogate loss: 0.0018
             Mean action noise std: 0.5929
                     Learning rate: 0.0004
                       Mean reward: -0.80
               Mean episode length: 47.27
       Episode_Reward/keep_balance: 0.0471
     Episode_Reward/rew_lin_vel_xy: 0.0457
      Episode_Reward/rew_ang_vel_z: 0.1410
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0047
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0571
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0472
Metrics/base_velocity/error_vel_xy: 0.2434
Metrics/base_velocity/error_vel_yaw: 0.0423
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 1.07s
                        Total time: 168.17s
                               ETA: 3130.4s

################################################################################
                     [1m Learning iteration 153/3000 [0m                      

                       Computation: 92115 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 0.1487
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5915
                     Learning rate: 0.0009
                       Mean reward: -0.89
               Mean episode length: 46.00
       Episode_Reward/keep_balance: 0.0474
     Episode_Reward/rew_lin_vel_xy: 0.0479
      Episode_Reward/rew_ang_vel_z: 0.1419
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0046
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0577
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2440
Metrics/base_velocity/error_vel_yaw: 0.0426
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.7500
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 1.07s
                        Total time: 169.24s
                               ETA: 3128.7s

################################################################################
                     [1m Learning iteration 154/3000 [0m                      

                       Computation: 92328 steps/s (collection: 0.941s, learning 0.124s)
               Value function loss: 0.1576
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5897
                     Learning rate: 0.0013
                       Mean reward: -0.79
               Mean episode length: 46.31
       Episode_Reward/keep_balance: 0.0473
     Episode_Reward/rew_lin_vel_xy: 0.0482
      Episode_Reward/rew_ang_vel_z: 0.1423
    Episode_Reward/pen_base_height: -0.1061
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0047
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0022
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0565
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2408
Metrics/base_velocity/error_vel_yaw: 0.0418
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.8750
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 1.06s
                        Total time: 170.30s
                               ETA: 3127.0s

################################################################################
                     [1m Learning iteration 155/3000 [0m                      

                       Computation: 91982 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.2033
                    Surrogate loss: 0.0011
             Mean action noise std: 0.5895
                     Learning rate: 0.0013
                       Mean reward: -0.74
               Mean episode length: 49.13
       Episode_Reward/keep_balance: 0.0479
     Episode_Reward/rew_lin_vel_xy: 0.0484
      Episode_Reward/rew_ang_vel_z: 0.1437
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0048
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0570
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2458
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.6250
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 1.07s
                        Total time: 171.37s
                               ETA: 3125.4s

################################################################################
                     [1m Learning iteration 156/3000 [0m                      

                       Computation: 92084 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.2254
                    Surrogate loss: 0.0016
             Mean action noise std: 0.5891
                     Learning rate: 0.0013
                       Mean reward: -0.73
               Mean episode length: 47.66
       Episode_Reward/keep_balance: 0.0474
     Episode_Reward/rew_lin_vel_xy: 0.0479
      Episode_Reward/rew_ang_vel_z: 0.1428
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0048
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0568
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2396
Metrics/base_velocity/error_vel_yaw: 0.0419
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.8333
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 1.07s
                        Total time: 172.44s
                               ETA: 3123.7s

################################################################################
                     [1m Learning iteration 157/3000 [0m                      

                       Computation: 92183 steps/s (collection: 0.943s, learning 0.124s)
               Value function loss: 0.1900
                    Surrogate loss: 0.0045
             Mean action noise std: 0.5884
                     Learning rate: 0.0004
                       Mean reward: -0.69
               Mean episode length: 48.14
       Episode_Reward/keep_balance: 0.0477
     Episode_Reward/rew_lin_vel_xy: 0.0487
      Episode_Reward/rew_ang_vel_z: 0.1434
    Episode_Reward/pen_base_height: -0.1079
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0569
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2448
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.2917
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 1.07s
                        Total time: 173.51s
                               ETA: 3122.0s

################################################################################
                     [1m Learning iteration 158/3000 [0m                      

                       Computation: 92279 steps/s (collection: 0.941s, learning 0.125s)
               Value function loss: 0.1627
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5881
                     Learning rate: 0.0006
                       Mean reward: -0.67
               Mean episode length: 48.27
       Episode_Reward/keep_balance: 0.0482
     Episode_Reward/rew_lin_vel_xy: 0.0489
      Episode_Reward/rew_ang_vel_z: 0.1453
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0571
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0046
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2459
Metrics/base_velocity/error_vel_yaw: 0.0427
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.8750
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 1.07s
                        Total time: 174.57s
                               ETA: 3120.3s

################################################################################
                     [1m Learning iteration 159/3000 [0m                      

                       Computation: 90793 steps/s (collection: 0.957s, learning 0.126s)
               Value function loss: 0.1604
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5873
                     Learning rate: 0.0009
                       Mean reward: -0.88
               Mean episode length: 47.12
       Episode_Reward/keep_balance: 0.0483
     Episode_Reward/rew_lin_vel_xy: 0.0513
      Episode_Reward/rew_ang_vel_z: 0.1456
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0201
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0567
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2440
Metrics/base_velocity/error_vel_yaw: 0.0426
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 86.7917
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 1.08s
                        Total time: 175.66s
                               ETA: 3119.0s

################################################################################
                     [1m Learning iteration 160/3000 [0m                      

                       Computation: 92369 steps/s (collection: 0.940s, learning 0.124s)
               Value function loss: 0.1766
                    Surrogate loss: 0.0028
             Mean action noise std: 0.5866
                     Learning rate: 0.0004
                       Mean reward: -0.74
               Mean episode length: 47.55
       Episode_Reward/keep_balance: 0.0484
     Episode_Reward/rew_lin_vel_xy: 0.0506
      Episode_Reward/rew_ang_vel_z: 0.1458
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0201
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0561
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0481
Metrics/base_velocity/error_vel_xy: 0.2466
Metrics/base_velocity/error_vel_yaw: 0.0429
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.3750
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 1.06s
                        Total time: 176.72s
                               ETA: 3117.3s

################################################################################
                     [1m Learning iteration 161/3000 [0m                      

                       Computation: 91897 steps/s (collection: 0.944s, learning 0.126s)
               Value function loss: 0.1740
                    Surrogate loss: 0.0017
             Mean action noise std: 0.5865
                     Learning rate: 0.0004
                       Mean reward: -0.64
               Mean episode length: 49.65
       Episode_Reward/keep_balance: 0.0483
     Episode_Reward/rew_lin_vel_xy: 0.0491
      Episode_Reward/rew_ang_vel_z: 0.1461
    Episode_Reward/pen_base_height: -0.1083
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0562
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2470
Metrics/base_velocity/error_vel_yaw: 0.0421
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 1.07s
                        Total time: 177.79s
                               ETA: 3115.7s

################################################################################
                     [1m Learning iteration 162/3000 [0m                      

                       Computation: 92347 steps/s (collection: 0.941s, learning 0.124s)
               Value function loss: 0.1841
                    Surrogate loss: 0.0003
             Mean action noise std: 0.5864
                     Learning rate: 0.0009
                       Mean reward: -0.56
               Mean episode length: 48.04
       Episode_Reward/keep_balance: 0.0484
     Episode_Reward/rew_lin_vel_xy: 0.0506
      Episode_Reward/rew_ang_vel_z: 0.1455
    Episode_Reward/pen_base_height: -0.1082
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0567
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2461
Metrics/base_velocity/error_vel_yaw: 0.0429
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.4167
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 1.06s
                        Total time: 178.85s
                               ETA: 3114.0s

################################################################################
                     [1m Learning iteration 163/3000 [0m                      

                       Computation: 93006 steps/s (collection: 0.934s, learning 0.123s)
               Value function loss: 0.2149
                    Surrogate loss: -0.0011
             Mean action noise std: 0.5865
                     Learning rate: 0.0013
                       Mean reward: -0.19
               Mean episode length: 51.04
       Episode_Reward/keep_balance: 0.0485
     Episode_Reward/rew_lin_vel_xy: 0.0519
      Episode_Reward/rew_ang_vel_z: 0.1461
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0563
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0068
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2433
Metrics/base_velocity/error_vel_yaw: 0.0432
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.5833
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 1.06s
                        Total time: 179.91s
                               ETA: 3112.2s

################################################################################
                     [1m Learning iteration 164/3000 [0m                      

                       Computation: 90224 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.3121
                    Surrogate loss: -0.0002
             Mean action noise std: 0.5856
                     Learning rate: 0.0029
                       Mean reward: -0.55
               Mean episode length: 46.36
       Episode_Reward/keep_balance: 0.0480
     Episode_Reward/rew_lin_vel_xy: 0.0486
      Episode_Reward/rew_ang_vel_z: 0.1446
    Episode_Reward/pen_base_height: -0.1074
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0200
   Episode_Reward/pen_joint_torque: -0.0049
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0558
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2447
Metrics/base_velocity/error_vel_yaw: 0.0429
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 1.09s
                        Total time: 181.00s
                               ETA: 3111.0s

################################################################################
                     [1m Learning iteration 165/3000 [0m                      

                       Computation: 92732 steps/s (collection: 0.936s, learning 0.124s)
               Value function loss: 0.4729
                    Surrogate loss: 0.0024
             Mean action noise std: 0.5851
                     Learning rate: 0.0044
                       Mean reward: -0.60
               Mean episode length: 48.00
       Episode_Reward/keep_balance: 0.0485
     Episode_Reward/rew_lin_vel_xy: 0.0500
      Episode_Reward/rew_ang_vel_z: 0.1465
    Episode_Reward/pen_base_height: -0.1081
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0558
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2500
Metrics/base_velocity/error_vel_yaw: 0.0428
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.1667
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 1.06s
                        Total time: 182.06s
                               ETA: 3109.3s

################################################################################
                     [1m Learning iteration 166/3000 [0m                      

                       Computation: 90710 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.4212
                    Surrogate loss: 0.0051
             Mean action noise std: 0.5849
                     Learning rate: 0.0009
                       Mean reward: -0.62
               Mean episode length: 48.03
       Episode_Reward/keep_balance: 0.0485
     Episode_Reward/rew_lin_vel_xy: 0.0502
      Episode_Reward/rew_ang_vel_z: 0.1461
    Episode_Reward/pen_base_height: -0.1089
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0566
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2476
Metrics/base_velocity/error_vel_yaw: 0.0436
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.0000
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 1.08s
                        Total time: 183.14s
                               ETA: 3108.0s

################################################################################
                     [1m Learning iteration 167/3000 [0m                      

                       Computation: 90743 steps/s (collection: 0.959s, learning 0.125s)
               Value function loss: 0.2399
                    Surrogate loss: 0.0011
             Mean action noise std: 0.5852
                     Learning rate: 0.0009
                       Mean reward: -0.76
               Mean episode length: 47.07
       Episode_Reward/keep_balance: 0.0484
     Episode_Reward/rew_lin_vel_xy: 0.0469
      Episode_Reward/rew_ang_vel_z: 0.1460
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0561
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0047
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2530
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.4583
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 1.08s
                        Total time: 184.23s
                               ETA: 3106.6s

################################################################################
                     [1m Learning iteration 168/3000 [0m                      

                       Computation: 92328 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 0.2312
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5859
                     Learning rate: 0.0013
                       Mean reward: -0.56
               Mean episode length: 48.47
       Episode_Reward/keep_balance: 0.0485
     Episode_Reward/rew_lin_vel_xy: 0.0511
      Episode_Reward/rew_ang_vel_z: 0.1464
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0560
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2468
Metrics/base_velocity/error_vel_yaw: 0.0427
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.5417
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 1.06s
                        Total time: 185.29s
                               ETA: 3105.0s

################################################################################
                     [1m Learning iteration 169/3000 [0m                      

                       Computation: 93412 steps/s (collection: 0.930s, learning 0.122s)
               Value function loss: 0.2486
                    Surrogate loss: -0.0019
             Mean action noise std: 0.5858
                     Learning rate: 0.0019
                       Mean reward: -0.65
               Mean episode length: 48.38
       Episode_Reward/keep_balance: 0.0486
     Episode_Reward/rew_lin_vel_xy: 0.0487
      Episode_Reward/rew_ang_vel_z: 0.1469
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0202
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0561
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0482
Metrics/base_velocity/error_vel_xy: 0.2471
Metrics/base_velocity/error_vel_yaw: 0.0427
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.5833
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 1.05s
                        Total time: 186.34s
                               ETA: 3103.2s

################################################################################
                     [1m Learning iteration 170/3000 [0m                      

                       Computation: 93086 steps/s (collection: 0.933s, learning 0.123s)
               Value function loss: 0.3246
                    Surrogate loss: 0.0038
             Mean action noise std: 0.5865
                     Learning rate: 0.0013
                       Mean reward: -0.88
               Mean episode length: 46.11
       Episode_Reward/keep_balance: 0.0484
     Episode_Reward/rew_lin_vel_xy: 0.0494
      Episode_Reward/rew_ang_vel_z: 0.1468
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0553
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2494
Metrics/base_velocity/error_vel_yaw: 0.0424
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.4583
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 1.06s
                        Total time: 187.40s
                               ETA: 3101.4s

################################################################################
                     [1m Learning iteration 171/3000 [0m                      

                       Computation: 92926 steps/s (collection: 0.934s, learning 0.124s)
               Value function loss: 0.2307
                    Surrogate loss: 0.0133
             Mean action noise std: 0.5871
                     Learning rate: 0.0000
                       Mean reward: -0.58
               Mean episode length: 49.49
       Episode_Reward/keep_balance: 0.0493
     Episode_Reward/rew_lin_vel_xy: 0.0494
      Episode_Reward/rew_ang_vel_z: 0.1487
    Episode_Reward/pen_base_height: -0.1086
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0564
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0484
Metrics/base_velocity/error_vel_xy: 0.2547
Metrics/base_velocity/error_vel_yaw: 0.0439
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.4583
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 1.06s
                        Total time: 188.46s
                               ETA: 3099.7s

################################################################################
                     [1m Learning iteration 172/3000 [0m                      

                       Computation: 92708 steps/s (collection: 0.938s, learning 0.122s)
               Value function loss: 0.2035
                    Surrogate loss: 0.0033
             Mean action noise std: 0.5872
                     Learning rate: 0.0001
                       Mean reward: -0.45
               Mean episode length: 49.87
       Episode_Reward/keep_balance: 0.0488
     Episode_Reward/rew_lin_vel_xy: 0.0504
      Episode_Reward/rew_ang_vel_z: 0.1471
    Episode_Reward/pen_base_height: -0.1074
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0559
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0049
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2460
Metrics/base_velocity/error_vel_yaw: 0.0431
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 87.9167
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 1.06s
                        Total time: 189.52s
                               ETA: 3098.0s

################################################################################
                     [1m Learning iteration 173/3000 [0m                      

                       Computation: 93285 steps/s (collection: 0.931s, learning 0.122s)
               Value function loss: 0.2019
                    Surrogate loss: -0.0019
             Mean action noise std: 0.5872
                     Learning rate: 0.0009
                       Mean reward: -0.65
               Mean episode length: 48.33
       Episode_Reward/keep_balance: 0.0484
     Episode_Reward/rew_lin_vel_xy: 0.0521
      Episode_Reward/rew_ang_vel_z: 0.1462
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0554
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0049
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2428
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 1.05s
                        Total time: 190.57s
                               ETA: 3096.3s

################################################################################
                     [1m Learning iteration 174/3000 [0m                      

                       Computation: 92198 steps/s (collection: 0.943s, learning 0.123s)
               Value function loss: 0.2554
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5864
                     Learning rate: 0.0019
                       Mean reward: -0.75
               Mean episode length: 46.60
       Episode_Reward/keep_balance: 0.0478
     Episode_Reward/rew_lin_vel_xy: 0.0490
      Episode_Reward/rew_ang_vel_z: 0.1437
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0050
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0552
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2461
Metrics/base_velocity/error_vel_yaw: 0.0428
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 1.07s
                        Total time: 191.64s
                               ETA: 3094.7s

################################################################################
                     [1m Learning iteration 175/3000 [0m                      

                       Computation: 92377 steps/s (collection: 0.940s, learning 0.124s)
               Value function loss: 0.1765
                    Surrogate loss: 0.0037
             Mean action noise std: 0.5864
                     Learning rate: 0.0006
                       Mean reward: -0.74
               Mean episode length: 49.94
       Episode_Reward/keep_balance: 0.0487
     Episode_Reward/rew_lin_vel_xy: 0.0492
      Episode_Reward/rew_ang_vel_z: 0.1469
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0555
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0049
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0482
Metrics/base_velocity/error_vel_xy: 0.2484
Metrics/base_velocity/error_vel_yaw: 0.0432
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.5833
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 1.06s
                        Total time: 192.70s
                               ETA: 3093.1s

################################################################################
                     [1m Learning iteration 176/3000 [0m                      

                       Computation: 93343 steps/s (collection: 0.927s, learning 0.126s)
               Value function loss: 0.1820
                    Surrogate loss: -0.0016
             Mean action noise std: 0.5856
                     Learning rate: 0.0013
                       Mean reward: -0.73
               Mean episode length: 47.21
       Episode_Reward/keep_balance: 0.0481
     Episode_Reward/rew_lin_vel_xy: 0.0480
      Episode_Reward/rew_ang_vel_z: 0.1451
    Episode_Reward/pen_base_height: -0.1065
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0051
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0470
Metrics/base_velocity/error_vel_xy: 0.2468
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.1667
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 1.05s
                        Total time: 193.76s
                               ETA: 3091.3s

################################################################################
                     [1m Learning iteration 177/3000 [0m                      

                       Computation: 93372 steps/s (collection: 0.929s, learning 0.124s)
               Value function loss: 0.2585
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5844
                     Learning rate: 0.0029
                       Mean reward: -0.72
               Mean episode length: 49.26
       Episode_Reward/keep_balance: 0.0492
     Episode_Reward/rew_lin_vel_xy: 0.0512
      Episode_Reward/rew_ang_vel_z: 0.1489
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0201
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0560
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0048
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0481
Metrics/base_velocity/error_vel_xy: 0.2483
Metrics/base_velocity/error_vel_yaw: 0.0434
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.0833
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 1.05s
                        Total time: 194.81s
                               ETA: 3089.6s

################################################################################
                     [1m Learning iteration 178/3000 [0m                      

                       Computation: 92146 steps/s (collection: 0.943s, learning 0.124s)
               Value function loss: 0.3283
                    Surrogate loss: 0.0019
             Mean action noise std: 0.5844
                     Learning rate: 0.0019
                       Mean reward: -0.69
               Mean episode length: 47.43
       Episode_Reward/keep_balance: 0.0481
     Episode_Reward/rew_lin_vel_xy: 0.0500
      Episode_Reward/rew_ang_vel_z: 0.1455
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0199
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0023
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0556
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0049
   Episode_Reward/foot_landing_vel: -0.0069
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2402
Metrics/base_velocity/error_vel_yaw: 0.0423
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.3750
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 1.07s
                        Total time: 195.88s
                               ETA: 3088.0s

################################################################################
                     [1m Learning iteration 179/3000 [0m                      

                       Computation: 92881 steps/s (collection: 0.936s, learning 0.123s)
               Value function loss: 0.2350
                    Surrogate loss: 0.0051
             Mean action noise std: 0.5842
                     Learning rate: 0.0004
                       Mean reward: -0.39
               Mean episode length: 47.89
       Episode_Reward/keep_balance: 0.0489
     Episode_Reward/rew_lin_vel_xy: 0.0518
      Episode_Reward/rew_ang_vel_z: 0.1479
    Episode_Reward/pen_base_height: -0.1079
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0552
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2471
Metrics/base_velocity/error_vel_yaw: 0.0432
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.2083
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 1.06s
                        Total time: 196.93s
                               ETA: 3086.4s

################################################################################
                     [1m Learning iteration 180/3000 [0m                      

                       Computation: 93449 steps/s (collection: 0.930s, learning 0.122s)
               Value function loss: 0.1905
                    Surrogate loss: 0.0043
             Mean action noise std: 0.5839
                     Learning rate: 0.0003
                       Mean reward: -0.71
               Mean episode length: 50.69
       Episode_Reward/keep_balance: 0.0488
     Episode_Reward/rew_lin_vel_xy: 0.0472
      Episode_Reward/rew_ang_vel_z: 0.1470
    Episode_Reward/pen_base_height: -0.1083
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0560
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2522
Metrics/base_velocity/error_vel_yaw: 0.0435
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.0000
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 1.05s
                        Total time: 197.99s
                               ETA: 3084.6s

################################################################################
                     [1m Learning iteration 181/3000 [0m                      

                       Computation: 92674 steps/s (collection: 0.937s, learning 0.124s)
               Value function loss: 0.1765
                    Surrogate loss: 0.0043
             Mean action noise std: 0.5839
                     Learning rate: 0.0002
                       Mean reward: -0.43
               Mean episode length: 49.98
       Episode_Reward/keep_balance: 0.0495
     Episode_Reward/rew_lin_vel_xy: 0.0529
      Episode_Reward/rew_ang_vel_z: 0.1499
    Episode_Reward/pen_base_height: -0.1094
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0567
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0482
Metrics/base_velocity/error_vel_xy: 0.2488
Metrics/base_velocity/error_vel_yaw: 0.0439
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.0417
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 1.06s
                        Total time: 199.05s
                               ETA: 3083.0s

################################################################################
                     [1m Learning iteration 182/3000 [0m                      

                       Computation: 90782 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.1824
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5834
                     Learning rate: 0.0006
                       Mean reward: -0.41
               Mean episode length: 49.24
       Episode_Reward/keep_balance: 0.0490
     Episode_Reward/rew_lin_vel_xy: 0.0519
      Episode_Reward/rew_ang_vel_z: 0.1482
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0559
  Episode_Reward/pen_feet_distance: -0.0000
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2461
Metrics/base_velocity/error_vel_yaw: 0.0434
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 1.08s
                        Total time: 200.13s
                               ETA: 3081.8s

################################################################################
                     [1m Learning iteration 183/3000 [0m                      

                       Computation: 90922 steps/s (collection: 0.956s, learning 0.125s)
               Value function loss: 0.1931
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5825
                     Learning rate: 0.0013
                       Mean reward: -0.29
               Mean episode length: 50.60
       Episode_Reward/keep_balance: 0.0492
     Episode_Reward/rew_lin_vel_xy: 0.0513
      Episode_Reward/rew_ang_vel_z: 0.1486
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0551
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2500
Metrics/base_velocity/error_vel_yaw: 0.0431
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.0833
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 1.08s
                        Total time: 201.21s
                               ETA: 3080.5s

################################################################################
                     [1m Learning iteration 184/3000 [0m                      

                       Computation: 91828 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.2381
                    Surrogate loss: 0.0031
             Mean action noise std: 0.5818
                     Learning rate: 0.0006
                       Mean reward: -0.71
               Mean episode length: 50.98
       Episode_Reward/keep_balance: 0.0493
     Episode_Reward/rew_lin_vel_xy: 0.0498
      Episode_Reward/rew_ang_vel_z: 0.1493
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0552
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0050
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2543
Metrics/base_velocity/error_vel_yaw: 0.0429
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.0417
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 1.07s
                        Total time: 202.28s
                               ETA: 3079.0s

################################################################################
                     [1m Learning iteration 185/3000 [0m                      

                       Computation: 91407 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.1960
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5818
                     Learning rate: 0.0013
                       Mean reward: -0.64
               Mean episode length: 49.89
       Episode_Reward/keep_balance: 0.0494
     Episode_Reward/rew_lin_vel_xy: 0.0518
      Episode_Reward/rew_ang_vel_z: 0.1493
    Episode_Reward/pen_base_height: -0.1086
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0044
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0560
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0482
Metrics/base_velocity/error_vel_xy: 0.2501
Metrics/base_velocity/error_vel_yaw: 0.0436
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.5000
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 1.08s
                        Total time: 203.36s
                               ETA: 3077.7s

################################################################################
                     [1m Learning iteration 186/3000 [0m                      

                       Computation: 90811 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 0.1996
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5804
                     Learning rate: 0.0019
                       Mean reward: -0.32
               Mean episode length: 49.32
       Episode_Reward/keep_balance: 0.0494
     Episode_Reward/rew_lin_vel_xy: 0.0510
      Episode_Reward/rew_ang_vel_z: 0.1500
    Episode_Reward/pen_base_height: -0.1092
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0562
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0051
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2550
Metrics/base_velocity/error_vel_yaw: 0.0434
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.4167
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 1.08s
                        Total time: 204.44s
                               ETA: 3076.4s

################################################################################
                     [1m Learning iteration 187/3000 [0m                      

                       Computation: 91906 steps/s (collection: 0.944s, learning 0.126s)
               Value function loss: 0.2439
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5792
                     Learning rate: 0.0029
                       Mean reward: -0.18
               Mean episode length: 51.49
       Episode_Reward/keep_balance: 0.0492
     Episode_Reward/rew_lin_vel_xy: 0.0510
      Episode_Reward/rew_ang_vel_z: 0.1494
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0549
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2513
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.3750
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 1.07s
                        Total time: 205.51s
                               ETA: 3075.0s

################################################################################
                     [1m Learning iteration 188/3000 [0m                      

                       Computation: 91858 steps/s (collection: 0.945s, learning 0.125s)
               Value function loss: 0.2886
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5791
                     Learning rate: 0.0044
                       Mean reward: -0.31
               Mean episode length: 51.16
       Episode_Reward/keep_balance: 0.0493
     Episode_Reward/rew_lin_vel_xy: 0.0510
      Episode_Reward/rew_ang_vel_z: 0.1493
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0016
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0555
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2510
Metrics/base_velocity/error_vel_yaw: 0.0432
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.4583
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 1.07s
                        Total time: 206.58s
                               ETA: 3073.5s

################################################################################
                     [1m Learning iteration 189/3000 [0m                      

                       Computation: 92171 steps/s (collection: 0.942s, learning 0.124s)
               Value function loss: 0.3155
                    Surrogate loss: 0.0083
             Mean action noise std: 0.5796
                     Learning rate: 0.0004
                       Mean reward: -0.21
               Mean episode length: 49.87
       Episode_Reward/keep_balance: 0.0492
     Episode_Reward/rew_lin_vel_xy: 0.0510
      Episode_Reward/rew_ang_vel_z: 0.1498
    Episode_Reward/pen_base_height: -0.1069
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0052
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2512
Metrics/base_velocity/error_vel_yaw: 0.0424
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.3750
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 1.07s
                        Total time: 207.65s
                               ETA: 3072.1s

################################################################################
                     [1m Learning iteration 190/3000 [0m                      

                       Computation: 91140 steps/s (collection: 0.952s, learning 0.127s)
               Value function loss: 0.1938
                    Surrogate loss: 0.0017
             Mean action noise std: 0.5796
                     Learning rate: 0.0004
                       Mean reward: -0.46
               Mean episode length: 50.62
       Episode_Reward/keep_balance: 0.0492
     Episode_Reward/rew_lin_vel_xy: 0.0518
      Episode_Reward/rew_ang_vel_z: 0.1498
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0547
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0052
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2507
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.5417
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 1.08s
                        Total time: 208.72s
                               ETA: 3070.8s

################################################################################
                     [1m Learning iteration 191/3000 [0m                      

                       Computation: 92194 steps/s (collection: 0.942s, learning 0.125s)
               Value function loss: 0.1896
                    Surrogate loss: 0.0012
             Mean action noise std: 0.5799
                     Learning rate: 0.0004
                       Mean reward: -0.41
               Mean episode length: 49.18
       Episode_Reward/keep_balance: 0.0493
     Episode_Reward/rew_lin_vel_xy: 0.0508
      Episode_Reward/rew_ang_vel_z: 0.1500
    Episode_Reward/pen_base_height: -0.1069
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2520
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.0417
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 1.07s
                        Total time: 209.79s
                               ETA: 3069.3s

################################################################################
                     [1m Learning iteration 192/3000 [0m                      

                       Computation: 91996 steps/s (collection: 0.945s, learning 0.124s)
               Value function loss: 0.1849
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5797
                     Learning rate: 0.0009
                       Mean reward: -0.25
               Mean episode length: 49.47
       Episode_Reward/keep_balance: 0.0495
     Episode_Reward/rew_lin_vel_xy: 0.0521
      Episode_Reward/rew_ang_vel_z: 0.1505
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2537
Metrics/base_velocity/error_vel_yaw: 0.0431
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.5000
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 1.07s
                        Total time: 210.86s
                               ETA: 3067.8s

################################################################################
                     [1m Learning iteration 193/3000 [0m                      

                       Computation: 91803 steps/s (collection: 0.947s, learning 0.124s)
               Value function loss: 0.2011
                    Surrogate loss: 0.0056
             Mean action noise std: 0.5795
                     Learning rate: 0.0004
                       Mean reward: -0.38
               Mean episode length: 49.73
       Episode_Reward/keep_balance: 0.0494
     Episode_Reward/rew_lin_vel_xy: 0.0515
      Episode_Reward/rew_ang_vel_z: 0.1503
    Episode_Reward/pen_base_height: -0.1074
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0552
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2486
Metrics/base_velocity/error_vel_yaw: 0.0428
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.8750
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 1.07s
                        Total time: 211.93s
                               ETA: 3066.4s

################################################################################
                     [1m Learning iteration 194/3000 [0m                      

                       Computation: 91421 steps/s (collection: 0.945s, learning 0.130s)
               Value function loss: 0.1795
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5791
                     Learning rate: 0.0003
                       Mean reward: -0.52
               Mean episode length: 49.79
       Episode_Reward/keep_balance: 0.0495
     Episode_Reward/rew_lin_vel_xy: 0.0519
      Episode_Reward/rew_ang_vel_z: 0.1509
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0053
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2508
Metrics/base_velocity/error_vel_yaw: 0.0427
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.6250
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 1.08s
                        Total time: 213.00s
                               ETA: 3065.1s

################################################################################
                     [1m Learning iteration 195/3000 [0m                      

                       Computation: 92775 steps/s (collection: 0.937s, learning 0.123s)
               Value function loss: 0.1823
                    Surrogate loss: 0.0001
             Mean action noise std: 0.5785
                     Learning rate: 0.0003
                       Mean reward: -0.17
               Mean episode length: 49.79
       Episode_Reward/keep_balance: 0.0499
     Episode_Reward/rew_lin_vel_xy: 0.0546
      Episode_Reward/rew_ang_vel_z: 0.1522
    Episode_Reward/pen_base_height: -0.1069
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0053
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2502
Metrics/base_velocity/error_vel_yaw: 0.0429
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.9167
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 1.06s
                        Total time: 214.06s
                               ETA: 3063.5s

################################################################################
                     [1m Learning iteration 196/3000 [0m                      

                       Computation: 91964 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.1741
                    Surrogate loss: -0.0011
             Mean action noise std: 0.5784
                     Learning rate: 0.0004
                       Mean reward: -0.50
               Mean episode length: 49.18
       Episode_Reward/keep_balance: 0.0498
     Episode_Reward/rew_lin_vel_xy: 0.0532
      Episode_Reward/rew_ang_vel_z: 0.1515
    Episode_Reward/pen_base_height: -0.1079
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2500
Metrics/base_velocity/error_vel_yaw: 0.0439
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.5000
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 1.07s
                        Total time: 215.13s
                               ETA: 3062.1s

################################################################################
                     [1m Learning iteration 197/3000 [0m                      

                       Computation: 91326 steps/s (collection: 0.950s, learning 0.127s)
               Value function loss: 0.1833
                    Surrogate loss: 0.0004
             Mean action noise std: 0.5774
                     Learning rate: 0.0006
                       Mean reward: -0.40
               Mean episode length: 50.41
       Episode_Reward/keep_balance: 0.0494
     Episode_Reward/rew_lin_vel_xy: 0.0511
      Episode_Reward/rew_ang_vel_z: 0.1501
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0054
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0054
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2497
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.7500
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 1.08s
                        Total time: 216.21s
                               ETA: 3060.8s

################################################################################
                     [1m Learning iteration 198/3000 [0m                      

                       Computation: 91199 steps/s (collection: 0.951s, learning 0.127s)
               Value function loss: 0.1630
                    Surrogate loss: 0.0013
             Mean action noise std: 0.5765
                     Learning rate: 0.0004
                       Mean reward: -0.27
               Mean episode length: 50.73
       Episode_Reward/keep_balance: 0.0500
     Episode_Reward/rew_lin_vel_xy: 0.0518
      Episode_Reward/rew_ang_vel_z: 0.1520
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0037
Episode_Reward/pen_flat_orientation: -0.0547
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0472
Metrics/base_velocity/error_vel_xy: 0.2562
Metrics/base_velocity/error_vel_yaw: 0.0433
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 84.8333
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 1.08s
                        Total time: 217.29s
                               ETA: 3059.5s

################################################################################
                     [1m Learning iteration 199/3000 [0m                      

                       Computation: 90292 steps/s (collection: 0.961s, learning 0.127s)
               Value function loss: 0.1745
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5767
                     Learning rate: 0.0006
                       Mean reward: -0.48
               Mean episode length: 50.29
       Episode_Reward/keep_balance: 0.0500
     Episode_Reward/rew_lin_vel_xy: 0.0526
      Episode_Reward/rew_ang_vel_z: 0.1522
    Episode_Reward/pen_base_height: -0.1076
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0204
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0054
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2542
Metrics/base_velocity/error_vel_yaw: 0.0433
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.8750
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 1.09s
                        Total time: 218.38s
                               ETA: 3058.4s

################################################################################
                     [1m Learning iteration 200/3000 [0m                      

                       Computation: 91359 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.1976
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5760
                     Learning rate: 0.0004
                       Mean reward: -0.40
               Mean episode length: 49.68
       Episode_Reward/keep_balance: 0.0498
     Episode_Reward/rew_lin_vel_xy: 0.0511
      Episode_Reward/rew_ang_vel_z: 0.1517
    Episode_Reward/pen_base_height: -0.1074
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0203
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0070
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2532
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.5000
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 1.08s
                        Total time: 219.45s
                               ETA: 3057.0s

################################################################################
                     [1m Learning iteration 201/3000 [0m                      

                       Computation: 91374 steps/s (collection: 0.950s, learning 0.125s)
               Value function loss: 0.1928
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5752
                     Learning rate: 0.0004
                       Mean reward: -0.31
               Mean episode length: 51.49
       Episode_Reward/keep_balance: 0.0499
     Episode_Reward/rew_lin_vel_xy: 0.0512
      Episode_Reward/rew_ang_vel_z: 0.1520
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0468
Metrics/base_velocity/error_vel_xy: 0.2549
Metrics/base_velocity/error_vel_yaw: 0.0431
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 1.08s
                        Total time: 220.53s
                               ETA: 3055.7s

################################################################################
                     [1m Learning iteration 202/3000 [0m                      

                       Computation: 91363 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.1765
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5748
                     Learning rate: 0.0004
                       Mean reward: -0.60
               Mean episode length: 48.32
       Episode_Reward/keep_balance: 0.0499
     Episode_Reward/rew_lin_vel_xy: 0.0509
      Episode_Reward/rew_ang_vel_z: 0.1519
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0057
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0464
Metrics/base_velocity/error_vel_xy: 0.2552
Metrics/base_velocity/error_vel_yaw: 0.0433
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 1.08s
                        Total time: 221.60s
                               ETA: 3054.4s

################################################################################
                     [1m Learning iteration 203/3000 [0m                      

                       Computation: 92247 steps/s (collection: 0.943s, learning 0.123s)
               Value function loss: 0.1875
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5747
                     Learning rate: 0.0009
                       Mean reward: -0.34
               Mean episode length: 49.21
       Episode_Reward/keep_balance: 0.0504
     Episode_Reward/rew_lin_vel_xy: 0.0554
      Episode_Reward/rew_ang_vel_z: 0.1539
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0038
Episode_Reward/pen_flat_orientation: -0.0547
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2522
Metrics/base_velocity/error_vel_yaw: 0.0436
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 85.2917
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 1.07s
                        Total time: 222.67s
                               ETA: 3053.0s

################################################################################
                     [1m Learning iteration 204/3000 [0m                      

                       Computation: 54531 steps/s (collection: 1.678s, learning 0.124s)
               Value function loss: 0.2196
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5743
                     Learning rate: 0.0019
                       Mean reward: -0.44
               Mean episode length: 50.07
       Episode_Reward/keep_balance: 0.0508
     Episode_Reward/rew_lin_vel_xy: 0.0572
      Episode_Reward/rew_ang_vel_z: 0.1553
    Episode_Reward/pen_base_height: -0.1076
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2508
Metrics/base_velocity/error_vel_yaw: 0.0436
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 1.80s
                        Total time: 224.47s
                               ETA: 3061.6s

################################################################################
                     [1m Learning iteration 205/3000 [0m                      

                       Computation: 91494 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.2374
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5740
                     Learning rate: 0.0029
                       Mean reward: -0.20
               Mean episode length: 51.50
       Episode_Reward/keep_balance: 0.0503
     Episode_Reward/rew_lin_vel_xy: 0.0529
      Episode_Reward/rew_ang_vel_z: 0.1533
    Episode_Reward/pen_base_height: -0.1076
      Episode_Reward/pen_lin_vel_z: -0.0114
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0543
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2521
Metrics/base_velocity/error_vel_yaw: 0.0433
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.6667
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 1.07s
                        Total time: 225.55s
                               ETA: 3060.2s

################################################################################
                     [1m Learning iteration 206/3000 [0m                      

                       Computation: 90834 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.3368
                    Surrogate loss: 0.0062
             Mean action noise std: 0.5736
                     Learning rate: 0.0003
                       Mean reward: -0.26
               Mean episode length: 50.35
       Episode_Reward/keep_balance: 0.0503
     Episode_Reward/rew_lin_vel_xy: 0.0527
      Episode_Reward/rew_ang_vel_z: 0.1536
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0113
     Episode_Reward/pen_ang_vel_xy: -0.0206
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0055
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0471
Metrics/base_velocity/error_vel_xy: 0.2554
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.3333
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 1.08s
                        Total time: 226.63s
                               ETA: 3058.9s

################################################################################
                     [1m Learning iteration 207/3000 [0m                      

                       Computation: 91210 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.2027
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5729
                     Learning rate: 0.0006
                       Mean reward: -0.02
               Mean episode length: 52.13
       Episode_Reward/keep_balance: 0.0503
     Episode_Reward/rew_lin_vel_xy: 0.0518
      Episode_Reward/rew_ang_vel_z: 0.1544
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0205
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0054
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2550
Metrics/base_velocity/error_vel_yaw: 0.0425
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.7500
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 1.08s
                        Total time: 227.71s
                               ETA: 3057.6s

################################################################################
                     [1m Learning iteration 208/3000 [0m                      

                       Computation: 91390 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.1998
                    Surrogate loss: 0.0014
             Mean action noise std: 0.5718
                     Learning rate: 0.0004
                       Mean reward: -0.30
               Mean episode length: 48.96
       Episode_Reward/keep_balance: 0.0505
     Episode_Reward/rew_lin_vel_xy: 0.0541
      Episode_Reward/rew_ang_vel_z: 0.1545
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0055
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0056
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2525
Metrics/base_velocity/error_vel_yaw: 0.0435
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 81.5833
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 1.08s
                        Total time: 228.78s
                               ETA: 3056.3s

################################################################################
                     [1m Learning iteration 209/3000 [0m                      

                       Computation: 91963 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.2042
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5711
                     Learning rate: 0.0009
                       Mean reward: -0.54
               Mean episode length: 49.47
       Episode_Reward/keep_balance: 0.0502
     Episode_Reward/rew_lin_vel_xy: 0.0497
      Episode_Reward/rew_ang_vel_z: 0.1537
    Episode_Reward/pen_base_height: -0.1070
      Episode_Reward/pen_lin_vel_z: -0.0116
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0539
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0057
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0470
Metrics/base_velocity/error_vel_xy: 0.2558
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 82.9167
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 1.07s
                        Total time: 229.85s
                               ETA: 3054.8s

################################################################################
                     [1m Learning iteration 210/3000 [0m                      

                       Computation: 91580 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 0.2145
                    Surrogate loss: 0.0013
             Mean action noise std: 0.5705
                     Learning rate: 0.0004
                       Mean reward: -0.58
               Mean episode length: 48.27
       Episode_Reward/keep_balance: 0.0503
     Episode_Reward/rew_lin_vel_xy: 0.0516
      Episode_Reward/rew_ang_vel_z: 0.1540
    Episode_Reward/pen_base_height: -0.1071
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0207
   Episode_Reward/pen_joint_torque: -0.0056
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0015
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0024
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0057
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0469
Metrics/base_velocity/error_vel_xy: 0.2572
Metrics/base_velocity/error_vel_yaw: 0.0429
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 1.07s
                        Total time: 230.93s
                               ETA: 3053.5s

################################################################################
                     [1m Learning iteration 211/3000 [0m                      

                       Computation: 90949 steps/s (collection: 0.956s, learning 0.125s)
               Value function loss: 0.1745
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5694
                     Learning rate: 0.0009
                       Mean reward: -0.42
               Mean episode length: 50.36
       Episode_Reward/keep_balance: 0.0506
     Episode_Reward/rew_lin_vel_xy: 0.0500
      Episode_Reward/rew_ang_vel_z: 0.1553
    Episode_Reward/pen_base_height: -0.1076
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0045
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0543
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0470
Metrics/base_velocity/error_vel_xy: 0.2606
Metrics/base_velocity/error_vel_yaw: 0.0430
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 1.08s
                        Total time: 232.01s
                               ETA: 3052.2s

################################################################################
                     [1m Learning iteration 212/3000 [0m                      

                       Computation: 91067 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.1787
                    Surrogate loss: 0.0038
             Mean action noise std: 0.5693
                     Learning rate: 0.0003
                       Mean reward: -0.16
               Mean episode length: 52.47
       Episode_Reward/keep_balance: 0.0509
     Episode_Reward/rew_lin_vel_xy: 0.0530
      Episode_Reward/rew_ang_vel_z: 0.1559
    Episode_Reward/pen_base_height: -0.1081
      Episode_Reward/pen_lin_vel_z: -0.0115
     Episode_Reward/pen_ang_vel_xy: -0.0208
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0545
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0472
Metrics/base_velocity/error_vel_xy: 0.2571
Metrics/base_velocity/error_vel_yaw: 0.0438
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.1250
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 1.08s
                        Total time: 233.09s
                               ETA: 3050.9s

################################################################################
                     [1m Learning iteration 213/3000 [0m                      

                       Computation: 90507 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.1737
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5679
                     Learning rate: 0.0006
                       Mean reward: -0.27
               Mean episode length: 50.17
       Episode_Reward/keep_balance: 0.0512
     Episode_Reward/rew_lin_vel_xy: 0.0546
      Episode_Reward/rew_ang_vel_z: 0.1572
    Episode_Reward/pen_base_height: -0.1068
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0058
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0059
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2575
Metrics/base_velocity/error_vel_yaw: 0.0435
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.0833
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 1.09s
                        Total time: 234.17s
                               ETA: 3049.7s

################################################################################
                     [1m Learning iteration 214/3000 [0m                      

                       Computation: 92457 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 0.1770
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5671
                     Learning rate: 0.0006
                       Mean reward: -0.35
               Mean episode length: 49.78
       Episode_Reward/keep_balance: 0.0511
     Episode_Reward/rew_lin_vel_xy: 0.0573
      Episode_Reward/rew_ang_vel_z: 0.1572
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0071
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2557
Metrics/base_velocity/error_vel_yaw: 0.0431
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.2917
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 1.06s
                        Total time: 235.23s
                               ETA: 3048.2s

################################################################################
                     [1m Learning iteration 215/3000 [0m                      

                       Computation: 92647 steps/s (collection: 0.937s, learning 0.124s)
               Value function loss: 0.1918
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5671
                     Learning rate: 0.0003
                       Mean reward: -0.10
               Mean episode length: 51.35
       Episode_Reward/keep_balance: 0.0511
     Episode_Reward/rew_lin_vel_xy: 0.0538
      Episode_Reward/rew_ang_vel_z: 0.1568
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0209
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0542
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2564
Metrics/base_velocity/error_vel_yaw: 0.0432
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 1.06s
                        Total time: 236.30s
                               ETA: 3046.7s

################################################################################
                     [1m Learning iteration 216/3000 [0m                      

                       Computation: 91897 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.1655
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5670
                     Learning rate: 0.0006
                       Mean reward: -0.24
               Mean episode length: 50.72
       Episode_Reward/keep_balance: 0.0508
     Episode_Reward/rew_lin_vel_xy: 0.0545
      Episode_Reward/rew_ang_vel_z: 0.1562
    Episode_Reward/pen_base_height: -0.1074
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0057
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2598
Metrics/base_velocity/error_vel_yaw: 0.0433
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 77.0417
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 1.07s
                        Total time: 237.37s
                               ETA: 3045.3s

################################################################################
                     [1m Learning iteration 217/3000 [0m                      

                       Computation: 91280 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 0.1969
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5676
                     Learning rate: 0.0009
                       Mean reward: -0.38
               Mean episode length: 51.44
       Episode_Reward/keep_balance: 0.0515
     Episode_Reward/rew_lin_vel_xy: 0.0529
      Episode_Reward/rew_ang_vel_z: 0.1584
    Episode_Reward/pen_base_height: -0.1072
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0058
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0059
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2605
Metrics/base_velocity/error_vel_yaw: 0.0437
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.2083
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 1.08s
                        Total time: 238.44s
                               ETA: 3044.0s

################################################################################
                     [1m Learning iteration 218/3000 [0m                      

                       Computation: 91628 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.1912
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5678
                     Learning rate: 0.0013
                       Mean reward: -0.32
               Mean episode length: 50.37
       Episode_Reward/keep_balance: 0.0509
     Episode_Reward/rew_lin_vel_xy: 0.0522
      Episode_Reward/rew_ang_vel_z: 0.1560
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0211
   Episode_Reward/pen_joint_torque: -0.0058
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0059
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2589
Metrics/base_velocity/error_vel_yaw: 0.0434
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.4167
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 1.07s
                        Total time: 239.52s
                               ETA: 3042.6s

################################################################################
                     [1m Learning iteration 219/3000 [0m                      

                       Computation: 93035 steps/s (collection: 0.934s, learning 0.122s)
               Value function loss: 0.1832
                    Surrogate loss: 0.0030
             Mean action noise std: 0.5680
                     Learning rate: 0.0006
                       Mean reward: -0.29
               Mean episode length: 50.70
       Episode_Reward/keep_balance: 0.0511
     Episode_Reward/rew_lin_vel_xy: 0.0544
      Episode_Reward/rew_ang_vel_z: 0.1569
    Episode_Reward/pen_base_height: -0.1076
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0210
   Episode_Reward/pen_joint_torque: -0.0058
    Episode_Reward/pen_joint_accel: -0.0046
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0017
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0058
   Episode_Reward/foot_landing_vel: -0.0072
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2577
Metrics/base_velocity/error_vel_yaw: 0.0433
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.3750
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 1.06s
                        Total time: 240.57s
                               ETA: 3041.0s

################################################################################
                     [1m Learning iteration 220/3000 [0m                      

                       Computation: 92125 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 0.1806
                    Surrogate loss: -0.0008
             Mean action noise std: 0.5688
                     Learning rate: 0.0009
                       Mean reward: 0.04
               Mean episode length: 52.67
       Episode_Reward/keep_balance: 0.0520
     Episode_Reward/rew_lin_vel_xy: 0.0560
      Episode_Reward/rew_ang_vel_z: 0.1593
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0059
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0547
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0059
   Episode_Reward/foot_landing_vel: -0.0073
   Episode_Reward/test_gait_reward: -0.0483
Metrics/base_velocity/error_vel_xy: 0.2590
Metrics/base_velocity/error_vel_yaw: 0.0443
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 77.9583
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 1.07s
                        Total time: 241.64s
                               ETA: 3039.6s

################################################################################
                     [1m Learning iteration 221/3000 [0m                      

                       Computation: 91392 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.1943
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5687
                     Learning rate: 0.0006
                       Mean reward: -0.59
               Mean episode length: 49.82
       Episode_Reward/keep_balance: 0.0512
     Episode_Reward/rew_lin_vel_xy: 0.0526
      Episode_Reward/rew_ang_vel_z: 0.1571
    Episode_Reward/pen_base_height: -0.1077
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0213
   Episode_Reward/pen_joint_torque: -0.0059
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0025
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0039
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0059
   Episode_Reward/foot_landing_vel: -0.0074
   Episode_Reward/test_gait_reward: -0.0473
Metrics/base_velocity/error_vel_xy: 0.2608
Metrics/base_velocity/error_vel_yaw: 0.0437
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 79.8333
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 1.08s
                        Total time: 242.71s
                               ETA: 3038.3s

################################################################################
                     [1m Learning iteration 222/3000 [0m                      

                       Computation: 92595 steps/s (collection: 0.940s, learning 0.121s)
               Value function loss: 0.1855
                    Surrogate loss: 0.0003
             Mean action noise std: 0.5681
                     Learning rate: 0.0004
                       Mean reward: -0.15
               Mean episode length: 52.63
       Episode_Reward/keep_balance: 0.0523
     Episode_Reward/rew_lin_vel_xy: 0.0572
      Episode_Reward/rew_ang_vel_z: 0.1606
    Episode_Reward/pen_base_height: -0.1081
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0547
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0074
   Episode_Reward/test_gait_reward: -0.0486
Metrics/base_velocity/error_vel_xy: 0.2637
Metrics/base_velocity/error_vel_yaw: 0.0446
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 1.06s
                        Total time: 243.78s
                               ETA: 3036.8s

################################################################################
                     [1m Learning iteration 223/3000 [0m                      

                       Computation: 91988 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.1626
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5680
                     Learning rate: 0.0004
                       Mean reward: -0.15
               Mean episode length: 52.90
       Episode_Reward/keep_balance: 0.0517
     Episode_Reward/rew_lin_vel_xy: 0.0563
      Episode_Reward/rew_ang_vel_z: 0.1589
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0212
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0062
   Episode_Reward/foot_landing_vel: -0.0074
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2621
Metrics/base_velocity/error_vel_yaw: 0.0436
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.7500
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 1.07s
                        Total time: 244.85s
                               ETA: 3035.4s

################################################################################
                     [1m Learning iteration 224/3000 [0m                      

                       Computation: 92564 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 0.1691
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5680
                     Learning rate: 0.0006
                       Mean reward: -0.59
               Mean episode length: 50.07
       Episode_Reward/keep_balance: 0.0517
     Episode_Reward/rew_lin_vel_xy: 0.0548
      Episode_Reward/rew_ang_vel_z: 0.1588
    Episode_Reward/pen_base_height: -0.1074
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0047
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2587
Metrics/base_velocity/error_vel_yaw: 0.0440
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 77.5000
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 1.06s
                        Total time: 245.91s
                               ETA: 3033.9s

################################################################################
                     [1m Learning iteration 225/3000 [0m                      

                       Computation: 92581 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 0.1780
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5675
                     Learning rate: 0.0004
                       Mean reward: -0.28
               Mean episode length: 52.36
       Episode_Reward/keep_balance: 0.0519
     Episode_Reward/rew_lin_vel_xy: 0.0549
      Episode_Reward/rew_ang_vel_z: 0.1595
    Episode_Reward/pen_base_height: -0.1079
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0534
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0074
   Episode_Reward/test_gait_reward: -0.0480
Metrics/base_velocity/error_vel_xy: 0.2632
Metrics/base_velocity/error_vel_yaw: 0.0439
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 1.06s
                        Total time: 246.97s
                               ETA: 3032.5s

################################################################################
                     [1m Learning iteration 226/3000 [0m                      

                       Computation: 92011 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.1761
                    Surrogate loss: -0.0008
             Mean action noise std: 0.5667
                     Learning rate: 0.0006
                       Mean reward: -0.33
               Mean episode length: 51.34
       Episode_Reward/keep_balance: 0.0517
     Episode_Reward/rew_lin_vel_xy: 0.0566
      Episode_Reward/rew_ang_vel_z: 0.1585
    Episode_Reward/pen_base_height: -0.1069
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0216
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0527
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0061
   Episode_Reward/foot_landing_vel: -0.0074
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2601
Metrics/base_velocity/error_vel_yaw: 0.0443
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.0000
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 1.07s
                        Total time: 248.04s
                               ETA: 3031.1s

################################################################################
                     [1m Learning iteration 227/3000 [0m                      

                       Computation: 92327 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 0.1754
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5658
                     Learning rate: 0.0006
                       Mean reward: -0.34
               Mean episode length: 51.44
       Episode_Reward/keep_balance: 0.0517
     Episode_Reward/rew_lin_vel_xy: 0.0553
      Episode_Reward/rew_ang_vel_z: 0.1586
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0215
   Episode_Reward/pen_joint_torque: -0.0060
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0060
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2584
Metrics/base_velocity/error_vel_yaw: 0.0439
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 1.06s
                        Total time: 249.10s
                               ETA: 3029.6s

################################################################################
                     [1m Learning iteration 228/3000 [0m                      

                       Computation: 92510 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 0.1839
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5650
                     Learning rate: 0.0009
                       Mean reward: -0.30
               Mean episode length: 52.37
       Episode_Reward/keep_balance: 0.0526
     Episode_Reward/rew_lin_vel_xy: 0.0555
      Episode_Reward/rew_ang_vel_z: 0.1606
    Episode_Reward/pen_base_height: -0.1093
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0214
   Episode_Reward/pen_joint_torque: -0.0061
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0557
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0064
   Episode_Reward/foot_landing_vel: -0.0076
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2709
Metrics/base_velocity/error_vel_yaw: 0.0455
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 72.1250
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 1.06s
                        Total time: 250.16s
                               ETA: 3028.2s

################################################################################
                     [1m Learning iteration 229/3000 [0m                      

                       Computation: 91682 steps/s (collection: 0.949s, learning 0.124s)
               Value function loss: 0.1848
                    Surrogate loss: 0.0081
             Mean action noise std: 0.5648
                     Learning rate: 0.0001
                       Mean reward: -0.10
               Mean episode length: 56.27
       Episode_Reward/keep_balance: 0.0532
     Episode_Reward/rew_lin_vel_xy: 0.0578
      Episode_Reward/rew_ang_vel_z: 0.1628
    Episode_Reward/pen_base_height: -0.1090
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0063
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0544
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0065
   Episode_Reward/foot_landing_vel: -0.0076
   Episode_Reward/test_gait_reward: -0.0486
Metrics/base_velocity/error_vel_xy: 0.2686
Metrics/base_velocity/error_vel_yaw: 0.0457
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 83.0417
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 1.07s
                        Total time: 251.24s
                               ETA: 3026.9s

################################################################################
                     [1m Learning iteration 230/3000 [0m                      

                       Computation: 91556 steps/s (collection: 0.950s, learning 0.124s)
               Value function loss: 0.1704
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5643
                     Learning rate: 0.0003
                       Mean reward: -0.15
               Mean episode length: 52.80
       Episode_Reward/keep_balance: 0.0532
     Episode_Reward/rew_lin_vel_xy: 0.0570
      Episode_Reward/rew_ang_vel_z: 0.1627
    Episode_Reward/pen_base_height: -0.1075
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0061
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0064
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0490
Metrics/base_velocity/error_vel_xy: 0.2675
Metrics/base_velocity/error_vel_yaw: 0.0456
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 77.0000
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 1.07s
                        Total time: 252.31s
                               ETA: 3025.5s

################################################################################
                     [1m Learning iteration 231/3000 [0m                      

                       Computation: 91788 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.1891
                    Surrogate loss: -0.0011
             Mean action noise std: 0.5639
                     Learning rate: 0.0006
                       Mean reward: -0.33
               Mean episode length: 52.14
       Episode_Reward/keep_balance: 0.0520
     Episode_Reward/rew_lin_vel_xy: 0.0550
      Episode_Reward/rew_ang_vel_z: 0.1593
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0061
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0065
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2647
Metrics/base_velocity/error_vel_yaw: 0.0443
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 77.1250
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 1.07s
                        Total time: 253.38s
                               ETA: 3024.2s

################################################################################
                     [1m Learning iteration 232/3000 [0m                      

                       Computation: 91156 steps/s (collection: 0.954s, learning 0.125s)
               Value function loss: 0.2085
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5636
                     Learning rate: 0.0013
                       Mean reward: -0.49
               Mean episode length: 50.66
       Episode_Reward/keep_balance: 0.0528
     Episode_Reward/rew_lin_vel_xy: 0.0579
      Episode_Reward/rew_ang_vel_z: 0.1617
    Episode_Reward/pen_base_height: -0.1073
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0061
    Episode_Reward/pen_joint_accel: -0.0048
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0528
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0064
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0483
Metrics/base_velocity/error_vel_xy: 0.2664
Metrics/base_velocity/error_vel_yaw: 0.0449
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 80.3750
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 1.08s
                        Total time: 254.46s
                               ETA: 3022.9s

################################################################################
                     [1m Learning iteration 233/3000 [0m                      

                       Computation: 87877 steps/s (collection: 0.996s, learning 0.123s)
               Value function loss: 0.1982
                    Surrogate loss: 0.0102
             Mean action noise std: 0.5640
                     Learning rate: 0.0002
                       Mean reward: 0.05
               Mean episode length: 53.08
       Episode_Reward/keep_balance: 0.0523
     Episode_Reward/rew_lin_vel_xy: 0.0551
      Episode_Reward/rew_ang_vel_z: 0.1604
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0061
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0534
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0065
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2620
Metrics/base_velocity/error_vel_yaw: 0.0445
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 75.2500
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 1.12s
                        Total time: 255.58s
                               ETA: 3022.2s

################################################################################
                     [1m Learning iteration 234/3000 [0m                      

                       Computation: 90165 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.1769
                    Surrogate loss: -0.0021
             Mean action noise std: 0.5636
                     Learning rate: 0.0004
                       Mean reward: -0.19
               Mean episode length: 51.70
       Episode_Reward/keep_balance: 0.0524
     Episode_Reward/rew_lin_vel_xy: 0.0556
      Episode_Reward/rew_ang_vel_z: 0.1600
    Episode_Reward/pen_base_height: -0.1066
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0062
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0530
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0066
   Episode_Reward/foot_landing_vel: -0.0075
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2684
Metrics/base_velocity/error_vel_yaw: 0.0450
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.2083
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 1.09s
                        Total time: 256.67s
                               ETA: 3021.0s

################################################################################
                     [1m Learning iteration 235/3000 [0m                      

                       Computation: 90204 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.1719
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5629
                     Learning rate: 0.0006
                       Mean reward: -0.24
               Mean episode length: 53.68
       Episode_Reward/keep_balance: 0.0532
     Episode_Reward/rew_lin_vel_xy: 0.0581
      Episode_Reward/rew_ang_vel_z: 0.1636
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0062
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0066
   Episode_Reward/foot_landing_vel: -0.0076
   Episode_Reward/test_gait_reward: -0.0479
Metrics/base_velocity/error_vel_xy: 0.2618
Metrics/base_velocity/error_vel_yaw: 0.0452
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.8333
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 1.09s
                        Total time: 257.76s
                               ETA: 3019.9s

################################################################################
                     [1m Learning iteration 236/3000 [0m                      

                       Computation: 91585 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 0.1806
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5613
                     Learning rate: 0.0009
                       Mean reward: -0.11
               Mean episode length: 51.96
       Episode_Reward/keep_balance: 0.0536
     Episode_Reward/rew_lin_vel_xy: 0.0590
      Episode_Reward/rew_ang_vel_z: 0.1651
    Episode_Reward/pen_base_height: -0.1079
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0217
   Episode_Reward/pen_joint_torque: -0.0063
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0066
   Episode_Reward/foot_landing_vel: -0.0076
   Episode_Reward/test_gait_reward: -0.0485
Metrics/base_velocity/error_vel_xy: 0.2705
Metrics/base_velocity/error_vel_yaw: 0.0455
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.9167
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 1.07s
                        Total time: 258.83s
                               ETA: 3018.6s

################################################################################
                     [1m Learning iteration 237/3000 [0m                      

                       Computation: 91807 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.1959
                    Surrogate loss: 0.0010
             Mean action noise std: 0.5607
                     Learning rate: 0.0004
                       Mean reward: -0.00
               Mean episode length: 52.36
       Episode_Reward/keep_balance: 0.0529
     Episode_Reward/rew_lin_vel_xy: 0.0539
      Episode_Reward/rew_ang_vel_z: 0.1623
    Episode_Reward/pen_base_height: -0.1074
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0218
   Episode_Reward/pen_joint_torque: -0.0062
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0018
   Episode_Reward/pen_joint_powers: -0.0026
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0067
   Episode_Reward/foot_landing_vel: -0.0077
   Episode_Reward/test_gait_reward: -0.0478
Metrics/base_velocity/error_vel_xy: 0.2696
Metrics/base_velocity/error_vel_yaw: 0.0451
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.4583
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 1.07s
                        Total time: 259.90s
                               ETA: 3017.3s

################################################################################
                     [1m Learning iteration 238/3000 [0m                      

                       Computation: 91221 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.2007
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5604
                     Learning rate: 0.0009
                       Mean reward: -0.20
               Mean episode length: 52.13
       Episode_Reward/keep_balance: 0.0528
     Episode_Reward/rew_lin_vel_xy: 0.0550
      Episode_Reward/rew_ang_vel_z: 0.1623
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0063
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0068
   Episode_Reward/foot_landing_vel: -0.0077
   Episode_Reward/test_gait_reward: -0.0474
Metrics/base_velocity/error_vel_xy: 0.2703
Metrics/base_velocity/error_vel_yaw: 0.0451
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.3750
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 1.08s
                        Total time: 260.98s
                               ETA: 3016.0s

################################################################################
                     [1m Learning iteration 239/3000 [0m                      

                       Computation: 91038 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.2223
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5609
                     Learning rate: 0.0013
                       Mean reward: -0.14
               Mean episode length: 53.18
       Episode_Reward/keep_balance: 0.0536
     Episode_Reward/rew_lin_vel_xy: 0.0554
      Episode_Reward/rew_ang_vel_z: 0.1644
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0063
    Episode_Reward/pen_joint_accel: -0.0049
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0069
   Episode_Reward/foot_landing_vel: -0.0077
   Episode_Reward/test_gait_reward: -0.0477
Metrics/base_velocity/error_vel_xy: 0.2701
Metrics/base_velocity/error_vel_yaw: 0.0454
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.4167
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 1.08s
                        Total time: 262.06s
                               ETA: 3014.8s

################################################################################
                     [1m Learning iteration 240/3000 [0m                      

                       Computation: 91178 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.3015
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5609
                     Learning rate: 0.0029
                       Mean reward: -0.42
               Mean episode length: 53.74
       Episode_Reward/keep_balance: 0.0533
     Episode_Reward/rew_lin_vel_xy: 0.0557
      Episode_Reward/rew_ang_vel_z: 0.1632
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0064
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0040
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0071
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0476
Metrics/base_velocity/error_vel_xy: 0.2722
Metrics/base_velocity/error_vel_yaw: 0.0457
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 78.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 1.08s
                        Total time: 263.14s
                               ETA: 3013.5s

################################################################################
                     [1m Learning iteration 241/3000 [0m                      

                       Computation: 92492 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 0.3761
                    Surrogate loss: -0.0011
             Mean action noise std: 0.5614
                     Learning rate: 0.0044
                       Mean reward: -0.07
               Mean episode length: 53.94
       Episode_Reward/keep_balance: 0.0546
     Episode_Reward/rew_lin_vel_xy: 0.0585
      Episode_Reward/rew_ang_vel_z: 0.1671
    Episode_Reward/pen_base_height: -0.1081
      Episode_Reward/pen_lin_vel_z: -0.0117
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0065
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0070
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0488
Metrics/base_velocity/error_vel_xy: 0.2769
Metrics/base_velocity/error_vel_yaw: 0.0468
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 76.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 1.06s
                        Total time: 264.20s
                               ETA: 3012.1s

################################################################################
                     [1m Learning iteration 242/3000 [0m                      

                       Computation: 92288 steps/s (collection: 0.941s, learning 0.124s)
               Value function loss: 0.3536
                    Surrogate loss: 0.0057
             Mean action noise std: 0.5621
                     Learning rate: 0.0006
                       Mean reward: 0.19
               Mean episode length: 56.69
       Episode_Reward/keep_balance: 0.0532
     Episode_Reward/rew_lin_vel_xy: 0.0548
      Episode_Reward/rew_ang_vel_z: 0.1630
    Episode_Reward/pen_base_height: -0.1079
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0220
   Episode_Reward/pen_joint_torque: -0.0063
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0532
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0070
   Episode_Reward/foot_landing_vel: -0.0077
   Episode_Reward/test_gait_reward: -0.0475
Metrics/base_velocity/error_vel_xy: 0.2723
Metrics/base_velocity/error_vel_yaw: 0.0459
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 75.5417
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 1.07s
                        Total time: 265.27s
                               ETA: 3010.7s

################################################################################
                     [1m Learning iteration 243/3000 [0m                      

                       Computation: 91269 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 0.2386
                    Surrogate loss: -0.0008
             Mean action noise std: 0.5623
                     Learning rate: 0.0003
                       Mean reward: -0.39
               Mean episode length: 51.81
       Episode_Reward/keep_balance: 0.0541
     Episode_Reward/rew_lin_vel_xy: 0.0604
      Episode_Reward/rew_ang_vel_z: 0.1653
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0065
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0073
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0481
Metrics/base_velocity/error_vel_xy: 0.2682
Metrics/base_velocity/error_vel_yaw: 0.0471
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.5833
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 1.08s
                        Total time: 266.34s
                               ETA: 3009.5s

################################################################################
                     [1m Learning iteration 244/3000 [0m                      

                       Computation: 90704 steps/s (collection: 0.959s, learning 0.125s)
               Value function loss: 0.2073
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5617
                     Learning rate: 0.0006
                       Mean reward: -0.18
               Mean episode length: 55.20
       Episode_Reward/keep_balance: 0.0541
     Episode_Reward/rew_lin_vel_xy: 0.0585
      Episode_Reward/rew_ang_vel_z: 0.1649
    Episode_Reward/pen_base_height: -0.1080
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0221
   Episode_Reward/pen_joint_torque: -0.0065
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0027
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0074
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0482
Metrics/base_velocity/error_vel_xy: 0.2726
Metrics/base_velocity/error_vel_yaw: 0.0471
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 75.6250
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 1.08s
                        Total time: 267.43s
                               ETA: 3008.3s

################################################################################
                     [1m Learning iteration 245/3000 [0m                      

                       Computation: 91077 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.2027
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5593
                     Learning rate: 0.0009
                       Mean reward: 0.26
               Mean episode length: 54.32
       Episode_Reward/keep_balance: 0.0545
     Episode_Reward/rew_lin_vel_xy: 0.0585
      Episode_Reward/rew_ang_vel_z: 0.1663
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0219
   Episode_Reward/pen_joint_torque: -0.0066
    Episode_Reward/pen_joint_accel: -0.0050
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0019
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0536
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0074
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0484
Metrics/base_velocity/error_vel_xy: 0.2763
Metrics/base_velocity/error_vel_yaw: 0.0472
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 1.08s
                        Total time: 268.51s
                               ETA: 3007.1s

################################################################################
                     [1m Learning iteration 246/3000 [0m                      

                       Computation: 90657 steps/s (collection: 0.959s, learning 0.125s)
               Value function loss: 0.2411
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5577
                     Learning rate: 0.0019
                       Mean reward: -0.04
               Mean episode length: 54.94
       Episode_Reward/keep_balance: 0.0547
     Episode_Reward/rew_lin_vel_xy: 0.0611
      Episode_Reward/rew_ang_vel_z: 0.1674
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0066
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0076
   Episode_Reward/foot_landing_vel: -0.0077
   Episode_Reward/test_gait_reward: -0.0492
Metrics/base_velocity/error_vel_xy: 0.2745
Metrics/base_velocity/error_vel_yaw: 0.0469
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.6250
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 1.08s
                        Total time: 269.59s
                               ETA: 3005.9s

################################################################################
                     [1m Learning iteration 247/3000 [0m                      

                       Computation: 91200 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.2637
                    Surrogate loss: 0.0027
             Mean action noise std: 0.5586
                     Learning rate: 0.0003
                       Mean reward: -0.28
               Mean episode length: 52.78
       Episode_Reward/keep_balance: 0.0553
     Episode_Reward/rew_lin_vel_xy: 0.0589
      Episode_Reward/rew_ang_vel_z: 0.1693
    Episode_Reward/pen_base_height: -0.1082
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0067
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0078
   Episode_Reward/foot_landing_vel: -0.0079
   Episode_Reward/test_gait_reward: -0.0491
Metrics/base_velocity/error_vel_xy: 0.2809
Metrics/base_velocity/error_vel_yaw: 0.0477
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 73.8333
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 1.08s
                        Total time: 270.67s
                               ETA: 3004.6s

################################################################################
                     [1m Learning iteration 248/3000 [0m                      

                       Computation: 91246 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.2157
                    Surrogate loss: 0.0026
             Mean action noise std: 0.5589
                     Learning rate: 0.0004
                       Mean reward: 0.31
               Mean episode length: 55.99
       Episode_Reward/keep_balance: 0.0545
     Episode_Reward/rew_lin_vel_xy: 0.0600
      Episode_Reward/rew_ang_vel_z: 0.1667
    Episode_Reward/pen_base_height: -0.1085
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0221
   Episode_Reward/pen_joint_torque: -0.0066
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0041
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0077
   Episode_Reward/foot_landing_vel: -0.0078
   Episode_Reward/test_gait_reward: -0.0486
Metrics/base_velocity/error_vel_xy: 0.2724
Metrics/base_velocity/error_vel_yaw: 0.0468
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.6250
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 1.08s
                        Total time: 271.75s
                               ETA: 3003.4s

################################################################################
                     [1m Learning iteration 249/3000 [0m                      

                       Computation: 91143 steps/s (collection: 0.953s, learning 0.126s)
               Value function loss: 0.1952
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5585
                     Learning rate: 0.0006
                       Mean reward: -0.24
               Mean episode length: 52.97
       Episode_Reward/keep_balance: 0.0559
     Episode_Reward/rew_lin_vel_xy: 0.0620
      Episode_Reward/rew_ang_vel_z: 0.1711
    Episode_Reward/pen_base_height: -0.1082
      Episode_Reward/pen_lin_vel_z: -0.0118
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0067
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0042
Episode_Reward/pen_flat_orientation: -0.0538
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0079
   Episode_Reward/foot_landing_vel: -0.0079
   Episode_Reward/test_gait_reward: -0.0495
Metrics/base_velocity/error_vel_xy: 0.2782
Metrics/base_velocity/error_vel_yaw: 0.0478
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 73.2083
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 1.08s
                        Total time: 272.82s
                               ETA: 3002.2s

################################################################################
                     [1m Learning iteration 250/3000 [0m                      

                       Computation: 90951 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.2096
                    Surrogate loss: 0.0015
             Mean action noise std: 0.5578
                     Learning rate: 0.0004
                       Mean reward: -0.32
               Mean episode length: 52.52
       Episode_Reward/keep_balance: 0.0554
     Episode_Reward/rew_lin_vel_xy: 0.0624
      Episode_Reward/rew_ang_vel_z: 0.1701
    Episode_Reward/pen_base_height: -0.1078
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0067
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0042
Episode_Reward/pen_flat_orientation: -0.0533
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0079
   Episode_Reward/foot_landing_vel: -0.0079
   Episode_Reward/test_gait_reward: -0.0489
Metrics/base_velocity/error_vel_xy: 0.2764
Metrics/base_velocity/error_vel_yaw: 0.0469
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 73.5417
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 1.08s
                        Total time: 273.91s
                               ETA: 3001.0s

################################################################################
                     [1m Learning iteration 251/3000 [0m                      

                       Computation: 91200 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.1988
                    Surrogate loss: 0.0060
             Mean action noise std: 0.5580
                     Learning rate: 0.0001
                       Mean reward: 0.28
               Mean episode length: 56.34
       Episode_Reward/keep_balance: 0.0562
     Episode_Reward/rew_lin_vel_xy: 0.0621
      Episode_Reward/rew_ang_vel_z: 0.1717
    Episode_Reward/pen_base_height: -0.1095
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0067
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0042
Episode_Reward/pen_flat_orientation: -0.0548
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0078
   Episode_Reward/foot_landing_vel: -0.0079
   Episode_Reward/test_gait_reward: -0.0500
Metrics/base_velocity/error_vel_xy: 0.2794
Metrics/base_velocity/error_vel_yaw: 0.0484
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 71.9167
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 1.08s
                        Total time: 274.98s
                               ETA: 2999.7s

################################################################################
                     [1m Learning iteration 252/3000 [0m                      

                       Computation: 90729 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.1949
                    Surrogate loss: 0.0026
             Mean action noise std: 0.5584
                     Learning rate: 0.0001
                       Mean reward: 0.16
               Mean episode length: 57.23
       Episode_Reward/keep_balance: 0.0557
     Episode_Reward/rew_lin_vel_xy: 0.0602
      Episode_Reward/rew_ang_vel_z: 0.1706
    Episode_Reward/pen_base_height: -0.1083
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0068
    Episode_Reward/pen_joint_accel: -0.0053
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0042
Episode_Reward/pen_flat_orientation: -0.0535
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0081
   Episode_Reward/foot_landing_vel: -0.0080
   Episode_Reward/test_gait_reward: -0.0494
Metrics/base_velocity/error_vel_xy: 0.2776
Metrics/base_velocity/error_vel_yaw: 0.0477
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 74.9167
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 1.08s
                        Total time: 276.07s
                               ETA: 2998.5s

################################################################################
                     [1m Learning iteration 253/3000 [0m                      

                       Computation: 91354 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.1837
                    Surrogate loss: 0.0007
             Mean action noise std: 0.5583
                     Learning rate: 0.0001
                       Mean reward: -0.33
               Mean episode length: 54.66
       Episode_Reward/keep_balance: 0.0561
     Episode_Reward/rew_lin_vel_xy: 0.0613
      Episode_Reward/rew_ang_vel_z: 0.1725
    Episode_Reward/pen_base_height: -0.1083
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0068
    Episode_Reward/pen_joint_accel: -0.0051
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0042
Episode_Reward/pen_flat_orientation: -0.0537
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0080
   Episode_Reward/foot_landing_vel: -0.0079
   Episode_Reward/test_gait_reward: -0.0498
Metrics/base_velocity/error_vel_xy: 0.2799
Metrics/base_velocity/error_vel_yaw: 0.0473
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 70.5000
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 1.08s
                        Total time: 277.14s
                               ETA: 2997.3s

################################################################################
                     [1m Learning iteration 254/3000 [0m                      

                       Computation: 91582 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.1992
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5579
                     Learning rate: 0.0003
                       Mean reward: 0.20
               Mean episode length: 57.84
       Episode_Reward/keep_balance: 0.0566
     Episode_Reward/rew_lin_vel_xy: 0.0664
      Episode_Reward/rew_ang_vel_z: 0.1736
    Episode_Reward/pen_base_height: -0.1092
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0069
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0028
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0043
Episode_Reward/pen_flat_orientation: -0.0546
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0079
   Episode_Reward/foot_landing_vel: -0.0079
   Episode_Reward/test_gait_reward: -0.0503
Metrics/base_velocity/error_vel_xy: 0.2759
Metrics/base_velocity/error_vel_yaw: 0.0487
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 75.2083
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 1.07s
                        Total time: 278.22s
                               ETA: 2996.0s

################################################################################
                     [1m Learning iteration 255/3000 [0m                      

                       Computation: 91510 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.2094
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5573
                     Learning rate: 0.0006
                       Mean reward: -0.10
               Mean episode length: 55.69
       Episode_Reward/keep_balance: 0.0559
     Episode_Reward/rew_lin_vel_xy: 0.0585
      Episode_Reward/rew_ang_vel_z: 0.1716
    Episode_Reward/pen_base_height: -0.1090
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0222
   Episode_Reward/pen_joint_torque: -0.0069
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0043
Episode_Reward/pen_flat_orientation: -0.0540
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0081
   Episode_Reward/foot_landing_vel: -0.0079
   Episode_Reward/test_gait_reward: -0.0496
Metrics/base_velocity/error_vel_xy: 0.2831
Metrics/base_velocity/error_vel_yaw: 0.0478
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 70.9167
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 1.07s
                        Total time: 279.29s
                               ETA: 2994.7s

################################################################################
                     [1m Learning iteration 256/3000 [0m                      

                       Computation: 91296 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 0.2248
                    Surrogate loss: 0.0004
             Mean action noise std: 0.5573
                     Learning rate: 0.0009
                       Mean reward: 0.05
               Mean episode length: 57.19
       Episode_Reward/keep_balance: 0.0565
     Episode_Reward/rew_lin_vel_xy: 0.0623
      Episode_Reward/rew_ang_vel_z: 0.1730
    Episode_Reward/pen_base_height: -0.1101
      Episode_Reward/pen_lin_vel_z: -0.0119
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0071
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0043
Episode_Reward/pen_flat_orientation: -0.0553
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0082
   Episode_Reward/foot_landing_vel: -0.0081
   Episode_Reward/test_gait_reward: -0.0501
Metrics/base_velocity/error_vel_xy: 0.2812
Metrics/base_velocity/error_vel_yaw: 0.0491
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 70.9583
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 1.08s
                        Total time: 280.37s
                               ETA: 2993.5s

################################################################################
                     [1m Learning iteration 257/3000 [0m                      

                       Computation: 92773 steps/s (collection: 0.936s, learning 0.124s)
               Value function loss: 0.2369
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5578
                     Learning rate: 0.0009
                       Mean reward: -0.13
               Mean episode length: 55.35
       Episode_Reward/keep_balance: 0.0567
     Episode_Reward/rew_lin_vel_xy: 0.0607
      Episode_Reward/rew_ang_vel_z: 0.1735
    Episode_Reward/pen_base_height: -0.1093
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0071
    Episode_Reward/pen_joint_accel: -0.0052
    Episode_Reward/pen_action_rate: -0.0018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0020
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0043
Episode_Reward/pen_flat_orientation: -0.0547
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0083
   Episode_Reward/foot_landing_vel: -0.0082
   Episode_Reward/test_gait_reward: -0.0503
Metrics/base_velocity/error_vel_xy: 0.2808
Metrics/base_velocity/error_vel_yaw: 0.0487
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 73.3333
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 1.06s
                        Total time: 281.43s
                               ETA: 2992.1s

################################################################################
                     [1m Learning iteration 258/3000 [0m                      

                       Computation: 91940 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 0.2537
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5568
                     Learning rate: 0.0004
                       Mean reward: 0.46
               Mean episode length: 61.46
       Episode_Reward/keep_balance: 0.0580
     Episode_Reward/rew_lin_vel_xy: 0.0664
      Episode_Reward/rew_ang_vel_z: 0.1781
    Episode_Reward/pen_base_height: -0.1095
      Episode_Reward/pen_lin_vel_z: -0.0120
     Episode_Reward/pen_ang_vel_xy: -0.0223
   Episode_Reward/pen_joint_torque: -0.0073
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0029
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0044
Episode_Reward/pen_flat_orientation: -0.0555
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0085
   Episode_Reward/foot_landing_vel: -0.0082
   Episode_Reward/test_gait_reward: -0.0513
Metrics/base_velocity/error_vel_xy: 0.2865
Metrics/base_velocity/error_vel_yaw: 0.0496
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 67.4167
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 1.07s
                        Total time: 282.50s
                               ETA: 2990.8s

################################################################################
                     [1m Learning iteration 259/3000 [0m                      

                       Computation: 92219 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 0.2453
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5560
                     Learning rate: 0.0003
                       Mean reward: -0.03
               Mean episode length: 58.89
       Episode_Reward/keep_balance: 0.0577
     Episode_Reward/rew_lin_vel_xy: 0.0665
      Episode_Reward/rew_ang_vel_z: 0.1764
    Episode_Reward/pen_base_height: -0.1098
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0073
    Episode_Reward/pen_joint_accel: -0.0054
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0044
Episode_Reward/pen_flat_orientation: -0.0555
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0087
   Episode_Reward/foot_landing_vel: -0.0083
   Episode_Reward/test_gait_reward: -0.0508
Metrics/base_velocity/error_vel_xy: 0.2844
Metrics/base_velocity/error_vel_yaw: 0.0499
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 73.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 1.07s
                        Total time: 283.56s
                               ETA: 2989.4s

################################################################################
                     [1m Learning iteration 260/3000 [0m                      

                       Computation: 91176 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.2657
                    Surrogate loss: -0.0027
             Mean action noise std: 0.5557
                     Learning rate: 0.0006
                       Mean reward: 0.28
               Mean episode length: 59.21
       Episode_Reward/keep_balance: 0.0583
     Episode_Reward/rew_lin_vel_xy: 0.0645
      Episode_Reward/rew_ang_vel_z: 0.1777
    Episode_Reward/pen_base_height: -0.1110
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0074
    Episode_Reward/pen_joint_accel: -0.0056
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0044
Episode_Reward/pen_flat_orientation: -0.0569
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0087
   Episode_Reward/foot_landing_vel: -0.0083
   Episode_Reward/test_gait_reward: -0.0512
Metrics/base_velocity/error_vel_xy: 0.2886
Metrics/base_velocity/error_vel_yaw: 0.0506
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 65.5417
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 1.08s
                        Total time: 284.64s
                               ETA: 2988.2s

################################################################################
                     [1m Learning iteration 261/3000 [0m                      

                       Computation: 92622 steps/s (collection: 0.940s, learning 0.121s)
               Value function loss: 0.2463
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5559
                     Learning rate: 0.0004
                       Mean reward: 0.21
               Mean episode length: 58.84
       Episode_Reward/keep_balance: 0.0589
     Episode_Reward/rew_lin_vel_xy: 0.0723
      Episode_Reward/rew_ang_vel_z: 0.1787
    Episode_Reward/pen_base_height: -0.1119
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0075
    Episode_Reward/pen_joint_accel: -0.0057
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0030
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0045
Episode_Reward/pen_flat_orientation: -0.0581
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0090
   Episode_Reward/foot_landing_vel: -0.0085
   Episode_Reward/test_gait_reward: -0.0516
Metrics/base_velocity/error_vel_xy: 0.2844
Metrics/base_velocity/error_vel_yaw: 0.0524
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 70.0000
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 1.06s
                        Total time: 285.70s
                               ETA: 2986.8s

################################################################################
                     [1m Learning iteration 262/3000 [0m                      

                       Computation: 93367 steps/s (collection: 0.930s, learning 0.123s)
               Value function loss: 0.2754
                    Surrogate loss: -0.0021
             Mean action noise std: 0.5561
                     Learning rate: 0.0009
                       Mean reward: 0.08
               Mean episode length: 58.63
       Episode_Reward/keep_balance: 0.0598
     Episode_Reward/rew_lin_vel_xy: 0.0682
      Episode_Reward/rew_ang_vel_z: 0.1823
    Episode_Reward/pen_base_height: -0.1111
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0076
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0021
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0045
Episode_Reward/pen_flat_orientation: -0.0567
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0092
   Episode_Reward/foot_landing_vel: -0.0086
   Episode_Reward/test_gait_reward: -0.0522
Metrics/base_velocity/error_vel_xy: 0.2916
Metrics/base_velocity/error_vel_yaw: 0.0522
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 68.5000
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 1.05s
                        Total time: 286.75s
                               ETA: 2985.3s

################################################################################
                     [1m Learning iteration 263/3000 [0m                      

                       Computation: 93305 steps/s (collection: 0.931s, learning 0.122s)
               Value function loss: 0.3095
                    Surrogate loss: -0.0024
             Mean action noise std: 0.5564
                     Learning rate: 0.0019
                       Mean reward: -0.04
               Mean episode length: 58.94
       Episode_Reward/keep_balance: 0.0597
     Episode_Reward/rew_lin_vel_xy: 0.0699
      Episode_Reward/rew_ang_vel_z: 0.1815
    Episode_Reward/pen_base_height: -0.1106
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0077
    Episode_Reward/pen_joint_accel: -0.0055
    Episode_Reward/pen_action_rate: -0.0019
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0045
Episode_Reward/pen_flat_orientation: -0.0573
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0093
   Episode_Reward/foot_landing_vel: -0.0086
   Episode_Reward/test_gait_reward: -0.0524
Metrics/base_velocity/error_vel_xy: 0.2890
Metrics/base_velocity/error_vel_yaw: 0.0523
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 66.7500
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 1.05s
                        Total time: 287.81s
                               ETA: 2983.8s

################################################################################
                     [1m Learning iteration 264/3000 [0m                      

                       Computation: 91591 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.3384
                    Surrogate loss: -0.0028
             Mean action noise std: 0.5571
                     Learning rate: 0.0029
                       Mean reward: 0.24
               Mean episode length: 58.34
       Episode_Reward/keep_balance: 0.0604
     Episode_Reward/rew_lin_vel_xy: 0.0718
      Episode_Reward/rew_ang_vel_z: 0.1831
    Episode_Reward/pen_base_height: -0.1122
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0077
    Episode_Reward/pen_joint_accel: -0.0059
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0045
Episode_Reward/pen_flat_orientation: -0.0580
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0093
   Episode_Reward/foot_landing_vel: -0.0086
   Episode_Reward/test_gait_reward: -0.0530
Metrics/base_velocity/error_vel_xy: 0.2924
Metrics/base_velocity/error_vel_yaw: 0.0536
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 68.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 1.07s
                        Total time: 288.88s
                               ETA: 2982.6s

################################################################################
                     [1m Learning iteration 265/3000 [0m                      

                       Computation: 91920 steps/s (collection: 0.943s, learning 0.126s)
               Value function loss: 0.3953
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5570
                     Learning rate: 0.0013
                       Mean reward: 0.17
               Mean episode length: 59.82
       Episode_Reward/keep_balance: 0.0606
     Episode_Reward/rew_lin_vel_xy: 0.0700
      Episode_Reward/rew_ang_vel_z: 0.1836
    Episode_Reward/pen_base_height: -0.1117
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0079
    Episode_Reward/pen_joint_accel: -0.0058
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0046
Episode_Reward/pen_flat_orientation: -0.0582
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0093
   Episode_Reward/foot_landing_vel: -0.0085
   Episode_Reward/test_gait_reward: -0.0533
Metrics/base_velocity/error_vel_xy: 0.2905
Metrics/base_velocity/error_vel_yaw: 0.0536
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 66.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 1.07s
                        Total time: 289.95s
                               ETA: 2981.3s

################################################################################
                     [1m Learning iteration 266/3000 [0m                      

                       Computation: 91988 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 0.3301
                    Surrogate loss: 0.0011
             Mean action noise std: 0.5561
                     Learning rate: 0.0009
                       Mean reward: 0.13
               Mean episode length: 61.43
       Episode_Reward/keep_balance: 0.0605
     Episode_Reward/rew_lin_vel_xy: 0.0692
      Episode_Reward/rew_ang_vel_z: 0.1831
    Episode_Reward/pen_base_height: -0.1125
      Episode_Reward/pen_lin_vel_z: -0.0123
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0078
    Episode_Reward/pen_joint_accel: -0.0058
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0031
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0046
Episode_Reward/pen_flat_orientation: -0.0586
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0096
   Episode_Reward/foot_landing_vel: -0.0086
   Episode_Reward/test_gait_reward: -0.0532
Metrics/base_velocity/error_vel_xy: 0.2929
Metrics/base_velocity/error_vel_yaw: 0.0538
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 66.7917
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 1.07s
                        Total time: 291.02s
                               ETA: 2980.0s

################################################################################
                     [1m Learning iteration 267/3000 [0m                      

                       Computation: 91041 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.2703
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5560
                     Learning rate: 0.0009
                       Mean reward: 0.00
               Mean episode length: 60.57
       Episode_Reward/keep_balance: 0.0614
     Episode_Reward/rew_lin_vel_xy: 0.0733
      Episode_Reward/rew_ang_vel_z: 0.1867
    Episode_Reward/pen_base_height: -0.1124
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0080
    Episode_Reward/pen_joint_accel: -0.0058
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0047
Episode_Reward/pen_flat_orientation: -0.0589
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0096
   Episode_Reward/foot_landing_vel: -0.0088
   Episode_Reward/test_gait_reward: -0.0537
Metrics/base_velocity/error_vel_xy: 0.2971
Metrics/base_velocity/error_vel_yaw: 0.0540
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 66.3750
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 1.08s
                        Total time: 292.10s
                               ETA: 2978.8s

################################################################################
                     [1m Learning iteration 268/3000 [0m                      

                       Computation: 91303 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.2813
                    Surrogate loss: 0.0000
             Mean action noise std: 0.5563
                     Learning rate: 0.0009
                       Mean reward: 0.55
               Mean episode length: 64.22
       Episode_Reward/keep_balance: 0.0622
     Episode_Reward/rew_lin_vel_xy: 0.0707
      Episode_Reward/rew_ang_vel_z: 0.1886
    Episode_Reward/pen_base_height: -0.1133
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0083
    Episode_Reward/pen_joint_accel: -0.0061
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0047
Episode_Reward/pen_flat_orientation: -0.0599
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0099
   Episode_Reward/foot_landing_vel: -0.0090
   Episode_Reward/test_gait_reward: -0.0540
Metrics/base_velocity/error_vel_xy: 0.3001
Metrics/base_velocity/error_vel_yaw: 0.0550
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 64.8750
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 1.08s
                        Total time: 293.18s
                               ETA: 2977.5s

################################################################################
                     [1m Learning iteration 269/3000 [0m                      

                       Computation: 91522 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 0.2688
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5568
                     Learning rate: 0.0013
                       Mean reward: 0.25
               Mean episode length: 59.14
       Episode_Reward/keep_balance: 0.0620
     Episode_Reward/rew_lin_vel_xy: 0.0760
      Episode_Reward/rew_ang_vel_z: 0.1883
    Episode_Reward/pen_base_height: -0.1142
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0082
    Episode_Reward/pen_joint_accel: -0.0059
    Episode_Reward/pen_action_rate: -0.0020
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0047
Episode_Reward/pen_flat_orientation: -0.0603
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0098
   Episode_Reward/foot_landing_vel: -0.0091
   Episode_Reward/test_gait_reward: -0.0542
Metrics/base_velocity/error_vel_xy: 0.2959
Metrics/base_velocity/error_vel_yaw: 0.0547
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 65.9167
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 1.07s
                        Total time: 294.25s
                               ETA: 2976.3s

################################################################################
                     [1m Learning iteration 270/3000 [0m                      

                       Computation: 90967 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.3084
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5563
                     Learning rate: 0.0009
                       Mean reward: 0.54
               Mean episode length: 62.38
       Episode_Reward/keep_balance: 0.0628
     Episode_Reward/rew_lin_vel_xy: 0.0748
      Episode_Reward/rew_ang_vel_z: 0.1906
    Episode_Reward/pen_base_height: -0.1147
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0085
    Episode_Reward/pen_joint_accel: -0.0061
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0048
Episode_Reward/pen_flat_orientation: -0.0602
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0100
   Episode_Reward/foot_landing_vel: -0.0092
   Episode_Reward/test_gait_reward: -0.0553
Metrics/base_velocity/error_vel_xy: 0.2998
Metrics/base_velocity/error_vel_yaw: 0.0562
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 65.4167
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 1.08s
                        Total time: 295.33s
                               ETA: 2975.1s

################################################################################
                     [1m Learning iteration 271/3000 [0m                      

                       Computation: 90165 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.2562
                    Surrogate loss: -0.0000
             Mean action noise std: 0.5563
                     Learning rate: 0.0004
                       Mean reward: 0.16
               Mean episode length: 62.37
       Episode_Reward/keep_balance: 0.0628
     Episode_Reward/rew_lin_vel_xy: 0.0767
      Episode_Reward/rew_ang_vel_z: 0.1908
    Episode_Reward/pen_base_height: -0.1141
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0084
    Episode_Reward/pen_joint_accel: -0.0059
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0048
Episode_Reward/pen_flat_orientation: -0.0600
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0096
   Episode_Reward/foot_landing_vel: -0.0091
   Episode_Reward/test_gait_reward: -0.0544
Metrics/base_velocity/error_vel_xy: 0.3008
Metrics/base_velocity/error_vel_yaw: 0.0553
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 65.7083
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 1.09s
                        Total time: 296.42s
                               ETA: 2974.0s

################################################################################
                     [1m Learning iteration 272/3000 [0m                      

                       Computation: 90688 steps/s (collection: 0.956s, learning 0.128s)
               Value function loss: 0.2545
                    Surrogate loss: -0.0022
             Mean action noise std: 0.5569
                     Learning rate: 0.0009
                       Mean reward: 0.51
               Mean episode length: 62.16
       Episode_Reward/keep_balance: 0.0624
     Episode_Reward/rew_lin_vel_xy: 0.0720
      Episode_Reward/rew_ang_vel_z: 0.1901
    Episode_Reward/pen_base_height: -0.1147
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0084
    Episode_Reward/pen_joint_accel: -0.0061
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0047
Episode_Reward/pen_flat_orientation: -0.0607
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0098
   Episode_Reward/foot_landing_vel: -0.0090
   Episode_Reward/test_gait_reward: -0.0549
Metrics/base_velocity/error_vel_xy: 0.2997
Metrics/base_velocity/error_vel_yaw: 0.0548
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 64.7500
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 1.08s
                        Total time: 297.50s
                               ETA: 2972.9s

################################################################################
                     [1m Learning iteration 273/3000 [0m                      

                       Computation: 91752 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 0.2962
                    Surrogate loss: 0.0003
             Mean action noise std: 0.5573
                     Learning rate: 0.0006
                       Mean reward: 0.56
               Mean episode length: 63.41
       Episode_Reward/keep_balance: 0.0623
     Episode_Reward/rew_lin_vel_xy: 0.0704
      Episode_Reward/rew_ang_vel_z: 0.1887
    Episode_Reward/pen_base_height: -0.1142
      Episode_Reward/pen_lin_vel_z: -0.0121
     Episode_Reward/pen_ang_vel_xy: -0.0225
   Episode_Reward/pen_joint_torque: -0.0083
    Episode_Reward/pen_joint_accel: -0.0061
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0022
   Episode_Reward/pen_joint_powers: -0.0032
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0048
Episode_Reward/pen_flat_orientation: -0.0598
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0099
   Episode_Reward/foot_landing_vel: -0.0090
   Episode_Reward/test_gait_reward: -0.0545
Metrics/base_velocity/error_vel_xy: 0.3031
Metrics/base_velocity/error_vel_yaw: 0.0553
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 64.2500
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 1.07s
                        Total time: 298.58s
                               ETA: 2971.6s

################################################################################
                     [1m Learning iteration 274/3000 [0m                      

                       Computation: 91084 steps/s (collection: 0.954s, learning 0.125s)
               Value function loss: 0.2897
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5580
                     Learning rate: 0.0009
                       Mean reward: 0.33
               Mean episode length: 63.83
       Episode_Reward/keep_balance: 0.0631
     Episode_Reward/rew_lin_vel_xy: 0.0785
      Episode_Reward/rew_ang_vel_z: 0.1913
    Episode_Reward/pen_base_height: -0.1151
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0084
    Episode_Reward/pen_joint_accel: -0.0062
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0048
Episode_Reward/pen_flat_orientation: -0.0615
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0097
   Episode_Reward/foot_landing_vel: -0.0091
   Episode_Reward/test_gait_reward: -0.0555
Metrics/base_velocity/error_vel_xy: 0.2972
Metrics/base_velocity/error_vel_yaw: 0.0558
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 64.5417
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 1.08s
                        Total time: 299.66s
                               ETA: 2970.4s

################################################################################
                     [1m Learning iteration 275/3000 [0m                      

                       Computation: 90021 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 0.2827
                    Surrogate loss: 0.0048
             Mean action noise std: 0.5585
                     Learning rate: 0.0002
                       Mean reward: 0.39
               Mean episode length: 63.11
       Episode_Reward/keep_balance: 0.0644
     Episode_Reward/rew_lin_vel_xy: 0.0772
      Episode_Reward/rew_ang_vel_z: 0.1957
    Episode_Reward/pen_base_height: -0.1155
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0224
   Episode_Reward/pen_joint_torque: -0.0086
    Episode_Reward/pen_joint_accel: -0.0060
    Episode_Reward/pen_action_rate: -0.0021
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0033
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0049
Episode_Reward/pen_flat_orientation: -0.0617
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0098
   Episode_Reward/foot_landing_vel: -0.0092
   Episode_Reward/test_gait_reward: -0.0567
Metrics/base_velocity/error_vel_xy: 0.3075
Metrics/base_velocity/error_vel_yaw: 0.0568
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 62.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 1.09s
                        Total time: 300.75s
                               ETA: 2969.3s

################################################################################
                     [1m Learning iteration 276/3000 [0m                      

                       Computation: 92384 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 0.2536
                    Surrogate loss: -0.0024
             Mean action noise std: 0.5587
                     Learning rate: 0.0004
                       Mean reward: 0.46
               Mean episode length: 66.94
       Episode_Reward/keep_balance: 0.0645
     Episode_Reward/rew_lin_vel_xy: 0.0820
      Episode_Reward/rew_ang_vel_z: 0.1954
    Episode_Reward/pen_base_height: -0.1143
      Episode_Reward/pen_lin_vel_z: -0.0125
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0087
    Episode_Reward/pen_joint_accel: -0.0063
    Episode_Reward/pen_action_rate: -0.0022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0050
Episode_Reward/pen_flat_orientation: -0.0608
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0104
   Episode_Reward/foot_landing_vel: -0.0093
   Episode_Reward/test_gait_reward: -0.0566
Metrics/base_velocity/error_vel_xy: 0.3027
Metrics/base_velocity/error_vel_yaw: 0.0573
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 61.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 1.06s
                        Total time: 301.81s
                               ETA: 2968.0s

################################################################################
                     [1m Learning iteration 277/3000 [0m                      

                       Computation: 91346 steps/s (collection: 0.952s, learning 0.125s)
               Value function loss: 0.2633
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5587
                     Learning rate: 0.0009
                       Mean reward: 0.40
               Mean episode length: 62.27
       Episode_Reward/keep_balance: 0.0647
     Episode_Reward/rew_lin_vel_xy: 0.0817
      Episode_Reward/rew_ang_vel_z: 0.1964
    Episode_Reward/pen_base_height: -0.1153
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0087
    Episode_Reward/pen_joint_accel: -0.0063
    Episode_Reward/pen_action_rate: -0.0022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0050
Episode_Reward/pen_flat_orientation: -0.0619
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0103
   Episode_Reward/foot_landing_vel: -0.0095
   Episode_Reward/test_gait_reward: -0.0565
Metrics/base_velocity/error_vel_xy: 0.2998
Metrics/base_velocity/error_vel_yaw: 0.0574
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 62.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 1.08s
                        Total time: 302.89s
                               ETA: 2966.8s

################################################################################
                     [1m Learning iteration 278/3000 [0m                      

                       Computation: 91448 steps/s (collection: 0.948s, learning 0.127s)
               Value function loss: 0.3000
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5596
                     Learning rate: 0.0013
                       Mean reward: 0.49
               Mean episode length: 66.97
       Episode_Reward/keep_balance: 0.0660
     Episode_Reward/rew_lin_vel_xy: 0.0831
      Episode_Reward/rew_ang_vel_z: 0.1998
    Episode_Reward/pen_base_height: -0.1161
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0089
    Episode_Reward/pen_joint_accel: -0.0065
    Episode_Reward/pen_action_rate: -0.0022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0024
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0051
Episode_Reward/pen_flat_orientation: -0.0627
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0104
   Episode_Reward/foot_landing_vel: -0.0097
   Episode_Reward/test_gait_reward: -0.0574
Metrics/base_velocity/error_vel_xy: 0.3108
Metrics/base_velocity/error_vel_yaw: 0.0589
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 60.6667
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 1.07s
                        Total time: 303.96s
                               ETA: 2965.5s

################################################################################
                     [1m Learning iteration 279/3000 [0m                      

                       Computation: 92044 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.3254
                    Surrogate loss: 0.0010
             Mean action noise std: 0.5606
                     Learning rate: 0.0006
                       Mean reward: 0.69
               Mean episode length: 67.40
       Episode_Reward/keep_balance: 0.0664
     Episode_Reward/rew_lin_vel_xy: 0.0819
      Episode_Reward/rew_ang_vel_z: 0.2004
    Episode_Reward/pen_base_height: -0.1161
      Episode_Reward/pen_lin_vel_z: -0.0122
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0089
    Episode_Reward/pen_joint_accel: -0.0063
    Episode_Reward/pen_action_rate: -0.0022
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0023
   Episode_Reward/pen_joint_powers: -0.0034
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0052
Episode_Reward/pen_flat_orientation: -0.0626
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0103
   Episode_Reward/foot_landing_vel: -0.0097
   Episode_Reward/test_gait_reward: -0.0583
Metrics/base_velocity/error_vel_xy: 0.3115
Metrics/base_velocity/error_vel_yaw: 0.0597
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 61.7500
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 1.07s
                        Total time: 305.03s
                               ETA: 2964.2s

################################################################################
                     [1m Learning iteration 280/3000 [0m                      

                       Computation: 92151 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 0.3455
                    Surrogate loss: -0.0029
             Mean action noise std: 0.5601
                     Learning rate: 0.0009
                       Mean reward: 0.66
               Mean episode length: 71.39
       Episode_Reward/keep_balance: 0.0665
     Episode_Reward/rew_lin_vel_xy: 0.0809
      Episode_Reward/rew_ang_vel_z: 0.2009
    Episode_Reward/pen_base_height: -0.1163
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0091
    Episode_Reward/pen_joint_accel: -0.0066
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0024
   Episode_Reward/pen_joint_powers: -0.0035
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0052
Episode_Reward/pen_flat_orientation: -0.0623
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0109
   Episode_Reward/foot_landing_vel: -0.0098
   Episode_Reward/test_gait_reward: -0.0585
Metrics/base_velocity/error_vel_xy: 0.3122
Metrics/base_velocity/error_vel_yaw: 0.0591
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 60.8333
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 1.07s
                        Total time: 306.10s
                               ETA: 2962.9s

################################################################################
                     [1m Learning iteration 281/3000 [0m                      

                       Computation: 91278 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.3333
                    Surrogate loss: 0.0012
             Mean action noise std: 0.5594
                     Learning rate: 0.0002
                       Mean reward: 1.20
               Mean episode length: 73.81
       Episode_Reward/keep_balance: 0.0675
     Episode_Reward/rew_lin_vel_xy: 0.0842
      Episode_Reward/rew_ang_vel_z: 0.2036
    Episode_Reward/pen_base_height: -0.1169
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0092
    Episode_Reward/pen_joint_accel: -0.0066
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0024
   Episode_Reward/pen_joint_powers: -0.0035
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0053
Episode_Reward/pen_flat_orientation: -0.0633
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0108
   Episode_Reward/foot_landing_vel: -0.0098
   Episode_Reward/test_gait_reward: -0.0591
Metrics/base_velocity/error_vel_xy: 0.3104
Metrics/base_velocity/error_vel_yaw: 0.0606
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 60.0833
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 1.08s
                        Total time: 307.17s
                               ETA: 2961.7s

################################################################################
                     [1m Learning iteration 282/3000 [0m                      

                       Computation: 91418 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.3247
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5594
                     Learning rate: 0.0002
                       Mean reward: 0.71
               Mean episode length: 67.01
       Episode_Reward/keep_balance: 0.0672
     Episode_Reward/rew_lin_vel_xy: 0.0839
      Episode_Reward/rew_ang_vel_z: 0.2024
    Episode_Reward/pen_base_height: -0.1166
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0092
    Episode_Reward/pen_joint_accel: -0.0065
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0024
   Episode_Reward/pen_joint_powers: -0.0036
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0053
Episode_Reward/pen_flat_orientation: -0.0633
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0109
   Episode_Reward/foot_landing_vel: -0.0099
   Episode_Reward/test_gait_reward: -0.0585
Metrics/base_velocity/error_vel_xy: 0.3115
Metrics/base_velocity/error_vel_yaw: 0.0608
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 58.1250
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 1.08s
                        Total time: 308.25s
                               ETA: 2960.5s

################################################################################
                     [1m Learning iteration 283/3000 [0m                      

                       Computation: 90265 steps/s (collection: 0.964s, learning 0.125s)
               Value function loss: 0.3345
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5595
                     Learning rate: 0.0004
                       Mean reward: 0.20
               Mean episode length: 66.19
       Episode_Reward/keep_balance: 0.0681
     Episode_Reward/rew_lin_vel_xy: 0.0841
      Episode_Reward/rew_ang_vel_z: 0.2063
    Episode_Reward/pen_base_height: -0.1179
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0094
    Episode_Reward/pen_joint_accel: -0.0065
    Episode_Reward/pen_action_rate: -0.0023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0024
   Episode_Reward/pen_joint_powers: -0.0036
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0053
Episode_Reward/pen_flat_orientation: -0.0656
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0109
   Episode_Reward/foot_landing_vel: -0.0101
   Episode_Reward/test_gait_reward: -0.0589
Metrics/base_velocity/error_vel_xy: 0.3159
Metrics/base_velocity/error_vel_yaw: 0.0600
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 56.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 1.09s
                        Total time: 309.34s
                               ETA: 2959.4s

################################################################################
                     [1m Learning iteration 284/3000 [0m                      

                       Computation: 89885 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.3523
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5593
                     Learning rate: 0.0009
                       Mean reward: 0.82
               Mean episode length: 69.15
       Episode_Reward/keep_balance: 0.0693
     Episode_Reward/rew_lin_vel_xy: 0.0882
      Episode_Reward/rew_ang_vel_z: 0.2091
    Episode_Reward/pen_base_height: -0.1192
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0095
    Episode_Reward/pen_joint_accel: -0.0068
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0025
   Episode_Reward/pen_joint_powers: -0.0036
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0054
Episode_Reward/pen_flat_orientation: -0.0673
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0112
   Episode_Reward/foot_landing_vel: -0.0100
   Episode_Reward/test_gait_reward: -0.0604
Metrics/base_velocity/error_vel_xy: 0.3183
Metrics/base_velocity/error_vel_yaw: 0.0624
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 59.3750
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 1.09s
                        Total time: 310.43s
                               ETA: 2958.4s

################################################################################
                     [1m Learning iteration 285/3000 [0m                      

                       Computation: 91618 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.3749
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5590
                     Learning rate: 0.0013
                       Mean reward: 0.99
               Mean episode length: 74.09
       Episode_Reward/keep_balance: 0.0710
     Episode_Reward/rew_lin_vel_xy: 0.0923
      Episode_Reward/rew_ang_vel_z: 0.2137
    Episode_Reward/pen_base_height: -0.1202
      Episode_Reward/pen_lin_vel_z: -0.0124
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0099
    Episode_Reward/pen_joint_accel: -0.0068
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0025
   Episode_Reward/pen_joint_powers: -0.0037
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0056
Episode_Reward/pen_flat_orientation: -0.0678
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0115
   Episode_Reward/foot_landing_vel: -0.0104
   Episode_Reward/test_gait_reward: -0.0615
Metrics/base_velocity/error_vel_xy: 0.3265
Metrics/base_velocity/error_vel_yaw: 0.0642
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 56.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 1.07s
                        Total time: 311.51s
                               ETA: 2957.1s

################################################################################
                     [1m Learning iteration 286/3000 [0m                      

                       Computation: 90978 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 0.4241
                    Surrogate loss: -0.0002
             Mean action noise std: 0.5590
                     Learning rate: 0.0013
                       Mean reward: -0.05
               Mean episode length: 66.09
       Episode_Reward/keep_balance: 0.0706
     Episode_Reward/rew_lin_vel_xy: 0.0869
      Episode_Reward/rew_ang_vel_z: 0.2129
    Episode_Reward/pen_base_height: -0.1192
      Episode_Reward/pen_lin_vel_z: -0.0128
     Episode_Reward/pen_ang_vel_xy: -0.0230
   Episode_Reward/pen_joint_torque: -0.0101
    Episode_Reward/pen_joint_accel: -0.0066
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0026
   Episode_Reward/pen_joint_powers: -0.0038
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0056
Episode_Reward/pen_flat_orientation: -0.0665
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0121
   Episode_Reward/foot_landing_vel: -0.0106
   Episode_Reward/test_gait_reward: -0.0611
Metrics/base_velocity/error_vel_xy: 0.3239
Metrics/base_velocity/error_vel_yaw: 0.0633
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 58.1250
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 1.08s
                        Total time: 312.59s
                               ETA: 2956.0s

################################################################################
                     [1m Learning iteration 287/3000 [0m                      

                       Computation: 91200 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.4335
                    Surrogate loss: 0.0020
             Mean action noise std: 0.5588
                     Learning rate: 0.0006
                       Mean reward: 0.50
               Mean episode length: 70.23
       Episode_Reward/keep_balance: 0.0707
     Episode_Reward/rew_lin_vel_xy: 0.0844
      Episode_Reward/rew_ang_vel_z: 0.2127
    Episode_Reward/pen_base_height: -0.1198
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0099
    Episode_Reward/pen_joint_accel: -0.0069
    Episode_Reward/pen_action_rate: -0.0024
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0026
   Episode_Reward/pen_joint_powers: -0.0038
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0056
Episode_Reward/pen_flat_orientation: -0.0678
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0118
   Episode_Reward/foot_landing_vel: -0.0106
   Episode_Reward/test_gait_reward: -0.0616
Metrics/base_velocity/error_vel_xy: 0.3289
Metrics/base_velocity/error_vel_yaw: 0.0640
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 57.0000
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 1.08s
                        Total time: 313.66s
                               ETA: 2954.8s

################################################################################
                     [1m Learning iteration 288/3000 [0m                      

                       Computation: 92605 steps/s (collection: 0.934s, learning 0.128s)
               Value function loss: 0.4574
                    Surrogate loss: 0.0004
             Mean action noise std: 0.5587
                     Learning rate: 0.0009
                       Mean reward: 0.51
               Mean episode length: 74.12
       Episode_Reward/keep_balance: 0.0713
     Episode_Reward/rew_lin_vel_xy: 0.0943
      Episode_Reward/rew_ang_vel_z: 0.2147
    Episode_Reward/pen_base_height: -0.1207
      Episode_Reward/pen_lin_vel_z: -0.0126
     Episode_Reward/pen_ang_vel_xy: -0.0227
   Episode_Reward/pen_joint_torque: -0.0102
    Episode_Reward/pen_joint_accel: -0.0067
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0026
   Episode_Reward/pen_joint_powers: -0.0038
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0056
Episode_Reward/pen_flat_orientation: -0.0678
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0120
   Episode_Reward/foot_landing_vel: -0.0107
   Episode_Reward/test_gait_reward: -0.0623
Metrics/base_velocity/error_vel_xy: 0.3236
Metrics/base_velocity/error_vel_yaw: 0.0640
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 52.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 1.06s
                        Total time: 314.73s
                               ETA: 2953.4s

################################################################################
                     [1m Learning iteration 289/3000 [0m                      

                       Computation: 90384 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 0.5484
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5592
                     Learning rate: 0.0013
                       Mean reward: 0.41
               Mean episode length: 68.85
       Episode_Reward/keep_balance: 0.0719
     Episode_Reward/rew_lin_vel_xy: 0.0911
      Episode_Reward/rew_ang_vel_z: 0.2163
    Episode_Reward/pen_base_height: -0.1208
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0231
   Episode_Reward/pen_joint_torque: -0.0103
    Episode_Reward/pen_joint_accel: -0.0071
    Episode_Reward/pen_action_rate: -0.0025
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0027
   Episode_Reward/pen_joint_powers: -0.0039
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0057
Episode_Reward/pen_flat_orientation: -0.0690
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0127
   Episode_Reward/foot_landing_vel: -0.0109
   Episode_Reward/test_gait_reward: -0.0624
Metrics/base_velocity/error_vel_xy: 0.3298
Metrics/base_velocity/error_vel_yaw: 0.0649
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 53.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 1.09s
                        Total time: 315.81s
                               ETA: 2952.3s

################################################################################
                     [1m Learning iteration 290/3000 [0m                      

                       Computation: 92014 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.5228
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5585
                     Learning rate: 0.0019
                       Mean reward: 0.63
               Mean episode length: 73.79
       Episode_Reward/keep_balance: 0.0748
     Episode_Reward/rew_lin_vel_xy: 0.1072
      Episode_Reward/rew_ang_vel_z: 0.2241
    Episode_Reward/pen_base_height: -0.1249
      Episode_Reward/pen_lin_vel_z: -0.0129
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0106
    Episode_Reward/pen_joint_accel: -0.0074
    Episode_Reward/pen_action_rate: -0.0026
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0027
   Episode_Reward/pen_joint_powers: -0.0040
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0060
Episode_Reward/pen_flat_orientation: -0.0733
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.0127
   Episode_Reward/foot_landing_vel: -0.0111
   Episode_Reward/test_gait_reward: -0.0651
Metrics/base_velocity/error_vel_xy: 0.3260
Metrics/base_velocity/error_vel_yaw: 0.0687
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 56.0417
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 1.07s
                        Total time: 316.88s
                               ETA: 2951.0s

################################################################################
                     [1m Learning iteration 291/3000 [0m                      

                       Computation: 91634 steps/s (collection: 0.947s, learning 0.126s)
               Value function loss: 0.4837
                    Surrogate loss: 0.0067
             Mean action noise std: 0.5586
                     Learning rate: 0.0004
                       Mean reward: 0.94
               Mean episode length: 72.65
       Episode_Reward/keep_balance: 0.0768
     Episode_Reward/rew_lin_vel_xy: 0.1056
      Episode_Reward/rew_ang_vel_z: 0.2295
    Episode_Reward/pen_base_height: -0.1270
      Episode_Reward/pen_lin_vel_z: -0.0131
     Episode_Reward/pen_ang_vel_xy: -0.0229
   Episode_Reward/pen_joint_torque: -0.0112
    Episode_Reward/pen_joint_accel: -0.0075
    Episode_Reward/pen_action_rate: -0.0027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0028
   Episode_Reward/pen_joint_powers: -0.0042
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0061
Episode_Reward/pen_flat_orientation: -0.0760
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0132
   Episode_Reward/foot_landing_vel: -0.0116
   Episode_Reward/test_gait_reward: -0.0667
Metrics/base_velocity/error_vel_xy: 0.3363
Metrics/base_velocity/error_vel_yaw: 0.0715
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 56.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 1.07s
                        Total time: 317.95s
                               ETA: 2949.8s

################################################################################
                     [1m Learning iteration 292/3000 [0m                      

                       Computation: 92597 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 0.3984
                    Surrogate loss: 0.0017
             Mean action noise std: 0.5582
                     Learning rate: 0.0003
                       Mean reward: 0.91
               Mean episode length: 76.52
       Episode_Reward/keep_balance: 0.0742
     Episode_Reward/rew_lin_vel_xy: 0.0985
      Episode_Reward/rew_ang_vel_z: 0.2225
    Episode_Reward/pen_base_height: -0.1243
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0228
   Episode_Reward/pen_joint_torque: -0.0107
    Episode_Reward/pen_joint_accel: -0.0072
    Episode_Reward/pen_action_rate: -0.0026
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0027
   Episode_Reward/pen_joint_powers: -0.0040
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0059
Episode_Reward/pen_flat_orientation: -0.0720
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0123
   Episode_Reward/foot_landing_vel: -0.0110
   Episode_Reward/test_gait_reward: -0.0652
Metrics/base_velocity/error_vel_xy: 0.3347
Metrics/base_velocity/error_vel_yaw: 0.0681
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 51.3333
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 1.06s
                        Total time: 319.02s
                               ETA: 2948.4s

################################################################################
                     [1m Learning iteration 293/3000 [0m                      

                       Computation: 91342 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.3848
                    Surrogate loss: 0.0002
             Mean action noise std: 0.5582
                     Learning rate: 0.0004
                       Mean reward: 0.83
               Mean episode length: 74.86
       Episode_Reward/keep_balance: 0.0750
     Episode_Reward/rew_lin_vel_xy: 0.0909
      Episode_Reward/rew_ang_vel_z: 0.2244
    Episode_Reward/pen_base_height: -0.1241
      Episode_Reward/pen_lin_vel_z: -0.0127
     Episode_Reward/pen_ang_vel_xy: -0.0226
   Episode_Reward/pen_joint_torque: -0.0108
    Episode_Reward/pen_joint_accel: -0.0069
    Episode_Reward/pen_action_rate: -0.0026
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0027
   Episode_Reward/pen_joint_powers: -0.0040
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0059
Episode_Reward/pen_flat_orientation: -0.0718
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0125
   Episode_Reward/foot_landing_vel: -0.0113
   Episode_Reward/test_gait_reward: -0.0658
Metrics/base_velocity/error_vel_xy: 0.3396
Metrics/base_velocity/error_vel_yaw: 0.0691
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 52.0417
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 1.08s
                        Total time: 320.09s
                               ETA: 2947.2s

################################################################################
                     [1m Learning iteration 294/3000 [0m                      

                       Computation: 91597 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.3586
                    Surrogate loss: -0.0019
             Mean action noise std: 0.5584
                     Learning rate: 0.0006
                       Mean reward: 0.92
               Mean episode length: 81.14
       Episode_Reward/keep_balance: 0.0757
     Episode_Reward/rew_lin_vel_xy: 0.0992
      Episode_Reward/rew_ang_vel_z: 0.2254
    Episode_Reward/pen_base_height: -0.1241
      Episode_Reward/pen_lin_vel_z: -0.0133
     Episode_Reward/pen_ang_vel_xy: -0.0235
   Episode_Reward/pen_joint_torque: -0.0113
    Episode_Reward/pen_joint_accel: -0.0074
    Episode_Reward/pen_action_rate: -0.0027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0028
   Episode_Reward/pen_joint_powers: -0.0042
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0060
Episode_Reward/pen_flat_orientation: -0.0720
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0139
   Episode_Reward/foot_landing_vel: -0.0117
   Episode_Reward/test_gait_reward: -0.0661
Metrics/base_velocity/error_vel_xy: 0.3381
Metrics/base_velocity/error_vel_yaw: 0.0710
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 51.5417
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 1.07s
                        Total time: 321.17s
                               ETA: 2946.0s

################################################################################
                     [1m Learning iteration 295/3000 [0m                      

                       Computation: 92449 steps/s (collection: 0.942s, learning 0.121s)
               Value function loss: 0.3839
                    Surrogate loss: 0.0014
             Mean action noise std: 0.5590
                     Learning rate: 0.0004
                       Mean reward: 1.45
               Mean episode length: 81.73
       Episode_Reward/keep_balance: 0.0772
     Episode_Reward/rew_lin_vel_xy: 0.0971
      Episode_Reward/rew_ang_vel_z: 0.2329
    Episode_Reward/pen_base_height: -0.1227
      Episode_Reward/pen_lin_vel_z: -0.0133
     Episode_Reward/pen_ang_vel_xy: -0.0235
   Episode_Reward/pen_joint_torque: -0.0113
    Episode_Reward/pen_joint_accel: -0.0073
    Episode_Reward/pen_action_rate: -0.0027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0028
   Episode_Reward/pen_joint_powers: -0.0042
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0061
Episode_Reward/pen_flat_orientation: -0.0692
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0135
   Episode_Reward/foot_landing_vel: -0.0115
   Episode_Reward/test_gait_reward: -0.0671
Metrics/base_velocity/error_vel_xy: 0.3476
Metrics/base_velocity/error_vel_yaw: 0.0699
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 57.2500
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 1.06s
                        Total time: 322.23s
                               ETA: 2944.7s

################################################################################
                     [1m Learning iteration 296/3000 [0m                      

                       Computation: 92927 steps/s (collection: 0.936s, learning 0.122s)
               Value function loss: 0.4147
                    Surrogate loss: -0.0019
             Mean action noise std: 0.5594
                     Learning rate: 0.0006
                       Mean reward: 1.08
               Mean episode length: 76.99
       Episode_Reward/keep_balance: 0.0761
     Episode_Reward/rew_lin_vel_xy: 0.1003
      Episode_Reward/rew_ang_vel_z: 0.2292
    Episode_Reward/pen_base_height: -0.1213
      Episode_Reward/pen_lin_vel_z: -0.0133
     Episode_Reward/pen_ang_vel_xy: -0.0236
   Episode_Reward/pen_joint_torque: -0.0112
    Episode_Reward/pen_joint_accel: -0.0075
    Episode_Reward/pen_action_rate: -0.0027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0028
   Episode_Reward/pen_joint_powers: -0.0042
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0060
Episode_Reward/pen_flat_orientation: -0.0687
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0137
   Episode_Reward/foot_landing_vel: -0.0114
   Episode_Reward/test_gait_reward: -0.0667
Metrics/base_velocity/error_vel_xy: 0.3453
Metrics/base_velocity/error_vel_yaw: 0.0690
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 53.5000
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 1.06s
                        Total time: 323.29s
                               ETA: 2943.3s

################################################################################
                     [1m Learning iteration 297/3000 [0m                      

                       Computation: 92956 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 0.4013
                    Surrogate loss: -0.0035
             Mean action noise std: 0.5593
                     Learning rate: 0.0013
                       Mean reward: 0.86
               Mean episode length: 78.68
       Episode_Reward/keep_balance: 0.0770
     Episode_Reward/rew_lin_vel_xy: 0.0972
      Episode_Reward/rew_ang_vel_z: 0.2308
    Episode_Reward/pen_base_height: -0.1230
      Episode_Reward/pen_lin_vel_z: -0.0134
     Episode_Reward/pen_ang_vel_xy: -0.0234
   Episode_Reward/pen_joint_torque: -0.0112
    Episode_Reward/pen_joint_accel: -0.0074
    Episode_Reward/pen_action_rate: -0.0027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0029
   Episode_Reward/pen_joint_powers: -0.0042
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0061
Episode_Reward/pen_flat_orientation: -0.0697
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0137
   Episode_Reward/foot_landing_vel: -0.0116
   Episode_Reward/test_gait_reward: -0.0675
Metrics/base_velocity/error_vel_xy: 0.3501
Metrics/base_velocity/error_vel_yaw: 0.0708
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 51.7083
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 1.06s
                        Total time: 324.34s
                               ETA: 2942.0s

################################################################################
                     [1m Learning iteration 298/3000 [0m                      

                       Computation: 93915 steps/s (collection: 0.925s, learning 0.122s)
               Value function loss: 0.6114
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5588
                     Learning rate: 0.0029
                       Mean reward: 0.62
               Mean episode length: 74.11
       Episode_Reward/keep_balance: 0.0766
     Episode_Reward/rew_lin_vel_xy: 0.0982
      Episode_Reward/rew_ang_vel_z: 0.2305
    Episode_Reward/pen_base_height: -0.1225
      Episode_Reward/pen_lin_vel_z: -0.0135
     Episode_Reward/pen_ang_vel_xy: -0.0235
   Episode_Reward/pen_joint_torque: -0.0114
    Episode_Reward/pen_joint_accel: -0.0072
    Episode_Reward/pen_action_rate: -0.0027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0029
   Episode_Reward/pen_joint_powers: -0.0043
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0061
Episode_Reward/pen_flat_orientation: -0.0676
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0139
   Episode_Reward/foot_landing_vel: -0.0116
   Episode_Reward/test_gait_reward: -0.0677
Metrics/base_velocity/error_vel_xy: 0.3450
Metrics/base_velocity/error_vel_yaw: 0.0692
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 53.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 1.05s
                        Total time: 325.39s
                               ETA: 2940.5s

################################################################################
                     [1m Learning iteration 299/3000 [0m                      

                       Computation: 92453 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 0.6531
                    Surrogate loss: 0.0031
             Mean action noise std: 0.5583
                     Learning rate: 0.0009
                       Mean reward: 0.99
               Mean episode length: 77.19
       Episode_Reward/keep_balance: 0.0759
     Episode_Reward/rew_lin_vel_xy: 0.0994
      Episode_Reward/rew_ang_vel_z: 0.2280
    Episode_Reward/pen_base_height: -0.1220
      Episode_Reward/pen_lin_vel_z: -0.0133
     Episode_Reward/pen_ang_vel_xy: -0.0234
   Episode_Reward/pen_joint_torque: -0.0109
    Episode_Reward/pen_joint_accel: -0.0069
    Episode_Reward/pen_action_rate: -0.0027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0028
   Episode_Reward/pen_joint_powers: -0.0041
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0060
Episode_Reward/pen_flat_orientation: -0.0680
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0133
   Episode_Reward/foot_landing_vel: -0.0112
   Episode_Reward/test_gait_reward: -0.0674
Metrics/base_velocity/error_vel_xy: 0.3432
Metrics/base_velocity/error_vel_yaw: 0.0687
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 51.9583
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 1.06s
                        Total time: 326.45s
                               ETA: 2939.2s

################################################################################
                     [1m Learning iteration 300/3000 [0m                      

                       Computation: 92925 steps/s (collection: 0.935s, learning 0.123s)
               Value function loss: 0.4880
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5584
                     Learning rate: 0.0013
                       Mean reward: 0.79
               Mean episode length: 79.47
       Episode_Reward/keep_balance: 0.0774
     Episode_Reward/rew_lin_vel_xy: 0.1029
      Episode_Reward/rew_ang_vel_z: 0.2318
    Episode_Reward/pen_base_height: -0.1248
      Episode_Reward/pen_lin_vel_z: -0.0134
     Episode_Reward/pen_ang_vel_xy: -0.0236
   Episode_Reward/pen_joint_torque: -0.0113
    Episode_Reward/pen_joint_accel: -0.0076
    Episode_Reward/pen_action_rate: -0.0028
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0029
   Episode_Reward/pen_joint_powers: -0.0043
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0063
Episode_Reward/pen_flat_orientation: -0.0710
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0141
   Episode_Reward/foot_landing_vel: -0.0117
   Episode_Reward/test_gait_reward: -0.0686
Metrics/base_velocity/error_vel_xy: 0.3402
Metrics/base_velocity/error_vel_yaw: 0.0703
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 48.2083
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 1.06s
                        Total time: 327.51s
                               ETA: 2937.8s

################################################################################
                     [1m Learning iteration 301/3000 [0m                      

                       Computation: 89355 steps/s (collection: 0.974s, learning 0.126s)
               Value function loss: 0.4569
                    Surrogate loss: 0.0019
             Mean action noise std: 0.5588
                     Learning rate: 0.0006
                       Mean reward: 0.74
               Mean episode length: 78.02
       Episode_Reward/keep_balance: 0.0796
     Episode_Reward/rew_lin_vel_xy: 0.1151
      Episode_Reward/rew_ang_vel_z: 0.2381
    Episode_Reward/pen_base_height: -0.1268
      Episode_Reward/pen_lin_vel_z: -0.0134
     Episode_Reward/pen_ang_vel_xy: -0.0234
   Episode_Reward/pen_joint_torque: -0.0116
    Episode_Reward/pen_joint_accel: -0.0075
    Episode_Reward/pen_action_rate: -0.0028
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0029
   Episode_Reward/pen_joint_powers: -0.0044
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0064
Episode_Reward/pen_flat_orientation: -0.0733
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0140
   Episode_Reward/foot_landing_vel: -0.0116
   Episode_Reward/test_gait_reward: -0.0708
Metrics/base_velocity/error_vel_xy: 0.3419
Metrics/base_velocity/error_vel_yaw: 0.0728
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 52.9583
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 1.10s
                        Total time: 328.61s
                               ETA: 2936.8s

################################################################################
                     [1m Learning iteration 302/3000 [0m                      

                       Computation: 91382 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.4429
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5585
                     Learning rate: 0.0013
                       Mean reward: 1.37
               Mean episode length: 81.93
       Episode_Reward/keep_balance: 0.0805
     Episode_Reward/rew_lin_vel_xy: 0.1124
      Episode_Reward/rew_ang_vel_z: 0.2413
    Episode_Reward/pen_base_height: -0.1267
      Episode_Reward/pen_lin_vel_z: -0.0136
     Episode_Reward/pen_ang_vel_xy: -0.0234
   Episode_Reward/pen_joint_torque: -0.0116
    Episode_Reward/pen_joint_accel: -0.0078
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0030
   Episode_Reward/pen_joint_powers: -0.0044
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0065
Episode_Reward/pen_flat_orientation: -0.0738
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0142
   Episode_Reward/foot_landing_vel: -0.0118
   Episode_Reward/test_gait_reward: -0.0714
Metrics/base_velocity/error_vel_xy: 0.3491
Metrics/base_velocity/error_vel_yaw: 0.0736
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 48.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 1.08s
                        Total time: 329.69s
                               ETA: 2935.6s

################################################################################
                     [1m Learning iteration 303/3000 [0m                      

                       Computation: 91383 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.4205
                    Surrogate loss: 0.0028
             Mean action noise std: 0.5581
                     Learning rate: 0.0006
                       Mean reward: 1.49
               Mean episode length: 84.12
       Episode_Reward/keep_balance: 0.0824
     Episode_Reward/rew_lin_vel_xy: 0.1203
      Episode_Reward/rew_ang_vel_z: 0.2463
    Episode_Reward/pen_base_height: -0.1290
      Episode_Reward/pen_lin_vel_z: -0.0136
     Episode_Reward/pen_ang_vel_xy: -0.0237
   Episode_Reward/pen_joint_torque: -0.0118
    Episode_Reward/pen_joint_accel: -0.0079
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0030
   Episode_Reward/pen_joint_powers: -0.0045
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0067
Episode_Reward/pen_flat_orientation: -0.0756
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0141
   Episode_Reward/foot_landing_vel: -0.0119
   Episode_Reward/test_gait_reward: -0.0734
Metrics/base_velocity/error_vel_xy: 0.3477
Metrics/base_velocity/error_vel_yaw: 0.0760
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 50.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 1.08s
                        Total time: 330.76s
                               ETA: 2934.4s

################################################################################
                     [1m Learning iteration 304/3000 [0m                      

                       Computation: 92160 steps/s (collection: 0.943s, learning 0.123s)
               Value function loss: 0.4090
                    Surrogate loss: 0.0106
             Mean action noise std: 0.5584
                     Learning rate: 0.0001
                       Mean reward: 1.25
               Mean episode length: 82.00
       Episode_Reward/keep_balance: 0.0810
     Episode_Reward/rew_lin_vel_xy: 0.1088
      Episode_Reward/rew_ang_vel_z: 0.2416
    Episode_Reward/pen_base_height: -0.1268
      Episode_Reward/pen_lin_vel_z: -0.0137
     Episode_Reward/pen_ang_vel_xy: -0.0235
   Episode_Reward/pen_joint_torque: -0.0117
    Episode_Reward/pen_joint_accel: -0.0078
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0029
   Episode_Reward/pen_joint_powers: -0.0044
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0066
Episode_Reward/pen_flat_orientation: -0.0742
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0141
   Episode_Reward/foot_landing_vel: -0.0116
   Episode_Reward/test_gait_reward: -0.0726
Metrics/base_velocity/error_vel_xy: 0.3579
Metrics/base_velocity/error_vel_yaw: 0.0749
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 50.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 1.07s
                        Total time: 331.83s
                               ETA: 2933.2s

################################################################################
                     [1m Learning iteration 305/3000 [0m                      

                       Computation: 92470 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 0.4116
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5586
                     Learning rate: 0.0003
                       Mean reward: 1.18
               Mean episode length: 79.85
       Episode_Reward/keep_balance: 0.0804
     Episode_Reward/rew_lin_vel_xy: 0.1074
      Episode_Reward/rew_ang_vel_z: 0.2398
    Episode_Reward/pen_base_height: -0.1261
      Episode_Reward/pen_lin_vel_z: -0.0135
     Episode_Reward/pen_ang_vel_xy: -0.0236
   Episode_Reward/pen_joint_torque: -0.0116
    Episode_Reward/pen_joint_accel: -0.0080
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0029
   Episode_Reward/pen_joint_powers: -0.0044
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0066
Episode_Reward/pen_flat_orientation: -0.0737
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0140
   Episode_Reward/foot_landing_vel: -0.0115
   Episode_Reward/test_gait_reward: -0.0720
Metrics/base_velocity/error_vel_xy: 0.3550
Metrics/base_velocity/error_vel_yaw: 0.0742
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 45.6667
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 1.06s
                        Total time: 332.89s
                               ETA: 2931.9s

################################################################################
                     [1m Learning iteration 306/3000 [0m                      

                       Computation: 92325 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.3957
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5590
                     Learning rate: 0.0009
                       Mean reward: 1.51
               Mean episode length: 84.41
       Episode_Reward/keep_balance: 0.0816
     Episode_Reward/rew_lin_vel_xy: 0.1109
      Episode_Reward/rew_ang_vel_z: 0.2434
    Episode_Reward/pen_base_height: -0.1284
      Episode_Reward/pen_lin_vel_z: -0.0135
     Episode_Reward/pen_ang_vel_xy: -0.0236
   Episode_Reward/pen_joint_torque: -0.0116
    Episode_Reward/pen_joint_accel: -0.0083
    Episode_Reward/pen_action_rate: -0.0029
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0030
   Episode_Reward/pen_joint_powers: -0.0044
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0067
Episode_Reward/pen_flat_orientation: -0.0748
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0144
   Episode_Reward/foot_landing_vel: -0.0118
   Episode_Reward/test_gait_reward: -0.0730
Metrics/base_velocity/error_vel_xy: 0.3574
Metrics/base_velocity/error_vel_yaw: 0.0758
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 47.7500
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 1.06s
                        Total time: 333.96s
                               ETA: 2930.6s

################################################################################
                     [1m Learning iteration 307/3000 [0m                      

                       Computation: 91416 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.4285
                    Surrogate loss: -0.0021
             Mean action noise std: 0.5594
                     Learning rate: 0.0009
                       Mean reward: 1.02
               Mean episode length: 84.68
       Episode_Reward/keep_balance: 0.0839
     Episode_Reward/rew_lin_vel_xy: 0.1191
      Episode_Reward/rew_ang_vel_z: 0.2504
    Episode_Reward/pen_base_height: -0.1296
      Episode_Reward/pen_lin_vel_z: -0.0136
     Episode_Reward/pen_ang_vel_xy: -0.0237
   Episode_Reward/pen_joint_torque: -0.0121
    Episode_Reward/pen_joint_accel: -0.0081
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0030
   Episode_Reward/pen_joint_powers: -0.0046
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0068
Episode_Reward/pen_flat_orientation: -0.0766
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0144
   Episode_Reward/foot_landing_vel: -0.0121
   Episode_Reward/test_gait_reward: -0.0754
Metrics/base_velocity/error_vel_xy: 0.3564
Metrics/base_velocity/error_vel_yaw: 0.0777
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 48.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 1.08s
                        Total time: 335.03s
                               ETA: 2929.4s

################################################################################
                     [1m Learning iteration 308/3000 [0m                      

                       Computation: 92067 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.4729
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5597
                     Learning rate: 0.0006
                       Mean reward: 1.25
               Mean episode length: 85.49
       Episode_Reward/keep_balance: 0.0862
     Episode_Reward/rew_lin_vel_xy: 0.1236
      Episode_Reward/rew_ang_vel_z: 0.2578
    Episode_Reward/pen_base_height: -0.1305
      Episode_Reward/pen_lin_vel_z: -0.0138
     Episode_Reward/pen_ang_vel_xy: -0.0240
   Episode_Reward/pen_joint_torque: -0.0126
    Episode_Reward/pen_joint_accel: -0.0084
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0031
   Episode_Reward/pen_joint_powers: -0.0047
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0070
Episode_Reward/pen_flat_orientation: -0.0782
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0150
   Episode_Reward/foot_landing_vel: -0.0125
   Episode_Reward/test_gait_reward: -0.0773
Metrics/base_velocity/error_vel_xy: 0.3626
Metrics/base_velocity/error_vel_yaw: 0.0794
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 49.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 1.07s
                        Total time: 336.10s
                               ETA: 2928.1s

################################################################################
                     [1m Learning iteration 309/3000 [0m                      

                       Computation: 92716 steps/s (collection: 0.937s, learning 0.123s)
               Value function loss: 0.5386
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5600
                     Learning rate: 0.0013
                       Mean reward: 1.53
               Mean episode length: 83.28
       Episode_Reward/keep_balance: 0.0850
     Episode_Reward/rew_lin_vel_xy: 0.1196
      Episode_Reward/rew_ang_vel_z: 0.2537
    Episode_Reward/pen_base_height: -0.1303
      Episode_Reward/pen_lin_vel_z: -0.0135
     Episode_Reward/pen_ang_vel_xy: -0.0239
   Episode_Reward/pen_joint_torque: -0.0122
    Episode_Reward/pen_joint_accel: -0.0087
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0031
   Episode_Reward/pen_joint_powers: -0.0046
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0069
Episode_Reward/pen_flat_orientation: -0.0770
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0151
   Episode_Reward/foot_landing_vel: -0.0123
   Episode_Reward/test_gait_reward: -0.0762
Metrics/base_velocity/error_vel_xy: 0.3602
Metrics/base_velocity/error_vel_yaw: 0.0789
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 45.4167
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 1.06s
                        Total time: 337.16s
                               ETA: 2926.8s

################################################################################
                     [1m Learning iteration 310/3000 [0m                      

                       Computation: 92707 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 0.4526
                    Surrogate loss: 0.0051
             Mean action noise std: 0.5603
                     Learning rate: 0.0002
                       Mean reward: 1.15
               Mean episode length: 84.76
       Episode_Reward/keep_balance: 0.0835
     Episode_Reward/rew_lin_vel_xy: 0.1173
      Episode_Reward/rew_ang_vel_z: 0.2491
    Episode_Reward/pen_base_height: -0.1291
      Episode_Reward/pen_lin_vel_z: -0.0135
     Episode_Reward/pen_ang_vel_xy: -0.0239
   Episode_Reward/pen_joint_torque: -0.0121
    Episode_Reward/pen_joint_accel: -0.0081
    Episode_Reward/pen_action_rate: -0.0030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0031
   Episode_Reward/pen_joint_powers: -0.0046
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0068
Episode_Reward/pen_flat_orientation: -0.0760
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0146
   Episode_Reward/foot_landing_vel: -0.0121
   Episode_Reward/test_gait_reward: -0.0751
Metrics/base_velocity/error_vel_xy: 0.3575
Metrics/base_velocity/error_vel_yaw: 0.0772
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 46.4583
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 1.06s
                        Total time: 338.22s
                               ETA: 2925.5s

################################################################################
                     [1m Learning iteration 311/3000 [0m                      

                       Computation: 91791 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 0.4066
                    Surrogate loss: 0.0032
             Mean action noise std: 0.5605
                     Learning rate: 0.0002
                       Mean reward: 0.76
               Mean episode length: 86.64
       Episode_Reward/keep_balance: 0.0857
     Episode_Reward/rew_lin_vel_xy: 0.1206
      Episode_Reward/rew_ang_vel_z: 0.2540
    Episode_Reward/pen_base_height: -0.1314
      Episode_Reward/pen_lin_vel_z: -0.0138
     Episode_Reward/pen_ang_vel_xy: -0.0239
   Episode_Reward/pen_joint_torque: -0.0125
    Episode_Reward/pen_joint_accel: -0.0084
    Episode_Reward/pen_action_rate: -0.0031
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0032
   Episode_Reward/pen_joint_powers: -0.0047
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0071
Episode_Reward/pen_flat_orientation: -0.0794
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0155
   Episode_Reward/foot_landing_vel: -0.0127
   Episode_Reward/test_gait_reward: -0.0771
Metrics/base_velocity/error_vel_xy: 0.3648
Metrics/base_velocity/error_vel_yaw: 0.0802
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 44.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 1.07s
                        Total time: 339.29s
                               ETA: 2924.2s

################################################################################
                     [1m Learning iteration 312/3000 [0m                      

                       Computation: 92403 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 0.4409
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5606
                     Learning rate: 0.0004
                       Mean reward: 1.44
               Mean episode length: 90.44
       Episode_Reward/keep_balance: 0.0892
     Episode_Reward/rew_lin_vel_xy: 0.1274
      Episode_Reward/rew_ang_vel_z: 0.2657
    Episode_Reward/pen_base_height: -0.1329
      Episode_Reward/pen_lin_vel_z: -0.0138
     Episode_Reward/pen_ang_vel_xy: -0.0238
   Episode_Reward/pen_joint_torque: -0.0130
    Episode_Reward/pen_joint_accel: -0.0089
    Episode_Reward/pen_action_rate: -0.0032
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0033
   Episode_Reward/pen_joint_powers: -0.0049
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0074
Episode_Reward/pen_flat_orientation: -0.0811
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0160
   Episode_Reward/foot_landing_vel: -0.0131
   Episode_Reward/test_gait_reward: -0.0800
Metrics/base_velocity/error_vel_xy: 0.3753
Metrics/base_velocity/error_vel_yaw: 0.0828
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 47.2917
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 1.06s
                        Total time: 340.36s
                               ETA: 2922.9s

################################################################################
                     [1m Learning iteration 313/3000 [0m                      

                       Computation: 92130 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 0.4560
                    Surrogate loss: -0.0030
             Mean action noise std: 0.5609
                     Learning rate: 0.0009
                       Mean reward: 2.37
               Mean episode length: 95.78
       Episode_Reward/keep_balance: 0.0905
     Episode_Reward/rew_lin_vel_xy: 0.1325
      Episode_Reward/rew_ang_vel_z: 0.2697
    Episode_Reward/pen_base_height: -0.1335
      Episode_Reward/pen_lin_vel_z: -0.0140
     Episode_Reward/pen_ang_vel_xy: -0.0240
   Episode_Reward/pen_joint_torque: -0.0133
    Episode_Reward/pen_joint_accel: -0.0089
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0033
   Episode_Reward/pen_joint_powers: -0.0050
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0074
Episode_Reward/pen_flat_orientation: -0.0830
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0168
   Episode_Reward/foot_landing_vel: -0.0135
   Episode_Reward/test_gait_reward: -0.0810
Metrics/base_velocity/error_vel_xy: 0.3763
Metrics/base_velocity/error_vel_yaw: 0.0838
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 41.1250
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 1.07s
                        Total time: 341.42s
                               ETA: 2921.7s

################################################################################
                     [1m Learning iteration 314/3000 [0m                      

                       Computation: 92912 steps/s (collection: 0.935s, learning 0.123s)
               Value function loss: 0.5038
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5608
                     Learning rate: 0.0019
                       Mean reward: 2.28
               Mean episode length: 95.81
       Episode_Reward/keep_balance: 0.0886
     Episode_Reward/rew_lin_vel_xy: 0.1328
      Episode_Reward/rew_ang_vel_z: 0.2631
    Episode_Reward/pen_base_height: -0.1331
      Episode_Reward/pen_lin_vel_z: -0.0139
     Episode_Reward/pen_ang_vel_xy: -0.0237
   Episode_Reward/pen_joint_torque: -0.0129
    Episode_Reward/pen_joint_accel: -0.0090
    Episode_Reward/pen_action_rate: -0.0033
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0033
   Episode_Reward/pen_joint_powers: -0.0049
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0074
Episode_Reward/pen_flat_orientation: -0.0839
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0162
   Episode_Reward/foot_landing_vel: -0.0133
   Episode_Reward/test_gait_reward: -0.0798
Metrics/base_velocity/error_vel_xy: 0.3687
Metrics/base_velocity/error_vel_yaw: 0.0828
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 44.2083
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 1.06s
                        Total time: 342.48s
                               ETA: 2920.3s

################################################################################
                     [1m Learning iteration 315/3000 [0m                      

                       Computation: 91062 steps/s (collection: 0.955s, learning 0.125s)
               Value function loss: 0.6726
                    Surrogate loss: 0.0000
             Mean action noise std: 0.5613
                     Learning rate: 0.0029
                       Mean reward: 1.51
               Mean episode length: 93.93
       Episode_Reward/keep_balance: 0.0919
     Episode_Reward/rew_lin_vel_xy: 0.1299
      Episode_Reward/rew_ang_vel_z: 0.2744
    Episode_Reward/pen_base_height: -0.1338
      Episode_Reward/pen_lin_vel_z: -0.0142
     Episode_Reward/pen_ang_vel_xy: -0.0245
   Episode_Reward/pen_joint_torque: -0.0135
    Episode_Reward/pen_joint_accel: -0.0089
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0034
   Episode_Reward/pen_joint_powers: -0.0051
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0076
Episode_Reward/pen_flat_orientation: -0.0823
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0163
   Episode_Reward/foot_landing_vel: -0.0134
   Episode_Reward/test_gait_reward: -0.0832
Metrics/base_velocity/error_vel_xy: 0.3903
Metrics/base_velocity/error_vel_yaw: 0.0846
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 42.2917
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 1.08s
                        Total time: 343.56s
                               ETA: 2919.2s

################################################################################
                     [1m Learning iteration 316/3000 [0m                      

                       Computation: 90265 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.8795
                    Surrogate loss: 0.0325
             Mean action noise std: 0.5632
                     Learning rate: 0.0006
                       Mean reward: 1.63
               Mean episode length: 92.06
       Episode_Reward/keep_balance: 0.0920
     Episode_Reward/rew_lin_vel_xy: 0.1363
      Episode_Reward/rew_ang_vel_z: 0.2748
    Episode_Reward/pen_base_height: -0.1331
      Episode_Reward/pen_lin_vel_z: -0.0144
     Episode_Reward/pen_ang_vel_xy: -0.0245
   Episode_Reward/pen_joint_torque: -0.0137
    Episode_Reward/pen_joint_accel: -0.0089
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0035
   Episode_Reward/pen_joint_powers: -0.0051
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0076
Episode_Reward/pen_flat_orientation: -0.0833
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0176
   Episode_Reward/foot_landing_vel: -0.0137
   Episode_Reward/test_gait_reward: -0.0828
Metrics/base_velocity/error_vel_xy: 0.3901
Metrics/base_velocity/error_vel_yaw: 0.0843
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 42.2500
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 1.09s
                        Total time: 344.65s
                               ETA: 2918.1s

################################################################################
                     [1m Learning iteration 317/3000 [0m                      

                       Computation: 90641 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.6991
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5642
                     Learning rate: 0.0009
                       Mean reward: 1.32
               Mean episode length: 83.79
       Episode_Reward/keep_balance: 0.0916
     Episode_Reward/rew_lin_vel_xy: 0.1373
      Episode_Reward/rew_ang_vel_z: 0.2719
    Episode_Reward/pen_base_height: -0.1351
      Episode_Reward/pen_lin_vel_z: -0.0147
     Episode_Reward/pen_ang_vel_xy: -0.0245
   Episode_Reward/pen_joint_torque: -0.0138
    Episode_Reward/pen_joint_accel: -0.0092
    Episode_Reward/pen_action_rate: -0.0034
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0035
   Episode_Reward/pen_joint_powers: -0.0052
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0077
Episode_Reward/pen_flat_orientation: -0.0838
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0177
   Episode_Reward/foot_landing_vel: -0.0140
   Episode_Reward/test_gait_reward: -0.0830
Metrics/base_velocity/error_vel_xy: 0.3804
Metrics/base_velocity/error_vel_yaw: 0.0859
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 40.8333
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 1.08s
                        Total time: 345.73s
                               ETA: 2917.0s

################################################################################
                     [1m Learning iteration 318/3000 [0m                      

                       Computation: 90874 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.5635
                    Surrogate loss: 0.0004
             Mean action noise std: 0.5652
                     Learning rate: 0.0006
                       Mean reward: 1.71
               Mean episode length: 96.18
       Episode_Reward/keep_balance: 0.0963
     Episode_Reward/rew_lin_vel_xy: 0.1455
      Episode_Reward/rew_ang_vel_z: 0.2852
    Episode_Reward/pen_base_height: -0.1403
      Episode_Reward/pen_lin_vel_z: -0.0147
     Episode_Reward/pen_ang_vel_xy: -0.0243
   Episode_Reward/pen_joint_torque: -0.0146
    Episode_Reward/pen_joint_accel: -0.0096
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0036
   Episode_Reward/pen_joint_powers: -0.0054
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0082
Episode_Reward/pen_flat_orientation: -0.0876
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0181
   Episode_Reward/foot_landing_vel: -0.0147
   Episode_Reward/test_gait_reward: -0.0865
Metrics/base_velocity/error_vel_xy: 0.3929
Metrics/base_velocity/error_vel_yaw: 0.0909
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 39.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 1.08s
                        Total time: 346.82s
                               ETA: 2915.9s

################################################################################
                     [1m Learning iteration 319/3000 [0m                      

                       Computation: 90636 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.5390
                    Surrogate loss: -0.0002
             Mean action noise std: 0.5657
                     Learning rate: 0.0004
                       Mean reward: 2.23
               Mean episode length: 99.24
       Episode_Reward/keep_balance: 0.0999
     Episode_Reward/rew_lin_vel_xy: 0.1487
      Episode_Reward/rew_ang_vel_z: 0.2973
    Episode_Reward/pen_base_height: -0.1430
      Episode_Reward/pen_lin_vel_z: -0.0147
     Episode_Reward/pen_ang_vel_xy: -0.0244
   Episode_Reward/pen_joint_torque: -0.0156
    Episode_Reward/pen_joint_accel: -0.0096
    Episode_Reward/pen_action_rate: -0.0038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0037
   Episode_Reward/pen_joint_powers: -0.0056
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0084
Episode_Reward/pen_flat_orientation: -0.0892
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0186
   Episode_Reward/foot_landing_vel: -0.0149
   Episode_Reward/test_gait_reward: -0.0903
Metrics/base_velocity/error_vel_xy: 0.4075
Metrics/base_velocity/error_vel_yaw: 0.0932
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 43.5833
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 1.08s
                        Total time: 347.90s
                               ETA: 2914.8s

################################################################################
                     [1m Learning iteration 320/3000 [0m                      

                       Computation: 92800 steps/s (collection: 0.938s, learning 0.121s)
               Value function loss: 0.4882
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5663
                     Learning rate: 0.0009
                       Mean reward: 2.64
               Mean episode length: 107.80
       Episode_Reward/keep_balance: 0.0996
     Episode_Reward/rew_lin_vel_xy: 0.1534
      Episode_Reward/rew_ang_vel_z: 0.2948
    Episode_Reward/pen_base_height: -0.1442
      Episode_Reward/pen_lin_vel_z: -0.0145
     Episode_Reward/pen_ang_vel_xy: -0.0245
   Episode_Reward/pen_joint_torque: -0.0156
    Episode_Reward/pen_joint_accel: -0.0096
    Episode_Reward/pen_action_rate: -0.0038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0037
   Episode_Reward/pen_joint_powers: -0.0055
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0085
Episode_Reward/pen_flat_orientation: -0.0902
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0185
   Episode_Reward/foot_landing_vel: -0.0151
   Episode_Reward/test_gait_reward: -0.0903
Metrics/base_velocity/error_vel_xy: 0.4015
Metrics/base_velocity/error_vel_yaw: 0.0947
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 45.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 1.06s
                        Total time: 348.96s
                               ETA: 2913.4s

################################################################################
                     [1m Learning iteration 321/3000 [0m                      

                       Computation: 92362 steps/s (collection: 0.943s, learning 0.121s)
               Value function loss: 0.5732
                    Surrogate loss: 0.0027
             Mean action noise std: 0.5668
                     Learning rate: 0.0013
                       Mean reward: 2.53
               Mean episode length: 103.35
       Episode_Reward/keep_balance: 0.0983
     Episode_Reward/rew_lin_vel_xy: 0.1516
      Episode_Reward/rew_ang_vel_z: 0.2918
    Episode_Reward/pen_base_height: -0.1423
      Episode_Reward/pen_lin_vel_z: -0.0140
     Episode_Reward/pen_ang_vel_xy: -0.0241
   Episode_Reward/pen_joint_torque: -0.0154
    Episode_Reward/pen_joint_accel: -0.0099
    Episode_Reward/pen_action_rate: -0.0037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0036
   Episode_Reward/pen_joint_powers: -0.0054
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0083
Episode_Reward/pen_flat_orientation: -0.0881
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0177
   Episode_Reward/foot_landing_vel: -0.0146
   Episode_Reward/test_gait_reward: -0.0895
Metrics/base_velocity/error_vel_xy: 0.3947
Metrics/base_velocity/error_vel_yaw: 0.0925
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 43.3750
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 1.06s
                        Total time: 350.02s
                               ETA: 2912.2s

################################################################################
                     [1m Learning iteration 322/3000 [0m                      

                       Computation: 91998 steps/s (collection: 0.945s, learning 0.124s)
               Value function loss: 0.5720
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5677
                     Learning rate: 0.0013
                       Mean reward: 1.68
               Mean episode length: 88.23
       Episode_Reward/keep_balance: 0.0942
     Episode_Reward/rew_lin_vel_xy: 0.1362
      Episode_Reward/rew_ang_vel_z: 0.2796
    Episode_Reward/pen_base_height: -0.1386
      Episode_Reward/pen_lin_vel_z: -0.0139
     Episode_Reward/pen_ang_vel_xy: -0.0238
   Episode_Reward/pen_joint_torque: -0.0145
    Episode_Reward/pen_joint_accel: -0.0092
    Episode_Reward/pen_action_rate: -0.0035
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0034
   Episode_Reward/pen_joint_powers: -0.0052
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0080
Episode_Reward/pen_flat_orientation: -0.0836
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0165
   Episode_Reward/foot_landing_vel: -0.0141
   Episode_Reward/test_gait_reward: -0.0863
Metrics/base_velocity/error_vel_xy: 0.3934
Metrics/base_velocity/error_vel_yaw: 0.0882
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 37.9167
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 1.07s
                        Total time: 351.09s
                               ETA: 2910.9s

################################################################################
                     [1m Learning iteration 323/3000 [0m                      

                       Computation: 92847 steps/s (collection: 0.936s, learning 0.122s)
               Value function loss: 0.5539
                    Surrogate loss: 0.0015
             Mean action noise std: 0.5685
                     Learning rate: 0.0009
                       Mean reward: 1.84
               Mean episode length: 97.22
       Episode_Reward/keep_balance: 0.0941
     Episode_Reward/rew_lin_vel_xy: 0.1350
      Episode_Reward/rew_ang_vel_z: 0.2799
    Episode_Reward/pen_base_height: -0.1397
      Episode_Reward/pen_lin_vel_z: -0.0141
     Episode_Reward/pen_ang_vel_xy: -0.0238
   Episode_Reward/pen_joint_torque: -0.0146
    Episode_Reward/pen_joint_accel: -0.0096
    Episode_Reward/pen_action_rate: -0.0036
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0035
   Episode_Reward/pen_joint_powers: -0.0052
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0080
Episode_Reward/pen_flat_orientation: -0.0840
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0171
   Episode_Reward/foot_landing_vel: -0.0145
   Episode_Reward/test_gait_reward: -0.0866
Metrics/base_velocity/error_vel_xy: 0.3868
Metrics/base_velocity/error_vel_yaw: 0.0876
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 36.4583
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 1.06s
                        Total time: 352.15s
                               ETA: 2909.6s

################################################################################
                     [1m Learning iteration 324/3000 [0m                      

                       Computation: 92287 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.5372
                    Surrogate loss: 0.0016
             Mean action noise std: 0.5688
                     Learning rate: 0.0004
                       Mean reward: 2.24
               Mean episode length: 100.42
       Episode_Reward/keep_balance: 0.0986
     Episode_Reward/rew_lin_vel_xy: 0.1440
      Episode_Reward/rew_ang_vel_z: 0.2926
    Episode_Reward/pen_base_height: -0.1413
      Episode_Reward/pen_lin_vel_z: -0.0145
     Episode_Reward/pen_ang_vel_xy: -0.0244
   Episode_Reward/pen_joint_torque: -0.0157
    Episode_Reward/pen_joint_accel: -0.0097
    Episode_Reward/pen_action_rate: -0.0038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0037
   Episode_Reward/pen_joint_powers: -0.0055
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0084
Episode_Reward/pen_flat_orientation: -0.0861
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0182
   Episode_Reward/foot_landing_vel: -0.0150
   Episode_Reward/test_gait_reward: -0.0906
Metrics/base_velocity/error_vel_xy: 0.4105
Metrics/base_velocity/error_vel_yaw: 0.0922
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 39.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 1.07s
                        Total time: 353.22s
                               ETA: 2908.3s

################################################################################
                     [1m Learning iteration 325/3000 [0m                      

                       Computation: 92502 steps/s (collection: 0.941s, learning 0.121s)
               Value function loss: 0.5252
                    Surrogate loss: 0.0009
             Mean action noise std: 0.5689
                     Learning rate: 0.0006
                       Mean reward: 2.72
               Mean episode length: 104.76
       Episode_Reward/keep_balance: 0.1006
     Episode_Reward/rew_lin_vel_xy: 0.1462
      Episode_Reward/rew_ang_vel_z: 0.2999
    Episode_Reward/pen_base_height: -0.1424
      Episode_Reward/pen_lin_vel_z: -0.0147
     Episode_Reward/pen_ang_vel_xy: -0.0246
   Episode_Reward/pen_joint_torque: -0.0160
    Episode_Reward/pen_joint_accel: -0.0102
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0038
   Episode_Reward/pen_joint_powers: -0.0056
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0086
Episode_Reward/pen_flat_orientation: -0.0870
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0184
   Episode_Reward/foot_landing_vel: -0.0156
   Episode_Reward/test_gait_reward: -0.0924
Metrics/base_velocity/error_vel_xy: 0.4152
Metrics/base_velocity/error_vel_yaw: 0.0934
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 35.9167
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 1.06s
                        Total time: 354.28s
                               ETA: 2907.1s

################################################################################
                     [1m Learning iteration 326/3000 [0m                      

                       Computation: 91544 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.5611
                    Surrogate loss: 0.0028
             Mean action noise std: 0.5684
                     Learning rate: 0.0004
                       Mean reward: 1.92
               Mean episode length: 102.79
       Episode_Reward/keep_balance: 0.0998
     Episode_Reward/rew_lin_vel_xy: 0.1344
      Episode_Reward/rew_ang_vel_z: 0.2957
    Episode_Reward/pen_base_height: -0.1400
      Episode_Reward/pen_lin_vel_z: -0.0148
     Episode_Reward/pen_ang_vel_xy: -0.0250
   Episode_Reward/pen_joint_torque: -0.0159
    Episode_Reward/pen_joint_accel: -0.0102
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0038
   Episode_Reward/pen_joint_powers: -0.0057
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0086
Episode_Reward/pen_flat_orientation: -0.0837
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0190
   Episode_Reward/foot_landing_vel: -0.0155
   Episode_Reward/test_gait_reward: -0.0922
Metrics/base_velocity/error_vel_xy: 0.4212
Metrics/base_velocity/error_vel_yaw: 0.0936
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 33.8333
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 1.07s
                        Total time: 355.35s
                               ETA: 2905.9s

################################################################################
                     [1m Learning iteration 327/3000 [0m                      

                       Computation: 92469 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 0.5396
                    Surrogate loss: -0.0036
             Mean action noise std: 0.5681
                     Learning rate: 0.0006
                       Mean reward: 2.52
               Mean episode length: 105.24
       Episode_Reward/keep_balance: 0.1007
     Episode_Reward/rew_lin_vel_xy: 0.1467
      Episode_Reward/rew_ang_vel_z: 0.2988
    Episode_Reward/pen_base_height: -0.1406
      Episode_Reward/pen_lin_vel_z: -0.0151
     Episode_Reward/pen_ang_vel_xy: -0.0247
   Episode_Reward/pen_joint_torque: -0.0162
    Episode_Reward/pen_joint_accel: -0.0101
    Episode_Reward/pen_action_rate: -0.0039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0038
   Episode_Reward/pen_joint_powers: -0.0057
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0087
Episode_Reward/pen_flat_orientation: -0.0850
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0188
   Episode_Reward/foot_landing_vel: -0.0156
   Episode_Reward/test_gait_reward: -0.0924
Metrics/base_velocity/error_vel_xy: 0.4182
Metrics/base_velocity/error_vel_yaw: 0.0944
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 34.4583
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 1.06s
                        Total time: 356.42s
                               ETA: 2904.6s

################################################################################
                     [1m Learning iteration 328/3000 [0m                      

                       Computation: 93222 steps/s (collection: 0.933s, learning 0.122s)
               Value function loss: 0.5581
                    Surrogate loss: -0.0021
             Mean action noise std: 0.5690
                     Learning rate: 0.0009
                       Mean reward: 1.97
               Mean episode length: 100.93
       Episode_Reward/keep_balance: 0.1058
     Episode_Reward/rew_lin_vel_xy: 0.1483
      Episode_Reward/rew_ang_vel_z: 0.3137
    Episode_Reward/pen_base_height: -0.1420
      Episode_Reward/pen_lin_vel_z: -0.0153
     Episode_Reward/pen_ang_vel_xy: -0.0254
   Episode_Reward/pen_joint_torque: -0.0168
    Episode_Reward/pen_joint_accel: -0.0107
    Episode_Reward/pen_action_rate: -0.0042
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0041
   Episode_Reward/pen_joint_powers: -0.0060
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0092
Episode_Reward/pen_flat_orientation: -0.0864
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0204
   Episode_Reward/foot_landing_vel: -0.0166
   Episode_Reward/test_gait_reward: -0.0975
Metrics/base_velocity/error_vel_xy: 0.4339
Metrics/base_velocity/error_vel_yaw: 0.0994
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 32.9167
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 1.05s
                        Total time: 357.47s
                               ETA: 2903.2s

################################################################################
                     [1m Learning iteration 329/3000 [0m                      

                       Computation: 92817 steps/s (collection: 0.938s, learning 0.122s)
               Value function loss: 0.6480
                    Surrogate loss: 0.0000
             Mean action noise std: 0.5702
                     Learning rate: 0.0013
                       Mean reward: 3.54
               Mean episode length: 118.98
       Episode_Reward/keep_balance: 0.1114
     Episode_Reward/rew_lin_vel_xy: 0.1666
      Episode_Reward/rew_ang_vel_z: 0.3290
    Episode_Reward/pen_base_height: -0.1441
      Episode_Reward/pen_lin_vel_z: -0.0159
     Episode_Reward/pen_ang_vel_xy: -0.0258
   Episode_Reward/pen_joint_torque: -0.0180
    Episode_Reward/pen_joint_accel: -0.0112
    Episode_Reward/pen_action_rate: -0.0045
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0043
   Episode_Reward/pen_joint_powers: -0.0064
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0098
Episode_Reward/pen_flat_orientation: -0.0884
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0213
   Episode_Reward/foot_landing_vel: -0.0176
   Episode_Reward/test_gait_reward: -0.1017
Metrics/base_velocity/error_vel_xy: 0.4526
Metrics/base_velocity/error_vel_yaw: 0.1048
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 32.8333
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 1.06s
                        Total time: 358.53s
                               ETA: 2901.9s

################################################################################
                     [1m Learning iteration 330/3000 [0m                      

                       Computation: 91962 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 0.6229
                    Surrogate loss: 0.0044
             Mean action noise std: 0.5704
                     Learning rate: 0.0002
                       Mean reward: 2.60
               Mean episode length: 112.90
       Episode_Reward/keep_balance: 0.1110
     Episode_Reward/rew_lin_vel_xy: 0.1679
      Episode_Reward/rew_ang_vel_z: 0.3304
    Episode_Reward/pen_base_height: -0.1451
      Episode_Reward/pen_lin_vel_z: -0.0160
     Episode_Reward/pen_ang_vel_xy: -0.0261
   Episode_Reward/pen_joint_torque: -0.0182
    Episode_Reward/pen_joint_accel: -0.0113
    Episode_Reward/pen_action_rate: -0.0044
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0044
   Episode_Reward/pen_joint_powers: -0.0065
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0097
Episode_Reward/pen_flat_orientation: -0.0891
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0216
   Episode_Reward/foot_landing_vel: -0.0176
   Episode_Reward/test_gait_reward: -0.1016
Metrics/base_velocity/error_vel_xy: 0.4494
Metrics/base_velocity/error_vel_yaw: 0.1027
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 29.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 1.07s
                        Total time: 359.60s
                               ETA: 2900.7s

################################################################################
                     [1m Learning iteration 331/3000 [0m                      

                       Computation: 93448 steps/s (collection: 0.931s, learning 0.121s)
               Value function loss: 0.5274
                    Surrogate loss: 0.0022
             Mean action noise std: 0.5705
                     Learning rate: 0.0003
                       Mean reward: 4.27
               Mean episode length: 126.39
       Episode_Reward/keep_balance: 0.1147
     Episode_Reward/rew_lin_vel_xy: 0.1770
      Episode_Reward/rew_ang_vel_z: 0.3396
    Episode_Reward/pen_base_height: -0.1475
      Episode_Reward/pen_lin_vel_z: -0.0158
     Episode_Reward/pen_ang_vel_xy: -0.0257
   Episode_Reward/pen_joint_torque: -0.0180
    Episode_Reward/pen_joint_accel: -0.0113
    Episode_Reward/pen_action_rate: -0.0046
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0044
   Episode_Reward/pen_joint_powers: -0.0065
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0101
Episode_Reward/pen_flat_orientation: -0.0918
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0217
   Episode_Reward/foot_landing_vel: -0.0181
   Episode_Reward/test_gait_reward: -0.1048
Metrics/base_velocity/error_vel_xy: 0.4500
Metrics/base_velocity/error_vel_yaw: 0.1075
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 32.8750
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 1.05s
                        Total time: 360.65s
                               ETA: 2899.3s

################################################################################
                     [1m Learning iteration 332/3000 [0m                      

                       Computation: 93119 steps/s (collection: 0.934s, learning 0.121s)
               Value function loss: 0.5504
                    Surrogate loss: 0.0018
             Mean action noise std: 0.5707
                     Learning rate: 0.0003
                       Mean reward: 3.02
               Mean episode length: 119.74
       Episode_Reward/keep_balance: 0.1169
     Episode_Reward/rew_lin_vel_xy: 0.1703
      Episode_Reward/rew_ang_vel_z: 0.3466
    Episode_Reward/pen_base_height: -0.1476
      Episode_Reward/pen_lin_vel_z: -0.0163
     Episode_Reward/pen_ang_vel_xy: -0.0263
   Episode_Reward/pen_joint_torque: -0.0188
    Episode_Reward/pen_joint_accel: -0.0114
    Episode_Reward/pen_action_rate: -0.0047
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0046
   Episode_Reward/pen_joint_powers: -0.0067
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0103
Episode_Reward/pen_flat_orientation: -0.0914
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0228
   Episode_Reward/foot_landing_vel: -0.0186
   Episode_Reward/test_gait_reward: -0.1069
Metrics/base_velocity/error_vel_xy: 0.4800
Metrics/base_velocity/error_vel_yaw: 0.1095
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 31.7917
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 1.06s
                        Total time: 361.71s
                               ETA: 2898.0s

################################################################################
                     [1m Learning iteration 333/3000 [0m                      

                       Computation: 92963 steps/s (collection: 0.936s, learning 0.121s)
               Value function loss: 0.5073
                    Surrogate loss: 0.0027
             Mean action noise std: 0.5709
                     Learning rate: 0.0002
                       Mean reward: 4.05
               Mean episode length: 128.15
       Episode_Reward/keep_balance: 0.1221
     Episode_Reward/rew_lin_vel_xy: 0.1778
      Episode_Reward/rew_ang_vel_z: 0.3625
    Episode_Reward/pen_base_height: -0.1503
      Episode_Reward/pen_lin_vel_z: -0.0167
     Episode_Reward/pen_ang_vel_xy: -0.0264
   Episode_Reward/pen_joint_torque: -0.0196
    Episode_Reward/pen_joint_accel: -0.0126
    Episode_Reward/pen_action_rate: -0.0049
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0048
   Episode_Reward/pen_joint_powers: -0.0070
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0108
Episode_Reward/pen_flat_orientation: -0.0953
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0240
   Episode_Reward/foot_landing_vel: -0.0196
   Episode_Reward/test_gait_reward: -0.1117
Metrics/base_velocity/error_vel_xy: 0.4881
Metrics/base_velocity/error_vel_yaw: 0.1144
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 30.5000
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 1.06s
                        Total time: 362.76s
                               ETA: 2896.7s

################################################################################
                     [1m Learning iteration 334/3000 [0m                      

                       Computation: 92363 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 0.5884
                    Surrogate loss: -0.0013
             Mean action noise std: 0.5707
                     Learning rate: 0.0004
                       Mean reward: 3.96
               Mean episode length: 136.88
       Episode_Reward/keep_balance: 0.1265
     Episode_Reward/rew_lin_vel_xy: 0.1897
      Episode_Reward/rew_ang_vel_z: 0.3747
    Episode_Reward/pen_base_height: -0.1513
      Episode_Reward/pen_lin_vel_z: -0.0170
     Episode_Reward/pen_ang_vel_xy: -0.0272
   Episode_Reward/pen_joint_torque: -0.0206
    Episode_Reward/pen_joint_accel: -0.0124
    Episode_Reward/pen_action_rate: -0.0052
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0048
   Episode_Reward/pen_joint_powers: -0.0073
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0114
Episode_Reward/pen_flat_orientation: -0.0951
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0240
   Episode_Reward/foot_landing_vel: -0.0198
   Episode_Reward/test_gait_reward: -0.1159
Metrics/base_velocity/error_vel_xy: 0.5006
Metrics/base_velocity/error_vel_yaw: 0.1194
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 30.6250
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 1.06s
                        Total time: 363.83s
                               ETA: 2895.4s

################################################################################
                     [1m Learning iteration 335/3000 [0m                      

                       Computation: 93030 steps/s (collection: 0.935s, learning 0.121s)
               Value function loss: 0.7444
                    Surrogate loss: 0.0024
             Mean action noise std: 0.5705
                     Learning rate: 0.0003
                       Mean reward: 2.44
               Mean episode length: 113.84
       Episode_Reward/keep_balance: 0.1211
     Episode_Reward/rew_lin_vel_xy: 0.1725
      Episode_Reward/rew_ang_vel_z: 0.3577
    Episode_Reward/pen_base_height: -0.1489
      Episode_Reward/pen_lin_vel_z: -0.0174
     Episode_Reward/pen_ang_vel_xy: -0.0276
   Episode_Reward/pen_joint_torque: -0.0201
    Episode_Reward/pen_joint_accel: -0.0123
    Episode_Reward/pen_action_rate: -0.0050
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0049
   Episode_Reward/pen_joint_powers: -0.0072
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0108
Episode_Reward/pen_flat_orientation: -0.0911
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0256
   Episode_Reward/foot_landing_vel: -0.0198
   Episode_Reward/test_gait_reward: -0.1113
Metrics/base_velocity/error_vel_xy: 0.4948
Metrics/base_velocity/error_vel_yaw: 0.1137
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 26.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 1.06s
                        Total time: 364.89s
                               ETA: 2894.1s

################################################################################
                     [1m Learning iteration 336/3000 [0m                      

                       Computation: 93063 steps/s (collection: 0.934s, learning 0.122s)
               Value function loss: 0.5696
                    Surrogate loss: -0.0026
             Mean action noise std: 0.5699
                     Learning rate: 0.0006
                       Mean reward: 4.22
               Mean episode length: 136.49
       Episode_Reward/keep_balance: 0.1247
     Episode_Reward/rew_lin_vel_xy: 0.1918
      Episode_Reward/rew_ang_vel_z: 0.3672
    Episode_Reward/pen_base_height: -0.1518
      Episode_Reward/pen_lin_vel_z: -0.0173
     Episode_Reward/pen_ang_vel_xy: -0.0273
   Episode_Reward/pen_joint_torque: -0.0206
    Episode_Reward/pen_joint_accel: -0.0130
    Episode_Reward/pen_action_rate: -0.0052
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0050
   Episode_Reward/pen_joint_powers: -0.0074
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0113
Episode_Reward/pen_flat_orientation: -0.0959
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0255
   Episode_Reward/foot_landing_vel: -0.0205
   Episode_Reward/test_gait_reward: -0.1147
Metrics/base_velocity/error_vel_xy: 0.4922
Metrics/base_velocity/error_vel_yaw: 0.1181
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 28.3333
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 1.06s
                        Total time: 365.94s
                               ETA: 2892.8s

################################################################################
                     [1m Learning iteration 337/3000 [0m                      

                       Computation: 93196 steps/s (collection: 0.932s, learning 0.122s)
               Value function loss: 0.5553
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5696
                     Learning rate: 0.0013
                       Mean reward: 6.89
               Mean episode length: 161.34
       Episode_Reward/keep_balance: 0.1387
     Episode_Reward/rew_lin_vel_xy: 0.2243
      Episode_Reward/rew_ang_vel_z: 0.4128
    Episode_Reward/pen_base_height: -0.1601
      Episode_Reward/pen_lin_vel_z: -0.0176
     Episode_Reward/pen_ang_vel_xy: -0.0272
   Episode_Reward/pen_joint_torque: -0.0220
    Episode_Reward/pen_joint_accel: -0.0142
    Episode_Reward/pen_action_rate: -0.0057
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0053
   Episode_Reward/pen_joint_powers: -0.0078
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.0125
Episode_Reward/pen_flat_orientation: -0.1060
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0257
   Episode_Reward/foot_landing_vel: -0.0221
   Episode_Reward/test_gait_reward: -0.1262
Metrics/base_velocity/error_vel_xy: 0.5184
Metrics/base_velocity/error_vel_yaw: 0.1292
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 40.6667
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 1.05s
                        Total time: 367.00s
                               ETA: 2891.5s

################################################################################
                     [1m Learning iteration 338/3000 [0m                      

                       Computation: 86916 steps/s (collection: 1.009s, learning 0.122s)
               Value function loss: 0.7711
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5696
                     Learning rate: 0.0019
                       Mean reward: 4.44
               Mean episode length: 130.77
       Episode_Reward/keep_balance: 0.1352
     Episode_Reward/rew_lin_vel_xy: 0.2199
      Episode_Reward/rew_ang_vel_z: 0.4035
    Episode_Reward/pen_base_height: -0.1559
      Episode_Reward/pen_lin_vel_z: -0.0172
     Episode_Reward/pen_ang_vel_xy: -0.0274
   Episode_Reward/pen_joint_torque: -0.0213
    Episode_Reward/pen_joint_accel: -0.0128
    Episode_Reward/pen_action_rate: -0.0055
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0050
   Episode_Reward/pen_joint_powers: -0.0076
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0120
Episode_Reward/pen_flat_orientation: -0.1001
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0243
   Episode_Reward/foot_landing_vel: -0.0209
   Episode_Reward/test_gait_reward: -0.1238
Metrics/base_velocity/error_vel_xy: 0.5208
Metrics/base_velocity/error_vel_yaw: 0.1254
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 31.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 1.13s
                        Total time: 368.13s
                               ETA: 2890.7s

################################################################################
                     [1m Learning iteration 339/3000 [0m                      

                       Computation: 92189 steps/s (collection: 0.945s, learning 0.121s)
               Value function loss: 0.9081
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5697
                     Learning rate: 0.0019
                       Mean reward: 3.74
               Mean episode length: 121.55
       Episode_Reward/keep_balance: 0.1255
     Episode_Reward/rew_lin_vel_xy: 0.1809
      Episode_Reward/rew_ang_vel_z: 0.3715
    Episode_Reward/pen_base_height: -0.1502
      Episode_Reward/pen_lin_vel_z: -0.0170
     Episode_Reward/pen_ang_vel_xy: -0.0271
   Episode_Reward/pen_joint_torque: -0.0203
    Episode_Reward/pen_joint_accel: -0.0128
    Episode_Reward/pen_action_rate: -0.0051
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0050
   Episode_Reward/pen_joint_powers: -0.0073
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0112
Episode_Reward/pen_flat_orientation: -0.0936
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0247
   Episode_Reward/foot_landing_vel: -0.0206
   Episode_Reward/test_gait_reward: -0.1150
Metrics/base_velocity/error_vel_xy: 0.5056
Metrics/base_velocity/error_vel_yaw: 0.1182
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 25.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 1.07s
                        Total time: 369.19s
                               ETA: 2889.5s

################################################################################
                     [1m Learning iteration 340/3000 [0m                      

                       Computation: 92789 steps/s (collection: 0.936s, learning 0.123s)
               Value function loss: 0.7395
                    Surrogate loss: 0.0007
             Mean action noise std: 0.5700
                     Learning rate: 0.0013
                       Mean reward: 3.69
               Mean episode length: 130.10
       Episode_Reward/keep_balance: 0.1146
     Episode_Reward/rew_lin_vel_xy: 0.1636
      Episode_Reward/rew_ang_vel_z: 0.3383
    Episode_Reward/pen_base_height: -0.1466
      Episode_Reward/pen_lin_vel_z: -0.0162
     Episode_Reward/pen_ang_vel_xy: -0.0260
   Episode_Reward/pen_joint_torque: -0.0184
    Episode_Reward/pen_joint_accel: -0.0121
    Episode_Reward/pen_action_rate: -0.0047
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0046
   Episode_Reward/pen_joint_powers: -0.0067
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0103
Episode_Reward/pen_flat_orientation: -0.0902
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0232
   Episode_Reward/foot_landing_vel: -0.0187
   Episode_Reward/test_gait_reward: -0.1069
Metrics/base_velocity/error_vel_xy: 0.4640
Metrics/base_velocity/error_vel_yaw: 0.1084
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 25.1250
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 1.06s
                        Total time: 370.25s
                               ETA: 2888.2s

################################################################################
                     [1m Learning iteration 341/3000 [0m                      

                       Computation: 93160 steps/s (collection: 0.933s, learning 0.122s)
               Value function loss: 0.6802
                    Surrogate loss: -0.0009
             Mean action noise std: 0.5707
                     Learning rate: 0.0013
                       Mean reward: 4.20
               Mean episode length: 135.70
       Episode_Reward/keep_balance: 0.1229
     Episode_Reward/rew_lin_vel_xy: 0.1801
      Episode_Reward/rew_ang_vel_z: 0.3657
    Episode_Reward/pen_base_height: -0.1519
      Episode_Reward/pen_lin_vel_z: -0.0170
     Episode_Reward/pen_ang_vel_xy: -0.0269
   Episode_Reward/pen_joint_torque: -0.0199
    Episode_Reward/pen_joint_accel: -0.0130
    Episode_Reward/pen_action_rate: -0.0050
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0048
   Episode_Reward/pen_joint_powers: -0.0071
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0109
Episode_Reward/pen_flat_orientation: -0.0959
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0243
   Episode_Reward/foot_landing_vel: -0.0199
   Episode_Reward/test_gait_reward: -0.1128
Metrics/base_velocity/error_vel_xy: 0.4862
Metrics/base_velocity/error_vel_yaw: 0.1153
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 26.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 1.06s
                        Total time: 371.31s
                               ETA: 2886.9s

################################################################################
                     [1m Learning iteration 342/3000 [0m                      

                       Computation: 91396 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.7988
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5712
                     Learning rate: 0.0029
                       Mean reward: 3.96
               Mean episode length: 138.31
       Episode_Reward/keep_balance: 0.1293
     Episode_Reward/rew_lin_vel_xy: 0.1966
      Episode_Reward/rew_ang_vel_z: 0.3849
    Episode_Reward/pen_base_height: -0.1531
      Episode_Reward/pen_lin_vel_z: -0.0173
     Episode_Reward/pen_ang_vel_xy: -0.0276
   Episode_Reward/pen_joint_torque: -0.0208
    Episode_Reward/pen_joint_accel: -0.0136
    Episode_Reward/pen_action_rate: -0.0053
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0051
   Episode_Reward/pen_joint_powers: -0.0074
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0115
Episode_Reward/pen_flat_orientation: -0.0972
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0250
   Episode_Reward/foot_landing_vel: -0.0207
   Episode_Reward/test_gait_reward: -0.1191
Metrics/base_velocity/error_vel_xy: 0.5021
Metrics/base_velocity/error_vel_yaw: 0.1202
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 27.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 1.08s
                        Total time: 372.38s
                               ETA: 2885.7s

################################################################################
                     [1m Learning iteration 343/3000 [0m                      

                       Computation: 89109 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.7213
                    Surrogate loss: 0.0052
             Mean action noise std: 0.5722
                     Learning rate: 0.0003
                       Mean reward: 4.55
               Mean episode length: 143.51
       Episode_Reward/keep_balance: 0.1329
     Episode_Reward/rew_lin_vel_xy: 0.2107
      Episode_Reward/rew_ang_vel_z: 0.3919
    Episode_Reward/pen_base_height: -0.1536
      Episode_Reward/pen_lin_vel_z: -0.0178
     Episode_Reward/pen_ang_vel_xy: -0.0279
   Episode_Reward/pen_joint_torque: -0.0215
    Episode_Reward/pen_joint_accel: -0.0139
    Episode_Reward/pen_action_rate: -0.0055
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0052
   Episode_Reward/pen_joint_powers: -0.0077
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0121
Episode_Reward/pen_flat_orientation: -0.0983
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0266
   Episode_Reward/foot_landing_vel: -0.0220
   Episode_Reward/test_gait_reward: -0.1218
Metrics/base_velocity/error_vel_xy: 0.5157
Metrics/base_velocity/error_vel_yaw: 0.1266
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 26.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 1.10s
                        Total time: 373.49s
                               ETA: 2884.8s

################################################################################
                     [1m Learning iteration 344/3000 [0m                      

                       Computation: 91489 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.6084
                    Surrogate loss: 0.0070
             Mean action noise std: 0.5723
                     Learning rate: 0.0001
                       Mean reward: 4.50
               Mean episode length: 140.35
       Episode_Reward/keep_balance: 0.1377
     Episode_Reward/rew_lin_vel_xy: 0.2313
      Episode_Reward/rew_ang_vel_z: 0.4109
    Episode_Reward/pen_base_height: -0.1553
      Episode_Reward/pen_lin_vel_z: -0.0183
     Episode_Reward/pen_ang_vel_xy: -0.0279
   Episode_Reward/pen_joint_torque: -0.0230
    Episode_Reward/pen_joint_accel: -0.0133
    Episode_Reward/pen_action_rate: -0.0057
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0053
   Episode_Reward/pen_joint_powers: -0.0081
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0123
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0273
   Episode_Reward/foot_landing_vel: -0.0226
   Episode_Reward/test_gait_reward: -0.1257
Metrics/base_velocity/error_vel_xy: 0.5164
Metrics/base_velocity/error_vel_yaw: 0.1271
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 22.9167
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 1.07s
                        Total time: 374.56s
                               ETA: 2883.6s

################################################################################
                     [1m Learning iteration 345/3000 [0m                      

                       Computation: 91837 steps/s (collection: 0.947s, learning 0.124s)
               Value function loss: 0.5841
                    Surrogate loss: 0.0032
             Mean action noise std: 0.5725
                     Learning rate: 0.0002
                       Mean reward: 4.51
               Mean episode length: 138.99
       Episode_Reward/keep_balance: 0.1436
     Episode_Reward/rew_lin_vel_xy: 0.2327
      Episode_Reward/rew_ang_vel_z: 0.4275
    Episode_Reward/pen_base_height: -0.1587
      Episode_Reward/pen_lin_vel_z: -0.0187
     Episode_Reward/pen_ang_vel_xy: -0.0282
   Episode_Reward/pen_joint_torque: -0.0238
    Episode_Reward/pen_joint_accel: -0.0143
    Episode_Reward/pen_action_rate: -0.0060
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0056
   Episode_Reward/pen_joint_powers: -0.0084
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0130
Episode_Reward/pen_flat_orientation: -0.1036
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0283
   Episode_Reward/foot_landing_vel: -0.0229
   Episode_Reward/test_gait_reward: -0.1311
Metrics/base_velocity/error_vel_xy: 0.5381
Metrics/base_velocity/error_vel_yaw: 0.1330
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 23.4583
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 1.07s
                        Total time: 375.63s
                               ETA: 2882.4s

################################################################################
                     [1m Learning iteration 346/3000 [0m                      

                       Computation: 91569 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.5776
                    Surrogate loss: 0.0054
             Mean action noise std: 0.5728
                     Learning rate: 0.0001
                       Mean reward: 5.48
               Mean episode length: 146.53
       Episode_Reward/keep_balance: 0.1416
     Episode_Reward/rew_lin_vel_xy: 0.2188
      Episode_Reward/rew_ang_vel_z: 0.4214
    Episode_Reward/pen_base_height: -0.1564
      Episode_Reward/pen_lin_vel_z: -0.0181
     Episode_Reward/pen_ang_vel_xy: -0.0285
   Episode_Reward/pen_joint_torque: -0.0225
    Episode_Reward/pen_joint_accel: -0.0139
    Episode_Reward/pen_action_rate: -0.0059
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0054
   Episode_Reward/pen_joint_powers: -0.0081
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0128
Episode_Reward/pen_flat_orientation: -0.1044
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0270
   Episode_Reward/foot_landing_vel: -0.0219
   Episode_Reward/test_gait_reward: -0.1291
Metrics/base_velocity/error_vel_xy: 0.5462
Metrics/base_velocity/error_vel_yaw: 0.1324
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 23.7917
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 1.07s
                        Total time: 376.71s
                               ETA: 2881.2s

################################################################################
                     [1m Learning iteration 347/3000 [0m                      

                       Computation: 92061 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 0.5937
                    Surrogate loss: -0.0023
             Mean action noise std: 0.5730
                     Learning rate: 0.0003
                       Mean reward: 4.93
               Mean episode length: 143.92
       Episode_Reward/keep_balance: 0.1504
     Episode_Reward/rew_lin_vel_xy: 0.2464
      Episode_Reward/rew_ang_vel_z: 0.4478
    Episode_Reward/pen_base_height: -0.1595
      Episode_Reward/pen_lin_vel_z: -0.0184
     Episode_Reward/pen_ang_vel_xy: -0.0282
   Episode_Reward/pen_joint_torque: -0.0241
    Episode_Reward/pen_joint_accel: -0.0152
    Episode_Reward/pen_action_rate: -0.0062
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0056
   Episode_Reward/pen_joint_powers: -0.0085
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0135
Episode_Reward/pen_flat_orientation: -0.1066
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0284
   Episode_Reward/foot_landing_vel: -0.0231
   Episode_Reward/test_gait_reward: -0.1361
Metrics/base_velocity/error_vel_xy: 0.5641
Metrics/base_velocity/error_vel_yaw: 0.1392
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 22.6667
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 1.07s
                        Total time: 377.77s
                               ETA: 2880.0s

################################################################################
                     [1m Learning iteration 348/3000 [0m                      

                       Computation: 91122 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.6294
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5731
                     Learning rate: 0.0009
                       Mean reward: 4.54
               Mean episode length: 144.94
       Episode_Reward/keep_balance: 0.1466
     Episode_Reward/rew_lin_vel_xy: 0.2316
      Episode_Reward/rew_ang_vel_z: 0.4370
    Episode_Reward/pen_base_height: -0.1579
      Episode_Reward/pen_lin_vel_z: -0.0182
     Episode_Reward/pen_ang_vel_xy: -0.0286
   Episode_Reward/pen_joint_torque: -0.0238
    Episode_Reward/pen_joint_accel: -0.0144
    Episode_Reward/pen_action_rate: -0.0061
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0056
   Episode_Reward/pen_joint_powers: -0.0084
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0132
Episode_Reward/pen_flat_orientation: -0.1071
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0283
   Episode_Reward/foot_landing_vel: -0.0235
   Episode_Reward/test_gait_reward: -0.1344
Metrics/base_velocity/error_vel_xy: 0.5635
Metrics/base_velocity/error_vel_yaw: 0.1357
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 24.5833
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 1.08s
                        Total time: 378.85s
                               ETA: 2878.8s

################################################################################
                     [1m Learning iteration 349/3000 [0m                      

                       Computation: 92336 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.8000
                    Surrogate loss: -0.0008
             Mean action noise std: 0.5731
                     Learning rate: 0.0013
                       Mean reward: 5.24
               Mean episode length: 144.11
       Episode_Reward/keep_balance: 0.1531
     Episode_Reward/rew_lin_vel_xy: 0.2369
      Episode_Reward/rew_ang_vel_z: 0.4574
    Episode_Reward/pen_base_height: -0.1605
      Episode_Reward/pen_lin_vel_z: -0.0192
     Episode_Reward/pen_ang_vel_xy: -0.0293
   Episode_Reward/pen_joint_torque: -0.0249
    Episode_Reward/pen_joint_accel: -0.0158
    Episode_Reward/pen_action_rate: -0.0064
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0060
   Episode_Reward/pen_joint_powers: -0.0088
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0138
Episode_Reward/pen_flat_orientation: -0.1076
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0309
   Episode_Reward/foot_landing_vel: -0.0250
   Episode_Reward/test_gait_reward: -0.1389
Metrics/base_velocity/error_vel_xy: 0.5830
Metrics/base_velocity/error_vel_yaw: 0.1415
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 23.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 1.06s
                        Total time: 379.92s
                               ETA: 2877.6s

################################################################################
                     [1m Learning iteration 350/3000 [0m                      

                       Computation: 92390 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.6447
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5730
                     Learning rate: 0.0009
                       Mean reward: 5.77
               Mean episode length: 151.43
       Episode_Reward/keep_balance: 0.1441
     Episode_Reward/rew_lin_vel_xy: 0.2317
      Episode_Reward/rew_ang_vel_z: 0.4307
    Episode_Reward/pen_base_height: -0.1587
      Episode_Reward/pen_lin_vel_z: -0.0183
     Episode_Reward/pen_ang_vel_xy: -0.0281
   Episode_Reward/pen_joint_torque: -0.0234
    Episode_Reward/pen_joint_accel: -0.0137
    Episode_Reward/pen_action_rate: -0.0060
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0056
   Episode_Reward/pen_joint_powers: -0.0084
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0129
Episode_Reward/pen_flat_orientation: -0.1049
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0289
   Episode_Reward/foot_landing_vel: -0.0228
   Episode_Reward/test_gait_reward: -0.1313
Metrics/base_velocity/error_vel_xy: 0.5488
Metrics/base_velocity/error_vel_yaw: 0.1326
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 19.7917
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 1.06s
                        Total time: 380.98s
                               ETA: 2876.4s

################################################################################
                     [1m Learning iteration 351/3000 [0m                      

                       Computation: 91115 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.7046
                    Surrogate loss: 0.0002
             Mean action noise std: 0.5732
                     Learning rate: 0.0006
                       Mean reward: 6.98
               Mean episode length: 174.54
       Episode_Reward/keep_balance: 0.1678
     Episode_Reward/rew_lin_vel_xy: 0.2868
      Episode_Reward/rew_ang_vel_z: 0.5002
    Episode_Reward/pen_base_height: -0.1663
      Episode_Reward/pen_lin_vel_z: -0.0200
     Episode_Reward/pen_ang_vel_xy: -0.0300
   Episode_Reward/pen_joint_torque: -0.0267
    Episode_Reward/pen_joint_accel: -0.0166
    Episode_Reward/pen_action_rate: -0.0071
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0064
   Episode_Reward/pen_joint_powers: -0.0096
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0153
Episode_Reward/pen_flat_orientation: -0.1182
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0319
   Episode_Reward/foot_landing_vel: -0.0266
   Episode_Reward/test_gait_reward: -0.1526
Metrics/base_velocity/error_vel_xy: 0.6210
Metrics/base_velocity/error_vel_yaw: 0.1552
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 29.0833
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 1.08s
                        Total time: 382.06s
                               ETA: 2875.2s

################################################################################
                     [1m Learning iteration 352/3000 [0m                      

                       Computation: 89023 steps/s (collection: 0.979s, learning 0.126s)
               Value function loss: 0.7080
                    Surrogate loss: 0.0021
             Mean action noise std: 0.5736
                     Learning rate: 0.0006
                       Mean reward: 6.87
               Mean episode length: 178.13
       Episode_Reward/keep_balance: 0.1647
     Episode_Reward/rew_lin_vel_xy: 0.2866
      Episode_Reward/rew_ang_vel_z: 0.4922
    Episode_Reward/pen_base_height: -0.1665
      Episode_Reward/pen_lin_vel_z: -0.0196
     Episode_Reward/pen_ang_vel_xy: -0.0298
   Episode_Reward/pen_joint_torque: -0.0261
    Episode_Reward/pen_joint_accel: -0.0161
    Episode_Reward/pen_action_rate: -0.0069
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0062
   Episode_Reward/pen_joint_powers: -0.0093
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0149
Episode_Reward/pen_flat_orientation: -0.1138
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0315
   Episode_Reward/foot_landing_vel: -0.0262
   Episode_Reward/test_gait_reward: -0.1498
Metrics/base_velocity/error_vel_xy: 0.6009
Metrics/base_velocity/error_vel_yaw: 0.1513
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 24.7083
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 1.10s
                        Total time: 383.16s
                               ETA: 2874.3s

################################################################################
                     [1m Learning iteration 353/3000 [0m                      

                       Computation: 92332 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 0.6612
                    Surrogate loss: 0.0002
             Mean action noise std: 0.5730
                     Learning rate: 0.0006
                       Mean reward: 6.30
               Mean episode length: 166.81
       Episode_Reward/keep_balance: 0.1561
     Episode_Reward/rew_lin_vel_xy: 0.2632
      Episode_Reward/rew_ang_vel_z: 0.4657
    Episode_Reward/pen_base_height: -0.1622
      Episode_Reward/pen_lin_vel_z: -0.0186
     Episode_Reward/pen_ang_vel_xy: -0.0291
   Episode_Reward/pen_joint_torque: -0.0247
    Episode_Reward/pen_joint_accel: -0.0150
    Episode_Reward/pen_action_rate: -0.0065
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0059
   Episode_Reward/pen_joint_powers: -0.0089
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0141
Episode_Reward/pen_flat_orientation: -0.1136
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0306
   Episode_Reward/foot_landing_vel: -0.0239
   Episode_Reward/test_gait_reward: -0.1423
Metrics/base_velocity/error_vel_xy: 0.5714
Metrics/base_velocity/error_vel_yaw: 0.1445
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 17.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 1.06s
                        Total time: 384.23s
                               ETA: 2873.0s

################################################################################
                     [1m Learning iteration 354/3000 [0m                      

                       Computation: 91013 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 0.7405
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5728
                     Learning rate: 0.0013
                       Mean reward: 6.64
               Mean episode length: 161.97
       Episode_Reward/keep_balance: 0.1686
     Episode_Reward/rew_lin_vel_xy: 0.2704
      Episode_Reward/rew_ang_vel_z: 0.5058
    Episode_Reward/pen_base_height: -0.1692
      Episode_Reward/pen_lin_vel_z: -0.0200
     Episode_Reward/pen_ang_vel_xy: -0.0299
   Episode_Reward/pen_joint_torque: -0.0270
    Episode_Reward/pen_joint_accel: -0.0164
    Episode_Reward/pen_action_rate: -0.0071
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0064
   Episode_Reward/pen_joint_powers: -0.0097
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0153
Episode_Reward/pen_flat_orientation: -0.1206
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0319
   Episode_Reward/foot_landing_vel: -0.0267
   Episode_Reward/test_gait_reward: -0.1534
Metrics/base_velocity/error_vel_xy: 0.6218
Metrics/base_velocity/error_vel_yaw: 0.1541
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 23.5833
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 1.08s
                        Total time: 385.31s
                               ETA: 2871.9s

################################################################################
                     [1m Learning iteration 355/3000 [0m                      

                       Computation: 91212 steps/s (collection: 0.949s, learning 0.128s)
               Value function loss: 0.8465
                    Surrogate loss: -0.0016
             Mean action noise std: 0.5740
                     Learning rate: 0.0029
                       Mean reward: 6.57
               Mean episode length: 148.63
       Episode_Reward/keep_balance: 0.1590
     Episode_Reward/rew_lin_vel_xy: 0.2849
      Episode_Reward/rew_ang_vel_z: 0.4743
    Episode_Reward/pen_base_height: -0.1652
      Episode_Reward/pen_lin_vel_z: -0.0185
     Episode_Reward/pen_ang_vel_xy: -0.0283
   Episode_Reward/pen_joint_torque: -0.0245
    Episode_Reward/pen_joint_accel: -0.0155
    Episode_Reward/pen_action_rate: -0.0066
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0059
   Episode_Reward/pen_joint_powers: -0.0088
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0144
Episode_Reward/pen_flat_orientation: -0.1169
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0290
   Episode_Reward/foot_landing_vel: -0.0242
   Episode_Reward/test_gait_reward: -0.1465
Metrics/base_velocity/error_vel_xy: 0.5695
Metrics/base_velocity/error_vel_yaw: 0.1472
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 23.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 1.08s
                        Total time: 386.39s
                               ETA: 2870.8s

################################################################################
                     [1m Learning iteration 356/3000 [0m                      

                       Computation: 92091 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 0.7304
                    Surrogate loss: 0.0021
             Mean action noise std: 0.5747
                     Learning rate: 0.0013
                       Mean reward: 5.98
               Mean episode length: 162.82
       Episode_Reward/keep_balance: 0.1693
     Episode_Reward/rew_lin_vel_xy: 0.2818
      Episode_Reward/rew_ang_vel_z: 0.5085
    Episode_Reward/pen_base_height: -0.1672
      Episode_Reward/pen_lin_vel_z: -0.0188
     Episode_Reward/pen_ang_vel_xy: -0.0290
   Episode_Reward/pen_joint_torque: -0.0259
    Episode_Reward/pen_joint_accel: -0.0154
    Episode_Reward/pen_action_rate: -0.0070
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0060
   Episode_Reward/pen_joint_powers: -0.0092
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0153
Episode_Reward/pen_flat_orientation: -0.1194
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0297
   Episode_Reward/foot_landing_vel: -0.0254
   Episode_Reward/test_gait_reward: -0.1531
Metrics/base_velocity/error_vel_xy: 0.6193
Metrics/base_velocity/error_vel_yaw: 0.1540
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 23.2500
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 1.07s
                        Total time: 387.45s
                               ETA: 2869.5s

################################################################################
                     [1m Learning iteration 357/3000 [0m                      

                       Computation: 92821 steps/s (collection: 0.936s, learning 0.123s)
               Value function loss: 0.7290
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5752
                     Learning rate: 0.0013
                       Mean reward: 6.82
               Mean episode length: 158.15
       Episode_Reward/keep_balance: 0.1657
     Episode_Reward/rew_lin_vel_xy: 0.2842
      Episode_Reward/rew_ang_vel_z: 0.4993
    Episode_Reward/pen_base_height: -0.1648
      Episode_Reward/pen_lin_vel_z: -0.0187
     Episode_Reward/pen_ang_vel_xy: -0.0288
   Episode_Reward/pen_joint_torque: -0.0254
    Episode_Reward/pen_joint_accel: -0.0166
    Episode_Reward/pen_action_rate: -0.0068
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0059
   Episode_Reward/pen_joint_powers: -0.0090
Episode_Reward/pen_undesired_contacts: -0.0018
Episode_Reward/pen_action_smoothness: -0.0150
Episode_Reward/pen_flat_orientation: -0.1142
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0282
   Episode_Reward/foot_landing_vel: -0.0248
   Episode_Reward/test_gait_reward: -0.1505
Metrics/base_velocity/error_vel_xy: 0.5958
Metrics/base_velocity/error_vel_yaw: 0.1499
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 21.7500
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 1.06s
                        Total time: 388.51s
                               ETA: 2868.3s

################################################################################
                     [1m Learning iteration 358/3000 [0m                      

                       Computation: 92254 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 0.8149
                    Surrogate loss: 0.0076
             Mean action noise std: 0.5753
                     Learning rate: 0.0002
                       Mean reward: 5.99
               Mean episode length: 157.89
       Episode_Reward/keep_balance: 0.1752
     Episode_Reward/rew_lin_vel_xy: 0.2972
      Episode_Reward/rew_ang_vel_z: 0.5303
    Episode_Reward/pen_base_height: -0.1708
      Episode_Reward/pen_lin_vel_z: -0.0202
     Episode_Reward/pen_ang_vel_xy: -0.0298
   Episode_Reward/pen_joint_torque: -0.0284
    Episode_Reward/pen_joint_accel: -0.0165
    Episode_Reward/pen_action_rate: -0.0073
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0064
   Episode_Reward/pen_joint_powers: -0.0099
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0157
Episode_Reward/pen_flat_orientation: -0.1189
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0318
   Episode_Reward/foot_landing_vel: -0.0266
   Episode_Reward/test_gait_reward: -0.1586
Metrics/base_velocity/error_vel_xy: 0.6396
Metrics/base_velocity/error_vel_yaw: 0.1557
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 18.1250
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 1.07s
                        Total time: 389.58s
                               ETA: 2867.0s

################################################################################
                     [1m Learning iteration 359/3000 [0m                      

                       Computation: 89729 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.6012
                    Surrogate loss: -0.0018
             Mean action noise std: 0.5753
                     Learning rate: 0.0006
                       Mean reward: 6.78
               Mean episode length: 167.53
       Episode_Reward/keep_balance: 0.1601
     Episode_Reward/rew_lin_vel_xy: 0.2792
      Episode_Reward/rew_ang_vel_z: 0.4763
    Episode_Reward/pen_base_height: -0.1647
      Episode_Reward/pen_lin_vel_z: -0.0186
     Episode_Reward/pen_ang_vel_xy: -0.0286
   Episode_Reward/pen_joint_torque: -0.0255
    Episode_Reward/pen_joint_accel: -0.0157
    Episode_Reward/pen_action_rate: -0.0068
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0060
   Episode_Reward/pen_joint_powers: -0.0090
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0147
Episode_Reward/pen_flat_orientation: -0.1124
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0302
   Episode_Reward/foot_landing_vel: -0.0247
   Episode_Reward/test_gait_reward: -0.1469
Metrics/base_velocity/error_vel_xy: 0.5902
Metrics/base_velocity/error_vel_yaw: 0.1490
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 1.10s
                        Total time: 390.67s
                               ETA: 2866.0s

################################################################################
                     [1m Learning iteration 360/3000 [0m                      

                       Computation: 92227 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 0.6288
                    Surrogate loss: 0.0010
             Mean action noise std: 0.5749
                     Learning rate: 0.0006
                       Mean reward: 6.28
               Mean episode length: 165.82
       Episode_Reward/keep_balance: 0.1530
     Episode_Reward/rew_lin_vel_xy: 0.2512
      Episode_Reward/rew_ang_vel_z: 0.4608
    Episode_Reward/pen_base_height: -0.1611
      Episode_Reward/pen_lin_vel_z: -0.0177
     Episode_Reward/pen_ang_vel_xy: -0.0279
   Episode_Reward/pen_joint_torque: -0.0241
    Episode_Reward/pen_joint_accel: -0.0143
    Episode_Reward/pen_action_rate: -0.0064
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0056
   Episode_Reward/pen_joint_powers: -0.0085
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0139
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0285
   Episode_Reward/foot_landing_vel: -0.0230
   Episode_Reward/test_gait_reward: -0.1405
Metrics/base_velocity/error_vel_xy: 0.5556
Metrics/base_velocity/error_vel_yaw: 0.1380
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 17.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 1.07s
                        Total time: 391.74s
                               ETA: 2864.8s

################################################################################
                     [1m Learning iteration 361/3000 [0m                      

                       Computation: 91612 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.6028
                    Surrogate loss: 0.0004
             Mean action noise std: 0.5752
                     Learning rate: 0.0006
                       Mean reward: 6.31
               Mean episode length: 169.24
       Episode_Reward/keep_balance: 0.1675
     Episode_Reward/rew_lin_vel_xy: 0.2892
      Episode_Reward/rew_ang_vel_z: 0.5013
    Episode_Reward/pen_base_height: -0.1660
      Episode_Reward/pen_lin_vel_z: -0.0185
     Episode_Reward/pen_ang_vel_xy: -0.0290
   Episode_Reward/pen_joint_torque: -0.0261
    Episode_Reward/pen_joint_accel: -0.0167
    Episode_Reward/pen_action_rate: -0.0071
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0061
   Episode_Reward/pen_joint_powers: -0.0092
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0154
Episode_Reward/pen_flat_orientation: -0.1172
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0305
   Episode_Reward/foot_landing_vel: -0.0256
   Episode_Reward/test_gait_reward: -0.1534
Metrics/base_velocity/error_vel_xy: 0.5962
Metrics/base_velocity/error_vel_yaw: 0.1536
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 17.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 1.07s
                        Total time: 392.81s
                               ETA: 2863.6s

################################################################################
                     [1m Learning iteration 362/3000 [0m                      

                       Computation: 91564 steps/s (collection: 0.947s, learning 0.126s)
               Value function loss: 0.5766
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5763
                     Learning rate: 0.0013
                       Mean reward: 7.28
               Mean episode length: 176.38
       Episode_Reward/keep_balance: 0.1728
     Episode_Reward/rew_lin_vel_xy: 0.2931
      Episode_Reward/rew_ang_vel_z: 0.5218
    Episode_Reward/pen_base_height: -0.1681
      Episode_Reward/pen_lin_vel_z: -0.0187
     Episode_Reward/pen_ang_vel_xy: -0.0287
   Episode_Reward/pen_joint_torque: -0.0272
    Episode_Reward/pen_joint_accel: -0.0171
    Episode_Reward/pen_action_rate: -0.0073
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0061
   Episode_Reward/pen_joint_powers: -0.0095
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0159
Episode_Reward/pen_flat_orientation: -0.1203
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0294
   Episode_Reward/foot_landing_vel: -0.0257
   Episode_Reward/test_gait_reward: -0.1572
Metrics/base_velocity/error_vel_xy: 0.6283
Metrics/base_velocity/error_vel_yaw: 0.1547
      Episode_Termination/time_out: 0.0833
  Episode_Termination/base_contact: 17.2083
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 1.07s
                        Total time: 393.89s
                               ETA: 2862.5s

################################################################################
                     [1m Learning iteration 363/3000 [0m                      

                       Computation: 89947 steps/s (collection: 0.965s, learning 0.128s)
               Value function loss: 0.7179
                    Surrogate loss: 0.0007
             Mean action noise std: 0.5760
                     Learning rate: 0.0006
                       Mean reward: 7.87
               Mean episode length: 183.18
       Episode_Reward/keep_balance: 0.1912
     Episode_Reward/rew_lin_vel_xy: 0.3399
      Episode_Reward/rew_ang_vel_z: 0.5800
    Episode_Reward/pen_base_height: -0.1749
      Episode_Reward/pen_lin_vel_z: -0.0200
     Episode_Reward/pen_ang_vel_xy: -0.0301
   Episode_Reward/pen_joint_torque: -0.0298
    Episode_Reward/pen_joint_accel: -0.0176
    Episode_Reward/pen_action_rate: -0.0081
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0067
   Episode_Reward/pen_joint_powers: -0.0104
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0175
Episode_Reward/pen_flat_orientation: -0.1255
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0326
   Episode_Reward/foot_landing_vel: -0.0286
   Episode_Reward/test_gait_reward: -0.1740
Metrics/base_velocity/error_vel_xy: 0.6724
Metrics/base_velocity/error_vel_yaw: 0.1690
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 19.5000
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 1.09s
                        Total time: 394.98s
                               ETA: 2861.4s

################################################################################
                     [1m Learning iteration 364/3000 [0m                      

                       Computation: 90100 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.7556
                    Surrogate loss: 0.0018
             Mean action noise std: 0.5758
                     Learning rate: 0.0004
                       Mean reward: 6.31
               Mean episode length: 175.91
       Episode_Reward/keep_balance: 0.1835
     Episode_Reward/rew_lin_vel_xy: 0.3028
      Episode_Reward/rew_ang_vel_z: 0.5513
    Episode_Reward/pen_base_height: -0.1704
      Episode_Reward/pen_lin_vel_z: -0.0197
     Episode_Reward/pen_ang_vel_xy: -0.0299
   Episode_Reward/pen_joint_torque: -0.0290
    Episode_Reward/pen_joint_accel: -0.0173
    Episode_Reward/pen_action_rate: -0.0078
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0067
   Episode_Reward/pen_joint_powers: -0.0102
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0168
Episode_Reward/pen_flat_orientation: -0.1224
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0337
   Episode_Reward/foot_landing_vel: -0.0285
   Episode_Reward/test_gait_reward: -0.1690
Metrics/base_velocity/error_vel_xy: 0.6827
Metrics/base_velocity/error_vel_yaw: 0.1657
      Episode_Termination/time_out: 0.1250
  Episode_Termination/base_contact: 13.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 1.09s
                        Total time: 396.07s
                               ETA: 2860.4s

################################################################################
                     [1m Learning iteration 365/3000 [0m                      

                       Computation: 90610 steps/s (collection: 0.960s, learning 0.125s)
               Value function loss: 0.6164
                    Surrogate loss: 0.0032
             Mean action noise std: 0.5763
                     Learning rate: 0.0004
                       Mean reward: 8.27
               Mean episode length: 197.12
       Episode_Reward/keep_balance: 0.1717
     Episode_Reward/rew_lin_vel_xy: 0.2797
      Episode_Reward/rew_ang_vel_z: 0.5131
    Episode_Reward/pen_base_height: -0.1690
      Episode_Reward/pen_lin_vel_z: -0.0190
     Episode_Reward/pen_ang_vel_xy: -0.0295
   Episode_Reward/pen_joint_torque: -0.0263
    Episode_Reward/pen_joint_accel: -0.0174
    Episode_Reward/pen_action_rate: -0.0074
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0064
   Episode_Reward/pen_joint_powers: -0.0095
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0159
Episode_Reward/pen_flat_orientation: -0.1222
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0315
   Episode_Reward/foot_landing_vel: -0.0258
   Episode_Reward/test_gait_reward: -0.1584
Metrics/base_velocity/error_vel_xy: 0.6267
Metrics/base_velocity/error_vel_yaw: 0.1578
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 14.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 1.08s
                        Total time: 397.16s
                               ETA: 2859.3s

################################################################################
                     [1m Learning iteration 366/3000 [0m                      

                       Computation: 89038 steps/s (collection: 0.981s, learning 0.123s)
               Value function loss: 0.5914
                    Surrogate loss: -0.0006
             Mean action noise std: 0.5762
                     Learning rate: 0.0009
                       Mean reward: 10.97
               Mean episode length: 224.96
       Episode_Reward/keep_balance: 0.1970
     Episode_Reward/rew_lin_vel_xy: 0.3425
      Episode_Reward/rew_ang_vel_z: 0.5974
    Episode_Reward/pen_base_height: -0.1773
      Episode_Reward/pen_lin_vel_z: -0.0204
     Episode_Reward/pen_ang_vel_xy: -0.0307
   Episode_Reward/pen_joint_torque: -0.0306
    Episode_Reward/pen_joint_accel: -0.0191
    Episode_Reward/pen_action_rate: -0.0085
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0070
   Episode_Reward/pen_joint_powers: -0.0107
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0182
Episode_Reward/pen_flat_orientation: -0.1309
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0335
   Episode_Reward/foot_landing_vel: -0.0294
   Episode_Reward/test_gait_reward: -0.1794
Metrics/base_velocity/error_vel_xy: 0.6973
Metrics/base_velocity/error_vel_yaw: 0.1748
      Episode_Termination/time_out: 0.0417
  Episode_Termination/base_contact: 22.5000
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 1.10s
                        Total time: 398.26s
                               ETA: 2858.4s

################################################################################
                     [1m Learning iteration 367/3000 [0m                      

                       Computation: 89494 steps/s (collection: 0.974s, learning 0.125s)
               Value function loss: 0.8113
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5764
                     Learning rate: 0.0009
                       Mean reward: 11.82
               Mean episode length: 220.25
       Episode_Reward/keep_balance: 0.2314
     Episode_Reward/rew_lin_vel_xy: 0.4236
      Episode_Reward/rew_ang_vel_z: 0.6988
    Episode_Reward/pen_base_height: -0.1898
      Episode_Reward/pen_lin_vel_z: -0.0227
     Episode_Reward/pen_ang_vel_xy: -0.0342
   Episode_Reward/pen_joint_torque: -0.0358
    Episode_Reward/pen_joint_accel: -0.0218
    Episode_Reward/pen_action_rate: -0.0101
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0082
   Episode_Reward/pen_joint_powers: -0.0125
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0216
Episode_Reward/pen_flat_orientation: -0.1467
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0400
   Episode_Reward/foot_landing_vel: -0.0343
   Episode_Reward/test_gait_reward: -0.2106
Metrics/base_velocity/error_vel_xy: 0.8090
Metrics/base_velocity/error_vel_yaw: 0.2061
      Episode_Termination/time_out: 0.0000
  Episode_Termination/base_contact: 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 1.10s
                        Total time: 399.36s
                               ETA: 2857.4s

################################################################################
                     [1m Learning iteration 368/3000 [0m                      

                       Computation: 90933 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 0.6071
                    Surrogate loss: 0.0014
             Mean action noise std: 0.5770
                     Learning rate: 0.0004
                       Mean reward: 6.21
               Mean episode length: 173.78
       Episode_Reward/keep_balance: 0.1947
     Episode_Reward/rew_lin_vel_xy: 0.3207
      Episode_Reward/rew_ang_vel_z: 0.5841
    Episode_Reward/pen_base_height: -0.1745
      Episode_Reward/pen_lin_vel_z: -0.0200
     Episode_Reward/pen_ang_vel_xy: -0.0309
   Episode_Reward/pen_joint_torque: -0.0301
    Episode_Reward/pen_joint_accel: -0.0187
    Episode_Reward/pen_action_rate: -0.0084
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0069
   Episode_Reward/pen_joint_powers: -0.0106
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0183
Episode_Reward/pen_flat_orientation: -0.1306
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0333
   Episode_Reward/foot_landing_vel: -0.0291
   Episode_Reward/test_gait_reward: -0.1778
Metrics/base_velocity/error_vel_xy: 0.6983
Metrics/base_velocity/error_vel_yaw: 0.1770
      Episode_Termination/time_out: 0.0833
  Episode_Termination/base_contact: 14.5833
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 1.08s
                        Total time: 400.44s
                               ETA: 2856.2s

################################################################################
                     [1m Learning iteration 369/3000 [0m                      

                       Computation: 90102 steps/s (collection: 0.966s, learning 0.125s)
               Value function loss: 0.5725
                    Surrogate loss: 0.0011
             Mean action noise std: 0.5776
                     Learning rate: 0.0006
                       Mean reward: 10.01
               Mean episode length: 210.89
       Episode_Reward/keep_balance: 0.2075
     Episode_Reward/rew_lin_vel_xy: 0.3685
      Episode_Reward/rew_ang_vel_z: 0.6268
    Episode_Reward/pen_base_height: -0.1811
      Episode_Reward/pen_lin_vel_z: -0.0214
     Episode_Reward/pen_ang_vel_xy: -0.0318
   Episode_Reward/pen_joint_torque: -0.0331
    Episode_Reward/pen_joint_accel: -0.0198
    Episode_Reward/pen_action_rate: -0.0090
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0074
   Episode_Reward/pen_joint_powers: -0.0114
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0193
Episode_Reward/pen_flat_orientation: -0.1405
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0367
   Episode_Reward/foot_landing_vel: -0.0313
   Episode_Reward/test_gait_reward: -0.1902
Metrics/base_velocity/error_vel_xy: 0.7299
Metrics/base_velocity/error_vel_yaw: 0.1851
      Episode_Termination/time_out: 0.1250
  Episode_Termination/base_contact: 17.5000
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 1.09s
                        Total time: 401.53s
                               ETA: 2855.2s

################################################################################
                     [1m Learning iteration 370/3000 [0m                      

                       Computation: 90882 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.5757
                    Surrogate loss: 0.0016
             Mean action noise std: 0.5777
                     Learning rate: 0.0009
                       Mean reward: 11.50
               Mean episode length: 234.50
       Episode_Reward/keep_balance: 0.2156
     Episode_Reward/rew_lin_vel_xy: 0.3669
      Episode_Reward/rew_ang_vel_z: 0.6503
    Episode_Reward/pen_base_height: -0.1830
      Episode_Reward/pen_lin_vel_z: -0.0223
     Episode_Reward/pen_ang_vel_xy: -0.0329
   Episode_Reward/pen_joint_torque: -0.0340
    Episode_Reward/pen_joint_accel: -0.0210
    Episode_Reward/pen_action_rate: -0.0095
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0079
   Episode_Reward/pen_joint_powers: -0.0120
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.0202
Episode_Reward/pen_flat_orientation: -0.1444
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0394
   Episode_Reward/foot_landing_vel: -0.0334
   Episode_Reward/test_gait_reward: -0.1984
Metrics/base_velocity/error_vel_xy: 0.7651
Metrics/base_velocity/error_vel_yaw: 0.1930
      Episode_Termination/time_out: 0.1667
  Episode_Termination/base_contact: 15.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 1.08s
                        Total time: 402.61s
                               ETA: 2854.1s

################################################################################
                     [1m Learning iteration 371/3000 [0m                      

                       Computation: 90574 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.7602
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5781
                     Learning rate: 0.0013
                       Mean reward: 10.29
               Mean episode length: 230.35
       Episode_Reward/keep_balance: 0.2017
     Episode_Reward/rew_lin_vel_xy: 0.3366
      Episode_Reward/rew_ang_vel_z: 0.6123
    Episode_Reward/pen_base_height: -0.1778
      Episode_Reward/pen_lin_vel_z: -0.0203
     Episode_Reward/pen_ang_vel_xy: -0.0312
   Episode_Reward/pen_joint_torque: -0.0311
    Episode_Reward/pen_joint_accel: -0.0204
    Episode_Reward/pen_action_rate: -0.0087
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0072
   Episode_Reward/pen_joint_powers: -0.0109
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0188
Episode_Reward/pen_flat_orientation: -0.1328
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0339
   Episode_Reward/foot_landing_vel: -0.0306
   Episode_Reward/test_gait_reward: -0.1838
Metrics/base_velocity/error_vel_xy: 0.7141
Metrics/base_velocity/error_vel_yaw: 0.1782
      Episode_Termination/time_out: 0.2083
  Episode_Termination/base_contact: 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 1.09s
                        Total time: 403.70s
                               ETA: 2853.0s

################################################################################
                     [1m Learning iteration 372/3000 [0m                      

                       Computation: 90782 steps/s (collection: 0.957s, learning 0.126s)
               Value function loss: 0.7097
                    Surrogate loss: 0.0010
             Mean action noise std: 0.5786
                     Learning rate: 0.0013
                       Mean reward: 8.39
               Mean episode length: 206.06
       Episode_Reward/keep_balance: 0.2000
     Episode_Reward/rew_lin_vel_xy: 0.3290
      Episode_Reward/rew_ang_vel_z: 0.6034
    Episode_Reward/pen_base_height: -0.1787
      Episode_Reward/pen_lin_vel_z: -0.0208
     Episode_Reward/pen_ang_vel_xy: -0.0311
   Episode_Reward/pen_joint_torque: -0.0312
    Episode_Reward/pen_joint_accel: -0.0191
    Episode_Reward/pen_action_rate: -0.0087
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0072
   Episode_Reward/pen_joint_powers: -0.0109
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0187
Episode_Reward/pen_flat_orientation: -0.1366
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0357
   Episode_Reward/foot_landing_vel: -0.0297
   Episode_Reward/test_gait_reward: -0.1843
Metrics/base_velocity/error_vel_xy: 0.7144
Metrics/base_velocity/error_vel_yaw: 0.1801
      Episode_Termination/time_out: 0.1667
  Episode_Termination/base_contact: 14.2083
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 1.08s
                        Total time: 404.78s
                               ETA: 2851.9s

################################################################################
                     [1m Learning iteration 373/3000 [0m                      

                       Computation: 89653 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 0.6981
                    Surrogate loss: -0.0027
             Mean action noise std: 0.5781
                     Learning rate: 0.0019
                       Mean reward: 9.41
               Mean episode length: 222.07
       Episode_Reward/keep_balance: 0.2082
     Episode_Reward/rew_lin_vel_xy: 0.3609
      Episode_Reward/rew_ang_vel_z: 0.6286
    Episode_Reward/pen_base_height: -0.1775
      Episode_Reward/pen_lin_vel_z: -0.0212
     Episode_Reward/pen_ang_vel_xy: -0.0322
   Episode_Reward/pen_joint_torque: -0.0330
    Episode_Reward/pen_joint_accel: -0.0203
    Episode_Reward/pen_action_rate: -0.0091
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0075
   Episode_Reward/pen_joint_powers: -0.0115
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.0196
Episode_Reward/pen_flat_orientation: -0.1382
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0361
   Episode_Reward/foot_landing_vel: -0.0313
   Episode_Reward/test_gait_reward: -0.1902
Metrics/base_velocity/error_vel_xy: 0.7382
Metrics/base_velocity/error_vel_yaw: 0.1863
      Episode_Termination/time_out: 0.1667
  Episode_Termination/base_contact: 13.5833
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 1.10s
                        Total time: 405.88s
                               ETA: 2850.9s

################################################################################
                     [1m Learning iteration 374/3000 [0m                      

                       Computation: 89274 steps/s (collection: 0.973s, learning 0.128s)
               Value function loss: 0.7756
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5777
                     Learning rate: 0.0013
                       Mean reward: 9.32
               Mean episode length: 208.25
       Episode_Reward/keep_balance: 0.2191
     Episode_Reward/rew_lin_vel_xy: 0.3885
      Episode_Reward/rew_ang_vel_z: 0.6646
    Episode_Reward/pen_base_height: -0.1828
      Episode_Reward/pen_lin_vel_z: -0.0213
     Episode_Reward/pen_ang_vel_xy: -0.0326
   Episode_Reward/pen_joint_torque: -0.0334
    Episode_Reward/pen_joint_accel: -0.0197
    Episode_Reward/pen_action_rate: -0.0096
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0076
   Episode_Reward/pen_joint_powers: -0.0117
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0207
Episode_Reward/pen_flat_orientation: -0.1416
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0371
   Episode_Reward/foot_landing_vel: -0.0328
   Episode_Reward/test_gait_reward: -0.1992
Metrics/base_velocity/error_vel_xy: 0.7707
Metrics/base_velocity/error_vel_yaw: 0.1939
      Episode_Termination/time_out: 0.1667
  Episode_Termination/base_contact: 12.9583
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 1.10s
                        Total time: 406.98s
                               ETA: 2849.9s

################################################################################
                     [1m Learning iteration 375/3000 [0m                      

                       Computation: 88421 steps/s (collection: 0.985s, learning 0.127s)
               Value function loss: 0.7319
                    Surrogate loss: 0.0012
             Mean action noise std: 0.5779
                     Learning rate: 0.0004
                       Mean reward: 10.61
               Mean episode length: 227.07
       Episode_Reward/keep_balance: 0.2310
     Episode_Reward/rew_lin_vel_xy: 0.4090
      Episode_Reward/rew_ang_vel_z: 0.6901
    Episode_Reward/pen_base_height: -0.1856
      Episode_Reward/pen_lin_vel_z: -0.0229
     Episode_Reward/pen_ang_vel_xy: -0.0335
   Episode_Reward/pen_joint_torque: -0.0366
    Episode_Reward/pen_joint_accel: -0.0221
    Episode_Reward/pen_action_rate: -0.0102
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0083
   Episode_Reward/pen_joint_powers: -0.0127
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0220
Episode_Reward/pen_flat_orientation: -0.1482
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0414
   Episode_Reward/foot_landing_vel: -0.0342
   Episode_Reward/test_gait_reward: -0.2098
Metrics/base_velocity/error_vel_xy: 0.7882
Metrics/base_velocity/error_vel_yaw: 0.2123
      Episode_Termination/time_out: 0.3333
  Episode_Termination/base_contact: 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 1.11s
                        Total time: 408.09s
                               ETA: 2849.0s

################################################################################
                     [1m Learning iteration 376/3000 [0m                      

                       Computation: 83740 steps/s (collection: 1.045s, learning 0.129s)
               Value function loss: 0.7245
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5782
                     Learning rate: 0.0009
                       Mean reward: 11.43
               Mean episode length: 244.62
       Episode_Reward/keep_balance: 0.2455
     Episode_Reward/rew_lin_vel_xy: 0.4086
      Episode_Reward/rew_ang_vel_z: 0.7351
    Episode_Reward/pen_base_height: -0.1928
      Episode_Reward/pen_lin_vel_z: -0.0255
     Episode_Reward/pen_ang_vel_xy: -0.0359
   Episode_Reward/pen_joint_torque: -0.0409
    Episode_Reward/pen_joint_accel: -0.0249
    Episode_Reward/pen_action_rate: -0.0112
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0094
   Episode_Reward/pen_joint_powers: -0.0143
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0236
Episode_Reward/pen_flat_orientation: -0.1607
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0455
   Episode_Reward/foot_landing_vel: -0.0416
   Episode_Reward/test_gait_reward: -0.2261
Metrics/base_velocity/error_vel_xy: 0.8609
Metrics/base_velocity/error_vel_yaw: 0.2240
      Episode_Termination/time_out: 0.6250
  Episode_Termination/base_contact: 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 1.17s
                        Total time: 409.26s
                               ETA: 2848.6s

################################################################################
                     [1m Learning iteration 377/3000 [0m                      

                       Computation: 87285 steps/s (collection: 0.999s, learning 0.127s)
               Value function loss: 0.5987
                    Surrogate loss: 0.0015
             Mean action noise std: 0.5785
                     Learning rate: 0.0006
                       Mean reward: 11.66
               Mean episode length: 227.21
       Episode_Reward/keep_balance: 0.2265
     Episode_Reward/rew_lin_vel_xy: 0.3976
      Episode_Reward/rew_ang_vel_z: 0.6886
    Episode_Reward/pen_base_height: -0.1832
      Episode_Reward/pen_lin_vel_z: -0.0218
     Episode_Reward/pen_ang_vel_xy: -0.0331
   Episode_Reward/pen_joint_torque: -0.0353
    Episode_Reward/pen_joint_accel: -0.0215
    Episode_Reward/pen_action_rate: -0.0100
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0078
   Episode_Reward/pen_joint_powers: -0.0122
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.0214
Episode_Reward/pen_flat_orientation: -0.1451
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0376
   Episode_Reward/foot_landing_vel: -0.0332
   Episode_Reward/test_gait_reward: -0.2060
Metrics/base_velocity/error_vel_xy: 0.7962
Metrics/base_velocity/error_vel_yaw: 0.1989
      Episode_Termination/time_out: 0.3750
  Episode_Termination/base_contact: 16.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 1.13s
                        Total time: 410.39s
                               ETA: 2847.8s

################################################################################
                     [1m Learning iteration 378/3000 [0m                      

                       Computation: 89743 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.5868
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5788
                     Learning rate: 0.0009
                       Mean reward: 13.64
               Mean episode length: 274.60
       Episode_Reward/keep_balance: 0.2508
     Episode_Reward/rew_lin_vel_xy: 0.4497
      Episode_Reward/rew_ang_vel_z: 0.7590
    Episode_Reward/pen_base_height: -0.1898
      Episode_Reward/pen_lin_vel_z: -0.0232
     Episode_Reward/pen_ang_vel_xy: -0.0340
   Episode_Reward/pen_joint_torque: -0.0398
    Episode_Reward/pen_joint_accel: -0.0214
    Episode_Reward/pen_action_rate: -0.0110
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0084
   Episode_Reward/pen_joint_powers: -0.0134
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0237
Episode_Reward/pen_flat_orientation: -0.1528
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0413
   Episode_Reward/foot_landing_vel: -0.0361
   Episode_Reward/test_gait_reward: -0.2274
Metrics/base_velocity/error_vel_xy: 0.8783
Metrics/base_velocity/error_vel_yaw: 0.2225
      Episode_Termination/time_out: 0.3333
  Episode_Termination/base_contact: 13.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 1.10s
                        Total time: 411.49s
                               ETA: 2846.7s

################################################################################
                     [1m Learning iteration 379/3000 [0m                      

                       Computation: 90463 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.5549
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5789
                     Learning rate: 0.0013
                       Mean reward: 12.02
               Mean episode length: 258.60
       Episode_Reward/keep_balance: 0.2740
     Episode_Reward/rew_lin_vel_xy: 0.4762
      Episode_Reward/rew_ang_vel_z: 0.8258
    Episode_Reward/pen_base_height: -0.2006
      Episode_Reward/pen_lin_vel_z: -0.0275
     Episode_Reward/pen_ang_vel_xy: -0.0380
   Episode_Reward/pen_joint_torque: -0.0453
    Episode_Reward/pen_joint_accel: -0.0277
    Episode_Reward/pen_action_rate: -0.0125
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0102
   Episode_Reward/pen_joint_powers: -0.0156
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0261
Episode_Reward/pen_flat_orientation: -0.1754
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0528
   Episode_Reward/foot_landing_vel: -0.0432
   Episode_Reward/test_gait_reward: -0.2509
Metrics/base_velocity/error_vel_xy: 0.9404
Metrics/base_velocity/error_vel_yaw: 0.2455
      Episode_Termination/time_out: 0.7500
  Episode_Termination/base_contact: 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 1.09s
                        Total time: 412.57s
                               ETA: 2845.7s

################################################################################
                     [1m Learning iteration 380/3000 [0m                      

                       Computation: 89784 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.6962
                    Surrogate loss: 0.0015
             Mean action noise std: 0.5790
                     Learning rate: 0.0006
                       Mean reward: 13.69
               Mean episode length: 268.04
       Episode_Reward/keep_balance: 0.2499
     Episode_Reward/rew_lin_vel_xy: 0.4535
      Episode_Reward/rew_ang_vel_z: 0.7606
    Episode_Reward/pen_base_height: -0.1922
      Episode_Reward/pen_lin_vel_z: -0.0251
     Episode_Reward/pen_ang_vel_xy: -0.0353
   Episode_Reward/pen_joint_torque: -0.0411
    Episode_Reward/pen_joint_accel: -0.0261
    Episode_Reward/pen_action_rate: -0.0113
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0092
   Episode_Reward/pen_joint_powers: -0.0141
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0237
Episode_Reward/pen_flat_orientation: -0.1606
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0449
   Episode_Reward/foot_landing_vel: -0.0391
   Episode_Reward/test_gait_reward: -0.2279
Metrics/base_velocity/error_vel_xy: 0.8724
Metrics/base_velocity/error_vel_yaw: 0.2187
      Episode_Termination/time_out: 0.5000
  Episode_Termination/base_contact: 12.7500
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 1.09s
                        Total time: 413.67s
                               ETA: 2844.6s

################################################################################
                     [1m Learning iteration 381/3000 [0m                      

                       Computation: 90281 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.6236
                    Surrogate loss: -0.0026
             Mean action noise std: 0.5794
                     Learning rate: 0.0013
                       Mean reward: 10.11
               Mean episode length: 248.33
       Episode_Reward/keep_balance: 0.2376
     Episode_Reward/rew_lin_vel_xy: 0.3942
      Episode_Reward/rew_ang_vel_z: 0.7165
    Episode_Reward/pen_base_height: -0.1851
      Episode_Reward/pen_lin_vel_z: -0.0237
     Episode_Reward/pen_ang_vel_xy: -0.0344
   Episode_Reward/pen_joint_torque: -0.0386
    Episode_Reward/pen_joint_accel: -0.0236
    Episode_Reward/pen_action_rate: -0.0108
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0086
   Episode_Reward/pen_joint_powers: -0.0132
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0229
Episode_Reward/pen_flat_orientation: -0.1539
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0410
   Episode_Reward/foot_landing_vel: -0.0375
   Episode_Reward/test_gait_reward: -0.2181
Metrics/base_velocity/error_vel_xy: 0.8349
Metrics/base_velocity/error_vel_yaw: 0.2123
      Episode_Termination/time_out: 0.4583
  Episode_Termination/base_contact: 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 1.09s
                        Total time: 414.76s
                               ETA: 2843.6s

################################################################################
                     [1m Learning iteration 382/3000 [0m                      

                       Computation: 90763 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.6676
                    Surrogate loss: 0.0015
             Mean action noise std: 0.5802
                     Learning rate: 0.0009
                       Mean reward: 10.85
               Mean episode length: 254.70
       Episode_Reward/keep_balance: 0.2657
     Episode_Reward/rew_lin_vel_xy: 0.4542
      Episode_Reward/rew_ang_vel_z: 0.7980
    Episode_Reward/pen_base_height: -0.1948
      Episode_Reward/pen_lin_vel_z: -0.0253
     Episode_Reward/pen_ang_vel_xy: -0.0362
   Episode_Reward/pen_joint_torque: -0.0423
    Episode_Reward/pen_joint_accel: -0.0271
    Episode_Reward/pen_action_rate: -0.0122
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0096
   Episode_Reward/pen_joint_powers: -0.0145
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0260
Episode_Reward/pen_flat_orientation: -0.1680
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0462
   Episode_Reward/foot_landing_vel: -0.0420
   Episode_Reward/test_gait_reward: -0.2427
Metrics/base_velocity/error_vel_xy: 0.9368
Metrics/base_velocity/error_vel_yaw: 0.2403
      Episode_Termination/time_out: 0.5833
  Episode_Termination/base_contact: 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 1.08s
                        Total time: 415.84s
                               ETA: 2842.5s

################################################################################
                     [1m Learning iteration 383/3000 [0m                      

                       Computation: 90368 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.6362
                    Surrogate loss: 0.0082
             Mean action noise std: 0.5804
                     Learning rate: 0.0000
                       Mean reward: 15.94
               Mean episode length: 288.13
       Episode_Reward/keep_balance: 0.2685
     Episode_Reward/rew_lin_vel_xy: 0.4902
      Episode_Reward/rew_ang_vel_z: 0.8072
    Episode_Reward/pen_base_height: -0.1963
      Episode_Reward/pen_lin_vel_z: -0.0259
     Episode_Reward/pen_ang_vel_xy: -0.0359
   Episode_Reward/pen_joint_torque: -0.0426
    Episode_Reward/pen_joint_accel: -0.0278
    Episode_Reward/pen_action_rate: -0.0123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0099
   Episode_Reward/pen_joint_powers: -0.0148
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0259
Episode_Reward/pen_flat_orientation: -0.1687
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0488
   Episode_Reward/foot_landing_vel: -0.0432
   Episode_Reward/test_gait_reward: -0.2464
Metrics/base_velocity/error_vel_xy: 0.9058
Metrics/base_velocity/error_vel_yaw: 0.2429
      Episode_Termination/time_out: 0.9167
  Episode_Termination/base_contact: 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 1.09s
                        Total time: 416.93s
                               ETA: 2841.4s

################################################################################
                     [1m Learning iteration 384/3000 [0m                      

                       Computation: 87501 steps/s (collection: 0.993s, learning 0.130s)
               Value function loss: 0.6019
                    Surrogate loss: 0.0017
             Mean action noise std: 0.5808
                     Learning rate: 0.0001
                       Mean reward: 13.78
               Mean episode length: 294.56
       Episode_Reward/keep_balance: 0.2906
     Episode_Reward/rew_lin_vel_xy: 0.4773
      Episode_Reward/rew_ang_vel_z: 0.8784
    Episode_Reward/pen_base_height: -0.2099
      Episode_Reward/pen_lin_vel_z: -0.0304
     Episode_Reward/pen_ang_vel_xy: -0.0406
   Episode_Reward/pen_joint_torque: -0.0505
    Episode_Reward/pen_joint_accel: -0.0313
    Episode_Reward/pen_action_rate: -0.0136
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0114
   Episode_Reward/pen_joint_powers: -0.0173
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0282
Episode_Reward/pen_flat_orientation: -0.1829
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0569
   Episode_Reward/foot_landing_vel: -0.0506
   Episode_Reward/test_gait_reward: -0.2679
Metrics/base_velocity/error_vel_xy: 1.0386
Metrics/base_velocity/error_vel_yaw: 0.2583
      Episode_Termination/time_out: 0.7083
  Episode_Termination/base_contact: 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 1.12s
                        Total time: 418.05s
                               ETA: 2840.6s

################################################################################
                     [1m Learning iteration 385/3000 [0m                      

                       Computation: 89417 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.6196
                    Surrogate loss: 0.0034
             Mean action noise std: 0.5812
                     Learning rate: 0.0001
                       Mean reward: 10.97
               Mean episode length: 230.08
       Episode_Reward/keep_balance: 0.2720
     Episode_Reward/rew_lin_vel_xy: 0.5023
      Episode_Reward/rew_ang_vel_z: 0.8151
    Episode_Reward/pen_base_height: -0.2029
      Episode_Reward/pen_lin_vel_z: -0.0271
     Episode_Reward/pen_ang_vel_xy: -0.0381
   Episode_Reward/pen_joint_torque: -0.0466
    Episode_Reward/pen_joint_accel: -0.0284
    Episode_Reward/pen_action_rate: -0.0127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0102
   Episode_Reward/pen_joint_powers: -0.0157
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0266
Episode_Reward/pen_flat_orientation: -0.1667
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0509
   Episode_Reward/foot_landing_vel: -0.0450
   Episode_Reward/test_gait_reward: -0.2489
Metrics/base_velocity/error_vel_xy: 0.9215
Metrics/base_velocity/error_vel_yaw: 0.2475
      Episode_Termination/time_out: 0.7083
  Episode_Termination/base_contact: 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 1.10s
                        Total time: 419.15s
                               ETA: 2839.6s

################################################################################
                     [1m Learning iteration 386/3000 [0m                      

                       Computation: 90589 steps/s (collection: 0.958s, learning 0.127s)
               Value function loss: 0.6815
                    Surrogate loss: 0.0038
             Mean action noise std: 0.5815
                     Learning rate: 0.0001
                       Mean reward: 13.54
               Mean episode length: 262.53
       Episode_Reward/keep_balance: 0.2639
     Episode_Reward/rew_lin_vel_xy: 0.4991
      Episode_Reward/rew_ang_vel_z: 0.8084
    Episode_Reward/pen_base_height: -0.1989
      Episode_Reward/pen_lin_vel_z: -0.0261
     Episode_Reward/pen_ang_vel_xy: -0.0372
   Episode_Reward/pen_joint_torque: -0.0437
    Episode_Reward/pen_joint_accel: -0.0254
    Episode_Reward/pen_action_rate: -0.0121
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0098
   Episode_Reward/pen_joint_powers: -0.0149
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0252
Episode_Reward/pen_flat_orientation: -0.1616
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0476
   Episode_Reward/foot_landing_vel: -0.0437
   Episode_Reward/test_gait_reward: -0.2401
Metrics/base_velocity/error_vel_xy: 0.8880
Metrics/base_velocity/error_vel_yaw: 0.2281
      Episode_Termination/time_out: 0.6250
  Episode_Termination/base_contact: 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 1.09s
                        Total time: 420.23s
                               ETA: 2838.5s

################################################################################
                     [1m Learning iteration 387/3000 [0m                      

                       Computation: 90974 steps/s (collection: 0.953s, learning 0.127s)
               Value function loss: 0.6032
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5818
                     Learning rate: 0.0004
                       Mean reward: 14.00
               Mean episode length: 294.96
       Episode_Reward/keep_balance: 0.2899
     Episode_Reward/rew_lin_vel_xy: 0.5026
      Episode_Reward/rew_ang_vel_z: 0.8805
    Episode_Reward/pen_base_height: -0.2075
      Episode_Reward/pen_lin_vel_z: -0.0287
     Episode_Reward/pen_ang_vel_xy: -0.0389
   Episode_Reward/pen_joint_torque: -0.0487
    Episode_Reward/pen_joint_accel: -0.0275
    Episode_Reward/pen_action_rate: -0.0134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0105
   Episode_Reward/pen_joint_powers: -0.0165
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0280
Episode_Reward/pen_flat_orientation: -0.1722
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0548
   Episode_Reward/foot_landing_vel: -0.0456
   Episode_Reward/test_gait_reward: -0.2641
Metrics/base_velocity/error_vel_xy: 1.0084
Metrics/base_velocity/error_vel_yaw: 0.2555
      Episode_Termination/time_out: 0.7083
  Episode_Termination/base_contact: 11.5417
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 1.08s
                        Total time: 421.31s
                               ETA: 2837.4s

################################################################################
                     [1m Learning iteration 388/3000 [0m                      

                       Computation: 85739 steps/s (collection: 1.024s, learning 0.123s)
               Value function loss: 0.7752
                    Surrogate loss: 0.0011
             Mean action noise std: 0.5818
                     Learning rate: 0.0004
                       Mean reward: 17.86
               Mean episode length: 314.76
       Episode_Reward/keep_balance: 0.2981
     Episode_Reward/rew_lin_vel_xy: 0.5405
      Episode_Reward/rew_ang_vel_z: 0.9152
    Episode_Reward/pen_base_height: -0.2107
      Episode_Reward/pen_lin_vel_z: -0.0287
     Episode_Reward/pen_ang_vel_xy: -0.0388
   Episode_Reward/pen_joint_torque: -0.0506
    Episode_Reward/pen_joint_accel: -0.0279
    Episode_Reward/pen_action_rate: -0.0137
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0106
   Episode_Reward/pen_joint_powers: -0.0168
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0285
Episode_Reward/pen_flat_orientation: -0.1743
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0524
   Episode_Reward/foot_landing_vel: -0.0461
   Episode_Reward/test_gait_reward: -0.2703
Metrics/base_velocity/error_vel_xy: 1.0145
Metrics/base_velocity/error_vel_yaw: 0.2554
      Episode_Termination/time_out: 0.7917
  Episode_Termination/base_contact: 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 1.15s
                        Total time: 422.46s
                               ETA: 2836.7s

################################################################################
                     [1m Learning iteration 389/3000 [0m                      

                       Computation: 90814 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 0.7287
                    Surrogate loss: 0.0000
             Mean action noise std: 0.5820
                     Learning rate: 0.0009
                       Mean reward: 13.92
               Mean episode length: 259.84
       Episode_Reward/keep_balance: 0.2855
     Episode_Reward/rew_lin_vel_xy: 0.5239
      Episode_Reward/rew_ang_vel_z: 0.8665
    Episode_Reward/pen_base_height: -0.2088
      Episode_Reward/pen_lin_vel_z: -0.0277
     Episode_Reward/pen_ang_vel_xy: -0.0390
   Episode_Reward/pen_joint_torque: -0.0468
    Episode_Reward/pen_joint_accel: -0.0263
    Episode_Reward/pen_action_rate: -0.0133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0102
   Episode_Reward/pen_joint_powers: -0.0159
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0279
Episode_Reward/pen_flat_orientation: -0.1679
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0526
   Episode_Reward/foot_landing_vel: -0.0445
   Episode_Reward/test_gait_reward: -0.2614
Metrics/base_velocity/error_vel_xy: 0.9984
Metrics/base_velocity/error_vel_yaw: 0.2533
      Episode_Termination/time_out: 0.6250
  Episode_Termination/base_contact: 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 1.08s
                        Total time: 423.54s
                               ETA: 2835.6s

################################################################################
                     [1m Learning iteration 390/3000 [0m                      

                       Computation: 90225 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.7334
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5838
                     Learning rate: 0.0013
                       Mean reward: 18.49
               Mean episode length: 334.21
       Episode_Reward/keep_balance: 0.3064
     Episode_Reward/rew_lin_vel_xy: 0.5644
      Episode_Reward/rew_ang_vel_z: 0.9281
    Episode_Reward/pen_base_height: -0.2154
      Episode_Reward/pen_lin_vel_z: -0.0305
     Episode_Reward/pen_ang_vel_xy: -0.0411
   Episode_Reward/pen_joint_torque: -0.0525
    Episode_Reward/pen_joint_accel: -0.0296
    Episode_Reward/pen_action_rate: -0.0145
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0114
   Episode_Reward/pen_joint_powers: -0.0177
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0301
Episode_Reward/pen_flat_orientation: -0.1782
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0574
   Episode_Reward/foot_landing_vel: -0.0513
   Episode_Reward/test_gait_reward: -0.2786
Metrics/base_velocity/error_vel_xy: 1.0123
Metrics/base_velocity/error_vel_yaw: 0.2717
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 1.09s
                        Total time: 424.63s
                               ETA: 2834.5s

################################################################################
                     [1m Learning iteration 391/3000 [0m                      

                       Computation: 90798 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.7756
                    Surrogate loss: 0.0005
             Mean action noise std: 0.5849
                     Learning rate: 0.0004
                       Mean reward: 19.96
               Mean episode length: 363.38
       Episode_Reward/keep_balance: 0.3402
     Episode_Reward/rew_lin_vel_xy: 0.6277
      Episode_Reward/rew_ang_vel_z: 1.0373
    Episode_Reward/pen_base_height: -0.2261
      Episode_Reward/pen_lin_vel_z: -0.0322
     Episode_Reward/pen_ang_vel_xy: -0.0431
   Episode_Reward/pen_joint_torque: -0.0566
    Episode_Reward/pen_joint_accel: -0.0315
    Episode_Reward/pen_action_rate: -0.0159
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0122
   Episode_Reward/pen_joint_powers: -0.0190
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0332
Episode_Reward/pen_flat_orientation: -0.1850
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0606
   Episode_Reward/foot_landing_vel: -0.0548
   Episode_Reward/test_gait_reward: -0.3074
Metrics/base_velocity/error_vel_xy: 1.1593
Metrics/base_velocity/error_vel_yaw: 0.2964
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 15.5000
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 1.08s
                        Total time: 425.72s
                               ETA: 2833.4s

################################################################################
                     [1m Learning iteration 392/3000 [0m                      

                       Computation: 91981 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.6415
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5851
                     Learning rate: 0.0006
                       Mean reward: 18.49
               Mean episode length: 354.44
       Episode_Reward/keep_balance: 0.3258
     Episode_Reward/rew_lin_vel_xy: 0.5931
      Episode_Reward/rew_ang_vel_z: 0.9851
    Episode_Reward/pen_base_height: -0.2221
      Episode_Reward/pen_lin_vel_z: -0.0321
     Episode_Reward/pen_ang_vel_xy: -0.0429
   Episode_Reward/pen_joint_torque: -0.0557
    Episode_Reward/pen_joint_accel: -0.0331
    Episode_Reward/pen_action_rate: -0.0155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0123
   Episode_Reward/pen_joint_powers: -0.0189
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0321
Episode_Reward/pen_flat_orientation: -0.1920
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0631
   Episode_Reward/foot_landing_vel: -0.0557
   Episode_Reward/test_gait_reward: -0.2971
Metrics/base_velocity/error_vel_xy: 1.0820
Metrics/base_velocity/error_vel_yaw: 0.2906
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 1.07s
                        Total time: 426.78s
                               ETA: 2832.2s

################################################################################
                     [1m Learning iteration 393/3000 [0m                      

                       Computation: 89980 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.6839
                    Surrogate loss: -0.0020
             Mean action noise std: 0.5858
                     Learning rate: 0.0009
                       Mean reward: 18.19
               Mean episode length: 339.46
       Episode_Reward/keep_balance: 0.3417
     Episode_Reward/rew_lin_vel_xy: 0.5812
      Episode_Reward/rew_ang_vel_z: 1.0379
    Episode_Reward/pen_base_height: -0.2282
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.0434
   Episode_Reward/pen_joint_torque: -0.0622
    Episode_Reward/pen_joint_accel: -0.0350
    Episode_Reward/pen_action_rate: -0.0165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0207
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0338
Episode_Reward/pen_flat_orientation: -0.1978
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0696
   Episode_Reward/foot_landing_vel: -0.0620
   Episode_Reward/test_gait_reward: -0.3148
Metrics/base_velocity/error_vel_xy: 1.1546
Metrics/base_velocity/error_vel_yaw: 0.3008
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 1.09s
                        Total time: 427.88s
                               ETA: 2831.2s

################################################################################
                     [1m Learning iteration 394/3000 [0m                      

                       Computation: 89924 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 0.7329
                    Surrogate loss: 0.0001
             Mean action noise std: 0.5852
                     Learning rate: 0.0013
                       Mean reward: 16.93
               Mean episode length: 314.29
       Episode_Reward/keep_balance: 0.3237
     Episode_Reward/rew_lin_vel_xy: 0.5681
      Episode_Reward/rew_ang_vel_z: 0.9830
    Episode_Reward/pen_base_height: -0.2217
      Episode_Reward/pen_lin_vel_z: -0.0313
     Episode_Reward/pen_ang_vel_xy: -0.0425
   Episode_Reward/pen_joint_torque: -0.0560
    Episode_Reward/pen_joint_accel: -0.0326
    Episode_Reward/pen_action_rate: -0.0154
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0121
   Episode_Reward/pen_joint_powers: -0.0187
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0321
Episode_Reward/pen_flat_orientation: -0.1792
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0608
   Episode_Reward/foot_landing_vel: -0.0542
   Episode_Reward/test_gait_reward: -0.2945
Metrics/base_velocity/error_vel_xy: 1.1027
Metrics/base_velocity/error_vel_yaw: 0.2852
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 12.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 1.09s
                        Total time: 428.97s
                               ETA: 2830.1s

################################################################################
                     [1m Learning iteration 395/3000 [0m                      

                       Computation: 90564 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.7446
                    Surrogate loss: 0.0017
             Mean action noise std: 0.5846
                     Learning rate: 0.0009
                       Mean reward: 16.33
               Mean episode length: 307.69
       Episode_Reward/keep_balance: 0.3078
     Episode_Reward/rew_lin_vel_xy: 0.5849
      Episode_Reward/rew_ang_vel_z: 0.9414
    Episode_Reward/pen_base_height: -0.2138
      Episode_Reward/pen_lin_vel_z: -0.0306
     Episode_Reward/pen_ang_vel_xy: -0.0397
   Episode_Reward/pen_joint_torque: -0.0545
    Episode_Reward/pen_joint_accel: -0.0294
    Episode_Reward/pen_action_rate: -0.0146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0113
   Episode_Reward/pen_joint_powers: -0.0178
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0301
Episode_Reward/pen_flat_orientation: -0.1689
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0579
   Episode_Reward/foot_landing_vel: -0.0513
   Episode_Reward/test_gait_reward: -0.2807
Metrics/base_velocity/error_vel_xy: 1.0562
Metrics/base_velocity/error_vel_yaw: 0.2670
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 1.09s
                        Total time: 430.06s
                               ETA: 2829.0s

################################################################################
                     [1m Learning iteration 396/3000 [0m                      

                       Computation: 91701 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 0.7269
                    Surrogate loss: -0.0017
             Mean action noise std: 0.5854
                     Learning rate: 0.0019
                       Mean reward: 17.92
               Mean episode length: 332.83
       Episode_Reward/keep_balance: 0.3054
     Episode_Reward/rew_lin_vel_xy: 0.5864
      Episode_Reward/rew_ang_vel_z: 0.9222
    Episode_Reward/pen_base_height: -0.2157
      Episode_Reward/pen_lin_vel_z: -0.0303
     Episode_Reward/pen_ang_vel_xy: -0.0400
   Episode_Reward/pen_joint_torque: -0.0535
    Episode_Reward/pen_joint_accel: -0.0313
    Episode_Reward/pen_action_rate: -0.0146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0115
   Episode_Reward/pen_joint_powers: -0.0177
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0305
Episode_Reward/pen_flat_orientation: -0.1717
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0580
   Episode_Reward/foot_landing_vel: -0.0511
   Episode_Reward/test_gait_reward: -0.2780
Metrics/base_velocity/error_vel_xy: 1.0142
Metrics/base_velocity/error_vel_yaw: 0.2731
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 1.07s
                        Total time: 431.13s
                               ETA: 2827.9s

################################################################################
                     [1m Learning iteration 397/3000 [0m                      

                       Computation: 91542 steps/s (collection: 0.953s, learning 0.121s)
               Value function loss: 0.8538
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5857
                     Learning rate: 0.0013
                       Mean reward: 20.49
               Mean episode length: 385.15
       Episode_Reward/keep_balance: 0.3499
     Episode_Reward/rew_lin_vel_xy: 0.6860
      Episode_Reward/rew_ang_vel_z: 1.0661
    Episode_Reward/pen_base_height: -0.2303
      Episode_Reward/pen_lin_vel_z: -0.0343
     Episode_Reward/pen_ang_vel_xy: -0.0439
   Episode_Reward/pen_joint_torque: -0.0613
    Episode_Reward/pen_joint_accel: -0.0346
    Episode_Reward/pen_action_rate: -0.0169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0130
   Episode_Reward/pen_joint_powers: -0.0203
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0347
Episode_Reward/pen_flat_orientation: -0.1875
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0660
   Episode_Reward/foot_landing_vel: -0.0619
   Episode_Reward/test_gait_reward: -0.3166
Metrics/base_velocity/error_vel_xy: 1.1275
Metrics/base_velocity/error_vel_yaw: 0.3051
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 1.07s
                        Total time: 432.20s
                               ETA: 2826.7s

################################################################################
                     [1m Learning iteration 398/3000 [0m                      

                       Computation: 91569 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 0.7432
                    Surrogate loss: 0.0012
             Mean action noise std: 0.5867
                     Learning rate: 0.0013
                       Mean reward: 21.24
               Mean episode length: 392.14
       Episode_Reward/keep_balance: 0.3521
     Episode_Reward/rew_lin_vel_xy: 0.6434
      Episode_Reward/rew_ang_vel_z: 1.0716
    Episode_Reward/pen_base_height: -0.2252
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.0448
   Episode_Reward/pen_joint_torque: -0.0622
    Episode_Reward/pen_joint_accel: -0.0345
    Episode_Reward/pen_action_rate: -0.0171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0209
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0350
Episode_Reward/pen_flat_orientation: -0.1815
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0679
   Episode_Reward/foot_landing_vel: -0.0628
   Episode_Reward/test_gait_reward: -0.3196
Metrics/base_velocity/error_vel_xy: 1.1910
Metrics/base_velocity/error_vel_yaw: 0.3093
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 1.07s
                        Total time: 433.28s
                               ETA: 2825.5s

################################################################################
                     [1m Learning iteration 399/3000 [0m                      

                       Computation: 92000 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 0.7809
                    Surrogate loss: -0.0004
             Mean action noise std: 0.5875
                     Learning rate: 0.0013
                       Mean reward: 18.26
               Mean episode length: 373.09
       Episode_Reward/keep_balance: 0.3524
     Episode_Reward/rew_lin_vel_xy: 0.6031
      Episode_Reward/rew_ang_vel_z: 1.0648
    Episode_Reward/pen_base_height: -0.2249
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.0451
   Episode_Reward/pen_joint_torque: -0.0653
    Episode_Reward/pen_joint_accel: -0.0364
    Episode_Reward/pen_action_rate: -0.0174
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0219
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0355
Episode_Reward/pen_flat_orientation: -0.1939
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0718
   Episode_Reward/foot_landing_vel: -0.0654
   Episode_Reward/test_gait_reward: -0.3202
Metrics/base_velocity/error_vel_xy: 1.2083
Metrics/base_velocity/error_vel_yaw: 0.3149
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 1.07s
                        Total time: 434.34s
                               ETA: 2824.3s

################################################################################
                     [1m Learning iteration 400/3000 [0m                      

                       Computation: 88670 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 0.6701
                    Surrogate loss: 0.0096
             Mean action noise std: 0.5879
                     Learning rate: 0.0001
                       Mean reward: 18.71
               Mean episode length: 364.04
       Episode_Reward/keep_balance: 0.3111
     Episode_Reward/rew_lin_vel_xy: 0.5465
      Episode_Reward/rew_ang_vel_z: 0.9401
    Episode_Reward/pen_base_height: -0.2159
      Episode_Reward/pen_lin_vel_z: -0.0310
     Episode_Reward/pen_ang_vel_xy: -0.0417
   Episode_Reward/pen_joint_torque: -0.0543
    Episode_Reward/pen_joint_accel: -0.0316
    Episode_Reward/pen_action_rate: -0.0152
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0118
   Episode_Reward/pen_joint_powers: -0.0182
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0315
Episode_Reward/pen_flat_orientation: -0.1671
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0591
   Episode_Reward/foot_landing_vel: -0.0537
   Episode_Reward/test_gait_reward: -0.2832
Metrics/base_velocity/error_vel_xy: 1.0868
Metrics/base_velocity/error_vel_yaw: 0.2784
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 1.11s
                        Total time: 435.45s
                               ETA: 2823.4s

################################################################################
                     [1m Learning iteration 401/3000 [0m                      

                       Computation: 89322 steps/s (collection: 0.977s, learning 0.124s)
               Value function loss: 0.6363
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5884
                     Learning rate: 0.0003
                       Mean reward: 17.09
               Mean episode length: 323.97
       Episode_Reward/keep_balance: 0.3105
     Episode_Reward/rew_lin_vel_xy: 0.5380
      Episode_Reward/rew_ang_vel_z: 0.9480
    Episode_Reward/pen_base_height: -0.2210
      Episode_Reward/pen_lin_vel_z: -0.0311
     Episode_Reward/pen_ang_vel_xy: -0.0408
   Episode_Reward/pen_joint_torque: -0.0548
    Episode_Reward/pen_joint_accel: -0.0310
    Episode_Reward/pen_action_rate: -0.0150
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0117
   Episode_Reward/pen_joint_powers: -0.0182
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0310
Episode_Reward/pen_flat_orientation: -0.1666
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0594
   Episode_Reward/foot_landing_vel: -0.0531
   Episode_Reward/test_gait_reward: -0.2815
Metrics/base_velocity/error_vel_xy: 1.0731
Metrics/base_velocity/error_vel_yaw: 0.2702
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 1.10s
                        Total time: 436.55s
                               ETA: 2822.4s

################################################################################
                     [1m Learning iteration 402/3000 [0m                      

                       Computation: 90118 steps/s (collection: 0.965s, learning 0.126s)
               Value function loss: 0.7000
                    Surrogate loss: -0.0025
             Mean action noise std: 0.5890
                     Learning rate: 0.0009
                       Mean reward: 13.92
               Mean episode length: 273.90
       Episode_Reward/keep_balance: 0.2831
     Episode_Reward/rew_lin_vel_xy: 0.4925
      Episode_Reward/rew_ang_vel_z: 0.8594
    Episode_Reward/pen_base_height: -0.2134
      Episode_Reward/pen_lin_vel_z: -0.0282
     Episode_Reward/pen_ang_vel_xy: -0.0382
   Episode_Reward/pen_joint_torque: -0.0485
    Episode_Reward/pen_joint_accel: -0.0284
    Episode_Reward/pen_action_rate: -0.0135
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0101
   Episode_Reward/pen_joint_powers: -0.0159
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0283
Episode_Reward/pen_flat_orientation: -0.1500
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0528
   Episode_Reward/foot_landing_vel: -0.0453
   Episode_Reward/test_gait_reward: -0.2557
Metrics/base_velocity/error_vel_xy: 0.9678
Metrics/base_velocity/error_vel_yaw: 0.2509
      Episode_Termination/time_out: 0.9167
  Episode_Termination/base_contact: 11.4583
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 1.09s
                        Total time: 437.64s
                               ETA: 2821.3s

################################################################################
                     [1m Learning iteration 403/3000 [0m                      

                       Computation: 88902 steps/s (collection: 0.983s, learning 0.123s)
               Value function loss: 0.8273
                    Surrogate loss: -0.0001
             Mean action noise std: 0.5893
                     Learning rate: 0.0013
                       Mean reward: 18.59
               Mean episode length: 338.44
       Episode_Reward/keep_balance: 0.3439
     Episode_Reward/rew_lin_vel_xy: 0.7009
      Episode_Reward/rew_ang_vel_z: 1.0496
    Episode_Reward/pen_base_height: -0.2374
      Episode_Reward/pen_lin_vel_z: -0.0333
     Episode_Reward/pen_ang_vel_xy: -0.0434
   Episode_Reward/pen_joint_torque: -0.0612
    Episode_Reward/pen_joint_accel: -0.0338
    Episode_Reward/pen_action_rate: -0.0167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0124
   Episode_Reward/pen_joint_powers: -0.0197
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0347
Episode_Reward/pen_flat_orientation: -0.1685
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0653
   Episode_Reward/foot_landing_vel: -0.0566
   Episode_Reward/test_gait_reward: -0.3096
Metrics/base_velocity/error_vel_xy: 1.1300
Metrics/base_velocity/error_vel_yaw: 0.3007
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 9.3333
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 1.11s
                        Total time: 438.75s
                               ETA: 2820.4s

################################################################################
                     [1m Learning iteration 404/3000 [0m                      

                       Computation: 90767 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.8338
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5898
                     Learning rate: 0.0013
                       Mean reward: 17.67
               Mean episode length: 325.88
       Episode_Reward/keep_balance: 0.3223
     Episode_Reward/rew_lin_vel_xy: 0.5522
      Episode_Reward/rew_ang_vel_z: 0.9763
    Episode_Reward/pen_base_height: -0.2254
      Episode_Reward/pen_lin_vel_z: -0.0327
     Episode_Reward/pen_ang_vel_xy: -0.0424
   Episode_Reward/pen_joint_torque: -0.0581
    Episode_Reward/pen_joint_accel: -0.0327
    Episode_Reward/pen_action_rate: -0.0158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0121
   Episode_Reward/pen_joint_powers: -0.0191
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0329
Episode_Reward/pen_flat_orientation: -0.1693
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0643
   Episode_Reward/foot_landing_vel: -0.0537
   Episode_Reward/test_gait_reward: -0.2931
Metrics/base_velocity/error_vel_xy: 1.1001
Metrics/base_velocity/error_vel_yaw: 0.2863
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 10.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 1.08s
                        Total time: 439.83s
                               ETA: 2819.3s

################################################################################
                     [1m Learning iteration 405/3000 [0m                      

                       Computation: 89960 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.9645
                    Surrogate loss: -0.0007
             Mean action noise std: 0.5909
                     Learning rate: 0.0013
                       Mean reward: 18.12
               Mean episode length: 325.83
       Episode_Reward/keep_balance: 0.3291
     Episode_Reward/rew_lin_vel_xy: 0.6220
      Episode_Reward/rew_ang_vel_z: 1.0030
    Episode_Reward/pen_base_height: -0.2310
      Episode_Reward/pen_lin_vel_z: -0.0327
     Episode_Reward/pen_ang_vel_xy: -0.0431
   Episode_Reward/pen_joint_torque: -0.0566
    Episode_Reward/pen_joint_accel: -0.0340
    Episode_Reward/pen_action_rate: -0.0161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0122
   Episode_Reward/pen_joint_powers: -0.0189
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0336
Episode_Reward/pen_flat_orientation: -0.1696
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0621
   Episode_Reward/foot_landing_vel: -0.0556
   Episode_Reward/test_gait_reward: -0.3002
Metrics/base_velocity/error_vel_xy: 1.1031
Metrics/base_velocity/error_vel_yaw: 0.2911
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 1.09s
                        Total time: 440.93s
                               ETA: 2818.2s

################################################################################
                     [1m Learning iteration 406/3000 [0m                      

                       Computation: 90078 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.8734
                    Surrogate loss: 0.0015
             Mean action noise std: 0.5920
                     Learning rate: 0.0004
                       Mean reward: 17.95
               Mean episode length: 319.53
       Episode_Reward/keep_balance: 0.3349
     Episode_Reward/rew_lin_vel_xy: 0.5829
      Episode_Reward/rew_ang_vel_z: 1.0253
    Episode_Reward/pen_base_height: -0.2300
      Episode_Reward/pen_lin_vel_z: -0.0335
     Episode_Reward/pen_ang_vel_xy: -0.0436
   Episode_Reward/pen_joint_torque: -0.0595
    Episode_Reward/pen_joint_accel: -0.0340
    Episode_Reward/pen_action_rate: -0.0163
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0125
   Episode_Reward/pen_joint_powers: -0.0195
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0337
Episode_Reward/pen_flat_orientation: -0.1688
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0631
   Episode_Reward/foot_landing_vel: -0.0581
   Episode_Reward/test_gait_reward: -0.3034
Metrics/base_velocity/error_vel_xy: 1.1374
Metrics/base_velocity/error_vel_yaw: 0.2898
      Episode_Termination/time_out: 1.0000
  Episode_Termination/base_contact: 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 1.09s
                        Total time: 442.02s
                               ETA: 2817.2s

################################################################################
                     [1m Learning iteration 407/3000 [0m                      

                       Computation: 89146 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 0.7193
                    Surrogate loss: -0.0033
             Mean action noise std: 0.5924
                     Learning rate: 0.0009
                       Mean reward: 14.74
               Mean episode length: 298.40
       Episode_Reward/keep_balance: 0.3115
     Episode_Reward/rew_lin_vel_xy: 0.6056
      Episode_Reward/rew_ang_vel_z: 0.9444
    Episode_Reward/pen_base_height: -0.2223
      Episode_Reward/pen_lin_vel_z: -0.0317
     Episode_Reward/pen_ang_vel_xy: -0.0405
   Episode_Reward/pen_joint_torque: -0.0554
    Episode_Reward/pen_joint_accel: -0.0328
    Episode_Reward/pen_action_rate: -0.0152
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0119
   Episode_Reward/pen_joint_powers: -0.0185
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0314
Episode_Reward/pen_flat_orientation: -0.1595
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0621
   Episode_Reward/foot_landing_vel: -0.0542
   Episode_Reward/test_gait_reward: -0.2839
Metrics/base_velocity/error_vel_xy: 1.0420
Metrics/base_velocity/error_vel_yaw: 0.2762
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 1.10s
                        Total time: 443.12s
                               ETA: 2816.2s

################################################################################
                     [1m Learning iteration 408/3000 [0m                      

                       Computation: 89351 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.8195
                    Surrogate loss: 0.0012
             Mean action noise std: 0.5931
                     Learning rate: 0.0002
                       Mean reward: 20.59
               Mean episode length: 365.79
       Episode_Reward/keep_balance: 0.3340
     Episode_Reward/rew_lin_vel_xy: 0.6121
      Episode_Reward/rew_ang_vel_z: 1.0181
    Episode_Reward/pen_base_height: -0.2289
      Episode_Reward/pen_lin_vel_z: -0.0333
     Episode_Reward/pen_ang_vel_xy: -0.0427
   Episode_Reward/pen_joint_torque: -0.0600
    Episode_Reward/pen_joint_accel: -0.0332
    Episode_Reward/pen_action_rate: -0.0164
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0125
   Episode_Reward/pen_joint_powers: -0.0197
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0338
Episode_Reward/pen_flat_orientation: -0.1655
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0640
   Episode_Reward/foot_landing_vel: -0.0580
   Episode_Reward/test_gait_reward: -0.3019
Metrics/base_velocity/error_vel_xy: 1.1514
Metrics/base_velocity/error_vel_yaw: 0.2919
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 1.10s
                        Total time: 444.22s
                               ETA: 2815.2s

################################################################################
                     [1m Learning iteration 409/3000 [0m                      

                       Computation: 91995 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 0.7552
                    Surrogate loss: 0.0069
             Mean action noise std: 0.5932
                     Learning rate: 0.0000
                       Mean reward: 18.49
               Mean episode length: 344.73
       Episode_Reward/keep_balance: 0.3388
     Episode_Reward/rew_lin_vel_xy: 0.6346
      Episode_Reward/rew_ang_vel_z: 1.0328
    Episode_Reward/pen_base_height: -0.2341
      Episode_Reward/pen_lin_vel_z: -0.0333
     Episode_Reward/pen_ang_vel_xy: -0.0430
   Episode_Reward/pen_joint_torque: -0.0615
    Episode_Reward/pen_joint_accel: -0.0344
    Episode_Reward/pen_action_rate: -0.0167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0125
   Episode_Reward/pen_joint_powers: -0.0197
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0348
Episode_Reward/pen_flat_orientation: -0.1632
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0640
   Episode_Reward/foot_landing_vel: -0.0559
   Episode_Reward/test_gait_reward: -0.3051
Metrics/base_velocity/error_vel_xy: 1.1482
Metrics/base_velocity/error_vel_yaw: 0.2958
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 1.07s
                        Total time: 445.29s
                               ETA: 2814.0s

################################################################################
                     [1m Learning iteration 410/3000 [0m                      

                       Computation: 92028 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.6309
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5932
                     Learning rate: 0.0002
                       Mean reward: 16.64
               Mean episode length: 322.74
       Episode_Reward/keep_balance: 0.3305
     Episode_Reward/rew_lin_vel_xy: 0.6104
      Episode_Reward/rew_ang_vel_z: 1.0106
    Episode_Reward/pen_base_height: -0.2313
      Episode_Reward/pen_lin_vel_z: -0.0336
     Episode_Reward/pen_ang_vel_xy: -0.0437
   Episode_Reward/pen_joint_torque: -0.0618
    Episode_Reward/pen_joint_accel: -0.0348
    Episode_Reward/pen_action_rate: -0.0165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0127
   Episode_Reward/pen_joint_powers: -0.0199
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0340
Episode_Reward/pen_flat_orientation: -0.1637
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0645
   Episode_Reward/foot_landing_vel: -0.0578
   Episode_Reward/test_gait_reward: -0.2992
Metrics/base_velocity/error_vel_xy: 1.1183
Metrics/base_velocity/error_vel_yaw: 0.2877
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 1.07s
                        Total time: 446.36s
                               ETA: 2812.8s

################################################################################
                     [1m Learning iteration 411/3000 [0m                      

                       Computation: 91719 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 0.7301
                    Surrogate loss: -0.0015
             Mean action noise std: 0.5936
                     Learning rate: 0.0004
                       Mean reward: 17.63
               Mean episode length: 330.81
       Episode_Reward/keep_balance: 0.3713
     Episode_Reward/rew_lin_vel_xy: 0.7527
      Episode_Reward/rew_ang_vel_z: 1.1317
    Episode_Reward/pen_base_height: -0.2384
      Episode_Reward/pen_lin_vel_z: -0.0349
     Episode_Reward/pen_ang_vel_xy: -0.0451
   Episode_Reward/pen_joint_torque: -0.0646
    Episode_Reward/pen_joint_accel: -0.0369
    Episode_Reward/pen_action_rate: -0.0183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0382
Episode_Reward/pen_flat_orientation: -0.1713
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0667
   Episode_Reward/foot_landing_vel: -0.0636
   Episode_Reward/test_gait_reward: -0.3330
Metrics/base_velocity/error_vel_xy: 1.2164
Metrics/base_velocity/error_vel_yaw: 0.3249
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 11.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 1.07s
                        Total time: 447.43s
                               ETA: 2811.6s

################################################################################
                     [1m Learning iteration 412/3000 [0m                      

                       Computation: 91400 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.6928
                    Surrogate loss: -0.0014
             Mean action noise std: 0.5944
                     Learning rate: 0.0006
                       Mean reward: 14.46
               Mean episode length: 282.90
       Episode_Reward/keep_balance: 0.3108
     Episode_Reward/rew_lin_vel_xy: 0.5721
      Episode_Reward/rew_ang_vel_z: 0.9392
    Episode_Reward/pen_base_height: -0.2237
      Episode_Reward/pen_lin_vel_z: -0.0326
     Episode_Reward/pen_ang_vel_xy: -0.0425
   Episode_Reward/pen_joint_torque: -0.0582
    Episode_Reward/pen_joint_accel: -0.0325
    Episode_Reward/pen_action_rate: -0.0155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0122
   Episode_Reward/pen_joint_powers: -0.0189
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0321
Episode_Reward/pen_flat_orientation: -0.1587
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0633
   Episode_Reward/foot_landing_vel: -0.0564
   Episode_Reward/test_gait_reward: -0.2811
Metrics/base_velocity/error_vel_xy: 1.0524
Metrics/base_velocity/error_vel_yaw: 0.2777
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 1.08s
                        Total time: 448.50s
                               ETA: 2810.5s

################################################################################
                     [1m Learning iteration 413/3000 [0m                      

                       Computation: 91288 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.7718
                    Surrogate loss: -0.0024
             Mean action noise std: 0.5949
                     Learning rate: 0.0013
                       Mean reward: 12.22
               Mean episode length: 299.32
       Episode_Reward/keep_balance: 0.2898
     Episode_Reward/rew_lin_vel_xy: 0.5060
      Episode_Reward/rew_ang_vel_z: 0.8766
    Episode_Reward/pen_base_height: -0.2236
      Episode_Reward/pen_lin_vel_z: -0.0317
     Episode_Reward/pen_ang_vel_xy: -0.0406
   Episode_Reward/pen_joint_torque: -0.0560
    Episode_Reward/pen_joint_accel: -0.0321
    Episode_Reward/pen_action_rate: -0.0145
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0117
   Episode_Reward/pen_joint_powers: -0.0181
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0299
Episode_Reward/pen_flat_orientation: -0.1472
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0621
   Episode_Reward/foot_landing_vel: -0.0532
   Episode_Reward/test_gait_reward: -0.2640
Metrics/base_velocity/error_vel_xy: 1.0444
Metrics/base_velocity/error_vel_yaw: 0.2584
      Episode_Termination/time_out: 0.8333
  Episode_Termination/base_contact: 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 1.08s
                        Total time: 449.58s
                               ETA: 2809.3s

################################################################################
                     [1m Learning iteration 414/3000 [0m                      

                       Computation: 91492 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.7580
                    Surrogate loss: 0.0048
             Mean action noise std: 0.5952
                     Learning rate: 0.0003
                       Mean reward: 11.60
               Mean episode length: 247.13
       Episode_Reward/keep_balance: 0.2842
     Episode_Reward/rew_lin_vel_xy: 0.5145
      Episode_Reward/rew_ang_vel_z: 0.8628
    Episode_Reward/pen_base_height: -0.2149
      Episode_Reward/pen_lin_vel_z: -0.0292
     Episode_Reward/pen_ang_vel_xy: -0.0398
   Episode_Reward/pen_joint_torque: -0.0509
    Episode_Reward/pen_joint_accel: -0.0292
    Episode_Reward/pen_action_rate: -0.0141
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0107
   Episode_Reward/pen_joint_powers: -0.0167
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0294
Episode_Reward/pen_flat_orientation: -0.1402
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0551
   Episode_Reward/foot_landing_vel: -0.0494
   Episode_Reward/test_gait_reward: -0.2577
Metrics/base_velocity/error_vel_xy: 0.9557
Metrics/base_velocity/error_vel_yaw: 0.2520
      Episode_Termination/time_out: 0.9583
  Episode_Termination/base_contact: 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 1.07s
                        Total time: 450.66s
                               ETA: 2808.2s

################################################################################
                     [1m Learning iteration 415/3000 [0m                      

                       Computation: 90110 steps/s (collection: 0.966s, learning 0.125s)
               Value function loss: 0.7921
                    Surrogate loss: -0.0002
             Mean action noise std: 0.5959
                     Learning rate: 0.0006
                       Mean reward: 19.35
               Mean episode length: 347.95
       Episode_Reward/keep_balance: 0.3511
     Episode_Reward/rew_lin_vel_xy: 0.7014
      Episode_Reward/rew_ang_vel_z: 1.0693
    Episode_Reward/pen_base_height: -0.2370
      Episode_Reward/pen_lin_vel_z: -0.0350
     Episode_Reward/pen_ang_vel_xy: -0.0443
   Episode_Reward/pen_joint_torque: -0.0635
    Episode_Reward/pen_joint_accel: -0.0372
    Episode_Reward/pen_action_rate: -0.0176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0206
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0364
Episode_Reward/pen_flat_orientation: -0.1627
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0687
   Episode_Reward/foot_landing_vel: -0.0614
   Episode_Reward/test_gait_reward: -0.3167
Metrics/base_velocity/error_vel_xy: 1.1894
Metrics/base_velocity/error_vel_yaw: 0.3074
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 1.09s
                        Total time: 451.75s
                               ETA: 2807.1s

################################################################################
                     [1m Learning iteration 416/3000 [0m                      

                       Computation: 89353 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.7399
                    Surrogate loss: 0.0003
             Mean action noise std: 0.5961
                     Learning rate: 0.0004
                       Mean reward: 19.43
               Mean episode length: 331.96
       Episode_Reward/keep_balance: 0.2988
     Episode_Reward/rew_lin_vel_xy: 0.5798
      Episode_Reward/rew_ang_vel_z: 0.9011
    Episode_Reward/pen_base_height: -0.2226
      Episode_Reward/pen_lin_vel_z: -0.0313
     Episode_Reward/pen_ang_vel_xy: -0.0415
   Episode_Reward/pen_joint_torque: -0.0545
    Episode_Reward/pen_joint_accel: -0.0318
    Episode_Reward/pen_action_rate: -0.0150
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0116
   Episode_Reward/pen_joint_powers: -0.0179
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0311
Episode_Reward/pen_flat_orientation: -0.1419
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0598
   Episode_Reward/foot_landing_vel: -0.0528
   Episode_Reward/test_gait_reward: -0.2701
Metrics/base_velocity/error_vel_xy: 1.0019
Metrics/base_velocity/error_vel_yaw: 0.2682
      Episode_Termination/time_out: 0.8750
  Episode_Termination/base_contact: 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 1.10s
                        Total time: 452.85s
                               ETA: 2806.1s

################################################################################
                     [1m Learning iteration 417/3000 [0m                      

                       Computation: 90210 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.7896
                    Surrogate loss: 0.0007
             Mean action noise std: 0.5964
                     Learning rate: 0.0009
                       Mean reward: 15.06
               Mean episode length: 281.87
       Episode_Reward/keep_balance: 0.2655
     Episode_Reward/rew_lin_vel_xy: 0.5190
      Episode_Reward/rew_ang_vel_z: 0.8019
    Episode_Reward/pen_base_height: -0.2089
      Episode_Reward/pen_lin_vel_z: -0.0276
     Episode_Reward/pen_ang_vel_xy: -0.0373
   Episode_Reward/pen_joint_torque: -0.0473
    Episode_Reward/pen_joint_accel: -0.0276
    Episode_Reward/pen_action_rate: -0.0133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0100
   Episode_Reward/pen_joint_powers: -0.0155
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0279
Episode_Reward/pen_flat_orientation: -0.1314
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0515
   Episode_Reward/foot_landing_vel: -0.0444
   Episode_Reward/test_gait_reward: -0.2406
Metrics/base_velocity/error_vel_xy: 0.9095
Metrics/base_velocity/error_vel_yaw: 0.2394
      Episode_Termination/time_out: 0.7917
  Episode_Termination/base_contact: 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 1.09s
                        Total time: 453.94s
                               ETA: 2805.1s

################################################################################
                     [1m Learning iteration 418/3000 [0m                      

                       Computation: 90032 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.9594
                    Surrogate loss: -0.0010
             Mean action noise std: 0.5966
                     Learning rate: 0.0013
                       Mean reward: 21.13
               Mean episode length: 370.96
       Episode_Reward/keep_balance: 0.3630
     Episode_Reward/rew_lin_vel_xy: 0.7084
      Episode_Reward/rew_ang_vel_z: 1.0929
    Episode_Reward/pen_base_height: -0.2411
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.0480
   Episode_Reward/pen_joint_torque: -0.0671
    Episode_Reward/pen_joint_accel: -0.0413
    Episode_Reward/pen_action_rate: -0.0187
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0148
   Episode_Reward/pen_joint_powers: -0.0224
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0385
Episode_Reward/pen_flat_orientation: -0.1729
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0767
   Episode_Reward/foot_landing_vel: -0.0735
   Episode_Reward/test_gait_reward: -0.3296
Metrics/base_velocity/error_vel_xy: 1.1921
Metrics/base_velocity/error_vel_yaw: 0.3284
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 1.09s
                        Total time: 455.03s
                               ETA: 2804.0s

################################################################################
                     [1m Learning iteration 419/3000 [0m                      

                       Computation: 90236 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 1.0173
                    Surrogate loss: 0.0017
             Mean action noise std: 0.5968
                     Learning rate: 0.0006
                       Mean reward: 21.05
               Mean episode length: 349.92
       Episode_Reward/keep_balance: 0.3385
     Episode_Reward/rew_lin_vel_xy: 0.6898
      Episode_Reward/rew_ang_vel_z: 1.0368
    Episode_Reward/pen_base_height: -0.2336
      Episode_Reward/pen_lin_vel_z: -0.0334
     Episode_Reward/pen_ang_vel_xy: -0.0428
   Episode_Reward/pen_joint_torque: -0.0612
    Episode_Reward/pen_joint_accel: -0.0328
    Episode_Reward/pen_action_rate: -0.0170
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0123
   Episode_Reward/pen_joint_powers: -0.0197
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0354
Episode_Reward/pen_flat_orientation: -0.1485
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0633
   Episode_Reward/foot_landing_vel: -0.0568
   Episode_Reward/test_gait_reward: -0.3050
Metrics/base_velocity/error_vel_xy: 1.1077
Metrics/base_velocity/error_vel_yaw: 0.2913
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 1.09s
                        Total time: 456.12s
                               ETA: 2802.9s

################################################################################
                     [1m Learning iteration 420/3000 [0m                      

                       Computation: 89147 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.7906
                    Surrogate loss: -0.0005
             Mean action noise std: 0.5967
                     Learning rate: 0.0009
                       Mean reward: 17.24
               Mean episode length: 344.03
       Episode_Reward/keep_balance: 0.3320
     Episode_Reward/rew_lin_vel_xy: 0.5982
      Episode_Reward/rew_ang_vel_z: 1.0069
    Episode_Reward/pen_base_height: -0.2398
      Episode_Reward/pen_lin_vel_z: -0.0333
     Episode_Reward/pen_ang_vel_xy: -0.0434
   Episode_Reward/pen_joint_torque: -0.0615
    Episode_Reward/pen_joint_accel: -0.0326
    Episode_Reward/pen_action_rate: -0.0169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0126
   Episode_Reward/pen_joint_powers: -0.0198
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0351
Episode_Reward/pen_flat_orientation: -0.1480
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0651
   Episode_Reward/foot_landing_vel: -0.0585
   Episode_Reward/test_gait_reward: -0.2987
Metrics/base_velocity/error_vel_xy: 1.1346
Metrics/base_velocity/error_vel_yaw: 0.2940
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 1.10s
                        Total time: 457.22s
                               ETA: 2802.0s

################################################################################
                     [1m Learning iteration 421/3000 [0m                      

                       Computation: 89629 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.7995
                    Surrogate loss: -0.0012
             Mean action noise std: 0.5968
                     Learning rate: 0.0009
                       Mean reward: 18.07
               Mean episode length: 343.03
       Episode_Reward/keep_balance: 0.3108
     Episode_Reward/rew_lin_vel_xy: 0.6230
      Episode_Reward/rew_ang_vel_z: 0.9433
    Episode_Reward/pen_base_height: -0.2354
      Episode_Reward/pen_lin_vel_z: -0.0316
     Episode_Reward/pen_ang_vel_xy: -0.0413
   Episode_Reward/pen_joint_torque: -0.0575
    Episode_Reward/pen_joint_accel: -0.0322
    Episode_Reward/pen_action_rate: -0.0155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0117
   Episode_Reward/pen_joint_powers: -0.0183
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0324
Episode_Reward/pen_flat_orientation: -0.1454
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0619
   Episode_Reward/foot_landing_vel: -0.0546
   Episode_Reward/test_gait_reward: -0.2808
Metrics/base_velocity/error_vel_xy: 1.0377
Metrics/base_velocity/error_vel_yaw: 0.2756
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 1.10s
                        Total time: 458.32s
                               ETA: 2800.9s

################################################################################
                     [1m Learning iteration 422/3000 [0m                      

                       Computation: 90307 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.8199
                    Surrogate loss: -0.0003
             Mean action noise std: 0.5987
                     Learning rate: 0.0006
                       Mean reward: 16.22
               Mean episode length: 295.38
       Episode_Reward/keep_balance: 0.3340
     Episode_Reward/rew_lin_vel_xy: 0.6372
      Episode_Reward/rew_ang_vel_z: 1.0200
    Episode_Reward/pen_base_height: -0.2378
      Episode_Reward/pen_lin_vel_z: -0.0322
     Episode_Reward/pen_ang_vel_xy: -0.0429
   Episode_Reward/pen_joint_torque: -0.0592
    Episode_Reward/pen_joint_accel: -0.0330
    Episode_Reward/pen_action_rate: -0.0167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0119
   Episode_Reward/pen_joint_powers: -0.0190
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0351
Episode_Reward/pen_flat_orientation: -0.1440
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0608
   Episode_Reward/foot_landing_vel: -0.0543
   Episode_Reward/test_gait_reward: -0.2995
Metrics/base_velocity/error_vel_xy: 1.1032
Metrics/base_velocity/error_vel_yaw: 0.2916
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 12.2083
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 1.09s
                        Total time: 459.41s
                               ETA: 2799.9s

################################################################################
                     [1m Learning iteration 423/3000 [0m                      

                       Computation: 89628 steps/s (collection: 0.970s, learning 0.127s)
               Value function loss: 0.8435
                    Surrogate loss: 0.0006
             Mean action noise std: 0.5988
                     Learning rate: 0.0004
                       Mean reward: 15.58
               Mean episode length: 307.05
       Episode_Reward/keep_balance: 0.3179
     Episode_Reward/rew_lin_vel_xy: 0.5924
      Episode_Reward/rew_ang_vel_z: 0.9640
    Episode_Reward/pen_base_height: -0.2324
      Episode_Reward/pen_lin_vel_z: -0.0338
     Episode_Reward/pen_ang_vel_xy: -0.0427
   Episode_Reward/pen_joint_torque: -0.0600
    Episode_Reward/pen_joint_accel: -0.0329
    Episode_Reward/pen_action_rate: -0.0160
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0126
   Episode_Reward/pen_joint_powers: -0.0196
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0331
Episode_Reward/pen_flat_orientation: -0.1476
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0664
   Episode_Reward/foot_landing_vel: -0.0574
   Episode_Reward/test_gait_reward: -0.2873
Metrics/base_velocity/error_vel_xy: 1.1048
Metrics/base_velocity/error_vel_yaw: 0.2830
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 1.10s
                        Total time: 460.50s
                               ETA: 2798.9s

################################################################################
                     [1m Learning iteration 424/3000 [0m                      

                       Computation: 89908 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.7957
                    Surrogate loss: 0.0038
             Mean action noise std: 0.5989
                     Learning rate: 0.0001
                       Mean reward: 18.25
               Mean episode length: 345.80
       Episode_Reward/keep_balance: 0.3313
     Episode_Reward/rew_lin_vel_xy: 0.6207
      Episode_Reward/rew_ang_vel_z: 1.0017
    Episode_Reward/pen_base_height: -0.2357
      Episode_Reward/pen_lin_vel_z: -0.0336
     Episode_Reward/pen_ang_vel_xy: -0.0424
   Episode_Reward/pen_joint_torque: -0.0613
    Episode_Reward/pen_joint_accel: -0.0328
    Episode_Reward/pen_action_rate: -0.0168
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0125
   Episode_Reward/pen_joint_powers: -0.0198
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0348
Episode_Reward/pen_flat_orientation: -0.1439
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0648
   Episode_Reward/foot_landing_vel: -0.0594
   Episode_Reward/test_gait_reward: -0.2970
Metrics/base_velocity/error_vel_xy: 1.1518
Metrics/base_velocity/error_vel_yaw: 0.2959
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 9.3333
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 1.09s
                        Total time: 461.60s
                               ETA: 2797.8s

################################################################################
                     [1m Learning iteration 425/3000 [0m                      

                       Computation: 90012 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.8046
                    Surrogate loss: -0.0008
             Mean action noise std: 0.5987
                     Learning rate: 0.0004
                       Mean reward: 16.52
               Mean episode length: 306.55
       Episode_Reward/keep_balance: 0.2928
     Episode_Reward/rew_lin_vel_xy: 0.5880
      Episode_Reward/rew_ang_vel_z: 0.8948
    Episode_Reward/pen_base_height: -0.2249
      Episode_Reward/pen_lin_vel_z: -0.0307
     Episode_Reward/pen_ang_vel_xy: -0.0404
   Episode_Reward/pen_joint_torque: -0.0564
    Episode_Reward/pen_joint_accel: -0.0309
    Episode_Reward/pen_action_rate: -0.0146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0114
   Episode_Reward/pen_joint_powers: -0.0179
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0304
Episode_Reward/pen_flat_orientation: -0.1364
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0596
   Episode_Reward/foot_landing_vel: -0.0512
   Episode_Reward/test_gait_reward: -0.2662
Metrics/base_velocity/error_vel_xy: 0.9970
Metrics/base_velocity/error_vel_yaw: 0.2548
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 1.09s
                        Total time: 462.69s
                               ETA: 2796.8s

################################################################################
                     [1m Learning iteration 426/3000 [0m                      

                       Computation: 90093 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.9104
                    Surrogate loss: -0.0021
             Mean action noise std: 0.5986
                     Learning rate: 0.0009
                       Mean reward: 16.43
               Mean episode length: 287.46
       Episode_Reward/keep_balance: 0.3220
     Episode_Reward/rew_lin_vel_xy: 0.6464
      Episode_Reward/rew_ang_vel_z: 0.9823
    Episode_Reward/pen_base_height: -0.2314
      Episode_Reward/pen_lin_vel_z: -0.0343
     Episode_Reward/pen_ang_vel_xy: -0.0444
   Episode_Reward/pen_joint_torque: -0.0622
    Episode_Reward/pen_joint_accel: -0.0350
    Episode_Reward/pen_action_rate: -0.0166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0128
   Episode_Reward/pen_joint_powers: -0.0201
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0338
Episode_Reward/pen_flat_orientation: -0.1471
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0675
   Episode_Reward/foot_landing_vel: -0.0612
   Episode_Reward/test_gait_reward: -0.2926
Metrics/base_velocity/error_vel_xy: 1.0788
Metrics/base_velocity/error_vel_yaw: 0.2816
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 1.09s
                        Total time: 463.78s
                               ETA: 2795.7s

################################################################################
                     [1m Learning iteration 427/3000 [0m                      

                       Computation: 90721 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.8892
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6004
                     Learning rate: 0.0019
                       Mean reward: 18.20
               Mean episode length: 303.40
       Episode_Reward/keep_balance: 0.3093
     Episode_Reward/rew_lin_vel_xy: 0.6133
      Episode_Reward/rew_ang_vel_z: 0.9416
    Episode_Reward/pen_base_height: -0.2231
      Episode_Reward/pen_lin_vel_z: -0.0312
     Episode_Reward/pen_ang_vel_xy: -0.0407
   Episode_Reward/pen_joint_torque: -0.0566
    Episode_Reward/pen_joint_accel: -0.0315
    Episode_Reward/pen_action_rate: -0.0155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0114
   Episode_Reward/pen_joint_powers: -0.0182
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0323
Episode_Reward/pen_flat_orientation: -0.1394
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0595
   Episode_Reward/foot_landing_vel: -0.0541
   Episode_Reward/test_gait_reward: -0.2796
Metrics/base_velocity/error_vel_xy: 1.0370
Metrics/base_velocity/error_vel_yaw: 0.2735
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 1.08s
                        Total time: 464.86s
                               ETA: 2794.6s

################################################################################
                     [1m Learning iteration 428/3000 [0m                      

                       Computation: 90405 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 1.2544
                    Surrogate loss: 0.0007
             Mean action noise std: 0.6020
                     Learning rate: 0.0019
                       Mean reward: 20.98
               Mean episode length: 372.99
       Episode_Reward/keep_balance: 0.3217
     Episode_Reward/rew_lin_vel_xy: 0.6461
      Episode_Reward/rew_ang_vel_z: 0.9866
    Episode_Reward/pen_base_height: -0.2362
      Episode_Reward/pen_lin_vel_z: -0.0319
     Episode_Reward/pen_ang_vel_xy: -0.0414
   Episode_Reward/pen_joint_torque: -0.0582
    Episode_Reward/pen_joint_accel: -0.0329
    Episode_Reward/pen_action_rate: -0.0162
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0118
   Episode_Reward/pen_joint_powers: -0.0188
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0337
Episode_Reward/pen_flat_orientation: -0.1381
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0604
   Episode_Reward/foot_landing_vel: -0.0535
   Episode_Reward/test_gait_reward: -0.2897
Metrics/base_velocity/error_vel_xy: 1.0747
Metrics/base_velocity/error_vel_yaw: 0.2770
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 13.0833
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 1.09s
                        Total time: 465.95s
                               ETA: 2793.5s

################################################################################
                     [1m Learning iteration 429/3000 [0m                      

                       Computation: 90984 steps/s (collection: 0.956s, learning 0.125s)
               Value function loss: 1.0494
                    Surrogate loss: 0.0031
             Mean action noise std: 0.6022
                     Learning rate: 0.0006
                       Mean reward: 21.50
               Mean episode length: 356.82
       Episode_Reward/keep_balance: 0.3605
     Episode_Reward/rew_lin_vel_xy: 0.7352
      Episode_Reward/rew_ang_vel_z: 1.1141
    Episode_Reward/pen_base_height: -0.2453
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.0441
   Episode_Reward/pen_joint_torque: -0.0670
    Episode_Reward/pen_joint_accel: -0.0334
    Episode_Reward/pen_action_rate: -0.0180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0131
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0376
Episode_Reward/pen_flat_orientation: -0.1520
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0689
   Episode_Reward/foot_landing_vel: -0.0586
   Episode_Reward/test_gait_reward: -0.3253
Metrics/base_velocity/error_vel_xy: 1.1911
Metrics/base_velocity/error_vel_yaw: 0.3048
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 1.08s
                        Total time: 467.03s
                               ETA: 2792.4s

################################################################################
                     [1m Learning iteration 430/3000 [0m                      

                       Computation: 89847 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.8922
                    Surrogate loss: 0.0010
             Mean action noise std: 0.6026
                     Learning rate: 0.0004
                       Mean reward: 19.37
               Mean episode length: 341.40
       Episode_Reward/keep_balance: 0.3387
     Episode_Reward/rew_lin_vel_xy: 0.6468
      Episode_Reward/rew_ang_vel_z: 1.0359
    Episode_Reward/pen_base_height: -0.2287
      Episode_Reward/pen_lin_vel_z: -0.0335
     Episode_Reward/pen_ang_vel_xy: -0.0425
   Episode_Reward/pen_joint_torque: -0.0616
    Episode_Reward/pen_joint_accel: -0.0355
    Episode_Reward/pen_action_rate: -0.0172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0125
   Episode_Reward/pen_joint_powers: -0.0198
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0358
Episode_Reward/pen_flat_orientation: -0.1450
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0642
   Episode_Reward/foot_landing_vel: -0.0579
   Episode_Reward/test_gait_reward: -0.3056
Metrics/base_velocity/error_vel_xy: 1.1400
Metrics/base_velocity/error_vel_yaw: 0.2943
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 1.09s
                        Total time: 468.12s
                               ETA: 2791.4s

################################################################################
                     [1m Learning iteration 431/3000 [0m                      

                       Computation: 89223 steps/s (collection: 0.976s, learning 0.126s)
               Value function loss: 0.8650
                    Surrogate loss: 0.0025
             Mean action noise std: 0.6034
                     Learning rate: 0.0002
                       Mean reward: 18.49
               Mean episode length: 310.82
       Episode_Reward/keep_balance: 0.3052
     Episode_Reward/rew_lin_vel_xy: 0.5819
      Episode_Reward/rew_ang_vel_z: 0.9286
    Episode_Reward/pen_base_height: -0.2222
      Episode_Reward/pen_lin_vel_z: -0.0310
     Episode_Reward/pen_ang_vel_xy: -0.0407
   Episode_Reward/pen_joint_torque: -0.0554
    Episode_Reward/pen_joint_accel: -0.0308
    Episode_Reward/pen_action_rate: -0.0155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0115
   Episode_Reward/pen_joint_powers: -0.0180
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0321
Episode_Reward/pen_flat_orientation: -0.1356
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0604
   Episode_Reward/foot_landing_vel: -0.0539
   Episode_Reward/test_gait_reward: -0.2759
Metrics/base_velocity/error_vel_xy: 1.0412
Metrics/base_velocity/error_vel_yaw: 0.2682
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 1.10s
                        Total time: 469.23s
                               ETA: 2790.4s

################################################################################
                     [1m Learning iteration 432/3000 [0m                      

                       Computation: 90396 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.8071
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6040
                     Learning rate: 0.0004
                       Mean reward: 25.07
               Mean episode length: 392.25
       Episode_Reward/keep_balance: 0.3626
     Episode_Reward/rew_lin_vel_xy: 0.6818
      Episode_Reward/rew_ang_vel_z: 1.1018
    Episode_Reward/pen_base_height: -0.2397
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.0457
   Episode_Reward/pen_joint_torque: -0.0673
    Episode_Reward/pen_joint_accel: -0.0374
    Episode_Reward/pen_action_rate: -0.0188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0217
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0388
Episode_Reward/pen_flat_orientation: -0.1554
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0738
   Episode_Reward/foot_landing_vel: -0.0636
   Episode_Reward/test_gait_reward: -0.3270
Metrics/base_velocity/error_vel_xy: 1.2238
Metrics/base_velocity/error_vel_yaw: 0.3201
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 10.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 1.09s
                        Total time: 470.31s
                               ETA: 2789.3s

################################################################################
                     [1m Learning iteration 433/3000 [0m                      

                       Computation: 88635 steps/s (collection: 0.986s, learning 0.123s)
               Value function loss: 0.8483
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6053
                     Learning rate: 0.0009
                       Mean reward: 21.93
               Mean episode length: 353.81
       Episode_Reward/keep_balance: 0.3535
     Episode_Reward/rew_lin_vel_xy: 0.7670
      Episode_Reward/rew_ang_vel_z: 1.0737
    Episode_Reward/pen_base_height: -0.2361
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.0456
   Episode_Reward/pen_joint_torque: -0.0654
    Episode_Reward/pen_joint_accel: -0.0373
    Episode_Reward/pen_action_rate: -0.0182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0135
   Episode_Reward/pen_joint_powers: -0.0213
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0376
Episode_Reward/pen_flat_orientation: -0.1505
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0696
   Episode_Reward/foot_landing_vel: -0.0644
   Episode_Reward/test_gait_reward: -0.3195
Metrics/base_velocity/error_vel_xy: 1.1278
Metrics/base_velocity/error_vel_yaw: 0.3129
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 12.4167
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 1.11s
                        Total time: 471.42s
                               ETA: 2788.3s

################################################################################
                     [1m Learning iteration 434/3000 [0m                      

                       Computation: 90200 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.8280
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6065
                     Learning rate: 0.0013
                       Mean reward: 17.43
               Mean episode length: 344.43
       Episode_Reward/keep_balance: 0.3629
     Episode_Reward/rew_lin_vel_xy: 0.6730
      Episode_Reward/rew_ang_vel_z: 1.1009
    Episode_Reward/pen_base_height: -0.2416
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.0468
   Episode_Reward/pen_joint_torque: -0.0704
    Episode_Reward/pen_joint_accel: -0.0395
    Episode_Reward/pen_action_rate: -0.0190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0146
   Episode_Reward/pen_joint_powers: -0.0227
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0389
Episode_Reward/pen_flat_orientation: -0.1620
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0767
   Episode_Reward/foot_landing_vel: -0.0687
   Episode_Reward/test_gait_reward: -0.3298
Metrics/base_velocity/error_vel_xy: 1.2270
Metrics/base_velocity/error_vel_yaw: 0.3218
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 1.09s
                        Total time: 472.51s
                               ETA: 2787.3s

################################################################################
                     [1m Learning iteration 435/3000 [0m                      

                       Computation: 89126 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 0.9406
                    Surrogate loss: 0.0010
             Mean action noise std: 0.6071
                     Learning rate: 0.0004
                       Mean reward: 19.16
               Mean episode length: 322.25
       Episode_Reward/keep_balance: 0.3505
     Episode_Reward/rew_lin_vel_xy: 0.6999
      Episode_Reward/rew_ang_vel_z: 1.0672
    Episode_Reward/pen_base_height: -0.2352
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.0462
   Episode_Reward/pen_joint_torque: -0.0649
    Episode_Reward/pen_joint_accel: -0.0362
    Episode_Reward/pen_action_rate: -0.0181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0133
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0375
Episode_Reward/pen_flat_orientation: -0.1520
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0709
   Episode_Reward/foot_landing_vel: -0.0628
   Episode_Reward/test_gait_reward: -0.3178
Metrics/base_velocity/error_vel_xy: 1.1646
Metrics/base_velocity/error_vel_yaw: 0.3087
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 10.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 1.10s
                        Total time: 473.62s
                               ETA: 2786.3s

################################################################################
                     [1m Learning iteration 436/3000 [0m                      

                       Computation: 90441 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.8122
                    Surrogate loss: 0.0058
             Mean action noise std: 0.6075
                     Learning rate: 0.0001
                       Mean reward: 19.90
               Mean episode length: 321.33
       Episode_Reward/keep_balance: 0.3377
     Episode_Reward/rew_lin_vel_xy: 0.7048
      Episode_Reward/rew_ang_vel_z: 1.0265
    Episode_Reward/pen_base_height: -0.2311
      Episode_Reward/pen_lin_vel_z: -0.0332
     Episode_Reward/pen_ang_vel_xy: -0.0437
   Episode_Reward/pen_joint_torque: -0.0607
    Episode_Reward/pen_joint_accel: -0.0327
    Episode_Reward/pen_action_rate: -0.0174
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0126
   Episode_Reward/pen_joint_powers: -0.0198
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0363
Episode_Reward/pen_flat_orientation: -0.1418
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0657
   Episode_Reward/foot_landing_vel: -0.0573
   Episode_Reward/test_gait_reward: -0.3038
Metrics/base_velocity/error_vel_xy: 1.1151
Metrics/base_velocity/error_vel_yaw: 0.2974
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 1.09s
                        Total time: 474.70s
                               ETA: 2785.2s

################################################################################
                     [1m Learning iteration 437/3000 [0m                      

                       Computation: 88923 steps/s (collection: 0.980s, learning 0.125s)
               Value function loss: 0.8122
                    Surrogate loss: 0.0029
             Mean action noise std: 0.6080
                     Learning rate: 0.0001
                       Mean reward: 18.66
               Mean episode length: 319.06
       Episode_Reward/keep_balance: 0.3551
     Episode_Reward/rew_lin_vel_xy: 0.7413
      Episode_Reward/rew_ang_vel_z: 1.0752
    Episode_Reward/pen_base_height: -0.2433
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.0463
   Episode_Reward/pen_joint_torque: -0.0672
    Episode_Reward/pen_joint_accel: -0.0372
    Episode_Reward/pen_action_rate: -0.0185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0136
   Episode_Reward/pen_joint_powers: -0.0217
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0381
Episode_Reward/pen_flat_orientation: -0.1524
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0755
   Episode_Reward/foot_landing_vel: -0.0629
   Episode_Reward/test_gait_reward: -0.3220
Metrics/base_velocity/error_vel_xy: 1.1701
Metrics/base_velocity/error_vel_yaw: 0.3167
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 1.11s
                        Total time: 475.81s
                               ETA: 2784.2s

################################################################################
                     [1m Learning iteration 438/3000 [0m                      

                       Computation: 90332 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.7926
                    Surrogate loss: 0.0072
             Mean action noise std: 0.6083
                     Learning rate: 0.0000
                       Mean reward: 19.61
               Mean episode length: 340.29
       Episode_Reward/keep_balance: 0.3214
     Episode_Reward/rew_lin_vel_xy: 0.6219
      Episode_Reward/rew_ang_vel_z: 0.9704
    Episode_Reward/pen_base_height: -0.2253
      Episode_Reward/pen_lin_vel_z: -0.0311
     Episode_Reward/pen_ang_vel_xy: -0.0415
   Episode_Reward/pen_joint_torque: -0.0586
    Episode_Reward/pen_joint_accel: -0.0312
    Episode_Reward/pen_action_rate: -0.0167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0118
   Episode_Reward/pen_joint_powers: -0.0187
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0349
Episode_Reward/pen_flat_orientation: -0.1365
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0606
   Episode_Reward/foot_landing_vel: -0.0547
   Episode_Reward/test_gait_reward: -0.2916
Metrics/base_velocity/error_vel_xy: 1.0980
Metrics/base_velocity/error_vel_yaw: 0.2884
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 1.09s
                        Total time: 476.90s
                               ETA: 2783.2s

################################################################################
                     [1m Learning iteration 439/3000 [0m                      

                       Computation: 88311 steps/s (collection: 0.990s, learning 0.124s)
               Value function loss: 0.6951
                    Surrogate loss: -0.0012
             Mean action noise std: 0.6088
                     Learning rate: 0.0001
                       Mean reward: 26.31
               Mean episode length: 432.10
       Episode_Reward/keep_balance: 0.3828
     Episode_Reward/rew_lin_vel_xy: 0.8076
      Episode_Reward/rew_ang_vel_z: 1.1623
    Episode_Reward/pen_base_height: -0.2467
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.0480
   Episode_Reward/pen_joint_torque: -0.0685
    Episode_Reward/pen_joint_accel: -0.0397
    Episode_Reward/pen_action_rate: -0.0198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0140
   Episode_Reward/pen_joint_powers: -0.0222
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0411
Episode_Reward/pen_flat_orientation: -0.1501
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0718
   Episode_Reward/foot_landing_vel: -0.0649
   Episode_Reward/test_gait_reward: -0.3423
Metrics/base_velocity/error_vel_xy: 1.2313
Metrics/base_velocity/error_vel_yaw: 0.3373
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 1.11s
                        Total time: 478.01s
                               ETA: 2782.2s

################################################################################
                     [1m Learning iteration 440/3000 [0m                      

                       Computation: 90135 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.7653
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6092
                     Learning rate: 0.0003
                       Mean reward: 19.03
               Mean episode length: 330.00
       Episode_Reward/keep_balance: 0.3511
     Episode_Reward/rew_lin_vel_xy: 0.7440
      Episode_Reward/rew_ang_vel_z: 1.0691
    Episode_Reward/pen_base_height: -0.2392
      Episode_Reward/pen_lin_vel_z: -0.0349
     Episode_Reward/pen_ang_vel_xy: -0.0461
   Episode_Reward/pen_joint_torque: -0.0664
    Episode_Reward/pen_joint_accel: -0.0340
    Episode_Reward/pen_action_rate: -0.0181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0212
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0374
Episode_Reward/pen_flat_orientation: -0.1470
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0719
   Episode_Reward/foot_landing_vel: -0.0605
   Episode_Reward/test_gait_reward: -0.3210
Metrics/base_velocity/error_vel_xy: 1.1156
Metrics/base_velocity/error_vel_yaw: 0.3089
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 1.09s
                        Total time: 479.10s
                               ETA: 2781.2s

################################################################################
                     [1m Learning iteration 441/3000 [0m                      

                       Computation: 89984 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.7533
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6088
                     Learning rate: 0.0006
                       Mean reward: 19.67
               Mean episode length: 343.81
       Episode_Reward/keep_balance: 0.3398
     Episode_Reward/rew_lin_vel_xy: 0.7037
      Episode_Reward/rew_ang_vel_z: 1.0262
    Episode_Reward/pen_base_height: -0.2235
      Episode_Reward/pen_lin_vel_z: -0.0340
     Episode_Reward/pen_ang_vel_xy: -0.0444
   Episode_Reward/pen_joint_torque: -0.0641
    Episode_Reward/pen_joint_accel: -0.0363
    Episode_Reward/pen_action_rate: -0.0179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0131
   Episode_Reward/pen_joint_powers: -0.0206
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0372
Episode_Reward/pen_flat_orientation: -0.1433
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0687
   Episode_Reward/foot_landing_vel: -0.0607
   Episode_Reward/test_gait_reward: -0.3095
Metrics/base_velocity/error_vel_xy: 1.1160
Metrics/base_velocity/error_vel_yaw: 0.3037
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 1.09s
                        Total time: 480.19s
                               ETA: 2780.1s

################################################################################
                     [1m Learning iteration 442/3000 [0m                      

                       Computation: 89431 steps/s (collection: 0.977s, learning 0.122s)
               Value function loss: 0.8178
                    Surrogate loss: 0.0003
             Mean action noise std: 0.6100
                     Learning rate: 0.0006
                       Mean reward: 19.93
               Mean episode length: 347.76
       Episode_Reward/keep_balance: 0.3367
     Episode_Reward/rew_lin_vel_xy: 0.6957
      Episode_Reward/rew_ang_vel_z: 1.0226
    Episode_Reward/pen_base_height: -0.2233
      Episode_Reward/pen_lin_vel_z: -0.0339
     Episode_Reward/pen_ang_vel_xy: -0.0453
   Episode_Reward/pen_joint_torque: -0.0634
    Episode_Reward/pen_joint_accel: -0.0355
    Episode_Reward/pen_action_rate: -0.0176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0129
   Episode_Reward/pen_joint_powers: -0.0205
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0362
Episode_Reward/pen_flat_orientation: -0.1483
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0706
   Episode_Reward/foot_landing_vel: -0.0583
   Episode_Reward/test_gait_reward: -0.3086
Metrics/base_velocity/error_vel_xy: 1.1091
Metrics/base_velocity/error_vel_yaw: 0.2985
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 1.10s
                        Total time: 481.29s
                               ETA: 2779.1s

################################################################################
                     [1m Learning iteration 443/3000 [0m                      

                       Computation: 89853 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 0.8849
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6102
                     Learning rate: 0.0013
                       Mean reward: 20.37
               Mean episode length: 396.28
       Episode_Reward/keep_balance: 0.3949
     Episode_Reward/rew_lin_vel_xy: 0.7651
      Episode_Reward/rew_ang_vel_z: 1.2043
    Episode_Reward/pen_base_height: -0.2483
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.0497
   Episode_Reward/pen_joint_torque: -0.0760
    Episode_Reward/pen_joint_accel: -0.0400
    Episode_Reward/pen_action_rate: -0.0209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0152
   Episode_Reward/pen_joint_powers: -0.0242
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0429
Episode_Reward/pen_flat_orientation: -0.1637
  Episode_Reward/pen_feet_distance: -0.0001
Episode_Reward/pen_feet_regulation: -0.0834
   Episode_Reward/foot_landing_vel: -0.0695
   Episode_Reward/test_gait_reward: -0.3586
Metrics/base_velocity/error_vel_xy: 1.3185
Metrics/base_velocity/error_vel_yaw: 0.3449
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 1.09s
                        Total time: 482.39s
                               ETA: 2778.1s

################################################################################
                     [1m Learning iteration 444/3000 [0m                      

                       Computation: 89656 steps/s (collection: 0.972s, learning 0.125s)
               Value function loss: 0.8771
                    Surrogate loss: -0.0007
             Mean action noise std: 0.6103
                     Learning rate: 0.0013
                       Mean reward: 15.90
               Mean episode length: 290.29
       Episode_Reward/keep_balance: 0.3360
     Episode_Reward/rew_lin_vel_xy: 0.6270
      Episode_Reward/rew_ang_vel_z: 1.0149
    Episode_Reward/pen_base_height: -0.2215
      Episode_Reward/pen_lin_vel_z: -0.0333
     Episode_Reward/pen_ang_vel_xy: -0.0455
   Episode_Reward/pen_joint_torque: -0.0603
    Episode_Reward/pen_joint_accel: -0.0338
    Episode_Reward/pen_action_rate: -0.0177
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0127
   Episode_Reward/pen_joint_powers: -0.0199
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0366
Episode_Reward/pen_flat_orientation: -0.1459
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0679
   Episode_Reward/foot_landing_vel: -0.0567
   Episode_Reward/test_gait_reward: -0.3051
Metrics/base_velocity/error_vel_xy: 1.1600
Metrics/base_velocity/error_vel_yaw: 0.3005
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 1.10s
                        Total time: 483.48s
                               ETA: 2777.0s

################################################################################
                     [1m Learning iteration 445/3000 [0m                      

                       Computation: 90096 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.7500
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6106
                     Learning rate: 0.0009
                       Mean reward: 23.11
               Mean episode length: 361.70
       Episode_Reward/keep_balance: 0.3602
     Episode_Reward/rew_lin_vel_xy: 0.7452
      Episode_Reward/rew_ang_vel_z: 1.0986
    Episode_Reward/pen_base_height: -0.2358
      Episode_Reward/pen_lin_vel_z: -0.0353
     Episode_Reward/pen_ang_vel_xy: -0.0460
   Episode_Reward/pen_joint_torque: -0.0668
    Episode_Reward/pen_joint_accel: -0.0342
    Episode_Reward/pen_action_rate: -0.0189
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0133
   Episode_Reward/pen_joint_powers: -0.0215
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0391
Episode_Reward/pen_flat_orientation: -0.1505
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0753
   Episode_Reward/foot_landing_vel: -0.0602
   Episode_Reward/test_gait_reward: -0.3272
Metrics/base_velocity/error_vel_xy: 1.1813
Metrics/base_velocity/error_vel_yaw: 0.3147
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 1.09s
                        Total time: 484.57s
                               ETA: 2776.0s

################################################################################
                     [1m Learning iteration 446/3000 [0m                      

                       Computation: 90154 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.9103
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6107
                     Learning rate: 0.0013
                       Mean reward: 21.88
               Mean episode length: 380.59
       Episode_Reward/keep_balance: 0.3663
     Episode_Reward/rew_lin_vel_xy: 0.7415
      Episode_Reward/rew_ang_vel_z: 1.1065
    Episode_Reward/pen_base_height: -0.2370
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.0499
   Episode_Reward/pen_joint_torque: -0.0686
    Episode_Reward/pen_joint_accel: -0.0383
    Episode_Reward/pen_action_rate: -0.0198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0145
   Episode_Reward/pen_joint_powers: -0.0227
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0403
Episode_Reward/pen_flat_orientation: -0.1595
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0811
   Episode_Reward/foot_landing_vel: -0.0675
   Episode_Reward/test_gait_reward: -0.3348
Metrics/base_velocity/error_vel_xy: 1.2232
Metrics/base_velocity/error_vel_yaw: 0.3281
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 8.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 1.09s
                        Total time: 485.66s
                               ETA: 2774.9s

################################################################################
                     [1m Learning iteration 447/3000 [0m                      

                       Computation: 90236 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 1.1232
                    Surrogate loss: -0.0012
             Mean action noise std: 0.6112
                     Learning rate: 0.0013
                       Mean reward: 21.58
               Mean episode length: 375.16
       Episode_Reward/keep_balance: 0.3689
     Episode_Reward/rew_lin_vel_xy: 0.6959
      Episode_Reward/rew_ang_vel_z: 1.1259
    Episode_Reward/pen_base_height: -0.2374
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.0483
   Episode_Reward/pen_joint_torque: -0.0684
    Episode_Reward/pen_joint_accel: -0.0377
    Episode_Reward/pen_action_rate: -0.0194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0139
   Episode_Reward/pen_joint_powers: -0.0222
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0398
Episode_Reward/pen_flat_orientation: -0.1539
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0762
   Episode_Reward/foot_landing_vel: -0.0623
   Episode_Reward/test_gait_reward: -0.3359
Metrics/base_velocity/error_vel_xy: 1.2859
Metrics/base_velocity/error_vel_yaw: 0.3210
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 1.09s
                        Total time: 486.75s
                               ETA: 2773.8s

################################################################################
                     [1m Learning iteration 448/3000 [0m                      

                       Computation: 89213 steps/s (collection: 0.978s, learning 0.124s)
               Value function loss: 1.1032
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6116
                     Learning rate: 0.0019
                       Mean reward: 18.51
               Mean episode length: 331.32
       Episode_Reward/keep_balance: 0.3553
     Episode_Reward/rew_lin_vel_xy: 0.6973
      Episode_Reward/rew_ang_vel_z: 1.0796
    Episode_Reward/pen_base_height: -0.2357
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.0472
   Episode_Reward/pen_joint_torque: -0.0675
    Episode_Reward/pen_joint_accel: -0.0376
    Episode_Reward/pen_action_rate: -0.0190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0140
   Episode_Reward/pen_joint_powers: -0.0219
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0389
Episode_Reward/pen_flat_orientation: -0.1546
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0785
   Episode_Reward/foot_landing_vel: -0.0602
   Episode_Reward/test_gait_reward: -0.3266
Metrics/base_velocity/error_vel_xy: 1.1512
Metrics/base_velocity/error_vel_yaw: 0.3149
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 1.10s
                        Total time: 487.85s
                               ETA: 2772.8s

################################################################################
                     [1m Learning iteration 449/3000 [0m                      

                       Computation: 88894 steps/s (collection: 0.982s, learning 0.124s)
               Value function loss: 1.1831
                    Surrogate loss: 0.0123
             Mean action noise std: 0.6122
                     Learning rate: 0.0001
                       Mean reward: 23.06
               Mean episode length: 365.18
       Episode_Reward/keep_balance: 0.4148
     Episode_Reward/rew_lin_vel_xy: 0.9123
      Episode_Reward/rew_ang_vel_z: 1.2572
    Episode_Reward/pen_base_height: -0.2508
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.0526
   Episode_Reward/pen_joint_torque: -0.0771
    Episode_Reward/pen_joint_accel: -0.0435
    Episode_Reward/pen_action_rate: -0.0224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0156
   Episode_Reward/pen_joint_powers: -0.0247
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0463
Episode_Reward/pen_flat_orientation: -0.1733
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0859
   Episode_Reward/foot_landing_vel: -0.0698
   Episode_Reward/test_gait_reward: -0.3758
Metrics/base_velocity/error_vel_xy: 1.3320
Metrics/base_velocity/error_vel_yaw: 0.3684
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 1.11s
                        Total time: 488.96s
                               ETA: 2771.9s

################################################################################
                     [1m Learning iteration 450/3000 [0m                      

                       Computation: 90479 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.8006
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6123
                     Learning rate: 0.0003
                       Mean reward: 24.02
               Mean episode length: 391.89
       Episode_Reward/keep_balance: 0.4036
     Episode_Reward/rew_lin_vel_xy: 0.8622
      Episode_Reward/rew_ang_vel_z: 1.2295
    Episode_Reward/pen_base_height: -0.2514
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.0508
   Episode_Reward/pen_joint_torque: -0.0765
    Episode_Reward/pen_joint_accel: -0.0420
    Episode_Reward/pen_action_rate: -0.0216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0152
   Episode_Reward/pen_joint_powers: -0.0244
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0444
Episode_Reward/pen_flat_orientation: -0.1641
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0852
   Episode_Reward/foot_landing_vel: -0.0662
   Episode_Reward/test_gait_reward: -0.3686
Metrics/base_velocity/error_vel_xy: 1.3027
Metrics/base_velocity/error_vel_yaw: 0.3540
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 1.09s
                        Total time: 490.05s
                               ETA: 2770.8s

################################################################################
                     [1m Learning iteration 451/3000 [0m                      

                       Computation: 90633 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.8037
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6126
                     Learning rate: 0.0003
                       Mean reward: 26.02
               Mean episode length: 424.02
       Episode_Reward/keep_balance: 0.3954
     Episode_Reward/rew_lin_vel_xy: 0.8615
      Episode_Reward/rew_ang_vel_z: 1.1978
    Episode_Reward/pen_base_height: -0.2461
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.0525
   Episode_Reward/pen_joint_torque: -0.0760
    Episode_Reward/pen_joint_accel: -0.0444
    Episode_Reward/pen_action_rate: -0.0214
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0156
   Episode_Reward/pen_joint_powers: -0.0246
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0438
Episode_Reward/pen_flat_orientation: -0.1595
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0845
   Episode_Reward/foot_landing_vel: -0.0686
   Episode_Reward/test_gait_reward: -0.3610
Metrics/base_velocity/error_vel_xy: 1.2495
Metrics/base_velocity/error_vel_yaw: 0.3523
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 1.08s
                        Total time: 491.13s
                               ETA: 2769.7s

################################################################################
                     [1m Learning iteration 452/3000 [0m                      

                       Computation: 89070 steps/s (collection: 0.981s, learning 0.123s)
               Value function loss: 0.7378
                    Surrogate loss: 0.0031
             Mean action noise std: 0.6129
                     Learning rate: 0.0001
                       Mean reward: 22.37
               Mean episode length: 354.24
       Episode_Reward/keep_balance: 0.3939
     Episode_Reward/rew_lin_vel_xy: 0.8579
      Episode_Reward/rew_ang_vel_z: 1.1962
    Episode_Reward/pen_base_height: -0.2477
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.0501
   Episode_Reward/pen_joint_torque: -0.0759
    Episode_Reward/pen_joint_accel: -0.0395
    Episode_Reward/pen_action_rate: -0.0214
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0148
   Episode_Reward/pen_joint_powers: -0.0239
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0441
Episode_Reward/pen_flat_orientation: -0.1615
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0838
   Episode_Reward/foot_landing_vel: -0.0629
   Episode_Reward/test_gait_reward: -0.3594
Metrics/base_velocity/error_vel_xy: 1.2698
Metrics/base_velocity/error_vel_yaw: 0.3492
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 1.10s
                        Total time: 492.24s
                               ETA: 2768.7s

################################################################################
                     [1m Learning iteration 453/3000 [0m                      

                       Computation: 89830 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.7287
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6125
                     Learning rate: 0.0001
                       Mean reward: 19.12
               Mean episode length: 371.89
       Episode_Reward/keep_balance: 0.3949
     Episode_Reward/rew_lin_vel_xy: 0.7803
      Episode_Reward/rew_ang_vel_z: 1.1980
    Episode_Reward/pen_base_height: -0.2457
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.0510
   Episode_Reward/pen_joint_torque: -0.0734
    Episode_Reward/pen_joint_accel: -0.0413
    Episode_Reward/pen_action_rate: -0.0216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0153
   Episode_Reward/pen_joint_powers: -0.0239
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0442
Episode_Reward/pen_flat_orientation: -0.1685
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0837
   Episode_Reward/foot_landing_vel: -0.0707
   Episode_Reward/test_gait_reward: -0.3624
Metrics/base_velocity/error_vel_xy: 1.3175
Metrics/base_velocity/error_vel_yaw: 0.3506
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 1.09s
                        Total time: 493.33s
                               ETA: 2767.6s

################################################################################
                     [1m Learning iteration 454/3000 [0m                      

                       Computation: 89546 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.8187
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6121
                     Learning rate: 0.0001
                       Mean reward: 20.38
               Mean episode length: 354.04
       Episode_Reward/keep_balance: 0.3693
     Episode_Reward/rew_lin_vel_xy: 0.8115
      Episode_Reward/rew_ang_vel_z: 1.1112
    Episode_Reward/pen_base_height: -0.2372
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.0494
   Episode_Reward/pen_joint_torque: -0.0693
    Episode_Reward/pen_joint_accel: -0.0405
    Episode_Reward/pen_action_rate: -0.0205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0229
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0421
Episode_Reward/pen_flat_orientation: -0.1539
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0808
   Episode_Reward/foot_landing_vel: -0.0689
   Episode_Reward/test_gait_reward: -0.3391
Metrics/base_velocity/error_vel_xy: 1.2398
Metrics/base_velocity/error_vel_yaw: 0.3325
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 1.10s
                        Total time: 494.43s
                               ETA: 2766.6s

################################################################################
                     [1m Learning iteration 455/3000 [0m                      

                       Computation: 89883 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.8089
                    Surrogate loss: 0.0014
             Mean action noise std: 0.6125
                     Learning rate: 0.0003
                       Mean reward: 21.71
               Mean episode length: 379.57
       Episode_Reward/keep_balance: 0.3955
     Episode_Reward/rew_lin_vel_xy: 0.7977
      Episode_Reward/rew_ang_vel_z: 1.1816
    Episode_Reward/pen_base_height: -0.2504
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.0497
   Episode_Reward/pen_joint_torque: -0.0739
    Episode_Reward/pen_joint_accel: -0.0402
    Episode_Reward/pen_action_rate: -0.0218
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0150
   Episode_Reward/pen_joint_powers: -0.0239
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0450
Episode_Reward/pen_flat_orientation: -0.1610
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0858
   Episode_Reward/foot_landing_vel: -0.0656
   Episode_Reward/test_gait_reward: -0.3610
Metrics/base_velocity/error_vel_xy: 1.3273
Metrics/base_velocity/error_vel_yaw: 0.3638
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 1.09s
                        Total time: 495.52s
                               ETA: 2765.6s

################################################################################
                     [1m Learning iteration 456/3000 [0m                      

                       Computation: 90737 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.8200
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6128
                     Learning rate: 0.0004
                       Mean reward: 20.16
               Mean episode length: 351.15
       Episode_Reward/keep_balance: 0.3740
     Episode_Reward/rew_lin_vel_xy: 0.7719
      Episode_Reward/rew_ang_vel_z: 1.1247
    Episode_Reward/pen_base_height: -0.2332
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.0489
   Episode_Reward/pen_joint_torque: -0.0687
    Episode_Reward/pen_joint_accel: -0.0396
    Episode_Reward/pen_action_rate: -0.0206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0225
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0424
Episode_Reward/pen_flat_orientation: -0.1579
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0816
   Episode_Reward/foot_landing_vel: -0.0618
   Episode_Reward/test_gait_reward: -0.3413
Metrics/base_velocity/error_vel_xy: 1.2244
Metrics/base_velocity/error_vel_yaw: 0.3385
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 1.08s
                        Total time: 496.60s
                               ETA: 2764.5s

################################################################################
                     [1m Learning iteration 457/3000 [0m                      

                       Computation: 90370 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.8559
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6127
                     Learning rate: 0.0009
                       Mean reward: 27.62
               Mean episode length: 396.15
       Episode_Reward/keep_balance: 0.3644
     Episode_Reward/rew_lin_vel_xy: 0.8313
      Episode_Reward/rew_ang_vel_z: 1.1082
    Episode_Reward/pen_base_height: -0.2321
      Episode_Reward/pen_lin_vel_z: -0.0343
     Episode_Reward/pen_ang_vel_xy: -0.0481
   Episode_Reward/pen_joint_torque: -0.0671
    Episode_Reward/pen_joint_accel: -0.0402
    Episode_Reward/pen_action_rate: -0.0200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0140
   Episode_Reward/pen_joint_powers: -0.0219
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0414
Episode_Reward/pen_flat_orientation: -0.1507
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0766
   Episode_Reward/foot_landing_vel: -0.0605
   Episode_Reward/test_gait_reward: -0.3334
Metrics/base_velocity/error_vel_xy: 1.1256
Metrics/base_velocity/error_vel_yaw: 0.3194
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 1.09s
                        Total time: 497.69s
                               ETA: 2763.4s

################################################################################
                     [1m Learning iteration 458/3000 [0m                      

                       Computation: 90555 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 1.2314
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6133
                     Learning rate: 0.0019
                       Mean reward: 21.91
               Mean episode length: 359.25
       Episode_Reward/keep_balance: 0.3962
     Episode_Reward/rew_lin_vel_xy: 0.9207
      Episode_Reward/rew_ang_vel_z: 1.1945
    Episode_Reward/pen_base_height: -0.2397
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.0521
   Episode_Reward/pen_joint_torque: -0.0737
    Episode_Reward/pen_joint_accel: -0.0430
    Episode_Reward/pen_action_rate: -0.0221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0155
   Episode_Reward/pen_joint_powers: -0.0242
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0457
Episode_Reward/pen_flat_orientation: -0.1651
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0854
   Episode_Reward/foot_landing_vel: -0.0705
   Episode_Reward/test_gait_reward: -0.3637
Metrics/base_velocity/error_vel_xy: 1.2486
Metrics/base_velocity/error_vel_yaw: 0.3616
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 1.09s
                        Total time: 498.78s
                               ETA: 2762.3s

################################################################################
                     [1m Learning iteration 459/3000 [0m                      

                       Computation: 90518 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 1.0006
                    Surrogate loss: 0.0031
             Mean action noise std: 0.6141
                     Learning rate: 0.0006
                       Mean reward: 20.01
               Mean episode length: 354.27
       Episode_Reward/keep_balance: 0.3893
     Episode_Reward/rew_lin_vel_xy: 0.8371
      Episode_Reward/rew_ang_vel_z: 1.1825
    Episode_Reward/pen_base_height: -0.2412
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.0509
   Episode_Reward/pen_joint_torque: -0.0727
    Episode_Reward/pen_joint_accel: -0.0407
    Episode_Reward/pen_action_rate: -0.0214
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0151
   Episode_Reward/pen_joint_powers: -0.0237
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0441
Episode_Reward/pen_flat_orientation: -0.1602
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0831
   Episode_Reward/foot_landing_vel: -0.0680
   Episode_Reward/test_gait_reward: -0.3564
Metrics/base_velocity/error_vel_xy: 1.2611
Metrics/base_velocity/error_vel_yaw: 0.3434
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 9.3333
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 1.09s
                        Total time: 499.86s
                               ETA: 2761.2s

################################################################################
                     [1m Learning iteration 460/3000 [0m                      

                       Computation: 90671 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.8126
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6145
                     Learning rate: 0.0009
                       Mean reward: 26.11
               Mean episode length: 407.92
       Episode_Reward/keep_balance: 0.3894
     Episode_Reward/rew_lin_vel_xy: 0.9103
      Episode_Reward/rew_ang_vel_z: 1.1852
    Episode_Reward/pen_base_height: -0.2400
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.0519
   Episode_Reward/pen_joint_torque: -0.0731
    Episode_Reward/pen_joint_accel: -0.0402
    Episode_Reward/pen_action_rate: -0.0214
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0145
   Episode_Reward/pen_joint_powers: -0.0233
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0442
Episode_Reward/pen_flat_orientation: -0.1566
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0796
   Episode_Reward/foot_landing_vel: -0.0625
   Episode_Reward/test_gait_reward: -0.3555
Metrics/base_velocity/error_vel_xy: 1.2118
Metrics/base_velocity/error_vel_yaw: 0.3429
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 1.08s
                        Total time: 500.95s
                               ETA: 2760.1s

################################################################################
                     [1m Learning iteration 461/3000 [0m                      

                       Computation: 89830 steps/s (collection: 0.969s, learning 0.126s)
               Value function loss: 0.8305
                    Surrogate loss: 0.0010
             Mean action noise std: 0.6154
                     Learning rate: 0.0004
                       Mean reward: 25.59
               Mean episode length: 414.83
       Episode_Reward/keep_balance: 0.3840
     Episode_Reward/rew_lin_vel_xy: 0.8361
      Episode_Reward/rew_ang_vel_z: 1.1649
    Episode_Reward/pen_base_height: -0.2391
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.0494
   Episode_Reward/pen_joint_torque: -0.0705
    Episode_Reward/pen_joint_accel: -0.0392
    Episode_Reward/pen_action_rate: -0.0211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0143
   Episode_Reward/pen_joint_powers: -0.0227
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0437
Episode_Reward/pen_flat_orientation: -0.1572
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0792
   Episode_Reward/foot_landing_vel: -0.0634
   Episode_Reward/test_gait_reward: -0.3502
Metrics/base_velocity/error_vel_xy: 1.2484
Metrics/base_velocity/error_vel_yaw: 0.3429
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 1.09s
                        Total time: 502.04s
                               ETA: 2759.1s

################################################################################
                     [1m Learning iteration 462/3000 [0m                      

                       Computation: 90369 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 0.9090
                    Surrogate loss: -0.0014
             Mean action noise std: 0.6158
                     Learning rate: 0.0006
                       Mean reward: 28.67
               Mean episode length: 432.78
       Episode_Reward/keep_balance: 0.4459
     Episode_Reward/rew_lin_vel_xy: 0.9826
      Episode_Reward/rew_ang_vel_z: 1.3528
    Episode_Reward/pen_base_height: -0.2515
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.0541
   Episode_Reward/pen_joint_torque: -0.0820
    Episode_Reward/pen_joint_accel: -0.0454
    Episode_Reward/pen_action_rate: -0.0248
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0163
   Episode_Reward/pen_joint_powers: -0.0262
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0508
Episode_Reward/pen_flat_orientation: -0.1700
  Episode_Reward/pen_feet_distance: -0.0002
Episode_Reward/pen_feet_regulation: -0.0916
   Episode_Reward/foot_landing_vel: -0.0737
   Episode_Reward/test_gait_reward: -0.4058
Metrics/base_velocity/error_vel_xy: 1.4568
Metrics/base_velocity/error_vel_yaw: 0.3931
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 1.09s
                        Total time: 503.13s
                               ETA: 2758.0s

################################################################################
                     [1m Learning iteration 463/3000 [0m                      

                       Computation: 90424 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 1.0003
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6165
                     Learning rate: 0.0019
                       Mean reward: 24.05
               Mean episode length: 385.52
       Episode_Reward/keep_balance: 0.3859
     Episode_Reward/rew_lin_vel_xy: 0.8120
      Episode_Reward/rew_ang_vel_z: 1.1583
    Episode_Reward/pen_base_height: -0.2368
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.0499
   Episode_Reward/pen_joint_torque: -0.0707
    Episode_Reward/pen_joint_accel: -0.0389
    Episode_Reward/pen_action_rate: -0.0215
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0143
   Episode_Reward/pen_joint_powers: -0.0228
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0444
Episode_Reward/pen_flat_orientation: -0.1524
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0792
   Episode_Reward/foot_landing_vel: -0.0645
   Episode_Reward/test_gait_reward: -0.3540
Metrics/base_velocity/error_vel_xy: 1.2699
Metrics/base_velocity/error_vel_yaw: 0.3499
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 1.09s
                        Total time: 504.22s
                               ETA: 2756.9s

################################################################################
                     [1m Learning iteration 464/3000 [0m                      

                       Computation: 89484 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 1.1061
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6178
                     Learning rate: 0.0006
                       Mean reward: 26.08
               Mean episode length: 388.36
       Episode_Reward/keep_balance: 0.3700
     Episode_Reward/rew_lin_vel_xy: 0.8509
      Episode_Reward/rew_ang_vel_z: 1.1309
    Episode_Reward/pen_base_height: -0.2324
      Episode_Reward/pen_lin_vel_z: -0.0332
     Episode_Reward/pen_ang_vel_xy: -0.0484
   Episode_Reward/pen_joint_torque: -0.0658
    Episode_Reward/pen_joint_accel: -0.0375
    Episode_Reward/pen_action_rate: -0.0202
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0133
   Episode_Reward/pen_joint_powers: -0.0213
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0421
Episode_Reward/pen_flat_orientation: -0.1494
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0715
   Episode_Reward/foot_landing_vel: -0.0581
   Episode_Reward/test_gait_reward: -0.3379
Metrics/base_velocity/error_vel_xy: 1.1727
Metrics/base_velocity/error_vel_yaw: 0.3216
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 11.3750
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 1.10s
                        Total time: 505.32s
                               ETA: 2755.9s

################################################################################
                     [1m Learning iteration 465/3000 [0m                      

                       Computation: 90566 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 1.2196
                    Surrogate loss: 0.0058
             Mean action noise std: 0.6179
                     Learning rate: 0.0001
                       Mean reward: 23.08
               Mean episode length: 369.98
       Episode_Reward/keep_balance: 0.3662
     Episode_Reward/rew_lin_vel_xy: 0.8088
      Episode_Reward/rew_ang_vel_z: 1.1002
    Episode_Reward/pen_base_height: -0.2297
      Episode_Reward/pen_lin_vel_z: -0.0339
     Episode_Reward/pen_ang_vel_xy: -0.0486
   Episode_Reward/pen_joint_torque: -0.0667
    Episode_Reward/pen_joint_accel: -0.0356
    Episode_Reward/pen_action_rate: -0.0203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0217
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0421
Episode_Reward/pen_flat_orientation: -0.1487
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0769
   Episode_Reward/foot_landing_vel: -0.0593
   Episode_Reward/test_gait_reward: -0.3363
Metrics/base_velocity/error_vel_xy: 1.1667
Metrics/base_velocity/error_vel_yaw: 0.3323
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 1.09s
                        Total time: 506.40s
                               ETA: 2754.8s

################################################################################
                     [1m Learning iteration 466/3000 [0m                      

                       Computation: 89306 steps/s (collection: 0.979s, learning 0.122s)
               Value function loss: 1.0423
                    Surrogate loss: 0.0061
             Mean action noise std: 0.6180
                     Learning rate: 0.0000
                       Mean reward: 22.53
               Mean episode length: 359.26
       Episode_Reward/keep_balance: 0.3502
     Episode_Reward/rew_lin_vel_xy: 0.7522
      Episode_Reward/rew_ang_vel_z: 1.0431
    Episode_Reward/pen_base_height: -0.2244
      Episode_Reward/pen_lin_vel_z: -0.0340
     Episode_Reward/pen_ang_vel_xy: -0.0485
   Episode_Reward/pen_joint_torque: -0.0630
    Episode_Reward/pen_joint_accel: -0.0373
    Episode_Reward/pen_action_rate: -0.0196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0136
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0406
Episode_Reward/pen_flat_orientation: -0.1476
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0765
   Episode_Reward/foot_landing_vel: -0.0595
   Episode_Reward/test_gait_reward: -0.3214
Metrics/base_velocity/error_vel_xy: 1.1394
Metrics/base_velocity/error_vel_yaw: 0.3278
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 1.10s
                        Total time: 507.50s
                               ETA: 2753.8s

################################################################################
                     [1m Learning iteration 467/3000 [0m                      

                       Computation: 89972 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.9868
                    Surrogate loss: 0.0008
             Mean action noise std: 0.6178
                     Learning rate: 0.0002
                       Mean reward: 23.25
               Mean episode length: 395.33
       Episode_Reward/keep_balance: 0.3822
     Episode_Reward/rew_lin_vel_xy: 0.7723
      Episode_Reward/rew_ang_vel_z: 1.1515
    Episode_Reward/pen_base_height: -0.2316
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.0518
   Episode_Reward/pen_joint_torque: -0.0736
    Episode_Reward/pen_joint_accel: -0.0432
    Episode_Reward/pen_action_rate: -0.0216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0154
   Episode_Reward/pen_joint_powers: -0.0240
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0439
Episode_Reward/pen_flat_orientation: -0.1563
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0847
   Episode_Reward/foot_landing_vel: -0.0669
   Episode_Reward/test_gait_reward: -0.3519
Metrics/base_velocity/error_vel_xy: 1.2845
Metrics/base_velocity/error_vel_yaw: 0.3458
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 1.09s
                        Total time: 508.59s
                               ETA: 2752.7s

################################################################################
                     [1m Learning iteration 468/3000 [0m                      

                       Computation: 89721 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 1.0050
                    Surrogate loss: 0.0022
             Mean action noise std: 0.6177
                     Learning rate: 0.0001
                       Mean reward: 25.46
               Mean episode length: 390.61
       Episode_Reward/keep_balance: 0.4079
     Episode_Reward/rew_lin_vel_xy: 0.9295
      Episode_Reward/rew_ang_vel_z: 1.2270
    Episode_Reward/pen_base_height: -0.2450
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.0541
   Episode_Reward/pen_joint_torque: -0.0788
    Episode_Reward/pen_joint_accel: -0.0437
    Episode_Reward/pen_action_rate: -0.0232
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0162
   Episode_Reward/pen_joint_powers: -0.0255
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0472
Episode_Reward/pen_flat_orientation: -0.1695
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0922
   Episode_Reward/foot_landing_vel: -0.0735
   Episode_Reward/test_gait_reward: -0.3767
Metrics/base_velocity/error_vel_xy: 1.3071
Metrics/base_velocity/error_vel_yaw: 0.3700
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 1.10s
                        Total time: 509.69s
                               ETA: 2751.7s

################################################################################
                     [1m Learning iteration 469/3000 [0m                      

                       Computation: 90005 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.8361
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6183
                     Learning rate: 0.0006
                       Mean reward: 23.72
               Mean episode length: 371.71
       Episode_Reward/keep_balance: 0.3696
     Episode_Reward/rew_lin_vel_xy: 0.8764
      Episode_Reward/rew_ang_vel_z: 1.1207
    Episode_Reward/pen_base_height: -0.2286
      Episode_Reward/pen_lin_vel_z: -0.0349
     Episode_Reward/pen_ang_vel_xy: -0.0495
   Episode_Reward/pen_joint_torque: -0.0699
    Episode_Reward/pen_joint_accel: -0.0406
    Episode_Reward/pen_action_rate: -0.0206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0142
   Episode_Reward/pen_joint_powers: -0.0224
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0424
Episode_Reward/pen_flat_orientation: -0.1504
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0788
   Episode_Reward/foot_landing_vel: -0.0606
   Episode_Reward/test_gait_reward: -0.3398
Metrics/base_velocity/error_vel_xy: 1.1392
Metrics/base_velocity/error_vel_yaw: 0.3279
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 13.0000
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 1.09s
                        Total time: 510.78s
                               ETA: 2750.6s

################################################################################
                     [1m Learning iteration 470/3000 [0m                      

                       Computation: 89927 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.9758
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6188
                     Learning rate: 0.0009
                       Mean reward: 23.81
               Mean episode length: 375.09
       Episode_Reward/keep_balance: 0.3406
     Episode_Reward/rew_lin_vel_xy: 0.7890
      Episode_Reward/rew_ang_vel_z: 1.0315
    Episode_Reward/pen_base_height: -0.2155
      Episode_Reward/pen_lin_vel_z: -0.0314
     Episode_Reward/pen_ang_vel_xy: -0.0473
   Episode_Reward/pen_joint_torque: -0.0620
    Episode_Reward/pen_joint_accel: -0.0341
    Episode_Reward/pen_action_rate: -0.0188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0126
   Episode_Reward/pen_joint_powers: -0.0202
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0390
Episode_Reward/pen_flat_orientation: -0.1374
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0677
   Episode_Reward/foot_landing_vel: -0.0532
   Episode_Reward/test_gait_reward: -0.3127
Metrics/base_velocity/error_vel_xy: 1.0991
Metrics/base_velocity/error_vel_yaw: 0.3040
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 12.0000
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 1.09s
                        Total time: 511.88s
                               ETA: 2749.6s

################################################################################
                     [1m Learning iteration 471/3000 [0m                      

                       Computation: 89788 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 1.6251
                    Surrogate loss: 0.0008
             Mean action noise std: 0.6188
                     Learning rate: 0.0006
                       Mean reward: 20.23
               Mean episode length: 320.95
       Episode_Reward/keep_balance: 0.3597
     Episode_Reward/rew_lin_vel_xy: 0.8543
      Episode_Reward/rew_ang_vel_z: 1.0922
    Episode_Reward/pen_base_height: -0.2304
      Episode_Reward/pen_lin_vel_z: -0.0328
     Episode_Reward/pen_ang_vel_xy: -0.0481
   Episode_Reward/pen_joint_torque: -0.0646
    Episode_Reward/pen_joint_accel: -0.0360
    Episode_Reward/pen_action_rate: -0.0200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0133
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0415
Episode_Reward/pen_flat_orientation: -0.1440
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0731
   Episode_Reward/foot_landing_vel: -0.0568
   Episode_Reward/test_gait_reward: -0.3311
Metrics/base_velocity/error_vel_xy: 1.1279
Metrics/base_velocity/error_vel_yaw: 0.3181
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 8.9167
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 1.09s
                        Total time: 512.97s
                               ETA: 2748.5s

################################################################################
                     [1m Learning iteration 472/3000 [0m                      

                       Computation: 87042 steps/s (collection: 1.000s, learning 0.129s)
               Value function loss: 0.9626
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6197
                     Learning rate: 0.0013
                       Mean reward: 20.55
               Mean episode length: 327.62
       Episode_Reward/keep_balance: 0.3253
     Episode_Reward/rew_lin_vel_xy: 0.7732
      Episode_Reward/rew_ang_vel_z: 0.9756
    Episode_Reward/pen_base_height: -0.2180
      Episode_Reward/pen_lin_vel_z: -0.0308
     Episode_Reward/pen_ang_vel_xy: -0.0461
   Episode_Reward/pen_joint_torque: -0.0595
    Episode_Reward/pen_joint_accel: -0.0348
    Episode_Reward/pen_action_rate: -0.0183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0126
   Episode_Reward/pen_joint_powers: -0.0196
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0379
Episode_Reward/pen_flat_orientation: -0.1378
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0723
   Episode_Reward/foot_landing_vel: -0.0522
   Episode_Reward/test_gait_reward: -0.3020
Metrics/base_velocity/error_vel_xy: 1.0168
Metrics/base_velocity/error_vel_yaw: 0.2975
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 10.7500
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 1.13s
                        Total time: 514.10s
                               ETA: 2747.7s

################################################################################
                     [1m Learning iteration 473/3000 [0m                      

                       Computation: 85878 steps/s (collection: 1.015s, learning 0.130s)
               Value function loss: 1.0770
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6210
                     Learning rate: 0.0013
                       Mean reward: 20.65
               Mean episode length: 336.17
       Episode_Reward/keep_balance: 0.3547
     Episode_Reward/rew_lin_vel_xy: 0.8077
      Episode_Reward/rew_ang_vel_z: 1.0767
    Episode_Reward/pen_base_height: -0.2236
      Episode_Reward/pen_lin_vel_z: -0.0332
     Episode_Reward/pen_ang_vel_xy: -0.0487
   Episode_Reward/pen_joint_torque: -0.0657
    Episode_Reward/pen_joint_accel: -0.0372
    Episode_Reward/pen_action_rate: -0.0198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0212
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0407
Episode_Reward/pen_flat_orientation: -0.1438
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0738
   Episode_Reward/foot_landing_vel: -0.0576
   Episode_Reward/test_gait_reward: -0.3265
Metrics/base_velocity/error_vel_xy: 1.1206
Metrics/base_velocity/error_vel_yaw: 0.3145
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 1.14s
                        Total time: 515.24s
                               ETA: 2746.9s

################################################################################
                     [1m Learning iteration 474/3000 [0m                      

                       Computation: 90355 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 1.2023
                    Surrogate loss: -0.0017
             Mean action noise std: 0.6222
                     Learning rate: 0.0013
                       Mean reward: 27.80
               Mean episode length: 454.43
       Episode_Reward/keep_balance: 0.4106
     Episode_Reward/rew_lin_vel_xy: 0.8950
      Episode_Reward/rew_ang_vel_z: 1.2434
    Episode_Reward/pen_base_height: -0.2412
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.0533
   Episode_Reward/pen_joint_torque: -0.0789
    Episode_Reward/pen_joint_accel: -0.0472
    Episode_Reward/pen_action_rate: -0.0233
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0252
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0478
Episode_Reward/pen_flat_orientation: -0.1637
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0888
   Episode_Reward/foot_landing_vel: -0.0686
   Episode_Reward/test_gait_reward: -0.3776
Metrics/base_velocity/error_vel_xy: 1.3461
Metrics/base_velocity/error_vel_yaw: 0.3662
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 10.3333
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 1.09s
                        Total time: 516.33s
                               ETA: 2745.8s

################################################################################
                     [1m Learning iteration 475/3000 [0m                      

                       Computation: 89932 steps/s (collection: 0.972s, learning 0.121s)
               Value function loss: 0.8705
                    Surrogate loss: -0.0006
             Mean action noise std: 0.6237
                     Learning rate: 0.0009
                       Mean reward: 23.08
               Mean episode length: 365.05
       Episode_Reward/keep_balance: 0.3934
     Episode_Reward/rew_lin_vel_xy: 0.9331
      Episode_Reward/rew_ang_vel_z: 1.1699
    Episode_Reward/pen_base_height: -0.2285
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.0535
   Episode_Reward/pen_joint_torque: -0.0749
    Episode_Reward/pen_joint_accel: -0.0446
    Episode_Reward/pen_action_rate: -0.0228
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0245
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0465
Episode_Reward/pen_flat_orientation: -0.1676
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0902
   Episode_Reward/foot_landing_vel: -0.0696
   Episode_Reward/test_gait_reward: -0.3640
Metrics/base_velocity/error_vel_xy: 1.2295
Metrics/base_velocity/error_vel_yaw: 0.3659
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 1.09s
                        Total time: 517.43s
                               ETA: 2744.7s

################################################################################
                     [1m Learning iteration 476/3000 [0m                      

                       Computation: 90831 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.9199
                    Surrogate loss: 0.0024
             Mean action noise std: 0.6237
                     Learning rate: 0.0002
                       Mean reward: 24.55
               Mean episode length: 390.97
       Episode_Reward/keep_balance: 0.3621
     Episode_Reward/rew_lin_vel_xy: 0.8102
      Episode_Reward/rew_ang_vel_z: 1.0756
    Episode_Reward/pen_base_height: -0.2225
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.0511
   Episode_Reward/pen_joint_torque: -0.0671
    Episode_Reward/pen_joint_accel: -0.0407
    Episode_Reward/pen_action_rate: -0.0207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0221
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0425
Episode_Reward/pen_flat_orientation: -0.1569
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0807
   Episode_Reward/foot_landing_vel: -0.0621
   Episode_Reward/test_gait_reward: -0.3341
Metrics/base_velocity/error_vel_xy: 1.1770
Metrics/base_velocity/error_vel_yaw: 0.3378
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 1.08s
                        Total time: 518.51s
                               ETA: 2743.6s

################################################################################
                     [1m Learning iteration 477/3000 [0m                      

                       Computation: 90975 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.8865
                    Surrogate loss: -0.0003
             Mean action noise std: 0.6240
                     Learning rate: 0.0002
                       Mean reward: 20.09
               Mean episode length: 347.97
       Episode_Reward/keep_balance: 0.3689
     Episode_Reward/rew_lin_vel_xy: 0.8085
      Episode_Reward/rew_ang_vel_z: 1.1067
    Episode_Reward/pen_base_height: -0.2231
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.0518
   Episode_Reward/pen_joint_torque: -0.0709
    Episode_Reward/pen_joint_accel: -0.0416
    Episode_Reward/pen_action_rate: -0.0212
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0152
   Episode_Reward/pen_joint_powers: -0.0234
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0433
Episode_Reward/pen_flat_orientation: -0.1582
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0870
   Episode_Reward/foot_landing_vel: -0.0679
   Episode_Reward/test_gait_reward: -0.3411
Metrics/base_velocity/error_vel_xy: 1.2196
Metrics/base_velocity/error_vel_yaw: 0.3380
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 8.5000
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 1.08s
                        Total time: 519.59s
                               ETA: 2742.5s

################################################################################
                     [1m Learning iteration 478/3000 [0m                      

                       Computation: 89637 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 0.8695
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6252
                     Learning rate: 0.0003
                       Mean reward: 22.96
               Mean episode length: 351.39
       Episode_Reward/keep_balance: 0.3668
     Episode_Reward/rew_lin_vel_xy: 0.8971
      Episode_Reward/rew_ang_vel_z: 1.0872
    Episode_Reward/pen_base_height: -0.2268
      Episode_Reward/pen_lin_vel_z: -0.0347
     Episode_Reward/pen_ang_vel_xy: -0.0503
   Episode_Reward/pen_joint_torque: -0.0680
    Episode_Reward/pen_joint_accel: -0.0389
    Episode_Reward/pen_action_rate: -0.0211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0146
   Episode_Reward/pen_joint_powers: -0.0224
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0431
Episode_Reward/pen_flat_orientation: -0.1455
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0837
   Episode_Reward/foot_landing_vel: -0.0635
   Episode_Reward/test_gait_reward: -0.3380
Metrics/base_velocity/error_vel_xy: 1.1334
Metrics/base_velocity/error_vel_yaw: 0.3431
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 8.0000
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 1.10s
                        Total time: 520.69s
                               ETA: 2741.5s

################################################################################
                     [1m Learning iteration 479/3000 [0m                      

                       Computation: 90103 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.8744
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6264
                     Learning rate: 0.0006
                       Mean reward: 23.56
               Mean episode length: 352.06
       Episode_Reward/keep_balance: 0.3622
     Episode_Reward/rew_lin_vel_xy: 0.9008
      Episode_Reward/rew_ang_vel_z: 1.0893
    Episode_Reward/pen_base_height: -0.2258
      Episode_Reward/pen_lin_vel_z: -0.0343
     Episode_Reward/pen_ang_vel_xy: -0.0493
   Episode_Reward/pen_joint_torque: -0.0685
    Episode_Reward/pen_joint_accel: -0.0372
    Episode_Reward/pen_action_rate: -0.0205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0220
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0421
Episode_Reward/pen_flat_orientation: -0.1445
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0788
   Episode_Reward/foot_landing_vel: -0.0592
   Episode_Reward/test_gait_reward: -0.3341
Metrics/base_velocity/error_vel_xy: 1.1054
Metrics/base_velocity/error_vel_yaw: 0.3286
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 1.09s
                        Total time: 521.78s
                               ETA: 2740.4s

################################################################################
                     [1m Learning iteration 480/3000 [0m                      

                       Computation: 90226 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.8962
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6262
                     Learning rate: 0.0009
                       Mean reward: 29.75
               Mean episode length: 447.88
       Episode_Reward/keep_balance: 0.4239
     Episode_Reward/rew_lin_vel_xy: 0.9864
      Episode_Reward/rew_ang_vel_z: 1.2574
    Episode_Reward/pen_base_height: -0.2421
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.0559
   Episode_Reward/pen_joint_torque: -0.0809
    Episode_Reward/pen_joint_accel: -0.0494
    Episode_Reward/pen_action_rate: -0.0248
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0170
   Episode_Reward/pen_joint_powers: -0.0263
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0508
Episode_Reward/pen_flat_orientation: -0.1596
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0990
   Episode_Reward/foot_landing_vel: -0.0719
   Episode_Reward/test_gait_reward: -0.3925
Metrics/base_velocity/error_vel_xy: 1.3637
Metrics/base_velocity/error_vel_yaw: 0.3979
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 1.09s
                        Total time: 522.87s
                               ETA: 2739.3s

################################################################################
                     [1m Learning iteration 481/3000 [0m                      

                       Computation: 90494 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.9323
                    Surrogate loss: -0.0016
             Mean action noise std: 0.6263
                     Learning rate: 0.0009
                       Mean reward: 23.24
               Mean episode length: 390.87
       Episode_Reward/keep_balance: 0.4264
     Episode_Reward/rew_lin_vel_xy: 0.9638
      Episode_Reward/rew_ang_vel_z: 1.2635
    Episode_Reward/pen_base_height: -0.2331
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.0574
   Episode_Reward/pen_joint_torque: -0.0802
    Episode_Reward/pen_joint_accel: -0.0489
    Episode_Reward/pen_action_rate: -0.0254
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0176
   Episode_Reward/pen_joint_powers: -0.0267
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0516
Episode_Reward/pen_flat_orientation: -0.1668
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.1004
   Episode_Reward/foot_landing_vel: -0.0790
   Episode_Reward/test_gait_reward: -0.3925
Metrics/base_velocity/error_vel_xy: 1.4044
Metrics/base_velocity/error_vel_yaw: 0.3990
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 1.09s
                        Total time: 523.95s
                               ETA: 2738.2s

################################################################################
                     [1m Learning iteration 482/3000 [0m                      

                       Computation: 90706 steps/s (collection: 0.957s, learning 0.126s)
               Value function loss: 1.0612
                    Surrogate loss: -0.0038
             Mean action noise std: 0.6271
                     Learning rate: 0.0019
                       Mean reward: 22.16
               Mean episode length: 350.74
       Episode_Reward/keep_balance: 0.3568
     Episode_Reward/rew_lin_vel_xy: 0.7955
      Episode_Reward/rew_ang_vel_z: 1.0703
    Episode_Reward/pen_base_height: -0.2209
      Episode_Reward/pen_lin_vel_z: -0.0334
     Episode_Reward/pen_ang_vel_xy: -0.0479
   Episode_Reward/pen_joint_torque: -0.0670
    Episode_Reward/pen_joint_accel: -0.0359
    Episode_Reward/pen_action_rate: -0.0204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0136
   Episode_Reward/pen_joint_powers: -0.0216
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0419
Episode_Reward/pen_flat_orientation: -0.1371
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0768
   Episode_Reward/foot_landing_vel: -0.0617
   Episode_Reward/test_gait_reward: -0.3280
Metrics/base_velocity/error_vel_xy: 1.1677
Metrics/base_velocity/error_vel_yaw: 0.3255
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 1.08s
                        Total time: 525.04s
                               ETA: 2737.1s

################################################################################
                     [1m Learning iteration 483/3000 [0m                      

                       Computation: 86685 steps/s (collection: 1.013s, learning 0.121s)
               Value function loss: 1.2005
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6293
                     Learning rate: 0.0009
                       Mean reward: 30.37
               Mean episode length: 415.83
       Episode_Reward/keep_balance: 0.3865
     Episode_Reward/rew_lin_vel_xy: 0.9896
      Episode_Reward/rew_ang_vel_z: 1.1612
    Episode_Reward/pen_base_height: -0.2282
      Episode_Reward/pen_lin_vel_z: -0.0348
     Episode_Reward/pen_ang_vel_xy: -0.0510
   Episode_Reward/pen_joint_torque: -0.0721
    Episode_Reward/pen_joint_accel: -0.0398
    Episode_Reward/pen_action_rate: -0.0223
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0146
   Episode_Reward/pen_joint_powers: -0.0232
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0458
Episode_Reward/pen_flat_orientation: -0.1469
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0828
   Episode_Reward/foot_landing_vel: -0.0644
   Episode_Reward/test_gait_reward: -0.3565
Metrics/base_velocity/error_vel_xy: 1.1439
Metrics/base_velocity/error_vel_yaw: 0.3513
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 1.13s
                        Total time: 526.17s
                               ETA: 2736.3s

################################################################################
                     [1m Learning iteration 484/3000 [0m                      

                       Computation: 89727 steps/s (collection: 0.970s, learning 0.126s)
               Value function loss: 0.8658
                    Surrogate loss: -0.0003
             Mean action noise std: 0.6307
                     Learning rate: 0.0009
                       Mean reward: 25.47
               Mean episode length: 390.17
       Episode_Reward/keep_balance: 0.3553
     Episode_Reward/rew_lin_vel_xy: 0.8562
      Episode_Reward/rew_ang_vel_z: 1.0593
    Episode_Reward/pen_base_height: -0.2240
      Episode_Reward/pen_lin_vel_z: -0.0344
     Episode_Reward/pen_ang_vel_xy: -0.0496
   Episode_Reward/pen_joint_torque: -0.0678
    Episode_Reward/pen_joint_accel: -0.0407
    Episode_Reward/pen_action_rate: -0.0208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0146
   Episode_Reward/pen_joint_powers: -0.0225
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0427
Episode_Reward/pen_flat_orientation: -0.1498
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0822
   Episode_Reward/foot_landing_vel: -0.0646
   Episode_Reward/test_gait_reward: -0.3315
Metrics/base_velocity/error_vel_xy: 1.1240
Metrics/base_velocity/error_vel_yaw: 0.3279
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 1.10s
                        Total time: 527.27s
                               ETA: 2735.3s

################################################################################
                     [1m Learning iteration 485/3000 [0m                      

                       Computation: 90152 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.9857
                    Surrogate loss: 0.0020
             Mean action noise std: 0.6316
                     Learning rate: 0.0003
                       Mean reward: 24.29
               Mean episode length: 386.49
       Episode_Reward/keep_balance: 0.3977
     Episode_Reward/rew_lin_vel_xy: 0.9308
      Episode_Reward/rew_ang_vel_z: 1.1804
    Episode_Reward/pen_base_height: -0.2391
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.0542
   Episode_Reward/pen_joint_torque: -0.0749
    Episode_Reward/pen_joint_accel: -0.0421
    Episode_Reward/pen_action_rate: -0.0232
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0162
   Episode_Reward/pen_joint_powers: -0.0248
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0476
Episode_Reward/pen_flat_orientation: -0.1607
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0926
   Episode_Reward/foot_landing_vel: -0.0695
   Episode_Reward/test_gait_reward: -0.3671
Metrics/base_velocity/error_vel_xy: 1.2561
Metrics/base_velocity/error_vel_yaw: 0.3711
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 9.2500
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 1.09s
                        Total time: 528.36s
                               ETA: 2734.2s

################################################################################
                     [1m Learning iteration 486/3000 [0m                      

                       Computation: 89826 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.8684
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6318
                     Learning rate: 0.0006
                       Mean reward: 21.87
               Mean episode length: 352.71
       Episode_Reward/keep_balance: 0.3763
     Episode_Reward/rew_lin_vel_xy: 0.8943
      Episode_Reward/rew_ang_vel_z: 1.1237
    Episode_Reward/pen_base_height: -0.2286
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.0522
   Episode_Reward/pen_joint_torque: -0.0708
    Episode_Reward/pen_joint_accel: -0.0381
    Episode_Reward/pen_action_rate: -0.0218
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0231
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0448
Episode_Reward/pen_flat_orientation: -0.1480
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0833
   Episode_Reward/foot_landing_vel: -0.0633
   Episode_Reward/test_gait_reward: -0.3448
Metrics/base_velocity/error_vel_xy: 1.1799
Metrics/base_velocity/error_vel_yaw: 0.3486
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 1.09s
                        Total time: 529.45s
                               ETA: 2733.1s

################################################################################
                     [1m Learning iteration 487/3000 [0m                      

                       Computation: 90777 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.9013
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6314
                     Learning rate: 0.0004
                       Mean reward: 22.89
               Mean episode length: 350.22
       Episode_Reward/keep_balance: 0.3573
     Episode_Reward/rew_lin_vel_xy: 0.8401
      Episode_Reward/rew_ang_vel_z: 1.0734
    Episode_Reward/pen_base_height: -0.2172
      Episode_Reward/pen_lin_vel_z: -0.0333
     Episode_Reward/pen_ang_vel_xy: -0.0487
   Episode_Reward/pen_joint_torque: -0.0684
    Episode_Reward/pen_joint_accel: -0.0392
    Episode_Reward/pen_action_rate: -0.0208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0140
   Episode_Reward/pen_joint_powers: -0.0221
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0429
Episode_Reward/pen_flat_orientation: -0.1385
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0801
   Episode_Reward/foot_landing_vel: -0.0598
   Episode_Reward/test_gait_reward: -0.3311
Metrics/base_velocity/error_vel_xy: 1.1220
Metrics/base_velocity/error_vel_yaw: 0.3259
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 1.08s
                        Total time: 530.53s
                               ETA: 2732.0s

################################################################################
                     [1m Learning iteration 488/3000 [0m                      

                       Computation: 91202 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.8290
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6305
                     Learning rate: 0.0009
                       Mean reward: 23.88
               Mean episode length: 371.10
       Episode_Reward/keep_balance: 0.3854
     Episode_Reward/rew_lin_vel_xy: 0.8872
      Episode_Reward/rew_ang_vel_z: 1.1575
    Episode_Reward/pen_base_height: -0.2269
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.0530
   Episode_Reward/pen_joint_torque: -0.0747
    Episode_Reward/pen_joint_accel: -0.0436
    Episode_Reward/pen_action_rate: -0.0227
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0156
   Episode_Reward/pen_joint_powers: -0.0243
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0460
Episode_Reward/pen_flat_orientation: -0.1521
  Episode_Reward/pen_feet_distance: -0.0004
Episode_Reward/pen_feet_regulation: -0.0895
   Episode_Reward/foot_landing_vel: -0.0697
   Episode_Reward/test_gait_reward: -0.3566
Metrics/base_velocity/error_vel_xy: 1.2302
Metrics/base_velocity/error_vel_yaw: 0.3501
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 8.3750
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 1.08s
                        Total time: 531.61s
                               ETA: 2730.9s

################################################################################
                     [1m Learning iteration 489/3000 [0m                      

                       Computation: 90146 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.8105
                    Surrogate loss: 0.0003
             Mean action noise std: 0.6307
                     Learning rate: 0.0004
                       Mean reward: 25.74
               Mean episode length: 388.65
       Episode_Reward/keep_balance: 0.3461
     Episode_Reward/rew_lin_vel_xy: 0.8154
      Episode_Reward/rew_ang_vel_z: 1.0364
    Episode_Reward/pen_base_height: -0.2194
      Episode_Reward/pen_lin_vel_z: -0.0309
     Episode_Reward/pen_ang_vel_xy: -0.0485
   Episode_Reward/pen_joint_torque: -0.0632
    Episode_Reward/pen_joint_accel: -0.0372
    Episode_Reward/pen_action_rate: -0.0200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0133
   Episode_Reward/pen_joint_powers: -0.0206
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0416
Episode_Reward/pen_flat_orientation: -0.1333
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0745
   Episode_Reward/foot_landing_vel: -0.0586
   Episode_Reward/test_gait_reward: -0.3188
Metrics/base_velocity/error_vel_xy: 1.0985
Metrics/base_velocity/error_vel_yaw: 0.3165
      Episode_Termination/time_out: 0.8750
  Episode_Termination/base_contact: 9.7500
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 1.09s
                        Total time: 532.70s
                               ETA: 2729.8s

################################################################################
                     [1m Learning iteration 490/3000 [0m                      

                       Computation: 90628 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 0.8206
                    Surrogate loss: -0.0006
             Mean action noise std: 0.6311
                     Learning rate: 0.0009
                       Mean reward: 21.35
               Mean episode length: 362.16
       Episode_Reward/keep_balance: 0.3807
     Episode_Reward/rew_lin_vel_xy: 0.8392
      Episode_Reward/rew_ang_vel_z: 1.1291
    Episode_Reward/pen_base_height: -0.2287
      Episode_Reward/pen_lin_vel_z: -0.0353
     Episode_Reward/pen_ang_vel_xy: -0.0514
   Episode_Reward/pen_joint_torque: -0.0711
    Episode_Reward/pen_joint_accel: -0.0405
    Episode_Reward/pen_action_rate: -0.0222
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0149
   Episode_Reward/pen_joint_powers: -0.0231
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0460
Episode_Reward/pen_flat_orientation: -0.1441
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0854
   Episode_Reward/foot_landing_vel: -0.0642
   Episode_Reward/test_gait_reward: -0.3503
Metrics/base_velocity/error_vel_xy: 1.2521
Metrics/base_velocity/error_vel_yaw: 0.3566
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 1.08s
                        Total time: 533.79s
                               ETA: 2728.7s

################################################################################
                     [1m Learning iteration 491/3000 [0m                      

                       Computation: 90073 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.8186
                    Surrogate loss: 0.0022
             Mean action noise std: 0.6318
                     Learning rate: 0.0002
                       Mean reward: 26.51
               Mean episode length: 389.01
       Episode_Reward/keep_balance: 0.4073
     Episode_Reward/rew_lin_vel_xy: 1.0115
      Episode_Reward/rew_ang_vel_z: 1.2332
    Episode_Reward/pen_base_height: -0.2312
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.0543
   Episode_Reward/pen_joint_torque: -0.0763
    Episode_Reward/pen_joint_accel: -0.0435
    Episode_Reward/pen_action_rate: -0.0240
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0162
   Episode_Reward/pen_joint_powers: -0.0252
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0490
Episode_Reward/pen_flat_orientation: -0.1479
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.0912
   Episode_Reward/foot_landing_vel: -0.0705
   Episode_Reward/test_gait_reward: -0.3739
Metrics/base_velocity/error_vel_xy: 1.2810
Metrics/base_velocity/error_vel_yaw: 0.3633
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 1.09s
                        Total time: 534.88s
                               ETA: 2727.7s

################################################################################
                     [1m Learning iteration 492/3000 [0m                      

                       Computation: 91890 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 0.8194
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6329
                     Learning rate: 0.0004
                       Mean reward: 25.14
               Mean episode length: 387.39
       Episode_Reward/keep_balance: 0.4203
     Episode_Reward/rew_lin_vel_xy: 0.9616
      Episode_Reward/rew_ang_vel_z: 1.2399
    Episode_Reward/pen_base_height: -0.2404
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.0571
   Episode_Reward/pen_joint_torque: -0.0834
    Episode_Reward/pen_joint_accel: -0.0462
    Episode_Reward/pen_action_rate: -0.0251
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0174
   Episode_Reward/pen_joint_powers: -0.0271
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0511
Episode_Reward/pen_flat_orientation: -0.1556
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1005
   Episode_Reward/foot_landing_vel: -0.0731
   Episode_Reward/test_gait_reward: -0.3877
Metrics/base_velocity/error_vel_xy: 1.3881
Metrics/base_velocity/error_vel_yaw: 0.3971
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 1.07s
                        Total time: 535.95s
                               ETA: 2726.5s

################################################################################
                     [1m Learning iteration 493/3000 [0m                      

                       Computation: 91626 steps/s (collection: 0.952s, learning 0.121s)
               Value function loss: 0.8534
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6347
                     Learning rate: 0.0009
                       Mean reward: 25.91
               Mean episode length: 394.11
       Episode_Reward/keep_balance: 0.3928
     Episode_Reward/rew_lin_vel_xy: 0.9020
      Episode_Reward/rew_ang_vel_z: 1.1685
    Episode_Reward/pen_base_height: -0.2326
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.0547
   Episode_Reward/pen_joint_torque: -0.0783
    Episode_Reward/pen_joint_accel: -0.0456
    Episode_Reward/pen_action_rate: -0.0234
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0164
   Episode_Reward/pen_joint_powers: -0.0254
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0477
Episode_Reward/pen_flat_orientation: -0.1521
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0921
   Episode_Reward/foot_landing_vel: -0.0728
   Episode_Reward/test_gait_reward: -0.3643
Metrics/base_velocity/error_vel_xy: 1.2556
Metrics/base_velocity/error_vel_yaw: 0.3670
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 1.07s
                        Total time: 537.02s
                               ETA: 2725.3s

################################################################################
                     [1m Learning iteration 494/3000 [0m                      

                       Computation: 92044 steps/s (collection: 0.944s, learning 0.124s)
               Value function loss: 1.0434
                    Surrogate loss: 0.0036
             Mean action noise std: 0.6365
                     Learning rate: 0.0003
                       Mean reward: 32.60
               Mean episode length: 481.95
       Episode_Reward/keep_balance: 0.4307
     Episode_Reward/rew_lin_vel_xy: 1.0901
      Episode_Reward/rew_ang_vel_z: 1.2870
    Episode_Reward/pen_base_height: -0.2446
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.0589
   Episode_Reward/pen_joint_torque: -0.0838
    Episode_Reward/pen_joint_accel: -0.0482
    Episode_Reward/pen_action_rate: -0.0258
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0182
   Episode_Reward/pen_joint_powers: -0.0278
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0523
Episode_Reward/pen_flat_orientation: -0.1700
  Episode_Reward/pen_feet_distance: -0.0003
Episode_Reward/pen_feet_regulation: -0.1079
   Episode_Reward/foot_landing_vel: -0.0787
   Episode_Reward/test_gait_reward: -0.4013
Metrics/base_velocity/error_vel_xy: 1.3036
Metrics/base_velocity/error_vel_yaw: 0.3966
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 1.07s
                        Total time: 538.09s
                               ETA: 2724.1s

################################################################################
                     [1m Learning iteration 495/3000 [0m                      

                       Computation: 90122 steps/s (collection: 0.964s, learning 0.127s)
               Value function loss: 0.8825
                    Surrogate loss: 0.0115
             Mean action noise std: 0.6368
                     Learning rate: 0.0000
                       Mean reward: 25.01
               Mean episode length: 404.67
       Episode_Reward/keep_balance: 0.3969
     Episode_Reward/rew_lin_vel_xy: 0.9458
      Episode_Reward/rew_ang_vel_z: 1.1796
    Episode_Reward/pen_base_height: -0.2363
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.0530
   Episode_Reward/pen_joint_torque: -0.0744
    Episode_Reward/pen_joint_accel: -0.0461
    Episode_Reward/pen_action_rate: -0.0237
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0160
   Episode_Reward/pen_joint_powers: -0.0245
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0489
Episode_Reward/pen_flat_orientation: -0.1474
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0929
   Episode_Reward/foot_landing_vel: -0.0704
   Episode_Reward/test_gait_reward: -0.3688
Metrics/base_velocity/error_vel_xy: 1.2364
Metrics/base_velocity/error_vel_yaw: 0.3711
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 1.09s
                        Total time: 539.18s
                               ETA: 2723.1s

################################################################################
                     [1m Learning iteration 496/3000 [0m                      

                       Computation: 90394 steps/s (collection: 0.961s, learning 0.126s)
               Value function loss: 0.9476
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6377
                     Learning rate: 0.0003
                       Mean reward: 24.16
               Mean episode length: 368.39
       Episode_Reward/keep_balance: 0.3876
     Episode_Reward/rew_lin_vel_xy: 0.9141
      Episode_Reward/rew_ang_vel_z: 1.1477
    Episode_Reward/pen_base_height: -0.2321
      Episode_Reward/pen_lin_vel_z: -0.0353
     Episode_Reward/pen_ang_vel_xy: -0.0532
   Episode_Reward/pen_joint_torque: -0.0728
    Episode_Reward/pen_joint_accel: -0.0389
    Episode_Reward/pen_action_rate: -0.0229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0151
   Episode_Reward/pen_joint_powers: -0.0238
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0479
Episode_Reward/pen_flat_orientation: -0.1441
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0875
   Episode_Reward/foot_landing_vel: -0.0669
   Episode_Reward/test_gait_reward: -0.3580
Metrics/base_velocity/error_vel_xy: 1.2351
Metrics/base_velocity/error_vel_yaw: 0.3652
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 1.09s
                        Total time: 540.27s
                               ETA: 2722.0s

################################################################################
                     [1m Learning iteration 497/3000 [0m                      

                       Computation: 90798 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.8952
                    Surrogate loss: -0.0029
             Mean action noise std: 0.6375
                     Learning rate: 0.0006
                       Mean reward: 22.56
               Mean episode length: 350.82
       Episode_Reward/keep_balance: 0.3503
     Episode_Reward/rew_lin_vel_xy: 0.8251
      Episode_Reward/rew_ang_vel_z: 1.0393
    Episode_Reward/pen_base_height: -0.2270
      Episode_Reward/pen_lin_vel_z: -0.0318
     Episode_Reward/pen_ang_vel_xy: -0.0492
   Episode_Reward/pen_joint_torque: -0.0649
    Episode_Reward/pen_joint_accel: -0.0369
    Episode_Reward/pen_action_rate: -0.0205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0211
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0431
Episode_Reward/pen_flat_orientation: -0.1325
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.0767
   Episode_Reward/foot_landing_vel: -0.0559
   Episode_Reward/test_gait_reward: -0.3237
Metrics/base_velocity/error_vel_xy: 1.1198
Metrics/base_velocity/error_vel_yaw: 0.3270
      Episode_Termination/time_out: 0.8333
  Episode_Termination/base_contact: 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 1.08s
                        Total time: 541.35s
                               ETA: 2720.9s

################################################################################
                     [1m Learning iteration 498/3000 [0m                      

                       Computation: 90261 steps/s (collection: 0.961s, learning 0.128s)
               Value function loss: 1.0963
                    Surrogate loss: -0.0034
             Mean action noise std: 0.6379
                     Learning rate: 0.0013
                       Mean reward: 25.64
               Mean episode length: 390.39
       Episode_Reward/keep_balance: 0.3574
     Episode_Reward/rew_lin_vel_xy: 0.9098
      Episode_Reward/rew_ang_vel_z: 1.0630
    Episode_Reward/pen_base_height: -0.2301
      Episode_Reward/pen_lin_vel_z: -0.0335
     Episode_Reward/pen_ang_vel_xy: -0.0494
   Episode_Reward/pen_joint_torque: -0.0683
    Episode_Reward/pen_joint_accel: -0.0377
    Episode_Reward/pen_action_rate: -0.0208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0138
   Episode_Reward/pen_joint_powers: -0.0222
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0433
Episode_Reward/pen_flat_orientation: -0.1324
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0789
   Episode_Reward/foot_landing_vel: -0.0588
   Episode_Reward/test_gait_reward: -0.3299
Metrics/base_velocity/error_vel_xy: 1.0745
Metrics/base_velocity/error_vel_yaw: 0.3319
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 1.09s
                        Total time: 542.44s
                               ETA: 2719.8s

################################################################################
                     [1m Learning iteration 499/3000 [0m                      

                       Computation: 90204 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 1.5414
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6400
                     Learning rate: 0.0029
                       Mean reward: 27.85
               Mean episode length: 397.52
       Episode_Reward/keep_balance: 0.3931
     Episode_Reward/rew_lin_vel_xy: 0.9764
      Episode_Reward/rew_ang_vel_z: 1.1781
    Episode_Reward/pen_base_height: -0.2285
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.0528
   Episode_Reward/pen_joint_torque: -0.0727
    Episode_Reward/pen_joint_accel: -0.0421
    Episode_Reward/pen_action_rate: -0.0232
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0151
   Episode_Reward/pen_joint_powers: -0.0238
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0481
Episode_Reward/pen_flat_orientation: -0.1415
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0862
   Episode_Reward/foot_landing_vel: -0.0659
   Episode_Reward/test_gait_reward: -0.3620
Metrics/base_velocity/error_vel_xy: 1.2430
Metrics/base_velocity/error_vel_yaw: 0.3588
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 1.09s
                        Total time: 543.53s
                               ETA: 2718.7s

################################################################################
                     [1m Learning iteration 500/3000 [0m                      

                       Computation: 91105 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 1.1013
                    Surrogate loss: 0.0040
             Mean action noise std: 0.6409
                     Learning rate: 0.0003
                       Mean reward: 25.93
               Mean episode length: 402.80
       Episode_Reward/keep_balance: 0.3563
     Episode_Reward/rew_lin_vel_xy: 0.8436
      Episode_Reward/rew_ang_vel_z: 1.0600
    Episode_Reward/pen_base_height: -0.2248
      Episode_Reward/pen_lin_vel_z: -0.0339
     Episode_Reward/pen_ang_vel_xy: -0.0495
   Episode_Reward/pen_joint_torque: -0.0673
    Episode_Reward/pen_joint_accel: -0.0388
    Episode_Reward/pen_action_rate: -0.0212
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0142
   Episode_Reward/pen_joint_powers: -0.0221
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0439
Episode_Reward/pen_flat_orientation: -0.1325
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0808
   Episode_Reward/foot_landing_vel: -0.0624
   Episode_Reward/test_gait_reward: -0.3325
Metrics/base_velocity/error_vel_xy: 1.1263
Metrics/base_velocity/error_vel_yaw: 0.3314
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 1.08s
                        Total time: 544.61s
                               ETA: 2717.6s

################################################################################
                     [1m Learning iteration 501/3000 [0m                      

                       Computation: 91793 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.9934
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6408
                     Learning rate: 0.0006
                       Mean reward: 22.69
               Mean episode length: 344.19
       Episode_Reward/keep_balance: 0.3545
     Episode_Reward/rew_lin_vel_xy: 0.8326
      Episode_Reward/rew_ang_vel_z: 1.0527
    Episode_Reward/pen_base_height: -0.2202
      Episode_Reward/pen_lin_vel_z: -0.0326
     Episode_Reward/pen_ang_vel_xy: -0.0491
   Episode_Reward/pen_joint_torque: -0.0656
    Episode_Reward/pen_joint_accel: -0.0388
    Episode_Reward/pen_action_rate: -0.0209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0214
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0437
Episode_Reward/pen_flat_orientation: -0.1340
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0767
   Episode_Reward/foot_landing_vel: -0.0601
   Episode_Reward/test_gait_reward: -0.3274
Metrics/base_velocity/error_vel_xy: 1.1436
Metrics/base_velocity/error_vel_yaw: 0.3303
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 1.07s
                        Total time: 545.68s
                               ETA: 2716.4s

################################################################################
                     [1m Learning iteration 502/3000 [0m                      

                       Computation: 91414 steps/s (collection: 0.954s, learning 0.121s)
               Value function loss: 1.2309
                    Surrogate loss: -0.0007
             Mean action noise std: 0.6410
                     Learning rate: 0.0006
                       Mean reward: 24.88
               Mean episode length: 368.83
       Episode_Reward/keep_balance: 0.3827
     Episode_Reward/rew_lin_vel_xy: 0.9858
      Episode_Reward/rew_ang_vel_z: 1.1453
    Episode_Reward/pen_base_height: -0.2263
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.0532
   Episode_Reward/pen_joint_torque: -0.0726
    Episode_Reward/pen_joint_accel: -0.0436
    Episode_Reward/pen_action_rate: -0.0229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0150
   Episode_Reward/pen_joint_powers: -0.0237
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0474
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0841
   Episode_Reward/foot_landing_vel: -0.0639
   Episode_Reward/test_gait_reward: -0.3556
Metrics/base_velocity/error_vel_xy: 1.1858
Metrics/base_velocity/error_vel_yaw: 0.3520
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 1.08s
                        Total time: 546.75s
                               ETA: 2715.3s

################################################################################
                     [1m Learning iteration 503/3000 [0m                      

                       Computation: 90465 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 1.1526
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6418
                     Learning rate: 0.0013
                       Mean reward: 26.63
               Mean episode length: 366.37
       Episode_Reward/keep_balance: 0.3840
     Episode_Reward/rew_lin_vel_xy: 0.9770
      Episode_Reward/rew_ang_vel_z: 1.1303
    Episode_Reward/pen_base_height: -0.2296
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.0531
   Episode_Reward/pen_joint_torque: -0.0741
    Episode_Reward/pen_joint_accel: -0.0433
    Episode_Reward/pen_action_rate: -0.0232
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0157
   Episode_Reward/pen_joint_powers: -0.0243
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0482
Episode_Reward/pen_flat_orientation: -0.1435
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.0886
   Episode_Reward/foot_landing_vel: -0.0661
   Episode_Reward/test_gait_reward: -0.3583
Metrics/base_velocity/error_vel_xy: 1.1687
Metrics/base_velocity/error_vel_yaw: 0.3667
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 1.09s
                        Total time: 547.84s
                               ETA: 2714.2s

################################################################################
                     [1m Learning iteration 504/3000 [0m                      

                       Computation: 89669 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 1.3953
                    Surrogate loss: 0.0019
             Mean action noise std: 0.6426
                     Learning rate: 0.0006
                       Mean reward: 22.19
               Mean episode length: 335.55
       Episode_Reward/keep_balance: 0.3405
     Episode_Reward/rew_lin_vel_xy: 0.8520
      Episode_Reward/rew_ang_vel_z: 1.0043
    Episode_Reward/pen_base_height: -0.2133
      Episode_Reward/pen_lin_vel_z: -0.0316
     Episode_Reward/pen_ang_vel_xy: -0.0482
   Episode_Reward/pen_joint_torque: -0.0622
    Episode_Reward/pen_joint_accel: -0.0376
    Episode_Reward/pen_action_rate: -0.0205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0207
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0428
Episode_Reward/pen_flat_orientation: -0.1287
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0775
   Episode_Reward/foot_landing_vel: -0.0579
   Episode_Reward/test_gait_reward: -0.3164
Metrics/base_velocity/error_vel_xy: 1.0414
Metrics/base_velocity/error_vel_yaw: 0.3251
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 1.10s
                        Total time: 548.94s
                               ETA: 2713.2s

################################################################################
                     [1m Learning iteration 505/3000 [0m                      

                       Computation: 91402 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 1.0768
                    Surrogate loss: -0.0011
             Mean action noise std: 0.6437
                     Learning rate: 0.0013
                       Mean reward: 25.62
               Mean episode length: 382.70
       Episode_Reward/keep_balance: 0.3832
     Episode_Reward/rew_lin_vel_xy: 0.9619
      Episode_Reward/rew_ang_vel_z: 1.1468
    Episode_Reward/pen_base_height: -0.2258
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.0523
   Episode_Reward/pen_joint_torque: -0.0711
    Episode_Reward/pen_joint_accel: -0.0421
    Episode_Reward/pen_action_rate: -0.0231
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0152
   Episode_Reward/pen_joint_powers: -0.0235
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0478
Episode_Reward/pen_flat_orientation: -0.1362
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0856
   Episode_Reward/foot_landing_vel: -0.0654
   Episode_Reward/test_gait_reward: -0.3540
Metrics/base_velocity/error_vel_xy: 1.1661
Metrics/base_velocity/error_vel_yaw: 0.3506
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 10.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 1.08s
                        Total time: 550.01s
                               ETA: 2712.0s

################################################################################
                     [1m Learning iteration 506/3000 [0m                      

                       Computation: 91180 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.2421
                    Surrogate loss: 0.0013
             Mean action noise std: 0.6456
                     Learning rate: 0.0006
                       Mean reward: 23.82
               Mean episode length: 374.05
       Episode_Reward/keep_balance: 0.3820
     Episode_Reward/rew_lin_vel_xy: 0.9037
      Episode_Reward/rew_ang_vel_z: 1.1332
    Episode_Reward/pen_base_height: -0.2332
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.0528
   Episode_Reward/pen_joint_torque: -0.0730
    Episode_Reward/pen_joint_accel: -0.0401
    Episode_Reward/pen_action_rate: -0.0231
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0149
   Episode_Reward/pen_joint_powers: -0.0238
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0480
Episode_Reward/pen_flat_orientation: -0.1371
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0857
   Episode_Reward/foot_landing_vel: -0.0640
   Episode_Reward/test_gait_reward: -0.3549
Metrics/base_velocity/error_vel_xy: 1.2454
Metrics/base_velocity/error_vel_yaw: 0.3583
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 1.08s
                        Total time: 551.09s
                               ETA: 2710.9s

################################################################################
                     [1m Learning iteration 507/3000 [0m                      

                       Computation: 89697 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 1.1029
                    Surrogate loss: -0.0007
             Mean action noise std: 0.6465
                     Learning rate: 0.0004
                       Mean reward: 24.77
               Mean episode length: 368.80
       Episode_Reward/keep_balance: 0.3822
     Episode_Reward/rew_lin_vel_xy: 0.9378
      Episode_Reward/rew_ang_vel_z: 1.1340
    Episode_Reward/pen_base_height: -0.2314
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.0524
   Episode_Reward/pen_joint_torque: -0.0721
    Episode_Reward/pen_joint_accel: -0.0405
    Episode_Reward/pen_action_rate: -0.0229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0235
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0477
Episode_Reward/pen_flat_orientation: -0.1371
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0837
   Episode_Reward/foot_landing_vel: -0.0616
   Episode_Reward/test_gait_reward: -0.3539
Metrics/base_velocity/error_vel_xy: 1.1965
Metrics/base_velocity/error_vel_yaw: 0.3593
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 11.8333
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 1.10s
                        Total time: 552.19s
                               ETA: 2709.8s

################################################################################
                     [1m Learning iteration 508/3000 [0m                      

                       Computation: 89529 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 1.2543
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6466
                     Learning rate: 0.0013
                       Mean reward: 19.60
               Mean episode length: 300.31
       Episode_Reward/keep_balance: 0.3327
     Episode_Reward/rew_lin_vel_xy: 0.8275
      Episode_Reward/rew_ang_vel_z: 0.9911
    Episode_Reward/pen_base_height: -0.2087
      Episode_Reward/pen_lin_vel_z: -0.0322
     Episode_Reward/pen_ang_vel_xy: -0.0486
   Episode_Reward/pen_joint_torque: -0.0622
    Episode_Reward/pen_joint_accel: -0.0364
    Episode_Reward/pen_action_rate: -0.0201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0134
   Episode_Reward/pen_joint_powers: -0.0208
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0418
Episode_Reward/pen_flat_orientation: -0.1319
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0742
   Episode_Reward/foot_landing_vel: -0.0585
   Episode_Reward/test_gait_reward: -0.3094
Metrics/base_velocity/error_vel_xy: 1.0460
Metrics/base_velocity/error_vel_yaw: 0.3104
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 1.10s
                        Total time: 553.28s
                               ETA: 2708.8s

################################################################################
                     [1m Learning iteration 509/3000 [0m                      

                       Computation: 89531 steps/s (collection: 0.972s, learning 0.126s)
               Value function loss: 1.1689
                    Surrogate loss: 0.0006
             Mean action noise std: 0.6481
                     Learning rate: 0.0004
                       Mean reward: 26.41
               Mean episode length: 378.43
       Episode_Reward/keep_balance: 0.3973
     Episode_Reward/rew_lin_vel_xy: 0.9934
      Episode_Reward/rew_ang_vel_z: 1.1882
    Episode_Reward/pen_base_height: -0.2298
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.0558
   Episode_Reward/pen_joint_torque: -0.0779
    Episode_Reward/pen_joint_accel: -0.0468
    Episode_Reward/pen_action_rate: -0.0242
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0166
   Episode_Reward/pen_joint_powers: -0.0258
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0499
Episode_Reward/pen_flat_orientation: -0.1473
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0924
   Episode_Reward/foot_landing_vel: -0.0712
   Episode_Reward/test_gait_reward: -0.3693
Metrics/base_velocity/error_vel_xy: 1.2321
Metrics/base_velocity/error_vel_yaw: 0.3655
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 1.10s
                        Total time: 554.38s
                               ETA: 2707.8s

################################################################################
                     [1m Learning iteration 510/3000 [0m                      

                       Computation: 88633 steps/s (collection: 0.986s, learning 0.123s)
               Value function loss: 0.9849
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6492
                     Learning rate: 0.0006
                       Mean reward: 24.62
               Mean episode length: 360.24
       Episode_Reward/keep_balance: 0.3456
     Episode_Reward/rew_lin_vel_xy: 0.8755
      Episode_Reward/rew_ang_vel_z: 1.0283
    Episode_Reward/pen_base_height: -0.2163
      Episode_Reward/pen_lin_vel_z: -0.0325
     Episode_Reward/pen_ang_vel_xy: -0.0488
   Episode_Reward/pen_joint_torque: -0.0650
    Episode_Reward/pen_joint_accel: -0.0370
    Episode_Reward/pen_action_rate: -0.0208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0136
   Episode_Reward/pen_joint_powers: -0.0214
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0436
Episode_Reward/pen_flat_orientation: -0.1330
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.0764
   Episode_Reward/foot_landing_vel: -0.0581
   Episode_Reward/test_gait_reward: -0.3208
Metrics/base_velocity/error_vel_xy: 1.0560
Metrics/base_velocity/error_vel_yaw: 0.3214
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 15.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 1.11s
                        Total time: 555.49s
                               ETA: 2706.8s

################################################################################
                     [1m Learning iteration 511/3000 [0m                      

                       Computation: 90548 steps/s (collection: 0.965s, learning 0.121s)
               Value function loss: 1.1210
                    Surrogate loss: 0.0015
             Mean action noise std: 0.6501
                     Learning rate: 0.0002
                       Mean reward: 28.34
               Mean episode length: 397.57
       Episode_Reward/keep_balance: 0.3602
     Episode_Reward/rew_lin_vel_xy: 0.9734
      Episode_Reward/rew_ang_vel_z: 1.0720
    Episode_Reward/pen_base_height: -0.2213
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.0507
   Episode_Reward/pen_joint_torque: -0.0688
    Episode_Reward/pen_joint_accel: -0.0399
    Episode_Reward/pen_action_rate: -0.0220
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0230
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0458
Episode_Reward/pen_flat_orientation: -0.1382
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0857
   Episode_Reward/foot_landing_vel: -0.0626
   Episode_Reward/test_gait_reward: -0.3370
Metrics/base_velocity/error_vel_xy: 1.0512
Metrics/base_velocity/error_vel_yaw: 0.3357
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 1.09s
                        Total time: 556.58s
                               ETA: 2705.7s

################################################################################
                     [1m Learning iteration 512/3000 [0m                      

                       Computation: 90455 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.9270
                    Surrogate loss: 0.0019
             Mean action noise std: 0.6504
                     Learning rate: 0.0001
                       Mean reward: 17.99
               Mean episode length: 296.12
       Episode_Reward/keep_balance: 0.3396
     Episode_Reward/rew_lin_vel_xy: 0.8226
      Episode_Reward/rew_ang_vel_z: 1.0065
    Episode_Reward/pen_base_height: -0.2116
      Episode_Reward/pen_lin_vel_z: -0.0317
     Episode_Reward/pen_ang_vel_xy: -0.0481
   Episode_Reward/pen_joint_torque: -0.0644
    Episode_Reward/pen_joint_accel: -0.0353
    Episode_Reward/pen_action_rate: -0.0205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0133
   Episode_Reward/pen_joint_powers: -0.0212
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0428
Episode_Reward/pen_flat_orientation: -0.1249
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0737
   Episode_Reward/foot_landing_vel: -0.0567
   Episode_Reward/test_gait_reward: -0.3154
Metrics/base_velocity/error_vel_xy: 1.0897
Metrics/base_velocity/error_vel_yaw: 0.3189
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 10.8750
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 1.09s
                        Total time: 557.66s
                               ETA: 2704.6s

################################################################################
                     [1m Learning iteration 513/3000 [0m                      

                       Computation: 91095 steps/s (collection: 0.954s, learning 0.125s)
               Value function loss: 1.0388
                    Surrogate loss: 0.0079
             Mean action noise std: 0.6505
                     Learning rate: 0.0000
                       Mean reward: 23.18
               Mean episode length: 334.82
       Episode_Reward/keep_balance: 0.3137
     Episode_Reward/rew_lin_vel_xy: 0.8216
      Episode_Reward/rew_ang_vel_z: 0.9172
    Episode_Reward/pen_base_height: -0.2066
      Episode_Reward/pen_lin_vel_z: -0.0300
     Episode_Reward/pen_ang_vel_xy: -0.0466
   Episode_Reward/pen_joint_torque: -0.0564
    Episode_Reward/pen_joint_accel: -0.0318
    Episode_Reward/pen_action_rate: -0.0190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0125
   Episode_Reward/pen_joint_powers: -0.0192
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0403
Episode_Reward/pen_flat_orientation: -0.1255
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0712
   Episode_Reward/foot_landing_vel: -0.0522
   Episode_Reward/test_gait_reward: -0.2924
Metrics/base_velocity/error_vel_xy: 0.9299
Metrics/base_velocity/error_vel_yaw: 0.3057
      Episode_Termination/time_out: 1.0000
  Episode_Termination/base_contact: 11.0000
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 1.08s
                        Total time: 558.74s
                               ETA: 2703.5s

################################################################################
                     [1m Learning iteration 514/3000 [0m                      

                       Computation: 91188 steps/s (collection: 0.953s, learning 0.125s)
               Value function loss: 0.9062
                    Surrogate loss: 0.0009
             Mean action noise std: 0.6508
                     Learning rate: 0.0001
                       Mean reward: 24.19
               Mean episode length: 366.43
       Episode_Reward/keep_balance: 0.3683
     Episode_Reward/rew_lin_vel_xy: 0.9114
      Episode_Reward/rew_ang_vel_z: 1.1012
    Episode_Reward/pen_base_height: -0.2167
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.0517
   Episode_Reward/pen_joint_torque: -0.0710
    Episode_Reward/pen_joint_accel: -0.0399
    Episode_Reward/pen_action_rate: -0.0226
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0149
   Episode_Reward/pen_joint_powers: -0.0234
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0471
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0825
   Episode_Reward/foot_landing_vel: -0.0643
   Episode_Reward/test_gait_reward: -0.3436
Metrics/base_velocity/error_vel_xy: 1.1481
Metrics/base_velocity/error_vel_yaw: 0.3384
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 1.08s
                        Total time: 559.82s
                               ETA: 2702.4s

################################################################################
                     [1m Learning iteration 515/3000 [0m                      

                       Computation: 91125 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 1.0364
                    Surrogate loss: -0.0036
             Mean action noise std: 0.6517
                     Learning rate: 0.0003
                       Mean reward: 27.34
               Mean episode length: 394.33
       Episode_Reward/keep_balance: 0.3797
     Episode_Reward/rew_lin_vel_xy: 0.9544
      Episode_Reward/rew_ang_vel_z: 1.1335
    Episode_Reward/pen_base_height: -0.2221
      Episode_Reward/pen_lin_vel_z: -0.0346
     Episode_Reward/pen_ang_vel_xy: -0.0523
   Episode_Reward/pen_joint_torque: -0.0710
    Episode_Reward/pen_joint_accel: -0.0409
    Episode_Reward/pen_action_rate: -0.0233
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0146
   Episode_Reward/pen_joint_powers: -0.0232
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0486
Episode_Reward/pen_flat_orientation: -0.1323
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0822
   Episode_Reward/foot_landing_vel: -0.0632
   Episode_Reward/test_gait_reward: -0.3493
Metrics/base_velocity/error_vel_xy: 1.1977
Metrics/base_velocity/error_vel_yaw: 0.3514
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 1.08s
                        Total time: 560.90s
                               ETA: 2701.2s

################################################################################
                     [1m Learning iteration 516/3000 [0m                      

                       Computation: 91087 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 1.1520
                    Surrogate loss: 0.0001
             Mean action noise std: 0.6535
                     Learning rate: 0.0006
                       Mean reward: 25.16
               Mean episode length: 363.99
       Episode_Reward/keep_balance: 0.3681
     Episode_Reward/rew_lin_vel_xy: 0.9721
      Episode_Reward/rew_ang_vel_z: 1.0971
    Episode_Reward/pen_base_height: -0.2209
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.0525
   Episode_Reward/pen_joint_torque: -0.0721
    Episode_Reward/pen_joint_accel: -0.0397
    Episode_Reward/pen_action_rate: -0.0227
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0151
   Episode_Reward/pen_joint_powers: -0.0236
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0472
Episode_Reward/pen_flat_orientation: -0.1381
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.0854
   Episode_Reward/foot_landing_vel: -0.0673
   Episode_Reward/test_gait_reward: -0.3426
Metrics/base_velocity/error_vel_xy: 1.0928
Metrics/base_velocity/error_vel_yaw: 0.3441
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 1.08s
                        Total time: 561.98s
                               ETA: 2700.1s

################################################################################
                     [1m Learning iteration 517/3000 [0m                      

                       Computation: 91194 steps/s (collection: 0.953s, learning 0.125s)
               Value function loss: 0.9716
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6541
                     Learning rate: 0.0004
                       Mean reward: 21.68
               Mean episode length: 334.83
       Episode_Reward/keep_balance: 0.3480
     Episode_Reward/rew_lin_vel_xy: 0.8950
      Episode_Reward/rew_ang_vel_z: 1.0307
    Episode_Reward/pen_base_height: -0.2152
      Episode_Reward/pen_lin_vel_z: -0.0340
     Episode_Reward/pen_ang_vel_xy: -0.0513
   Episode_Reward/pen_joint_torque: -0.0663
    Episode_Reward/pen_joint_accel: -0.0379
    Episode_Reward/pen_action_rate: -0.0216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0223
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0449
Episode_Reward/pen_flat_orientation: -0.1351
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.0798
   Episode_Reward/foot_landing_vel: -0.0610
   Episode_Reward/test_gait_reward: -0.3234
Metrics/base_velocity/error_vel_xy: 1.0584
Metrics/base_velocity/error_vel_yaw: 0.3280
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 10.7083
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 1.08s
                        Total time: 563.06s
                               ETA: 2699.0s

################################################################################
                     [1m Learning iteration 518/3000 [0m                      

                       Computation: 90513 steps/s (collection: 0.960s, learning 0.126s)
               Value function loss: 1.0169
                    Surrogate loss: -0.0000
             Mean action noise std: 0.6552
                     Learning rate: 0.0004
                       Mean reward: 21.20
               Mean episode length: 317.73
       Episode_Reward/keep_balance: 0.3425
     Episode_Reward/rew_lin_vel_xy: 0.8616
      Episode_Reward/rew_ang_vel_z: 1.0068
    Episode_Reward/pen_base_height: -0.2136
      Episode_Reward/pen_lin_vel_z: -0.0341
     Episode_Reward/pen_ang_vel_xy: -0.0513
   Episode_Reward/pen_joint_torque: -0.0652
    Episode_Reward/pen_joint_accel: -0.0371
    Episode_Reward/pen_action_rate: -0.0213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0143
   Episode_Reward/pen_joint_powers: -0.0221
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0443
Episode_Reward/pen_flat_orientation: -0.1371
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0815
   Episode_Reward/foot_landing_vel: -0.0622
   Episode_Reward/test_gait_reward: -0.3192
Metrics/base_velocity/error_vel_xy: 1.0718
Metrics/base_velocity/error_vel_yaw: 0.3276
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 1.09s
                        Total time: 564.14s
                               ETA: 2697.9s

################################################################################
                     [1m Learning iteration 519/3000 [0m                      

                       Computation: 91044 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 1.1190
                    Surrogate loss: 0.0043
             Mean action noise std: 0.6554
                     Learning rate: 0.0001
                       Mean reward: 23.73
               Mean episode length: 361.71
       Episode_Reward/keep_balance: 0.3461
     Episode_Reward/rew_lin_vel_xy: 0.8716
      Episode_Reward/rew_ang_vel_z: 1.0269
    Episode_Reward/pen_base_height: -0.2130
      Episode_Reward/pen_lin_vel_z: -0.0333
     Episode_Reward/pen_ang_vel_xy: -0.0504
   Episode_Reward/pen_joint_torque: -0.0667
    Episode_Reward/pen_joint_accel: -0.0357
    Episode_Reward/pen_action_rate: -0.0215
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0224
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0448
Episode_Reward/pen_flat_orientation: -0.1326
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.0811
   Episode_Reward/foot_landing_vel: -0.0634
   Episode_Reward/test_gait_reward: -0.3222
Metrics/base_velocity/error_vel_xy: 1.0564
Metrics/base_velocity/error_vel_yaw: 0.3243
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 1.08s
                        Total time: 565.22s
                               ETA: 2696.8s

################################################################################
                     [1m Learning iteration 520/3000 [0m                      

                       Computation: 90529 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.9069
                    Surrogate loss: -0.0007
             Mean action noise std: 0.6558
                     Learning rate: 0.0002
                       Mean reward: 20.80
               Mean episode length: 316.50
       Episode_Reward/keep_balance: 0.3224
     Episode_Reward/rew_lin_vel_xy: 0.8753
      Episode_Reward/rew_ang_vel_z: 0.9521
    Episode_Reward/pen_base_height: -0.2061
      Episode_Reward/pen_lin_vel_z: -0.0314
     Episode_Reward/pen_ang_vel_xy: -0.0472
   Episode_Reward/pen_joint_torque: -0.0634
    Episode_Reward/pen_joint_accel: -0.0362
    Episode_Reward/pen_action_rate: -0.0199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0130
   Episode_Reward/pen_joint_powers: -0.0206
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0417
Episode_Reward/pen_flat_orientation: -0.1258
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.0738
   Episode_Reward/foot_landing_vel: -0.0563
   Episode_Reward/test_gait_reward: -0.2990
Metrics/base_velocity/error_vel_xy: 0.9515
Metrics/base_velocity/error_vel_yaw: 0.3047
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 1.09s
                        Total time: 566.31s
                               ETA: 2695.7s

################################################################################
                     [1m Learning iteration 521/3000 [0m                      

                       Computation: 89845 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.9271
                    Surrogate loss: 0.0023
             Mean action noise std: 0.6563
                     Learning rate: 0.0002
                       Mean reward: 21.96
               Mean episode length: 319.70
       Episode_Reward/keep_balance: 0.3460
     Episode_Reward/rew_lin_vel_xy: 0.9492
      Episode_Reward/rew_ang_vel_z: 1.0205
    Episode_Reward/pen_base_height: -0.2133
      Episode_Reward/pen_lin_vel_z: -0.0325
     Episode_Reward/pen_ang_vel_xy: -0.0498
   Episode_Reward/pen_joint_torque: -0.0649
    Episode_Reward/pen_joint_accel: -0.0361
    Episode_Reward/pen_action_rate: -0.0216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0139
   Episode_Reward/pen_joint_powers: -0.0215
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0456
Episode_Reward/pen_flat_orientation: -0.1264
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.0777
   Episode_Reward/foot_landing_vel: -0.0601
   Episode_Reward/test_gait_reward: -0.3204
Metrics/base_velocity/error_vel_xy: 1.0253
Metrics/base_velocity/error_vel_yaw: 0.3283
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 1.09s
                        Total time: 567.40s
                               ETA: 2694.6s

################################################################################
                     [1m Learning iteration 522/3000 [0m                      

                       Computation: 91207 steps/s (collection: 0.952s, learning 0.126s)
               Value function loss: 0.8705
                    Surrogate loss: 0.0030
             Mean action noise std: 0.6568
                     Learning rate: 0.0001
                       Mean reward: 25.02
               Mean episode length: 360.61
       Episode_Reward/keep_balance: 0.3394
     Episode_Reward/rew_lin_vel_xy: 0.8818
      Episode_Reward/rew_ang_vel_z: 0.9989
    Episode_Reward/pen_base_height: -0.2137
      Episode_Reward/pen_lin_vel_z: -0.0321
     Episode_Reward/pen_ang_vel_xy: -0.0502
   Episode_Reward/pen_joint_torque: -0.0638
    Episode_Reward/pen_joint_accel: -0.0359
    Episode_Reward/pen_action_rate: -0.0213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0138
   Episode_Reward/pen_joint_powers: -0.0214
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0450
Episode_Reward/pen_flat_orientation: -0.1267
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0764
   Episode_Reward/foot_landing_vel: -0.0600
   Episode_Reward/test_gait_reward: -0.3139
Metrics/base_velocity/error_vel_xy: 1.0681
Metrics/base_velocity/error_vel_yaw: 0.3231
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 9.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 1.08s
                        Total time: 568.48s
                               ETA: 2693.5s

################################################################################
                     [1m Learning iteration 523/3000 [0m                      

                       Computation: 91486 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.9806
                    Surrogate loss: 0.0043
             Mean action noise std: 0.6569
                     Learning rate: 0.0000
                       Mean reward: 24.96
               Mean episode length: 357.16
       Episode_Reward/keep_balance: 0.3589
     Episode_Reward/rew_lin_vel_xy: 0.9326
      Episode_Reward/rew_ang_vel_z: 1.0665
    Episode_Reward/pen_base_height: -0.2189
      Episode_Reward/pen_lin_vel_z: -0.0335
     Episode_Reward/pen_ang_vel_xy: -0.0506
   Episode_Reward/pen_joint_torque: -0.0681
    Episode_Reward/pen_joint_accel: -0.0368
    Episode_Reward/pen_action_rate: -0.0224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0142
   Episode_Reward/pen_joint_powers: -0.0224
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0469
Episode_Reward/pen_flat_orientation: -0.1286
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.0811
   Episode_Reward/foot_landing_vel: -0.0618
   Episode_Reward/test_gait_reward: -0.3308
Metrics/base_velocity/error_vel_xy: 1.1185
Metrics/base_velocity/error_vel_yaw: 0.3350
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 1.07s
                        Total time: 569.55s
                               ETA: 2692.3s

################################################################################
                     [1m Learning iteration 524/3000 [0m                      

                       Computation: 90920 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 1.0350
                    Surrogate loss: 0.0059
             Mean action noise std: 0.6569
                     Learning rate: 0.0000
                       Mean reward: 23.01
               Mean episode length: 356.83
       Episode_Reward/keep_balance: 0.3300
     Episode_Reward/rew_lin_vel_xy: 0.7873
      Episode_Reward/rew_ang_vel_z: 0.9705
    Episode_Reward/pen_base_height: -0.2119
      Episode_Reward/pen_lin_vel_z: -0.0328
     Episode_Reward/pen_ang_vel_xy: -0.0495
   Episode_Reward/pen_joint_torque: -0.0640
    Episode_Reward/pen_joint_accel: -0.0392
    Episode_Reward/pen_action_rate: -0.0208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0215
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0437
Episode_Reward/pen_flat_orientation: -0.1280
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0821
   Episode_Reward/foot_landing_vel: -0.0604
   Episode_Reward/test_gait_reward: -0.3105
Metrics/base_velocity/error_vel_xy: 1.0653
Metrics/base_velocity/error_vel_yaw: 0.3183
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 1.08s
                        Total time: 570.64s
                               ETA: 2691.2s

################################################################################
                     [1m Learning iteration 525/3000 [0m                      

                       Computation: 90798 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.9871
                    Surrogate loss: -0.0018
             Mean action noise std: 0.6568
                     Learning rate: 0.0001
                       Mean reward: 21.58
               Mean episode length: 295.98
       Episode_Reward/keep_balance: 0.3274
     Episode_Reward/rew_lin_vel_xy: 0.9280
      Episode_Reward/rew_ang_vel_z: 0.9665
    Episode_Reward/pen_base_height: -0.2101
      Episode_Reward/pen_lin_vel_z: -0.0320
     Episode_Reward/pen_ang_vel_xy: -0.0483
   Episode_Reward/pen_joint_torque: -0.0641
    Episode_Reward/pen_joint_accel: -0.0345
    Episode_Reward/pen_action_rate: -0.0206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0137
   Episode_Reward/pen_joint_powers: -0.0214
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0431
Episode_Reward/pen_flat_orientation: -0.1245
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.0813
   Episode_Reward/foot_landing_vel: -0.0573
   Episode_Reward/test_gait_reward: -0.3052
Metrics/base_velocity/error_vel_xy: 0.9346
Metrics/base_velocity/error_vel_yaw: 0.3103
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 9.0417
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 1.08s
                        Total time: 571.72s
                               ETA: 2690.1s

################################################################################
                     [1m Learning iteration 526/3000 [0m                      

                       Computation: 90766 steps/s (collection: 0.958s, learning 0.125s)
               Value function loss: 1.0146
                    Surrogate loss: -0.0010
             Mean action noise std: 0.6575
                     Learning rate: 0.0003
                       Mean reward: 28.12
               Mean episode length: 374.67
       Episode_Reward/keep_balance: 0.3593
     Episode_Reward/rew_lin_vel_xy: 0.9593
      Episode_Reward/rew_ang_vel_z: 1.0625
    Episode_Reward/pen_base_height: -0.2184
      Episode_Reward/pen_lin_vel_z: -0.0334
     Episode_Reward/pen_ang_vel_xy: -0.0511
   Episode_Reward/pen_joint_torque: -0.0677
    Episode_Reward/pen_joint_accel: -0.0392
    Episode_Reward/pen_action_rate: -0.0226
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0225
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0474
Episode_Reward/pen_flat_orientation: -0.1302
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.0791
   Episode_Reward/foot_landing_vel: -0.0609
   Episode_Reward/test_gait_reward: -0.3339
Metrics/base_velocity/error_vel_xy: 1.0976
Metrics/base_velocity/error_vel_yaw: 0.3398
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 1.08s
                        Total time: 572.80s
                               ETA: 2689.0s

################################################################################
                     [1m Learning iteration 527/3000 [0m                      

                       Computation: 91565 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 0.9491
                    Surrogate loss: 0.0032
             Mean action noise std: 0.6583
                     Learning rate: 0.0002
                       Mean reward: 22.07
               Mean episode length: 317.20
       Episode_Reward/keep_balance: 0.3541
     Episode_Reward/rew_lin_vel_xy: 0.8966
      Episode_Reward/rew_ang_vel_z: 1.0508
    Episode_Reward/pen_base_height: -0.2148
      Episode_Reward/pen_lin_vel_z: -0.0330
     Episode_Reward/pen_ang_vel_xy: -0.0523
   Episode_Reward/pen_joint_torque: -0.0676
    Episode_Reward/pen_joint_accel: -0.0408
    Episode_Reward/pen_action_rate: -0.0223
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0145
   Episode_Reward/pen_joint_powers: -0.0224
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0467
Episode_Reward/pen_flat_orientation: -0.1322
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.0811
   Episode_Reward/foot_landing_vel: -0.0607
   Episode_Reward/test_gait_reward: -0.3269
Metrics/base_velocity/error_vel_xy: 1.0913
Metrics/base_velocity/error_vel_yaw: 0.3319
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 1.07s
                        Total time: 573.88s
                               ETA: 2687.9s

################################################################################
                     [1m Learning iteration 528/3000 [0m                      

                       Computation: 89999 steps/s (collection: 0.966s, learning 0.127s)
               Value function loss: 0.9331
                    Surrogate loss: -0.0031
             Mean action noise std: 0.6586
                     Learning rate: 0.0006
                       Mean reward: 25.00
               Mean episode length: 366.12
       Episode_Reward/keep_balance: 0.3552
     Episode_Reward/rew_lin_vel_xy: 0.9137
      Episode_Reward/rew_ang_vel_z: 1.0548
    Episode_Reward/pen_base_height: -0.2126
      Episode_Reward/pen_lin_vel_z: -0.0332
     Episode_Reward/pen_ang_vel_xy: -0.0527
   Episode_Reward/pen_joint_torque: -0.0671
    Episode_Reward/pen_joint_accel: -0.0390
    Episode_Reward/pen_action_rate: -0.0225
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0145
   Episode_Reward/pen_joint_powers: -0.0225
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0471
Episode_Reward/pen_flat_orientation: -0.1326
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0814
   Episode_Reward/foot_landing_vel: -0.0629
   Episode_Reward/test_gait_reward: -0.3305
Metrics/base_velocity/error_vel_xy: 1.1079
Metrics/base_velocity/error_vel_yaw: 0.3321
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 9.6250
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 1.09s
                        Total time: 574.97s
                               ETA: 2686.8s

################################################################################
                     [1m Learning iteration 529/3000 [0m                      

                       Computation: 90305 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 1.1742
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6599
                     Learning rate: 0.0009
                       Mean reward: 27.64
               Mean episode length: 377.28
       Episode_Reward/keep_balance: 0.3755
     Episode_Reward/rew_lin_vel_xy: 1.0263
      Episode_Reward/rew_ang_vel_z: 1.1183
    Episode_Reward/pen_base_height: -0.2151
      Episode_Reward/pen_lin_vel_z: -0.0337
     Episode_Reward/pen_ang_vel_xy: -0.0529
   Episode_Reward/pen_joint_torque: -0.0704
    Episode_Reward/pen_joint_accel: -0.0425
    Episode_Reward/pen_action_rate: -0.0236
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0147
   Episode_Reward/pen_joint_powers: -0.0232
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0490
Episode_Reward/pen_flat_orientation: -0.1348
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.0837
   Episode_Reward/foot_landing_vel: -0.0616
   Episode_Reward/test_gait_reward: -0.3453
Metrics/base_velocity/error_vel_xy: 1.1376
Metrics/base_velocity/error_vel_yaw: 0.3486
      Episode_Termination/time_out: 1.2083
  Episode_Termination/base_contact: 9.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 1.09s
                        Total time: 576.06s
                               ETA: 2685.7s

################################################################################
                     [1m Learning iteration 530/3000 [0m                      

                       Computation: 89343 steps/s (collection: 0.974s, learning 0.127s)
               Value function loss: 1.1563
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6612
                     Learning rate: 0.0019
                       Mean reward: 18.80
               Mean episode length: 294.39
       Episode_Reward/keep_balance: 0.3491
     Episode_Reward/rew_lin_vel_xy: 0.9253
      Episode_Reward/rew_ang_vel_z: 1.0368
    Episode_Reward/pen_base_height: -0.2095
      Episode_Reward/pen_lin_vel_z: -0.0330
     Episode_Reward/pen_ang_vel_xy: -0.0521
   Episode_Reward/pen_joint_torque: -0.0673
    Episode_Reward/pen_joint_accel: -0.0382
    Episode_Reward/pen_action_rate: -0.0223
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0143
   Episode_Reward/pen_joint_powers: -0.0224
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0466
Episode_Reward/pen_flat_orientation: -0.1351
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0791
   Episode_Reward/foot_landing_vel: -0.0604
   Episode_Reward/test_gait_reward: -0.3259
Metrics/base_velocity/error_vel_xy: 1.0649
Metrics/base_velocity/error_vel_yaw: 0.3281
      Episode_Termination/time_out: 0.9167
  Episode_Termination/base_contact: 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 1.10s
                        Total time: 577.16s
                               ETA: 2684.7s

################################################################################
                     [1m Learning iteration 531/3000 [0m                      

                       Computation: 88436 steps/s (collection: 0.987s, learning 0.125s)
               Value function loss: 1.1501
                    Surrogate loss: 0.0009
             Mean action noise std: 0.6637
                     Learning rate: 0.0009
                       Mean reward: 28.65
               Mean episode length: 403.47
       Episode_Reward/keep_balance: 0.3534
     Episode_Reward/rew_lin_vel_xy: 0.9257
      Episode_Reward/rew_ang_vel_z: 1.0511
    Episode_Reward/pen_base_height: -0.2129
      Episode_Reward/pen_lin_vel_z: -0.0325
     Episode_Reward/pen_ang_vel_xy: -0.0519
   Episode_Reward/pen_joint_torque: -0.0653
    Episode_Reward/pen_joint_accel: -0.0401
    Episode_Reward/pen_action_rate: -0.0225
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0221
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0471
Episode_Reward/pen_flat_orientation: -0.1313
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.0806
   Episode_Reward/foot_landing_vel: -0.0606
   Episode_Reward/test_gait_reward: -0.3254
Metrics/base_velocity/error_vel_xy: 1.0826
Metrics/base_velocity/error_vel_yaw: 0.3296
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 9.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 1.11s
                        Total time: 578.27s
                               ETA: 2683.7s

################################################################################
                     [1m Learning iteration 532/3000 [0m                      

                       Computation: 89718 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 1.2228
                    Surrogate loss: -0.0004
             Mean action noise std: 0.6648
                     Learning rate: 0.0013
                       Mean reward: 22.70
               Mean episode length: 324.89
       Episode_Reward/keep_balance: 0.3262
     Episode_Reward/rew_lin_vel_xy: 0.8598
      Episode_Reward/rew_ang_vel_z: 0.9690
    Episode_Reward/pen_base_height: -0.2054
      Episode_Reward/pen_lin_vel_z: -0.0311
     Episode_Reward/pen_ang_vel_xy: -0.0494
   Episode_Reward/pen_joint_torque: -0.0625
    Episode_Reward/pen_joint_accel: -0.0347
    Episode_Reward/pen_action_rate: -0.0206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0132
   Episode_Reward/pen_joint_powers: -0.0207
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0432
Episode_Reward/pen_flat_orientation: -0.1258
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.0736
   Episode_Reward/foot_landing_vel: -0.0541
   Episode_Reward/test_gait_reward: -0.3031
Metrics/base_velocity/error_vel_xy: 0.9915
Metrics/base_velocity/error_vel_yaw: 0.3085
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 9.5833
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 1.10s
                        Total time: 579.36s
                               ETA: 2682.7s

################################################################################
                     [1m Learning iteration 533/3000 [0m                      

                       Computation: 89697 steps/s (collection: 0.967s, learning 0.129s)
               Value function loss: 1.2731
                    Surrogate loss: -0.0001
             Mean action noise std: 0.6645
                     Learning rate: 0.0009
                       Mean reward: 24.31
               Mean episode length: 384.88
       Episode_Reward/keep_balance: 0.3618
     Episode_Reward/rew_lin_vel_xy: 0.9616
      Episode_Reward/rew_ang_vel_z: 1.0684
    Episode_Reward/pen_base_height: -0.2195
      Episode_Reward/pen_lin_vel_z: -0.0330
     Episode_Reward/pen_ang_vel_xy: -0.0524
   Episode_Reward/pen_joint_torque: -0.0690
    Episode_Reward/pen_joint_accel: -0.0382
    Episode_Reward/pen_action_rate: -0.0229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0148
   Episode_Reward/pen_joint_powers: -0.0231
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0480
Episode_Reward/pen_flat_orientation: -0.1348
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.0856
   Episode_Reward/foot_landing_vel: -0.0623
   Episode_Reward/test_gait_reward: -0.3365
Metrics/base_velocity/error_vel_xy: 1.0908
Metrics/base_velocity/error_vel_yaw: 0.3433
      Episode_Termination/time_out: 0.9583
  Episode_Termination/base_contact: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 1.10s
                        Total time: 580.46s
                               ETA: 2681.6s

################################################################################
                     [1m Learning iteration 534/3000 [0m                      

                       Computation: 90432 steps/s (collection: 0.960s, learning 0.127s)
               Value function loss: 1.4296
                    Surrogate loss: -0.0002
             Mean action noise std: 0.6651
                     Learning rate: 0.0009
                       Mean reward: 27.32
               Mean episode length: 405.85
       Episode_Reward/keep_balance: 0.3912
     Episode_Reward/rew_lin_vel_xy: 0.9905
      Episode_Reward/rew_ang_vel_z: 1.1627
    Episode_Reward/pen_base_height: -0.2156
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.0574
   Episode_Reward/pen_joint_torque: -0.0767
    Episode_Reward/pen_joint_accel: -0.0423
    Episode_Reward/pen_action_rate: -0.0255
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0166
   Episode_Reward/pen_joint_powers: -0.0260
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0524
Episode_Reward/pen_flat_orientation: -0.1466
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.0942
   Episode_Reward/foot_landing_vel: -0.0711
   Episode_Reward/test_gait_reward: -0.3646
Metrics/base_velocity/error_vel_xy: 1.2189
Metrics/base_velocity/error_vel_yaw: 0.3647
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 1.09s
                        Total time: 581.55s
                               ETA: 2680.5s

################################################################################
                     [1m Learning iteration 535/3000 [0m                      

                       Computation: 90589 steps/s (collection: 0.959s, learning 0.126s)
               Value function loss: 1.2465
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6662
                     Learning rate: 0.0013
                       Mean reward: 31.12
               Mean episode length: 403.73
       Episode_Reward/keep_balance: 0.3933
     Episode_Reward/rew_lin_vel_xy: 1.0861
      Episode_Reward/rew_ang_vel_z: 1.1413
    Episode_Reward/pen_base_height: -0.2245
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.0595
   Episode_Reward/pen_joint_torque: -0.0778
    Episode_Reward/pen_joint_accel: -0.0441
    Episode_Reward/pen_action_rate: -0.0262
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0176
   Episode_Reward/pen_joint_powers: -0.0268
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0541
Episode_Reward/pen_flat_orientation: -0.1530
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1041
   Episode_Reward/foot_landing_vel: -0.0747
   Episode_Reward/test_gait_reward: -0.3683
Metrics/base_velocity/error_vel_xy: 1.1216
Metrics/base_velocity/error_vel_yaw: 0.3905
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 1.09s
                        Total time: 582.63s
                               ETA: 2679.5s

################################################################################
                     [1m Learning iteration 536/3000 [0m                      

                       Computation: 89710 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 1.1163
                    Surrogate loss: -0.0003
             Mean action noise std: 0.6673
                     Learning rate: 0.0004
                       Mean reward: 27.16
               Mean episode length: 367.06
       Episode_Reward/keep_balance: 0.3524
     Episode_Reward/rew_lin_vel_xy: 0.9488
      Episode_Reward/rew_ang_vel_z: 1.0386
    Episode_Reward/pen_base_height: -0.2079
      Episode_Reward/pen_lin_vel_z: -0.0326
     Episode_Reward/pen_ang_vel_xy: -0.0521
   Episode_Reward/pen_joint_torque: -0.0666
    Episode_Reward/pen_joint_accel: -0.0404
    Episode_Reward/pen_action_rate: -0.0228
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0144
   Episode_Reward/pen_joint_powers: -0.0222
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0478
Episode_Reward/pen_flat_orientation: -0.1349
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0806
   Episode_Reward/foot_landing_vel: -0.0589
   Episode_Reward/test_gait_reward: -0.3265
Metrics/base_velocity/error_vel_xy: 1.0795
Metrics/base_velocity/error_vel_yaw: 0.3362
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 1.10s
                        Total time: 583.73s
                               ETA: 2678.4s

################################################################################
                     [1m Learning iteration 537/3000 [0m                      

                       Computation: 89119 steps/s (collection: 0.978s, learning 0.125s)
               Value function loss: 1.1469
                    Surrogate loss: -0.0007
             Mean action noise std: 0.6680
                     Learning rate: 0.0006
                       Mean reward: 23.21
               Mean episode length: 327.20
       Episode_Reward/keep_balance: 0.3790
     Episode_Reward/rew_lin_vel_xy: 1.0261
      Episode_Reward/rew_ang_vel_z: 1.1248
    Episode_Reward/pen_base_height: -0.2184
      Episode_Reward/pen_lin_vel_z: -0.0347
     Episode_Reward/pen_ang_vel_xy: -0.0539
   Episode_Reward/pen_joint_torque: -0.0710
    Episode_Reward/pen_joint_accel: -0.0416
    Episode_Reward/pen_action_rate: -0.0246
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0153
   Episode_Reward/pen_joint_powers: -0.0238
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0512
Episode_Reward/pen_flat_orientation: -0.1406
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.0876
   Episode_Reward/foot_landing_vel: -0.0662
   Episode_Reward/test_gait_reward: -0.3510
Metrics/base_velocity/error_vel_xy: 1.1517
Metrics/base_velocity/error_vel_yaw: 0.3546
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 1.10s
                        Total time: 584.83s
                               ETA: 2677.4s

################################################################################
                     [1m Learning iteration 538/3000 [0m                      

                       Computation: 89781 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 1.2906
                    Surrogate loss: 0.0002
             Mean action noise std: 0.6689
                     Learning rate: 0.0004
                       Mean reward: 29.21
               Mean episode length: 372.31
       Episode_Reward/keep_balance: 0.4001
     Episode_Reward/rew_lin_vel_xy: 1.1311
      Episode_Reward/rew_ang_vel_z: 1.1895
    Episode_Reward/pen_base_height: -0.2232
      Episode_Reward/pen_lin_vel_z: -0.0347
     Episode_Reward/pen_ang_vel_xy: -0.0561
   Episode_Reward/pen_joint_torque: -0.0756
    Episode_Reward/pen_joint_accel: -0.0440
    Episode_Reward/pen_action_rate: -0.0258
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0158
   Episode_Reward/pen_joint_powers: -0.0248
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0545
Episode_Reward/pen_flat_orientation: -0.1426
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.0883
   Episode_Reward/foot_landing_vel: -0.0661
   Episode_Reward/test_gait_reward: -0.3677
Metrics/base_velocity/error_vel_xy: 1.1521
Metrics/base_velocity/error_vel_yaw: 0.3740
      Episode_Termination/time_out: 1.2500
  Episode_Termination/base_contact: 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 1.09s
                        Total time: 585.93s
                               ETA: 2676.3s

################################################################################
                     [1m Learning iteration 539/3000 [0m                      

                       Computation: 89757 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 1.1152
                    Surrogate loss: 0.0007
             Mean action noise std: 0.6700
                     Learning rate: 0.0001
                       Mean reward: 26.22
               Mean episode length: 353.86
       Episode_Reward/keep_balance: 0.3748
     Episode_Reward/rew_lin_vel_xy: 1.0249
      Episode_Reward/rew_ang_vel_z: 1.0946
    Episode_Reward/pen_base_height: -0.2218
      Episode_Reward/pen_lin_vel_z: -0.0350
     Episode_Reward/pen_ang_vel_xy: -0.0556
   Episode_Reward/pen_joint_torque: -0.0726
    Episode_Reward/pen_joint_accel: -0.0425
    Episode_Reward/pen_action_rate: -0.0247
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0245
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0517
Episode_Reward/pen_flat_orientation: -0.1433
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.0910
   Episode_Reward/foot_landing_vel: -0.0644
   Episode_Reward/test_gait_reward: -0.3488
Metrics/base_velocity/error_vel_xy: 1.1197
Metrics/base_velocity/error_vel_yaw: 0.3639
      Episode_Termination/time_out: 1.0833
  Episode_Termination/base_contact: 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 1.10s
                        Total time: 587.02s
                               ETA: 2675.3s

################################################################################
                     [1m Learning iteration 540/3000 [0m                      

                       Computation: 89511 steps/s (collection: 0.971s, learning 0.127s)
               Value function loss: 1.0295
                    Surrogate loss: 0.0014
             Mean action noise std: 0.6698
                     Learning rate: 0.0001
                       Mean reward: 27.28
               Mean episode length: 374.22
       Episode_Reward/keep_balance: 0.3722
     Episode_Reward/rew_lin_vel_xy: 0.9880
      Episode_Reward/rew_ang_vel_z: 1.1069
    Episode_Reward/pen_base_height: -0.2175
      Episode_Reward/pen_lin_vel_z: -0.0337
     Episode_Reward/pen_ang_vel_xy: -0.0550
   Episode_Reward/pen_joint_torque: -0.0706
    Episode_Reward/pen_joint_accel: -0.0402
    Episode_Reward/pen_action_rate: -0.0242
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0150
   Episode_Reward/pen_joint_powers: -0.0236
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0506
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.0851
   Episode_Reward/foot_landing_vel: -0.0614
   Episode_Reward/test_gait_reward: -0.3437
Metrics/base_velocity/error_vel_xy: 1.1554
Metrics/base_velocity/error_vel_yaw: 0.3475
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 12.9167
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 1.10s
                        Total time: 588.12s
                               ETA: 2674.3s

################################################################################
                     [1m Learning iteration 541/3000 [0m                      

                       Computation: 89611 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.9380
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6701
                     Learning rate: 0.0002
                       Mean reward: 21.61
               Mean episode length: 313.97
       Episode_Reward/keep_balance: 0.3435
     Episode_Reward/rew_lin_vel_xy: 0.9167
      Episode_Reward/rew_ang_vel_z: 1.0062
    Episode_Reward/pen_base_height: -0.2078
      Episode_Reward/pen_lin_vel_z: -0.0325
     Episode_Reward/pen_ang_vel_xy: -0.0525
   Episode_Reward/pen_joint_torque: -0.0646
    Episode_Reward/pen_joint_accel: -0.0386
    Episode_Reward/pen_action_rate: -0.0225
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0141
   Episode_Reward/pen_joint_powers: -0.0218
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0471
Episode_Reward/pen_flat_orientation: -0.1361
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.0796
   Episode_Reward/foot_landing_vel: -0.0601
   Episode_Reward/test_gait_reward: -0.3194
Metrics/base_velocity/error_vel_xy: 1.0503
Metrics/base_velocity/error_vel_yaw: 0.3338
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 12.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 1.10s
                        Total time: 589.22s
                               ETA: 2673.2s

################################################################################
                     [1m Learning iteration 542/3000 [0m                      

                       Computation: 89751 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 1.0488
                    Surrogate loss: 0.0002
             Mean action noise std: 0.6707
                     Learning rate: 0.0002
                       Mean reward: 27.89
               Mean episode length: 386.15
       Episode_Reward/keep_balance: 0.3509
     Episode_Reward/rew_lin_vel_xy: 0.9730
      Episode_Reward/rew_ang_vel_z: 1.0379
    Episode_Reward/pen_base_height: -0.2082
      Episode_Reward/pen_lin_vel_z: -0.0326
     Episode_Reward/pen_ang_vel_xy: -0.0523
   Episode_Reward/pen_joint_torque: -0.0675
    Episode_Reward/pen_joint_accel: -0.0378
    Episode_Reward/pen_action_rate: -0.0229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0140
   Episode_Reward/pen_joint_powers: -0.0223
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0482
Episode_Reward/pen_flat_orientation: -0.1295
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0799
   Episode_Reward/foot_landing_vel: -0.0573
   Episode_Reward/test_gait_reward: -0.3239
Metrics/base_velocity/error_vel_xy: 1.0695
Metrics/base_velocity/error_vel_yaw: 0.3331
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 1.10s
                        Total time: 590.31s
                               ETA: 2672.2s

################################################################################
                     [1m Learning iteration 543/3000 [0m                      

                       Computation: 85559 steps/s (collection: 1.022s, learning 0.127s)
               Value function loss: 0.9099
                    Surrogate loss: -0.0029
             Mean action noise std: 0.6709
                     Learning rate: 0.0006
                       Mean reward: 21.76
               Mean episode length: 323.83
       Episode_Reward/keep_balance: 0.3701
     Episode_Reward/rew_lin_vel_xy: 0.9926
      Episode_Reward/rew_ang_vel_z: 1.0832
    Episode_Reward/pen_base_height: -0.2112
      Episode_Reward/pen_lin_vel_z: -0.0337
     Episode_Reward/pen_ang_vel_xy: -0.0545
   Episode_Reward/pen_joint_torque: -0.0699
    Episode_Reward/pen_joint_accel: -0.0422
    Episode_Reward/pen_action_rate: -0.0244
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0152
   Episode_Reward/pen_joint_powers: -0.0236
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0509
Episode_Reward/pen_flat_orientation: -0.1357
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.0866
   Episode_Reward/foot_landing_vel: -0.0608
   Episode_Reward/test_gait_reward: -0.3418
Metrics/base_velocity/error_vel_xy: 1.1335
Metrics/base_velocity/error_vel_yaw: 0.3586
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 1.15s
                        Total time: 591.46s
                               ETA: 2671.4s

################################################################################
                     [1m Learning iteration 544/3000 [0m                      

                       Computation: 89866 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 1.0706
                    Surrogate loss: -0.0030
             Mean action noise std: 0.6721
                     Learning rate: 0.0013
                       Mean reward: 24.23
               Mean episode length: 364.45
       Episode_Reward/keep_balance: 0.3676
     Episode_Reward/rew_lin_vel_xy: 0.9682
      Episode_Reward/rew_ang_vel_z: 1.0777
    Episode_Reward/pen_base_height: -0.2126
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.0569
   Episode_Reward/pen_joint_torque: -0.0712
    Episode_Reward/pen_joint_accel: -0.0433
    Episode_Reward/pen_action_rate: -0.0247
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0159
   Episode_Reward/pen_joint_powers: -0.0244
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0514
Episode_Reward/pen_flat_orientation: -0.1422
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0914
   Episode_Reward/foot_landing_vel: -0.0661
   Episode_Reward/test_gait_reward: -0.3424
Metrics/base_velocity/error_vel_xy: 1.1637
Metrics/base_velocity/error_vel_yaw: 0.3547
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 1.09s
                        Total time: 592.55s
                               ETA: 2670.3s

################################################################################
                     [1m Learning iteration 545/3000 [0m                      

                       Computation: 88211 steps/s (collection: 0.991s, learning 0.123s)
               Value function loss: 1.2747
                    Surrogate loss: 0.0028
             Mean action noise std: 0.6731
                     Learning rate: 0.0002
                       Mean reward: 36.42
               Mean episode length: 476.81
       Episode_Reward/keep_balance: 0.4271
     Episode_Reward/rew_lin_vel_xy: 1.2441
      Episode_Reward/rew_ang_vel_z: 1.2494
    Episode_Reward/pen_base_height: -0.2361
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.0631
   Episode_Reward/pen_joint_torque: -0.0857
    Episode_Reward/pen_joint_accel: -0.0496
    Episode_Reward/pen_action_rate: -0.0289
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0186
   Episode_Reward/pen_joint_powers: -0.0289
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0595
Episode_Reward/pen_flat_orientation: -0.1560
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1108
   Episode_Reward/foot_landing_vel: -0.0770
   Episode_Reward/test_gait_reward: -0.4004
Metrics/base_velocity/error_vel_xy: 1.2420
Metrics/base_velocity/error_vel_yaw: 0.4157
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 1.11s
                        Total time: 593.67s
                               ETA: 2669.3s

################################################################################
                     [1m Learning iteration 546/3000 [0m                      

                       Computation: 89966 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 1.0522
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6731
                     Learning rate: 0.0004
                       Mean reward: 24.91
               Mean episode length: 365.05
       Episode_Reward/keep_balance: 0.3753
     Episode_Reward/rew_lin_vel_xy: 1.0152
      Episode_Reward/rew_ang_vel_z: 1.0872
    Episode_Reward/pen_base_height: -0.2197
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.0584
   Episode_Reward/pen_joint_torque: -0.0723
    Episode_Reward/pen_joint_accel: -0.0457
    Episode_Reward/pen_action_rate: -0.0255
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0169
   Episode_Reward/pen_joint_powers: -0.0254
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0528
Episode_Reward/pen_flat_orientation: -0.1466
  Episode_Reward/pen_feet_distance: -0.0025
Episode_Reward/pen_feet_regulation: -0.0986
   Episode_Reward/foot_landing_vel: -0.0724
   Episode_Reward/test_gait_reward: -0.3500
Metrics/base_velocity/error_vel_xy: 1.1375
Metrics/base_velocity/error_vel_yaw: 0.3737
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 1.09s
                        Total time: 594.76s
                               ETA: 2668.3s

################################################################################
                     [1m Learning iteration 547/3000 [0m                      

                       Computation: 89151 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 1.1154
                    Surrogate loss: -0.0013
             Mean action noise std: 0.6738
                     Learning rate: 0.0003
                       Mean reward: 24.37
               Mean episode length: 363.17
       Episode_Reward/keep_balance: 0.3683
     Episode_Reward/rew_lin_vel_xy: 0.9675
      Episode_Reward/rew_ang_vel_z: 1.0775
    Episode_Reward/pen_base_height: -0.2157
      Episode_Reward/pen_lin_vel_z: -0.0340
     Episode_Reward/pen_ang_vel_xy: -0.0554
   Episode_Reward/pen_joint_torque: -0.0704
    Episode_Reward/pen_joint_accel: -0.0411
    Episode_Reward/pen_action_rate: -0.0245
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0156
   Episode_Reward/pen_joint_powers: -0.0241
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0513
Episode_Reward/pen_flat_orientation: -0.1375
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0885
   Episode_Reward/foot_landing_vel: -0.0637
   Episode_Reward/test_gait_reward: -0.3408
Metrics/base_velocity/error_vel_xy: 1.1130
Metrics/base_velocity/error_vel_yaw: 0.3580
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 10.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 1.10s
                        Total time: 595.86s
                               ETA: 2667.3s

################################################################################
                     [1m Learning iteration 548/3000 [0m                      

                       Computation: 88931 steps/s (collection: 0.981s, learning 0.124s)
               Value function loss: 0.9709
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6757
                     Learning rate: 0.0006
                       Mean reward: 28.19
               Mean episode length: 395.91
       Episode_Reward/keep_balance: 0.3815
     Episode_Reward/rew_lin_vel_xy: 1.0759
      Episode_Reward/rew_ang_vel_z: 1.1298
    Episode_Reward/pen_base_height: -0.2159
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.0560
   Episode_Reward/pen_joint_torque: -0.0740
    Episode_Reward/pen_joint_accel: -0.0430
    Episode_Reward/pen_action_rate: -0.0252
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0157
   Episode_Reward/pen_joint_powers: -0.0246
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0525
Episode_Reward/pen_flat_orientation: -0.1451
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.0899
   Episode_Reward/foot_landing_vel: -0.0621
   Episode_Reward/test_gait_reward: -0.3533
Metrics/base_velocity/error_vel_xy: 1.1252
Metrics/base_velocity/error_vel_yaw: 0.3594
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 9.4167
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 1.11s
                        Total time: 596.97s
                               ETA: 2666.2s

################################################################################
                     [1m Learning iteration 549/3000 [0m                      

                       Computation: 89309 steps/s (collection: 0.978s, learning 0.122s)
               Value function loss: 0.9883
                    Surrogate loss: -0.0024
             Mean action noise std: 0.6765
                     Learning rate: 0.0006
                       Mean reward: 24.06
               Mean episode length: 371.10
       Episode_Reward/keep_balance: 0.3756
     Episode_Reward/rew_lin_vel_xy: 1.0147
      Episode_Reward/rew_ang_vel_z: 1.0939
    Episode_Reward/pen_base_height: -0.2176
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.0591
   Episode_Reward/pen_joint_torque: -0.0732
    Episode_Reward/pen_joint_accel: -0.0423
    Episode_Reward/pen_action_rate: -0.0254
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0163
   Episode_Reward/pen_joint_powers: -0.0254
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0526
Episode_Reward/pen_flat_orientation: -0.1432
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.0950
   Episode_Reward/foot_landing_vel: -0.0649
   Episode_Reward/test_gait_reward: -0.3498
Metrics/base_velocity/error_vel_xy: 1.1168
Metrics/base_velocity/error_vel_yaw: 0.3689
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 1.10s
                        Total time: 598.07s
                               ETA: 2665.2s

################################################################################
                     [1m Learning iteration 550/3000 [0m                      

                       Computation: 90113 steps/s (collection: 0.964s, learning 0.127s)
               Value function loss: 1.0664
                    Surrogate loss: -0.0035
             Mean action noise std: 0.6773
                     Learning rate: 0.0013
                       Mean reward: 27.74
               Mean episode length: 395.73
       Episode_Reward/keep_balance: 0.4042
     Episode_Reward/rew_lin_vel_xy: 1.1059
      Episode_Reward/rew_ang_vel_z: 1.1829
    Episode_Reward/pen_base_height: -0.2163
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.0597
   Episode_Reward/pen_joint_torque: -0.0787
    Episode_Reward/pen_joint_accel: -0.0418
    Episode_Reward/pen_action_rate: -0.0274
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0170
   Episode_Reward/pen_joint_powers: -0.0266
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0570
Episode_Reward/pen_flat_orientation: -0.1483
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.0972
   Episode_Reward/foot_landing_vel: -0.0696
   Episode_Reward/test_gait_reward: -0.3740
Metrics/base_velocity/error_vel_xy: 1.2351
Metrics/base_velocity/error_vel_yaw: 0.3923
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 1.09s
                        Total time: 599.16s
                               ETA: 2664.1s

################################################################################
                     [1m Learning iteration 551/3000 [0m                      

                       Computation: 91152 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 1.0524
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6781
                     Learning rate: 0.0006
                       Mean reward: 35.47
               Mean episode length: 475.20
       Episode_Reward/keep_balance: 0.4617
     Episode_Reward/rew_lin_vel_xy: 1.2614
      Episode_Reward/rew_ang_vel_z: 1.3738
    Episode_Reward/pen_base_height: -0.2337
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.0657
   Episode_Reward/pen_joint_torque: -0.0937
    Episode_Reward/pen_joint_accel: -0.0518
    Episode_Reward/pen_action_rate: -0.0314
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0202
   Episode_Reward/pen_joint_powers: -0.0313
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0644
Episode_Reward/pen_flat_orientation: -0.1637
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1172
   Episode_Reward/foot_landing_vel: -0.0831
   Episode_Reward/test_gait_reward: -0.4292
Metrics/base_velocity/error_vel_xy: 1.3879
Metrics/base_velocity/error_vel_yaw: 0.4301
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 1.08s
                        Total time: 600.24s
                               ETA: 2663.0s

################################################################################
                     [1m Learning iteration 552/3000 [0m                      

                       Computation: 90018 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 1.0493
                    Surrogate loss: -0.0012
             Mean action noise std: 0.6789
                     Learning rate: 0.0006
                       Mean reward: 33.46
               Mean episode length: 461.06
       Episode_Reward/keep_balance: 0.4299
     Episode_Reward/rew_lin_vel_xy: 1.1847
      Episode_Reward/rew_ang_vel_z: 1.2740
    Episode_Reward/pen_base_height: -0.2239
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.0626
   Episode_Reward/pen_joint_torque: -0.0852
    Episode_Reward/pen_joint_accel: -0.0489
    Episode_Reward/pen_action_rate: -0.0294
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0186
   Episode_Reward/pen_joint_powers: -0.0288
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0602
Episode_Reward/pen_flat_orientation: -0.1531
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1097
   Episode_Reward/foot_landing_vel: -0.0745
   Episode_Reward/test_gait_reward: -0.3974
Metrics/base_velocity/error_vel_xy: 1.3109
Metrics/base_velocity/error_vel_yaw: 0.4065
      Episode_Termination/time_out: 2.5833
  Episode_Termination/base_contact: 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 1.09s
                        Total time: 601.33s
                               ETA: 2662.0s

################################################################################
                     [1m Learning iteration 553/3000 [0m                      

                       Computation: 90771 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.9992
                    Surrogate loss: 0.0010
             Mean action noise std: 0.6797
                     Learning rate: 0.0003
                       Mean reward: 34.96
               Mean episode length: 437.93
       Episode_Reward/keep_balance: 0.4166
     Episode_Reward/rew_lin_vel_xy: 1.1730
      Episode_Reward/rew_ang_vel_z: 1.2268
    Episode_Reward/pen_base_height: -0.2231
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.0612
   Episode_Reward/pen_joint_torque: -0.0817
    Episode_Reward/pen_joint_accel: -0.0483
    Episode_Reward/pen_action_rate: -0.0285
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0175
   Episode_Reward/pen_joint_powers: -0.0275
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0590
Episode_Reward/pen_flat_orientation: -0.1503
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.1019
   Episode_Reward/foot_landing_vel: -0.0703
   Episode_Reward/test_gait_reward: -0.3877
Metrics/base_velocity/error_vel_xy: 1.2672
Metrics/base_velocity/error_vel_yaw: 0.3970
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 1.08s
                        Total time: 602.41s
                               ETA: 2660.8s

################################################################################
                     [1m Learning iteration 554/3000 [0m                      

                       Computation: 90462 steps/s (collection: 0.965s, learning 0.121s)
               Value function loss: 1.0556
                    Surrogate loss: -0.0021
             Mean action noise std: 0.6810
                     Learning rate: 0.0006
                       Mean reward: 26.70
               Mean episode length: 385.66
       Episode_Reward/keep_balance: 0.4098
     Episode_Reward/rew_lin_vel_xy: 1.0614
      Episode_Reward/rew_ang_vel_z: 1.2032
    Episode_Reward/pen_base_height: -0.2191
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.0599
   Episode_Reward/pen_joint_torque: -0.0800
    Episode_Reward/pen_joint_accel: -0.0433
    Episode_Reward/pen_action_rate: -0.0280
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0173
   Episode_Reward/pen_joint_powers: -0.0270
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0582
Episode_Reward/pen_flat_orientation: -0.1410
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.0985
   Episode_Reward/foot_landing_vel: -0.0732
   Episode_Reward/test_gait_reward: -0.3766
Metrics/base_velocity/error_vel_xy: 1.3339
Metrics/base_velocity/error_vel_yaw: 0.3944
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 1.09s
                        Total time: 603.50s
                               ETA: 2659.8s

################################################################################
                     [1m Learning iteration 555/3000 [0m                      

                       Computation: 90822 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 1.1016
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6824
                     Learning rate: 0.0006
                       Mean reward: 28.09
               Mean episode length: 393.07
       Episode_Reward/keep_balance: 0.3735
     Episode_Reward/rew_lin_vel_xy: 1.0298
      Episode_Reward/rew_ang_vel_z: 1.0917
    Episode_Reward/pen_base_height: -0.2118
      Episode_Reward/pen_lin_vel_z: -0.0345
     Episode_Reward/pen_ang_vel_xy: -0.0565
   Episode_Reward/pen_joint_torque: -0.0721
    Episode_Reward/pen_joint_accel: -0.0456
    Episode_Reward/pen_action_rate: -0.0259
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0164
   Episode_Reward/pen_joint_powers: -0.0249
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0537
Episode_Reward/pen_flat_orientation: -0.1416
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.0923
   Episode_Reward/foot_landing_vel: -0.0675
   Episode_Reward/test_gait_reward: -0.3462
Metrics/base_velocity/error_vel_xy: 1.1314
Metrics/base_velocity/error_vel_yaw: 0.3646
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 6.8750
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 1.08s
                        Total time: 604.58s
                               ETA: 2658.6s

################################################################################
                     [1m Learning iteration 556/3000 [0m                      

                       Computation: 91443 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.9663
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6823
                     Learning rate: 0.0009
                       Mean reward: 33.03
               Mean episode length: 436.75
       Episode_Reward/keep_balance: 0.4222
     Episode_Reward/rew_lin_vel_xy: 1.1963
      Episode_Reward/rew_ang_vel_z: 1.2395
    Episode_Reward/pen_base_height: -0.2235
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.0622
   Episode_Reward/pen_joint_torque: -0.0825
    Episode_Reward/pen_joint_accel: -0.0465
    Episode_Reward/pen_action_rate: -0.0295
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0181
   Episode_Reward/pen_joint_powers: -0.0281
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0610
Episode_Reward/pen_flat_orientation: -0.1513
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1072
   Episode_Reward/foot_landing_vel: -0.0728
   Episode_Reward/test_gait_reward: -0.3934
Metrics/base_velocity/error_vel_xy: 1.2887
Metrics/base_velocity/error_vel_yaw: 0.4045
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 1.08s
                        Total time: 605.66s
                               ETA: 2657.5s

################################################################################
                     [1m Learning iteration 557/3000 [0m                      

                       Computation: 89287 steps/s (collection: 0.979s, learning 0.122s)
               Value function loss: 1.1807
                    Surrogate loss: 0.0003
             Mean action noise std: 0.6823
                     Learning rate: 0.0002
                       Mean reward: 28.24
               Mean episode length: 381.57
       Episode_Reward/keep_balance: 0.3812
     Episode_Reward/rew_lin_vel_xy: 1.1225
      Episode_Reward/rew_ang_vel_z: 1.1203
    Episode_Reward/pen_base_height: -0.2151
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.0569
   Episode_Reward/pen_joint_torque: -0.0750
    Episode_Reward/pen_joint_accel: -0.0417
    Episode_Reward/pen_action_rate: -0.0263
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0163
   Episode_Reward/pen_joint_powers: -0.0255
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.0542
Episode_Reward/pen_flat_orientation: -0.1407
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.0967
   Episode_Reward/foot_landing_vel: -0.0669
   Episode_Reward/test_gait_reward: -0.3553
Metrics/base_velocity/error_vel_xy: 1.1138
Metrics/base_velocity/error_vel_yaw: 0.3638
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 1.10s
                        Total time: 606.76s
                               ETA: 2656.5s

################################################################################
                     [1m Learning iteration 558/3000 [0m                      

                       Computation: 90528 steps/s (collection: 0.959s, learning 0.127s)
               Value function loss: 1.1199
                    Surrogate loss: -0.0019
             Mean action noise std: 0.6830
                     Learning rate: 0.0004
                       Mean reward: 30.68
               Mean episode length: 419.87
       Episode_Reward/keep_balance: 0.4412
     Episode_Reward/rew_lin_vel_xy: 1.2559
      Episode_Reward/rew_ang_vel_z: 1.2955
    Episode_Reward/pen_base_height: -0.2318
      Episode_Reward/pen_lin_vel_z: -0.0406
     Episode_Reward/pen_ang_vel_xy: -0.0648
   Episode_Reward/pen_joint_torque: -0.0861
    Episode_Reward/pen_joint_accel: -0.0527
    Episode_Reward/pen_action_rate: -0.0309
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0191
   Episode_Reward/pen_joint_powers: -0.0294
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0639
Episode_Reward/pen_flat_orientation: -0.1567
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.1088
   Episode_Reward/foot_landing_vel: -0.0759
   Episode_Reward/test_gait_reward: -0.4094
Metrics/base_velocity/error_vel_xy: 1.3384
Metrics/base_velocity/error_vel_yaw: 0.4231
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 1.09s
                        Total time: 607.85s
                               ETA: 2655.4s

################################################################################
                     [1m Learning iteration 559/3000 [0m                      

                       Computation: 89879 steps/s (collection: 0.968s, learning 0.126s)
               Value function loss: 1.0581
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6829
                     Learning rate: 0.0009
                       Mean reward: 26.15
               Mean episode length: 375.21
       Episode_Reward/keep_balance: 0.4154
     Episode_Reward/rew_lin_vel_xy: 1.2346
      Episode_Reward/rew_ang_vel_z: 1.2078
    Episode_Reward/pen_base_height: -0.2243
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.0605
   Episode_Reward/pen_joint_torque: -0.0817
    Episode_Reward/pen_joint_accel: -0.0473
    Episode_Reward/pen_action_rate: -0.0293
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0181
   Episode_Reward/pen_joint_powers: -0.0277
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0606
Episode_Reward/pen_flat_orientation: -0.1524
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.1049
   Episode_Reward/foot_landing_vel: -0.0733
   Episode_Reward/test_gait_reward: -0.3884
Metrics/base_velocity/error_vel_xy: 1.1721
Metrics/base_velocity/error_vel_yaw: 0.4092
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 1.09s
                        Total time: 608.94s
                               ETA: 2654.3s

################################################################################
                     [1m Learning iteration 560/3000 [0m                      

                       Computation: 90821 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 1.1850
                    Surrogate loss: -0.0005
             Mean action noise std: 0.6840
                     Learning rate: 0.0009
                       Mean reward: 26.02
               Mean episode length: 353.23
       Episode_Reward/keep_balance: 0.3861
     Episode_Reward/rew_lin_vel_xy: 1.0606
      Episode_Reward/rew_ang_vel_z: 1.1245
    Episode_Reward/pen_base_height: -0.2166
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.0598
   Episode_Reward/pen_joint_torque: -0.0743
    Episode_Reward/pen_joint_accel: -0.0434
    Episode_Reward/pen_action_rate: -0.0272
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0168
   Episode_Reward/pen_joint_powers: -0.0259
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0567
Episode_Reward/pen_flat_orientation: -0.1454
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.0981
   Episode_Reward/foot_landing_vel: -0.0675
   Episode_Reward/test_gait_reward: -0.3592
Metrics/base_velocity/error_vel_xy: 1.1650
Metrics/base_velocity/error_vel_yaw: 0.3788
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 1.08s
                        Total time: 610.02s
                               ETA: 2653.2s

################################################################################
                     [1m Learning iteration 561/3000 [0m                      

                       Computation: 90009 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 1.0274
                    Surrogate loss: 0.0030
             Mean action noise std: 0.6849
                     Learning rate: 0.0001
                       Mean reward: 24.84
               Mean episode length: 363.48
       Episode_Reward/keep_balance: 0.3618
     Episode_Reward/rew_lin_vel_xy: 0.9820
      Episode_Reward/rew_ang_vel_z: 1.0543
    Episode_Reward/pen_base_height: -0.2130
      Episode_Reward/pen_lin_vel_z: -0.0327
     Episode_Reward/pen_ang_vel_xy: -0.0562
   Episode_Reward/pen_joint_torque: -0.0677
    Episode_Reward/pen_joint_accel: -0.0408
    Episode_Reward/pen_action_rate: -0.0252
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0154
   Episode_Reward/pen_joint_powers: -0.0236
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0529
Episode_Reward/pen_flat_orientation: -0.1307
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0919
   Episode_Reward/foot_landing_vel: -0.0613
   Episode_Reward/test_gait_reward: -0.3381
Metrics/base_velocity/error_vel_xy: 1.1300
Metrics/base_velocity/error_vel_yaw: 0.3533
      Episode_Termination/time_out: 1.0417
  Episode_Termination/base_contact: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 1.09s
                        Total time: 611.11s
                               ETA: 2652.1s

################################################################################
                     [1m Learning iteration 562/3000 [0m                      

                       Computation: 89553 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 1.0707
                    Surrogate loss: 0.0014
             Mean action noise std: 0.6846
                     Learning rate: 0.0001
                       Mean reward: 31.58
               Mean episode length: 402.33
       Episode_Reward/keep_balance: 0.4177
     Episode_Reward/rew_lin_vel_xy: 1.1824
      Episode_Reward/rew_ang_vel_z: 1.2365
    Episode_Reward/pen_base_height: -0.2217
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.0620
   Episode_Reward/pen_joint_torque: -0.0802
    Episode_Reward/pen_joint_accel: -0.0452
    Episode_Reward/pen_action_rate: -0.0293
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0174
   Episode_Reward/pen_joint_powers: -0.0273
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0608
Episode_Reward/pen_flat_orientation: -0.1432
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1035
   Episode_Reward/foot_landing_vel: -0.0676
   Episode_Reward/test_gait_reward: -0.3880
Metrics/base_velocity/error_vel_xy: 1.2194
Metrics/base_velocity/error_vel_yaw: 0.3940
      Episode_Termination/time_out: 1.4583
  Episode_Termination/base_contact: 8.2083
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 1.10s
                        Total time: 612.21s
                               ETA: 2651.1s

################################################################################
                     [1m Learning iteration 563/3000 [0m                      

                       Computation: 88930 steps/s (collection: 0.982s, learning 0.123s)
               Value function loss: 1.0875
                    Surrogate loss: 0.0004
             Mean action noise std: 0.6844
                     Learning rate: 0.0002
                       Mean reward: 33.03
               Mean episode length: 441.52
       Episode_Reward/keep_balance: 0.4163
     Episode_Reward/rew_lin_vel_xy: 1.1854
      Episode_Reward/rew_ang_vel_z: 1.2299
    Episode_Reward/pen_base_height: -0.2263
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.0611
   Episode_Reward/pen_joint_torque: -0.0826
    Episode_Reward/pen_joint_accel: -0.0465
    Episode_Reward/pen_action_rate: -0.0293
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0177
   Episode_Reward/pen_joint_powers: -0.0279
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0606
Episode_Reward/pen_flat_orientation: -0.1510
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.1064
   Episode_Reward/foot_landing_vel: -0.0688
   Episode_Reward/test_gait_reward: -0.3904
Metrics/base_velocity/error_vel_xy: 1.2123
Metrics/base_velocity/error_vel_yaw: 0.3957
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 1.11s
                        Total time: 613.32s
                               ETA: 2650.1s

################################################################################
                     [1m Learning iteration 564/3000 [0m                      

                       Computation: 90804 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.9615
                    Surrogate loss: -0.0036
             Mean action noise std: 0.6847
                     Learning rate: 0.0004
                       Mean reward: 28.55
               Mean episode length: 395.05
       Episode_Reward/keep_balance: 0.4495
     Episode_Reward/rew_lin_vel_xy: 1.3133
      Episode_Reward/rew_ang_vel_z: 1.2965
    Episode_Reward/pen_base_height: -0.2384
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.0675
   Episode_Reward/pen_joint_torque: -0.0909
    Episode_Reward/pen_joint_accel: -0.0540
    Episode_Reward/pen_action_rate: -0.0328
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0210
   Episode_Reward/pen_joint_powers: -0.0317
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0675
Episode_Reward/pen_flat_orientation: -0.1686
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.1302
   Episode_Reward/foot_landing_vel: -0.0856
   Episode_Reward/test_gait_reward: -0.4195
Metrics/base_velocity/error_vel_xy: 1.3042
Metrics/base_velocity/error_vel_yaw: 0.4511
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 8.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 1.08s
                        Total time: 614.40s
                               ETA: 2649.0s

################################################################################
                     [1m Learning iteration 565/3000 [0m                      

                       Computation: 90017 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 1.1472
                    Surrogate loss: -0.0015
             Mean action noise std: 0.6855
                     Learning rate: 0.0009
                       Mean reward: 28.79
               Mean episode length: 392.12
       Episode_Reward/keep_balance: 0.3573
     Episode_Reward/rew_lin_vel_xy: 1.0084
      Episode_Reward/rew_ang_vel_z: 1.0566
    Episode_Reward/pen_base_height: -0.2075
      Episode_Reward/pen_lin_vel_z: -0.0320
     Episode_Reward/pen_ang_vel_xy: -0.0547
   Episode_Reward/pen_joint_torque: -0.0693
    Episode_Reward/pen_joint_accel: -0.0387
    Episode_Reward/pen_action_rate: -0.0250
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0146
   Episode_Reward/pen_joint_powers: -0.0233
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0523
Episode_Reward/pen_flat_orientation: -0.1328
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.0865
   Episode_Reward/foot_landing_vel: -0.0579
   Episode_Reward/test_gait_reward: -0.3308
Metrics/base_velocity/error_vel_xy: 1.0515
Metrics/base_velocity/error_vel_yaw: 0.3378
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 9.5833
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 1.09s
                        Total time: 615.49s
                               ETA: 2647.9s

################################################################################
                     [1m Learning iteration 566/3000 [0m                      

                       Computation: 91089 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 1.1374
                    Surrogate loss: -0.0007
             Mean action noise std: 0.6855
                     Learning rate: 0.0009
                       Mean reward: 36.95
               Mean episode length: 478.08
       Episode_Reward/keep_balance: 0.4547
     Episode_Reward/rew_lin_vel_xy: 1.3270
      Episode_Reward/rew_ang_vel_z: 1.3406
    Episode_Reward/pen_base_height: -0.2348
      Episode_Reward/pen_lin_vel_z: -0.0420
     Episode_Reward/pen_ang_vel_xy: -0.0664
   Episode_Reward/pen_joint_torque: -0.0918
    Episode_Reward/pen_joint_accel: -0.0517
    Episode_Reward/pen_action_rate: -0.0322
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0196
   Episode_Reward/pen_joint_powers: -0.0308
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0664
Episode_Reward/pen_flat_orientation: -0.1605
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1196
   Episode_Reward/foot_landing_vel: -0.0750
   Episode_Reward/test_gait_reward: -0.4227
Metrics/base_velocity/error_vel_xy: 1.3298
Metrics/base_velocity/error_vel_yaw: 0.4337
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 1.08s
                        Total time: 616.57s
                               ETA: 2646.8s

################################################################################
                     [1m Learning iteration 567/3000 [0m                      

                       Computation: 91112 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 1.0208
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6862
                     Learning rate: 0.0006
                       Mean reward: 26.74
               Mean episode length: 412.41
       Episode_Reward/keep_balance: 0.3978
     Episode_Reward/rew_lin_vel_xy: 1.1074
      Episode_Reward/rew_ang_vel_z: 1.1535
    Episode_Reward/pen_base_height: -0.2289
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.0614
   Episode_Reward/pen_joint_torque: -0.0772
    Episode_Reward/pen_joint_accel: -0.0443
    Episode_Reward/pen_action_rate: -0.0283
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0173
   Episode_Reward/pen_joint_powers: -0.0267
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0590
Episode_Reward/pen_flat_orientation: -0.1497
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1019
   Episode_Reward/foot_landing_vel: -0.0665
   Episode_Reward/test_gait_reward: -0.3730
Metrics/base_velocity/error_vel_xy: 1.2168
Metrics/base_velocity/error_vel_yaw: 0.3943
      Episode_Termination/time_out: 1.1250
  Episode_Termination/base_contact: 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 1.08s
                        Total time: 617.65s
                               ETA: 2645.7s

################################################################################
                     [1m Learning iteration 568/3000 [0m                      

                       Computation: 90650 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 1.0070
                    Surrogate loss: 0.0003
             Mean action noise std: 0.6866
                     Learning rate: 0.0004
                       Mean reward: 29.38
               Mean episode length: 434.52
       Episode_Reward/keep_balance: 0.3987
     Episode_Reward/rew_lin_vel_xy: 1.1014
      Episode_Reward/rew_ang_vel_z: 1.1642
    Episode_Reward/pen_base_height: -0.2211
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.0595
   Episode_Reward/pen_joint_torque: -0.0755
    Episode_Reward/pen_joint_accel: -0.0431
    Episode_Reward/pen_action_rate: -0.0282
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0168
   Episode_Reward/pen_joint_powers: -0.0260
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0590
Episode_Reward/pen_flat_orientation: -0.1499
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.0978
   Episode_Reward/foot_landing_vel: -0.0641
   Episode_Reward/test_gait_reward: -0.3705
Metrics/base_velocity/error_vel_xy: 1.1855
Metrics/base_velocity/error_vel_yaw: 0.3873
      Episode_Termination/time_out: 1.2917
  Episode_Termination/base_contact: 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 1.08s
                        Total time: 618.73s
                               ETA: 2644.6s

################################################################################
                     [1m Learning iteration 569/3000 [0m                      

                       Computation: 89840 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 1.0299
                    Surrogate loss: -0.0033
             Mean action noise std: 0.6872
                     Learning rate: 0.0009
                       Mean reward: 32.96
               Mean episode length: 438.20
       Episode_Reward/keep_balance: 0.4143
     Episode_Reward/rew_lin_vel_xy: 1.1842
      Episode_Reward/rew_ang_vel_z: 1.2268
    Episode_Reward/pen_base_height: -0.2238
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.0626
   Episode_Reward/pen_joint_torque: -0.0822
    Episode_Reward/pen_joint_accel: -0.0459
    Episode_Reward/pen_action_rate: -0.0295
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0176
   Episode_Reward/pen_joint_powers: -0.0279
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.0617
Episode_Reward/pen_flat_orientation: -0.1490
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1024
   Episode_Reward/foot_landing_vel: -0.0697
   Episode_Reward/test_gait_reward: -0.3853
Metrics/base_velocity/error_vel_xy: 1.2477
Metrics/base_velocity/error_vel_yaw: 0.3922
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 1.09s
                        Total time: 619.83s
                               ETA: 2643.5s

################################################################################
                     [1m Learning iteration 570/3000 [0m                      

                       Computation: 90597 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 1.0616
                    Surrogate loss: 0.0011
             Mean action noise std: 0.6887
                     Learning rate: 0.0003
                       Mean reward: 29.09
               Mean episode length: 425.10
       Episode_Reward/keep_balance: 0.4025
     Episode_Reward/rew_lin_vel_xy: 1.1065
      Episode_Reward/rew_ang_vel_z: 1.1777
    Episode_Reward/pen_base_height: -0.2212
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.0625
   Episode_Reward/pen_joint_torque: -0.0776
    Episode_Reward/pen_joint_accel: -0.0441
    Episode_Reward/pen_action_rate: -0.0290
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0174
   Episode_Reward/pen_joint_powers: -0.0270
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0601
Episode_Reward/pen_flat_orientation: -0.1468
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1037
   Episode_Reward/foot_landing_vel: -0.0669
   Episode_Reward/test_gait_reward: -0.3737
Metrics/base_velocity/error_vel_xy: 1.2233
Metrics/base_velocity/error_vel_yaw: 0.3905
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 1.09s
                        Total time: 620.91s
                               ETA: 2642.4s

################################################################################
                     [1m Learning iteration 571/3000 [0m                      

                       Computation: 89825 steps/s (collection: 0.968s, learning 0.126s)
               Value function loss: 1.0100
                    Surrogate loss: 0.0086
             Mean action noise std: 0.6888
                     Learning rate: 0.0000
                       Mean reward: 30.24
               Mean episode length: 398.62
       Episode_Reward/keep_balance: 0.4158
     Episode_Reward/rew_lin_vel_xy: 1.1858
      Episode_Reward/rew_ang_vel_z: 1.2177
    Episode_Reward/pen_base_height: -0.2265
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.0621
   Episode_Reward/pen_joint_torque: -0.0817
    Episode_Reward/pen_joint_accel: -0.0444
    Episode_Reward/pen_action_rate: -0.0298
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0176
   Episode_Reward/pen_joint_powers: -0.0279
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0618
Episode_Reward/pen_flat_orientation: -0.1475
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1028
   Episode_Reward/foot_landing_vel: -0.0696
   Episode_Reward/test_gait_reward: -0.3863
Metrics/base_velocity/error_vel_xy: 1.2428
Metrics/base_velocity/error_vel_yaw: 0.4031
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 1.09s
                        Total time: 622.01s
                               ETA: 2641.4s

################################################################################
                     [1m Learning iteration 572/3000 [0m                      

                       Computation: 89645 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 1.1151
                    Surrogate loss: 0.0096
             Mean action noise std: 0.6889
                     Learning rate: 0.0000
                       Mean reward: 28.67
               Mean episode length: 403.49
       Episode_Reward/keep_balance: 0.3848
     Episode_Reward/rew_lin_vel_xy: 1.0327
      Episode_Reward/rew_ang_vel_z: 1.1256
    Episode_Reward/pen_base_height: -0.2153
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.0600
   Episode_Reward/pen_joint_torque: -0.0735
    Episode_Reward/pen_joint_accel: -0.0474
    Episode_Reward/pen_action_rate: -0.0277
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0171
   Episode_Reward/pen_joint_powers: -0.0259
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0578
Episode_Reward/pen_flat_orientation: -0.1490
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1021
   Episode_Reward/foot_landing_vel: -0.0640
   Episode_Reward/test_gait_reward: -0.3585
Metrics/base_velocity/error_vel_xy: 1.2349
Metrics/base_velocity/error_vel_yaw: 0.3748
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 1.10s
                        Total time: 623.10s
                               ETA: 2640.3s

################################################################################
                     [1m Learning iteration 573/3000 [0m                      

                       Computation: 90363 steps/s (collection: 0.962s, learning 0.126s)
               Value function loss: 1.0308
                    Surrogate loss: 0.0072
             Mean action noise std: 0.6890
                     Learning rate: 0.0000
                       Mean reward: 30.88
               Mean episode length: 415.67
       Episode_Reward/keep_balance: 0.4056
     Episode_Reward/rew_lin_vel_xy: 1.1608
      Episode_Reward/rew_ang_vel_z: 1.1966
    Episode_Reward/pen_base_height: -0.2201
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.0596
   Episode_Reward/pen_joint_torque: -0.0792
    Episode_Reward/pen_joint_accel: -0.0456
    Episode_Reward/pen_action_rate: -0.0289
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0172
   Episode_Reward/pen_joint_powers: -0.0271
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0599
Episode_Reward/pen_flat_orientation: -0.1444
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.0993
   Episode_Reward/foot_landing_vel: -0.0680
   Episode_Reward/test_gait_reward: -0.3750
Metrics/base_velocity/error_vel_xy: 1.2064
Metrics/base_velocity/error_vel_yaw: 0.3867
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 8.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 1.09s
                        Total time: 624.19s
                               ETA: 2639.2s

################################################################################
                     [1m Learning iteration 574/3000 [0m                      

                       Computation: 86100 steps/s (collection: 1.020s, learning 0.122s)
               Value function loss: 1.1558
                    Surrogate loss: -0.0020
             Mean action noise std: 0.6895
                     Learning rate: 0.0001
                       Mean reward: 31.54
               Mean episode length: 409.14
       Episode_Reward/keep_balance: 0.4177
     Episode_Reward/rew_lin_vel_xy: 1.2266
      Episode_Reward/rew_ang_vel_z: 1.2238
    Episode_Reward/pen_base_height: -0.2281
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.0626
   Episode_Reward/pen_joint_torque: -0.0841
    Episode_Reward/pen_joint_accel: -0.0451
    Episode_Reward/pen_action_rate: -0.0300
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0178
   Episode_Reward/pen_joint_powers: -0.0283
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0623
Episode_Reward/pen_flat_orientation: -0.1487
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.1061
   Episode_Reward/foot_landing_vel: -0.0687
   Episode_Reward/test_gait_reward: -0.3884
Metrics/base_velocity/error_vel_xy: 1.2572
Metrics/base_velocity/error_vel_yaw: 0.4039
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 1.14s
                        Total time: 625.33s
                               ETA: 2638.4s

################################################################################
                     [1m Learning iteration 575/3000 [0m                      

                       Computation: 90399 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 1.0284
                    Surrogate loss: -0.0027
             Mean action noise std: 0.6899
                     Learning rate: 0.0006
                       Mean reward: 32.96
               Mean episode length: 439.10
       Episode_Reward/keep_balance: 0.4122
     Episode_Reward/rew_lin_vel_xy: 1.2050
      Episode_Reward/rew_ang_vel_z: 1.2013
    Episode_Reward/pen_base_height: -0.2328
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.0648
   Episode_Reward/pen_joint_torque: -0.0846
    Episode_Reward/pen_joint_accel: -0.0485
    Episode_Reward/pen_action_rate: -0.0299
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0186
   Episode_Reward/pen_joint_powers: -0.0291
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0616
Episode_Reward/pen_flat_orientation: -0.1582
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1125
   Episode_Reward/foot_landing_vel: -0.0712
   Episode_Reward/test_gait_reward: -0.3873
Metrics/base_velocity/error_vel_xy: 1.2062
Metrics/base_velocity/error_vel_yaw: 0.4062
      Episode_Termination/time_out: 1.5833
  Episode_Termination/base_contact: 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 1.09s
                        Total time: 626.42s
                               ETA: 2637.3s

################################################################################
                     [1m Learning iteration 576/3000 [0m                      

                       Computation: 90332 steps/s (collection: 0.964s, learning 0.125s)
               Value function loss: 1.0838
                    Surrogate loss: -0.0026
             Mean action noise std: 0.6906
                     Learning rate: 0.0013
                       Mean reward: 27.59
               Mean episode length: 395.91
       Episode_Reward/keep_balance: 0.4203
     Episode_Reward/rew_lin_vel_xy: 1.1722
      Episode_Reward/rew_ang_vel_z: 1.2240
    Episode_Reward/pen_base_height: -0.2306
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.0650
   Episode_Reward/pen_joint_torque: -0.0853
    Episode_Reward/pen_joint_accel: -0.0463
    Episode_Reward/pen_action_rate: -0.0306
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0192
   Episode_Reward/pen_joint_powers: -0.0296
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0633
Episode_Reward/pen_flat_orientation: -0.1591
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1146
   Episode_Reward/foot_landing_vel: -0.0771
   Episode_Reward/test_gait_reward: -0.3888
Metrics/base_velocity/error_vel_xy: 1.2731
Metrics/base_velocity/error_vel_yaw: 0.4123
      Episode_Termination/time_out: 1.3333
  Episode_Termination/base_contact: 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 1.09s
                        Total time: 627.51s
                               ETA: 2636.2s

################################################################################
                     [1m Learning iteration 577/3000 [0m                      

                       Computation: 90086 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 1.2755
                    Surrogate loss: 0.0027
             Mean action noise std: 0.6918
                     Learning rate: 0.0003
                       Mean reward: 31.49
               Mean episode length: 418.82
       Episode_Reward/keep_balance: 0.3895
     Episode_Reward/rew_lin_vel_xy: 1.0915
      Episode_Reward/rew_ang_vel_z: 1.1366
    Episode_Reward/pen_base_height: -0.2143
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.0608
   Episode_Reward/pen_joint_torque: -0.0775
    Episode_Reward/pen_joint_accel: -0.0442
    Episode_Reward/pen_action_rate: -0.0282
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0169
   Episode_Reward/pen_joint_powers: -0.0263
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0587
Episode_Reward/pen_flat_orientation: -0.1389
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1005
   Episode_Reward/foot_landing_vel: -0.0672
   Episode_Reward/test_gait_reward: -0.3606
Metrics/base_velocity/error_vel_xy: 1.1696
Metrics/base_velocity/error_vel_yaw: 0.3811
      Episode_Termination/time_out: 1.4167
  Episode_Termination/base_contact: 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 1.09s
                        Total time: 628.60s
                               ETA: 2635.1s

################################################################################
                     [1m Learning iteration 578/3000 [0m                      

                       Computation: 89945 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 1.0745
                    Surrogate loss: 0.0019
             Mean action noise std: 0.6915
                     Learning rate: 0.0002
                       Mean reward: 28.45
               Mean episode length: 405.17
       Episode_Reward/keep_balance: 0.4276
     Episode_Reward/rew_lin_vel_xy: 1.1861
      Episode_Reward/rew_ang_vel_z: 1.2540
    Episode_Reward/pen_base_height: -0.2217
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.0643
   Episode_Reward/pen_joint_torque: -0.0807
    Episode_Reward/pen_joint_accel: -0.0470
    Episode_Reward/pen_action_rate: -0.0310
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0179
   Episode_Reward/pen_joint_powers: -0.0279
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0648
Episode_Reward/pen_flat_orientation: -0.1482
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1064
   Episode_Reward/foot_landing_vel: -0.0688
   Episode_Reward/test_gait_reward: -0.3951
Metrics/base_velocity/error_vel_xy: 1.3165
Metrics/base_velocity/error_vel_yaw: 0.4110
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 1.09s
                        Total time: 629.69s
                               ETA: 2634.1s

################################################################################
                     [1m Learning iteration 579/3000 [0m                      

                       Computation: 88722 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 1.2145
                    Surrogate loss: 0.0015
             Mean action noise std: 0.6909
                     Learning rate: 0.0002
                       Mean reward: 33.54
               Mean episode length: 423.35
       Episode_Reward/keep_balance: 0.4099
     Episode_Reward/rew_lin_vel_xy: 1.1450
      Episode_Reward/rew_ang_vel_z: 1.2100
    Episode_Reward/pen_base_height: -0.2225
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.0606
   Episode_Reward/pen_joint_torque: -0.0806
    Episode_Reward/pen_joint_accel: -0.0435
    Episode_Reward/pen_action_rate: -0.0292
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0168
   Episode_Reward/pen_joint_powers: -0.0269
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0608
Episode_Reward/pen_flat_orientation: -0.1388
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.0995
   Episode_Reward/foot_landing_vel: -0.0649
   Episode_Reward/test_gait_reward: -0.3787
Metrics/base_velocity/error_vel_xy: 1.2363
Metrics/base_velocity/error_vel_yaw: 0.3882
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 1.11s
                        Total time: 630.80s
                               ETA: 2633.1s

################################################################################
                     [1m Learning iteration 580/3000 [0m                      

                       Computation: 90342 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 1.1236
                    Surrogate loss: 0.0029
             Mean action noise std: 0.6908
                     Learning rate: 0.0001
                       Mean reward: 29.25
               Mean episode length: 426.43
       Episode_Reward/keep_balance: 0.4230
     Episode_Reward/rew_lin_vel_xy: 1.1704
      Episode_Reward/rew_ang_vel_z: 1.2232
    Episode_Reward/pen_base_height: -0.2243
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.0654
   Episode_Reward/pen_joint_torque: -0.0842
    Episode_Reward/pen_joint_accel: -0.0482
    Episode_Reward/pen_action_rate: -0.0311
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0187
   Episode_Reward/pen_joint_powers: -0.0291
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0647
Episode_Reward/pen_flat_orientation: -0.1512
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1118
   Episode_Reward/foot_landing_vel: -0.0714
   Episode_Reward/test_gait_reward: -0.3919
Metrics/base_velocity/error_vel_xy: 1.3020
Metrics/base_velocity/error_vel_yaw: 0.4235
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 1.09s
                        Total time: 631.89s
                               ETA: 2632.0s

################################################################################
                     [1m Learning iteration 581/3000 [0m                      

                       Computation: 90314 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 1.0785
                    Surrogate loss: -0.0009
             Mean action noise std: 0.6913
                     Learning rate: 0.0002
                       Mean reward: 31.99
               Mean episode length: 443.63
       Episode_Reward/keep_balance: 0.4458
     Episode_Reward/rew_lin_vel_xy: 1.2577
      Episode_Reward/rew_ang_vel_z: 1.2985
    Episode_Reward/pen_base_height: -0.2353
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.0685
   Episode_Reward/pen_joint_torque: -0.0906
    Episode_Reward/pen_joint_accel: -0.0495
    Episode_Reward/pen_action_rate: -0.0329
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0198
   Episode_Reward/pen_joint_powers: -0.0311
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0678
Episode_Reward/pen_flat_orientation: -0.1570
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1197
   Episode_Reward/foot_landing_vel: -0.0789
   Episode_Reward/test_gait_reward: -0.4139
Metrics/base_velocity/error_vel_xy: 1.3560
Metrics/base_velocity/error_vel_yaw: 0.4361
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 1.09s
                        Total time: 632.98s
                               ETA: 2630.9s

################################################################################
                     [1m Learning iteration 582/3000 [0m                      

                       Computation: 90456 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 1.1135
                    Surrogate loss: 0.0027
             Mean action noise std: 0.6915
                     Learning rate: 0.0001
                       Mean reward: 36.91
               Mean episode length: 458.05
       Episode_Reward/keep_balance: 0.4433
     Episode_Reward/rew_lin_vel_xy: 1.3883
      Episode_Reward/rew_ang_vel_z: 1.2942
    Episode_Reward/pen_base_height: -0.2279
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.0654
   Episode_Reward/pen_joint_torque: -0.0884
    Episode_Reward/pen_joint_accel: -0.0511
    Episode_Reward/pen_action_rate: -0.0326
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0193
   Episode_Reward/pen_joint_powers: -0.0304
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0675
Episode_Reward/pen_flat_orientation: -0.1518
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1145
   Episode_Reward/foot_landing_vel: -0.0761
   Episode_Reward/test_gait_reward: -0.4112
Metrics/base_velocity/error_vel_xy: 1.2426
Metrics/base_velocity/error_vel_yaw: 0.4310
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 1.09s
                        Total time: 634.06s
                               ETA: 2629.8s

################################################################################
                     [1m Learning iteration 583/3000 [0m                      

                       Computation: 90741 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 1.0737
                    Surrogate loss: -0.0032
             Mean action noise std: 0.6915
                     Learning rate: 0.0002
                       Mean reward: 30.68
               Mean episode length: 429.92
       Episode_Reward/keep_balance: 0.4327
     Episode_Reward/rew_lin_vel_xy: 1.3296
      Episode_Reward/rew_ang_vel_z: 1.2521
    Episode_Reward/pen_base_height: -0.2258
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.0654
   Episode_Reward/pen_joint_torque: -0.0847
    Episode_Reward/pen_joint_accel: -0.0497
    Episode_Reward/pen_action_rate: -0.0319
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0189
   Episode_Reward/pen_joint_powers: -0.0293
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0664
Episode_Reward/pen_flat_orientation: -0.1490
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1149
   Episode_Reward/foot_landing_vel: -0.0742
   Episode_Reward/test_gait_reward: -0.4014
Metrics/base_velocity/error_vel_xy: 1.2445
Metrics/base_velocity/error_vel_yaw: 0.4310
      Episode_Termination/time_out: 2.2917
  Episode_Termination/base_contact: 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 1.08s
                        Total time: 635.15s
                               ETA: 2628.7s

################################################################################
                     [1m Learning iteration 584/3000 [0m                      

                       Computation: 90670 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 1.2511
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6910
                     Learning rate: 0.0006
                       Mean reward: 28.41
               Mean episode length: 390.14
       Episode_Reward/keep_balance: 0.4190
     Episode_Reward/rew_lin_vel_xy: 1.1730
      Episode_Reward/rew_ang_vel_z: 1.2303
    Episode_Reward/pen_base_height: -0.2205
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.0637
   Episode_Reward/pen_joint_torque: -0.0831
    Episode_Reward/pen_joint_accel: -0.0464
    Episode_Reward/pen_action_rate: -0.0306
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0179
   Episode_Reward/pen_joint_powers: -0.0284
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0634
Episode_Reward/pen_flat_orientation: -0.1426
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.1087
   Episode_Reward/foot_landing_vel: -0.0677
   Episode_Reward/test_gait_reward: -0.3878
Metrics/base_velocity/error_vel_xy: 1.2595
Metrics/base_velocity/error_vel_yaw: 0.4049
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 1.08s
                        Total time: 636.23s
                               ETA: 2627.6s

################################################################################
                     [1m Learning iteration 585/3000 [0m                      

                       Computation: 90007 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 1.4979
                    Surrogate loss: -0.0028
             Mean action noise std: 0.6910
                     Learning rate: 0.0013
                       Mean reward: 29.09
               Mean episode length: 383.01
       Episode_Reward/keep_balance: 0.3940
     Episode_Reward/rew_lin_vel_xy: 1.1588
      Episode_Reward/rew_ang_vel_z: 1.1499
    Episode_Reward/pen_base_height: -0.2120
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.0601
   Episode_Reward/pen_joint_torque: -0.0783
    Episode_Reward/pen_joint_accel: -0.0460
    Episode_Reward/pen_action_rate: -0.0288
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0171
   Episode_Reward/pen_joint_powers: -0.0268
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.0600
Episode_Reward/pen_flat_orientation: -0.1390
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.1028
   Episode_Reward/foot_landing_vel: -0.0635
   Episode_Reward/test_gait_reward: -0.3651
Metrics/base_velocity/error_vel_xy: 1.1756
Metrics/base_velocity/error_vel_yaw: 0.3834
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 1.09s
                        Total time: 637.32s
                               ETA: 2626.5s

################################################################################
                     [1m Learning iteration 586/3000 [0m                      

                       Computation: 89334 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 1.3597
                    Surrogate loss: -0.0022
             Mean action noise std: 0.6924
                     Learning rate: 0.0019
                       Mean reward: 25.23
               Mean episode length: 345.05
       Episode_Reward/keep_balance: 0.3844
     Episode_Reward/rew_lin_vel_xy: 1.0850
      Episode_Reward/rew_ang_vel_z: 1.1245
    Episode_Reward/pen_base_height: -0.2138
      Episode_Reward/pen_lin_vel_z: -0.0350
     Episode_Reward/pen_ang_vel_xy: -0.0597
   Episode_Reward/pen_joint_torque: -0.0758
    Episode_Reward/pen_joint_accel: -0.0435
    Episode_Reward/pen_action_rate: -0.0282
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0170
   Episode_Reward/pen_joint_powers: -0.0264
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0587
Episode_Reward/pen_flat_orientation: -0.1323
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.1004
   Episode_Reward/foot_landing_vel: -0.0660
   Episode_Reward/test_gait_reward: -0.3559
Metrics/base_velocity/error_vel_xy: 1.1567
Metrics/base_velocity/error_vel_yaw: 0.3738
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 1.10s
                        Total time: 638.43s
                               ETA: 2625.5s

################################################################################
                     [1m Learning iteration 587/3000 [0m                      

                       Computation: 89291 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 1.1176
                    Surrogate loss: 0.0043
             Mean action noise std: 0.6929
                     Learning rate: 0.0003
                       Mean reward: 27.97
               Mean episode length: 420.95
       Episode_Reward/keep_balance: 0.4280
     Episode_Reward/rew_lin_vel_xy: 1.1812
      Episode_Reward/rew_ang_vel_z: 1.2300
    Episode_Reward/pen_base_height: -0.2314
      Episode_Reward/pen_lin_vel_z: -0.0406
     Episode_Reward/pen_ang_vel_xy: -0.0658
   Episode_Reward/pen_joint_torque: -0.0868
    Episode_Reward/pen_joint_accel: -0.0499
    Episode_Reward/pen_action_rate: -0.0319
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0191
   Episode_Reward/pen_joint_powers: -0.0298
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0664
Episode_Reward/pen_flat_orientation: -0.1557
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1175
   Episode_Reward/foot_landing_vel: -0.0771
   Episode_Reward/test_gait_reward: -0.3992
Metrics/base_velocity/error_vel_xy: 1.2996
Metrics/base_velocity/error_vel_yaw: 0.4302
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 8.2917
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 1.10s
                        Total time: 639.53s
                               ETA: 2624.4s

################################################################################
                     [1m Learning iteration 588/3000 [0m                      

                       Computation: 89458 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.9356
                    Surrogate loss: -0.0008
             Mean action noise std: 0.6936
                     Learning rate: 0.0004
                       Mean reward: 32.26
               Mean episode length: 429.09
       Episode_Reward/keep_balance: 0.4337
     Episode_Reward/rew_lin_vel_xy: 1.2177
      Episode_Reward/rew_ang_vel_z: 1.2739
    Episode_Reward/pen_base_height: -0.2302
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.0662
   Episode_Reward/pen_joint_torque: -0.0885
    Episode_Reward/pen_joint_accel: -0.0502
    Episode_Reward/pen_action_rate: -0.0319
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0190
   Episode_Reward/pen_joint_powers: -0.0301
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0660
Episode_Reward/pen_flat_orientation: -0.1496
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1146
   Episode_Reward/foot_landing_vel: -0.0739
   Episode_Reward/test_gait_reward: -0.4021
Metrics/base_velocity/error_vel_xy: 1.2885
Metrics/base_velocity/error_vel_yaw: 0.4161
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 1.10s
                        Total time: 640.62s
                               ETA: 2623.4s

################################################################################
                     [1m Learning iteration 589/3000 [0m                      

                       Computation: 89024 steps/s (collection: 0.980s, learning 0.124s)
               Value function loss: 1.1219
                    Surrogate loss: -0.0025
             Mean action noise std: 0.6955
                     Learning rate: 0.0006
                       Mean reward: 29.85
               Mean episode length: 420.69
       Episode_Reward/keep_balance: 0.4556
     Episode_Reward/rew_lin_vel_xy: 1.3301
      Episode_Reward/rew_ang_vel_z: 1.3257
    Episode_Reward/pen_base_height: -0.2393
      Episode_Reward/pen_lin_vel_z: -0.0422
     Episode_Reward/pen_ang_vel_xy: -0.0691
   Episode_Reward/pen_joint_torque: -0.0939
    Episode_Reward/pen_joint_accel: -0.0534
    Episode_Reward/pen_action_rate: -0.0337
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0205
   Episode_Reward/pen_joint_powers: -0.0323
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0693
Episode_Reward/pen_flat_orientation: -0.1499
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1257
   Episode_Reward/foot_landing_vel: -0.0770
   Episode_Reward/test_gait_reward: -0.4246
Metrics/base_velocity/error_vel_xy: 1.3761
Metrics/base_velocity/error_vel_yaw: 0.4472
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 1.10s
                        Total time: 641.73s
                               ETA: 2622.4s

################################################################################
                     [1m Learning iteration 590/3000 [0m                      

                       Computation: 89392 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 1.4791
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6974
                     Learning rate: 0.0013
                       Mean reward: 40.66
               Mean episode length: 528.37
       Episode_Reward/keep_balance: 0.4761
     Episode_Reward/rew_lin_vel_xy: 1.3344
      Episode_Reward/rew_ang_vel_z: 1.4004
    Episode_Reward/pen_base_height: -0.2354
      Episode_Reward/pen_lin_vel_z: -0.0443
     Episode_Reward/pen_ang_vel_xy: -0.0699
   Episode_Reward/pen_joint_torque: -0.0972
    Episode_Reward/pen_joint_accel: -0.0521
    Episode_Reward/pen_action_rate: -0.0352
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0206
   Episode_Reward/pen_joint_powers: -0.0329
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0725
Episode_Reward/pen_flat_orientation: -0.1579
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1236
   Episode_Reward/foot_landing_vel: -0.0795
   Episode_Reward/test_gait_reward: -0.4415
Metrics/base_velocity/error_vel_xy: 1.4327
Metrics/base_velocity/error_vel_yaw: 0.4562
      Episode_Termination/time_out: 1.8333
  Episode_Termination/base_contact: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 1.10s
                        Total time: 642.83s
                               ETA: 2621.3s

################################################################################
                     [1m Learning iteration 591/3000 [0m                      

                       Computation: 90031 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 1.1585
                    Surrogate loss: 0.0004
             Mean action noise std: 0.6991
                     Learning rate: 0.0003
                       Mean reward: 33.05
               Mean episode length: 459.66
       Episode_Reward/keep_balance: 0.4041
     Episode_Reward/rew_lin_vel_xy: 1.1821
      Episode_Reward/rew_ang_vel_z: 1.1626
    Episode_Reward/pen_base_height: -0.2227
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.0632
   Episode_Reward/pen_joint_torque: -0.0803
    Episode_Reward/pen_joint_accel: -0.0464
    Episode_Reward/pen_action_rate: -0.0300
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0180
   Episode_Reward/pen_joint_powers: -0.0279
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0628
Episode_Reward/pen_flat_orientation: -0.1423
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1101
   Episode_Reward/foot_landing_vel: -0.0685
   Episode_Reward/test_gait_reward: -0.3748
Metrics/base_velocity/error_vel_xy: 1.1733
Metrics/base_velocity/error_vel_yaw: 0.4074
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 1.09s
                        Total time: 643.92s
                               ETA: 2620.3s

################################################################################
                     [1m Learning iteration 592/3000 [0m                      

                       Computation: 87276 steps/s (collection: 1.004s, learning 0.122s)
               Value function loss: 0.9472
                    Surrogate loss: -0.0023
             Mean action noise std: 0.6999
                     Learning rate: 0.0004
                       Mean reward: 26.17
               Mean episode length: 359.97
       Episode_Reward/keep_balance: 0.4028
     Episode_Reward/rew_lin_vel_xy: 1.1373
      Episode_Reward/rew_ang_vel_z: 1.1713
    Episode_Reward/pen_base_height: -0.2200
      Episode_Reward/pen_lin_vel_z: -0.0353
     Episode_Reward/pen_ang_vel_xy: -0.0617
   Episode_Reward/pen_joint_torque: -0.0801
    Episode_Reward/pen_joint_accel: -0.0425
    Episode_Reward/pen_action_rate: -0.0295
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0169
   Episode_Reward/pen_joint_powers: -0.0269
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0619
Episode_Reward/pen_flat_orientation: -0.1391
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.0996
   Episode_Reward/foot_landing_vel: -0.0651
   Episode_Reward/test_gait_reward: -0.3715
Metrics/base_velocity/error_vel_xy: 1.2239
Metrics/base_velocity/error_vel_yaw: 0.3946
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 1.13s
                        Total time: 645.05s
                               ETA: 2619.3s

################################################################################
                     [1m Learning iteration 593/3000 [0m                      

                       Computation: 90878 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 1.0358
                    Surrogate loss: -0.0001
             Mean action noise std: 0.7006
                     Learning rate: 0.0004
                       Mean reward: 33.21
               Mean episode length: 452.10
       Episode_Reward/keep_balance: 0.4311
     Episode_Reward/rew_lin_vel_xy: 1.2719
      Episode_Reward/rew_ang_vel_z: 1.2595
    Episode_Reward/pen_base_height: -0.2301
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.0650
   Episode_Reward/pen_joint_torque: -0.0892
    Episode_Reward/pen_joint_accel: -0.0477
    Episode_Reward/pen_action_rate: -0.0320
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0189
   Episode_Reward/pen_joint_powers: -0.0299
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0660
Episode_Reward/pen_flat_orientation: -0.1459
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.1163
   Episode_Reward/foot_landing_vel: -0.0735
   Episode_Reward/test_gait_reward: -0.4003
Metrics/base_velocity/error_vel_xy: 1.2934
Metrics/base_velocity/error_vel_yaw: 0.4199
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 1.08s
                        Total time: 646.13s
                               ETA: 2618.2s

################################################################################
                     [1m Learning iteration 594/3000 [0m                      

                       Computation: 90061 steps/s (collection: 0.967s, learning 0.125s)
               Value function loss: 1.0153
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7011
                     Learning rate: 0.0006
                       Mean reward: 30.40
               Mean episode length: 426.43
       Episode_Reward/keep_balance: 0.4643
     Episode_Reward/rew_lin_vel_xy: 1.3070
      Episode_Reward/rew_ang_vel_z: 1.3708
    Episode_Reward/pen_base_height: -0.2354
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.0688
   Episode_Reward/pen_joint_torque: -0.0979
    Episode_Reward/pen_joint_accel: -0.0548
    Episode_Reward/pen_action_rate: -0.0348
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0205
   Episode_Reward/pen_joint_powers: -0.0326
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0708
Episode_Reward/pen_flat_orientation: -0.1559
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1254
   Episode_Reward/foot_landing_vel: -0.0792
   Episode_Reward/test_gait_reward: -0.4291
Metrics/base_velocity/error_vel_xy: 1.3948
Metrics/base_velocity/error_vel_yaw: 0.4397
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 1.09s
                        Total time: 647.22s
                               ETA: 2617.2s

################################################################################
                     [1m Learning iteration 595/3000 [0m                      

                       Computation: 90628 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.9873
                    Surrogate loss: 0.0013
             Mean action noise std: 0.7014
                     Learning rate: 0.0003
                       Mean reward: 32.16
               Mean episode length: 417.57
       Episode_Reward/keep_balance: 0.4372
     Episode_Reward/rew_lin_vel_xy: 1.3124
      Episode_Reward/rew_ang_vel_z: 1.2729
    Episode_Reward/pen_base_height: -0.2320
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.0685
   Episode_Reward/pen_joint_torque: -0.0897
    Episode_Reward/pen_joint_accel: -0.0493
    Episode_Reward/pen_action_rate: -0.0324
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0194
   Episode_Reward/pen_joint_powers: -0.0305
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0674
Episode_Reward/pen_flat_orientation: -0.1452
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.1177
   Episode_Reward/foot_landing_vel: -0.0718
   Episode_Reward/test_gait_reward: -0.4061
Metrics/base_velocity/error_vel_xy: 1.2705
Metrics/base_velocity/error_vel_yaw: 0.4288
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 1.08s
                        Total time: 648.30s
                               ETA: 2616.1s

################################################################################
                     [1m Learning iteration 596/3000 [0m                      

                       Computation: 90058 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 0.9327
                    Surrogate loss: 0.0036
             Mean action noise std: 0.7021
                     Learning rate: 0.0001
                       Mean reward: 30.01
               Mean episode length: 408.73
       Episode_Reward/keep_balance: 0.3976
     Episode_Reward/rew_lin_vel_xy: 1.2065
      Episode_Reward/rew_ang_vel_z: 1.1381
    Episode_Reward/pen_base_height: -0.2196
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.0627
   Episode_Reward/pen_joint_torque: -0.0818
    Episode_Reward/pen_joint_accel: -0.0449
    Episode_Reward/pen_action_rate: -0.0297
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0179
   Episode_Reward/pen_joint_powers: -0.0280
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.0615
Episode_Reward/pen_flat_orientation: -0.1389
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1141
   Episode_Reward/foot_landing_vel: -0.0686
   Episode_Reward/test_gait_reward: -0.3723
Metrics/base_velocity/error_vel_xy: 1.1017
Metrics/base_velocity/error_vel_yaw: 0.4040
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 1.09s
                        Total time: 649.40s
                               ETA: 2615.0s

################################################################################
                     [1m Learning iteration 597/3000 [0m                      

                       Computation: 90260 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.9598
                    Surrogate loss: -0.0025
             Mean action noise std: 0.7016
                     Learning rate: 0.0003
                       Mean reward: 35.20
               Mean episode length: 467.61
       Episode_Reward/keep_balance: 0.4514
     Episode_Reward/rew_lin_vel_xy: 1.3273
      Episode_Reward/rew_ang_vel_z: 1.3141
    Episode_Reward/pen_base_height: -0.2309
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.0663
   Episode_Reward/pen_joint_torque: -0.0917
    Episode_Reward/pen_joint_accel: -0.0505
    Episode_Reward/pen_action_rate: -0.0338
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0193
   Episode_Reward/pen_joint_powers: -0.0307
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0699
Episode_Reward/pen_flat_orientation: -0.1482
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1182
   Episode_Reward/foot_landing_vel: -0.0726
   Episode_Reward/test_gait_reward: -0.4167
Metrics/base_velocity/error_vel_xy: 1.3594
Metrics/base_velocity/error_vel_yaw: 0.4428
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 1.09s
                        Total time: 650.49s
                               ETA: 2613.9s

################################################################################
                     [1m Learning iteration 598/3000 [0m                      

                       Computation: 89054 steps/s (collection: 0.981s, learning 0.123s)
               Value function loss: 0.9700
                    Surrogate loss: -0.0032
             Mean action noise std: 0.7014
                     Learning rate: 0.0006
                       Mean reward: 32.70
               Mean episode length: 431.70
       Episode_Reward/keep_balance: 0.4239
     Episode_Reward/rew_lin_vel_xy: 1.2771
      Episode_Reward/rew_ang_vel_z: 1.2319
    Episode_Reward/pen_base_height: -0.2223
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.0632
   Episode_Reward/pen_joint_torque: -0.0846
    Episode_Reward/pen_joint_accel: -0.0474
    Episode_Reward/pen_action_rate: -0.0319
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0188
   Episode_Reward/pen_joint_powers: -0.0290
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0659
Episode_Reward/pen_flat_orientation: -0.1431
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1169
   Episode_Reward/foot_landing_vel: -0.0726
   Episode_Reward/test_gait_reward: -0.3941
Metrics/base_velocity/error_vel_xy: 1.2324
Metrics/base_velocity/error_vel_yaw: 0.4148
      Episode_Termination/time_out: 1.7083
  Episode_Termination/base_contact: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 1.10s
                        Total time: 651.59s
                               ETA: 2612.9s

################################################################################
                     [1m Learning iteration 599/3000 [0m                      

                       Computation: 89968 steps/s (collection: 0.967s, learning 0.125s)
               Value function loss: 1.0411
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7031
                     Learning rate: 0.0004
                       Mean reward: 41.56
               Mean episode length: 558.93
       Episode_Reward/keep_balance: 0.5650
     Episode_Reward/rew_lin_vel_xy: 1.7415
      Episode_Reward/rew_ang_vel_z: 1.6504
    Episode_Reward/pen_base_height: -0.2618
      Episode_Reward/pen_lin_vel_z: -0.0518
     Episode_Reward/pen_ang_vel_xy: -0.0830
   Episode_Reward/pen_joint_torque: -0.1190
    Episode_Reward/pen_joint_accel: -0.0636
    Episode_Reward/pen_action_rate: -0.0431
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0253
   Episode_Reward/pen_joint_powers: -0.0403
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0879
Episode_Reward/pen_flat_orientation: -0.1711
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.1539
   Episode_Reward/foot_landing_vel: -0.0975
   Episode_Reward/test_gait_reward: -0.5241
Metrics/base_velocity/error_vel_xy: 1.6231
Metrics/base_velocity/error_vel_yaw: 0.5498
      Episode_Termination/time_out: 2.2500
  Episode_Termination/base_contact: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 1.09s
                        Total time: 652.68s
                               ETA: 2611.8s

################################################################################
                     [1m Learning iteration 600/3000 [0m                      

                       Computation: 90744 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.9695
                    Surrogate loss: -0.0002
             Mean action noise std: 0.7040
                     Learning rate: 0.0006
                       Mean reward: 35.99
               Mean episode length: 459.89
       Episode_Reward/keep_balance: 0.4712
     Episode_Reward/rew_lin_vel_xy: 1.3550
      Episode_Reward/rew_ang_vel_z: 1.3898
    Episode_Reward/pen_base_height: -0.2381
      Episode_Reward/pen_lin_vel_z: -0.0430
     Episode_Reward/pen_ang_vel_xy: -0.0709
   Episode_Reward/pen_joint_torque: -0.0981
    Episode_Reward/pen_joint_accel: -0.0516
    Episode_Reward/pen_action_rate: -0.0353
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0208
   Episode_Reward/pen_joint_powers: -0.0330
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0723
Episode_Reward/pen_flat_orientation: -0.1529
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.1237
   Episode_Reward/foot_landing_vel: -0.0821
   Episode_Reward/test_gait_reward: -0.4360
Metrics/base_velocity/error_vel_xy: 1.4325
Metrics/base_velocity/error_vel_yaw: 0.4481
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 1.08s
                        Total time: 653.77s
                               ETA: 2610.7s

################################################################################
                     [1m Learning iteration 601/3000 [0m                      

                       Computation: 91440 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.8895
                    Surrogate loss: -0.0004
             Mean action noise std: 0.7049
                     Learning rate: 0.0004
                       Mean reward: 36.63
               Mean episode length: 504.04
       Episode_Reward/keep_balance: 0.4827
     Episode_Reward/rew_lin_vel_xy: 1.3985
      Episode_Reward/rew_ang_vel_z: 1.3968
    Episode_Reward/pen_base_height: -0.2374
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.0724
   Episode_Reward/pen_joint_torque: -0.1021
    Episode_Reward/pen_joint_accel: -0.0538
    Episode_Reward/pen_action_rate: -0.0369
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0218
   Episode_Reward/pen_joint_powers: -0.0344
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0759
Episode_Reward/pen_flat_orientation: -0.1602
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.1356
   Episode_Reward/foot_landing_vel: -0.0846
   Episode_Reward/test_gait_reward: -0.4475
Metrics/base_velocity/error_vel_xy: 1.3894
Metrics/base_velocity/error_vel_yaw: 0.4765
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 1.08s
                        Total time: 654.84s
                               ETA: 2609.6s

################################################################################
                     [1m Learning iteration 602/3000 [0m                      

                       Computation: 90388 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.9720
                    Surrogate loss: -0.0032
             Mean action noise std: 0.7054
                     Learning rate: 0.0006
                       Mean reward: 37.21
               Mean episode length: 474.97
       Episode_Reward/keep_balance: 0.5000
     Episode_Reward/rew_lin_vel_xy: 1.4420
      Episode_Reward/rew_ang_vel_z: 1.4495
    Episode_Reward/pen_base_height: -0.2469
      Episode_Reward/pen_lin_vel_z: -0.0440
     Episode_Reward/pen_ang_vel_xy: -0.0753
   Episode_Reward/pen_joint_torque: -0.1028
    Episode_Reward/pen_joint_accel: -0.0557
    Episode_Reward/pen_action_rate: -0.0383
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0227
   Episode_Reward/pen_joint_powers: -0.0354
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0790
Episode_Reward/pen_flat_orientation: -0.1560
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.1386
   Episode_Reward/foot_landing_vel: -0.0875
   Episode_Reward/test_gait_reward: -0.4616
Metrics/base_velocity/error_vel_xy: 1.5038
Metrics/base_velocity/error_vel_yaw: 0.4942
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 1.09s
                        Total time: 655.93s
                               ETA: 2608.5s

################################################################################
                     [1m Learning iteration 603/3000 [0m                      

                       Computation: 90965 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 1.0699
                    Surrogate loss: -0.0005
             Mean action noise std: 0.7060
                     Learning rate: 0.0006
                       Mean reward: 36.58
               Mean episode length: 496.16
       Episode_Reward/keep_balance: 0.4988
     Episode_Reward/rew_lin_vel_xy: 1.4344
      Episode_Reward/rew_ang_vel_z: 1.4516
    Episode_Reward/pen_base_height: -0.2508
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.0755
   Episode_Reward/pen_joint_torque: -0.1022
    Episode_Reward/pen_joint_accel: -0.0576
    Episode_Reward/pen_action_rate: -0.0380
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0220
   Episode_Reward/pen_joint_powers: -0.0346
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0787
Episode_Reward/pen_flat_orientation: -0.1627
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1319
   Episode_Reward/foot_landing_vel: -0.0829
   Episode_Reward/test_gait_reward: -0.4599
Metrics/base_velocity/error_vel_xy: 1.5199
Metrics/base_velocity/error_vel_yaw: 0.4891
      Episode_Termination/time_out: 1.5000
  Episode_Termination/base_contact: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 1.08s
                        Total time: 657.01s
                               ETA: 2607.4s

################################################################################
                     [1m Learning iteration 604/3000 [0m                      

                       Computation: 89884 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 1.0500
                    Surrogate loss: -0.0017
             Mean action noise std: 0.7077
                     Learning rate: 0.0009
                       Mean reward: 36.28
               Mean episode length: 463.80
       Episode_Reward/keep_balance: 0.4729
     Episode_Reward/rew_lin_vel_xy: 1.4880
      Episode_Reward/rew_ang_vel_z: 1.3681
    Episode_Reward/pen_base_height: -0.2413
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.0715
   Episode_Reward/pen_joint_torque: -0.0965
    Episode_Reward/pen_joint_accel: -0.0531
    Episode_Reward/pen_action_rate: -0.0359
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0210
   Episode_Reward/pen_joint_powers: -0.0331
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0739
Episode_Reward/pen_flat_orientation: -0.1563
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1371
   Episode_Reward/foot_landing_vel: -0.0786
   Episode_Reward/test_gait_reward: -0.4384
Metrics/base_velocity/error_vel_xy: 1.2980
Metrics/base_velocity/error_vel_yaw: 0.4700
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 1.09s
                        Total time: 658.10s
                               ETA: 2606.3s

################################################################################
                     [1m Learning iteration 605/3000 [0m                      

                       Computation: 90453 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 1.0880
                    Surrogate loss: 0.0034
             Mean action noise std: 0.7084
                     Learning rate: 0.0003
                       Mean reward: 40.66
               Mean episode length: 528.27
       Episode_Reward/keep_balance: 0.4805
     Episode_Reward/rew_lin_vel_xy: 1.4909
      Episode_Reward/rew_ang_vel_z: 1.4061
    Episode_Reward/pen_base_height: -0.2367
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.0704
   Episode_Reward/pen_joint_torque: -0.1016
    Episode_Reward/pen_joint_accel: -0.0558
    Episode_Reward/pen_action_rate: -0.0366
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0212
   Episode_Reward/pen_joint_powers: -0.0336
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0759
Episode_Reward/pen_flat_orientation: -0.1484
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1322
   Episode_Reward/foot_landing_vel: -0.0803
   Episode_Reward/test_gait_reward: -0.4457
Metrics/base_velocity/error_vel_xy: 1.3343
Metrics/base_velocity/error_vel_yaw: 0.4644
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 1.09s
                        Total time: 659.19s
                               ETA: 2605.2s

################################################################################
                     [1m Learning iteration 606/3000 [0m                      

                       Computation: 90990 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 1.2404
                    Surrogate loss: -0.0013
             Mean action noise std: 0.7097
                     Learning rate: 0.0006
                       Mean reward: 49.06
               Mean episode length: 607.92
       Episode_Reward/keep_balance: 0.5563
     Episode_Reward/rew_lin_vel_xy: 1.7639
      Episode_Reward/rew_ang_vel_z: 1.5961
    Episode_Reward/pen_base_height: -0.2739
      Episode_Reward/pen_lin_vel_z: -0.0508
     Episode_Reward/pen_ang_vel_xy: -0.0814
   Episode_Reward/pen_joint_torque: -0.1165
    Episode_Reward/pen_joint_accel: -0.0627
    Episode_Reward/pen_action_rate: -0.0430
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0255
   Episode_Reward/pen_joint_powers: -0.0396
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0886
Episode_Reward/pen_flat_orientation: -0.1728
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.1649
   Episode_Reward/foot_landing_vel: -0.0945
   Episode_Reward/test_gait_reward: -0.5178
Metrics/base_velocity/error_vel_xy: 1.5527
Metrics/base_velocity/error_vel_yaw: 0.5668
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 1.08s
                        Total time: 660.27s
                               ETA: 2604.1s

################################################################################
                     [1m Learning iteration 607/3000 [0m                      

                       Computation: 91160 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 1.1100
                    Surrogate loss: -0.0015
             Mean action noise std: 0.7100
                     Learning rate: 0.0009
                       Mean reward: 34.74
               Mean episode length: 483.54
       Episode_Reward/keep_balance: 0.5336
     Episode_Reward/rew_lin_vel_xy: 1.4759
      Episode_Reward/rew_ang_vel_z: 1.5591
    Episode_Reward/pen_base_height: -0.2557
      Episode_Reward/pen_lin_vel_z: -0.0484
     Episode_Reward/pen_ang_vel_xy: -0.0791
   Episode_Reward/pen_joint_torque: -0.1170
    Episode_Reward/pen_joint_accel: -0.0597
    Episode_Reward/pen_action_rate: -0.0411
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0239
   Episode_Reward/pen_joint_powers: -0.0386
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0842
Episode_Reward/pen_flat_orientation: -0.1628
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1511
   Episode_Reward/foot_landing_vel: -0.0931
   Episode_Reward/test_gait_reward: -0.4950
Metrics/base_velocity/error_vel_xy: 1.6746
Metrics/base_velocity/error_vel_yaw: 0.5187
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 1.08s
                        Total time: 661.35s
                               ETA: 2603.0s

################################################################################
                     [1m Learning iteration 608/3000 [0m                      

                       Computation: 90690 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 1.1285
                    Surrogate loss: 0.0008
             Mean action noise std: 0.7097
                     Learning rate: 0.0003
                       Mean reward: 35.55
               Mean episode length: 471.11
       Episode_Reward/keep_balance: 0.4547
     Episode_Reward/rew_lin_vel_xy: 1.3286
      Episode_Reward/rew_ang_vel_z: 1.3110
    Episode_Reward/pen_base_height: -0.2361
      Episode_Reward/pen_lin_vel_z: -0.0425
     Episode_Reward/pen_ang_vel_xy: -0.0710
   Episode_Reward/pen_joint_torque: -0.0950
    Episode_Reward/pen_joint_accel: -0.0554
    Episode_Reward/pen_action_rate: -0.0353
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0208
   Episode_Reward/pen_joint_powers: -0.0325
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0734
Episode_Reward/pen_flat_orientation: -0.1478
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1279
   Episode_Reward/foot_landing_vel: -0.0768
   Episode_Reward/test_gait_reward: -0.4227
Metrics/base_velocity/error_vel_xy: 1.3651
Metrics/base_velocity/error_vel_yaw: 0.4532
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 1.08s
                        Total time: 662.43s
                               ETA: 2601.9s

################################################################################
                     [1m Learning iteration 609/3000 [0m                      

                       Computation: 87467 steps/s (collection: 0.999s, learning 0.125s)
               Value function loss: 1.0786
                    Surrogate loss: -0.0019
             Mean action noise std: 0.7107
                     Learning rate: 0.0006
                       Mean reward: 39.12
               Mean episode length: 502.78
       Episode_Reward/keep_balance: 0.4740
     Episode_Reward/rew_lin_vel_xy: 1.3262
      Episode_Reward/rew_ang_vel_z: 1.3560
    Episode_Reward/pen_base_height: -0.2399
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.0705
   Episode_Reward/pen_joint_torque: -0.0940
    Episode_Reward/pen_joint_accel: -0.0527
    Episode_Reward/pen_action_rate: -0.0362
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0201
   Episode_Reward/pen_joint_powers: -0.0317
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0767
Episode_Reward/pen_flat_orientation: -0.1376
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1184
   Episode_Reward/foot_landing_vel: -0.0780
   Episode_Reward/test_gait_reward: -0.4347
Metrics/base_velocity/error_vel_xy: 1.5178
Metrics/base_velocity/error_vel_yaw: 0.4837
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 1.12s
                        Total time: 663.56s
                               ETA: 2600.9s

################################################################################
                     [1m Learning iteration 610/3000 [0m                      

                       Computation: 90373 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 1.0344
                    Surrogate loss: -0.0022
             Mean action noise std: 0.7119
                     Learning rate: 0.0009
                       Mean reward: 41.60
               Mean episode length: 564.01
       Episode_Reward/keep_balance: 0.5354
     Episode_Reward/rew_lin_vel_xy: 1.5607
      Episode_Reward/rew_ang_vel_z: 1.5529
    Episode_Reward/pen_base_height: -0.2590
      Episode_Reward/pen_lin_vel_z: -0.0492
     Episode_Reward/pen_ang_vel_xy: -0.0789
   Episode_Reward/pen_joint_torque: -0.1144
    Episode_Reward/pen_joint_accel: -0.0631
    Episode_Reward/pen_action_rate: -0.0414
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0242
   Episode_Reward/pen_joint_powers: -0.0382
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0854
Episode_Reward/pen_flat_orientation: -0.1548
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.1468
   Episode_Reward/foot_landing_vel: -0.0937
   Episode_Reward/test_gait_reward: -0.4951
Metrics/base_velocity/error_vel_xy: 1.5601
Metrics/base_velocity/error_vel_yaw: 0.5277
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 1.09s
                        Total time: 664.64s
                               ETA: 2599.8s

################################################################################
                     [1m Learning iteration 611/3000 [0m                      

                       Computation: 90893 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 1.0814
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7126
                     Learning rate: 0.0004
                       Mean reward: 41.89
               Mean episode length: 551.09
       Episode_Reward/keep_balance: 0.5283
     Episode_Reward/rew_lin_vel_xy: 1.5911
      Episode_Reward/rew_ang_vel_z: 1.5404
    Episode_Reward/pen_base_height: -0.2592
      Episode_Reward/pen_lin_vel_z: -0.0474
     Episode_Reward/pen_ang_vel_xy: -0.0786
   Episode_Reward/pen_joint_torque: -0.1079
    Episode_Reward/pen_joint_accel: -0.0666
    Episode_Reward/pen_action_rate: -0.0409
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0238
   Episode_Reward/pen_joint_powers: -0.0369
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.0845
Episode_Reward/pen_flat_orientation: -0.1574
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.1455
   Episode_Reward/foot_landing_vel: -0.0929
   Episode_Reward/test_gait_reward: -0.4854
Metrics/base_velocity/error_vel_xy: 1.5846
Metrics/base_velocity/error_vel_yaw: 0.5181
      Episode_Termination/time_out: 1.6250
  Episode_Termination/base_contact: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 1.08s
                        Total time: 665.73s
                               ETA: 2598.7s

################################################################################
                     [1m Learning iteration 612/3000 [0m                      

                       Computation: 91913 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 1.1284
                    Surrogate loss: -0.0012
             Mean action noise std: 0.7132
                     Learning rate: 0.0006
                       Mean reward: 42.21
               Mean episode length: 553.81
       Episode_Reward/keep_balance: 0.5060
     Episode_Reward/rew_lin_vel_xy: 1.5692
      Episode_Reward/rew_ang_vel_z: 1.4555
    Episode_Reward/pen_base_height: -0.2466
      Episode_Reward/pen_lin_vel_z: -0.0479
     Episode_Reward/pen_ang_vel_xy: -0.0766
   Episode_Reward/pen_joint_torque: -0.1076
    Episode_Reward/pen_joint_accel: -0.0652
    Episode_Reward/pen_action_rate: -0.0397
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0238
   Episode_Reward/pen_joint_powers: -0.0370
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0819
Episode_Reward/pen_flat_orientation: -0.1579
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.1463
   Episode_Reward/foot_landing_vel: -0.0950
   Episode_Reward/test_gait_reward: -0.4698
Metrics/base_velocity/error_vel_xy: 1.4629
Metrics/base_velocity/error_vel_yaw: 0.5094
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 1.07s
                        Total time: 666.79s
                               ETA: 2597.6s

################################################################################
                     [1m Learning iteration 613/3000 [0m                      

                       Computation: 91438 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 1.1535
                    Surrogate loss: -0.0016
             Mean action noise std: 0.7142
                     Learning rate: 0.0004
                       Mean reward: 40.32
               Mean episode length: 545.16
       Episode_Reward/keep_balance: 0.5464
     Episode_Reward/rew_lin_vel_xy: 1.5841
      Episode_Reward/rew_ang_vel_z: 1.5691
    Episode_Reward/pen_base_height: -0.2608
      Episode_Reward/pen_lin_vel_z: -0.0486
     Episode_Reward/pen_ang_vel_xy: -0.0795
   Episode_Reward/pen_joint_torque: -0.1140
    Episode_Reward/pen_joint_accel: -0.0588
    Episode_Reward/pen_action_rate: -0.0423
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0241
   Episode_Reward/pen_joint_powers: -0.0382
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0883
Episode_Reward/pen_flat_orientation: -0.1562
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.1472
   Episode_Reward/foot_landing_vel: -0.0910
   Episode_Reward/test_gait_reward: -0.5000
Metrics/base_velocity/error_vel_xy: 1.6015
Metrics/base_velocity/error_vel_yaw: 0.5526
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 1.08s
                        Total time: 667.87s
                               ETA: 2596.4s

################################################################################
                     [1m Learning iteration 614/3000 [0m                      

                       Computation: 91189 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.1595
                    Surrogate loss: -0.0037
             Mean action noise std: 0.7154
                     Learning rate: 0.0009
                       Mean reward: 46.72
               Mean episode length: 585.53
       Episode_Reward/keep_balance: 0.5772
     Episode_Reward/rew_lin_vel_xy: 1.7759
      Episode_Reward/rew_ang_vel_z: 1.6508
    Episode_Reward/pen_base_height: -0.2720
      Episode_Reward/pen_lin_vel_z: -0.0529
     Episode_Reward/pen_ang_vel_xy: -0.0844
   Episode_Reward/pen_joint_torque: -0.1228
    Episode_Reward/pen_joint_accel: -0.0725
    Episode_Reward/pen_action_rate: -0.0451
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0269
   Episode_Reward/pen_joint_powers: -0.0418
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0938
Episode_Reward/pen_flat_orientation: -0.1661
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1614
   Episode_Reward/foot_landing_vel: -0.1043
   Episode_Reward/test_gait_reward: -0.5344
Metrics/base_velocity/error_vel_xy: 1.5327
Metrics/base_velocity/error_vel_yaw: 0.5875
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 1.08s
                        Total time: 668.95s
                               ETA: 2595.3s

################################################################################
                     [1m Learning iteration 615/3000 [0m                      

                       Computation: 91102 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 1.3551
                    Surrogate loss: -0.0012
             Mean action noise std: 0.7151
                     Learning rate: 0.0009
                       Mean reward: 47.17
               Mean episode length: 597.96
       Episode_Reward/keep_balance: 0.6024
     Episode_Reward/rew_lin_vel_xy: 1.9558
      Episode_Reward/rew_ang_vel_z: 1.7587
    Episode_Reward/pen_base_height: -0.2758
      Episode_Reward/pen_lin_vel_z: -0.0558
     Episode_Reward/pen_ang_vel_xy: -0.0851
   Episode_Reward/pen_joint_torque: -0.1341
    Episode_Reward/pen_joint_accel: -0.0683
    Episode_Reward/pen_action_rate: -0.0472
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0276
   Episode_Reward/pen_joint_powers: -0.0439
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0960
Episode_Reward/pen_flat_orientation: -0.1659
  Episode_Reward/pen_feet_distance: -0.0025
Episode_Reward/pen_feet_regulation: -0.1763
   Episode_Reward/foot_landing_vel: -0.1117
   Episode_Reward/test_gait_reward: -0.5577
Metrics/base_velocity/error_vel_xy: 1.7135
Metrics/base_velocity/error_vel_yaw: 0.5856
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 1.08s
                        Total time: 670.03s
                               ETA: 2594.2s

################################################################################
                     [1m Learning iteration 616/3000 [0m                      

                       Computation: 90624 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 1.1925
                    Surrogate loss: -0.0003
             Mean action noise std: 0.7169
                     Learning rate: 0.0009
                       Mean reward: 47.98
               Mean episode length: 618.69
       Episode_Reward/keep_balance: 0.5670
     Episode_Reward/rew_lin_vel_xy: 1.7296
      Episode_Reward/rew_ang_vel_z: 1.6395
    Episode_Reward/pen_base_height: -0.2713
      Episode_Reward/pen_lin_vel_z: -0.0536
     Episode_Reward/pen_ang_vel_xy: -0.0835
   Episode_Reward/pen_joint_torque: -0.1243
    Episode_Reward/pen_joint_accel: -0.0716
    Episode_Reward/pen_action_rate: -0.0440
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0269
   Episode_Reward/pen_joint_powers: -0.0421
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0905
Episode_Reward/pen_flat_orientation: -0.1673
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.1672
   Episode_Reward/foot_landing_vel: -0.1026
   Episode_Reward/test_gait_reward: -0.5271
Metrics/base_velocity/error_vel_xy: 1.6573
Metrics/base_velocity/error_vel_yaw: 0.5680
      Episode_Termination/time_out: 2.6667
  Episode_Termination/base_contact: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 1.08s
                        Total time: 671.11s
                               ETA: 2593.1s

################################################################################
                     [1m Learning iteration 617/3000 [0m                      

                       Computation: 90484 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 1.0666
                    Surrogate loss: 0.0015
             Mean action noise std: 0.7179
                     Learning rate: 0.0003
                       Mean reward: 42.97
               Mean episode length: 534.49
       Episode_Reward/keep_balance: 0.5551
     Episode_Reward/rew_lin_vel_xy: 1.6451
      Episode_Reward/rew_ang_vel_z: 1.6127
    Episode_Reward/pen_base_height: -0.2647
      Episode_Reward/pen_lin_vel_z: -0.0495
     Episode_Reward/pen_ang_vel_xy: -0.0782
   Episode_Reward/pen_joint_torque: -0.1222
    Episode_Reward/pen_joint_accel: -0.0628
    Episode_Reward/pen_action_rate: -0.0431
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0250
   Episode_Reward/pen_joint_powers: -0.0401
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0889
Episode_Reward/pen_flat_orientation: -0.1497
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1533
   Episode_Reward/foot_landing_vel: -0.0960
   Episode_Reward/test_gait_reward: -0.5112
Metrics/base_velocity/error_vel_xy: 1.6346
Metrics/base_velocity/error_vel_yaw: 0.5456
      Episode_Termination/time_out: 2.7917
  Episode_Termination/base_contact: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 1.09s
                        Total time: 672.20s
                               ETA: 2592.0s

################################################################################
                     [1m Learning iteration 618/3000 [0m                      

                       Computation: 89893 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.9826
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7182
                     Learning rate: 0.0004
                       Mean reward: 40.75
               Mean episode length: 541.75
       Episode_Reward/keep_balance: 0.5101
     Episode_Reward/rew_lin_vel_xy: 1.5035
      Episode_Reward/rew_ang_vel_z: 1.4656
    Episode_Reward/pen_base_height: -0.2478
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.0727
   Episode_Reward/pen_joint_torque: -0.1059
    Episode_Reward/pen_joint_accel: -0.0560
    Episode_Reward/pen_action_rate: -0.0396
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0219
   Episode_Reward/pen_joint_powers: -0.0348
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0825
Episode_Reward/pen_flat_orientation: -0.1376
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.1330
   Episode_Reward/foot_landing_vel: -0.0830
   Episode_Reward/test_gait_reward: -0.4686
Metrics/base_velocity/error_vel_xy: 1.5562
Metrics/base_velocity/error_vel_yaw: 0.5144
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 1.09s
                        Total time: 673.29s
                               ETA: 2590.9s

################################################################################
                     [1m Learning iteration 619/3000 [0m                      

                       Computation: 90608 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 1.0257
                    Surrogate loss: -0.0024
             Mean action noise std: 0.7195
                     Learning rate: 0.0006
                       Mean reward: 46.55
               Mean episode length: 565.07
       Episode_Reward/keep_balance: 0.5519
     Episode_Reward/rew_lin_vel_xy: 1.6964
      Episode_Reward/rew_ang_vel_z: 1.5978
    Episode_Reward/pen_base_height: -0.2675
      Episode_Reward/pen_lin_vel_z: -0.0517
     Episode_Reward/pen_ang_vel_xy: -0.0805
   Episode_Reward/pen_joint_torque: -0.1211
    Episode_Reward/pen_joint_accel: -0.0702
    Episode_Reward/pen_action_rate: -0.0433
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0255
   Episode_Reward/pen_joint_powers: -0.0403
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0895
Episode_Reward/pen_flat_orientation: -0.1515
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1582
   Episode_Reward/foot_landing_vel: -0.0978
   Episode_Reward/test_gait_reward: -0.5143
Metrics/base_velocity/error_vel_xy: 1.5843
Metrics/base_velocity/error_vel_yaw: 0.5475
      Episode_Termination/time_out: 2.5417
  Episode_Termination/base_contact: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 1.08s
                        Total time: 674.38s
                               ETA: 2589.8s

################################################################################
                     [1m Learning iteration 620/3000 [0m                      

                       Computation: 90315 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 1.0998
                    Surrogate loss: 0.0012
             Mean action noise std: 0.7207
                     Learning rate: 0.0003
                       Mean reward: 37.68
               Mean episode length: 499.30
       Episode_Reward/keep_balance: 0.4980
     Episode_Reward/rew_lin_vel_xy: 1.4933
      Episode_Reward/rew_ang_vel_z: 1.4300
    Episode_Reward/pen_base_height: -0.2502
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.0724
   Episode_Reward/pen_joint_torque: -0.1061
    Episode_Reward/pen_joint_accel: -0.0549
    Episode_Reward/pen_action_rate: -0.0385
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0221
   Episode_Reward/pen_joint_powers: -0.0352
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0808
Episode_Reward/pen_flat_orientation: -0.1406
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1327
   Episode_Reward/foot_landing_vel: -0.0840
   Episode_Reward/test_gait_reward: -0.4592
Metrics/base_velocity/error_vel_xy: 1.4125
Metrics/base_velocity/error_vel_yaw: 0.5056
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 1.09s
                        Total time: 675.46s
                               ETA: 2588.7s

################################################################################
                     [1m Learning iteration 621/3000 [0m                      

                       Computation: 88425 steps/s (collection: 0.989s, learning 0.123s)
               Value function loss: 1.0325
                    Surrogate loss: -0.0023
             Mean action noise std: 0.7217
                     Learning rate: 0.0006
                       Mean reward: 38.04
               Mean episode length: 518.90
       Episode_Reward/keep_balance: 0.5364
     Episode_Reward/rew_lin_vel_xy: 1.6683
      Episode_Reward/rew_ang_vel_z: 1.5347
    Episode_Reward/pen_base_height: -0.2672
      Episode_Reward/pen_lin_vel_z: -0.0496
     Episode_Reward/pen_ang_vel_xy: -0.0794
   Episode_Reward/pen_joint_torque: -0.1175
    Episode_Reward/pen_joint_accel: -0.0685
    Episode_Reward/pen_action_rate: -0.0424
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0252
   Episode_Reward/pen_joint_powers: -0.0395
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0878
Episode_Reward/pen_flat_orientation: -0.1486
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1566
   Episode_Reward/foot_landing_vel: -0.0976
   Episode_Reward/test_gait_reward: -0.4972
Metrics/base_velocity/error_vel_xy: 1.5109
Metrics/base_velocity/error_vel_yaw: 0.5447
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 1.11s
                        Total time: 676.58s
                               ETA: 2587.7s

################################################################################
                     [1m Learning iteration 622/3000 [0m                      

                       Computation: 89689 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.9888
                    Surrogate loss: 0.0005
             Mean action noise std: 0.7224
                     Learning rate: 0.0001
                       Mean reward: 45.93
               Mean episode length: 594.45
       Episode_Reward/keep_balance: 0.5635
     Episode_Reward/rew_lin_vel_xy: 1.6626
      Episode_Reward/rew_ang_vel_z: 1.6130
    Episode_Reward/pen_base_height: -0.2654
      Episode_Reward/pen_lin_vel_z: -0.0514
     Episode_Reward/pen_ang_vel_xy: -0.0811
   Episode_Reward/pen_joint_torque: -0.1223
    Episode_Reward/pen_joint_accel: -0.0635
    Episode_Reward/pen_action_rate: -0.0443
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0253
   Episode_Reward/pen_joint_powers: -0.0405
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0925
Episode_Reward/pen_flat_orientation: -0.1459
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1535
   Episode_Reward/foot_landing_vel: -0.0997
   Episode_Reward/test_gait_reward: -0.5192
Metrics/base_velocity/error_vel_xy: 1.6943
Metrics/base_velocity/error_vel_yaw: 0.5751
      Episode_Termination/time_out: 2.8750
  Episode_Termination/base_contact: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 1.10s
                        Total time: 677.67s
                               ETA: 2586.7s

################################################################################
                     [1m Learning iteration 623/3000 [0m                      

                       Computation: 91529 steps/s (collection: 0.950s, learning 0.124s)
               Value function loss: 1.1161
                    Surrogate loss: 0.0022
             Mean action noise std: 0.7225
                     Learning rate: 0.0001
                       Mean reward: 41.74
               Mean episode length: 581.07
       Episode_Reward/keep_balance: 0.5572
     Episode_Reward/rew_lin_vel_xy: 1.5840
      Episode_Reward/rew_ang_vel_z: 1.5770
    Episode_Reward/pen_base_height: -0.2577
      Episode_Reward/pen_lin_vel_z: -0.0527
     Episode_Reward/pen_ang_vel_xy: -0.0837
   Episode_Reward/pen_joint_torque: -0.1228
    Episode_Reward/pen_joint_accel: -0.0709
    Episode_Reward/pen_action_rate: -0.0446
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0263
   Episode_Reward/pen_joint_powers: -0.0413
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0925
Episode_Reward/pen_flat_orientation: -0.1500
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1606
   Episode_Reward/foot_landing_vel: -0.1038
   Episode_Reward/test_gait_reward: -0.5163
Metrics/base_velocity/error_vel_xy: 1.7085
Metrics/base_velocity/error_vel_yaw: 0.5786
      Episode_Termination/time_out: 2.8333
  Episode_Termination/base_contact: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 1.07s
                        Total time: 678.75s
                               ETA: 2585.5s

################################################################################
                     [1m Learning iteration 624/3000 [0m                      

                       Computation: 90120 steps/s (collection: 0.964s, learning 0.127s)
               Value function loss: 1.0593
                    Surrogate loss: 0.0033
             Mean action noise std: 0.7226
                     Learning rate: 0.0000
                       Mean reward: 42.44
               Mean episode length: 565.29
       Episode_Reward/keep_balance: 0.5618
     Episode_Reward/rew_lin_vel_xy: 1.6628
      Episode_Reward/rew_ang_vel_z: 1.6158
    Episode_Reward/pen_base_height: -0.2711
      Episode_Reward/pen_lin_vel_z: -0.0514
     Episode_Reward/pen_ang_vel_xy: -0.0818
   Episode_Reward/pen_joint_torque: -0.1214
    Episode_Reward/pen_joint_accel: -0.0660
    Episode_Reward/pen_action_rate: -0.0447
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0260
   Episode_Reward/pen_joint_powers: -0.0409
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0927
Episode_Reward/pen_flat_orientation: -0.1447
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1573
   Episode_Reward/foot_landing_vel: -0.1029
   Episode_Reward/test_gait_reward: -0.5219
Metrics/base_velocity/error_vel_xy: 1.6525
Metrics/base_velocity/error_vel_yaw: 0.5692
      Episode_Termination/time_out: 2.7083
  Episode_Termination/base_contact: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 1.09s
                        Total time: 679.84s
                               ETA: 2584.5s

################################################################################
                     [1m Learning iteration 625/3000 [0m                      

                       Computation: 89502 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 1.0487
                    Surrogate loss: -0.0007
             Mean action noise std: 0.7223
                     Learning rate: 0.0001
                       Mean reward: 40.25
               Mean episode length: 537.26
       Episode_Reward/keep_balance: 0.5372
     Episode_Reward/rew_lin_vel_xy: 1.5934
      Episode_Reward/rew_ang_vel_z: 1.5417
    Episode_Reward/pen_base_height: -0.2658
      Episode_Reward/pen_lin_vel_z: -0.0473
     Episode_Reward/pen_ang_vel_xy: -0.0783
   Episode_Reward/pen_joint_torque: -0.1162
    Episode_Reward/pen_joint_accel: -0.0637
    Episode_Reward/pen_action_rate: -0.0423
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0244
   Episode_Reward/pen_joint_powers: -0.0384
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0884
Episode_Reward/pen_flat_orientation: -0.1368
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1493
   Episode_Reward/foot_landing_vel: -0.0944
   Episode_Reward/test_gait_reward: -0.4968
Metrics/base_velocity/error_vel_xy: 1.5859
Metrics/base_velocity/error_vel_yaw: 0.5435
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 1.10s
                        Total time: 680.94s
                               ETA: 2583.4s

################################################################################
                     [1m Learning iteration 626/3000 [0m                      

                       Computation: 90996 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 1.0246
                    Surrogate loss: -0.0028
             Mean action noise std: 0.7214
                     Learning rate: 0.0003
                       Mean reward: 45.49
               Mean episode length: 571.46
       Episode_Reward/keep_balance: 0.5655
     Episode_Reward/rew_lin_vel_xy: 1.7390
      Episode_Reward/rew_ang_vel_z: 1.6229
    Episode_Reward/pen_base_height: -0.2729
      Episode_Reward/pen_lin_vel_z: -0.0508
     Episode_Reward/pen_ang_vel_xy: -0.0805
   Episode_Reward/pen_joint_torque: -0.1245
    Episode_Reward/pen_joint_accel: -0.0646
    Episode_Reward/pen_action_rate: -0.0445
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0255
   Episode_Reward/pen_joint_powers: -0.0408
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0926
Episode_Reward/pen_flat_orientation: -0.1407
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1560
   Episode_Reward/foot_landing_vel: -0.0952
   Episode_Reward/test_gait_reward: -0.5215
Metrics/base_velocity/error_vel_xy: 1.5998
Metrics/base_velocity/error_vel_yaw: 0.5711
      Episode_Termination/time_out: 2.7083
  Episode_Termination/base_contact: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 1.08s
                        Total time: 682.02s
                               ETA: 2582.3s

################################################################################
                     [1m Learning iteration 627/3000 [0m                      

                       Computation: 90434 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 1.0477
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7219
                     Learning rate: 0.0004
                       Mean reward: 42.13
               Mean episode length: 617.60
       Episode_Reward/keep_balance: 0.5811
     Episode_Reward/rew_lin_vel_xy: 1.6698
      Episode_Reward/rew_ang_vel_z: 1.6484
    Episode_Reward/pen_base_height: -0.2798
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.0861
   Episode_Reward/pen_joint_torque: -0.1318
    Episode_Reward/pen_joint_accel: -0.0684
    Episode_Reward/pen_action_rate: -0.0463
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0278
   Episode_Reward/pen_joint_powers: -0.0435
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0964
Episode_Reward/pen_flat_orientation: -0.1515
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1683
   Episode_Reward/foot_landing_vel: -0.1053
   Episode_Reward/test_gait_reward: -0.5408
Metrics/base_velocity/error_vel_xy: 1.7455
Metrics/base_velocity/error_vel_yaw: 0.6055
      Episode_Termination/time_out: 2.1667
  Episode_Termination/base_contact: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 1.09s
                        Total time: 683.10s
                               ETA: 2581.2s

################################################################################
                     [1m Learning iteration 628/3000 [0m                      

                       Computation: 91243 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 1.0464
                    Surrogate loss: -0.0022
             Mean action noise std: 0.7227
                     Learning rate: 0.0006
                       Mean reward: 41.37
               Mean episode length: 577.21
       Episode_Reward/keep_balance: 0.5642
     Episode_Reward/rew_lin_vel_xy: 1.6944
      Episode_Reward/rew_ang_vel_z: 1.5966
    Episode_Reward/pen_base_height: -0.2680
      Episode_Reward/pen_lin_vel_z: -0.0529
     Episode_Reward/pen_ang_vel_xy: -0.0821
   Episode_Reward/pen_joint_torque: -0.1211
    Episode_Reward/pen_joint_accel: -0.0739
    Episode_Reward/pen_action_rate: -0.0456
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0274
   Episode_Reward/pen_joint_powers: -0.0417
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0948
Episode_Reward/pen_flat_orientation: -0.1443
  Episode_Reward/pen_feet_distance: -0.0005
Episode_Reward/pen_feet_regulation: -0.1694
   Episode_Reward/foot_landing_vel: -0.1097
   Episode_Reward/test_gait_reward: -0.5248
Metrics/base_velocity/error_vel_xy: 1.7225
Metrics/base_velocity/error_vel_yaw: 0.5894
      Episode_Termination/time_out: 2.6667
  Episode_Termination/base_contact: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 1.08s
                        Total time: 684.18s
                               ETA: 2580.1s

################################################################################
                     [1m Learning iteration 629/3000 [0m                      

                       Computation: 91351 steps/s (collection: 0.955s, learning 0.121s)
               Value function loss: 1.1906
                    Surrogate loss: -0.0026
             Mean action noise std: 0.7229
                     Learning rate: 0.0009
                       Mean reward: 40.56
               Mean episode length: 534.71
       Episode_Reward/keep_balance: 0.5423
     Episode_Reward/rew_lin_vel_xy: 1.7349
      Episode_Reward/rew_ang_vel_z: 1.5264
    Episode_Reward/pen_base_height: -0.2728
      Episode_Reward/pen_lin_vel_z: -0.0533
     Episode_Reward/pen_ang_vel_xy: -0.0826
   Episode_Reward/pen_joint_torque: -0.1239
    Episode_Reward/pen_joint_accel: -0.0690
    Episode_Reward/pen_action_rate: -0.0440
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0270
   Episode_Reward/pen_joint_powers: -0.0418
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0911
Episode_Reward/pen_flat_orientation: -0.1420
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1680
   Episode_Reward/foot_landing_vel: -0.1092
   Episode_Reward/test_gait_reward: -0.5085
Metrics/base_velocity/error_vel_xy: 1.5146
Metrics/base_velocity/error_vel_yaw: 0.5715
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 1.08s
                        Total time: 685.26s
                               ETA: 2579.0s

################################################################################
                     [1m Learning iteration 630/3000 [0m                      

                       Computation: 90589 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.9332
                    Surrogate loss: -0.0029
             Mean action noise std: 0.7234
                     Learning rate: 0.0009
                       Mean reward: 40.26
               Mean episode length: 550.31
       Episode_Reward/keep_balance: 0.5887
     Episode_Reward/rew_lin_vel_xy: 1.7296
      Episode_Reward/rew_ang_vel_z: 1.6781
    Episode_Reward/pen_base_height: -0.2867
      Episode_Reward/pen_lin_vel_z: -0.0551
     Episode_Reward/pen_ang_vel_xy: -0.0858
   Episode_Reward/pen_joint_torque: -0.1330
    Episode_Reward/pen_joint_accel: -0.0778
    Episode_Reward/pen_action_rate: -0.0470
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0285
   Episode_Reward/pen_joint_powers: -0.0445
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.0969
Episode_Reward/pen_flat_orientation: -0.1423
  Episode_Reward/pen_feet_distance: -0.0006
Episode_Reward/pen_feet_regulation: -0.1770
   Episode_Reward/foot_landing_vel: -0.1160
   Episode_Reward/test_gait_reward: -0.5449
Metrics/base_velocity/error_vel_xy: 1.7469
Metrics/base_velocity/error_vel_yaw: 0.6053
      Episode_Termination/time_out: 2.2083
  Episode_Termination/base_contact: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 1.09s
                        Total time: 686.34s
                               ETA: 2577.9s

################################################################################
                     [1m Learning iteration 631/3000 [0m                      

                       Computation: 90949 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 1.1167
                    Surrogate loss: -0.0004
             Mean action noise std: 0.7249
                     Learning rate: 0.0006
                       Mean reward: 37.14
               Mean episode length: 504.90
       Episode_Reward/keep_balance: 0.5193
     Episode_Reward/rew_lin_vel_xy: 1.5260
      Episode_Reward/rew_ang_vel_z: 1.4790
    Episode_Reward/pen_base_height: -0.2586
      Episode_Reward/pen_lin_vel_z: -0.0466
     Episode_Reward/pen_ang_vel_xy: -0.0740
   Episode_Reward/pen_joint_torque: -0.1143
    Episode_Reward/pen_joint_accel: -0.0603
    Episode_Reward/pen_action_rate: -0.0407
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0233
   Episode_Reward/pen_joint_powers: -0.0372
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0856
Episode_Reward/pen_flat_orientation: -0.1297
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1392
   Episode_Reward/foot_landing_vel: -0.0900
   Episode_Reward/test_gait_reward: -0.4775
Metrics/base_velocity/error_vel_xy: 1.5136
Metrics/base_velocity/error_vel_yaw: 0.5342
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 1.08s
                        Total time: 687.42s
                               ETA: 2576.7s

################################################################################
                     [1m Learning iteration 632/3000 [0m                      

                       Computation: 92087 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 1.0200
                    Surrogate loss: -0.0031
             Mean action noise std: 0.7245
                     Learning rate: 0.0006
                       Mean reward: 44.25
               Mean episode length: 559.97
       Episode_Reward/keep_balance: 0.5834
     Episode_Reward/rew_lin_vel_xy: 1.8393
      Episode_Reward/rew_ang_vel_z: 1.6795
    Episode_Reward/pen_base_height: -0.2755
      Episode_Reward/pen_lin_vel_z: -0.0550
     Episode_Reward/pen_ang_vel_xy: -0.0833
   Episode_Reward/pen_joint_torque: -0.1286
    Episode_Reward/pen_joint_accel: -0.0701
    Episode_Reward/pen_action_rate: -0.0460
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0272
   Episode_Reward/pen_joint_powers: -0.0430
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0953
Episode_Reward/pen_flat_orientation: -0.1396
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1674
   Episode_Reward/foot_landing_vel: -0.1106
   Episode_Reward/test_gait_reward: -0.5400
Metrics/base_velocity/error_vel_xy: 1.6369
Metrics/base_velocity/error_vel_yaw: 0.5846
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 1.07s
                        Total time: 688.49s
                               ETA: 2575.6s

################################################################################
                     [1m Learning iteration 633/3000 [0m                      

                       Computation: 91701 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 1.1610
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7246
                     Learning rate: 0.0006
                       Mean reward: 51.17
               Mean episode length: 661.18
       Episode_Reward/keep_balance: 0.5995
     Episode_Reward/rew_lin_vel_xy: 1.8930
      Episode_Reward/rew_ang_vel_z: 1.6936
    Episode_Reward/pen_base_height: -0.2912
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.0883
   Episode_Reward/pen_joint_torque: -0.1375
    Episode_Reward/pen_joint_accel: -0.0802
    Episode_Reward/pen_action_rate: -0.0483
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0298
   Episode_Reward/pen_joint_powers: -0.0462
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1000
Episode_Reward/pen_flat_orientation: -0.1448
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1879
   Episode_Reward/foot_landing_vel: -0.1181
   Episode_Reward/test_gait_reward: -0.5606
Metrics/base_velocity/error_vel_xy: 1.7053
Metrics/base_velocity/error_vel_yaw: 0.6275
      Episode_Termination/time_out: 2.9167
  Episode_Termination/base_contact: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 1.07s
                        Total time: 689.56s
                               ETA: 2574.4s

################################################################################
                     [1m Learning iteration 634/3000 [0m                      

                       Computation: 90268 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 1.1307
                    Surrogate loss: -0.0013
             Mean action noise std: 0.7238
                     Learning rate: 0.0009
                       Mean reward: 52.57
               Mean episode length: 653.12
       Episode_Reward/keep_balance: 0.6510
     Episode_Reward/rew_lin_vel_xy: 2.0330
      Episode_Reward/rew_ang_vel_z: 1.8748
    Episode_Reward/pen_base_height: -0.2909
      Episode_Reward/pen_lin_vel_z: -0.0594
     Episode_Reward/pen_ang_vel_xy: -0.0923
   Episode_Reward/pen_joint_torque: -0.1470
    Episode_Reward/pen_joint_accel: -0.0823
    Episode_Reward/pen_action_rate: -0.0525
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0316
   Episode_Reward/pen_joint_powers: -0.0492
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1087
Episode_Reward/pen_flat_orientation: -0.1407
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.1962
   Episode_Reward/foot_landing_vel: -0.1265
   Episode_Reward/test_gait_reward: -0.6019
Metrics/base_velocity/error_vel_xy: 1.8339
Metrics/base_velocity/error_vel_yaw: 0.6553
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 1.09s
                        Total time: 690.65s
                               ETA: 2573.4s

################################################################################
                     [1m Learning iteration 635/3000 [0m                      

                       Computation: 90161 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 1.1286
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7230
                     Learning rate: 0.0006
                       Mean reward: 44.91
               Mean episode length: 600.42
       Episode_Reward/keep_balance: 0.5879
     Episode_Reward/rew_lin_vel_xy: 1.7712
      Episode_Reward/rew_ang_vel_z: 1.6704
    Episode_Reward/pen_base_height: -0.2766
      Episode_Reward/pen_lin_vel_z: -0.0548
     Episode_Reward/pen_ang_vel_xy: -0.0829
   Episode_Reward/pen_joint_torque: -0.1327
    Episode_Reward/pen_joint_accel: -0.0754
    Episode_Reward/pen_action_rate: -0.0472
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0280
   Episode_Reward/pen_joint_powers: -0.0437
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0977
Episode_Reward/pen_flat_orientation: -0.1399
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.1716
   Episode_Reward/foot_landing_vel: -0.1151
   Episode_Reward/test_gait_reward: -0.5456
Metrics/base_velocity/error_vel_xy: 1.7516
Metrics/base_velocity/error_vel_yaw: 0.6040
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 1.09s
                        Total time: 691.74s
                               ETA: 2572.3s

################################################################################
                     [1m Learning iteration 636/3000 [0m                      

                       Computation: 91416 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 1.1193
                    Surrogate loss: 0.0010
             Mean action noise std: 0.7229
                     Learning rate: 0.0003
                       Mean reward: 42.83
               Mean episode length: 546.63
       Episode_Reward/keep_balance: 0.6101
     Episode_Reward/rew_lin_vel_xy: 2.0007
      Episode_Reward/rew_ang_vel_z: 1.7123
    Episode_Reward/pen_base_height: -0.2826
      Episode_Reward/pen_lin_vel_z: -0.0579
     Episode_Reward/pen_ang_vel_xy: -0.0869
   Episode_Reward/pen_joint_torque: -0.1329
    Episode_Reward/pen_joint_accel: -0.0729
    Episode_Reward/pen_action_rate: -0.0493
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0290
   Episode_Reward/pen_joint_powers: -0.0451
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1032
Episode_Reward/pen_flat_orientation: -0.1467
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.1796
   Episode_Reward/foot_landing_vel: -0.1177
   Episode_Reward/test_gait_reward: -0.5667
Metrics/base_velocity/error_vel_xy: 1.6361
Metrics/base_velocity/error_vel_yaw: 0.6440
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 1.08s
                        Total time: 692.82s
                               ETA: 2571.1s

################################################################################
                     [1m Learning iteration 637/3000 [0m                      

                       Computation: 91492 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 1.0333
                    Surrogate loss: -0.0019
             Mean action noise std: 0.7228
                     Learning rate: 0.0004
                       Mean reward: 39.39
               Mean episode length: 510.27
       Episode_Reward/keep_balance: 0.5422
     Episode_Reward/rew_lin_vel_xy: 1.6835
      Episode_Reward/rew_ang_vel_z: 1.5405
    Episode_Reward/pen_base_height: -0.2691
      Episode_Reward/pen_lin_vel_z: -0.0465
     Episode_Reward/pen_ang_vel_xy: -0.0762
   Episode_Reward/pen_joint_torque: -0.1145
    Episode_Reward/pen_joint_accel: -0.0604
    Episode_Reward/pen_action_rate: -0.0427
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0245
   Episode_Reward/pen_joint_powers: -0.0383
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0907
Episode_Reward/pen_flat_orientation: -0.1264
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.1453
   Episode_Reward/foot_landing_vel: -0.0950
   Episode_Reward/test_gait_reward: -0.4994
Metrics/base_velocity/error_vel_xy: 1.5238
Metrics/base_velocity/error_vel_yaw: 0.5602
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 1.07s
                        Total time: 693.89s
                               ETA: 2570.0s

################################################################################
                     [1m Learning iteration 638/3000 [0m                      

                       Computation: 90419 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 1.0352
                    Surrogate loss: -0.0011
             Mean action noise std: 0.7234
                     Learning rate: 0.0004
                       Mean reward: 50.38
               Mean episode length: 624.51
       Episode_Reward/keep_balance: 0.6096
     Episode_Reward/rew_lin_vel_xy: 1.9794
      Episode_Reward/rew_ang_vel_z: 1.7315
    Episode_Reward/pen_base_height: -0.2819
      Episode_Reward/pen_lin_vel_z: -0.0528
     Episode_Reward/pen_ang_vel_xy: -0.0837
   Episode_Reward/pen_joint_torque: -0.1316
    Episode_Reward/pen_joint_accel: -0.0766
    Episode_Reward/pen_action_rate: -0.0485
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0287
   Episode_Reward/pen_joint_powers: -0.0442
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1018
Episode_Reward/pen_flat_orientation: -0.1291
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.1743
   Episode_Reward/foot_landing_vel: -0.1152
   Episode_Reward/test_gait_reward: -0.5610
Metrics/base_velocity/error_vel_xy: 1.6488
Metrics/base_velocity/error_vel_yaw: 0.6298
      Episode_Termination/time_out: 2.6667
  Episode_Termination/base_contact: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 1.09s
                        Total time: 694.98s
                               ETA: 2568.9s

################################################################################
                     [1m Learning iteration 639/3000 [0m                      

                       Computation: 91228 steps/s (collection: 0.956s, learning 0.121s)
               Value function loss: 1.1369
                    Surrogate loss: 0.0010
             Mean action noise std: 0.7242
                     Learning rate: 0.0002
                       Mean reward: 52.24
               Mean episode length: 661.38
       Episode_Reward/keep_balance: 0.6614
     Episode_Reward/rew_lin_vel_xy: 2.1268
      Episode_Reward/rew_ang_vel_z: 1.8834
    Episode_Reward/pen_base_height: -0.2963
      Episode_Reward/pen_lin_vel_z: -0.0590
     Episode_Reward/pen_ang_vel_xy: -0.0897
   Episode_Reward/pen_joint_torque: -0.1455
    Episode_Reward/pen_joint_accel: -0.0801
    Episode_Reward/pen_action_rate: -0.0528
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0313
   Episode_Reward/pen_joint_powers: -0.0485
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1102
Episode_Reward/pen_flat_orientation: -0.1437
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.1908
   Episode_Reward/foot_landing_vel: -0.1265
   Episode_Reward/test_gait_reward: -0.6133
Metrics/base_velocity/error_vel_xy: 1.8275
Metrics/base_velocity/error_vel_yaw: 0.6764
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 1.08s
                        Total time: 696.06s
                               ETA: 2567.8s

################################################################################
                     [1m Learning iteration 640/3000 [0m                      

                       Computation: 91198 steps/s (collection: 0.957s, learning 0.121s)
               Value function loss: 1.0811
                    Surrogate loss: -0.0025
             Mean action noise std: 0.7252
                     Learning rate: 0.0004
                       Mean reward: 49.15
               Mean episode length: 598.84
       Episode_Reward/keep_balance: 0.5969
     Episode_Reward/rew_lin_vel_xy: 2.0302
      Episode_Reward/rew_ang_vel_z: 1.6890
    Episode_Reward/pen_base_height: -0.2859
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.0846
   Episode_Reward/pen_joint_torque: -0.1299
    Episode_Reward/pen_joint_accel: -0.0741
    Episode_Reward/pen_action_rate: -0.0478
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0286
   Episode_Reward/pen_joint_powers: -0.0439
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.1005
Episode_Reward/pen_flat_orientation: -0.1325
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.1763
   Episode_Reward/foot_landing_vel: -0.1143
   Episode_Reward/test_gait_reward: -0.5544
Metrics/base_velocity/error_vel_xy: 1.5482
Metrics/base_velocity/error_vel_yaw: 0.6197
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 1.08s
                        Total time: 697.13s
                               ETA: 2566.7s

################################################################################
                     [1m Learning iteration 641/3000 [0m                      

                       Computation: 90402 steps/s (collection: 0.966s, learning 0.121s)
               Value function loss: 0.9905
                    Surrogate loss: 0.0009
             Mean action noise std: 0.7259
                     Learning rate: 0.0002
                       Mean reward: 41.87
               Mean episode length: 532.59
       Episode_Reward/keep_balance: 0.5485
     Episode_Reward/rew_lin_vel_xy: 1.7487
      Episode_Reward/rew_ang_vel_z: 1.5403
    Episode_Reward/pen_base_height: -0.2722
      Episode_Reward/pen_lin_vel_z: -0.0506
     Episode_Reward/pen_ang_vel_xy: -0.0793
   Episode_Reward/pen_joint_torque: -0.1231
    Episode_Reward/pen_joint_accel: -0.0710
    Episode_Reward/pen_action_rate: -0.0444
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0268
   Episode_Reward/pen_joint_powers: -0.0412
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.0932
Episode_Reward/pen_flat_orientation: -0.1304
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1624
   Episode_Reward/foot_landing_vel: -0.1099
   Episode_Reward/test_gait_reward: -0.5112
Metrics/base_velocity/error_vel_xy: 1.5278
Metrics/base_velocity/error_vel_yaw: 0.5820
      Episode_Termination/time_out: 2.3333
  Episode_Termination/base_contact: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 1.09s
                        Total time: 698.22s
                               ETA: 2565.6s

################################################################################
                     [1m Learning iteration 642/3000 [0m                      

                       Computation: 90597 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 1.1243
                    Surrogate loss: -0.0011
             Mean action noise std: 0.7265
                     Learning rate: 0.0003
                       Mean reward: 46.85
               Mean episode length: 583.57
       Episode_Reward/keep_balance: 0.5709
     Episode_Reward/rew_lin_vel_xy: 1.7438
      Episode_Reward/rew_ang_vel_z: 1.6193
    Episode_Reward/pen_base_height: -0.2682
      Episode_Reward/pen_lin_vel_z: -0.0510
     Episode_Reward/pen_ang_vel_xy: -0.0812
   Episode_Reward/pen_joint_torque: -0.1245
    Episode_Reward/pen_joint_accel: -0.0670
    Episode_Reward/pen_action_rate: -0.0459
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0272
   Episode_Reward/pen_joint_powers: -0.0418
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0965
Episode_Reward/pen_flat_orientation: -0.1352
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.1624
   Episode_Reward/foot_landing_vel: -0.1082
   Episode_Reward/test_gait_reward: -0.5291
Metrics/base_velocity/error_vel_xy: 1.6870
Metrics/base_velocity/error_vel_yaw: 0.5923
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 1.09s
                        Total time: 699.31s
                               ETA: 2564.5s

################################################################################
                     [1m Learning iteration 643/3000 [0m                      

                       Computation: 90939 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 1.1230
                    Surrogate loss: -0.0021
             Mean action noise std: 0.7274
                     Learning rate: 0.0003
                       Mean reward: 52.68
               Mean episode length: 669.08
       Episode_Reward/keep_balance: 0.6460
     Episode_Reward/rew_lin_vel_xy: 2.0255
      Episode_Reward/rew_ang_vel_z: 1.8162
    Episode_Reward/pen_base_height: -0.2972
      Episode_Reward/pen_lin_vel_z: -0.0587
     Episode_Reward/pen_ang_vel_xy: -0.0888
   Episode_Reward/pen_joint_torque: -0.1460
    Episode_Reward/pen_joint_accel: -0.0799
    Episode_Reward/pen_action_rate: -0.0521
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0312
   Episode_Reward/pen_joint_powers: -0.0490
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1091
Episode_Reward/pen_flat_orientation: -0.1352
  Episode_Reward/pen_feet_distance: -0.0007
Episode_Reward/pen_feet_regulation: -0.1938
   Episode_Reward/foot_landing_vel: -0.1262
   Episode_Reward/test_gait_reward: -0.6011
Metrics/base_velocity/error_vel_xy: 1.7827
Metrics/base_velocity/error_vel_yaw: 0.6798
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 1.08s
                        Total time: 700.39s
                               ETA: 2563.4s

################################################################################
                     [1m Learning iteration 644/3000 [0m                      

                       Computation: 90202 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 1.1175
                    Surrogate loss: -0.0036
             Mean action noise std: 0.7288
                     Learning rate: 0.0006
                       Mean reward: 48.76
               Mean episode length: 605.89
       Episode_Reward/keep_balance: 0.6036
     Episode_Reward/rew_lin_vel_xy: 1.8551
      Episode_Reward/rew_ang_vel_z: 1.7131
    Episode_Reward/pen_base_height: -0.2733
      Episode_Reward/pen_lin_vel_z: -0.0508
     Episode_Reward/pen_ang_vel_xy: -0.0823
   Episode_Reward/pen_joint_torque: -0.1276
    Episode_Reward/pen_joint_accel: -0.0742
    Episode_Reward/pen_action_rate: -0.0486
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0280
   Episode_Reward/pen_joint_powers: -0.0429
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1028
Episode_Reward/pen_flat_orientation: -0.1202
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.1620
   Episode_Reward/foot_landing_vel: -0.1163
   Episode_Reward/test_gait_reward: -0.5530
Metrics/base_velocity/error_vel_xy: 1.6869
Metrics/base_velocity/error_vel_yaw: 0.6224
      Episode_Termination/time_out: 2.4167
  Episode_Termination/base_contact: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 1.09s
                        Total time: 701.48s
                               ETA: 2562.3s

################################################################################
                     [1m Learning iteration 645/3000 [0m                      

                       Computation: 91211 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.2014
                    Surrogate loss: 0.0014
             Mean action noise std: 0.7296
                     Learning rate: 0.0001
                       Mean reward: 40.31
               Mean episode length: 554.72
       Episode_Reward/keep_balance: 0.5788
     Episode_Reward/rew_lin_vel_xy: 1.6927
      Episode_Reward/rew_ang_vel_z: 1.6220
    Episode_Reward/pen_base_height: -0.2788
      Episode_Reward/pen_lin_vel_z: -0.0503
     Episode_Reward/pen_ang_vel_xy: -0.0804
   Episode_Reward/pen_joint_torque: -0.1263
    Episode_Reward/pen_joint_accel: -0.0732
    Episode_Reward/pen_action_rate: -0.0468
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0275
   Episode_Reward/pen_joint_powers: -0.0423
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0989
Episode_Reward/pen_flat_orientation: -0.1241
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.1678
   Episode_Reward/foot_landing_vel: -0.1162
   Episode_Reward/test_gait_reward: -0.5349
Metrics/base_velocity/error_vel_xy: 1.7237
Metrics/base_velocity/error_vel_yaw: 0.6193
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 1.08s
                        Total time: 702.55s
                               ETA: 2561.2s

################################################################################
                     [1m Learning iteration 646/3000 [0m                      

                       Computation: 91870 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 1.2371
                    Surrogate loss: 0.0050
             Mean action noise std: 0.7297
                     Learning rate: 0.0001
                       Mean reward: 52.38
               Mean episode length: 665.43
       Episode_Reward/keep_balance: 0.6386
     Episode_Reward/rew_lin_vel_xy: 1.9668
      Episode_Reward/rew_ang_vel_z: 1.8070
    Episode_Reward/pen_base_height: -0.2895
      Episode_Reward/pen_lin_vel_z: -0.0546
     Episode_Reward/pen_ang_vel_xy: -0.0906
   Episode_Reward/pen_joint_torque: -0.1361
    Episode_Reward/pen_joint_accel: -0.0818
    Episode_Reward/pen_action_rate: -0.0518
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0297
   Episode_Reward/pen_joint_powers: -0.0459
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1086
Episode_Reward/pen_flat_orientation: -0.1336
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1748
   Episode_Reward/foot_landing_vel: -0.1224
   Episode_Reward/test_gait_reward: -0.5860
Metrics/base_velocity/error_vel_xy: 1.8379
Metrics/base_velocity/error_vel_yaw: 0.6648
      Episode_Termination/time_out: 2.5417
  Episode_Termination/base_contact: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 1.07s
                        Total time: 703.62s
                               ETA: 2560.0s

################################################################################
                     [1m Learning iteration 647/3000 [0m                      

                       Computation: 92485 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 1.1804
                    Surrogate loss: -0.0029
             Mean action noise std: 0.7300
                     Learning rate: 0.0003
                       Mean reward: 57.19
               Mean episode length: 722.60
       Episode_Reward/keep_balance: 0.7235
     Episode_Reward/rew_lin_vel_xy: 2.2342
      Episode_Reward/rew_ang_vel_z: 2.0533
    Episode_Reward/pen_base_height: -0.3025
      Episode_Reward/pen_lin_vel_z: -0.0650
     Episode_Reward/pen_ang_vel_xy: -0.0988
   Episode_Reward/pen_joint_torque: -0.1665
    Episode_Reward/pen_joint_accel: -0.0911
    Episode_Reward/pen_action_rate: -0.0590
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0346
   Episode_Reward/pen_joint_powers: -0.0544
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1231
Episode_Reward/pen_flat_orientation: -0.1391
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.2050
   Episode_Reward/foot_landing_vel: -0.1496
   Episode_Reward/test_gait_reward: -0.6692
Metrics/base_velocity/error_vel_xy: 2.0443
Metrics/base_velocity/error_vel_yaw: 0.7504
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 1.06s
                        Total time: 704.69s
                               ETA: 2558.8s

################################################################################
                     [1m Learning iteration 648/3000 [0m                      

                       Computation: 91215 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.1707
                    Surrogate loss: -0.0032
             Mean action noise std: 0.7314
                     Learning rate: 0.0006
                       Mean reward: 44.07
               Mean episode length: 581.48
       Episode_Reward/keep_balance: 0.6015
     Episode_Reward/rew_lin_vel_xy: 1.8591
      Episode_Reward/rew_ang_vel_z: 1.6951
    Episode_Reward/pen_base_height: -0.2781
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.0865
   Episode_Reward/pen_joint_torque: -0.1362
    Episode_Reward/pen_joint_accel: -0.0762
    Episode_Reward/pen_action_rate: -0.0492
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0292
   Episode_Reward/pen_joint_powers: -0.0454
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.1034
Episode_Reward/pen_flat_orientation: -0.1290
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.1768
   Episode_Reward/foot_landing_vel: -0.1225
   Episode_Reward/test_gait_reward: -0.5565
Metrics/base_velocity/error_vel_xy: 1.6929
Metrics/base_velocity/error_vel_yaw: 0.6312
      Episode_Termination/time_out: 2.2917
  Episode_Termination/base_contact: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 1.08s
                        Total time: 705.77s
                               ETA: 2557.7s

################################################################################
                     [1m Learning iteration 649/3000 [0m                      

                       Computation: 91276 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 1.2613
                    Surrogate loss: -0.0030
             Mean action noise std: 0.7321
                     Learning rate: 0.0006
                       Mean reward: 36.05
               Mean episode length: 487.89
       Episode_Reward/keep_balance: 0.5288
     Episode_Reward/rew_lin_vel_xy: 1.6809
      Episode_Reward/rew_ang_vel_z: 1.4790
    Episode_Reward/pen_base_height: -0.2648
      Episode_Reward/pen_lin_vel_z: -0.0477
     Episode_Reward/pen_ang_vel_xy: -0.0761
   Episode_Reward/pen_joint_torque: -0.1171
    Episode_Reward/pen_joint_accel: -0.0666
    Episode_Reward/pen_action_rate: -0.0427
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0254
   Episode_Reward/pen_joint_powers: -0.0392
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.0896
Episode_Reward/pen_flat_orientation: -0.1266
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.1486
   Episode_Reward/foot_landing_vel: -0.0989
   Episode_Reward/test_gait_reward: -0.4913
Metrics/base_velocity/error_vel_xy: 1.4600
Metrics/base_velocity/error_vel_yaw: 0.5691
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 1.08s
                        Total time: 706.84s
                               ETA: 2556.6s

################################################################################
                     [1m Learning iteration 650/3000 [0m                      

                       Computation: 91692 steps/s (collection: 0.951s, learning 0.121s)
               Value function loss: 1.1971
                    Surrogate loss: -0.0031
             Mean action noise std: 0.7332
                     Learning rate: 0.0006
                       Mean reward: 50.19
               Mean episode length: 642.93
       Episode_Reward/keep_balance: 0.6519
     Episode_Reward/rew_lin_vel_xy: 2.0296
      Episode_Reward/rew_ang_vel_z: 1.8387
    Episode_Reward/pen_base_height: -0.2827
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.0880
   Episode_Reward/pen_joint_torque: -0.1395
    Episode_Reward/pen_joint_accel: -0.0840
    Episode_Reward/pen_action_rate: -0.0526
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0300
   Episode_Reward/pen_joint_powers: -0.0462
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1115
Episode_Reward/pen_flat_orientation: -0.1261
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1670
   Episode_Reward/foot_landing_vel: -0.1264
   Episode_Reward/test_gait_reward: -0.5949
Metrics/base_velocity/error_vel_xy: 1.8503
Metrics/base_velocity/error_vel_yaw: 0.6831
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 1.07s
                        Total time: 707.91s
                               ETA: 2555.5s

################################################################################
                     [1m Learning iteration 651/3000 [0m                      

                       Computation: 91536 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.4134
                    Surrogate loss: -0.0039
             Mean action noise std: 0.7339
                     Learning rate: 0.0009
                       Mean reward: 51.92
               Mean episode length: 650.39
       Episode_Reward/keep_balance: 0.6438
     Episode_Reward/rew_lin_vel_xy: 2.0306
      Episode_Reward/rew_ang_vel_z: 1.8309
    Episode_Reward/pen_base_height: -0.2904
      Episode_Reward/pen_lin_vel_z: -0.0548
     Episode_Reward/pen_ang_vel_xy: -0.0883
   Episode_Reward/pen_joint_torque: -0.1385
    Episode_Reward/pen_joint_accel: -0.0721
    Episode_Reward/pen_action_rate: -0.0521
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0293
   Episode_Reward/pen_joint_powers: -0.0462
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1103
Episode_Reward/pen_flat_orientation: -0.1299
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.1712
   Episode_Reward/foot_landing_vel: -0.1213
   Episode_Reward/test_gait_reward: -0.5922
Metrics/base_velocity/error_vel_xy: 1.7697
Metrics/base_velocity/error_vel_yaw: 0.6634
      Episode_Termination/time_out: 2.5417
  Episode_Termination/base_contact: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 1.07s
                        Total time: 708.99s
                               ETA: 2554.3s

################################################################################
                     [1m Learning iteration 652/3000 [0m                      

                       Computation: 91117 steps/s (collection: 0.958s, learning 0.121s)
               Value function loss: 1.4765
                    Surrogate loss: -0.0022
             Mean action noise std: 0.7346
                     Learning rate: 0.0009
                       Mean reward: 48.25
               Mean episode length: 650.69
       Episode_Reward/keep_balance: 0.6624
     Episode_Reward/rew_lin_vel_xy: 2.0052
      Episode_Reward/rew_ang_vel_z: 1.8869
    Episode_Reward/pen_base_height: -0.2980
      Episode_Reward/pen_lin_vel_z: -0.0584
     Episode_Reward/pen_ang_vel_xy: -0.0936
   Episode_Reward/pen_joint_torque: -0.1423
    Episode_Reward/pen_joint_accel: -0.0898
    Episode_Reward/pen_action_rate: -0.0538
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0317
   Episode_Reward/pen_joint_powers: -0.0486
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1127
Episode_Reward/pen_flat_orientation: -0.1379
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.1859
   Episode_Reward/foot_landing_vel: -0.1325
   Episode_Reward/test_gait_reward: -0.6129
Metrics/base_velocity/error_vel_xy: 1.8884
Metrics/base_velocity/error_vel_yaw: 0.6861
      Episode_Termination/time_out: 2.4583
  Episode_Termination/base_contact: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 1.08s
                        Total time: 710.07s
                               ETA: 2553.2s

################################################################################
                     [1m Learning iteration 653/3000 [0m                      

                       Computation: 91453 steps/s (collection: 0.954s, learning 0.121s)
               Value function loss: 1.3889
                    Surrogate loss: -0.0022
             Mean action noise std: 0.7363
                     Learning rate: 0.0009
                       Mean reward: 46.12
               Mean episode length: 598.95
       Episode_Reward/keep_balance: 0.6429
     Episode_Reward/rew_lin_vel_xy: 1.9933
      Episode_Reward/rew_ang_vel_z: 1.8210
    Episode_Reward/pen_base_height: -0.2882
      Episode_Reward/pen_lin_vel_z: -0.0578
     Episode_Reward/pen_ang_vel_xy: -0.0884
   Episode_Reward/pen_joint_torque: -0.1441
    Episode_Reward/pen_joint_accel: -0.0826
    Episode_Reward/pen_action_rate: -0.0521
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0310
   Episode_Reward/pen_joint_powers: -0.0481
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1087
Episode_Reward/pen_flat_orientation: -0.1317
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.1828
   Episode_Reward/foot_landing_vel: -0.1289
   Episode_Reward/test_gait_reward: -0.5965
Metrics/base_velocity/error_vel_xy: 1.8290
Metrics/base_velocity/error_vel_yaw: 0.6694
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 1.07s
                        Total time: 711.14s
                               ETA: 2552.1s

################################################################################
                     [1m Learning iteration 654/3000 [0m                      

                       Computation: 91174 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.4385
                    Surrogate loss: -0.0029
             Mean action noise std: 0.7372
                     Learning rate: 0.0013
                       Mean reward: 51.60
               Mean episode length: 638.30
       Episode_Reward/keep_balance: 0.6176
     Episode_Reward/rew_lin_vel_xy: 1.9566
      Episode_Reward/rew_ang_vel_z: 1.7416
    Episode_Reward/pen_base_height: -0.2791
      Episode_Reward/pen_lin_vel_z: -0.0569
     Episode_Reward/pen_ang_vel_xy: -0.0878
   Episode_Reward/pen_joint_torque: -0.1379
    Episode_Reward/pen_joint_accel: -0.0825
    Episode_Reward/pen_action_rate: -0.0505
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0298
   Episode_Reward/pen_joint_powers: -0.0464
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1048
Episode_Reward/pen_flat_orientation: -0.1297
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.1803
   Episode_Reward/foot_landing_vel: -0.1244
   Episode_Reward/test_gait_reward: -0.5756
Metrics/base_velocity/error_vel_xy: 1.7594
Metrics/base_velocity/error_vel_yaw: 0.6508
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 1.08s
                        Total time: 712.22s
                               ETA: 2550.9s

################################################################################
                     [1m Learning iteration 655/3000 [0m                      

                       Computation: 91667 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 1.3252
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7398
                     Learning rate: 0.0006
                       Mean reward: 60.84
               Mean episode length: 741.93
       Episode_Reward/keep_balance: 0.7009
     Episode_Reward/rew_lin_vel_xy: 2.2858
      Episode_Reward/rew_ang_vel_z: 1.9676
    Episode_Reward/pen_base_height: -0.3018
      Episode_Reward/pen_lin_vel_z: -0.0638
     Episode_Reward/pen_ang_vel_xy: -0.0974
   Episode_Reward/pen_joint_torque: -0.1625
    Episode_Reward/pen_joint_accel: -0.0854
    Episode_Reward/pen_action_rate: -0.0579
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0348
   Episode_Reward/pen_joint_powers: -0.0539
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1219
Episode_Reward/pen_flat_orientation: -0.1470
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2085
   Episode_Reward/foot_landing_vel: -0.1389
   Episode_Reward/test_gait_reward: -0.6489
Metrics/base_velocity/error_vel_xy: 1.9161
Metrics/base_velocity/error_vel_yaw: 0.7451
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 1.07s
                        Total time: 713.29s
                               ETA: 2549.8s

################################################################################
                     [1m Learning iteration 656/3000 [0m                      

                       Computation: 92336 steps/s (collection: 0.943s, learning 0.121s)
               Value function loss: 1.2825
                    Surrogate loss: -0.0032
             Mean action noise std: 0.7396
                     Learning rate: 0.0009
                       Mean reward: 55.73
               Mean episode length: 700.37
       Episode_Reward/keep_balance: 0.6540
     Episode_Reward/rew_lin_vel_xy: 2.0889
      Episode_Reward/rew_ang_vel_z: 1.8382
    Episode_Reward/pen_base_height: -0.2969
      Episode_Reward/pen_lin_vel_z: -0.0583
     Episode_Reward/pen_ang_vel_xy: -0.0907
   Episode_Reward/pen_joint_torque: -0.1427
    Episode_Reward/pen_joint_accel: -0.0829
    Episode_Reward/pen_action_rate: -0.0535
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0317
   Episode_Reward/pen_joint_powers: -0.0481
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.1120
Episode_Reward/pen_flat_orientation: -0.1339
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.1918
   Episode_Reward/foot_landing_vel: -0.1248
   Episode_Reward/test_gait_reward: -0.6074
Metrics/base_velocity/error_vel_xy: 1.7962
Metrics/base_velocity/error_vel_yaw: 0.7001
      Episode_Termination/time_out: 2.9167
  Episode_Termination/base_contact: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 1.06s
                        Total time: 714.36s
                               ETA: 2548.6s

################################################################################
                     [1m Learning iteration 657/3000 [0m                      

                       Computation: 91535 steps/s (collection: 0.953s, learning 0.121s)
               Value function loss: 1.2404
                    Surrogate loss: -0.0036
             Mean action noise std: 0.7402
                     Learning rate: 0.0009
                       Mean reward: 63.11
               Mean episode length: 762.84
       Episode_Reward/keep_balance: 0.7467
     Episode_Reward/rew_lin_vel_xy: 2.5325
      Episode_Reward/rew_ang_vel_z: 2.1086
    Episode_Reward/pen_base_height: -0.3108
      Episode_Reward/pen_lin_vel_z: -0.0665
     Episode_Reward/pen_ang_vel_xy: -0.1048
   Episode_Reward/pen_joint_torque: -0.1683
    Episode_Reward/pen_joint_accel: -0.0942
    Episode_Reward/pen_action_rate: -0.0611
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0363
   Episode_Reward/pen_joint_powers: -0.0566
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.1277
Episode_Reward/pen_flat_orientation: -0.1428
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2172
   Episode_Reward/foot_landing_vel: -0.1472
   Episode_Reward/test_gait_reward: -0.6900
Metrics/base_velocity/error_vel_xy: 1.9771
Metrics/base_velocity/error_vel_yaw: 0.7849
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 1.07s
                        Total time: 715.43s
                               ETA: 2547.5s

################################################################################
                     [1m Learning iteration 658/3000 [0m                      

                       Computation: 92275 steps/s (collection: 0.944s, learning 0.121s)
               Value function loss: 1.2153
                    Surrogate loss: -0.0010
             Mean action noise std: 0.7420
                     Learning rate: 0.0004
                       Mean reward: 66.71
               Mean episode length: 788.14
       Episode_Reward/keep_balance: 0.7639
     Episode_Reward/rew_lin_vel_xy: 2.5315
      Episode_Reward/rew_ang_vel_z: 2.1633
    Episode_Reward/pen_base_height: -0.3150
      Episode_Reward/pen_lin_vel_z: -0.0672
     Episode_Reward/pen_ang_vel_xy: -0.1021
   Episode_Reward/pen_joint_torque: -0.1713
    Episode_Reward/pen_joint_accel: -0.1015
    Episode_Reward/pen_action_rate: -0.0624
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0369
   Episode_Reward/pen_joint_powers: -0.0574
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1304
Episode_Reward/pen_flat_orientation: -0.1436
  Episode_Reward/pen_feet_distance: -0.0029
Episode_Reward/pen_feet_regulation: -0.2217
   Episode_Reward/foot_landing_vel: -0.1511
   Episode_Reward/test_gait_reward: -0.7089
Metrics/base_velocity/error_vel_xy: 2.0780
Metrics/base_velocity/error_vel_yaw: 0.7957
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 1.07s
                        Total time: 716.50s
                               ETA: 2546.3s

################################################################################
                     [1m Learning iteration 659/3000 [0m                      

                       Computation: 91902 steps/s (collection: 0.949s, learning 0.121s)
               Value function loss: 1.1659
                    Surrogate loss: -0.0006
             Mean action noise std: 0.7420
                     Learning rate: 0.0001
                       Mean reward: 56.29
               Mean episode length: 693.25
       Episode_Reward/keep_balance: 0.7100
     Episode_Reward/rew_lin_vel_xy: 2.3023
      Episode_Reward/rew_ang_vel_z: 2.0172
    Episode_Reward/pen_base_height: -0.3045
      Episode_Reward/pen_lin_vel_z: -0.0593
     Episode_Reward/pen_ang_vel_xy: -0.0961
   Episode_Reward/pen_joint_torque: -0.1574
    Episode_Reward/pen_joint_accel: -0.0868
    Episode_Reward/pen_action_rate: -0.0578
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0335
   Episode_Reward/pen_joint_powers: -0.0523
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.1213
Episode_Reward/pen_flat_orientation: -0.1296
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.1997
   Episode_Reward/foot_landing_vel: -0.1323
   Episode_Reward/test_gait_reward: -0.6521
Metrics/base_velocity/error_vel_xy: 1.9917
Metrics/base_velocity/error_vel_yaw: 0.7345
      Episode_Termination/time_out: 2.7500
  Episode_Termination/base_contact: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 1.07s
                        Total time: 717.57s
                               ETA: 2545.2s

################################################################################
                     [1m Learning iteration 660/3000 [0m                      

                       Computation: 91706 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 1.0823
                    Surrogate loss: -0.0036
             Mean action noise std: 0.7421
                     Learning rate: 0.0003
                       Mean reward: 58.24
               Mean episode length: 711.93
       Episode_Reward/keep_balance: 0.7607
     Episode_Reward/rew_lin_vel_xy: 2.4815
      Episode_Reward/rew_ang_vel_z: 2.1288
    Episode_Reward/pen_base_height: -0.3022
      Episode_Reward/pen_lin_vel_z: -0.0605
     Episode_Reward/pen_ang_vel_xy: -0.0975
   Episode_Reward/pen_joint_torque: -0.1622
    Episode_Reward/pen_joint_accel: -0.0967
    Episode_Reward/pen_action_rate: -0.0617
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0346
   Episode_Reward/pen_joint_powers: -0.0538
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1311
Episode_Reward/pen_flat_orientation: -0.1329
  Episode_Reward/pen_feet_distance: -0.0037
Episode_Reward/pen_feet_regulation: -0.1985
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.6955
Metrics/base_velocity/error_vel_xy: 2.0564
Metrics/base_velocity/error_vel_yaw: 0.8111
      Episode_Termination/time_out: 2.8750
  Episode_Termination/base_contact: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 1.07s
                        Total time: 718.64s
                               ETA: 2544.0s

################################################################################
                     [1m Learning iteration 661/3000 [0m                      

                       Computation: 92489 steps/s (collection: 0.942s, learning 0.121s)
               Value function loss: 1.1071
                    Surrogate loss: -0.0016
             Mean action noise std: 0.7421
                     Learning rate: 0.0002
                       Mean reward: 60.86
               Mean episode length: 793.94
       Episode_Reward/keep_balance: 0.7695
     Episode_Reward/rew_lin_vel_xy: 2.2991
      Episode_Reward/rew_ang_vel_z: 2.1443
    Episode_Reward/pen_base_height: -0.3081
      Episode_Reward/pen_lin_vel_z: -0.0633
     Episode_Reward/pen_ang_vel_xy: -0.1006
   Episode_Reward/pen_joint_torque: -0.1698
    Episode_Reward/pen_joint_accel: -0.0982
    Episode_Reward/pen_action_rate: -0.0635
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0357
   Episode_Reward/pen_joint_powers: -0.0560
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.1345
Episode_Reward/pen_flat_orientation: -0.1354
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2164
   Episode_Reward/foot_landing_vel: -0.1395
   Episode_Reward/test_gait_reward: -0.7074
Metrics/base_velocity/error_vel_xy: 2.2560
Metrics/base_velocity/error_vel_yaw: 0.8261
      Episode_Termination/time_out: 2.9167
  Episode_Termination/base_contact: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 1.06s
                        Total time: 719.70s
                               ETA: 2542.9s

################################################################################
                     [1m Learning iteration 662/3000 [0m                      

                       Computation: 91931 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 1.0847
                    Surrogate loss: -0.0030
             Mean action noise std: 0.7430
                     Learning rate: 0.0003
                       Mean reward: 65.99
               Mean episode length: 776.58
       Episode_Reward/keep_balance: 0.7716
     Episode_Reward/rew_lin_vel_xy: 2.5470
      Episode_Reward/rew_ang_vel_z: 2.1838
    Episode_Reward/pen_base_height: -0.3131
      Episode_Reward/pen_lin_vel_z: -0.0659
     Episode_Reward/pen_ang_vel_xy: -0.1016
   Episode_Reward/pen_joint_torque: -0.1700
    Episode_Reward/pen_joint_accel: -0.0867
    Episode_Reward/pen_action_rate: -0.0632
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0363
   Episode_Reward/pen_joint_powers: -0.0572
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1324
Episode_Reward/pen_flat_orientation: -0.1308
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2170
   Episode_Reward/foot_landing_vel: -0.1487
   Episode_Reward/test_gait_reward: -0.7100
Metrics/base_velocity/error_vel_xy: 2.0779
Metrics/base_velocity/error_vel_yaw: 0.8021
      Episode_Termination/time_out: 3.1250
  Episode_Termination/base_contact: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 1.07s
                        Total time: 720.77s
                               ETA: 2541.7s

################################################################################
                     [1m Learning iteration 663/3000 [0m                      

                       Computation: 87870 steps/s (collection: 0.995s, learning 0.124s)
               Value function loss: 1.0351
                    Surrogate loss: -0.0020
             Mean action noise std: 0.7443
                     Learning rate: 0.0006
                       Mean reward: 65.11
               Mean episode length: 786.37
       Episode_Reward/keep_balance: 0.7786
     Episode_Reward/rew_lin_vel_xy: 2.5520
      Episode_Reward/rew_ang_vel_z: 2.1806
    Episode_Reward/pen_base_height: -0.3171
      Episode_Reward/pen_lin_vel_z: -0.0644
     Episode_Reward/pen_ang_vel_xy: -0.1058
   Episode_Reward/pen_joint_torque: -0.1751
    Episode_Reward/pen_joint_accel: -0.0981
    Episode_Reward/pen_action_rate: -0.0641
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0377
   Episode_Reward/pen_joint_powers: -0.0579
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.1355
Episode_Reward/pen_flat_orientation: -0.1435
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2233
   Episode_Reward/foot_landing_vel: -0.1539
   Episode_Reward/test_gait_reward: -0.7157
Metrics/base_velocity/error_vel_xy: 2.1906
Metrics/base_velocity/error_vel_yaw: 0.8276
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 1.12s
                        Total time: 721.89s
                               ETA: 2540.7s

################################################################################
                     [1m Learning iteration 664/3000 [0m                      

                       Computation: 93405 steps/s (collection: 0.929s, learning 0.124s)
               Value function loss: 1.0867
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7442
                     Learning rate: 0.0004
                       Mean reward: 61.45
               Mean episode length: 759.23
       Episode_Reward/keep_balance: 0.7585
     Episode_Reward/rew_lin_vel_xy: 2.4993
      Episode_Reward/rew_ang_vel_z: 2.0819
    Episode_Reward/pen_base_height: -0.2977
      Episode_Reward/pen_lin_vel_z: -0.0639
     Episode_Reward/pen_ang_vel_xy: -0.1037
   Episode_Reward/pen_joint_torque: -0.1691
    Episode_Reward/pen_joint_accel: -0.0923
    Episode_Reward/pen_action_rate: -0.0636
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0363
   Episode_Reward/pen_joint_powers: -0.0562
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1345
Episode_Reward/pen_flat_orientation: -0.1489
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2224
   Episode_Reward/foot_landing_vel: -0.1464
   Episode_Reward/test_gait_reward: -0.6974
Metrics/base_velocity/error_vel_xy: 2.0035
Metrics/base_velocity/error_vel_yaw: 0.8379
      Episode_Termination/time_out: 2.7917
  Episode_Termination/base_contact: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 1.05s
                        Total time: 722.94s
                               ETA: 2539.5s

################################################################################
                     [1m Learning iteration 665/3000 [0m                      

                       Computation: 92197 steps/s (collection: 0.945s, learning 0.121s)
               Value function loss: 1.0032
                    Surrogate loss: -0.0022
             Mean action noise std: 0.7435
                     Learning rate: 0.0004
                       Mean reward: 69.02
               Mean episode length: 798.39
       Episode_Reward/keep_balance: 0.8049
     Episode_Reward/rew_lin_vel_xy: 2.7712
      Episode_Reward/rew_ang_vel_z: 2.2714
    Episode_Reward/pen_base_height: -0.3168
      Episode_Reward/pen_lin_vel_z: -0.0693
     Episode_Reward/pen_ang_vel_xy: -0.1083
   Episode_Reward/pen_joint_torque: -0.1814
    Episode_Reward/pen_joint_accel: -0.1029
    Episode_Reward/pen_action_rate: -0.0664
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0388
   Episode_Reward/pen_joint_powers: -0.0605
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1389
Episode_Reward/pen_flat_orientation: -0.1403
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.2330
   Episode_Reward/foot_landing_vel: -0.1552
   Episode_Reward/test_gait_reward: -0.7484
Metrics/base_velocity/error_vel_xy: 2.1571
Metrics/base_velocity/error_vel_yaw: 0.8404
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 1.07s
                        Total time: 724.01s
                               ETA: 2538.4s

################################################################################
                     [1m Learning iteration 666/3000 [0m                      

                       Computation: 92471 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 1.1926
                    Surrogate loss: -0.0004
             Mean action noise std: 0.7440
                     Learning rate: 0.0002
                       Mean reward: 68.24
               Mean episode length: 820.59
       Episode_Reward/keep_balance: 0.8332
     Episode_Reward/rew_lin_vel_xy: 2.7021
      Episode_Reward/rew_ang_vel_z: 2.3432
    Episode_Reward/pen_base_height: -0.3223
      Episode_Reward/pen_lin_vel_z: -0.0696
     Episode_Reward/pen_ang_vel_xy: -0.1097
   Episode_Reward/pen_joint_torque: -0.1881
    Episode_Reward/pen_joint_accel: -0.1044
    Episode_Reward/pen_action_rate: -0.0689
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0390
   Episode_Reward/pen_joint_powers: -0.0618
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1440
Episode_Reward/pen_flat_orientation: -0.1341
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2296
   Episode_Reward/foot_landing_vel: -0.1640
   Episode_Reward/test_gait_reward: -0.7699
Metrics/base_velocity/error_vel_xy: 2.2472
Metrics/base_velocity/error_vel_yaw: 0.8814
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 1.06s
                        Total time: 725.07s
                               ETA: 2537.2s

################################################################################
                     [1m Learning iteration 667/3000 [0m                      

                       Computation: 91033 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.9983
                    Surrogate loss: -0.0035
             Mean action noise std: 0.7454
                     Learning rate: 0.0004
                       Mean reward: 71.29
               Mean episode length: 822.28
       Episode_Reward/keep_balance: 0.8353
     Episode_Reward/rew_lin_vel_xy: 2.7497
      Episode_Reward/rew_ang_vel_z: 2.3634
    Episode_Reward/pen_base_height: -0.3189
      Episode_Reward/pen_lin_vel_z: -0.0664
     Episode_Reward/pen_ang_vel_xy: -0.1110
   Episode_Reward/pen_joint_torque: -0.1840
    Episode_Reward/pen_joint_accel: -0.0965
    Episode_Reward/pen_action_rate: -0.0687
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0380
   Episode_Reward/pen_joint_powers: -0.0608
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1448
Episode_Reward/pen_flat_orientation: -0.1344
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2313
   Episode_Reward/foot_landing_vel: -0.1467
   Episode_Reward/test_gait_reward: -0.7634
Metrics/base_velocity/error_vel_xy: 2.2523
Metrics/base_velocity/error_vel_yaw: 0.8731
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 1.08s
                        Total time: 726.15s
                               ETA: 2536.1s

################################################################################
                     [1m Learning iteration 668/3000 [0m                      

                       Computation: 91239 steps/s (collection: 0.950s, learning 0.128s)
               Value function loss: 1.0517
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7467
                     Learning rate: 0.0004
                       Mean reward: 72.86
               Mean episode length: 820.78
       Episode_Reward/keep_balance: 0.8194
     Episode_Reward/rew_lin_vel_xy: 2.8987
      Episode_Reward/rew_ang_vel_z: 2.2968
    Episode_Reward/pen_base_height: -0.3179
      Episode_Reward/pen_lin_vel_z: -0.0651
     Episode_Reward/pen_ang_vel_xy: -0.1098
   Episode_Reward/pen_joint_torque: -0.1766
    Episode_Reward/pen_joint_accel: -0.0997
    Episode_Reward/pen_action_rate: -0.0678
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0367
   Episode_Reward/pen_joint_powers: -0.0582
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1438
Episode_Reward/pen_flat_orientation: -0.1362
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.2090
   Episode_Reward/foot_landing_vel: -0.1429
   Episode_Reward/test_gait_reward: -0.7472
Metrics/base_velocity/error_vel_xy: 2.0561
Metrics/base_velocity/error_vel_yaw: 0.8717
      Episode_Termination/time_out: 3.0000
  Episode_Termination/base_contact: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 1.08s
                        Total time: 727.23s
                               ETA: 2535.0s

################################################################################
                     [1m Learning iteration 669/3000 [0m                      

                       Computation: 92578 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 1.0603
                    Surrogate loss: -0.0006
             Mean action noise std: 0.7472
                     Learning rate: 0.0004
                       Mean reward: 65.42
               Mean episode length: 766.84
       Episode_Reward/keep_balance: 0.7532
     Episode_Reward/rew_lin_vel_xy: 2.3540
      Episode_Reward/rew_ang_vel_z: 2.1222
    Episode_Reward/pen_base_height: -0.3066
      Episode_Reward/pen_lin_vel_z: -0.0635
     Episode_Reward/pen_ang_vel_xy: -0.1020
   Episode_Reward/pen_joint_torque: -0.1703
    Episode_Reward/pen_joint_accel: -0.0908
    Episode_Reward/pen_action_rate: -0.0621
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0359
   Episode_Reward/pen_joint_powers: -0.0556
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.1303
Episode_Reward/pen_flat_orientation: -0.1471
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2162
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.6994
Metrics/base_velocity/error_vel_xy: 2.1953
Metrics/base_velocity/error_vel_yaw: 0.7967
      Episode_Termination/time_out: 2.7083
  Episode_Termination/base_contact: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 1.06s
                        Total time: 728.29s
                               ETA: 2533.8s

################################################################################
                     [1m Learning iteration 670/3000 [0m                      

                       Computation: 91920 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 1.0752
                    Surrogate loss: 0.0014
             Mean action noise std: 0.7479
                     Learning rate: 0.0001
                       Mean reward: 69.63
               Mean episode length: 856.20
       Episode_Reward/keep_balance: 0.8701
     Episode_Reward/rew_lin_vel_xy: 2.8201
      Episode_Reward/rew_ang_vel_z: 2.4373
    Episode_Reward/pen_base_height: -0.3386
      Episode_Reward/pen_lin_vel_z: -0.0706
     Episode_Reward/pen_ang_vel_xy: -0.1195
   Episode_Reward/pen_joint_torque: -0.1934
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.0724
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0407
   Episode_Reward/pen_joint_powers: -0.0642
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.1517
Episode_Reward/pen_flat_orientation: -0.1528
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2491
   Episode_Reward/foot_landing_vel: -0.1634
   Episode_Reward/test_gait_reward: -0.8015
Metrics/base_velocity/error_vel_xy: 2.4365
Metrics/base_velocity/error_vel_yaw: 0.9273
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 1.07s
                        Total time: 729.36s
                               ETA: 2532.6s

################################################################################
                     [1m Learning iteration 671/3000 [0m                      

                       Computation: 92717 steps/s (collection: 0.938s, learning 0.122s)
               Value function loss: 1.0925
                    Surrogate loss: -0.0023
             Mean action noise std: 0.7486
                     Learning rate: 0.0001
                       Mean reward: 68.83
               Mean episode length: 836.52
       Episode_Reward/keep_balance: 0.8381
     Episode_Reward/rew_lin_vel_xy: 2.6366
      Episode_Reward/rew_ang_vel_z: 2.3559
    Episode_Reward/pen_base_height: -0.3142
      Episode_Reward/pen_lin_vel_z: -0.0683
     Episode_Reward/pen_ang_vel_xy: -0.1149
   Episode_Reward/pen_joint_torque: -0.1832
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.0706
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0392
   Episode_Reward/pen_joint_powers: -0.0612
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1484
Episode_Reward/pen_flat_orientation: -0.1348
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.2331
   Episode_Reward/foot_landing_vel: -0.1636
   Episode_Reward/test_gait_reward: -0.7684
Metrics/base_velocity/error_vel_xy: 2.3101
Metrics/base_velocity/error_vel_yaw: 0.8830
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 1.06s
                        Total time: 730.42s
                               ETA: 2531.5s

################################################################################
                     [1m Learning iteration 672/3000 [0m                      

                       Computation: 92191 steps/s (collection: 0.941s, learning 0.125s)
               Value function loss: 1.1561
                    Surrogate loss: -0.0040
             Mean action noise std: 0.7485
                     Learning rate: 0.0003
                       Mean reward: 70.24
               Mean episode length: 836.33
       Episode_Reward/keep_balance: 0.8509
     Episode_Reward/rew_lin_vel_xy: 2.8201
      Episode_Reward/rew_ang_vel_z: 2.3742
    Episode_Reward/pen_base_height: -0.3393
      Episode_Reward/pen_lin_vel_z: -0.0704
     Episode_Reward/pen_ang_vel_xy: -0.1151
   Episode_Reward/pen_joint_torque: -0.1943
    Episode_Reward/pen_joint_accel: -0.1044
    Episode_Reward/pen_action_rate: -0.0712
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0403
   Episode_Reward/pen_joint_powers: -0.0645
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1487
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2461
   Episode_Reward/foot_landing_vel: -0.1591
   Episode_Reward/test_gait_reward: -0.7836
Metrics/base_velocity/error_vel_xy: 2.2463
Metrics/base_velocity/error_vel_yaw: 0.9133
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 1.07s
                        Total time: 731.49s
                               ETA: 2530.3s

################################################################################
                     [1m Learning iteration 673/3000 [0m                      

                       Computation: 93068 steps/s (collection: 0.935s, learning 0.121s)
               Value function loss: 1.0743
                    Surrogate loss: -0.0006
             Mean action noise std: 0.7488
                     Learning rate: 0.0002
                       Mean reward: 67.34
               Mean episode length: 811.87
       Episode_Reward/keep_balance: 0.8016
     Episode_Reward/rew_lin_vel_xy: 2.7575
      Episode_Reward/rew_ang_vel_z: 2.2424
    Episode_Reward/pen_base_height: -0.3167
      Episode_Reward/pen_lin_vel_z: -0.0666
     Episode_Reward/pen_ang_vel_xy: -0.1137
   Episode_Reward/pen_joint_torque: -0.1788
    Episode_Reward/pen_joint_accel: -0.1013
    Episode_Reward/pen_action_rate: -0.0677
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0385
   Episode_Reward/pen_joint_powers: -0.0601
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1424
Episode_Reward/pen_flat_orientation: -0.1527
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2308
   Episode_Reward/foot_landing_vel: -0.1517
   Episode_Reward/test_gait_reward: -0.7417
Metrics/base_velocity/error_vel_xy: 2.0700
Metrics/base_velocity/error_vel_yaw: 0.8606
      Episode_Termination/time_out: 2.9583
  Episode_Termination/base_contact: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 1.06s
                        Total time: 732.54s
                               ETA: 2529.1s

################################################################################
                     [1m Learning iteration 674/3000 [0m                      

                       Computation: 92119 steps/s (collection: 0.946s, learning 0.121s)
               Value function loss: 1.0834
                    Surrogate loss: -0.0011
             Mean action noise std: 0.7487
                     Learning rate: 0.0001
                       Mean reward: 74.79
               Mean episode length: 868.20
       Episode_Reward/keep_balance: 0.8666
     Episode_Reward/rew_lin_vel_xy: 2.9736
      Episode_Reward/rew_ang_vel_z: 2.4096
    Episode_Reward/pen_base_height: -0.3290
      Episode_Reward/pen_lin_vel_z: -0.0727
     Episode_Reward/pen_ang_vel_xy: -0.1199
   Episode_Reward/pen_joint_torque: -0.1937
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.0730
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0653
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1530
Episode_Reward/pen_flat_orientation: -0.1550
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2591
   Episode_Reward/foot_landing_vel: -0.1644
   Episode_Reward/test_gait_reward: -0.7990
Metrics/base_velocity/error_vel_xy: 2.3163
Metrics/base_velocity/error_vel_yaw: 0.9351
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 1.07s
                        Total time: 733.61s
                               ETA: 2528.0s

################################################################################
                     [1m Learning iteration 675/3000 [0m                      

                       Computation: 93208 steps/s (collection: 0.934s, learning 0.121s)
               Value function loss: 1.1565
                    Surrogate loss: -0.0031
             Mean action noise std: 0.7481
                     Learning rate: 0.0002
                       Mean reward: 80.60
               Mean episode length: 901.28
       Episode_Reward/keep_balance: 0.8977
     Episode_Reward/rew_lin_vel_xy: 3.0822
      Episode_Reward/rew_ang_vel_z: 2.5385
    Episode_Reward/pen_base_height: -0.3242
      Episode_Reward/pen_lin_vel_z: -0.0688
     Episode_Reward/pen_ang_vel_xy: -0.1210
   Episode_Reward/pen_joint_torque: -0.1960
    Episode_Reward/pen_joint_accel: -0.1202
    Episode_Reward/pen_action_rate: -0.0753
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0648
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1584
Episode_Reward/pen_flat_orientation: -0.1402
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.2417
   Episode_Reward/foot_landing_vel: -0.1636
   Episode_Reward/test_gait_reward: -0.8196
Metrics/base_velocity/error_vel_xy: 2.3620
Metrics/base_velocity/error_vel_yaw: 0.9392
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 1.05s
                        Total time: 734.66s
                               ETA: 2526.8s

################################################################################
                     [1m Learning iteration 676/3000 [0m                      

                       Computation: 91601 steps/s (collection: 0.947s, learning 0.127s)
               Value function loss: 1.0940
                    Surrogate loss: -0.0037
             Mean action noise std: 0.7490
                     Learning rate: 0.0004
                       Mean reward: 74.16
               Mean episode length: 840.44
       Episode_Reward/keep_balance: 0.8760
     Episode_Reward/rew_lin_vel_xy: 3.0696
      Episode_Reward/rew_ang_vel_z: 2.4517
    Episode_Reward/pen_base_height: -0.3244
      Episode_Reward/pen_lin_vel_z: -0.0720
     Episode_Reward/pen_ang_vel_xy: -0.1212
   Episode_Reward/pen_joint_torque: -0.2049
    Episode_Reward/pen_joint_accel: -0.1167
    Episode_Reward/pen_action_rate: -0.0742
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0426
   Episode_Reward/pen_joint_powers: -0.0666
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1544
Episode_Reward/pen_flat_orientation: -0.1453
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2617
   Episode_Reward/foot_landing_vel: -0.1639
   Episode_Reward/test_gait_reward: -0.8110
Metrics/base_velocity/error_vel_xy: 2.3700
Metrics/base_velocity/error_vel_yaw: 0.9323
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 1.07s
                        Total time: 735.74s
                               ETA: 2525.6s

################################################################################
                     [1m Learning iteration 677/3000 [0m                      

                       Computation: 91823 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 1.0740
                    Surrogate loss: -0.0024
             Mean action noise std: 0.7503
                     Learning rate: 0.0004
                       Mean reward: 70.53
               Mean episode length: 851.96
       Episode_Reward/keep_balance: 0.8606
     Episode_Reward/rew_lin_vel_xy: 2.7847
      Episode_Reward/rew_ang_vel_z: 2.4249
    Episode_Reward/pen_base_height: -0.3061
      Episode_Reward/pen_lin_vel_z: -0.0693
     Episode_Reward/pen_ang_vel_xy: -0.1153
   Episode_Reward/pen_joint_torque: -0.1931
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.0726
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0401
   Episode_Reward/pen_joint_powers: -0.0630
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1519
Episode_Reward/pen_flat_orientation: -0.1487
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.2436
   Episode_Reward/foot_landing_vel: -0.1586
   Episode_Reward/test_gait_reward: -0.7897
Metrics/base_velocity/error_vel_xy: 2.3605
Metrics/base_velocity/error_vel_yaw: 0.9041
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 1.07s
                        Total time: 736.81s
                               ETA: 2524.5s

################################################################################
                     [1m Learning iteration 678/3000 [0m                      

                       Computation: 92641 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 1.0946
                    Surrogate loss: -0.0024
             Mean action noise std: 0.7511
                     Learning rate: 0.0006
                       Mean reward: 70.21
               Mean episode length: 832.61
       Episode_Reward/keep_balance: 0.8259
     Episode_Reward/rew_lin_vel_xy: 2.6886
      Episode_Reward/rew_ang_vel_z: 2.2788
    Episode_Reward/pen_base_height: -0.3107
      Episode_Reward/pen_lin_vel_z: -0.0658
     Episode_Reward/pen_ang_vel_xy: -0.1152
   Episode_Reward/pen_joint_torque: -0.1793
    Episode_Reward/pen_joint_accel: -0.1030
    Episode_Reward/pen_action_rate: -0.0708
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0386
   Episode_Reward/pen_joint_powers: -0.0601
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.1499
Episode_Reward/pen_flat_orientation: -0.1474
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2330
   Episode_Reward/foot_landing_vel: -0.1450
   Episode_Reward/test_gait_reward: -0.7575
Metrics/base_velocity/error_vel_xy: 2.2990
Metrics/base_velocity/error_vel_yaw: 0.9147
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 1.06s
                        Total time: 737.87s
                               ETA: 2523.3s

################################################################################
                     [1m Learning iteration 679/3000 [0m                      

                       Computation: 93879 steps/s (collection: 0.924s, learning 0.123s)
               Value function loss: 1.0967
                    Surrogate loss: -0.0033
             Mean action noise std: 0.7512
                     Learning rate: 0.0009
                       Mean reward: 77.24
               Mean episode length: 866.16
       Episode_Reward/keep_balance: 0.8635
     Episode_Reward/rew_lin_vel_xy: 2.8911
      Episode_Reward/rew_ang_vel_z: 2.4196
    Episode_Reward/pen_base_height: -0.3127
      Episode_Reward/pen_lin_vel_z: -0.0638
     Episode_Reward/pen_ang_vel_xy: -0.1158
   Episode_Reward/pen_joint_torque: -0.1813
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.0727
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0384
   Episode_Reward/pen_joint_powers: -0.0601
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1543
Episode_Reward/pen_flat_orientation: -0.1370
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.2306
   Episode_Reward/foot_landing_vel: -0.1456
   Episode_Reward/test_gait_reward: -0.7868
Metrics/base_velocity/error_vel_xy: 2.3474
Metrics/base_velocity/error_vel_yaw: 0.9209
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 1.05s
                        Total time: 738.92s
                               ETA: 2522.1s

################################################################################
                     [1m Learning iteration 680/3000 [0m                      

                       Computation: 92821 steps/s (collection: 0.938s, learning 0.121s)
               Value function loss: 1.1332
                    Surrogate loss: -0.0029
             Mean action noise std: 0.7516
                     Learning rate: 0.0013
                       Mean reward: 73.13
               Mean episode length: 842.32
       Episode_Reward/keep_balance: 0.8505
     Episode_Reward/rew_lin_vel_xy: 2.8443
      Episode_Reward/rew_ang_vel_z: 2.3872
    Episode_Reward/pen_base_height: -0.3113
      Episode_Reward/pen_lin_vel_z: -0.0640
     Episode_Reward/pen_ang_vel_xy: -0.1153
   Episode_Reward/pen_joint_torque: -0.1821
    Episode_Reward/pen_joint_accel: -0.0985
    Episode_Reward/pen_action_rate: -0.0727
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0377
   Episode_Reward/pen_joint_powers: -0.0598
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1537
Episode_Reward/pen_flat_orientation: -0.1381
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2241
   Episode_Reward/foot_landing_vel: -0.1421
   Episode_Reward/test_gait_reward: -0.7756
Metrics/base_velocity/error_vel_xy: 2.3296
Metrics/base_velocity/error_vel_yaw: 0.9068
      Episode_Termination/time_out: 2.9167
  Episode_Termination/base_contact: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 1.06s
                        Total time: 739.98s
                               ETA: 2520.9s

################################################################################
                     [1m Learning iteration 681/3000 [0m                      

                       Computation: 92226 steps/s (collection: 0.945s, learning 0.121s)
               Value function loss: 1.1816
                    Surrogate loss: 0.0001
             Mean action noise std: 0.7528
                     Learning rate: 0.0004
                       Mean reward: 80.02
               Mean episode length: 877.21
       Episode_Reward/keep_balance: 0.8808
     Episode_Reward/rew_lin_vel_xy: 3.1564
      Episode_Reward/rew_ang_vel_z: 2.4647
    Episode_Reward/pen_base_height: -0.3199
      Episode_Reward/pen_lin_vel_z: -0.0658
     Episode_Reward/pen_ang_vel_xy: -0.1163
   Episode_Reward/pen_joint_torque: -0.1886
    Episode_Reward/pen_joint_accel: -0.1005
    Episode_Reward/pen_action_rate: -0.0742
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0396
   Episode_Reward/pen_joint_powers: -0.0625
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1565
Episode_Reward/pen_flat_orientation: -0.1424
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2335
   Episode_Reward/foot_landing_vel: -0.1539
   Episode_Reward/test_gait_reward: -0.8089
Metrics/base_velocity/error_vel_xy: 2.1283
Metrics/base_velocity/error_vel_yaw: 0.9347
      Episode_Termination/time_out: 3.2500
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 1.07s
                        Total time: 741.04s
                               ETA: 2519.8s

################################################################################
                     [1m Learning iteration 682/3000 [0m                      

                       Computation: 93635 steps/s (collection: 0.929s, learning 0.121s)
               Value function loss: 1.2164
                    Surrogate loss: -0.0042
             Mean action noise std: 0.7542
                     Learning rate: 0.0009
                       Mean reward: 73.68
               Mean episode length: 863.82
       Episode_Reward/keep_balance: 0.8718
     Episode_Reward/rew_lin_vel_xy: 2.9029
      Episode_Reward/rew_ang_vel_z: 2.4158
    Episode_Reward/pen_base_height: -0.3194
      Episode_Reward/pen_lin_vel_z: -0.0642
     Episode_Reward/pen_ang_vel_xy: -0.1165
   Episode_Reward/pen_joint_torque: -0.1881
    Episode_Reward/pen_joint_accel: -0.1000
    Episode_Reward/pen_action_rate: -0.0741
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0399
   Episode_Reward/pen_joint_powers: -0.0625
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1557
Episode_Reward/pen_flat_orientation: -0.1411
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2467
   Episode_Reward/foot_landing_vel: -0.1555
   Episode_Reward/test_gait_reward: -0.8003
Metrics/base_velocity/error_vel_xy: 2.3900
Metrics/base_velocity/error_vel_yaw: 0.9441
      Episode_Termination/time_out: 3.0833
  Episode_Termination/base_contact: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 1.05s
                        Total time: 742.09s
                               ETA: 2518.5s

################################################################################
                     [1m Learning iteration 683/3000 [0m                      

                       Computation: 92763 steps/s (collection: 0.939s, learning 0.120s)
               Value function loss: 1.1680
                    Surrogate loss: -0.0015
             Mean action noise std: 0.7552
                     Learning rate: 0.0004
                       Mean reward: 73.74
               Mean episode length: 837.30
       Episode_Reward/keep_balance: 0.8237
     Episode_Reward/rew_lin_vel_xy: 2.8040
      Episode_Reward/rew_ang_vel_z: 2.2847
    Episode_Reward/pen_base_height: -0.3007
      Episode_Reward/pen_lin_vel_z: -0.0603
     Episode_Reward/pen_ang_vel_xy: -0.1172
   Episode_Reward/pen_joint_torque: -0.1749
    Episode_Reward/pen_joint_accel: -0.0962
    Episode_Reward/pen_action_rate: -0.0704
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0377
   Episode_Reward/pen_joint_powers: -0.0587
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1494
Episode_Reward/pen_flat_orientation: -0.1375
  Episode_Reward/pen_feet_distance: -0.0036
Episode_Reward/pen_feet_regulation: -0.2233
   Episode_Reward/foot_landing_vel: -0.1428
   Episode_Reward/test_gait_reward: -0.7566
Metrics/base_velocity/error_vel_xy: 2.1595
Metrics/base_velocity/error_vel_yaw: 0.8956
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 1.06s
                        Total time: 743.15s
                               ETA: 2517.4s

################################################################################
                     [1m Learning iteration 684/3000 [0m                      

                       Computation: 92953 steps/s (collection: 0.937s, learning 0.121s)
               Value function loss: 1.2297
                    Surrogate loss: -0.0008
             Mean action noise std: 0.7552
                     Learning rate: 0.0003
                       Mean reward: 81.22
               Mean episode length: 881.13
       Episode_Reward/keep_balance: 0.8801
     Episode_Reward/rew_lin_vel_xy: 3.0471
      Episode_Reward/rew_ang_vel_z: 2.4866
    Episode_Reward/pen_base_height: -0.3075
      Episode_Reward/pen_lin_vel_z: -0.0635
     Episode_Reward/pen_ang_vel_xy: -0.1174
   Episode_Reward/pen_joint_torque: -0.1861
    Episode_Reward/pen_joint_accel: -0.0947
    Episode_Reward/pen_action_rate: -0.0740
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0378
   Episode_Reward/pen_joint_powers: -0.0606
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1573
Episode_Reward/pen_flat_orientation: -0.1398
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2179
   Episode_Reward/foot_landing_vel: -0.1439
   Episode_Reward/test_gait_reward: -0.7960
Metrics/base_velocity/error_vel_xy: 2.2215
Metrics/base_velocity/error_vel_yaw: 0.9206
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 1.06s
                        Total time: 744.21s
                               ETA: 2516.2s

################################################################################
                     [1m Learning iteration 685/3000 [0m                      

                       Computation: 92855 steps/s (collection: 0.937s, learning 0.121s)
               Value function loss: 1.0291
                    Surrogate loss: -0.0043
             Mean action noise std: 0.7555
                     Learning rate: 0.0006
                       Mean reward: 69.74
               Mean episode length: 792.79
       Episode_Reward/keep_balance: 0.8150
     Episode_Reward/rew_lin_vel_xy: 2.8597
      Episode_Reward/rew_ang_vel_z: 2.2765
    Episode_Reward/pen_base_height: -0.3086
      Episode_Reward/pen_lin_vel_z: -0.0622
     Episode_Reward/pen_ang_vel_xy: -0.1180
   Episode_Reward/pen_joint_torque: -0.1716
    Episode_Reward/pen_joint_accel: -0.0998
    Episode_Reward/pen_action_rate: -0.0710
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0381
   Episode_Reward/pen_joint_powers: -0.0593
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1491
Episode_Reward/pen_flat_orientation: -0.1451
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2359
   Episode_Reward/foot_landing_vel: -0.1448
   Episode_Reward/test_gait_reward: -0.7513
Metrics/base_velocity/error_vel_xy: 2.0564
Metrics/base_velocity/error_vel_yaw: 0.8776
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 1.06s
                        Total time: 745.27s
                               ETA: 2515.0s

################################################################################
                     [1m Learning iteration 686/3000 [0m                      

                       Computation: 93531 steps/s (collection: 0.923s, learning 0.128s)
               Value function loss: 1.1545
                    Surrogate loss: -0.0024
             Mean action noise std: 0.7582
                     Learning rate: 0.0004
                       Mean reward: 70.57
               Mean episode length: 817.59
       Episode_Reward/keep_balance: 0.8331
     Episode_Reward/rew_lin_vel_xy: 2.8461
      Episode_Reward/rew_ang_vel_z: 2.2905
    Episode_Reward/pen_base_height: -0.3085
      Episode_Reward/pen_lin_vel_z: -0.0592
     Episode_Reward/pen_ang_vel_xy: -0.1164
   Episode_Reward/pen_joint_torque: -0.1752
    Episode_Reward/pen_joint_accel: -0.1012
    Episode_Reward/pen_action_rate: -0.0723
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0384
   Episode_Reward/pen_joint_powers: -0.0591
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1543
Episode_Reward/pen_flat_orientation: -0.1473
  Episode_Reward/pen_feet_distance: -0.0027
Episode_Reward/pen_feet_regulation: -0.2295
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.7612
Metrics/base_velocity/error_vel_xy: 2.1369
Metrics/base_velocity/error_vel_yaw: 0.9262
      Episode_Termination/time_out: 2.8750
  Episode_Termination/base_contact: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 1.05s
                        Total time: 746.32s
                               ETA: 2513.8s

################################################################################
                     [1m Learning iteration 687/3000 [0m                      

                       Computation: 93237 steps/s (collection: 0.932s, learning 0.122s)
               Value function loss: 1.1551
                    Surrogate loss: -0.0038
             Mean action noise std: 0.7601
                     Learning rate: 0.0006
                       Mean reward: 69.64
               Mean episode length: 803.29
       Episode_Reward/keep_balance: 0.8420
     Episode_Reward/rew_lin_vel_xy: 2.8537
      Episode_Reward/rew_ang_vel_z: 2.3425
    Episode_Reward/pen_base_height: -0.3112
      Episode_Reward/pen_lin_vel_z: -0.0601
     Episode_Reward/pen_ang_vel_xy: -0.1191
   Episode_Reward/pen_joint_torque: -0.1769
    Episode_Reward/pen_joint_accel: -0.0948
    Episode_Reward/pen_action_rate: -0.0722
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0369
   Episode_Reward/pen_joint_powers: -0.0589
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1525
Episode_Reward/pen_flat_orientation: -0.1348
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.2288
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.7688
Metrics/base_velocity/error_vel_xy: 2.2197
Metrics/base_velocity/error_vel_yaw: 0.9122
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 1.05s
                        Total time: 747.37s
                               ETA: 2512.6s

################################################################################
                     [1m Learning iteration 688/3000 [0m                      

                       Computation: 92525 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 1.1656
                    Surrogate loss: -0.0025
             Mean action noise std: 0.7609
                     Learning rate: 0.0006
                       Mean reward: 69.72
               Mean episode length: 796.10
       Episode_Reward/keep_balance: 0.7857
     Episode_Reward/rew_lin_vel_xy: 2.7846
      Episode_Reward/rew_ang_vel_z: 2.1633
    Episode_Reward/pen_base_height: -0.3005
      Episode_Reward/pen_lin_vel_z: -0.0616
     Episode_Reward/pen_ang_vel_xy: -0.1167
   Episode_Reward/pen_joint_torque: -0.1734
    Episode_Reward/pen_joint_accel: -0.0984
    Episode_Reward/pen_action_rate: -0.0688
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0378
   Episode_Reward/pen_joint_powers: -0.0582
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1441
Episode_Reward/pen_flat_orientation: -0.1513
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2319
   Episode_Reward/foot_landing_vel: -0.1461
   Episode_Reward/test_gait_reward: -0.7295
Metrics/base_velocity/error_vel_xy: 2.0246
Metrics/base_velocity/error_vel_yaw: 0.8735
      Episode_Termination/time_out: 2.8750
  Episode_Termination/base_contact: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 1.06s
                        Total time: 748.43s
                               ETA: 2511.4s

################################################################################
                     [1m Learning iteration 689/3000 [0m                      

                       Computation: 93936 steps/s (collection: 0.923s, learning 0.124s)
               Value function loss: 1.0970
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7610
                     Learning rate: 0.0006
                       Mean reward: 72.24
               Mean episode length: 859.18
       Episode_Reward/keep_balance: 0.8767
     Episode_Reward/rew_lin_vel_xy: 2.9772
      Episode_Reward/rew_ang_vel_z: 2.4219
    Episode_Reward/pen_base_height: -0.3208
      Episode_Reward/pen_lin_vel_z: -0.0685
     Episode_Reward/pen_ang_vel_xy: -0.1294
   Episode_Reward/pen_joint_torque: -0.1924
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.0772
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0421
   Episode_Reward/pen_joint_powers: -0.0646
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1628
Episode_Reward/pen_flat_orientation: -0.1592
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2650
   Episode_Reward/foot_landing_vel: -0.1570
   Episode_Reward/test_gait_reward: -0.8074
Metrics/base_velocity/error_vel_xy: 2.3321
Metrics/base_velocity/error_vel_yaw: 0.9623
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 1.05s
                        Total time: 749.48s
                               ETA: 2510.2s

################################################################################
                     [1m Learning iteration 690/3000 [0m                      

                       Computation: 93186 steps/s (collection: 0.934s, learning 0.121s)
               Value function loss: 1.1513
                    Surrogate loss: 0.0011
             Mean action noise std: 0.7619
                     Learning rate: 0.0001
                       Mean reward: 70.49
               Mean episode length: 821.24
       Episode_Reward/keep_balance: 0.8252
     Episode_Reward/rew_lin_vel_xy: 2.8012
      Episode_Reward/rew_ang_vel_z: 2.2902
    Episode_Reward/pen_base_height: -0.2998
      Episode_Reward/pen_lin_vel_z: -0.0607
     Episode_Reward/pen_ang_vel_xy: -0.1184
   Episode_Reward/pen_joint_torque: -0.1791
    Episode_Reward/pen_joint_accel: -0.0999
    Episode_Reward/pen_action_rate: -0.0713
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0375
   Episode_Reward/pen_joint_powers: -0.0595
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1502
Episode_Reward/pen_flat_orientation: -0.1481
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.2299
   Episode_Reward/foot_landing_vel: -0.1381
   Episode_Reward/test_gait_reward: -0.7563
Metrics/base_velocity/error_vel_xy: 2.2437
Metrics/base_velocity/error_vel_yaw: 0.8976
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 1.05s
                        Total time: 750.54s
                               ETA: 2509.0s

################################################################################
                     [1m Learning iteration 691/3000 [0m                      

                       Computation: 90919 steps/s (collection: 0.960s, learning 0.121s)
               Value function loss: 1.1608
                    Surrogate loss: -0.0046
             Mean action noise std: 0.7637
                     Learning rate: 0.0003
                       Mean reward: 82.01
               Mean episode length: 901.73
       Episode_Reward/keep_balance: 0.9039
     Episode_Reward/rew_lin_vel_xy: 3.2375
      Episode_Reward/rew_ang_vel_z: 2.5231
    Episode_Reward/pen_base_height: -0.3209
      Episode_Reward/pen_lin_vel_z: -0.0672
     Episode_Reward/pen_ang_vel_xy: -0.1254
   Episode_Reward/pen_joint_torque: -0.1944
    Episode_Reward/pen_joint_accel: -0.1148
    Episode_Reward/pen_action_rate: -0.0784
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0416
   Episode_Reward/pen_joint_powers: -0.0649
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1651
Episode_Reward/pen_flat_orientation: -0.1490
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2568
   Episode_Reward/foot_landing_vel: -0.1555
   Episode_Reward/test_gait_reward: -0.8303
Metrics/base_velocity/error_vel_xy: 2.3343
Metrics/base_velocity/error_vel_yaw: 0.9648
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 1.08s
                        Total time: 751.62s
                               ETA: 2507.9s

################################################################################
                     [1m Learning iteration 692/3000 [0m                      

                       Computation: 92936 steps/s (collection: 0.935s, learning 0.122s)
               Value function loss: 1.1188
                    Surrogate loss: -0.0022
             Mean action noise std: 0.7649
                     Learning rate: 0.0003
                       Mean reward: 78.20
               Mean episode length: 889.45
       Episode_Reward/keep_balance: 0.8906
     Episode_Reward/rew_lin_vel_xy: 3.1481
      Episode_Reward/rew_ang_vel_z: 2.4653
    Episode_Reward/pen_base_height: -0.3033
      Episode_Reward/pen_lin_vel_z: -0.0625
     Episode_Reward/pen_ang_vel_xy: -0.1258
   Episode_Reward/pen_joint_torque: -0.1900
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.0776
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0408
   Episode_Reward/pen_joint_powers: -0.0641
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1642
Episode_Reward/pen_flat_orientation: -0.1404
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2460
   Episode_Reward/foot_landing_vel: -0.1533
   Episode_Reward/test_gait_reward: -0.8154
Metrics/base_velocity/error_vel_xy: 2.3251
Metrics/base_velocity/error_vel_yaw: 0.9686
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 1.06s
                        Total time: 752.68s
                               ETA: 2506.7s

################################################################################
                     [1m Learning iteration 693/3000 [0m                      

                       Computation: 92486 steps/s (collection: 0.942s, learning 0.121s)
               Value function loss: 1.2139
                    Surrogate loss: -0.0021
             Mean action noise std: 0.7648
                     Learning rate: 0.0004
                       Mean reward: 79.94
               Mean episode length: 879.48
       Episode_Reward/keep_balance: 0.8787
     Episode_Reward/rew_lin_vel_xy: 3.1329
      Episode_Reward/rew_ang_vel_z: 2.4676
    Episode_Reward/pen_base_height: -0.3180
      Episode_Reward/pen_lin_vel_z: -0.0653
     Episode_Reward/pen_ang_vel_xy: -0.1249
   Episode_Reward/pen_joint_torque: -0.1843
    Episode_Reward/pen_joint_accel: -0.0930
    Episode_Reward/pen_action_rate: -0.0759
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0402
   Episode_Reward/pen_joint_powers: -0.0629
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1592
Episode_Reward/pen_flat_orientation: -0.1455
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2504
   Episode_Reward/foot_landing_vel: -0.1563
   Episode_Reward/test_gait_reward: -0.8098
Metrics/base_velocity/error_vel_xy: 2.1885
Metrics/base_velocity/error_vel_yaw: 0.9268
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 1.06s
                        Total time: 753.74s
                               ETA: 2505.6s

################################################################################
                     [1m Learning iteration 694/3000 [0m                      

                       Computation: 90222 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 1.1772
                    Surrogate loss: -0.0010
             Mean action noise std: 0.7653
                     Learning rate: 0.0004
                       Mean reward: 81.75
               Mean episode length: 903.87
       Episode_Reward/keep_balance: 0.9134
     Episode_Reward/rew_lin_vel_xy: 3.1787
      Episode_Reward/rew_ang_vel_z: 2.5464
    Episode_Reward/pen_base_height: -0.3151
      Episode_Reward/pen_lin_vel_z: -0.0650
     Episode_Reward/pen_ang_vel_xy: -0.1294
   Episode_Reward/pen_joint_torque: -0.1927
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.0796
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0649
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1692
Episode_Reward/pen_flat_orientation: -0.1437
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2447
   Episode_Reward/foot_landing_vel: -0.1552
   Episode_Reward/test_gait_reward: -0.8337
Metrics/base_velocity/error_vel_xy: 2.4578
Metrics/base_velocity/error_vel_yaw: 0.9802
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 1.09s
                        Total time: 754.83s
                               ETA: 2504.5s

################################################################################
                     [1m Learning iteration 695/3000 [0m                      

                       Computation: 92529 steps/s (collection: 0.941s, learning 0.121s)
               Value function loss: 1.0684
                    Surrogate loss: -0.0016
             Mean action noise std: 0.7672
                     Learning rate: 0.0003
                       Mean reward: 73.56
               Mean episode length: 863.65
       Episode_Reward/keep_balance: 0.8820
     Episode_Reward/rew_lin_vel_xy: 2.9607
      Episode_Reward/rew_ang_vel_z: 2.4547
    Episode_Reward/pen_base_height: -0.3189
      Episode_Reward/pen_lin_vel_z: -0.0663
     Episode_Reward/pen_ang_vel_xy: -0.1272
   Episode_Reward/pen_joint_torque: -0.1927
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.0771
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0405
   Episode_Reward/pen_joint_powers: -0.0640
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1609
Episode_Reward/pen_flat_orientation: -0.1554
  Episode_Reward/pen_feet_distance: -0.0037
Episode_Reward/pen_feet_regulation: -0.2562
   Episode_Reward/foot_landing_vel: -0.1466
   Episode_Reward/test_gait_reward: -0.8135
Metrics/base_velocity/error_vel_xy: 2.3860
Metrics/base_velocity/error_vel_yaw: 0.9558
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 1.06s
                        Total time: 755.89s
                               ETA: 2503.3s

################################################################################
                     [1m Learning iteration 696/3000 [0m                      

                       Computation: 92979 steps/s (collection: 0.936s, learning 0.122s)
               Value function loss: 1.1197
                    Surrogate loss: -0.0024
             Mean action noise std: 0.7686
                     Learning rate: 0.0004
                       Mean reward: 84.06
               Mean episode length: 924.69
       Episode_Reward/keep_balance: 0.9059
     Episode_Reward/rew_lin_vel_xy: 3.2314
      Episode_Reward/rew_ang_vel_z: 2.4841
    Episode_Reward/pen_base_height: -0.3125
      Episode_Reward/pen_lin_vel_z: -0.0656
     Episode_Reward/pen_ang_vel_xy: -0.1333
   Episode_Reward/pen_joint_torque: -0.1897
    Episode_Reward/pen_joint_accel: -0.1096
    Episode_Reward/pen_action_rate: -0.0803
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0426
   Episode_Reward/pen_joint_powers: -0.0654
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1701
Episode_Reward/pen_flat_orientation: -0.1485
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.2569
   Episode_Reward/foot_landing_vel: -0.1526
   Episode_Reward/test_gait_reward: -0.8318
Metrics/base_velocity/error_vel_xy: 2.2923
Metrics/base_velocity/error_vel_yaw: 1.0115
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 1.06s
                        Total time: 756.95s
                               ETA: 2502.2s

################################################################################
                     [1m Learning iteration 697/3000 [0m                      

                       Computation: 92917 steps/s (collection: 0.936s, learning 0.122s)
               Value function loss: 1.1831
                    Surrogate loss: -0.0023
             Mean action noise std: 0.7705
                     Learning rate: 0.0006
                       Mean reward: 80.46
               Mean episode length: 912.59
       Episode_Reward/keep_balance: 0.9193
     Episode_Reward/rew_lin_vel_xy: 3.2420
      Episode_Reward/rew_ang_vel_z: 2.5421
    Episode_Reward/pen_base_height: -0.3150
      Episode_Reward/pen_lin_vel_z: -0.0666
     Episode_Reward/pen_ang_vel_xy: -0.1305
   Episode_Reward/pen_joint_torque: -0.1983
    Episode_Reward/pen_joint_accel: -0.1102
    Episode_Reward/pen_action_rate: -0.0806
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0433
   Episode_Reward/pen_joint_powers: -0.0671
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1706
Episode_Reward/pen_flat_orientation: -0.1533
  Episode_Reward/pen_feet_distance: -0.0029
Episode_Reward/pen_feet_regulation: -0.2686
   Episode_Reward/foot_landing_vel: -0.1622
   Episode_Reward/test_gait_reward: -0.8451
Metrics/base_velocity/error_vel_xy: 2.3827
Metrics/base_velocity/error_vel_yaw: 1.0019
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 1.06s
                        Total time: 758.01s
                               ETA: 2501.0s

################################################################################
                     [1m Learning iteration 698/3000 [0m                      

                       Computation: 92111 steps/s (collection: 0.946s, learning 0.121s)
               Value function loss: 1.2332
                    Surrogate loss: -0.0026
             Mean action noise std: 0.7715
                     Learning rate: 0.0006
                       Mean reward: 88.29
               Mean episode length: 898.97
       Episode_Reward/keep_balance: 0.8863
     Episode_Reward/rew_lin_vel_xy: 3.4634
      Episode_Reward/rew_ang_vel_z: 2.4507
    Episode_Reward/pen_base_height: -0.3107
      Episode_Reward/pen_lin_vel_z: -0.0635
     Episode_Reward/pen_ang_vel_xy: -0.1305
   Episode_Reward/pen_joint_torque: -0.1831
    Episode_Reward/pen_joint_accel: -0.1009
    Episode_Reward/pen_action_rate: -0.0785
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0409
   Episode_Reward/pen_joint_powers: -0.0631
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1671
Episode_Reward/pen_flat_orientation: -0.1542
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2529
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.8144
Metrics/base_velocity/error_vel_xy: 2.0507
Metrics/base_velocity/error_vel_yaw: 0.9737
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 1.07s
                        Total time: 759.07s
                               ETA: 2499.8s

################################################################################
                     [1m Learning iteration 699/3000 [0m                      

                       Computation: 92521 steps/s (collection: 0.942s, learning 0.121s)
               Value function loss: 1.1594
                    Surrogate loss: -0.0045
             Mean action noise std: 0.7727
                     Learning rate: 0.0009
                       Mean reward: 81.89
               Mean episode length: 885.03
       Episode_Reward/keep_balance: 0.8940
     Episode_Reward/rew_lin_vel_xy: 3.2726
      Episode_Reward/rew_ang_vel_z: 2.4825
    Episode_Reward/pen_base_height: -0.3090
      Episode_Reward/pen_lin_vel_z: -0.0674
     Episode_Reward/pen_ang_vel_xy: -0.1253
   Episode_Reward/pen_joint_torque: -0.1954
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.0776
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0653
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1628
Episode_Reward/pen_flat_orientation: -0.1486
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2600
   Episode_Reward/foot_landing_vel: -0.1512
   Episode_Reward/test_gait_reward: -0.8198
Metrics/base_velocity/error_vel_xy: 2.2197
Metrics/base_velocity/error_vel_yaw: 0.9690
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 1.06s
                        Total time: 760.14s
                               ETA: 2498.7s

################################################################################
                     [1m Learning iteration 700/3000 [0m                      

                       Computation: 91302 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 1.1071
                    Surrogate loss: 0.0090
             Mean action noise std: 0.7739
                     Learning rate: 0.0001
                       Mean reward: 78.21
               Mean episode length: 894.14
       Episode_Reward/keep_balance: 0.8749
     Episode_Reward/rew_lin_vel_xy: 3.0698
      Episode_Reward/rew_ang_vel_z: 2.4044
    Episode_Reward/pen_base_height: -0.3047
      Episode_Reward/pen_lin_vel_z: -0.0630
     Episode_Reward/pen_ang_vel_xy: -0.1273
   Episode_Reward/pen_joint_torque: -0.1919
    Episode_Reward/pen_joint_accel: -0.1169
    Episode_Reward/pen_action_rate: -0.0775
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0649
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1633
Episode_Reward/pen_flat_orientation: -0.1481
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.2506
   Episode_Reward/foot_landing_vel: -0.1526
   Episode_Reward/test_gait_reward: -0.8056
Metrics/base_velocity/error_vel_xy: 2.3046
Metrics/base_velocity/error_vel_yaw: 0.9697
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 1.08s
                        Total time: 761.21s
                               ETA: 2497.6s

################################################################################
                     [1m Learning iteration 701/3000 [0m                      

                       Computation: 91934 steps/s (collection: 0.949s, learning 0.121s)
               Value function loss: 0.9826
                    Surrogate loss: -0.0036
             Mean action noise std: 0.7748
                     Learning rate: 0.0002
                       Mean reward: 78.47
               Mean episode length: 875.20
       Episode_Reward/keep_balance: 0.8621
     Episode_Reward/rew_lin_vel_xy: 3.0579
      Episode_Reward/rew_ang_vel_z: 2.3969
    Episode_Reward/pen_base_height: -0.3094
      Episode_Reward/pen_lin_vel_z: -0.0617
     Episode_Reward/pen_ang_vel_xy: -0.1280
   Episode_Reward/pen_joint_torque: -0.1819
    Episode_Reward/pen_joint_accel: -0.1102
    Episode_Reward/pen_action_rate: -0.0760
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0400
   Episode_Reward/pen_joint_powers: -0.0617
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.1606
Episode_Reward/pen_flat_orientation: -0.1534
  Episode_Reward/pen_feet_distance: -0.0028
Episode_Reward/pen_feet_regulation: -0.2424
   Episode_Reward/foot_landing_vel: -0.1453
   Episode_Reward/test_gait_reward: -0.7902
Metrics/base_velocity/error_vel_xy: 2.2438
Metrics/base_velocity/error_vel_yaw: 0.9410
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 1.07s
                        Total time: 762.28s
                               ETA: 2496.4s

################################################################################
                     [1m Learning iteration 702/3000 [0m                      

                       Computation: 93297 steps/s (collection: 0.933s, learning 0.121s)
               Value function loss: 1.1295
                    Surrogate loss: -0.0034
             Mean action noise std: 0.7766
                     Learning rate: 0.0004
                       Mean reward: 87.33
               Mean episode length: 954.94
       Episode_Reward/keep_balance: 0.9493
     Episode_Reward/rew_lin_vel_xy: 3.6097
      Episode_Reward/rew_ang_vel_z: 2.5755
    Episode_Reward/pen_base_height: -0.3123
      Episode_Reward/pen_lin_vel_z: -0.0667
     Episode_Reward/pen_ang_vel_xy: -0.1417
   Episode_Reward/pen_joint_torque: -0.2003
    Episode_Reward/pen_joint_accel: -0.1238
    Episode_Reward/pen_action_rate: -0.0853
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0451
   Episode_Reward/pen_joint_powers: -0.0692
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.1816
Episode_Reward/pen_flat_orientation: -0.1525
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2809
   Episode_Reward/foot_landing_vel: -0.1581
   Episode_Reward/test_gait_reward: -0.8791
Metrics/base_velocity/error_vel_xy: 2.1441
Metrics/base_velocity/error_vel_yaw: 1.0753
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 1.05s
                        Total time: 763.33s
                               ETA: 2495.2s

################################################################################
                     [1m Learning iteration 703/3000 [0m                      

                       Computation: 93159 steps/s (collection: 0.934s, learning 0.121s)
               Value function loss: 1.3113
                    Surrogate loss: -0.0033
             Mean action noise std: 0.7786
                     Learning rate: 0.0009
                       Mean reward: 80.55
               Mean episode length: 903.62
       Episode_Reward/keep_balance: 0.8991
     Episode_Reward/rew_lin_vel_xy: 3.2642
      Episode_Reward/rew_ang_vel_z: 2.4401
    Episode_Reward/pen_base_height: -0.3164
      Episode_Reward/pen_lin_vel_z: -0.0640
     Episode_Reward/pen_ang_vel_xy: -0.1329
   Episode_Reward/pen_joint_torque: -0.1950
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.0805
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0424
   Episode_Reward/pen_joint_powers: -0.0667
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1701
Episode_Reward/pen_flat_orientation: -0.1605
  Episode_Reward/pen_feet_distance: -0.0015
Episode_Reward/pen_feet_regulation: -0.2759
   Episode_Reward/foot_landing_vel: -0.1475
   Episode_Reward/test_gait_reward: -0.8327
Metrics/base_velocity/error_vel_xy: 2.2517
Metrics/base_velocity/error_vel_yaw: 1.0297
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 1.06s
                        Total time: 764.39s
                               ETA: 2494.0s

################################################################################
                     [1m Learning iteration 704/3000 [0m                      

                       Computation: 85600 steps/s (collection: 1.027s, learning 0.122s)
               Value function loss: 1.1973
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7805
                     Learning rate: 0.0009
                       Mean reward: 82.86
               Mean episode length: 876.19
       Episode_Reward/keep_balance: 0.8978
     Episode_Reward/rew_lin_vel_xy: 3.3916
      Episode_Reward/rew_ang_vel_z: 2.4916
    Episode_Reward/pen_base_height: -0.2997
      Episode_Reward/pen_lin_vel_z: -0.0628
     Episode_Reward/pen_ang_vel_xy: -0.1278
   Episode_Reward/pen_joint_torque: -0.1892
    Episode_Reward/pen_joint_accel: -0.0975
    Episode_Reward/pen_action_rate: -0.0787
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0397
   Episode_Reward/pen_joint_powers: -0.0627
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1670
Episode_Reward/pen_flat_orientation: -0.1435
  Episode_Reward/pen_feet_distance: -0.0038
Episode_Reward/pen_feet_regulation: -0.2398
   Episode_Reward/foot_landing_vel: -0.1449
   Episode_Reward/test_gait_reward: -0.8176
Metrics/base_velocity/error_vel_xy: 2.2540
Metrics/base_velocity/error_vel_yaw: 0.9735
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 1.15s
                        Total time: 765.54s
                               ETA: 2493.2s

################################################################################
                     [1m Learning iteration 705/3000 [0m                      

                       Computation: 91888 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.1470
                    Surrogate loss: -0.0014
             Mean action noise std: 0.7811
                     Learning rate: 0.0004
                       Mean reward: 84.72
               Mean episode length: 937.05
       Episode_Reward/keep_balance: 0.8886
     Episode_Reward/rew_lin_vel_xy: 3.2389
      Episode_Reward/rew_ang_vel_z: 2.4270
    Episode_Reward/pen_base_height: -0.3061
      Episode_Reward/pen_lin_vel_z: -0.0626
     Episode_Reward/pen_ang_vel_xy: -0.1341
   Episode_Reward/pen_joint_torque: -0.1868
    Episode_Reward/pen_joint_accel: -0.1036
    Episode_Reward/pen_action_rate: -0.0797
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0421
   Episode_Reward/pen_joint_powers: -0.0643
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1700
Episode_Reward/pen_flat_orientation: -0.1490
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2534
   Episode_Reward/foot_landing_vel: -0.1503
   Episode_Reward/test_gait_reward: -0.8124
Metrics/base_velocity/error_vel_xy: 2.1588
Metrics/base_velocity/error_vel_yaw: 0.9965
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 1.07s
                        Total time: 766.61s
                               ETA: 2492.0s

################################################################################
                     [1m Learning iteration 706/3000 [0m                      

                       Computation: 90283 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 1.1023
                    Surrogate loss: -0.0022
             Mean action noise std: 0.7823
                     Learning rate: 0.0004
                       Mean reward: 83.09
               Mean episode length: 916.93
       Episode_Reward/keep_balance: 0.8759
     Episode_Reward/rew_lin_vel_xy: 3.1743
      Episode_Reward/rew_ang_vel_z: 2.4042
    Episode_Reward/pen_base_height: -0.3055
      Episode_Reward/pen_lin_vel_z: -0.0641
     Episode_Reward/pen_ang_vel_xy: -0.1281
   Episode_Reward/pen_joint_torque: -0.1896
    Episode_Reward/pen_joint_accel: -0.1004
    Episode_Reward/pen_action_rate: -0.0773
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0405
   Episode_Reward/pen_joint_powers: -0.0638
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1635
Episode_Reward/pen_flat_orientation: -0.1594
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.2482
   Episode_Reward/foot_landing_vel: -0.1537
   Episode_Reward/test_gait_reward: -0.8028
Metrics/base_velocity/error_vel_xy: 2.2296
Metrics/base_velocity/error_vel_yaw: 0.9806
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 1.09s
                        Total time: 767.70s
                               ETA: 2490.9s

################################################################################
                     [1m Learning iteration 707/3000 [0m                      

                       Computation: 91860 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 1.1145
                    Surrogate loss: -0.0004
             Mean action noise std: 0.7828
                     Learning rate: 0.0002
                       Mean reward: 82.62
               Mean episode length: 928.12
       Episode_Reward/keep_balance: 0.9367
     Episode_Reward/rew_lin_vel_xy: 3.3962
      Episode_Reward/rew_ang_vel_z: 2.5801
    Episode_Reward/pen_base_height: -0.3169
      Episode_Reward/pen_lin_vel_z: -0.0675
     Episode_Reward/pen_ang_vel_xy: -0.1361
   Episode_Reward/pen_joint_torque: -0.2050
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.0825
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0433
   Episode_Reward/pen_joint_powers: -0.0685
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1742
Episode_Reward/pen_flat_orientation: -0.1533
  Episode_Reward/pen_feet_distance: -0.0037
Episode_Reward/pen_feet_regulation: -0.2677
   Episode_Reward/foot_landing_vel: -0.1604
   Episode_Reward/test_gait_reward: -0.8643
Metrics/base_velocity/error_vel_xy: 2.3588
Metrics/base_velocity/error_vel_yaw: 1.0276
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 1.07s
                        Total time: 768.77s
                               ETA: 2489.8s

################################################################################
                     [1m Learning iteration 708/3000 [0m                      

                       Computation: 91965 steps/s (collection: 0.947s, learning 0.121s)
               Value function loss: 1.0488
                    Surrogate loss: -0.0039
             Mean action noise std: 0.7838
                     Learning rate: 0.0004
                       Mean reward: 82.97
               Mean episode length: 885.13
       Episode_Reward/keep_balance: 0.8847
     Episode_Reward/rew_lin_vel_xy: 3.2233
      Episode_Reward/rew_ang_vel_z: 2.4291
    Episode_Reward/pen_base_height: -0.3050
      Episode_Reward/pen_lin_vel_z: -0.0632
     Episode_Reward/pen_ang_vel_xy: -0.1341
   Episode_Reward/pen_joint_torque: -0.1871
    Episode_Reward/pen_joint_accel: -0.1050
    Episode_Reward/pen_action_rate: -0.0784
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0407
   Episode_Reward/pen_joint_powers: -0.0638
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1654
Episode_Reward/pen_flat_orientation: -0.1513
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2553
   Episode_Reward/foot_landing_vel: -0.1420
   Episode_Reward/test_gait_reward: -0.8132
Metrics/base_velocity/error_vel_xy: 2.2489
Metrics/base_velocity/error_vel_yaw: 0.9838
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 1.07s
                        Total time: 769.84s
                               ETA: 2488.7s

################################################################################
                     [1m Learning iteration 709/3000 [0m                      

                       Computation: 92480 steps/s (collection: 0.942s, learning 0.121s)
               Value function loss: 1.0870
                    Surrogate loss: -0.0021
             Mean action noise std: 0.7858
                     Learning rate: 0.0004
                       Mean reward: 83.80
               Mean episode length: 905.26
       Episode_Reward/keep_balance: 0.8931
     Episode_Reward/rew_lin_vel_xy: 3.2725
      Episode_Reward/rew_ang_vel_z: 2.4695
    Episode_Reward/pen_base_height: -0.3109
      Episode_Reward/pen_lin_vel_z: -0.0620
     Episode_Reward/pen_ang_vel_xy: -0.1334
   Episode_Reward/pen_joint_torque: -0.1875
    Episode_Reward/pen_joint_accel: -0.0993
    Episode_Reward/pen_action_rate: -0.0788
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0407
   Episode_Reward/pen_joint_powers: -0.0639
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1671
Episode_Reward/pen_flat_orientation: -0.1534
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2547
   Episode_Reward/foot_landing_vel: -0.1402
   Episode_Reward/test_gait_reward: -0.8207
Metrics/base_velocity/error_vel_xy: 2.2764
Metrics/base_velocity/error_vel_yaw: 0.9770
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 1.06s
                        Total time: 770.90s
                               ETA: 2487.5s

################################################################################
                     [1m Learning iteration 710/3000 [0m                      

                       Computation: 91968 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 1.1582
                    Surrogate loss: 0.0042
             Mean action noise std: 0.7861
                     Learning rate: 0.0000
                       Mean reward: 88.78
               Mean episode length: 934.55
       Episode_Reward/keep_balance: 0.9504
     Episode_Reward/rew_lin_vel_xy: 3.6657
      Episode_Reward/rew_ang_vel_z: 2.6097
    Episode_Reward/pen_base_height: -0.3238
      Episode_Reward/pen_lin_vel_z: -0.0649
     Episode_Reward/pen_ang_vel_xy: -0.1415
   Episode_Reward/pen_joint_torque: -0.2026
    Episode_Reward/pen_joint_accel: -0.1097
    Episode_Reward/pen_action_rate: -0.0846
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0423
   Episode_Reward/pen_joint_powers: -0.0678
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1792
Episode_Reward/pen_flat_orientation: -0.1532
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2663
   Episode_Reward/foot_landing_vel: -0.1468
   Episode_Reward/test_gait_reward: -0.8719
Metrics/base_velocity/error_vel_xy: 2.2435
Metrics/base_velocity/error_vel_yaw: 1.0541
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 1.07s
                        Total time: 771.97s
                               ETA: 2486.4s

################################################################################
                     [1m Learning iteration 711/3000 [0m                      

                       Computation: 90043 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 1.0392
                    Surrogate loss: -0.0029
             Mean action noise std: 0.7856
                     Learning rate: 0.0001
                       Mean reward: 85.01
               Mean episode length: 893.10
       Episode_Reward/keep_balance: 0.9000
     Episode_Reward/rew_lin_vel_xy: 3.3907
      Episode_Reward/rew_ang_vel_z: 2.4776
    Episode_Reward/pen_base_height: -0.3088
      Episode_Reward/pen_lin_vel_z: -0.0638
     Episode_Reward/pen_ang_vel_xy: -0.1388
   Episode_Reward/pen_joint_torque: -0.1893
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.0800
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0417
   Episode_Reward/pen_joint_powers: -0.0646
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1694
Episode_Reward/pen_flat_orientation: -0.1541
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2504
   Episode_Reward/foot_landing_vel: -0.1453
   Episode_Reward/test_gait_reward: -0.8263
Metrics/base_velocity/error_vel_xy: 2.1998
Metrics/base_velocity/error_vel_yaw: 0.9950
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 1.09s
                        Total time: 773.06s
                               ETA: 2485.3s

################################################################################
                     [1m Learning iteration 712/3000 [0m                      

                       Computation: 92463 steps/s (collection: 0.942s, learning 0.121s)
               Value function loss: 0.9523
                    Surrogate loss: -0.0041
             Mean action noise std: 0.7850
                     Learning rate: 0.0003
                       Mean reward: 86.63
               Mean episode length: 936.47
       Episode_Reward/keep_balance: 0.9237
     Episode_Reward/rew_lin_vel_xy: 3.5159
      Episode_Reward/rew_ang_vel_z: 2.5071
    Episode_Reward/pen_base_height: -0.3230
      Episode_Reward/pen_lin_vel_z: -0.0644
     Episode_Reward/pen_ang_vel_xy: -0.1466
   Episode_Reward/pen_joint_torque: -0.1954
    Episode_Reward/pen_joint_accel: -0.1092
    Episode_Reward/pen_action_rate: -0.0838
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0429
   Episode_Reward/pen_joint_powers: -0.0674
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1773
Episode_Reward/pen_flat_orientation: -0.1593
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2709
   Episode_Reward/foot_landing_vel: -0.1449
   Episode_Reward/test_gait_reward: -0.8528
Metrics/base_velocity/error_vel_xy: 2.2228
Metrics/base_velocity/error_vel_yaw: 1.0525
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 1.06s
                        Total time: 774.12s
                               ETA: 2484.1s

################################################################################
                     [1m Learning iteration 713/3000 [0m                      

                       Computation: 92615 steps/s (collection: 0.940s, learning 0.121s)
               Value function loss: 1.1172
                    Surrogate loss: -0.0032
             Mean action noise std: 0.7859
                     Learning rate: 0.0006
                       Mean reward: 82.21
               Mean episode length: 887.00
       Episode_Reward/keep_balance: 0.9063
     Episode_Reward/rew_lin_vel_xy: 3.4413
      Episode_Reward/rew_ang_vel_z: 2.4730
    Episode_Reward/pen_base_height: -0.3205
      Episode_Reward/pen_lin_vel_z: -0.0660
     Episode_Reward/pen_ang_vel_xy: -0.1396
   Episode_Reward/pen_joint_torque: -0.1969
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.0813
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0429
   Episode_Reward/pen_joint_powers: -0.0673
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1726
Episode_Reward/pen_flat_orientation: -0.1606
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.2713
   Episode_Reward/foot_landing_vel: -0.1557
   Episode_Reward/test_gait_reward: -0.8305
Metrics/base_velocity/error_vel_xy: 2.1819
Metrics/base_velocity/error_vel_yaw: 1.0229
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 1.06s
                        Total time: 775.18s
                               ETA: 2483.0s

################################################################################
                     [1m Learning iteration 714/3000 [0m                      

                       Computation: 91886 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 1.1589
                    Surrogate loss: -0.0033
             Mean action noise std: 0.7887
                     Learning rate: 0.0006
                       Mean reward: 84.90
               Mean episode length: 896.73
       Episode_Reward/keep_balance: 0.8874
     Episode_Reward/rew_lin_vel_xy: 3.4554
      Episode_Reward/rew_ang_vel_z: 2.4069
    Episode_Reward/pen_base_height: -0.3207
      Episode_Reward/pen_lin_vel_z: -0.0641
     Episode_Reward/pen_ang_vel_xy: -0.1385
   Episode_Reward/pen_joint_torque: -0.1922
    Episode_Reward/pen_joint_accel: -0.1009
    Episode_Reward/pen_action_rate: -0.0802
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0419
   Episode_Reward/pen_joint_powers: -0.0665
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1694
Episode_Reward/pen_flat_orientation: -0.1620
  Episode_Reward/pen_feet_distance: -0.0022
Episode_Reward/pen_feet_regulation: -0.2731
   Episode_Reward/foot_landing_vel: -0.1402
   Episode_Reward/test_gait_reward: -0.8249
Metrics/base_velocity/error_vel_xy: 2.0735
Metrics/base_velocity/error_vel_yaw: 1.0131
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 1.07s
                        Total time: 776.25s
                               ETA: 2481.8s

################################################################################
                     [1m Learning iteration 715/3000 [0m                      

                       Computation: 93360 steps/s (collection: 0.931s, learning 0.122s)
               Value function loss: 1.1785
                    Surrogate loss: -0.0004
             Mean action noise std: 0.7904
                     Learning rate: 0.0003
                       Mean reward: 82.88
               Mean episode length: 893.99
       Episode_Reward/keep_balance: 0.8989
     Episode_Reward/rew_lin_vel_xy: 3.2671
      Episode_Reward/rew_ang_vel_z: 2.4594
    Episode_Reward/pen_base_height: -0.3089
      Episode_Reward/pen_lin_vel_z: -0.0618
     Episode_Reward/pen_ang_vel_xy: -0.1420
   Episode_Reward/pen_joint_torque: -0.1924
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.0813
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0423
   Episode_Reward/pen_joint_powers: -0.0663
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1731
Episode_Reward/pen_flat_orientation: -0.1582
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.2601
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.8293
Metrics/base_velocity/error_vel_xy: 2.1773
Metrics/base_velocity/error_vel_yaw: 1.0143
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 1.05s
                        Total time: 777.31s
                               ETA: 2480.7s

################################################################################
                     [1m Learning iteration 716/3000 [0m                      

                       Computation: 92396 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 1.0943
                    Surrogate loss: -0.0042
             Mean action noise std: 0.7923
                     Learning rate: 0.0006
                       Mean reward: 80.33
               Mean episode length: 908.46
       Episode_Reward/keep_balance: 0.9358
     Episode_Reward/rew_lin_vel_xy: 3.3857
      Episode_Reward/rew_ang_vel_z: 2.5276
    Episode_Reward/pen_base_height: -0.3110
      Episode_Reward/pen_lin_vel_z: -0.0629
     Episode_Reward/pen_ang_vel_xy: -0.1430
   Episode_Reward/pen_joint_torque: -0.1986
    Episode_Reward/pen_joint_accel: -0.1132
    Episode_Reward/pen_action_rate: -0.0854
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0439
   Episode_Reward/pen_joint_powers: -0.0687
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1822
Episode_Reward/pen_flat_orientation: -0.1583
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2667
   Episode_Reward/foot_landing_vel: -0.1521
   Episode_Reward/test_gait_reward: -0.8620
Metrics/base_velocity/error_vel_xy: 2.2635
Metrics/base_velocity/error_vel_yaw: 1.0785
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 1.06s
                        Total time: 778.37s
                               ETA: 2479.5s

################################################################################
                     [1m Learning iteration 717/3000 [0m                      

                       Computation: 92681 steps/s (collection: 0.939s, learning 0.121s)
               Value function loss: 1.1403
                    Surrogate loss: -0.0040
             Mean action noise std: 0.7917
                     Learning rate: 0.0009
                       Mean reward: 84.03
               Mean episode length: 930.10
       Episode_Reward/keep_balance: 0.9517
     Episode_Reward/rew_lin_vel_xy: 3.6221
      Episode_Reward/rew_ang_vel_z: 2.6260
    Episode_Reward/pen_base_height: -0.3284
      Episode_Reward/pen_lin_vel_z: -0.0658
     Episode_Reward/pen_ang_vel_xy: -0.1469
   Episode_Reward/pen_joint_torque: -0.2063
    Episode_Reward/pen_joint_accel: -0.1143
    Episode_Reward/pen_action_rate: -0.0857
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0706
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1819
Episode_Reward/pen_flat_orientation: -0.1599
  Episode_Reward/pen_feet_distance: -0.0025
Episode_Reward/pen_feet_regulation: -0.2778
   Episode_Reward/foot_landing_vel: -0.1541
   Episode_Reward/test_gait_reward: -0.8773
Metrics/base_velocity/error_vel_xy: 2.3188
Metrics/base_velocity/error_vel_yaw: 1.0479
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 1.06s
                        Total time: 779.43s
                               ETA: 2478.3s

################################################################################
                     [1m Learning iteration 718/3000 [0m                      

                       Computation: 93907 steps/s (collection: 0.924s, learning 0.123s)
               Value function loss: 1.2609
                    Surrogate loss: -0.0044
             Mean action noise std: 0.7929
                     Learning rate: 0.0013
                       Mean reward: 85.95
               Mean episode length: 921.94
       Episode_Reward/keep_balance: 0.9253
     Episode_Reward/rew_lin_vel_xy: 3.5572
      Episode_Reward/rew_ang_vel_z: 2.5053
    Episode_Reward/pen_base_height: -0.3100
      Episode_Reward/pen_lin_vel_z: -0.0633
     Episode_Reward/pen_ang_vel_xy: -0.1361
   Episode_Reward/pen_joint_torque: -0.1976
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.0823
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0417
   Episode_Reward/pen_joint_powers: -0.0665
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1756
Episode_Reward/pen_flat_orientation: -0.1566
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.2595
   Episode_Reward/foot_landing_vel: -0.1456
   Episode_Reward/test_gait_reward: -0.8532
Metrics/base_velocity/error_vel_xy: 2.1531
Metrics/base_velocity/error_vel_yaw: 1.0511
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 1.05s
                        Total time: 780.48s
                               ETA: 2477.1s

################################################################################
                     [1m Learning iteration 719/3000 [0m                      

                       Computation: 92312 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 1.3285
                    Surrogate loss: -0.0026
             Mean action noise std: 0.7932
                     Learning rate: 0.0019
                       Mean reward: 82.53
               Mean episode length: 908.34
       Episode_Reward/keep_balance: 0.9205
     Episode_Reward/rew_lin_vel_xy: 3.3846
      Episode_Reward/rew_ang_vel_z: 2.4950
    Episode_Reward/pen_base_height: -0.3017
      Episode_Reward/pen_lin_vel_z: -0.0613
     Episode_Reward/pen_ang_vel_xy: -0.1370
   Episode_Reward/pen_joint_torque: -0.1924
    Episode_Reward/pen_joint_accel: -0.0989
    Episode_Reward/pen_action_rate: -0.0829
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0411
   Episode_Reward/pen_joint_powers: -0.0653
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1783
Episode_Reward/pen_flat_orientation: -0.1551
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2532
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.8426
Metrics/base_velocity/error_vel_xy: 2.3815
Metrics/base_velocity/error_vel_yaw: 1.0535
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 1.06s
                        Total time: 781.54s
                               ETA: 2476.0s

################################################################################
                     [1m Learning iteration 720/3000 [0m                      

                       Computation: 91322 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 1.2975
                    Surrogate loss: 0.0031
             Mean action noise std: 0.7937
                     Learning rate: 0.0003
                       Mean reward: 79.71
               Mean episode length: 870.99
       Episode_Reward/keep_balance: 0.8948
     Episode_Reward/rew_lin_vel_xy: 3.2727
      Episode_Reward/rew_ang_vel_z: 2.4187
    Episode_Reward/pen_base_height: -0.3060
      Episode_Reward/pen_lin_vel_z: -0.0633
     Episode_Reward/pen_ang_vel_xy: -0.1420
   Episode_Reward/pen_joint_torque: -0.1877
    Episode_Reward/pen_joint_accel: -0.1020
    Episode_Reward/pen_action_rate: -0.0821
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0422
   Episode_Reward/pen_joint_powers: -0.0658
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1756
Episode_Reward/pen_flat_orientation: -0.1645
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2631
   Episode_Reward/foot_landing_vel: -0.1403
   Episode_Reward/test_gait_reward: -0.8262
Metrics/base_velocity/error_vel_xy: 2.2016
Metrics/base_velocity/error_vel_yaw: 1.0323
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 1.08s
                        Total time: 782.62s
                               ETA: 2474.9s

################################################################################
                     [1m Learning iteration 721/3000 [0m                      

                       Computation: 92001 steps/s (collection: 0.945s, learning 0.123s)
               Value function loss: 1.0484
                    Surrogate loss: -0.0041
             Mean action noise std: 0.7936
                     Learning rate: 0.0006
                       Mean reward: 80.29
               Mean episode length: 874.35
       Episode_Reward/keep_balance: 0.8829
     Episode_Reward/rew_lin_vel_xy: 3.2184
      Episode_Reward/rew_ang_vel_z: 2.3741
    Episode_Reward/pen_base_height: -0.3023
      Episode_Reward/pen_lin_vel_z: -0.0580
     Episode_Reward/pen_ang_vel_xy: -0.1376
   Episode_Reward/pen_joint_torque: -0.1867
    Episode_Reward/pen_joint_accel: -0.1030
    Episode_Reward/pen_action_rate: -0.0804
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0406
   Episode_Reward/pen_joint_powers: -0.0640
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1718
Episode_Reward/pen_flat_orientation: -0.1480
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.2508
   Episode_Reward/foot_landing_vel: -0.1323
   Episode_Reward/test_gait_reward: -0.8113
Metrics/base_velocity/error_vel_xy: 2.2016
Metrics/base_velocity/error_vel_yaw: 1.0285
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 1.07s
                        Total time: 783.69s
                               ETA: 2473.7s

################################################################################
                     [1m Learning iteration 722/3000 [0m                      

                       Computation: 92127 steps/s (collection: 0.943s, learning 0.124s)
               Value function loss: 1.1261
                    Surrogate loss: -0.0018
             Mean action noise std: 0.7955
                     Learning rate: 0.0009
                       Mean reward: 83.08
               Mean episode length: 882.85
       Episode_Reward/keep_balance: 0.8548
     Episode_Reward/rew_lin_vel_xy: 3.1832
      Episode_Reward/rew_ang_vel_z: 2.3259
    Episode_Reward/pen_base_height: -0.2863
      Episode_Reward/pen_lin_vel_z: -0.0549
     Episode_Reward/pen_ang_vel_xy: -0.1277
   Episode_Reward/pen_joint_torque: -0.1775
    Episode_Reward/pen_joint_accel: -0.0925
    Episode_Reward/pen_action_rate: -0.0766
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0378
   Episode_Reward/pen_joint_powers: -0.0605
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1651
Episode_Reward/pen_flat_orientation: -0.1420
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2301
   Episode_Reward/foot_landing_vel: -0.1251
   Episode_Reward/test_gait_reward: -0.7809
Metrics/base_velocity/error_vel_xy: 1.9817
Metrics/base_velocity/error_vel_yaw: 0.9676
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 1.07s
                        Total time: 784.76s
                               ETA: 2472.6s

################################################################################
                     [1m Learning iteration 723/3000 [0m                      

                       Computation: 92487 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 1.1167
                    Surrogate loss: -0.0023
             Mean action noise std: 0.7964
                     Learning rate: 0.0009
                       Mean reward: 87.85
               Mean episode length: 907.74
       Episode_Reward/keep_balance: 0.9079
     Episode_Reward/rew_lin_vel_xy: 3.6346
      Episode_Reward/rew_ang_vel_z: 2.4304
    Episode_Reward/pen_base_height: -0.3195
      Episode_Reward/pen_lin_vel_z: -0.0602
     Episode_Reward/pen_ang_vel_xy: -0.1384
   Episode_Reward/pen_joint_torque: -0.1922
    Episode_Reward/pen_joint_accel: -0.0991
    Episode_Reward/pen_action_rate: -0.0826
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0421
   Episode_Reward/pen_joint_powers: -0.0657
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1766
Episode_Reward/pen_flat_orientation: -0.1658
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2613
   Episode_Reward/foot_landing_vel: -0.1420
   Episode_Reward/test_gait_reward: -0.8393
Metrics/base_velocity/error_vel_xy: 2.0688
Metrics/base_velocity/error_vel_yaw: 1.0586
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 1.06s
                        Total time: 785.82s
                               ETA: 2471.4s

################################################################################
                     [1m Learning iteration 724/3000 [0m                      

                       Computation: 92611 steps/s (collection: 0.938s, learning 0.123s)
               Value function loss: 1.1478
                    Surrogate loss: -0.0028
             Mean action noise std: 0.7975
                     Learning rate: 0.0013
                       Mean reward: 83.79
               Mean episode length: 881.79
       Episode_Reward/keep_balance: 0.8957
     Episode_Reward/rew_lin_vel_xy: 3.6349
      Episode_Reward/rew_ang_vel_z: 2.4189
    Episode_Reward/pen_base_height: -0.3086
      Episode_Reward/pen_lin_vel_z: -0.0610
     Episode_Reward/pen_ang_vel_xy: -0.1371
   Episode_Reward/pen_joint_torque: -0.1890
    Episode_Reward/pen_joint_accel: -0.0995
    Episode_Reward/pen_action_rate: -0.0816
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0417
   Episode_Reward/pen_joint_powers: -0.0651
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1745
Episode_Reward/pen_flat_orientation: -0.1589
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2578
   Episode_Reward/foot_landing_vel: -0.1444
   Episode_Reward/test_gait_reward: -0.8254
Metrics/base_velocity/error_vel_xy: 1.9600
Metrics/base_velocity/error_vel_yaw: 1.0300
      Episode_Termination/time_out: 2.9583
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 1.06s
                        Total time: 786.88s
                               ETA: 2470.3s

################################################################################
                     [1m Learning iteration 725/3000 [0m                      

                       Computation: 91800 steps/s (collection: 0.945s, learning 0.125s)
               Value function loss: 1.0881
                    Surrogate loss: -0.0024
             Mean action noise std: 0.7991
                     Learning rate: 0.0013
                       Mean reward: 89.74
               Mean episode length: 942.29
       Episode_Reward/keep_balance: 0.9295
     Episode_Reward/rew_lin_vel_xy: 3.4886
      Episode_Reward/rew_ang_vel_z: 2.5425
    Episode_Reward/pen_base_height: -0.2989
      Episode_Reward/pen_lin_vel_z: -0.0586
     Episode_Reward/pen_ang_vel_xy: -0.1395
   Episode_Reward/pen_joint_torque: -0.1891
    Episode_Reward/pen_joint_accel: -0.0983
    Episode_Reward/pen_action_rate: -0.0835
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0401
   Episode_Reward/pen_joint_powers: -0.0647
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1801
Episode_Reward/pen_flat_orientation: -0.1487
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2468
   Episode_Reward/foot_landing_vel: -0.1345
   Episode_Reward/test_gait_reward: -0.8504
Metrics/base_velocity/error_vel_xy: 2.2319
Metrics/base_velocity/error_vel_yaw: 1.0413
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 1.07s
                        Total time: 787.95s
                               ETA: 2469.1s

################################################################################
                     [1m Learning iteration 726/3000 [0m                      

                       Computation: 90345 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 1.1388
                    Surrogate loss: -0.0008
             Mean action noise std: 0.8004
                     Learning rate: 0.0004
                       Mean reward: 83.74
               Mean episode length: 919.24
       Episode_Reward/keep_balance: 0.9032
     Episode_Reward/rew_lin_vel_xy: 3.3385
      Episode_Reward/rew_ang_vel_z: 2.4213
    Episode_Reward/pen_base_height: -0.3082
      Episode_Reward/pen_lin_vel_z: -0.0637
     Episode_Reward/pen_ang_vel_xy: -0.1434
   Episode_Reward/pen_joint_torque: -0.1916
    Episode_Reward/pen_joint_accel: -0.0950
    Episode_Reward/pen_action_rate: -0.0829
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0422
   Episode_Reward/pen_joint_powers: -0.0666
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1767
Episode_Reward/pen_flat_orientation: -0.1685
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2643
   Episode_Reward/foot_landing_vel: -0.1395
   Episode_Reward/test_gait_reward: -0.8325
Metrics/base_velocity/error_vel_xy: 2.2430
Metrics/base_velocity/error_vel_yaw: 1.0597
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 1.09s
                        Total time: 789.04s
                               ETA: 2468.1s

################################################################################
                     [1m Learning iteration 727/3000 [0m                      

                       Computation: 92457 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 1.1414
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8016
                     Learning rate: 0.0006
                       Mean reward: 87.61
               Mean episode length: 918.74
       Episode_Reward/keep_balance: 0.8930
     Episode_Reward/rew_lin_vel_xy: 3.3997
      Episode_Reward/rew_ang_vel_z: 2.4218
    Episode_Reward/pen_base_height: -0.3077
      Episode_Reward/pen_lin_vel_z: -0.0594
     Episode_Reward/pen_ang_vel_xy: -0.1392
   Episode_Reward/pen_joint_torque: -0.1884
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.0825
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0417
   Episode_Reward/pen_joint_powers: -0.0654
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1770
Episode_Reward/pen_flat_orientation: -0.1560
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2555
   Episode_Reward/foot_landing_vel: -0.1388
   Episode_Reward/test_gait_reward: -0.8240
Metrics/base_velocity/error_vel_xy: 2.1243
Metrics/base_velocity/error_vel_yaw: 1.0275
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 1.06s
                        Total time: 790.10s
                               ETA: 2466.9s

################################################################################
                     [1m Learning iteration 728/3000 [0m                      

                       Computation: 92932 steps/s (collection: 0.936s, learning 0.122s)
               Value function loss: 1.0807
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8028
                     Learning rate: 0.0009
                       Mean reward: 86.26
               Mean episode length: 922.44
       Episode_Reward/keep_balance: 0.9010
     Episode_Reward/rew_lin_vel_xy: 3.4821
      Episode_Reward/rew_ang_vel_z: 2.3713
    Episode_Reward/pen_base_height: -0.3064
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.1400
   Episode_Reward/pen_joint_torque: -0.1806
    Episode_Reward/pen_joint_accel: -0.1021
    Episode_Reward/pen_action_rate: -0.0851
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0633
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1842
Episode_Reward/pen_flat_orientation: -0.1581
  Episode_Reward/pen_feet_distance: -0.0008
Episode_Reward/pen_feet_regulation: -0.2515
   Episode_Reward/foot_landing_vel: -0.1345
   Episode_Reward/test_gait_reward: -0.8330
Metrics/base_velocity/error_vel_xy: 2.0394
Metrics/base_velocity/error_vel_yaw: 1.0936
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 1.06s
                        Total time: 791.16s
                               ETA: 2465.7s

################################################################################
                     [1m Learning iteration 729/3000 [0m                      

                       Computation: 93109 steps/s (collection: 0.933s, learning 0.123s)
               Value function loss: 1.2359
                    Surrogate loss: -0.0004
             Mean action noise std: 0.8032
                     Learning rate: 0.0004
                       Mean reward: 84.92
               Mean episode length: 900.47
       Episode_Reward/keep_balance: 0.8863
     Episode_Reward/rew_lin_vel_xy: 3.4217
      Episode_Reward/rew_ang_vel_z: 2.3988
    Episode_Reward/pen_base_height: -0.3160
      Episode_Reward/pen_lin_vel_z: -0.0571
     Episode_Reward/pen_ang_vel_xy: -0.1419
   Episode_Reward/pen_joint_torque: -0.1828
    Episode_Reward/pen_joint_accel: -0.0950
    Episode_Reward/pen_action_rate: -0.0830
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0405
   Episode_Reward/pen_joint_powers: -0.0641
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1777
Episode_Reward/pen_flat_orientation: -0.1509
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.2540
   Episode_Reward/foot_landing_vel: -0.1341
   Episode_Reward/test_gait_reward: -0.8232
Metrics/base_velocity/error_vel_xy: 2.1550
Metrics/base_velocity/error_vel_yaw: 1.0214
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 1.06s
                        Total time: 792.22s
                               ETA: 2464.6s

################################################################################
                     [1m Learning iteration 730/3000 [0m                      

                       Computation: 92621 steps/s (collection: 0.939s, learning 0.123s)
               Value function loss: 1.0233
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8033
                     Learning rate: 0.0006
                       Mean reward: 83.47
               Mean episode length: 891.19
       Episode_Reward/keep_balance: 0.9137
     Episode_Reward/rew_lin_vel_xy: 3.4967
      Episode_Reward/rew_ang_vel_z: 2.4890
    Episode_Reward/pen_base_height: -0.2986
      Episode_Reward/pen_lin_vel_z: -0.0603
     Episode_Reward/pen_ang_vel_xy: -0.1447
   Episode_Reward/pen_joint_torque: -0.1901
    Episode_Reward/pen_joint_accel: -0.1008
    Episode_Reward/pen_action_rate: -0.0844
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0420
   Episode_Reward/pen_joint_powers: -0.0653
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1805
Episode_Reward/pen_flat_orientation: -0.1548
  Episode_Reward/pen_feet_distance: -0.0025
Episode_Reward/pen_feet_regulation: -0.2578
   Episode_Reward/foot_landing_vel: -0.1457
   Episode_Reward/test_gait_reward: -0.8393
Metrics/base_velocity/error_vel_xy: 2.2429
Metrics/base_velocity/error_vel_yaw: 1.0400
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 1.06s
                        Total time: 793.28s
                               ETA: 2463.4s

################################################################################
                     [1m Learning iteration 731/3000 [0m                      

                       Computation: 91332 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.9675
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8037
                     Learning rate: 0.0006
                       Mean reward: 85.38
               Mean episode length: 901.93
       Episode_Reward/keep_balance: 0.8974
     Episode_Reward/rew_lin_vel_xy: 3.5239
      Episode_Reward/rew_ang_vel_z: 2.3857
    Episode_Reward/pen_base_height: -0.3223
      Episode_Reward/pen_lin_vel_z: -0.0608
     Episode_Reward/pen_ang_vel_xy: -0.1439
   Episode_Reward/pen_joint_torque: -0.1906
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.0848
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0434
   Episode_Reward/pen_joint_powers: -0.0668
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1816
Episode_Reward/pen_flat_orientation: -0.1678
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2752
   Episode_Reward/foot_landing_vel: -0.1405
   Episode_Reward/test_gait_reward: -0.8331
Metrics/base_velocity/error_vel_xy: 2.0181
Metrics/base_velocity/error_vel_yaw: 1.0755
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 1.08s
                        Total time: 794.35s
                               ETA: 2462.3s

################################################################################
                     [1m Learning iteration 732/3000 [0m                      

                       Computation: 91826 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.0499
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8058
                     Learning rate: 0.0009
                       Mean reward: 89.55
               Mean episode length: 944.88
       Episode_Reward/keep_balance: 0.9390
     Episode_Reward/rew_lin_vel_xy: 3.5790
      Episode_Reward/rew_ang_vel_z: 2.5264
    Episode_Reward/pen_base_height: -0.3075
      Episode_Reward/pen_lin_vel_z: -0.0613
     Episode_Reward/pen_ang_vel_xy: -0.1444
   Episode_Reward/pen_joint_torque: -0.1986
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.0871
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0429
   Episode_Reward/pen_joint_powers: -0.0682
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1858
Episode_Reward/pen_flat_orientation: -0.1563
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2664
   Episode_Reward/foot_landing_vel: -0.1432
   Episode_Reward/test_gait_reward: -0.8677
Metrics/base_velocity/error_vel_xy: 2.1879
Metrics/base_velocity/error_vel_yaw: 1.0846
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 1.07s
                        Total time: 795.42s
                               ETA: 2461.1s

################################################################################
                     [1m Learning iteration 733/3000 [0m                      

                       Computation: 92492 steps/s (collection: 0.940s, learning 0.123s)
               Value function loss: 1.1170
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8076
                     Learning rate: 0.0013
                       Mean reward: 87.69
               Mean episode length: 950.57
       Episode_Reward/keep_balance: 0.9433
     Episode_Reward/rew_lin_vel_xy: 3.6565
      Episode_Reward/rew_ang_vel_z: 2.5127
    Episode_Reward/pen_base_height: -0.3240
      Episode_Reward/pen_lin_vel_z: -0.0610
     Episode_Reward/pen_ang_vel_xy: -0.1503
   Episode_Reward/pen_joint_torque: -0.1992
    Episode_Reward/pen_joint_accel: -0.1153
    Episode_Reward/pen_action_rate: -0.0884
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0449
   Episode_Reward/pen_joint_powers: -0.0694
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1894
Episode_Reward/pen_flat_orientation: -0.1627
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2780
   Episode_Reward/foot_landing_vel: -0.1485
   Episode_Reward/test_gait_reward: -0.8807
Metrics/base_velocity/error_vel_xy: 2.1631
Metrics/base_velocity/error_vel_yaw: 1.1110
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 1.06s
                        Total time: 796.49s
                               ETA: 2460.0s

################################################################################
                     [1m Learning iteration 734/3000 [0m                      

                       Computation: 90852 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 1.0882
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8100
                     Learning rate: 0.0013
                       Mean reward: 90.65
               Mean episode length: 933.01
       Episode_Reward/keep_balance: 0.9475
     Episode_Reward/rew_lin_vel_xy: 3.8138
      Episode_Reward/rew_ang_vel_z: 2.5659
    Episode_Reward/pen_base_height: -0.3160
      Episode_Reward/pen_lin_vel_z: -0.0625
     Episode_Reward/pen_ang_vel_xy: -0.1475
   Episode_Reward/pen_joint_torque: -0.2023
    Episode_Reward/pen_joint_accel: -0.1101
    Episode_Reward/pen_action_rate: -0.0884
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0448
   Episode_Reward/pen_joint_powers: -0.0702
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1894
Episode_Reward/pen_flat_orientation: -0.1611
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2838
   Episode_Reward/foot_landing_vel: -0.1610
   Episode_Reward/test_gait_reward: -0.8777
Metrics/base_velocity/error_vel_xy: 2.1461
Metrics/base_velocity/error_vel_yaw: 1.0819
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 1.08s
                        Total time: 797.57s
                               ETA: 2458.9s

################################################################################
                     [1m Learning iteration 735/3000 [0m                      

                       Computation: 90748 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 1.1407
                    Surrogate loss: 0.0076
             Mean action noise std: 0.8111
                     Learning rate: 0.0001
                       Mean reward: 85.94
               Mean episode length: 928.20
       Episode_Reward/keep_balance: 0.9510
     Episode_Reward/rew_lin_vel_xy: 3.6668
      Episode_Reward/rew_ang_vel_z: 2.5700
    Episode_Reward/pen_base_height: -0.3094
      Episode_Reward/pen_lin_vel_z: -0.0599
     Episode_Reward/pen_ang_vel_xy: -0.1527
   Episode_Reward/pen_joint_torque: -0.1927
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.0891
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0444
   Episode_Reward/pen_joint_powers: -0.0685
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1914
Episode_Reward/pen_flat_orientation: -0.1532
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2716
   Episode_Reward/foot_landing_vel: -0.1510
   Episode_Reward/test_gait_reward: -0.8839
Metrics/base_velocity/error_vel_xy: 2.1919
Metrics/base_velocity/error_vel_yaw: 1.0921
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 1.08s
                        Total time: 798.65s
                               ETA: 2457.8s

################################################################################
                     [1m Learning iteration 736/3000 [0m                      

                       Computation: 91928 steps/s (collection: 0.945s, learning 0.125s)
               Value function loss: 1.0169
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8108
                     Learning rate: 0.0002
                       Mean reward: 88.47
               Mean episode length: 901.62
       Episode_Reward/keep_balance: 0.9214
     Episode_Reward/rew_lin_vel_xy: 3.7822
      Episode_Reward/rew_ang_vel_z: 2.4738
    Episode_Reward/pen_base_height: -0.3028
      Episode_Reward/pen_lin_vel_z: -0.0596
     Episode_Reward/pen_ang_vel_xy: -0.1427
   Episode_Reward/pen_joint_torque: -0.1899
    Episode_Reward/pen_joint_accel: -0.1015
    Episode_Reward/pen_action_rate: -0.0862
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0422
   Episode_Reward/pen_joint_powers: -0.0665
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1858
Episode_Reward/pen_flat_orientation: -0.1489
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2602
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.8522
Metrics/base_velocity/error_vel_xy: 2.0068
Metrics/base_velocity/error_vel_yaw: 1.0742
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 1.07s
                        Total time: 799.72s
                               ETA: 2456.7s

################################################################################
                     [1m Learning iteration 737/3000 [0m                      

                       Computation: 91842 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 1.0703
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8105
                     Learning rate: 0.0004
                       Mean reward: 88.23
               Mean episode length: 945.81
       Episode_Reward/keep_balance: 0.9486
     Episode_Reward/rew_lin_vel_xy: 3.5789
      Episode_Reward/rew_ang_vel_z: 2.5769
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0639
     Episode_Reward/pen_ang_vel_xy: -0.1502
   Episode_Reward/pen_joint_torque: -0.2028
    Episode_Reward/pen_joint_accel: -0.1123
    Episode_Reward/pen_action_rate: -0.0888
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0704
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1887
Episode_Reward/pen_flat_orientation: -0.1597
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.2872
   Episode_Reward/foot_landing_vel: -0.1477
   Episode_Reward/test_gait_reward: -0.8832
Metrics/base_velocity/error_vel_xy: 2.2669
Metrics/base_velocity/error_vel_yaw: 1.0760
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 1.07s
                        Total time: 800.79s
                               ETA: 2455.5s

################################################################################
                     [1m Learning iteration 738/3000 [0m                      

                       Computation: 91128 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.9810
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8113
                     Learning rate: 0.0006
                       Mean reward: 89.26
               Mean episode length: 935.60
       Episode_Reward/keep_balance: 0.9431
     Episode_Reward/rew_lin_vel_xy: 3.5772
      Episode_Reward/rew_ang_vel_z: 2.5463
    Episode_Reward/pen_base_height: -0.3022
      Episode_Reward/pen_lin_vel_z: -0.0620
     Episode_Reward/pen_ang_vel_xy: -0.1455
   Episode_Reward/pen_joint_torque: -0.1948
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.0887
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0432
   Episode_Reward/pen_joint_powers: -0.0682
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1915
Episode_Reward/pen_flat_orientation: -0.1540
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2713
   Episode_Reward/foot_landing_vel: -0.1435
   Episode_Reward/test_gait_reward: -0.8610
Metrics/base_velocity/error_vel_xy: 2.2744
Metrics/base_velocity/error_vel_yaw: 1.0843
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 1.08s
                        Total time: 801.87s
                               ETA: 2454.4s

################################################################################
                     [1m Learning iteration 739/3000 [0m                      

                       Computation: 92273 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 1.1049
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8111
                     Learning rate: 0.0006
                       Mean reward: 90.59
               Mean episode length: 944.49
       Episode_Reward/keep_balance: 0.9433
     Episode_Reward/rew_lin_vel_xy: 3.8148
      Episode_Reward/rew_ang_vel_z: 2.4939
    Episode_Reward/pen_base_height: -0.3140
      Episode_Reward/pen_lin_vel_z: -0.0606
     Episode_Reward/pen_ang_vel_xy: -0.1504
   Episode_Reward/pen_joint_torque: -0.1968
    Episode_Reward/pen_joint_accel: -0.1054
    Episode_Reward/pen_action_rate: -0.0898
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0697
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1943
Episode_Reward/pen_flat_orientation: -0.1549
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2814
   Episode_Reward/foot_landing_vel: -0.1433
   Episode_Reward/test_gait_reward: -0.8789
Metrics/base_velocity/error_vel_xy: 2.1084
Metrics/base_velocity/error_vel_yaw: 1.1316
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 1.07s
                        Total time: 802.94s
                               ETA: 2453.3s

################################################################################
                     [1m Learning iteration 740/3000 [0m                      

                       Computation: 91643 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.9959
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8131
                     Learning rate: 0.0006
                       Mean reward: 92.18
               Mean episode length: 970.05
       Episode_Reward/keep_balance: 0.9644
     Episode_Reward/rew_lin_vel_xy: 3.6167
      Episode_Reward/rew_ang_vel_z: 2.6159
    Episode_Reward/pen_base_height: -0.3033
      Episode_Reward/pen_lin_vel_z: -0.0598
     Episode_Reward/pen_ang_vel_xy: -0.1513
   Episode_Reward/pen_joint_torque: -0.1977
    Episode_Reward/pen_joint_accel: -0.1010
    Episode_Reward/pen_action_rate: -0.0904
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0436
   Episode_Reward/pen_joint_powers: -0.0686
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1956
Episode_Reward/pen_flat_orientation: -0.1502
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2703
   Episode_Reward/foot_landing_vel: -0.1406
   Episode_Reward/test_gait_reward: -0.8888
Metrics/base_velocity/error_vel_xy: 2.3477
Metrics/base_velocity/error_vel_yaw: 1.1008
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 1.07s
                        Total time: 804.01s
                               ETA: 2452.2s

################################################################################
                     [1m Learning iteration 741/3000 [0m                      

                       Computation: 91475 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 1.0651
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8142
                     Learning rate: 0.0006
                       Mean reward: 93.51
               Mean episode length: 964.85
       Episode_Reward/keep_balance: 0.9593
     Episode_Reward/rew_lin_vel_xy: 3.7370
      Episode_Reward/rew_ang_vel_z: 2.5568
    Episode_Reward/pen_base_height: -0.3121
      Episode_Reward/pen_lin_vel_z: -0.0616
     Episode_Reward/pen_ang_vel_xy: -0.1487
   Episode_Reward/pen_joint_torque: -0.2053
    Episode_Reward/pen_joint_accel: -0.1129
    Episode_Reward/pen_action_rate: -0.0912
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0457
   Episode_Reward/pen_joint_powers: -0.0711
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1951
Episode_Reward/pen_flat_orientation: -0.1616
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.2807
   Episode_Reward/foot_landing_vel: -0.1464
   Episode_Reward/test_gait_reward: -0.8847
Metrics/base_velocity/error_vel_xy: 2.2427
Metrics/base_velocity/error_vel_yaw: 1.1317
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 1.07s
                        Total time: 805.08s
                               ETA: 2451.1s

################################################################################
                     [1m Learning iteration 742/3000 [0m                      

                       Computation: 90886 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 1.0471
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8128
                     Learning rate: 0.0006
                       Mean reward: 84.62
               Mean episode length: 921.70
       Episode_Reward/keep_balance: 0.9102
     Episode_Reward/rew_lin_vel_xy: 3.4460
      Episode_Reward/rew_ang_vel_z: 2.4353
    Episode_Reward/pen_base_height: -0.3175
      Episode_Reward/pen_lin_vel_z: -0.0654
     Episode_Reward/pen_ang_vel_xy: -0.1529
   Episode_Reward/pen_joint_torque: -0.2038
    Episode_Reward/pen_joint_accel: -0.1168
    Episode_Reward/pen_action_rate: -0.0876
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0463
   Episode_Reward/pen_joint_powers: -0.0718
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1850
Episode_Reward/pen_flat_orientation: -0.1684
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2943
   Episode_Reward/foot_landing_vel: -0.1560
   Episode_Reward/test_gait_reward: -0.8546
Metrics/base_velocity/error_vel_xy: 2.1589
Metrics/base_velocity/error_vel_yaw: 1.0653
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 1.08s
                        Total time: 806.16s
                               ETA: 2450.0s

################################################################################
                     [1m Learning iteration 743/3000 [0m                      

                       Computation: 89093 steps/s (collection: 0.978s, learning 0.125s)
               Value function loss: 1.0636
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8129
                     Learning rate: 0.0006
                       Mean reward: 86.91
               Mean episode length: 938.91
       Episode_Reward/keep_balance: 0.9527
     Episode_Reward/rew_lin_vel_xy: 3.6136
      Episode_Reward/rew_ang_vel_z: 2.5302
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0577
     Episode_Reward/pen_ang_vel_xy: -0.1472
   Episode_Reward/pen_joint_torque: -0.1939
    Episode_Reward/pen_joint_accel: -0.1153
    Episode_Reward/pen_action_rate: -0.0905
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0444
   Episode_Reward/pen_joint_powers: -0.0684
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1952
Episode_Reward/pen_flat_orientation: -0.1537
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2753
   Episode_Reward/foot_landing_vel: -0.1487
   Episode_Reward/test_gait_reward: -0.8821
Metrics/base_velocity/error_vel_xy: 2.1873
Metrics/base_velocity/error_vel_yaw: 1.1314
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 1.10s
                        Total time: 807.27s
                               ETA: 2448.9s

################################################################################
                     [1m Learning iteration 744/3000 [0m                      

                       Computation: 92674 steps/s (collection: 0.937s, learning 0.124s)
               Value function loss: 1.1255
                    Surrogate loss: -0.0008
             Mean action noise std: 0.8146
                     Learning rate: 0.0003
                       Mean reward: 87.19
               Mean episode length: 926.72
       Episode_Reward/keep_balance: 0.9307
     Episode_Reward/rew_lin_vel_xy: 3.4649
      Episode_Reward/rew_ang_vel_z: 2.4761
    Episode_Reward/pen_base_height: -0.2945
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.1519
   Episode_Reward/pen_joint_torque: -0.1861
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.0894
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0434
   Episode_Reward/pen_joint_powers: -0.0662
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1940
Episode_Reward/pen_flat_orientation: -0.1435
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2595
   Episode_Reward/foot_landing_vel: -0.1363
   Episode_Reward/test_gait_reward: -0.8633
Metrics/base_velocity/error_vel_xy: 2.1503
Metrics/base_velocity/error_vel_yaw: 1.1031
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 1.06s
                        Total time: 808.33s
                               ETA: 2447.8s

################################################################################
                     [1m Learning iteration 745/3000 [0m                      

                       Computation: 85392 steps/s (collection: 1.021s, learning 0.130s)
               Value function loss: 1.1000
                    Surrogate loss: 0.0007
             Mean action noise std: 0.8153
                     Learning rate: 0.0000
                       Mean reward: 93.04
               Mean episode length: 936.77
       Episode_Reward/keep_balance: 0.9143
     Episode_Reward/rew_lin_vel_xy: 3.8499
      Episode_Reward/rew_ang_vel_z: 2.4421
    Episode_Reward/pen_base_height: -0.3110
      Episode_Reward/pen_lin_vel_z: -0.0587
     Episode_Reward/pen_ang_vel_xy: -0.1396
   Episode_Reward/pen_joint_torque: -0.1899
    Episode_Reward/pen_joint_accel: -0.1015
    Episode_Reward/pen_action_rate: -0.0868
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0425
   Episode_Reward/pen_joint_powers: -0.0659
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1876
Episode_Reward/pen_flat_orientation: -0.1576
  Episode_Reward/pen_feet_distance: -0.0010
Episode_Reward/pen_feet_regulation: -0.2664
   Episode_Reward/foot_landing_vel: -0.1388
   Episode_Reward/test_gait_reward: -0.8482
Metrics/base_velocity/error_vel_xy: 1.9223
Metrics/base_velocity/error_vel_yaw: 1.0804
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 1.15s
                        Total time: 809.48s
                               ETA: 2446.9s

################################################################################
                     [1m Learning iteration 746/3000 [0m                      

                       Computation: 89349 steps/s (collection: 0.973s, learning 0.127s)
               Value function loss: 1.0214
                    Surrogate loss: 0.0050
             Mean action noise std: 0.8153
                     Learning rate: 0.0000
                       Mean reward: 86.62
               Mean episode length: 926.09
       Episode_Reward/keep_balance: 0.8998
     Episode_Reward/rew_lin_vel_xy: 3.4875
      Episode_Reward/rew_ang_vel_z: 2.4045
    Episode_Reward/pen_base_height: -0.3067
      Episode_Reward/pen_lin_vel_z: -0.0585
     Episode_Reward/pen_ang_vel_xy: -0.1485
   Episode_Reward/pen_joint_torque: -0.1886
    Episode_Reward/pen_joint_accel: -0.0957
    Episode_Reward/pen_action_rate: -0.0867
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0427
   Episode_Reward/pen_joint_powers: -0.0663
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1869
Episode_Reward/pen_flat_orientation: -0.1582
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2654
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.8369
Metrics/base_velocity/error_vel_xy: 2.0897
Metrics/base_velocity/error_vel_yaw: 1.0571
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 1.10s
                        Total time: 810.58s
                               ETA: 2445.8s

################################################################################
                     [1m Learning iteration 747/3000 [0m                      

                       Computation: 90231 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 1.1048
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8151
                     Learning rate: 0.0001
                       Mean reward: 83.01
               Mean episode length: 881.76
       Episode_Reward/keep_balance: 0.8936
     Episode_Reward/rew_lin_vel_xy: 3.4181
      Episode_Reward/rew_ang_vel_z: 2.3512
    Episode_Reward/pen_base_height: -0.3127
      Episode_Reward/pen_lin_vel_z: -0.0616
     Episode_Reward/pen_ang_vel_xy: -0.1479
   Episode_Reward/pen_joint_torque: -0.1935
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.0872
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0440
   Episode_Reward/pen_joint_powers: -0.0677
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1860
Episode_Reward/pen_flat_orientation: -0.1576
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2730
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.8318
Metrics/base_velocity/error_vel_xy: 2.1254
Metrics/base_velocity/error_vel_yaw: 1.0816
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 1.09s
                        Total time: 811.67s
                               ETA: 2444.8s

################################################################################
                     [1m Learning iteration 748/3000 [0m                      

                       Computation: 89724 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 1.1278
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8156
                     Learning rate: 0.0003
                       Mean reward: 85.32
               Mean episode length: 926.20
       Episode_Reward/keep_balance: 0.9340
     Episode_Reward/rew_lin_vel_xy: 3.7439
      Episode_Reward/rew_ang_vel_z: 2.5037
    Episode_Reward/pen_base_height: -0.3046
      Episode_Reward/pen_lin_vel_z: -0.0580
     Episode_Reward/pen_ang_vel_xy: -0.1456
   Episode_Reward/pen_joint_torque: -0.1961
    Episode_Reward/pen_joint_accel: -0.1074
    Episode_Reward/pen_action_rate: -0.0889
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0424
   Episode_Reward/pen_joint_powers: -0.0672
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1916
Episode_Reward/pen_flat_orientation: -0.1519
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2624
   Episode_Reward/foot_landing_vel: -0.1382
   Episode_Reward/test_gait_reward: -0.8674
Metrics/base_velocity/error_vel_xy: 2.0332
Metrics/base_velocity/error_vel_yaw: 1.0881
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 1.10s
                        Total time: 812.77s
                               ETA: 2443.7s

################################################################################
                     [1m Learning iteration 749/3000 [0m                      

                       Computation: 88156 steps/s (collection: 0.992s, learning 0.123s)
               Value function loss: 1.0825
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8190
                     Learning rate: 0.0006
                       Mean reward: 77.87
               Mean episode length: 871.30
       Episode_Reward/keep_balance: 0.8905
     Episode_Reward/rew_lin_vel_xy: 3.3970
      Episode_Reward/rew_ang_vel_z: 2.3719
    Episode_Reward/pen_base_height: -0.3187
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1449
   Episode_Reward/pen_joint_torque: -0.1842
    Episode_Reward/pen_joint_accel: -0.1027
    Episode_Reward/pen_action_rate: -0.0860
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0416
   Episode_Reward/pen_joint_powers: -0.0645
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1852
Episode_Reward/pen_flat_orientation: -0.1546
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2600
   Episode_Reward/foot_landing_vel: -0.1388
   Episode_Reward/test_gait_reward: -0.8277
Metrics/base_velocity/error_vel_xy: 2.1162
Metrics/base_velocity/error_vel_yaw: 1.0600
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 1.12s
                        Total time: 813.88s
                               ETA: 2442.7s

################################################################################
                     [1m Learning iteration 750/3000 [0m                      

                       Computation: 90049 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 1.0652
                    Surrogate loss: -0.0012
             Mean action noise std: 0.8199
                     Learning rate: 0.0003
                       Mean reward: 86.80
               Mean episode length: 920.37
       Episode_Reward/keep_balance: 0.9195
     Episode_Reward/rew_lin_vel_xy: 3.7089
      Episode_Reward/rew_ang_vel_z: 2.4435
    Episode_Reward/pen_base_height: -0.3097
      Episode_Reward/pen_lin_vel_z: -0.0583
     Episode_Reward/pen_ang_vel_xy: -0.1488
   Episode_Reward/pen_joint_torque: -0.1886
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.0887
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0439
   Episode_Reward/pen_joint_powers: -0.0672
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1923
Episode_Reward/pen_flat_orientation: -0.1553
  Episode_Reward/pen_feet_distance: -0.0014
Episode_Reward/pen_feet_regulation: -0.2722
   Episode_Reward/foot_landing_vel: -0.1433
   Episode_Reward/test_gait_reward: -0.8511
Metrics/base_velocity/error_vel_xy: 2.0158
Metrics/base_velocity/error_vel_yaw: 1.0938
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 1.09s
                        Total time: 814.97s
                               ETA: 2441.7s

################################################################################
                     [1m Learning iteration 751/3000 [0m                      

                       Computation: 88403 steps/s (collection: 0.987s, learning 0.125s)
               Value function loss: 0.9626
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8188
                     Learning rate: 0.0006
                       Mean reward: 88.41
               Mean episode length: 941.63
       Episode_Reward/keep_balance: 0.9023
     Episode_Reward/rew_lin_vel_xy: 3.4686
      Episode_Reward/rew_ang_vel_z: 2.4377
    Episode_Reward/pen_base_height: -0.3089
      Episode_Reward/pen_lin_vel_z: -0.0585
     Episode_Reward/pen_ang_vel_xy: -0.1430
   Episode_Reward/pen_joint_torque: -0.1945
    Episode_Reward/pen_joint_accel: -0.0993
    Episode_Reward/pen_action_rate: -0.0859
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0416
   Episode_Reward/pen_joint_powers: -0.0662
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1850
Episode_Reward/pen_flat_orientation: -0.1513
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.2667
   Episode_Reward/foot_landing_vel: -0.1304
   Episode_Reward/test_gait_reward: -0.8331
Metrics/base_velocity/error_vel_xy: 2.1459
Metrics/base_velocity/error_vel_yaw: 1.0356
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 1.11s
                        Total time: 816.08s
                               ETA: 2440.7s

################################################################################
                     [1m Learning iteration 752/3000 [0m                      

                       Computation: 92434 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 1.0816
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8181
                     Learning rate: 0.0006
                       Mean reward: 91.58
               Mean episode length: 936.15
       Episode_Reward/keep_balance: 0.9411
     Episode_Reward/rew_lin_vel_xy: 3.7638
      Episode_Reward/rew_ang_vel_z: 2.5284
    Episode_Reward/pen_base_height: -0.3065
      Episode_Reward/pen_lin_vel_z: -0.0571
     Episode_Reward/pen_ang_vel_xy: -0.1491
   Episode_Reward/pen_joint_torque: -0.1932
    Episode_Reward/pen_joint_accel: -0.1041
    Episode_Reward/pen_action_rate: -0.0900
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0656
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1952
Episode_Reward/pen_flat_orientation: -0.1415
  Episode_Reward/pen_feet_distance: -0.0028
Episode_Reward/pen_feet_regulation: -0.2478
   Episode_Reward/foot_landing_vel: -0.1323
   Episode_Reward/test_gait_reward: -0.8696
Metrics/base_velocity/error_vel_xy: 2.1187
Metrics/base_velocity/error_vel_yaw: 1.0884
      Episode_Termination/time_out: 3.1250
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 1.06s
                        Total time: 817.15s
                               ETA: 2439.5s

################################################################################
                     [1m Learning iteration 753/3000 [0m                      

                       Computation: 88555 steps/s (collection: 0.985s, learning 0.125s)
               Value function loss: 1.1314
                    Surrogate loss: -0.0005
             Mean action noise std: 0.8174
                     Learning rate: 0.0004
                       Mean reward: 89.10
               Mean episode length: 927.93
       Episode_Reward/keep_balance: 0.9379
     Episode_Reward/rew_lin_vel_xy: 3.6872
      Episode_Reward/rew_ang_vel_z: 2.4695
    Episode_Reward/pen_base_height: -0.3064
      Episode_Reward/pen_lin_vel_z: -0.0587
     Episode_Reward/pen_ang_vel_xy: -0.1528
   Episode_Reward/pen_joint_torque: -0.1925
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.0912
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0441
   Episode_Reward/pen_joint_powers: -0.0679
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1987
Episode_Reward/pen_flat_orientation: -0.1509
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2688
   Episode_Reward/foot_landing_vel: -0.1447
   Episode_Reward/test_gait_reward: -0.8630
Metrics/base_velocity/error_vel_xy: 2.2301
Metrics/base_velocity/error_vel_yaw: 1.1306
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 1.11s
                        Total time: 818.26s
                               ETA: 2438.5s

################################################################################
                     [1m Learning iteration 754/3000 [0m                      

                       Computation: 87146 steps/s (collection: 1.005s, learning 0.123s)
               Value function loss: 1.0857
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8180
                     Learning rate: 0.0006
                       Mean reward: 79.06
               Mean episode length: 885.07
       Episode_Reward/keep_balance: 0.8859
     Episode_Reward/rew_lin_vel_xy: 3.3381
      Episode_Reward/rew_ang_vel_z: 2.3490
    Episode_Reward/pen_base_height: -0.3099
      Episode_Reward/pen_lin_vel_z: -0.0591
     Episode_Reward/pen_ang_vel_xy: -0.1480
   Episode_Reward/pen_joint_torque: -0.1873
    Episode_Reward/pen_joint_accel: -0.0972
    Episode_Reward/pen_action_rate: -0.0864
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0419
   Episode_Reward/pen_joint_powers: -0.0652
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1870
Episode_Reward/pen_flat_orientation: -0.1498
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.2700
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.8197
Metrics/base_velocity/error_vel_xy: 2.1260
Metrics/base_velocity/error_vel_yaw: 1.0606
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 1.13s
                        Total time: 819.39s
                               ETA: 2437.5s

################################################################################
                     [1m Learning iteration 755/3000 [0m                      

                       Computation: 88109 steps/s (collection: 0.984s, learning 0.132s)
               Value function loss: 1.1454
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8196
                     Learning rate: 0.0009
                       Mean reward: 92.39
               Mean episode length: 951.07
       Episode_Reward/keep_balance: 0.9494
     Episode_Reward/rew_lin_vel_xy: 3.8976
      Episode_Reward/rew_ang_vel_z: 2.5216
    Episode_Reward/pen_base_height: -0.3332
      Episode_Reward/pen_lin_vel_z: -0.0635
     Episode_Reward/pen_ang_vel_xy: -0.1525
   Episode_Reward/pen_joint_torque: -0.2081
    Episode_Reward/pen_joint_accel: -0.1126
    Episode_Reward/pen_action_rate: -0.0930
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0452
   Episode_Reward/pen_joint_powers: -0.0717
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1985
Episode_Reward/pen_flat_orientation: -0.1565
  Episode_Reward/pen_feet_distance: -0.0016
Episode_Reward/pen_feet_regulation: -0.2954
   Episode_Reward/foot_landing_vel: -0.1535
   Episode_Reward/test_gait_reward: -0.8884
Metrics/base_velocity/error_vel_xy: 2.0951
Metrics/base_velocity/error_vel_yaw: 1.1281
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 1.12s
                        Total time: 820.50s
                               ETA: 2436.5s

################################################################################
                     [1m Learning iteration 756/3000 [0m                      

                       Computation: 84272 steps/s (collection: 1.040s, learning 0.126s)
               Value function loss: 1.2267
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8188
                     Learning rate: 0.0009
                       Mean reward: 85.70
               Mean episode length: 909.32
       Episode_Reward/keep_balance: 0.9135
     Episode_Reward/rew_lin_vel_xy: 3.3890
      Episode_Reward/rew_ang_vel_z: 2.4301
    Episode_Reward/pen_base_height: -0.3113
      Episode_Reward/pen_lin_vel_z: -0.0558
     Episode_Reward/pen_ang_vel_xy: -0.1463
   Episode_Reward/pen_joint_torque: -0.1956
    Episode_Reward/pen_joint_accel: -0.1020
    Episode_Reward/pen_action_rate: -0.0890
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0418
   Episode_Reward/pen_joint_powers: -0.0663
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1934
Episode_Reward/pen_flat_orientation: -0.1451
  Episode_Reward/pen_feet_distance: -0.0009
Episode_Reward/pen_feet_regulation: -0.2596
   Episode_Reward/foot_landing_vel: -0.1333
   Episode_Reward/test_gait_reward: -0.8405
Metrics/base_velocity/error_vel_xy: 2.1946
Metrics/base_velocity/error_vel_yaw: 1.0930
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 1.17s
                        Total time: 821.67s
                               ETA: 2435.7s

################################################################################
                     [1m Learning iteration 757/3000 [0m                      

                       Computation: 88776 steps/s (collection: 0.982s, learning 0.126s)
               Value function loss: 1.0720
                    Surrogate loss: -0.0009
             Mean action noise std: 0.8197
                     Learning rate: 0.0006
                       Mean reward: 82.63
               Mean episode length: 919.78
       Episode_Reward/keep_balance: 0.9231
     Episode_Reward/rew_lin_vel_xy: 3.4768
      Episode_Reward/rew_ang_vel_z: 2.4433
    Episode_Reward/pen_base_height: -0.3181
      Episode_Reward/pen_lin_vel_z: -0.0630
     Episode_Reward/pen_ang_vel_xy: -0.1566
   Episode_Reward/pen_joint_torque: -0.2051
    Episode_Reward/pen_joint_accel: -0.1172
    Episode_Reward/pen_action_rate: -0.0909
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0466
   Episode_Reward/pen_joint_powers: -0.0725
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1958
Episode_Reward/pen_flat_orientation: -0.1614
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2958
   Episode_Reward/foot_landing_vel: -0.1508
   Episode_Reward/test_gait_reward: -0.8605
Metrics/base_velocity/error_vel_xy: 2.2366
Metrics/base_velocity/error_vel_yaw: 1.1051
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 1.11s
                        Total time: 822.78s
                               ETA: 2434.7s

################################################################################
                     [1m Learning iteration 758/3000 [0m                      

                       Computation: 90929 steps/s (collection: 0.955s, learning 0.126s)
               Value function loss: 1.0614
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8192
                     Learning rate: 0.0004
                       Mean reward: 89.74
               Mean episode length: 939.08
       Episode_Reward/keep_balance: 0.9344
     Episode_Reward/rew_lin_vel_xy: 3.6667
      Episode_Reward/rew_ang_vel_z: 2.4754
    Episode_Reward/pen_base_height: -0.3175
      Episode_Reward/pen_lin_vel_z: -0.0590
     Episode_Reward/pen_ang_vel_xy: -0.1523
   Episode_Reward/pen_joint_torque: -0.2020
    Episode_Reward/pen_joint_accel: -0.1132
    Episode_Reward/pen_action_rate: -0.0912
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0449
   Episode_Reward/pen_joint_powers: -0.0701
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1967
Episode_Reward/pen_flat_orientation: -0.1573
  Episode_Reward/pen_feet_distance: -0.0044
Episode_Reward/pen_feet_regulation: -0.2831
   Episode_Reward/foot_landing_vel: -0.1470
   Episode_Reward/test_gait_reward: -0.8634
Metrics/base_velocity/error_vel_xy: 2.1987
Metrics/base_velocity/error_vel_yaw: 1.1199
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 1.08s
                        Total time: 823.86s
                               ETA: 2433.6s

################################################################################
                     [1m Learning iteration 759/3000 [0m                      

                       Computation: 91879 steps/s (collection: 0.945s, learning 0.125s)
               Value function loss: 1.2029
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8178
                     Learning rate: 0.0009
                       Mean reward: 86.69
               Mean episode length: 942.75
       Episode_Reward/keep_balance: 0.9052
     Episode_Reward/rew_lin_vel_xy: 3.5561
      Episode_Reward/rew_ang_vel_z: 2.4241
    Episode_Reward/pen_base_height: -0.3064
      Episode_Reward/pen_lin_vel_z: -0.0590
     Episode_Reward/pen_ang_vel_xy: -0.1482
   Episode_Reward/pen_joint_torque: -0.1965
    Episode_Reward/pen_joint_accel: -0.1121
    Episode_Reward/pen_action_rate: -0.0891
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0440
   Episode_Reward/pen_joint_powers: -0.0680
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1920
Episode_Reward/pen_flat_orientation: -0.1460
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2779
   Episode_Reward/foot_landing_vel: -0.1468
   Episode_Reward/test_gait_reward: -0.8383
Metrics/base_velocity/error_vel_xy: 2.1200
Metrics/base_velocity/error_vel_yaw: 1.0657
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 1.07s
                        Total time: 824.93s
                               ETA: 2432.4s

################################################################################
                     [1m Learning iteration 760/3000 [0m                      

                       Computation: 90212 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 1.0455
                    Surrogate loss: 0.0002
             Mean action noise std: 0.8182
                     Learning rate: 0.0004
                       Mean reward: 83.34
               Mean episode length: 897.12
       Episode_Reward/keep_balance: 0.9028
     Episode_Reward/rew_lin_vel_xy: 3.5635
      Episode_Reward/rew_ang_vel_z: 2.3906
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0611
     Episode_Reward/pen_ang_vel_xy: -0.1429
   Episode_Reward/pen_joint_torque: -0.2017
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.0877
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0436
   Episode_Reward/pen_joint_powers: -0.0686
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1895
Episode_Reward/pen_flat_orientation: -0.1576
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2843
   Episode_Reward/foot_landing_vel: -0.1426
   Episode_Reward/test_gait_reward: -0.8363
Metrics/base_velocity/error_vel_xy: 2.0825
Metrics/base_velocity/error_vel_yaw: 1.0804
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 1.09s
                        Total time: 826.02s
                               ETA: 2431.4s

################################################################################
                     [1m Learning iteration 761/3000 [0m                      

                       Computation: 90470 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 1.1898
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8196
                     Learning rate: 0.0006
                       Mean reward: 85.62
               Mean episode length: 924.05
       Episode_Reward/keep_balance: 0.9223
     Episode_Reward/rew_lin_vel_xy: 3.6480
      Episode_Reward/rew_ang_vel_z: 2.4285
    Episode_Reward/pen_base_height: -0.3246
      Episode_Reward/pen_lin_vel_z: -0.0609
     Episode_Reward/pen_ang_vel_xy: -0.1514
   Episode_Reward/pen_joint_torque: -0.2000
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.0914
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0449
   Episode_Reward/pen_joint_powers: -0.0697
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1971
Episode_Reward/pen_flat_orientation: -0.1675
  Episode_Reward/pen_feet_distance: -0.0021
Episode_Reward/pen_feet_regulation: -0.2961
   Episode_Reward/foot_landing_vel: -0.1466
   Episode_Reward/test_gait_reward: -0.8585
Metrics/base_velocity/error_vel_xy: 2.1096
Metrics/base_velocity/error_vel_yaw: 1.1188
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 1.09s
                        Total time: 827.10s
                               ETA: 2430.3s

################################################################################
                     [1m Learning iteration 762/3000 [0m                      

                       Computation: 85794 steps/s (collection: 1.020s, learning 0.126s)
               Value function loss: 1.0646
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8199
                     Learning rate: 0.0009
                       Mean reward: 83.58
               Mean episode length: 893.86
       Episode_Reward/keep_balance: 0.8693
     Episode_Reward/rew_lin_vel_xy: 3.4685
      Episode_Reward/rew_ang_vel_z: 2.2553
    Episode_Reward/pen_base_height: -0.3114
      Episode_Reward/pen_lin_vel_z: -0.0602
     Episode_Reward/pen_ang_vel_xy: -0.1530
   Episode_Reward/pen_joint_torque: -0.1873
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.0882
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0451
   Episode_Reward/pen_joint_powers: -0.0677
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1895
Episode_Reward/pen_flat_orientation: -0.1635
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2877
   Episode_Reward/foot_landing_vel: -0.1423
   Episode_Reward/test_gait_reward: -0.8132
Metrics/base_velocity/error_vel_xy: 1.9785
Metrics/base_velocity/error_vel_yaw: 1.0967
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 1.15s
                        Total time: 828.25s
                               ETA: 2429.4s

################################################################################
                     [1m Learning iteration 763/3000 [0m                      

                       Computation: 91158 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 1.1293
                    Surrogate loss: 0.0002
             Mean action noise std: 0.8203
                     Learning rate: 0.0004
                       Mean reward: 88.09
               Mean episode length: 923.71
       Episode_Reward/keep_balance: 0.9360
     Episode_Reward/rew_lin_vel_xy: 3.7664
      Episode_Reward/rew_ang_vel_z: 2.4716
    Episode_Reward/pen_base_height: -0.3294
      Episode_Reward/pen_lin_vel_z: -0.0589
     Episode_Reward/pen_ang_vel_xy: -0.1500
   Episode_Reward/pen_joint_torque: -0.2092
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.0921
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0441
   Episode_Reward/pen_joint_powers: -0.0703
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1988
Episode_Reward/pen_flat_orientation: -0.1594
  Episode_Reward/pen_feet_distance: -0.0031
Episode_Reward/pen_feet_regulation: -0.2920
   Episode_Reward/foot_landing_vel: -0.1392
   Episode_Reward/test_gait_reward: -0.8661
Metrics/base_velocity/error_vel_xy: 2.1520
Metrics/base_velocity/error_vel_yaw: 1.1212
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 1.08s
                        Total time: 829.33s
                               ETA: 2428.3s

################################################################################
                     [1m Learning iteration 764/3000 [0m                      

                       Computation: 88620 steps/s (collection: 0.983s, learning 0.126s)
               Value function loss: 1.0674
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8205
                     Learning rate: 0.0006
                       Mean reward: 87.57
               Mean episode length: 928.79
       Episode_Reward/keep_balance: 0.9241
     Episode_Reward/rew_lin_vel_xy: 3.6583
      Episode_Reward/rew_ang_vel_z: 2.4717
    Episode_Reward/pen_base_height: -0.3209
      Episode_Reward/pen_lin_vel_z: -0.0625
     Episode_Reward/pen_ang_vel_xy: -0.1505
   Episode_Reward/pen_joint_torque: -0.2069
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.0908
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0706
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1952
Episode_Reward/pen_flat_orientation: -0.1497
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.2966
   Episode_Reward/foot_landing_vel: -0.1527
   Episode_Reward/test_gait_reward: -0.8535
Metrics/base_velocity/error_vel_xy: 2.2327
Metrics/base_velocity/error_vel_yaw: 1.0824
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 1.11s
                        Total time: 830.44s
                               ETA: 2427.3s

################################################################################
                     [1m Learning iteration 765/3000 [0m                      

                       Computation: 91252 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.9964
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8202
                     Learning rate: 0.0004
                       Mean reward: 86.84
               Mean episode length: 943.34
       Episode_Reward/keep_balance: 0.9471
     Episode_Reward/rew_lin_vel_xy: 3.9279
      Episode_Reward/rew_ang_vel_z: 2.4467
    Episode_Reward/pen_base_height: -0.3423
      Episode_Reward/pen_lin_vel_z: -0.0641
     Episode_Reward/pen_ang_vel_xy: -0.1499
   Episode_Reward/pen_joint_torque: -0.2084
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.0945
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0470
   Episode_Reward/pen_joint_powers: -0.0727
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2038
Episode_Reward/pen_flat_orientation: -0.1678
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.3185
   Episode_Reward/foot_landing_vel: -0.1591
   Episode_Reward/test_gait_reward: -0.8845
Metrics/base_velocity/error_vel_xy: 2.0645
Metrics/base_velocity/error_vel_yaw: 1.1751
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 1.08s
                        Total time: 831.51s
                               ETA: 2426.2s

################################################################################
                     [1m Learning iteration 766/3000 [0m                      

                       Computation: 91613 steps/s (collection: 0.944s, learning 0.129s)
               Value function loss: 1.0910
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8212
                     Learning rate: 0.0006
                       Mean reward: 85.60
               Mean episode length: 932.68
       Episode_Reward/keep_balance: 0.9228
     Episode_Reward/rew_lin_vel_xy: 3.4597
      Episode_Reward/rew_ang_vel_z: 2.4368
    Episode_Reward/pen_base_height: -0.3221
      Episode_Reward/pen_lin_vel_z: -0.0582
     Episode_Reward/pen_ang_vel_xy: -0.1547
   Episode_Reward/pen_joint_torque: -0.2066
    Episode_Reward/pen_joint_accel: -0.1128
    Episode_Reward/pen_action_rate: -0.0922
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0711
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1985
Episode_Reward/pen_flat_orientation: -0.1542
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2856
   Episode_Reward/foot_landing_vel: -0.1504
   Episode_Reward/test_gait_reward: -0.8510
Metrics/base_velocity/error_vel_xy: 2.2180
Metrics/base_velocity/error_vel_yaw: 1.1190
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 1.07s
                        Total time: 832.59s
                               ETA: 2425.0s

################################################################################
                     [1m Learning iteration 767/3000 [0m                      

                       Computation: 90023 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 1.0840
                    Surrogate loss: 0.0038
             Mean action noise std: 0.8216
                     Learning rate: 0.0001
                       Mean reward: 84.59
               Mean episode length: 911.89
       Episode_Reward/keep_balance: 0.9186
     Episode_Reward/rew_lin_vel_xy: 3.4272
      Episode_Reward/rew_ang_vel_z: 2.4435
    Episode_Reward/pen_base_height: -0.3108
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1490
   Episode_Reward/pen_joint_torque: -0.1934
    Episode_Reward/pen_joint_accel: -0.0966
    Episode_Reward/pen_action_rate: -0.0899
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0428
   Episode_Reward/pen_joint_powers: -0.0666
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1957
Episode_Reward/pen_flat_orientation: -0.1445
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2746
   Episode_Reward/foot_landing_vel: -0.1387
   Episode_Reward/test_gait_reward: -0.8422
Metrics/base_velocity/error_vel_xy: 2.2349
Metrics/base_velocity/error_vel_yaw: 1.0920
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 1.09s
                        Total time: 833.68s
                               ETA: 2424.0s

################################################################################
                     [1m Learning iteration 768/3000 [0m                      

                       Computation: 90790 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.9825
                    Surrogate loss: -0.0003
             Mean action noise std: 0.8216
                     Learning rate: 0.0001
                       Mean reward: 83.48
               Mean episode length: 901.02
       Episode_Reward/keep_balance: 0.8815
     Episode_Reward/rew_lin_vel_xy: 3.4916
      Episode_Reward/rew_ang_vel_z: 2.3342
    Episode_Reward/pen_base_height: -0.3022
      Episode_Reward/pen_lin_vel_z: -0.0547
     Episode_Reward/pen_ang_vel_xy: -0.1427
   Episode_Reward/pen_joint_torque: -0.1880
    Episode_Reward/pen_joint_accel: -0.0962
    Episode_Reward/pen_action_rate: -0.0869
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0405
   Episode_Reward/pen_joint_powers: -0.0640
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1896
Episode_Reward/pen_flat_orientation: -0.1441
  Episode_Reward/pen_feet_distance: -0.0029
Episode_Reward/pen_feet_regulation: -0.2536
   Episode_Reward/foot_landing_vel: -0.1297
   Episode_Reward/test_gait_reward: -0.8086
Metrics/base_velocity/error_vel_xy: 2.0432
Metrics/base_velocity/error_vel_yaw: 1.0571
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 1.08s
                        Total time: 834.76s
                               ETA: 2422.9s

################################################################################
                     [1m Learning iteration 769/3000 [0m                      

                       Computation: 90931 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 1.1025
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8219
                     Learning rate: 0.0002
                       Mean reward: 87.93
               Mean episode length: 917.71
       Episode_Reward/keep_balance: 0.9312
     Episode_Reward/rew_lin_vel_xy: 3.6810
      Episode_Reward/rew_ang_vel_z: 2.4682
    Episode_Reward/pen_base_height: -0.3145
      Episode_Reward/pen_lin_vel_z: -0.0551
     Episode_Reward/pen_ang_vel_xy: -0.1452
   Episode_Reward/pen_joint_torque: -0.2041
    Episode_Reward/pen_joint_accel: -0.1083
    Episode_Reward/pen_action_rate: -0.0918
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0429
   Episode_Reward/pen_joint_powers: -0.0684
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.1993
Episode_Reward/pen_flat_orientation: -0.1417
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2770
   Episode_Reward/foot_landing_vel: -0.1338
   Episode_Reward/test_gait_reward: -0.8623
Metrics/base_velocity/error_vel_xy: 2.1734
Metrics/base_velocity/error_vel_yaw: 1.1031
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 1.08s
                        Total time: 835.84s
                               ETA: 2421.8s

################################################################################
                     [1m Learning iteration 770/3000 [0m                      

                       Computation: 91851 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 1.0659
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8211
                     Learning rate: 0.0004
                       Mean reward: 93.87
               Mean episode length: 958.23
       Episode_Reward/keep_balance: 0.9596
     Episode_Reward/rew_lin_vel_xy: 4.0660
      Episode_Reward/rew_ang_vel_z: 2.4796
    Episode_Reward/pen_base_height: -0.3177
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1611
   Episode_Reward/pen_joint_torque: -0.2005
    Episode_Reward/pen_joint_accel: -0.1184
    Episode_Reward/pen_action_rate: -0.0965
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0459
   Episode_Reward/pen_joint_powers: -0.0702
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2110
Episode_Reward/pen_flat_orientation: -0.1482
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2970
   Episode_Reward/foot_landing_vel: -0.1543
   Episode_Reward/test_gait_reward: -0.8873
Metrics/base_velocity/error_vel_xy: 2.0414
Metrics/base_velocity/error_vel_yaw: 1.1942
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 1.07s
                        Total time: 836.91s
                               ETA: 2420.6s

################################################################################
                     [1m Learning iteration 771/3000 [0m                      

                       Computation: 91766 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 1.1179
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8209
                     Learning rate: 0.0006
                       Mean reward: 94.77
               Mean episode length: 947.97
       Episode_Reward/keep_balance: 0.9600
     Episode_Reward/rew_lin_vel_xy: 4.0378
      Episode_Reward/rew_ang_vel_z: 2.5645
    Episode_Reward/pen_base_height: -0.3145
      Episode_Reward/pen_lin_vel_z: -0.0590
     Episode_Reward/pen_ang_vel_xy: -0.1559
   Episode_Reward/pen_joint_torque: -0.2044
    Episode_Reward/pen_joint_accel: -0.1077
    Episode_Reward/pen_action_rate: -0.0956
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0448
   Episode_Reward/pen_joint_powers: -0.0703
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2073
Episode_Reward/pen_flat_orientation: -0.1456
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2833
   Episode_Reward/foot_landing_vel: -0.1454
   Episode_Reward/test_gait_reward: -0.8911
Metrics/base_velocity/error_vel_xy: 2.0839
Metrics/base_velocity/error_vel_yaw: 1.1260
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 1.07s
                        Total time: 837.98s
                               ETA: 2419.5s

################################################################################
                     [1m Learning iteration 772/3000 [0m                      

                       Computation: 90045 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 1.1628
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8226
                     Learning rate: 0.0004
                       Mean reward: 87.15
               Mean episode length: 924.84
       Episode_Reward/keep_balance: 0.9161
     Episode_Reward/rew_lin_vel_xy: 3.6683
      Episode_Reward/rew_ang_vel_z: 2.4143
    Episode_Reward/pen_base_height: -0.3219
      Episode_Reward/pen_lin_vel_z: -0.0549
     Episode_Reward/pen_ang_vel_xy: -0.1469
   Episode_Reward/pen_joint_torque: -0.1971
    Episode_Reward/pen_joint_accel: -0.1032
    Episode_Reward/pen_action_rate: -0.0907
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0419
   Episode_Reward/pen_joint_powers: -0.0665
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1988
Episode_Reward/pen_flat_orientation: -0.1544
  Episode_Reward/pen_feet_distance: -0.0036
Episode_Reward/pen_feet_regulation: -0.2704
   Episode_Reward/foot_landing_vel: -0.1356
   Episode_Reward/test_gait_reward: -0.8431
Metrics/base_velocity/error_vel_xy: 2.0238
Metrics/base_velocity/error_vel_yaw: 1.1069
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 1.09s
                        Total time: 839.08s
                               ETA: 2418.4s

################################################################################
                     [1m Learning iteration 773/3000 [0m                      

                       Computation: 90978 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 1.0362
                    Surrogate loss: 0.0041
             Mean action noise std: 0.8231
                     Learning rate: 0.0000
                       Mean reward: 86.87
               Mean episode length: 920.26
       Episode_Reward/keep_balance: 0.9181
     Episode_Reward/rew_lin_vel_xy: 3.6995
      Episode_Reward/rew_ang_vel_z: 2.4028
    Episode_Reward/pen_base_height: -0.3210
      Episode_Reward/pen_lin_vel_z: -0.0589
     Episode_Reward/pen_ang_vel_xy: -0.1600
   Episode_Reward/pen_joint_torque: -0.1977
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.0935
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0464
   Episode_Reward/pen_joint_powers: -0.0707
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2030
Episode_Reward/pen_flat_orientation: -0.1573
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.3077
   Episode_Reward/foot_landing_vel: -0.1465
   Episode_Reward/test_gait_reward: -0.8587
Metrics/base_velocity/error_vel_xy: 2.0297
Metrics/base_velocity/error_vel_yaw: 1.1295
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 1.08s
                        Total time: 840.16s
                               ETA: 2417.3s

################################################################################
                     [1m Learning iteration 774/3000 [0m                      

                       Computation: 91900 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 1.0766
                    Surrogate loss: 0.0053
             Mean action noise std: 0.8231
                     Learning rate: 0.0000
                       Mean reward: 89.79
               Mean episode length: 952.61
       Episode_Reward/keep_balance: 0.9423
     Episode_Reward/rew_lin_vel_xy: 3.5755
      Episode_Reward/rew_ang_vel_z: 2.4855
    Episode_Reward/pen_base_height: -0.3246
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1466
   Episode_Reward/pen_joint_torque: -0.2054
    Episode_Reward/pen_joint_accel: -0.1036
    Episode_Reward/pen_action_rate: -0.0938
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0433
   Episode_Reward/pen_joint_powers: -0.0688
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2035
Episode_Reward/pen_flat_orientation: -0.1419
  Episode_Reward/pen_feet_distance: -0.0018
Episode_Reward/pen_feet_regulation: -0.2737
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.8709
Metrics/base_velocity/error_vel_xy: 2.3497
Metrics/base_velocity/error_vel_yaw: 1.1319
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 1.07s
                        Total time: 841.23s
                               ETA: 2416.2s

################################################################################
                     [1m Learning iteration 775/3000 [0m                      

                       Computation: 89598 steps/s (collection: 0.972s, learning 0.125s)
               Value function loss: 1.0914
                    Surrogate loss: 0.0021
             Mean action noise std: 0.8234
                     Learning rate: 0.0000
                       Mean reward: 86.43
               Mean episode length: 944.18
       Episode_Reward/keep_balance: 0.9481
     Episode_Reward/rew_lin_vel_xy: 3.6927
      Episode_Reward/rew_ang_vel_z: 2.5035
    Episode_Reward/pen_base_height: -0.3254
      Episode_Reward/pen_lin_vel_z: -0.0592
     Episode_Reward/pen_ang_vel_xy: -0.1520
   Episode_Reward/pen_joint_torque: -0.2141
    Episode_Reward/pen_joint_accel: -0.1150
    Episode_Reward/pen_action_rate: -0.0940
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0455
   Episode_Reward/pen_joint_powers: -0.0719
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2041
Episode_Reward/pen_flat_orientation: -0.1547
  Episode_Reward/pen_feet_distance: -0.0031
Episode_Reward/pen_feet_regulation: -0.2960
   Episode_Reward/foot_landing_vel: -0.1537
   Episode_Reward/test_gait_reward: -0.8731
Metrics/base_velocity/error_vel_xy: 2.1687
Metrics/base_velocity/error_vel_yaw: 1.1368
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 1.10s
                        Total time: 842.32s
                               ETA: 2415.2s

################################################################################
                     [1m Learning iteration 776/3000 [0m                      

                       Computation: 86176 steps/s (collection: 1.011s, learning 0.130s)
               Value function loss: 1.0457
                    Surrogate loss: 0.0035
             Mean action noise std: 0.8235
                     Learning rate: 0.0000
                       Mean reward: 87.33
               Mean episode length: 926.87
       Episode_Reward/keep_balance: 0.9320
     Episode_Reward/rew_lin_vel_xy: 3.7339
      Episode_Reward/rew_ang_vel_z: 2.5067
    Episode_Reward/pen_base_height: -0.3062
      Episode_Reward/pen_lin_vel_z: -0.0549
     Episode_Reward/pen_ang_vel_xy: -0.1513
   Episode_Reward/pen_joint_torque: -0.1969
    Episode_Reward/pen_joint_accel: -0.0944
    Episode_Reward/pen_action_rate: -0.0921
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0423
   Episode_Reward/pen_joint_powers: -0.0674
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2008
Episode_Reward/pen_flat_orientation: -0.1439
  Episode_Reward/pen_feet_distance: -0.0032
Episode_Reward/pen_feet_regulation: -0.2620
   Episode_Reward/foot_landing_vel: -0.1407
   Episode_Reward/test_gait_reward: -0.8498
Metrics/base_velocity/error_vel_xy: 2.0679
Metrics/base_velocity/error_vel_yaw: 1.0898
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 1.14s
                        Total time: 843.46s
                               ETA: 2414.2s

################################################################################
                     [1m Learning iteration 777/3000 [0m                      

                       Computation: 86700 steps/s (collection: 1.005s, learning 0.129s)
               Value function loss: 1.0728
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8235
                     Learning rate: 0.0001
                       Mean reward: 86.13
               Mean episode length: 942.92
       Episode_Reward/keep_balance: 0.9473
     Episode_Reward/rew_lin_vel_xy: 3.6173
      Episode_Reward/rew_ang_vel_z: 2.5069
    Episode_Reward/pen_base_height: -0.3294
      Episode_Reward/pen_lin_vel_z: -0.0590
     Episode_Reward/pen_ang_vel_xy: -0.1596
   Episode_Reward/pen_joint_torque: -0.2006
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.0963
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0457
   Episode_Reward/pen_joint_powers: -0.0706
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2096
Episode_Reward/pen_flat_orientation: -0.1546
  Episode_Reward/pen_feet_distance: -0.0031
Episode_Reward/pen_feet_regulation: -0.2937
   Episode_Reward/foot_landing_vel: -0.1499
   Episode_Reward/test_gait_reward: -0.8741
Metrics/base_velocity/error_vel_xy: 2.1767
Metrics/base_velocity/error_vel_yaw: 1.1381
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 1.13s
                        Total time: 844.60s
                               ETA: 2413.3s

################################################################################
                     [1m Learning iteration 778/3000 [0m                      

                       Computation: 89238 steps/s (collection: 0.976s, learning 0.126s)
               Value function loss: 1.0960
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8228
                     Learning rate: 0.0003
                       Mean reward: 89.82
               Mean episode length: 939.96
       Episode_Reward/keep_balance: 0.9452
     Episode_Reward/rew_lin_vel_xy: 3.7298
      Episode_Reward/rew_ang_vel_z: 2.4974
    Episode_Reward/pen_base_height: -0.3197
      Episode_Reward/pen_lin_vel_z: -0.0566
     Episode_Reward/pen_ang_vel_xy: -0.1516
   Episode_Reward/pen_joint_torque: -0.2072
    Episode_Reward/pen_joint_accel: -0.1095
    Episode_Reward/pen_action_rate: -0.0942
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0438
   Episode_Reward/pen_joint_powers: -0.0696
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2044
Episode_Reward/pen_flat_orientation: -0.1481
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.2775
   Episode_Reward/foot_landing_vel: -0.1423
   Episode_Reward/test_gait_reward: -0.8685
Metrics/base_velocity/error_vel_xy: 2.1918
Metrics/base_velocity/error_vel_yaw: 1.1348
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 1.10s
                        Total time: 845.70s
                               ETA: 2412.2s

################################################################################
                     [1m Learning iteration 779/3000 [0m                      

                       Computation: 90914 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 1.0084
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8217
                     Learning rate: 0.0006
                       Mean reward: 86.25
               Mean episode length: 908.25
       Episode_Reward/keep_balance: 0.9197
     Episode_Reward/rew_lin_vel_xy: 3.5657
      Episode_Reward/rew_ang_vel_z: 2.4545
    Episode_Reward/pen_base_height: -0.3179
      Episode_Reward/pen_lin_vel_z: -0.0568
     Episode_Reward/pen_ang_vel_xy: -0.1449
   Episode_Reward/pen_joint_torque: -0.2021
    Episode_Reward/pen_joint_accel: -0.0979
    Episode_Reward/pen_action_rate: -0.0901
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0668
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1952
Episode_Reward/pen_flat_orientation: -0.1420
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.2687
   Episode_Reward/foot_landing_vel: -0.1361
   Episode_Reward/test_gait_reward: -0.8405
Metrics/base_velocity/error_vel_xy: 2.1929
Metrics/base_velocity/error_vel_yaw: 1.0782
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 1.08s
                        Total time: 846.78s
                               ETA: 2411.2s

################################################################################
                     [1m Learning iteration 780/3000 [0m                      

                       Computation: 89042 steps/s (collection: 0.979s, learning 0.125s)
               Value function loss: 1.1664
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8227
                     Learning rate: 0.0013
                       Mean reward: 90.16
               Mean episode length: 926.48
       Episode_Reward/keep_balance: 0.9253
     Episode_Reward/rew_lin_vel_xy: 3.8324
      Episode_Reward/rew_ang_vel_z: 2.4724
    Episode_Reward/pen_base_height: -0.3009
      Episode_Reward/pen_lin_vel_z: -0.0579
     Episode_Reward/pen_ang_vel_xy: -0.1462
   Episode_Reward/pen_joint_torque: -0.1974
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.0927
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0434
   Episode_Reward/pen_joint_powers: -0.0681
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2030
Episode_Reward/pen_flat_orientation: -0.1399
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2813
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.8464
Metrics/base_velocity/error_vel_xy: 2.0448
Metrics/base_velocity/error_vel_yaw: 1.0836
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 1.10s
                        Total time: 847.88s
                               ETA: 2410.1s

################################################################################
                     [1m Learning iteration 781/3000 [0m                      

                       Computation: 92212 steps/s (collection: 0.944s, learning 0.122s)
               Value function loss: 1.3048
                    Surrogate loss: -0.0009
             Mean action noise std: 0.8247
                     Learning rate: 0.0013
                       Mean reward: 89.67
               Mean episode length: 929.28
       Episode_Reward/keep_balance: 0.9111
     Episode_Reward/rew_lin_vel_xy: 3.6550
      Episode_Reward/rew_ang_vel_z: 2.4144
    Episode_Reward/pen_base_height: -0.3108
      Episode_Reward/pen_lin_vel_z: -0.0542
     Episode_Reward/pen_ang_vel_xy: -0.1438
   Episode_Reward/pen_joint_torque: -0.1955
    Episode_Reward/pen_joint_accel: -0.0946
    Episode_Reward/pen_action_rate: -0.0910
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0421
   Episode_Reward/pen_joint_powers: -0.0670
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.1990
Episode_Reward/pen_flat_orientation: -0.1481
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.2722
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.8356
Metrics/base_velocity/error_vel_xy: 2.0319
Metrics/base_velocity/error_vel_yaw: 1.0942
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 1.07s
                        Total time: 848.95s
                               ETA: 2409.0s

################################################################################
                     [1m Learning iteration 782/3000 [0m                      

                       Computation: 91938 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.1784
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8257
                     Learning rate: 0.0019
                       Mean reward: 94.25
               Mean episode length: 966.00
       Episode_Reward/keep_balance: 0.9646
     Episode_Reward/rew_lin_vel_xy: 3.9783
      Episode_Reward/rew_ang_vel_z: 2.5495
    Episode_Reward/pen_base_height: -0.3338
      Episode_Reward/pen_lin_vel_z: -0.0613
     Episode_Reward/pen_ang_vel_xy: -0.1554
   Episode_Reward/pen_joint_torque: -0.2183
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.0967
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0729
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2105
Episode_Reward/pen_flat_orientation: -0.1538
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2989
   Episode_Reward/foot_landing_vel: -0.1420
   Episode_Reward/test_gait_reward: -0.8899
Metrics/base_velocity/error_vel_xy: 2.1407
Metrics/base_velocity/error_vel_yaw: 1.1612
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 1.07s
                        Total time: 850.02s
                               ETA: 2407.8s

################################################################################
                     [1m Learning iteration 783/3000 [0m                      

                       Computation: 90951 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 1.2157
                    Surrogate loss: -0.0014
             Mean action noise std: 0.8258
                     Learning rate: 0.0009
                       Mean reward: 90.66
               Mean episode length: 956.45
       Episode_Reward/keep_balance: 0.9522
     Episode_Reward/rew_lin_vel_xy: 3.7555
      Episode_Reward/rew_ang_vel_z: 2.5044
    Episode_Reward/pen_base_height: -0.3167
      Episode_Reward/pen_lin_vel_z: -0.0606
     Episode_Reward/pen_ang_vel_xy: -0.1499
   Episode_Reward/pen_joint_torque: -0.2146
    Episode_Reward/pen_joint_accel: -0.1104
    Episode_Reward/pen_action_rate: -0.0955
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0453
   Episode_Reward/pen_joint_powers: -0.0725
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2072
Episode_Reward/pen_flat_orientation: -0.1512
  Episode_Reward/pen_feet_distance: -0.0017
Episode_Reward/pen_feet_regulation: -0.2998
   Episode_Reward/foot_landing_vel: -0.1503
   Episode_Reward/test_gait_reward: -0.8723
Metrics/base_velocity/error_vel_xy: 2.2260
Metrics/base_velocity/error_vel_yaw: 1.1458
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 1.08s
                        Total time: 851.10s
                               ETA: 2406.7s

################################################################################
                     [1m Learning iteration 784/3000 [0m                      

                       Computation: 84462 steps/s (collection: 1.035s, learning 0.129s)
               Value function loss: 1.1025
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8259
                     Learning rate: 0.0019
                       Mean reward: 90.73
               Mean episode length: 939.46
       Episode_Reward/keep_balance: 0.9382
     Episode_Reward/rew_lin_vel_xy: 3.7974
      Episode_Reward/rew_ang_vel_z: 2.4726
    Episode_Reward/pen_base_height: -0.3221
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1482
   Episode_Reward/pen_joint_torque: -0.2046
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.0937
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0436
   Episode_Reward/pen_joint_powers: -0.0688
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2046
Episode_Reward/pen_flat_orientation: -0.1471
  Episode_Reward/pen_feet_distance: -0.0038
Episode_Reward/pen_feet_regulation: -0.2763
   Episode_Reward/foot_landing_vel: -0.1409
   Episode_Reward/test_gait_reward: -0.8564
Metrics/base_velocity/error_vel_xy: 2.0341
Metrics/base_velocity/error_vel_yaw: 1.1300
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 1.16s
                        Total time: 852.26s
                               ETA: 2405.9s

################################################################################
                     [1m Learning iteration 785/3000 [0m                      

                       Computation: 88407 steps/s (collection: 0.983s, learning 0.129s)
               Value function loss: 1.2501
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8265
                     Learning rate: 0.0029
                       Mean reward: 90.60
               Mean episode length: 958.06
       Episode_Reward/keep_balance: 0.9681
     Episode_Reward/rew_lin_vel_xy: 3.8704
      Episode_Reward/rew_ang_vel_z: 2.5517
    Episode_Reward/pen_base_height: -0.3180
      Episode_Reward/pen_lin_vel_z: -0.0553
     Episode_Reward/pen_ang_vel_xy: -0.1524
   Episode_Reward/pen_joint_torque: -0.2039
    Episode_Reward/pen_joint_accel: -0.1193
    Episode_Reward/pen_action_rate: -0.0972
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0705
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2138
Episode_Reward/pen_flat_orientation: -0.1445
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2913
   Episode_Reward/foot_landing_vel: -0.1406
   Episode_Reward/test_gait_reward: -0.8902
Metrics/base_velocity/error_vel_xy: 2.1762
Metrics/base_velocity/error_vel_yaw: 1.1648
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 1.11s
                        Total time: 853.38s
                               ETA: 2404.9s

################################################################################
                     [1m Learning iteration 786/3000 [0m                      

                       Computation: 89101 steps/s (collection: 0.982s, learning 0.121s)
               Value function loss: 1.4113
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8290
                     Learning rate: 0.0029
                       Mean reward: 89.08
               Mean episode length: 941.39
       Episode_Reward/keep_balance: 0.9528
     Episode_Reward/rew_lin_vel_xy: 3.8618
      Episode_Reward/rew_ang_vel_z: 2.4875
    Episode_Reward/pen_base_height: -0.3216
      Episode_Reward/pen_lin_vel_z: -0.0534
     Episode_Reward/pen_ang_vel_xy: -0.1598
   Episode_Reward/pen_joint_torque: -0.2004
    Episode_Reward/pen_joint_accel: -0.1154
    Episode_Reward/pen_action_rate: -0.0979
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0706
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2141
Episode_Reward/pen_flat_orientation: -0.1495
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.2893
   Episode_Reward/foot_landing_vel: -0.1459
   Episode_Reward/test_gait_reward: -0.8781
Metrics/base_velocity/error_vel_xy: 2.0933
Metrics/base_velocity/error_vel_yaw: 1.1730
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 1.10s
                        Total time: 854.48s
                               ETA: 2403.8s

################################################################################
                     [1m Learning iteration 787/3000 [0m                      

                       Computation: 88922 steps/s (collection: 0.981s, learning 0.125s)
               Value function loss: 1.1824
                    Surrogate loss: -0.0006
             Mean action noise std: 0.8310
                     Learning rate: 0.0013
                       Mean reward: 88.99
               Mean episode length: 929.86
       Episode_Reward/keep_balance: 0.9395
     Episode_Reward/rew_lin_vel_xy: 3.8276
      Episode_Reward/rew_ang_vel_z: 2.4576
    Episode_Reward/pen_base_height: -0.3240
      Episode_Reward/pen_lin_vel_z: -0.0591
     Episode_Reward/pen_ang_vel_xy: -0.1509
   Episode_Reward/pen_joint_torque: -0.2091
    Episode_Reward/pen_joint_accel: -0.1008
    Episode_Reward/pen_action_rate: -0.0950
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0713
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2072
Episode_Reward/pen_flat_orientation: -0.1481
  Episode_Reward/pen_feet_distance: -0.0013
Episode_Reward/pen_feet_regulation: -0.2894
   Episode_Reward/foot_landing_vel: -0.1460
   Episode_Reward/test_gait_reward: -0.8645
Metrics/base_velocity/error_vel_xy: 2.1077
Metrics/base_velocity/error_vel_yaw: 1.1451
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 1.11s
                        Total time: 855.58s
                               ETA: 2402.8s

################################################################################
                     [1m Learning iteration 788/3000 [0m                      

                       Computation: 83299 steps/s (collection: 1.055s, learning 0.125s)
               Value function loss: 1.1317
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8314
                     Learning rate: 0.0019
                       Mean reward: 91.06
               Mean episode length: 950.41
       Episode_Reward/keep_balance: 0.9186
     Episode_Reward/rew_lin_vel_xy: 3.6050
      Episode_Reward/rew_ang_vel_z: 2.4751
    Episode_Reward/pen_base_height: -0.3025
      Episode_Reward/pen_lin_vel_z: -0.0567
     Episode_Reward/pen_ang_vel_xy: -0.1503
   Episode_Reward/pen_joint_torque: -0.2056
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.0922
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0437
   Episode_Reward/pen_joint_powers: -0.0695
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2028
Episode_Reward/pen_flat_orientation: -0.1384
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2776
   Episode_Reward/foot_landing_vel: -0.1402
   Episode_Reward/test_gait_reward: -0.8389
Metrics/base_velocity/error_vel_xy: 2.1425
Metrics/base_velocity/error_vel_yaw: 1.0660
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 1.18s
                        Total time: 856.76s
                               ETA: 2402.0s

################################################################################
                     [1m Learning iteration 789/3000 [0m                      

                       Computation: 88030 steps/s (collection: 0.985s, learning 0.132s)
               Value function loss: 1.0397
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8315
                     Learning rate: 0.0006
                       Mean reward: 91.20
               Mean episode length: 944.65
       Episode_Reward/keep_balance: 0.9614
     Episode_Reward/rew_lin_vel_xy: 3.7891
      Episode_Reward/rew_ang_vel_z: 2.5054
    Episode_Reward/pen_base_height: -0.3080
      Episode_Reward/pen_lin_vel_z: -0.0533
     Episode_Reward/pen_ang_vel_xy: -0.1485
   Episode_Reward/pen_joint_torque: -0.2021
    Episode_Reward/pen_joint_accel: -0.1060
    Episode_Reward/pen_action_rate: -0.0968
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0437
   Episode_Reward/pen_joint_powers: -0.0686
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2134
Episode_Reward/pen_flat_orientation: -0.1422
  Episode_Reward/pen_feet_distance: -0.0029
Episode_Reward/pen_feet_regulation: -0.2696
   Episode_Reward/foot_landing_vel: -0.1434
   Episode_Reward/test_gait_reward: -0.8718
Metrics/base_velocity/error_vel_xy: 2.2273
Metrics/base_velocity/error_vel_yaw: 1.1781
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 1.12s
                        Total time: 857.88s
                               ETA: 2401.0s

################################################################################
                     [1m Learning iteration 790/3000 [0m                      

                       Computation: 87393 steps/s (collection: 0.993s, learning 0.132s)
               Value function loss: 0.9898
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8311
                     Learning rate: 0.0009
                       Mean reward: 93.41
               Mean episode length: 952.93
       Episode_Reward/keep_balance: 0.9606
     Episode_Reward/rew_lin_vel_xy: 4.0045
      Episode_Reward/rew_ang_vel_z: 2.5505
    Episode_Reward/pen_base_height: -0.3247
      Episode_Reward/pen_lin_vel_z: -0.0586
     Episode_Reward/pen_ang_vel_xy: -0.1542
   Episode_Reward/pen_joint_torque: -0.2116
    Episode_Reward/pen_joint_accel: -0.1024
    Episode_Reward/pen_action_rate: -0.0967
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0444
   Episode_Reward/pen_joint_powers: -0.0711
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2113
Episode_Reward/pen_flat_orientation: -0.1453
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.2950
   Episode_Reward/foot_landing_vel: -0.1468
   Episode_Reward/test_gait_reward: -0.8825
Metrics/base_velocity/error_vel_xy: 2.1100
Metrics/base_velocity/error_vel_yaw: 1.1387
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 1.12s
                        Total time: 859.01s
                               ETA: 2400.0s

################################################################################
                     [1m Learning iteration 791/3000 [0m                      

                       Computation: 90826 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 1.0514
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8310
                     Learning rate: 0.0013
                       Mean reward: 86.51
               Mean episode length: 949.87
       Episode_Reward/keep_balance: 0.9636
     Episode_Reward/rew_lin_vel_xy: 3.7739
      Episode_Reward/rew_ang_vel_z: 2.5316
    Episode_Reward/pen_base_height: -0.3385
      Episode_Reward/pen_lin_vel_z: -0.0602
     Episode_Reward/pen_ang_vel_xy: -0.1573
   Episode_Reward/pen_joint_torque: -0.2151
    Episode_Reward/pen_joint_accel: -0.1066
    Episode_Reward/pen_action_rate: -0.0978
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0455
   Episode_Reward/pen_joint_powers: -0.0727
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2122
Episode_Reward/pen_flat_orientation: -0.1530
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.3073
   Episode_Reward/foot_landing_vel: -0.1418
   Episode_Reward/test_gait_reward: -0.8889
Metrics/base_velocity/error_vel_xy: 2.1715
Metrics/base_velocity/error_vel_yaw: 1.1704
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 1.08s
                        Total time: 860.09s
                               ETA: 2398.9s

################################################################################
                     [1m Learning iteration 792/3000 [0m                      

                       Computation: 90432 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 1.0090
                    Surrogate loss: 0.0006
             Mean action noise std: 0.8314
                     Learning rate: 0.0002
                       Mean reward: 91.99
               Mean episode length: 946.91
       Episode_Reward/keep_balance: 0.9505
     Episode_Reward/rew_lin_vel_xy: 3.8405
      Episode_Reward/rew_ang_vel_z: 2.5238
    Episode_Reward/pen_base_height: -0.3154
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.1527
   Episode_Reward/pen_joint_torque: -0.2058
    Episode_Reward/pen_joint_accel: -0.0962
    Episode_Reward/pen_action_rate: -0.0944
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0437
   Episode_Reward/pen_joint_powers: -0.0698
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2079
Episode_Reward/pen_flat_orientation: -0.1377
  Episode_Reward/pen_feet_distance: -0.0035
Episode_Reward/pen_feet_regulation: -0.2806
   Episode_Reward/foot_landing_vel: -0.1324
   Episode_Reward/test_gait_reward: -0.8588
Metrics/base_velocity/error_vel_xy: 2.1183
Metrics/base_velocity/error_vel_yaw: 1.1225
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 1.09s
                        Total time: 861.18s
                               ETA: 2397.8s

################################################################################
                     [1m Learning iteration 793/3000 [0m                      

                       Computation: 92901 steps/s (collection: 0.937s, learning 0.122s)
               Value function loss: 1.0548
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8305
                     Learning rate: 0.0004
                       Mean reward: 96.36
               Mean episode length: 962.73
       Episode_Reward/keep_balance: 0.9745
     Episode_Reward/rew_lin_vel_xy: 4.0460
      Episode_Reward/rew_ang_vel_z: 2.5656
    Episode_Reward/pen_base_height: -0.3198
      Episode_Reward/pen_lin_vel_z: -0.0536
     Episode_Reward/pen_ang_vel_xy: -0.1543
   Episode_Reward/pen_joint_torque: -0.2051
    Episode_Reward/pen_joint_accel: -0.1063
    Episode_Reward/pen_action_rate: -0.0975
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0428
   Episode_Reward/pen_joint_powers: -0.0689
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2159
Episode_Reward/pen_flat_orientation: -0.1378
  Episode_Reward/pen_feet_distance: -0.0012
Episode_Reward/pen_feet_regulation: -0.2734
   Episode_Reward/foot_landing_vel: -0.1290
   Episode_Reward/test_gait_reward: -0.8882
Metrics/base_velocity/error_vel_xy: 2.1152
Metrics/base_velocity/error_vel_yaw: 1.1712
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 1.06s
                        Total time: 862.23s
                               ETA: 2396.7s

################################################################################
                     [1m Learning iteration 794/3000 [0m                      

                       Computation: 91312 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.9962
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8310
                     Learning rate: 0.0009
                       Mean reward: 94.72
               Mean episode length: 941.91
       Episode_Reward/keep_balance: 0.9499
     Episode_Reward/rew_lin_vel_xy: 3.9971
      Episode_Reward/rew_ang_vel_z: 2.4899
    Episode_Reward/pen_base_height: -0.3263
      Episode_Reward/pen_lin_vel_z: -0.0584
     Episode_Reward/pen_ang_vel_xy: -0.1672
   Episode_Reward/pen_joint_torque: -0.2041
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.0981
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0475
   Episode_Reward/pen_joint_powers: -0.0721
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2163
Episode_Reward/pen_flat_orientation: -0.1558
  Episode_Reward/pen_feet_distance: -0.0011
Episode_Reward/pen_feet_regulation: -0.3025
   Episode_Reward/foot_landing_vel: -0.1436
   Episode_Reward/test_gait_reward: -0.8737
Metrics/base_velocity/error_vel_xy: 2.0156
Metrics/base_velocity/error_vel_yaw: 1.1692
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 1.08s
                        Total time: 863.31s
                               ETA: 2395.6s

################################################################################
                     [1m Learning iteration 795/3000 [0m                      

                       Computation: 91695 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 0.9767
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8312
                     Learning rate: 0.0006
                       Mean reward: 88.38
               Mean episode length: 925.85
       Episode_Reward/keep_balance: 0.9265
     Episode_Reward/rew_lin_vel_xy: 3.7734
      Episode_Reward/rew_ang_vel_z: 2.4137
    Episode_Reward/pen_base_height: -0.3158
      Episode_Reward/pen_lin_vel_z: -0.0572
     Episode_Reward/pen_ang_vel_xy: -0.1582
   Episode_Reward/pen_joint_torque: -0.2026
    Episode_Reward/pen_joint_accel: -0.1016
    Episode_Reward/pen_action_rate: -0.0940
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0442
   Episode_Reward/pen_joint_powers: -0.0698
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2053
Episode_Reward/pen_flat_orientation: -0.1435
  Episode_Reward/pen_feet_distance: -0.0031
Episode_Reward/pen_feet_regulation: -0.2865
   Episode_Reward/foot_landing_vel: -0.1396
   Episode_Reward/test_gait_reward: -0.8508
Metrics/base_velocity/error_vel_xy: 2.0772
Metrics/base_velocity/error_vel_yaw: 1.1426
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 1.07s
                        Total time: 864.38s
                               ETA: 2394.4s

################################################################################
                     [1m Learning iteration 796/3000 [0m                      

                       Computation: 90843 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 1.0781
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8311
                     Learning rate: 0.0009
                       Mean reward: 89.72
               Mean episode length: 960.05
       Episode_Reward/keep_balance: 0.9654
     Episode_Reward/rew_lin_vel_xy: 3.7729
      Episode_Reward/rew_ang_vel_z: 2.5568
    Episode_Reward/pen_base_height: -0.3368
      Episode_Reward/pen_lin_vel_z: -0.0579
     Episode_Reward/pen_ang_vel_xy: -0.1588
   Episode_Reward/pen_joint_torque: -0.2098
    Episode_Reward/pen_joint_accel: -0.1037
    Episode_Reward/pen_action_rate: -0.0973
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0444
   Episode_Reward/pen_joint_powers: -0.0716
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2121
Episode_Reward/pen_flat_orientation: -0.1457
  Episode_Reward/pen_feet_distance: -0.0031
Episode_Reward/pen_feet_regulation: -0.2951
   Episode_Reward/foot_landing_vel: -0.1468
   Episode_Reward/test_gait_reward: -0.8793
Metrics/base_velocity/error_vel_xy: 2.2896
Metrics/base_velocity/error_vel_yaw: 1.1496
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 1.08s
                        Total time: 865.46s
                               ETA: 2393.3s

################################################################################
                     [1m Learning iteration 797/3000 [0m                      

                       Computation: 91502 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 1.0766
                    Surrogate loss: 0.0114
             Mean action noise std: 0.8311
                     Learning rate: 0.0000
                       Mean reward: 91.29
               Mean episode length: 949.93
       Episode_Reward/keep_balance: 0.9558
     Episode_Reward/rew_lin_vel_xy: 3.8430
      Episode_Reward/rew_ang_vel_z: 2.4944
    Episode_Reward/pen_base_height: -0.3301
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1535
   Episode_Reward/pen_joint_torque: -0.2085
    Episode_Reward/pen_joint_accel: -0.1006
    Episode_Reward/pen_action_rate: -0.0961
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0436
   Episode_Reward/pen_joint_powers: -0.0707
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2102
Episode_Reward/pen_flat_orientation: -0.1437
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2864
   Episode_Reward/foot_landing_vel: -0.1338
   Episode_Reward/test_gait_reward: -0.8794
Metrics/base_velocity/error_vel_xy: 2.1470
Metrics/base_velocity/error_vel_yaw: 1.1776
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 1.07s
                        Total time: 866.54s
                               ETA: 2392.2s

################################################################################
                     [1m Learning iteration 798/3000 [0m                      

                       Computation: 91230 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.1215
                    Surrogate loss: -0.0001
             Mean action noise std: 0.8312
                     Learning rate: 0.0001
                       Mean reward: 95.31
               Mean episode length: 958.60
       Episode_Reward/keep_balance: 0.9363
     Episode_Reward/rew_lin_vel_xy: 3.9378
      Episode_Reward/rew_ang_vel_z: 2.4471
    Episode_Reward/pen_base_height: -0.3251
      Episode_Reward/pen_lin_vel_z: -0.0568
     Episode_Reward/pen_ang_vel_xy: -0.1590
   Episode_Reward/pen_joint_torque: -0.2083
    Episode_Reward/pen_joint_accel: -0.1047
    Episode_Reward/pen_action_rate: -0.0957
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0715
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2096
Episode_Reward/pen_flat_orientation: -0.1507
  Episode_Reward/pen_feet_distance: -0.0039
Episode_Reward/pen_feet_regulation: -0.2941
   Episode_Reward/foot_landing_vel: -0.1392
   Episode_Reward/test_gait_reward: -0.8567
Metrics/base_velocity/error_vel_xy: 1.9633
Metrics/base_velocity/error_vel_yaw: 1.1455
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 1.08s
                        Total time: 867.62s
                               ETA: 2391.1s

################################################################################
                     [1m Learning iteration 799/3000 [0m                      

                       Computation: 90581 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 1.0218
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8305
                     Learning rate: 0.0003
                       Mean reward: 89.60
               Mean episode length: 941.30
       Episode_Reward/keep_balance: 0.9436
     Episode_Reward/rew_lin_vel_xy: 3.7732
      Episode_Reward/rew_ang_vel_z: 2.4862
    Episode_Reward/pen_base_height: -0.3247
      Episode_Reward/pen_lin_vel_z: -0.0585
     Episode_Reward/pen_ang_vel_xy: -0.1526
   Episode_Reward/pen_joint_torque: -0.2094
    Episode_Reward/pen_joint_accel: -0.1074
    Episode_Reward/pen_action_rate: -0.0947
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0715
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2079
Episode_Reward/pen_flat_orientation: -0.1480
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.2926
   Episode_Reward/foot_landing_vel: -0.1407
   Episode_Reward/test_gait_reward: -0.8614
Metrics/base_velocity/error_vel_xy: 2.1142
Metrics/base_velocity/error_vel_yaw: 1.1411
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 1.09s
                        Total time: 868.70s
                               ETA: 2390.0s

################################################################################
                     [1m Learning iteration 800/3000 [0m                      

                       Computation: 91830 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 1.0944
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8313
                     Learning rate: 0.0006
                       Mean reward: 90.32
               Mean episode length: 911.05
       Episode_Reward/keep_balance: 0.9187
     Episode_Reward/rew_lin_vel_xy: 3.7450
      Episode_Reward/rew_ang_vel_z: 2.4437
    Episode_Reward/pen_base_height: -0.3080
      Episode_Reward/pen_lin_vel_z: -0.0540
     Episode_Reward/pen_ang_vel_xy: -0.1508
   Episode_Reward/pen_joint_torque: -0.1986
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.0925
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0422
   Episode_Reward/pen_joint_powers: -0.0679
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2038
Episode_Reward/pen_flat_orientation: -0.1431
  Episode_Reward/pen_feet_distance: -0.0039
Episode_Reward/pen_feet_regulation: -0.2707
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.8354
Metrics/base_velocity/error_vel_xy: 2.0382
Metrics/base_velocity/error_vel_yaw: 1.0915
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 1.07s
                        Total time: 869.77s
                               ETA: 2388.9s

################################################################################
                     [1m Learning iteration 801/3000 [0m                      

                       Computation: 90377 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 1.0916
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8321
                     Learning rate: 0.0009
                       Mean reward: 92.41
               Mean episode length: 951.04
       Episode_Reward/keep_balance: 0.9508
     Episode_Reward/rew_lin_vel_xy: 3.9291
      Episode_Reward/rew_ang_vel_z: 2.5104
    Episode_Reward/pen_base_height: -0.3224
      Episode_Reward/pen_lin_vel_z: -0.0555
     Episode_Reward/pen_ang_vel_xy: -0.1544
   Episode_Reward/pen_joint_torque: -0.2130
    Episode_Reward/pen_joint_accel: -0.1022
    Episode_Reward/pen_action_rate: -0.0952
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0437
   Episode_Reward/pen_joint_powers: -0.0708
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2087
Episode_Reward/pen_flat_orientation: -0.1438
  Episode_Reward/pen_feet_distance: -0.0023
Episode_Reward/pen_feet_regulation: -0.2809
   Episode_Reward/foot_landing_vel: -0.1311
   Episode_Reward/test_gait_reward: -0.8705
Metrics/base_velocity/error_vel_xy: 2.0777
Metrics/base_velocity/error_vel_yaw: 1.1363
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 1.09s
                        Total time: 870.86s
                               ETA: 2387.8s

################################################################################
                     [1m Learning iteration 802/3000 [0m                      

                       Computation: 91294 steps/s (collection: 0.952s, learning 0.125s)
               Value function loss: 1.2798
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8325
                     Learning rate: 0.0013
                       Mean reward: 91.19
               Mean episode length: 946.02
       Episode_Reward/keep_balance: 0.9559
     Episode_Reward/rew_lin_vel_xy: 3.8001
      Episode_Reward/rew_ang_vel_z: 2.5573
    Episode_Reward/pen_base_height: -0.3046
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.1494
   Episode_Reward/pen_joint_torque: -0.2101
    Episode_Reward/pen_joint_accel: -0.0953
    Episode_Reward/pen_action_rate: -0.0940
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0425
   Episode_Reward/pen_joint_powers: -0.0701
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2081
Episode_Reward/pen_flat_orientation: -0.1408
  Episode_Reward/pen_feet_distance: -0.0019
Episode_Reward/pen_feet_regulation: -0.2685
   Episode_Reward/foot_landing_vel: -0.1325
   Episode_Reward/test_gait_reward: -0.8620
Metrics/base_velocity/error_vel_xy: 2.1836
Metrics/base_velocity/error_vel_yaw: 1.1168
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 1.08s
                        Total time: 871.94s
                               ETA: 2386.7s

################################################################################
                     [1m Learning iteration 803/3000 [0m                      

                       Computation: 91589 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 1.2593
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8337
                     Learning rate: 0.0004
                       Mean reward: 88.98
               Mean episode length: 956.51
       Episode_Reward/keep_balance: 0.9469
     Episode_Reward/rew_lin_vel_xy: 3.7520
      Episode_Reward/rew_ang_vel_z: 2.4844
    Episode_Reward/pen_base_height: -0.3283
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1584
   Episode_Reward/pen_joint_torque: -0.2087
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.0958
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0455
   Episode_Reward/pen_joint_powers: -0.0724
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2092
Episode_Reward/pen_flat_orientation: -0.1552
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2855
   Episode_Reward/foot_landing_vel: -0.1370
   Episode_Reward/test_gait_reward: -0.8649
Metrics/base_velocity/error_vel_xy: 2.1539
Metrics/base_velocity/error_vel_yaw: 1.1578
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 1.07s
                        Total time: 873.01s
                               ETA: 2385.6s

################################################################################
                     [1m Learning iteration 804/3000 [0m                      

                       Computation: 90457 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 1.0624
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8352
                     Learning rate: 0.0004
                       Mean reward: 91.96
               Mean episode length: 920.69
       Episode_Reward/keep_balance: 0.9241
     Episode_Reward/rew_lin_vel_xy: 3.7285
      Episode_Reward/rew_ang_vel_z: 2.4514
    Episode_Reward/pen_base_height: -0.3074
      Episode_Reward/pen_lin_vel_z: -0.0505
     Episode_Reward/pen_ang_vel_xy: -0.1519
   Episode_Reward/pen_joint_torque: -0.1962
    Episode_Reward/pen_joint_accel: -0.1001
    Episode_Reward/pen_action_rate: -0.0921
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0414
   Episode_Reward/pen_joint_powers: -0.0668
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2035
Episode_Reward/pen_flat_orientation: -0.1383
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2612
   Episode_Reward/foot_landing_vel: -0.1286
   Episode_Reward/test_gait_reward: -0.8411
Metrics/base_velocity/error_vel_xy: 1.9586
Metrics/base_velocity/error_vel_yaw: 1.0941
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 1.09s
                        Total time: 874.10s
                               ETA: 2384.5s

################################################################################
                     [1m Learning iteration 805/3000 [0m                      

                       Computation: 90835 steps/s (collection: 0.958s, learning 0.125s)
               Value function loss: 1.1312
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8352
                     Learning rate: 0.0009
                       Mean reward: 91.08
               Mean episode length: 941.35
       Episode_Reward/keep_balance: 0.9522
     Episode_Reward/rew_lin_vel_xy: 3.8520
      Episode_Reward/rew_ang_vel_z: 2.5067
    Episode_Reward/pen_base_height: -0.3214
      Episode_Reward/pen_lin_vel_z: -0.0578
     Episode_Reward/pen_ang_vel_xy: -0.1567
   Episode_Reward/pen_joint_torque: -0.2109
    Episode_Reward/pen_joint_accel: -0.1041
    Episode_Reward/pen_action_rate: -0.0961
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0441
   Episode_Reward/pen_joint_powers: -0.0715
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2113
Episode_Reward/pen_flat_orientation: -0.1448
  Episode_Reward/pen_feet_distance: -0.0027
Episode_Reward/pen_feet_regulation: -0.2917
   Episode_Reward/foot_landing_vel: -0.1285
   Episode_Reward/test_gait_reward: -0.8762
Metrics/base_velocity/error_vel_xy: 2.1394
Metrics/base_velocity/error_vel_yaw: 1.1454
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 1.08s
                        Total time: 875.18s
                               ETA: 2383.4s

################################################################################
                     [1m Learning iteration 806/3000 [0m                      

                       Computation: 91653 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 1.1957
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8339
                     Learning rate: 0.0013
                       Mean reward: 93.18
               Mean episode length: 946.65
       Episode_Reward/keep_balance: 0.9485
     Episode_Reward/rew_lin_vel_xy: 3.8174
      Episode_Reward/rew_ang_vel_z: 2.4927
    Episode_Reward/pen_base_height: -0.3145
      Episode_Reward/pen_lin_vel_z: -0.0525
     Episode_Reward/pen_ang_vel_xy: -0.1487
   Episode_Reward/pen_joint_torque: -0.2019
    Episode_Reward/pen_joint_accel: -0.1030
    Episode_Reward/pen_action_rate: -0.0949
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0427
   Episode_Reward/pen_joint_powers: -0.0684
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2106
Episode_Reward/pen_flat_orientation: -0.1435
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.2701
   Episode_Reward/foot_landing_vel: -0.1368
   Episode_Reward/test_gait_reward: -0.8595
Metrics/base_velocity/error_vel_xy: 2.1262
Metrics/base_velocity/error_vel_yaw: 1.1444
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 1.07s
                        Total time: 876.25s
                               ETA: 2382.3s

################################################################################
                     [1m Learning iteration 807/3000 [0m                      

                       Computation: 90998 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 1.1445
                    Surrogate loss: 0.0002
             Mean action noise std: 0.8352
                     Learning rate: 0.0004
                       Mean reward: 88.68
               Mean episode length: 899.43
       Episode_Reward/keep_balance: 0.8939
     Episode_Reward/rew_lin_vel_xy: 3.6980
      Episode_Reward/rew_ang_vel_z: 2.3230
    Episode_Reward/pen_base_height: -0.3207
      Episode_Reward/pen_lin_vel_z: -0.0514
     Episode_Reward/pen_ang_vel_xy: -0.1516
   Episode_Reward/pen_joint_torque: -0.1922
    Episode_Reward/pen_joint_accel: -0.0928
    Episode_Reward/pen_action_rate: -0.0901
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0421
   Episode_Reward/pen_joint_powers: -0.0667
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.1990
Episode_Reward/pen_flat_orientation: -0.1479
  Episode_Reward/pen_feet_distance: -0.0024
Episode_Reward/pen_feet_regulation: -0.2674
   Episode_Reward/foot_landing_vel: -0.1266
   Episode_Reward/test_gait_reward: -0.8145
Metrics/base_velocity/error_vel_xy: 1.8835
Metrics/base_velocity/error_vel_yaw: 1.1106
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 1.08s
                        Total time: 877.33s
                               ETA: 2381.2s

################################################################################
                     [1m Learning iteration 808/3000 [0m                      

                       Computation: 91748 steps/s (collection: 0.946s, learning 0.125s)
               Value function loss: 1.0836
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8357
                     Learning rate: 0.0006
                       Mean reward: 97.26
               Mean episode length: 951.56
       Episode_Reward/keep_balance: 0.9505
     Episode_Reward/rew_lin_vel_xy: 4.0208
      Episode_Reward/rew_ang_vel_z: 2.5175
    Episode_Reward/pen_base_height: -0.3070
      Episode_Reward/pen_lin_vel_z: -0.0532
     Episode_Reward/pen_ang_vel_xy: -0.1531
   Episode_Reward/pen_joint_torque: -0.2023
    Episode_Reward/pen_joint_accel: -0.0980
    Episode_Reward/pen_action_rate: -0.0949
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0431
   Episode_Reward/pen_joint_powers: -0.0693
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2101
Episode_Reward/pen_flat_orientation: -0.1424
  Episode_Reward/pen_feet_distance: -0.0029
Episode_Reward/pen_feet_regulation: -0.2687
   Episode_Reward/foot_landing_vel: -0.1311
   Episode_Reward/test_gait_reward: -0.8650
Metrics/base_velocity/error_vel_xy: 1.9915
Metrics/base_velocity/error_vel_yaw: 1.1394
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 1.07s
                        Total time: 878.40s
                               ETA: 2380.0s

################################################################################
                     [1m Learning iteration 809/3000 [0m                      

                       Computation: 90466 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 1.1939
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8370
                     Learning rate: 0.0013
                       Mean reward: 94.94
               Mean episode length: 958.22
       Episode_Reward/keep_balance: 0.9420
     Episode_Reward/rew_lin_vel_xy: 3.8771
      Episode_Reward/rew_ang_vel_z: 2.5037
    Episode_Reward/pen_base_height: -0.3132
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1530
   Episode_Reward/pen_joint_torque: -0.2020
    Episode_Reward/pen_joint_accel: -0.0913
    Episode_Reward/pen_action_rate: -0.0945
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0437
   Episode_Reward/pen_joint_powers: -0.0696
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2084
Episode_Reward/pen_flat_orientation: -0.1485
  Episode_Reward/pen_feet_distance: -0.0035
Episode_Reward/pen_feet_regulation: -0.2886
   Episode_Reward/foot_landing_vel: -0.1310
   Episode_Reward/test_gait_reward: -0.8615
Metrics/base_velocity/error_vel_xy: 2.0440
Metrics/base_velocity/error_vel_yaw: 1.1132
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 1.09s
                        Total time: 879.49s
                               ETA: 2379.0s

################################################################################
                     [1m Learning iteration 810/3000 [0m                      

                       Computation: 90298 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 1.1035
                    Surrogate loss: 0.0012
             Mean action noise std: 0.8378
                     Learning rate: 0.0003
                       Mean reward: 89.44
               Mean episode length: 901.34
       Episode_Reward/keep_balance: 0.9179
     Episode_Reward/rew_lin_vel_xy: 3.8566
      Episode_Reward/rew_ang_vel_z: 2.4418
    Episode_Reward/pen_base_height: -0.3311
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1599
   Episode_Reward/pen_joint_torque: -0.2008
    Episode_Reward/pen_joint_accel: -0.1019
    Episode_Reward/pen_action_rate: -0.0940
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0440
   Episode_Reward/pen_joint_powers: -0.0706
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2046
Episode_Reward/pen_flat_orientation: -0.1500
  Episode_Reward/pen_feet_distance: -0.0098
Episode_Reward/pen_feet_regulation: -0.2910
   Episode_Reward/foot_landing_vel: -0.1270
   Episode_Reward/test_gait_reward: -0.8467
Metrics/base_velocity/error_vel_xy: 1.9577
Metrics/base_velocity/error_vel_yaw: 1.0916
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 1.09s
                        Total time: 880.58s
                               ETA: 2377.9s

################################################################################
                     [1m Learning iteration 811/3000 [0m                      

                       Computation: 90842 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.9977
                    Surrogate loss: -0.0014
             Mean action noise std: 0.8373
                     Learning rate: 0.0003
                       Mean reward: 92.64
               Mean episode length: 945.79
       Episode_Reward/keep_balance: 0.9331
     Episode_Reward/rew_lin_vel_xy: 3.8534
      Episode_Reward/rew_ang_vel_z: 2.4296
    Episode_Reward/pen_base_height: -0.3124
      Episode_Reward/pen_lin_vel_z: -0.0522
     Episode_Reward/pen_ang_vel_xy: -0.1585
   Episode_Reward/pen_joint_torque: -0.1980
    Episode_Reward/pen_joint_accel: -0.1039
    Episode_Reward/pen_action_rate: -0.0954
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0446
   Episode_Reward/pen_joint_powers: -0.0700
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2113
Episode_Reward/pen_flat_orientation: -0.1524
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.2836
   Episode_Reward/foot_landing_vel: -0.1331
   Episode_Reward/test_gait_reward: -0.8519
Metrics/base_velocity/error_vel_xy: 1.9681
Metrics/base_velocity/error_vel_yaw: 1.1513
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 1.08s
                        Total time: 881.66s
                               ETA: 2376.8s

################################################################################
                     [1m Learning iteration 812/3000 [0m                      

                       Computation: 92224 steps/s (collection: 0.943s, learning 0.123s)
               Value function loss: 1.0223
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8384
                     Learning rate: 0.0004
                       Mean reward: 94.94
               Mean episode length: 963.81
       Episode_Reward/keep_balance: 0.9495
     Episode_Reward/rew_lin_vel_xy: 3.7708
      Episode_Reward/rew_ang_vel_z: 2.5039
    Episode_Reward/pen_base_height: -0.3046
      Episode_Reward/pen_lin_vel_z: -0.0504
     Episode_Reward/pen_ang_vel_xy: -0.1621
   Episode_Reward/pen_joint_torque: -0.1897
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.0971
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0437
   Episode_Reward/pen_joint_powers: -0.0681
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2161
Episode_Reward/pen_flat_orientation: -0.1329
  Episode_Reward/pen_feet_distance: -0.0031
Episode_Reward/pen_feet_regulation: -0.2759
   Episode_Reward/foot_landing_vel: -0.1321
   Episode_Reward/test_gait_reward: -0.8690
Metrics/base_velocity/error_vel_xy: 2.1461
Metrics/base_velocity/error_vel_yaw: 1.1376
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 1.07s
                        Total time: 882.73s
                               ETA: 2375.7s

################################################################################
                     [1m Learning iteration 813/3000 [0m                      

                       Computation: 91455 steps/s (collection: 0.951s, learning 0.124s)
               Value function loss: 0.9596
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8389
                     Learning rate: 0.0003
                       Mean reward: 95.80
               Mean episode length: 963.93
       Episode_Reward/keep_balance: 0.9640
     Episode_Reward/rew_lin_vel_xy: 4.1372
      Episode_Reward/rew_ang_vel_z: 2.5432
    Episode_Reward/pen_base_height: -0.3249
      Episode_Reward/pen_lin_vel_z: -0.0580
     Episode_Reward/pen_ang_vel_xy: -0.1652
   Episode_Reward/pen_joint_torque: -0.2081
    Episode_Reward/pen_joint_accel: -0.1112
    Episode_Reward/pen_action_rate: -0.0988
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0466
   Episode_Reward/pen_joint_powers: -0.0733
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2169
Episode_Reward/pen_flat_orientation: -0.1581
  Episode_Reward/pen_feet_distance: -0.0034
Episode_Reward/pen_feet_regulation: -0.2972
   Episode_Reward/foot_landing_vel: -0.1414
   Episode_Reward/test_gait_reward: -0.8918
Metrics/base_velocity/error_vel_xy: 1.9417
Metrics/base_velocity/error_vel_yaw: 1.1641
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 1.07s
                        Total time: 883.80s
                               ETA: 2374.5s

################################################################################
                     [1m Learning iteration 814/3000 [0m                      

                       Computation: 89948 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 1.1236
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8402
                     Learning rate: 0.0006
                       Mean reward: 92.43
               Mean episode length: 955.77
       Episode_Reward/keep_balance: 0.9654
     Episode_Reward/rew_lin_vel_xy: 3.9726
      Episode_Reward/rew_ang_vel_z: 2.5248
    Episode_Reward/pen_base_height: -0.3255
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.1698
   Episode_Reward/pen_joint_torque: -0.2033
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.0994
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0472
   Episode_Reward/pen_joint_powers: -0.0728
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2198
Episode_Reward/pen_flat_orientation: -0.1472
  Episode_Reward/pen_feet_distance: -0.0020
Episode_Reward/pen_feet_regulation: -0.2934
   Episode_Reward/foot_landing_vel: -0.1535
   Episode_Reward/test_gait_reward: -0.8891
Metrics/base_velocity/error_vel_xy: 2.0981
Metrics/base_velocity/error_vel_yaw: 1.1840
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 1.09s
                        Total time: 884.89s
                               ETA: 2373.5s

################################################################################
                     [1m Learning iteration 815/3000 [0m                      

                       Computation: 91667 steps/s (collection: 0.947s, learning 0.125s)
               Value function loss: 1.0790
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8409
                     Learning rate: 0.0013
                       Mean reward: 92.31
               Mean episode length: 951.58
       Episode_Reward/keep_balance: 0.9575
     Episode_Reward/rew_lin_vel_xy: 4.0183
      Episode_Reward/rew_ang_vel_z: 2.4973
    Episode_Reward/pen_base_height: -0.3248
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1631
   Episode_Reward/pen_joint_torque: -0.2041
    Episode_Reward/pen_joint_accel: -0.1091
    Episode_Reward/pen_action_rate: -0.0983
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0459
   Episode_Reward/pen_joint_powers: -0.0722
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2161
Episode_Reward/pen_flat_orientation: -0.1559
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.2945
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.8843
Metrics/base_velocity/error_vel_xy: 1.9792
Metrics/base_velocity/error_vel_yaw: 1.1813
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 1.07s
                        Total time: 885.97s
                               ETA: 2372.4s

################################################################################
                     [1m Learning iteration 816/3000 [0m                      

                       Computation: 91781 steps/s (collection: 0.947s, learning 0.124s)
               Value function loss: 1.0899
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8428
                     Learning rate: 0.0013
                       Mean reward: 87.98
               Mean episode length: 892.38
       Episode_Reward/keep_balance: 0.9281
     Episode_Reward/rew_lin_vel_xy: 3.9660
      Episode_Reward/rew_ang_vel_z: 2.4718
    Episode_Reward/pen_base_height: -0.3168
      Episode_Reward/pen_lin_vel_z: -0.0531
     Episode_Reward/pen_ang_vel_xy: -0.1540
   Episode_Reward/pen_joint_torque: -0.1973
    Episode_Reward/pen_joint_accel: -0.1004
    Episode_Reward/pen_action_rate: -0.0934
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0425
   Episode_Reward/pen_joint_powers: -0.0683
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2051
Episode_Reward/pen_flat_orientation: -0.1495
  Episode_Reward/pen_feet_distance: -0.0037
Episode_Reward/pen_feet_regulation: -0.2739
   Episode_Reward/foot_landing_vel: -0.1271
   Episode_Reward/test_gait_reward: -0.8534
Metrics/base_velocity/error_vel_xy: 1.9259
Metrics/base_velocity/error_vel_yaw: 1.1001
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 1.07s
                        Total time: 887.04s
                               ETA: 2371.2s

################################################################################
                     [1m Learning iteration 817/3000 [0m                      

                       Computation: 90236 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 1.0870
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8433
                     Learning rate: 0.0009
                       Mean reward: 93.20
               Mean episode length: 955.58
       Episode_Reward/keep_balance: 0.9639
     Episode_Reward/rew_lin_vel_xy: 3.8858
      Episode_Reward/rew_ang_vel_z: 2.5442
    Episode_Reward/pen_base_height: -0.3205
      Episode_Reward/pen_lin_vel_z: -0.0564
     Episode_Reward/pen_ang_vel_xy: -0.1607
   Episode_Reward/pen_joint_torque: -0.2095
    Episode_Reward/pen_joint_accel: -0.1155
    Episode_Reward/pen_action_rate: -0.0979
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0463
   Episode_Reward/pen_joint_powers: -0.0731
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2156
Episode_Reward/pen_flat_orientation: -0.1479
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.3010
   Episode_Reward/foot_landing_vel: -0.1460
   Episode_Reward/test_gait_reward: -0.8861
Metrics/base_velocity/error_vel_xy: 2.1496
Metrics/base_velocity/error_vel_yaw: 1.1547
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 1.09s
                        Total time: 888.13s
                               ETA: 2370.1s

################################################################################
                     [1m Learning iteration 818/3000 [0m                      

                       Computation: 90623 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 1.1191
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8439
                     Learning rate: 0.0006
                       Mean reward: 88.28
               Mean episode length: 924.74
       Episode_Reward/keep_balance: 0.9404
     Episode_Reward/rew_lin_vel_xy: 3.7997
      Episode_Reward/rew_ang_vel_z: 2.5021
    Episode_Reward/pen_base_height: -0.3115
      Episode_Reward/pen_lin_vel_z: -0.0561
     Episode_Reward/pen_ang_vel_xy: -0.1656
   Episode_Reward/pen_joint_torque: -0.2020
    Episode_Reward/pen_joint_accel: -0.0918
    Episode_Reward/pen_action_rate: -0.0961
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0459
   Episode_Reward/pen_joint_powers: -0.0725
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2109
Episode_Reward/pen_flat_orientation: -0.1548
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.2953
   Episode_Reward/foot_landing_vel: -0.1418
   Episode_Reward/test_gait_reward: -0.8659
Metrics/base_velocity/error_vel_xy: 1.9743
Metrics/base_velocity/error_vel_yaw: 1.1188
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 1.08s
                        Total time: 889.21s
                               ETA: 2369.1s

################################################################################
                     [1m Learning iteration 819/3000 [0m                      

                       Computation: 88797 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 1.0527
                    Surrogate loss: -0.0016
             Mean action noise std: 0.8455
                     Learning rate: 0.0009
                       Mean reward: 85.15
               Mean episode length: 918.08
       Episode_Reward/keep_balance: 0.9228
     Episode_Reward/rew_lin_vel_xy: 3.6469
      Episode_Reward/rew_ang_vel_z: 2.4292
    Episode_Reward/pen_base_height: -0.3087
      Episode_Reward/pen_lin_vel_z: -0.0501
     Episode_Reward/pen_ang_vel_xy: -0.1568
   Episode_Reward/pen_joint_torque: -0.1899
    Episode_Reward/pen_joint_accel: -0.0925
    Episode_Reward/pen_action_rate: -0.0938
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0419
   Episode_Reward/pen_joint_powers: -0.0666
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2078
Episode_Reward/pen_flat_orientation: -0.1419
  Episode_Reward/pen_feet_distance: -0.0055
Episode_Reward/pen_feet_regulation: -0.2519
   Episode_Reward/foot_landing_vel: -0.1241
   Episode_Reward/test_gait_reward: -0.8416
Metrics/base_velocity/error_vel_xy: 2.0631
Metrics/base_velocity/error_vel_yaw: 1.1149
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 1.11s
                        Total time: 890.32s
                               ETA: 2368.0s

################################################################################
                     [1m Learning iteration 820/3000 [0m                      

                       Computation: 89925 steps/s (collection: 0.967s, learning 0.126s)
               Value function loss: 0.9926
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8445
                     Learning rate: 0.0006
                       Mean reward: 94.60
               Mean episode length: 955.62
       Episode_Reward/keep_balance: 0.9641
     Episode_Reward/rew_lin_vel_xy: 3.9391
      Episode_Reward/rew_ang_vel_z: 2.5772
    Episode_Reward/pen_base_height: -0.3142
      Episode_Reward/pen_lin_vel_z: -0.0576
     Episode_Reward/pen_ang_vel_xy: -0.1597
   Episode_Reward/pen_joint_torque: -0.2081
    Episode_Reward/pen_joint_accel: -0.1076
    Episode_Reward/pen_action_rate: -0.0975
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0448
   Episode_Reward/pen_joint_powers: -0.0718
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2135
Episode_Reward/pen_flat_orientation: -0.1455
  Episode_Reward/pen_feet_distance: -0.0026
Episode_Reward/pen_feet_regulation: -0.2878
   Episode_Reward/foot_landing_vel: -0.1346
   Episode_Reward/test_gait_reward: -0.8819
Metrics/base_velocity/error_vel_xy: 2.1105
Metrics/base_velocity/error_vel_yaw: 1.1292
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 1.09s
                        Total time: 891.41s
                               ETA: 2367.0s

################################################################################
                     [1m Learning iteration 821/3000 [0m                      

                       Computation: 92297 steps/s (collection: 0.942s, learning 0.123s)
               Value function loss: 1.0406
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8450
                     Learning rate: 0.0009
                       Mean reward: 97.67
               Mean episode length: 977.27
       Episode_Reward/keep_balance: 0.9650
     Episode_Reward/rew_lin_vel_xy: 3.9900
      Episode_Reward/rew_ang_vel_z: 2.5680
    Episode_Reward/pen_base_height: -0.3223
      Episode_Reward/pen_lin_vel_z: -0.0589
     Episode_Reward/pen_ang_vel_xy: -0.1683
   Episode_Reward/pen_joint_torque: -0.2143
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.0986
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0461
   Episode_Reward/pen_joint_powers: -0.0746
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2158
Episode_Reward/pen_flat_orientation: -0.1563
  Episode_Reward/pen_feet_distance: -0.0038
Episode_Reward/pen_feet_regulation: -0.3029
   Episode_Reward/foot_landing_vel: -0.1395
   Episode_Reward/test_gait_reward: -0.8861
Metrics/base_velocity/error_vel_xy: 2.1299
Metrics/base_velocity/error_vel_yaw: 1.1413
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 1.07s
                        Total time: 892.48s
                               ETA: 2365.8s

################################################################################
                     [1m Learning iteration 822/3000 [0m                      

                       Computation: 89691 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.9581
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8459
                     Learning rate: 0.0009
                       Mean reward: 93.28
               Mean episode length: 944.22
       Episode_Reward/keep_balance: 0.9230
     Episode_Reward/rew_lin_vel_xy: 3.8957
      Episode_Reward/rew_ang_vel_z: 2.3995
    Episode_Reward/pen_base_height: -0.3082
      Episode_Reward/pen_lin_vel_z: -0.0537
     Episode_Reward/pen_ang_vel_xy: -0.1589
   Episode_Reward/pen_joint_torque: -0.1987
    Episode_Reward/pen_joint_accel: -0.1053
    Episode_Reward/pen_action_rate: -0.0952
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0456
   Episode_Reward/pen_joint_powers: -0.0715
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2106
Episode_Reward/pen_flat_orientation: -0.1461
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.2900
   Episode_Reward/foot_landing_vel: -0.1376
   Episode_Reward/test_gait_reward: -0.8491
Metrics/base_velocity/error_vel_xy: 1.9457
Metrics/base_velocity/error_vel_yaw: 1.1409
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 1.10s
                        Total time: 893.57s
                               ETA: 2364.8s

################################################################################
                     [1m Learning iteration 823/3000 [0m                      

                       Computation: 90300 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 1.1454
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8461
                     Learning rate: 0.0006
                       Mean reward: 99.27
               Mean episode length: 967.94
       Episode_Reward/keep_balance: 0.9679
     Episode_Reward/rew_lin_vel_xy: 4.0213
      Episode_Reward/rew_ang_vel_z: 2.6001
    Episode_Reward/pen_base_height: -0.3123
      Episode_Reward/pen_lin_vel_z: -0.0551
     Episode_Reward/pen_ang_vel_xy: -0.1585
   Episode_Reward/pen_joint_torque: -0.2063
    Episode_Reward/pen_joint_accel: -0.1025
    Episode_Reward/pen_action_rate: -0.0965
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0441
   Episode_Reward/pen_joint_powers: -0.0714
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2129
Episode_Reward/pen_flat_orientation: -0.1417
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.2775
   Episode_Reward/foot_landing_vel: -0.1346
   Episode_Reward/test_gait_reward: -0.8812
Metrics/base_velocity/error_vel_xy: 2.0859
Metrics/base_velocity/error_vel_yaw: 1.1271
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 1.09s
                        Total time: 894.66s
                               ETA: 2363.7s

################################################################################
                     [1m Learning iteration 824/3000 [0m                      

                       Computation: 91087 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 1.0422
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8469
                     Learning rate: 0.0006
                       Mean reward: 90.61
               Mean episode length: 927.05
       Episode_Reward/keep_balance: 0.9265
     Episode_Reward/rew_lin_vel_xy: 3.7648
      Episode_Reward/rew_ang_vel_z: 2.4414
    Episode_Reward/pen_base_height: -0.3115
      Episode_Reward/pen_lin_vel_z: -0.0525
     Episode_Reward/pen_ang_vel_xy: -0.1540
   Episode_Reward/pen_joint_torque: -0.1983
    Episode_Reward/pen_joint_accel: -0.0985
    Episode_Reward/pen_action_rate: -0.0943
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0439
   Episode_Reward/pen_joint_powers: -0.0695
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2065
Episode_Reward/pen_flat_orientation: -0.1443
  Episode_Reward/pen_feet_distance: -0.0078
Episode_Reward/pen_feet_regulation: -0.2728
   Episode_Reward/foot_landing_vel: -0.1282
   Episode_Reward/test_gait_reward: -0.8453
Metrics/base_velocity/error_vel_xy: 1.9794
Metrics/base_velocity/error_vel_yaw: 1.1216
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 1.08s
                        Total time: 895.74s
                               ETA: 2362.6s

################################################################################
                     [1m Learning iteration 825/3000 [0m                      

                       Computation: 91565 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.9885
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8480
                     Learning rate: 0.0009
                       Mean reward: 92.46
               Mean episode length: 923.28
       Episode_Reward/keep_balance: 0.9090
     Episode_Reward/rew_lin_vel_xy: 3.9515
      Episode_Reward/rew_ang_vel_z: 2.4024
    Episode_Reward/pen_base_height: -0.3093
      Episode_Reward/pen_lin_vel_z: -0.0580
     Episode_Reward/pen_ang_vel_xy: -0.1563
   Episode_Reward/pen_joint_torque: -0.2042
    Episode_Reward/pen_joint_accel: -0.1043
    Episode_Reward/pen_action_rate: -0.0925
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0721
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2008
Episode_Reward/pen_flat_orientation: -0.1573
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2904
   Episode_Reward/foot_landing_vel: -0.1293
   Episode_Reward/test_gait_reward: -0.8391
Metrics/base_velocity/error_vel_xy: 1.8953
Metrics/base_velocity/error_vel_yaw: 1.0927
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 1.07s
                        Total time: 896.81s
                               ETA: 2361.5s

################################################################################
                     [1m Learning iteration 826/3000 [0m                      

                       Computation: 91118 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 1.1109
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8494
                     Learning rate: 0.0004
                       Mean reward: 91.86
               Mean episode length: 923.18
       Episode_Reward/keep_balance: 0.9461
     Episode_Reward/rew_lin_vel_xy: 3.9282
      Episode_Reward/rew_ang_vel_z: 2.5072
    Episode_Reward/pen_base_height: -0.3133
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.1563
   Episode_Reward/pen_joint_torque: -0.1987
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.0960
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0448
   Episode_Reward/pen_joint_powers: -0.0704
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2124
Episode_Reward/pen_flat_orientation: -0.1416
  Episode_Reward/pen_feet_distance: -0.0031
Episode_Reward/pen_feet_regulation: -0.2809
   Episode_Reward/foot_landing_vel: -0.1358
   Episode_Reward/test_gait_reward: -0.8700
Metrics/base_velocity/error_vel_xy: 2.0630
Metrics/base_velocity/error_vel_yaw: 1.1273
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 1.08s
                        Total time: 897.89s
                               ETA: 2360.4s

################################################################################
                     [1m Learning iteration 827/3000 [0m                      

                       Computation: 91050 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 1.2028
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8506
                     Learning rate: 0.0006
                       Mean reward: 93.84
               Mean episode length: 953.38
       Episode_Reward/keep_balance: 0.9241
     Episode_Reward/rew_lin_vel_xy: 3.8549
      Episode_Reward/rew_ang_vel_z: 2.3772
    Episode_Reward/pen_base_height: -0.3133
      Episode_Reward/pen_lin_vel_z: -0.0521
     Episode_Reward/pen_ang_vel_xy: -0.1632
   Episode_Reward/pen_joint_torque: -0.1891
    Episode_Reward/pen_joint_accel: -0.1078
    Episode_Reward/pen_action_rate: -0.0967
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0453
   Episode_Reward/pen_joint_powers: -0.0694
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2141
Episode_Reward/pen_flat_orientation: -0.1491
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.2887
   Episode_Reward/foot_landing_vel: -0.1335
   Episode_Reward/test_gait_reward: -0.8561
Metrics/base_velocity/error_vel_xy: 1.9323
Metrics/base_velocity/error_vel_yaw: 1.1688
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 1.08s
                        Total time: 898.97s
                               ETA: 2359.3s

################################################################################
                     [1m Learning iteration 828/3000 [0m                      

                       Computation: 91109 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 1.1122
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8509
                     Learning rate: 0.0009
                       Mean reward: 91.64
               Mean episode length: 943.34
       Episode_Reward/keep_balance: 0.9424
     Episode_Reward/rew_lin_vel_xy: 3.9448
      Episode_Reward/rew_ang_vel_z: 2.4692
    Episode_Reward/pen_base_height: -0.3198
      Episode_Reward/pen_lin_vel_z: -0.0529
     Episode_Reward/pen_ang_vel_xy: -0.1617
   Episode_Reward/pen_joint_torque: -0.1979
    Episode_Reward/pen_joint_accel: -0.1087
    Episode_Reward/pen_action_rate: -0.0979
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0464
   Episode_Reward/pen_joint_powers: -0.0719
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2155
Episode_Reward/pen_flat_orientation: -0.1506
  Episode_Reward/pen_feet_distance: -0.0061
Episode_Reward/pen_feet_regulation: -0.2978
   Episode_Reward/foot_landing_vel: -0.1378
   Episode_Reward/test_gait_reward: -0.8725
Metrics/base_velocity/error_vel_xy: 1.9200
Metrics/base_velocity/error_vel_yaw: 1.1536
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 1.08s
                        Total time: 900.05s
                               ETA: 2358.2s

################################################################################
                     [1m Learning iteration 829/3000 [0m                      

                       Computation: 85790 steps/s (collection: 1.023s, learning 0.122s)
               Value function loss: 1.1150
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8504
                     Learning rate: 0.0006
                       Mean reward: 92.81
               Mean episode length: 950.26
       Episode_Reward/keep_balance: 0.9590
     Episode_Reward/rew_lin_vel_xy: 4.0426
      Episode_Reward/rew_ang_vel_z: 2.5130
    Episode_Reward/pen_base_height: -0.3146
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1626
   Episode_Reward/pen_joint_torque: -0.2036
    Episode_Reward/pen_joint_accel: -0.0962
    Episode_Reward/pen_action_rate: -0.0984
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0451
   Episode_Reward/pen_joint_powers: -0.0722
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2174
Episode_Reward/pen_flat_orientation: -0.1447
  Episode_Reward/pen_feet_distance: -0.0025
Episode_Reward/pen_feet_regulation: -0.2865
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.8795
Metrics/base_velocity/error_vel_xy: 2.0656
Metrics/base_velocity/error_vel_yaw: 1.1643
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 1.15s
                        Total time: 901.20s
                               ETA: 2357.2s

################################################################################
                     [1m Learning iteration 830/3000 [0m                      

                       Computation: 90334 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 1.0382
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8509
                     Learning rate: 0.0009
                       Mean reward: 94.00
               Mean episode length: 942.64
       Episode_Reward/keep_balance: 0.9474
     Episode_Reward/rew_lin_vel_xy: 3.8597
      Episode_Reward/rew_ang_vel_z: 2.4892
    Episode_Reward/pen_base_height: -0.3061
      Episode_Reward/pen_lin_vel_z: -0.0522
     Episode_Reward/pen_ang_vel_xy: -0.1718
   Episode_Reward/pen_joint_torque: -0.1967
    Episode_Reward/pen_joint_accel: -0.1089
    Episode_Reward/pen_action_rate: -0.0995
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0471
   Episode_Reward/pen_joint_powers: -0.0717
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2187
Episode_Reward/pen_flat_orientation: -0.1480
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.2763
   Episode_Reward/foot_landing_vel: -0.1420
   Episode_Reward/test_gait_reward: -0.8618
Metrics/base_velocity/error_vel_xy: 2.1010
Metrics/base_velocity/error_vel_yaw: 1.1651
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 1.09s
                        Total time: 902.29s
                               ETA: 2356.2s

################################################################################
                     [1m Learning iteration 831/3000 [0m                      

                       Computation: 92206 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 1.0895
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8514
                     Learning rate: 0.0006
                       Mean reward: 95.36
               Mean episode length: 969.53
       Episode_Reward/keep_balance: 0.9617
     Episode_Reward/rew_lin_vel_xy: 3.9544
      Episode_Reward/rew_ang_vel_z: 2.5313
    Episode_Reward/pen_base_height: -0.3259
      Episode_Reward/pen_lin_vel_z: -0.0581
     Episode_Reward/pen_ang_vel_xy: -0.1619
   Episode_Reward/pen_joint_torque: -0.2070
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.0980
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0461
   Episode_Reward/pen_joint_powers: -0.0732
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2151
Episode_Reward/pen_flat_orientation: -0.1585
  Episode_Reward/pen_feet_distance: -0.0057
Episode_Reward/pen_feet_regulation: -0.2958
   Episode_Reward/foot_landing_vel: -0.1458
   Episode_Reward/test_gait_reward: -0.8836
Metrics/base_velocity/error_vel_xy: 2.0687
Metrics/base_velocity/error_vel_yaw: 1.1608
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 1.07s
                        Total time: 903.35s
                               ETA: 2355.0s

################################################################################
                     [1m Learning iteration 832/3000 [0m                      

                       Computation: 89801 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 1.1705
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8497
                     Learning rate: 0.0006
                       Mean reward: 95.96
               Mean episode length: 958.47
       Episode_Reward/keep_balance: 0.9512
     Episode_Reward/rew_lin_vel_xy: 3.9769
      Episode_Reward/rew_ang_vel_z: 2.4979
    Episode_Reward/pen_base_height: -0.3227
      Episode_Reward/pen_lin_vel_z: -0.0552
     Episode_Reward/pen_ang_vel_xy: -0.1601
   Episode_Reward/pen_joint_torque: -0.2118
    Episode_Reward/pen_joint_accel: -0.1044
    Episode_Reward/pen_action_rate: -0.0966
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0729
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2114
Episode_Reward/pen_flat_orientation: -0.1499
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.2887
   Episode_Reward/foot_landing_vel: -0.1350
   Episode_Reward/test_gait_reward: -0.8721
Metrics/base_velocity/error_vel_xy: 2.0015
Metrics/base_velocity/error_vel_yaw: 1.1512
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 1.09s
                        Total time: 904.45s
                               ETA: 2354.0s

################################################################################
                     [1m Learning iteration 833/3000 [0m                      

                       Computation: 90407 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 1.0992
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8505
                     Learning rate: 0.0004
                       Mean reward: 94.56
               Mean episode length: 948.60
       Episode_Reward/keep_balance: 0.9553
     Episode_Reward/rew_lin_vel_xy: 3.9973
      Episode_Reward/rew_ang_vel_z: 2.5545
    Episode_Reward/pen_base_height: -0.3133
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.1629
   Episode_Reward/pen_joint_torque: -0.2006
    Episode_Reward/pen_joint_accel: -0.1025
    Episode_Reward/pen_action_rate: -0.0970
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0711
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2130
Episode_Reward/pen_flat_orientation: -0.1462
  Episode_Reward/pen_feet_distance: -0.0035
Episode_Reward/pen_feet_regulation: -0.2862
   Episode_Reward/foot_landing_vel: -0.1313
   Episode_Reward/test_gait_reward: -0.8717
Metrics/base_velocity/error_vel_xy: 1.9968
Metrics/base_velocity/error_vel_yaw: 1.1254
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 1.09s
                        Total time: 905.53s
                               ETA: 2352.9s

################################################################################
                     [1m Learning iteration 834/3000 [0m                      

                       Computation: 91811 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 1.0334
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8526
                     Learning rate: 0.0009
                       Mean reward: 93.43
               Mean episode length: 955.61
       Episode_Reward/keep_balance: 0.9508
     Episode_Reward/rew_lin_vel_xy: 3.8706
      Episode_Reward/rew_ang_vel_z: 2.5025
    Episode_Reward/pen_base_height: -0.3178
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1680
   Episode_Reward/pen_joint_torque: -0.2054
    Episode_Reward/pen_joint_accel: -0.0998
    Episode_Reward/pen_action_rate: -0.0975
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0465
   Episode_Reward/pen_joint_powers: -0.0732
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2138
Episode_Reward/pen_flat_orientation: -0.1462
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.2943
   Episode_Reward/foot_landing_vel: -0.1315
   Episode_Reward/test_gait_reward: -0.8711
Metrics/base_velocity/error_vel_xy: 2.0779
Metrics/base_velocity/error_vel_yaw: 1.1510
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 1.07s
                        Total time: 906.61s
                               ETA: 2351.7s

################################################################################
                     [1m Learning iteration 835/3000 [0m                      

                       Computation: 92878 steps/s (collection: 0.935s, learning 0.124s)
               Value function loss: 1.1168
                    Surrogate loss: -0.0014
             Mean action noise std: 0.8543
                     Learning rate: 0.0006
                       Mean reward: 89.85
               Mean episode length: 939.30
       Episode_Reward/keep_balance: 0.9335
     Episode_Reward/rew_lin_vel_xy: 3.9010
      Episode_Reward/rew_ang_vel_z: 2.4484
    Episode_Reward/pen_base_height: -0.3104
      Episode_Reward/pen_lin_vel_z: -0.0556
     Episode_Reward/pen_ang_vel_xy: -0.1638
   Episode_Reward/pen_joint_torque: -0.2028
    Episode_Reward/pen_joint_accel: -0.1136
    Episode_Reward/pen_action_rate: -0.0957
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0457
   Episode_Reward/pen_joint_powers: -0.0718
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2112
Episode_Reward/pen_flat_orientation: -0.1417
  Episode_Reward/pen_feet_distance: -0.0048
Episode_Reward/pen_feet_regulation: -0.2984
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.8578
Metrics/base_velocity/error_vel_xy: 1.9638
Metrics/base_velocity/error_vel_yaw: 1.1330
      Episode_Termination/time_out: 2.6667
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 1.06s
                        Total time: 907.66s
                               ETA: 2350.6s

################################################################################
                     [1m Learning iteration 836/3000 [0m                      

                       Computation: 90649 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 1.0949
                    Surrogate loss: -0.0000
             Mean action noise std: 0.8564
                     Learning rate: 0.0002
                       Mean reward: 87.49
               Mean episode length: 908.68
       Episode_Reward/keep_balance: 0.9322
     Episode_Reward/rew_lin_vel_xy: 3.7787
      Episode_Reward/rew_ang_vel_z: 2.4272
    Episode_Reward/pen_base_height: -0.3174
      Episode_Reward/pen_lin_vel_z: -0.0541
     Episode_Reward/pen_ang_vel_xy: -0.1707
   Episode_Reward/pen_joint_torque: -0.1962
    Episode_Reward/pen_joint_accel: -0.1019
    Episode_Reward/pen_action_rate: -0.0964
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0464
   Episode_Reward/pen_joint_powers: -0.0714
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2112
Episode_Reward/pen_flat_orientation: -0.1524
  Episode_Reward/pen_feet_distance: -0.0029
Episode_Reward/pen_feet_regulation: -0.2876
   Episode_Reward/foot_landing_vel: -0.1336
   Episode_Reward/test_gait_reward: -0.8552
Metrics/base_velocity/error_vel_xy: 2.0851
Metrics/base_velocity/error_vel_yaw: 1.1509
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 1.08s
                        Total time: 908.75s
                               ETA: 2349.5s

################################################################################
                     [1m Learning iteration 837/3000 [0m                      

                       Computation: 91105 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 1.0929
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8574
                     Learning rate: 0.0003
                       Mean reward: 89.33
               Mean episode length: 963.56
       Episode_Reward/keep_balance: 0.9773
     Episode_Reward/rew_lin_vel_xy: 3.9437
      Episode_Reward/rew_ang_vel_z: 2.5353
    Episode_Reward/pen_base_height: -0.3245
      Episode_Reward/pen_lin_vel_z: -0.0574
     Episode_Reward/pen_ang_vel_xy: -0.1722
   Episode_Reward/pen_joint_torque: -0.2094
    Episode_Reward/pen_joint_accel: -0.0992
    Episode_Reward/pen_action_rate: -0.1008
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0473
   Episode_Reward/pen_joint_powers: -0.0746
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2202
Episode_Reward/pen_flat_orientation: -0.1500
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.3095
   Episode_Reward/foot_landing_vel: -0.1387
   Episode_Reward/test_gait_reward: -0.8956
Metrics/base_velocity/error_vel_xy: 2.1873
Metrics/base_velocity/error_vel_yaw: 1.2132
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 1.08s
                        Total time: 909.83s
                               ETA: 2348.4s

################################################################################
                     [1m Learning iteration 838/3000 [0m                      

                       Computation: 91333 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.9871
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8598
                     Learning rate: 0.0004
                       Mean reward: 94.00
               Mean episode length: 925.24
       Episode_Reward/keep_balance: 0.9282
     Episode_Reward/rew_lin_vel_xy: 3.9404
      Episode_Reward/rew_ang_vel_z: 2.4638
    Episode_Reward/pen_base_height: -0.3246
      Episode_Reward/pen_lin_vel_z: -0.0557
     Episode_Reward/pen_ang_vel_xy: -0.1619
   Episode_Reward/pen_joint_torque: -0.2035
    Episode_Reward/pen_joint_accel: -0.1011
    Episode_Reward/pen_action_rate: -0.0943
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0717
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2055
Episode_Reward/pen_flat_orientation: -0.1444
  Episode_Reward/pen_feet_distance: -0.0046
Episode_Reward/pen_feet_regulation: -0.2945
   Episode_Reward/foot_landing_vel: -0.1334
   Episode_Reward/test_gait_reward: -0.8464
Metrics/base_velocity/error_vel_xy: 1.9425
Metrics/base_velocity/error_vel_yaw: 1.1053
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 1.08s
                        Total time: 910.90s
                               ETA: 2347.3s

################################################################################
                     [1m Learning iteration 839/3000 [0m                      

                       Computation: 90723 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 1.0163
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8599
                     Learning rate: 0.0006
                       Mean reward: 95.18
               Mean episode length: 961.07
       Episode_Reward/keep_balance: 0.9692
     Episode_Reward/rew_lin_vel_xy: 3.9362
      Episode_Reward/rew_ang_vel_z: 2.5690
    Episode_Reward/pen_base_height: -0.3207
      Episode_Reward/pen_lin_vel_z: -0.0533
     Episode_Reward/pen_ang_vel_xy: -0.1683
   Episode_Reward/pen_joint_torque: -0.2061
    Episode_Reward/pen_joint_accel: -0.0986
    Episode_Reward/pen_action_rate: -0.0984
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0452
   Episode_Reward/pen_joint_powers: -0.0724
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2177
Episode_Reward/pen_flat_orientation: -0.1395
  Episode_Reward/pen_feet_distance: -0.0044
Episode_Reward/pen_feet_regulation: -0.2930
   Episode_Reward/foot_landing_vel: -0.1331
   Episode_Reward/test_gait_reward: -0.8800
Metrics/base_velocity/error_vel_xy: 2.1898
Metrics/base_velocity/error_vel_yaw: 1.1544
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 1.08s
                        Total time: 911.99s
                               ETA: 2346.2s

################################################################################
                     [1m Learning iteration 840/3000 [0m                      

                       Computation: 89112 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 1.0303
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8603
                     Learning rate: 0.0004
                       Mean reward: 94.34
               Mean episode length: 953.09
       Episode_Reward/keep_balance: 0.9642
     Episode_Reward/rew_lin_vel_xy: 3.9456
      Episode_Reward/rew_ang_vel_z: 2.5494
    Episode_Reward/pen_base_height: -0.3244
      Episode_Reward/pen_lin_vel_z: -0.0556
     Episode_Reward/pen_ang_vel_xy: -0.1634
   Episode_Reward/pen_joint_torque: -0.2124
    Episode_Reward/pen_joint_accel: -0.1021
    Episode_Reward/pen_action_rate: -0.0984
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0460
   Episode_Reward/pen_joint_powers: -0.0737
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2167
Episode_Reward/pen_flat_orientation: -0.1449
  Episode_Reward/pen_feet_distance: -0.0064
Episode_Reward/pen_feet_regulation: -0.3006
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.8817
Metrics/base_velocity/error_vel_xy: 2.0152
Metrics/base_velocity/error_vel_yaw: 1.1493
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 1.10s
                        Total time: 913.09s
                               ETA: 2345.2s

################################################################################
                     [1m Learning iteration 841/3000 [0m                      

                       Computation: 90396 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 1.1215
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8608
                     Learning rate: 0.0009
                       Mean reward: 94.69
               Mean episode length: 949.66
       Episode_Reward/keep_balance: 0.9574
     Episode_Reward/rew_lin_vel_xy: 3.9545
      Episode_Reward/rew_ang_vel_z: 2.4978
    Episode_Reward/pen_base_height: -0.3113
      Episode_Reward/pen_lin_vel_z: -0.0559
     Episode_Reward/pen_ang_vel_xy: -0.1661
   Episode_Reward/pen_joint_torque: -0.2074
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.0980
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0465
   Episode_Reward/pen_joint_powers: -0.0737
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2158
Episode_Reward/pen_flat_orientation: -0.1448
  Episode_Reward/pen_feet_distance: -0.0044
Episode_Reward/pen_feet_regulation: -0.2983
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.8747
Metrics/base_velocity/error_vel_xy: 2.0615
Metrics/base_velocity/error_vel_yaw: 1.1734
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 1.09s
                        Total time: 914.18s
                               ETA: 2344.1s

################################################################################
                     [1m Learning iteration 842/3000 [0m                      

                       Computation: 91219 steps/s (collection: 0.956s, learning 0.121s)
               Value function loss: 1.0900
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8607
                     Learning rate: 0.0013
                       Mean reward: 90.23
               Mean episode length: 933.06
       Episode_Reward/keep_balance: 0.9277
     Episode_Reward/rew_lin_vel_xy: 3.8387
      Episode_Reward/rew_ang_vel_z: 2.4391
    Episode_Reward/pen_base_height: -0.3145
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.1641
   Episode_Reward/pen_joint_torque: -0.2043
    Episode_Reward/pen_joint_accel: -0.0980
    Episode_Reward/pen_action_rate: -0.0953
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0450
   Episode_Reward/pen_joint_powers: -0.0717
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2100
Episode_Reward/pen_flat_orientation: -0.1435
  Episode_Reward/pen_feet_distance: -0.0055
Episode_Reward/pen_feet_regulation: -0.2938
   Episode_Reward/foot_landing_vel: -0.1310
   Episode_Reward/test_gait_reward: -0.8499
Metrics/base_velocity/error_vel_xy: 2.0619
Metrics/base_velocity/error_vel_yaw: 1.1186
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 1.08s
                        Total time: 915.26s
                               ETA: 2343.0s

################################################################################
                     [1m Learning iteration 843/3000 [0m                      

                       Computation: 91853 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.2391
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8594
                     Learning rate: 0.0019
                       Mean reward: 90.28
               Mean episode length: 935.33
       Episode_Reward/keep_balance: 0.9360
     Episode_Reward/rew_lin_vel_xy: 3.7927
      Episode_Reward/rew_ang_vel_z: 2.4573
    Episode_Reward/pen_base_height: -0.3165
      Episode_Reward/pen_lin_vel_z: -0.0540
     Episode_Reward/pen_ang_vel_xy: -0.1596
   Episode_Reward/pen_joint_torque: -0.2075
    Episode_Reward/pen_joint_accel: -0.0956
    Episode_Reward/pen_action_rate: -0.0949
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0446
   Episode_Reward/pen_joint_powers: -0.0722
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2084
Episode_Reward/pen_flat_orientation: -0.1466
  Episode_Reward/pen_feet_distance: -0.0040
Episode_Reward/pen_feet_regulation: -0.2850
   Episode_Reward/foot_landing_vel: -0.1288
   Episode_Reward/test_gait_reward: -0.8577
Metrics/base_velocity/error_vel_xy: 2.1009
Metrics/base_velocity/error_vel_yaw: 1.1451
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 1.07s
                        Total time: 916.33s
                               ETA: 2341.8s

################################################################################
                     [1m Learning iteration 844/3000 [0m                      

                       Computation: 92709 steps/s (collection: 0.934s, learning 0.126s)
               Value function loss: 1.1292
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8607
                     Learning rate: 0.0006
                       Mean reward: 93.42
               Mean episode length: 938.14
       Episode_Reward/keep_balance: 0.9374
     Episode_Reward/rew_lin_vel_xy: 3.9598
      Episode_Reward/rew_ang_vel_z: 2.4949
    Episode_Reward/pen_base_height: -0.3148
      Episode_Reward/pen_lin_vel_z: -0.0543
     Episode_Reward/pen_ang_vel_xy: -0.1630
   Episode_Reward/pen_joint_torque: -0.2077
    Episode_Reward/pen_joint_accel: -0.0984
    Episode_Reward/pen_action_rate: -0.0960
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0732
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2101
Episode_Reward/pen_flat_orientation: -0.1425
  Episode_Reward/pen_feet_distance: -0.0119
Episode_Reward/pen_feet_regulation: -0.3006
   Episode_Reward/foot_landing_vel: -0.1409
   Episode_Reward/test_gait_reward: -0.8617
Metrics/base_velocity/error_vel_xy: 1.9590
Metrics/base_velocity/error_vel_yaw: 1.1119
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 1.06s
                        Total time: 917.39s
                               ETA: 2340.7s

################################################################################
                     [1m Learning iteration 845/3000 [0m                      

                       Computation: 90238 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 1.0263
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8594
                     Learning rate: 0.0013
                       Mean reward: 89.23
               Mean episode length: 944.11
       Episode_Reward/keep_balance: 0.9538
     Episode_Reward/rew_lin_vel_xy: 3.7839
      Episode_Reward/rew_ang_vel_z: 2.4883
    Episode_Reward/pen_base_height: -0.3125
      Episode_Reward/pen_lin_vel_z: -0.0548
     Episode_Reward/pen_ang_vel_xy: -0.1682
   Episode_Reward/pen_joint_torque: -0.2052
    Episode_Reward/pen_joint_accel: -0.1039
    Episode_Reward/pen_action_rate: -0.0978
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0465
   Episode_Reward/pen_joint_powers: -0.0733
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2151
Episode_Reward/pen_flat_orientation: -0.1448
  Episode_Reward/pen_feet_distance: -0.0054
Episode_Reward/pen_feet_regulation: -0.2967
   Episode_Reward/foot_landing_vel: -0.1385
   Episode_Reward/test_gait_reward: -0.8707
Metrics/base_velocity/error_vel_xy: 2.1354
Metrics/base_velocity/error_vel_yaw: 1.1737
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 1.09s
                        Total time: 918.48s
                               ETA: 2339.6s

################################################################################
                     [1m Learning iteration 846/3000 [0m                      

                       Computation: 90679 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 1.1436
                    Surrogate loss: 0.0007
             Mean action noise std: 0.8602
                     Learning rate: 0.0004
                       Mean reward: 94.61
               Mean episode length: 956.15
       Episode_Reward/keep_balance: 0.9504
     Episode_Reward/rew_lin_vel_xy: 3.9182
      Episode_Reward/rew_ang_vel_z: 2.4657
    Episode_Reward/pen_base_height: -0.3262
      Episode_Reward/pen_lin_vel_z: -0.0518
     Episode_Reward/pen_ang_vel_xy: -0.1691
   Episode_Reward/pen_joint_torque: -0.2042
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.0985
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0460
   Episode_Reward/pen_joint_powers: -0.0727
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2171
Episode_Reward/pen_flat_orientation: -0.1448
  Episode_Reward/pen_feet_distance: -0.0035
Episode_Reward/pen_feet_regulation: -0.2969
   Episode_Reward/foot_landing_vel: -0.1291
   Episode_Reward/test_gait_reward: -0.8693
Metrics/base_velocity/error_vel_xy: 2.0329
Metrics/base_velocity/error_vel_yaw: 1.1850
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 1.08s
                        Total time: 919.56s
                               ETA: 2338.5s

################################################################################
                     [1m Learning iteration 847/3000 [0m                      

                       Computation: 90461 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 1.0387
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8609
                     Learning rate: 0.0006
                       Mean reward: 95.23
               Mean episode length: 951.19
       Episode_Reward/keep_balance: 0.9506
     Episode_Reward/rew_lin_vel_xy: 3.9796
      Episode_Reward/rew_ang_vel_z: 2.4986
    Episode_Reward/pen_base_height: -0.3031
      Episode_Reward/pen_lin_vel_z: -0.0516
     Episode_Reward/pen_ang_vel_xy: -0.1611
   Episode_Reward/pen_joint_torque: -0.2025
    Episode_Reward/pen_joint_accel: -0.0980
    Episode_Reward/pen_action_rate: -0.0965
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0447
   Episode_Reward/pen_joint_powers: -0.0711
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2145
Episode_Reward/pen_flat_orientation: -0.1387
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.2838
   Episode_Reward/foot_landing_vel: -0.1291
   Episode_Reward/test_gait_reward: -0.8601
Metrics/base_velocity/error_vel_xy: 2.0842
Metrics/base_velocity/error_vel_yaw: 1.1469
      Episode_Termination/time_out: 3.2500
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 1.09s
                        Total time: 920.65s
                               ETA: 2337.4s

################################################################################
                     [1m Learning iteration 848/3000 [0m                      

                       Computation: 90635 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 1.0745
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8612
                     Learning rate: 0.0004
                       Mean reward: 89.06
               Mean episode length: 917.76
       Episode_Reward/keep_balance: 0.8901
     Episode_Reward/rew_lin_vel_xy: 3.8041
      Episode_Reward/rew_ang_vel_z: 2.3067
    Episode_Reward/pen_base_height: -0.3106
      Episode_Reward/pen_lin_vel_z: -0.0528
     Episode_Reward/pen_ang_vel_xy: -0.1571
   Episode_Reward/pen_joint_torque: -0.1995
    Episode_Reward/pen_joint_accel: -0.0931
    Episode_Reward/pen_action_rate: -0.0918
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0445
   Episode_Reward/pen_joint_powers: -0.0705
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2015
Episode_Reward/pen_flat_orientation: -0.1427
  Episode_Reward/pen_feet_distance: -0.0047
Episode_Reward/pen_feet_regulation: -0.2953
   Episode_Reward/foot_landing_vel: -0.1325
   Episode_Reward/test_gait_reward: -0.8181
Metrics/base_velocity/error_vel_xy: 1.8599
Metrics/base_velocity/error_vel_yaw: 1.1038
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 1.08s
                        Total time: 921.73s
                               ETA: 2336.4s

################################################################################
                     [1m Learning iteration 849/3000 [0m                      

                       Computation: 90338 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 1.0086
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8622
                     Learning rate: 0.0004
                       Mean reward: 90.25
               Mean episode length: 962.89
       Episode_Reward/keep_balance: 0.9790
     Episode_Reward/rew_lin_vel_xy: 3.9279
      Episode_Reward/rew_ang_vel_z: 2.5608
    Episode_Reward/pen_base_height: -0.3100
      Episode_Reward/pen_lin_vel_z: -0.0533
     Episode_Reward/pen_ang_vel_xy: -0.1634
   Episode_Reward/pen_joint_torque: -0.2105
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.1000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0460
   Episode_Reward/pen_joint_powers: -0.0734
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2224
Episode_Reward/pen_flat_orientation: -0.1338
  Episode_Reward/pen_feet_distance: -0.0043
Episode_Reward/pen_feet_regulation: -0.2881
   Episode_Reward/foot_landing_vel: -0.1428
   Episode_Reward/test_gait_reward: -0.8867
Metrics/base_velocity/error_vel_xy: 2.2158
Metrics/base_velocity/error_vel_yaw: 1.1932
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 1.09s
                        Total time: 922.82s
                               ETA: 2335.3s

################################################################################
                     [1m Learning iteration 850/3000 [0m                      

                       Computation: 90634 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 1.0219
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8623
                     Learning rate: 0.0009
                       Mean reward: 98.10
               Mean episode length: 955.26
       Episode_Reward/keep_balance: 0.9617
     Episode_Reward/rew_lin_vel_xy: 4.1020
      Episode_Reward/rew_ang_vel_z: 2.5341
    Episode_Reward/pen_base_height: -0.3161
      Episode_Reward/pen_lin_vel_z: -0.0528
     Episode_Reward/pen_ang_vel_xy: -0.1650
   Episode_Reward/pen_joint_torque: -0.2097
    Episode_Reward/pen_joint_accel: -0.0963
    Episode_Reward/pen_action_rate: -0.0986
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0466
   Episode_Reward/pen_joint_powers: -0.0739
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2176
Episode_Reward/pen_flat_orientation: -0.1384
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3041
   Episode_Reward/foot_landing_vel: -0.1388
   Episode_Reward/test_gait_reward: -0.8831
Metrics/base_velocity/error_vel_xy: 2.0121
Metrics/base_velocity/error_vel_yaw: 1.1581
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 1.08s
                        Total time: 923.90s
                               ETA: 2334.2s

################################################################################
                     [1m Learning iteration 851/3000 [0m                      

                       Computation: 90711 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.9855
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8649
                     Learning rate: 0.0009
                       Mean reward: 90.59
               Mean episode length: 950.69
       Episode_Reward/keep_balance: 0.9514
     Episode_Reward/rew_lin_vel_xy: 3.8758
      Episode_Reward/rew_ang_vel_z: 2.4942
    Episode_Reward/pen_base_height: -0.3293
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1706
   Episode_Reward/pen_joint_torque: -0.2106
    Episode_Reward/pen_joint_accel: -0.0996
    Episode_Reward/pen_action_rate: -0.0980
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0474
   Episode_Reward/pen_joint_powers: -0.0749
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2142
Episode_Reward/pen_flat_orientation: -0.1453
  Episode_Reward/pen_feet_distance: -0.0054
Episode_Reward/pen_feet_regulation: -0.3065
   Episode_Reward/foot_landing_vel: -0.1387
   Episode_Reward/test_gait_reward: -0.8716
Metrics/base_velocity/error_vel_xy: 2.0821
Metrics/base_velocity/error_vel_yaw: 1.1597
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 1.08s
                        Total time: 924.99s
                               ETA: 2333.1s

################################################################################
                     [1m Learning iteration 852/3000 [0m                      

                       Computation: 90868 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 1.0483
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8658
                     Learning rate: 0.0004
                       Mean reward: 92.63
               Mean episode length: 951.99
       Episode_Reward/keep_balance: 0.9644
     Episode_Reward/rew_lin_vel_xy: 3.9662
      Episode_Reward/rew_ang_vel_z: 2.5539
    Episode_Reward/pen_base_height: -0.3293
      Episode_Reward/pen_lin_vel_z: -0.0542
     Episode_Reward/pen_ang_vel_xy: -0.1661
   Episode_Reward/pen_joint_torque: -0.2123
    Episode_Reward/pen_joint_accel: -0.1076
    Episode_Reward/pen_action_rate: -0.0995
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0470
   Episode_Reward/pen_joint_powers: -0.0753
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2183
Episode_Reward/pen_flat_orientation: -0.1408
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3083
   Episode_Reward/foot_landing_vel: -0.1370
   Episode_Reward/test_gait_reward: -0.8923
Metrics/base_velocity/error_vel_xy: 2.0938
Metrics/base_velocity/error_vel_yaw: 1.1508
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 1.08s
                        Total time: 926.07s
                               ETA: 2332.0s

################################################################################
                     [1m Learning iteration 853/3000 [0m                      

                       Computation: 91028 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.9804
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8639
                     Learning rate: 0.0006
                       Mean reward: 92.80
               Mean episode length: 953.01
       Episode_Reward/keep_balance: 0.9594
     Episode_Reward/rew_lin_vel_xy: 4.1065
      Episode_Reward/rew_ang_vel_z: 2.4709
    Episode_Reward/pen_base_height: -0.3138
      Episode_Reward/pen_lin_vel_z: -0.0508
     Episode_Reward/pen_ang_vel_xy: -0.1672
   Episode_Reward/pen_joint_torque: -0.2034
    Episode_Reward/pen_joint_accel: -0.1096
    Episode_Reward/pen_action_rate: -0.1003
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0465
   Episode_Reward/pen_joint_powers: -0.0725
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2232
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0041
Episode_Reward/pen_feet_regulation: -0.3021
   Episode_Reward/foot_landing_vel: -0.1360
   Episode_Reward/test_gait_reward: -0.8821
Metrics/base_velocity/error_vel_xy: 1.9376
Metrics/base_velocity/error_vel_yaw: 1.1995
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 1.08s
                        Total time: 927.15s
                               ETA: 2330.9s

################################################################################
                     [1m Learning iteration 854/3000 [0m                      

                       Computation: 91114 steps/s (collection: 0.954s, learning 0.125s)
               Value function loss: 1.0608
                    Surrogate loss: -0.0008
             Mean action noise std: 0.8631
                     Learning rate: 0.0001
                       Mean reward: 97.32
               Mean episode length: 940.81
       Episode_Reward/keep_balance: 0.9010
     Episode_Reward/rew_lin_vel_xy: 3.9470
      Episode_Reward/rew_ang_vel_z: 2.3896
    Episode_Reward/pen_base_height: -0.2998
      Episode_Reward/pen_lin_vel_z: -0.0494
     Episode_Reward/pen_ang_vel_xy: -0.1599
   Episode_Reward/pen_joint_torque: -0.1907
    Episode_Reward/pen_joint_accel: -0.1008
    Episode_Reward/pen_action_rate: -0.0922
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0433
   Episode_Reward/pen_joint_powers: -0.0685
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2047
Episode_Reward/pen_flat_orientation: -0.1321
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.2729
   Episode_Reward/foot_landing_vel: -0.1303
   Episode_Reward/test_gait_reward: -0.8237
Metrics/base_velocity/error_vel_xy: 1.8749
Metrics/base_velocity/error_vel_yaw: 1.0742
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 1.08s
                        Total time: 928.23s
                               ETA: 2329.8s

################################################################################
                     [1m Learning iteration 855/3000 [0m                      

                       Computation: 91369 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.9844
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8625
                     Learning rate: 0.0003
                       Mean reward: 95.58
               Mean episode length: 956.83
       Episode_Reward/keep_balance: 0.9651
     Episode_Reward/rew_lin_vel_xy: 4.2588
      Episode_Reward/rew_ang_vel_z: 2.5343
    Episode_Reward/pen_base_height: -0.3294
      Episode_Reward/pen_lin_vel_z: -0.0558
     Episode_Reward/pen_ang_vel_xy: -0.1702
   Episode_Reward/pen_joint_torque: -0.2135
    Episode_Reward/pen_joint_accel: -0.1060
    Episode_Reward/pen_action_rate: -0.1002
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0485
   Episode_Reward/pen_joint_powers: -0.0759
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2204
Episode_Reward/pen_flat_orientation: -0.1451
  Episode_Reward/pen_feet_distance: -0.0084
Episode_Reward/pen_feet_regulation: -0.3217
   Episode_Reward/foot_landing_vel: -0.1440
   Episode_Reward/test_gait_reward: -0.8964
Metrics/base_velocity/error_vel_xy: 1.9273
Metrics/base_velocity/error_vel_yaw: 1.1684
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 1.08s
                        Total time: 929.30s
                               ETA: 2328.7s

################################################################################
                     [1m Learning iteration 856/3000 [0m                      

                       Computation: 90017 steps/s (collection: 0.966s, learning 0.126s)
               Value function loss: 1.0515
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8621
                     Learning rate: 0.0006
                       Mean reward: 95.58
               Mean episode length: 935.88
       Episode_Reward/keep_balance: 0.9176
     Episode_Reward/rew_lin_vel_xy: 3.9735
      Episode_Reward/rew_ang_vel_z: 2.3576
    Episode_Reward/pen_base_height: -0.3179
      Episode_Reward/pen_lin_vel_z: -0.0504
     Episode_Reward/pen_ang_vel_xy: -0.1701
   Episode_Reward/pen_joint_torque: -0.1939
    Episode_Reward/pen_joint_accel: -0.1019
    Episode_Reward/pen_action_rate: -0.0958
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0462
   Episode_Reward/pen_joint_powers: -0.0712
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2125
Episode_Reward/pen_flat_orientation: -0.1367
  Episode_Reward/pen_feet_distance: -0.0039
Episode_Reward/pen_feet_regulation: -0.2920
   Episode_Reward/foot_landing_vel: -0.1360
   Episode_Reward/test_gait_reward: -0.8489
Metrics/base_velocity/error_vel_xy: 1.8049
Metrics/base_velocity/error_vel_yaw: 1.1584
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 1.09s
                        Total time: 930.40s
                               ETA: 2327.6s

################################################################################
                     [1m Learning iteration 857/3000 [0m                      

                       Computation: 89548 steps/s (collection: 0.972s, learning 0.126s)
               Value function loss: 0.9209
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8624
                     Learning rate: 0.0009
                       Mean reward: 97.66
               Mean episode length: 973.63
       Episode_Reward/keep_balance: 0.9729
     Episode_Reward/rew_lin_vel_xy: 4.2717
      Episode_Reward/rew_ang_vel_z: 2.5326
    Episode_Reward/pen_base_height: -0.3314
      Episode_Reward/pen_lin_vel_z: -0.0556
     Episode_Reward/pen_ang_vel_xy: -0.1691
   Episode_Reward/pen_joint_torque: -0.2138
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.1014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0479
   Episode_Reward/pen_joint_powers: -0.0754
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2221
Episode_Reward/pen_flat_orientation: -0.1408
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3179
   Episode_Reward/foot_landing_vel: -0.1401
   Episode_Reward/test_gait_reward: -0.8937
Metrics/base_velocity/error_vel_xy: 1.9338
Metrics/base_velocity/error_vel_yaw: 1.2007
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 1.10s
                        Total time: 931.49s
                               ETA: 2326.6s

################################################################################
                     [1m Learning iteration 858/3000 [0m                      

                       Computation: 90263 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 1.0576
                    Surrogate loss: -0.0008
             Mean action noise std: 0.8627
                     Learning rate: 0.0003
                       Mean reward: 95.92
               Mean episode length: 984.02
       Episode_Reward/keep_balance: 0.9772
     Episode_Reward/rew_lin_vel_xy: 4.0744
      Episode_Reward/rew_ang_vel_z: 2.5774
    Episode_Reward/pen_base_height: -0.3409
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1674
   Episode_Reward/pen_joint_torque: -0.2216
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1011
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0472
   Episode_Reward/pen_joint_powers: -0.0760
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2224
Episode_Reward/pen_flat_orientation: -0.1413
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.3115
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.9055
Metrics/base_velocity/error_vel_xy: 2.1194
Metrics/base_velocity/error_vel_yaw: 1.1759
      Episode_Termination/time_out: 5.0833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 1.09s
                        Total time: 932.58s
                               ETA: 2325.5s

################################################################################
                     [1m Learning iteration 859/3000 [0m                      

                       Computation: 89814 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 1.0746
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8621
                     Learning rate: 0.0006
                       Mean reward: 96.65
               Mean episode length: 949.93
       Episode_Reward/keep_balance: 0.9145
     Episode_Reward/rew_lin_vel_xy: 3.9622
      Episode_Reward/rew_ang_vel_z: 2.4170
    Episode_Reward/pen_base_height: -0.3063
      Episode_Reward/pen_lin_vel_z: -0.0523
     Episode_Reward/pen_ang_vel_xy: -0.1610
   Episode_Reward/pen_joint_torque: -0.2028
    Episode_Reward/pen_joint_accel: -0.1049
    Episode_Reward/pen_action_rate: -0.0942
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0456
   Episode_Reward/pen_joint_powers: -0.0720
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2083
Episode_Reward/pen_flat_orientation: -0.1372
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.2934
   Episode_Reward/foot_landing_vel: -0.1407
   Episode_Reward/test_gait_reward: -0.8403
Metrics/base_velocity/error_vel_xy: 1.9018
Metrics/base_velocity/error_vel_yaw: 1.0973
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 1.09s
                        Total time: 933.68s
                               ETA: 2324.4s

################################################################################
                     [1m Learning iteration 860/3000 [0m                      

                       Computation: 92062 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 1.0699
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8619
                     Learning rate: 0.0006
                       Mean reward: 90.83
               Mean episode length: 946.86
       Episode_Reward/keep_balance: 0.9525
     Episode_Reward/rew_lin_vel_xy: 3.9197
      Episode_Reward/rew_ang_vel_z: 2.5076
    Episode_Reward/pen_base_height: -0.3181
      Episode_Reward/pen_lin_vel_z: -0.0534
     Episode_Reward/pen_ang_vel_xy: -0.1661
   Episode_Reward/pen_joint_torque: -0.2043
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.0990
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0464
   Episode_Reward/pen_joint_powers: -0.0729
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2192
Episode_Reward/pen_flat_orientation: -0.1368
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.2975
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.8721
Metrics/base_velocity/error_vel_xy: 2.0895
Metrics/base_velocity/error_vel_yaw: 1.1565
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 1.07s
                        Total time: 934.75s
                               ETA: 2323.3s

################################################################################
                     [1m Learning iteration 861/3000 [0m                      

                       Computation: 91490 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 1.0926
                    Surrogate loss: 0.0007
             Mean action noise std: 0.8628
                     Learning rate: 0.0002
                       Mean reward: 93.68
               Mean episode length: 920.52
       Episode_Reward/keep_balance: 0.9380
     Episode_Reward/rew_lin_vel_xy: 4.1926
      Episode_Reward/rew_ang_vel_z: 2.4497
    Episode_Reward/pen_base_height: -0.3272
      Episode_Reward/pen_lin_vel_z: -0.0534
     Episode_Reward/pen_ang_vel_xy: -0.1654
   Episode_Reward/pen_joint_torque: -0.2034
    Episode_Reward/pen_joint_accel: -0.0933
    Episode_Reward/pen_action_rate: -0.0976
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0459
   Episode_Reward/pen_joint_powers: -0.0725
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2142
Episode_Reward/pen_flat_orientation: -0.1380
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.2982
   Episode_Reward/foot_landing_vel: -0.1345
   Episode_Reward/test_gait_reward: -0.8716
Metrics/base_velocity/error_vel_xy: 1.7913
Metrics/base_velocity/error_vel_yaw: 1.1590
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 1.07s
                        Total time: 935.82s
                               ETA: 2322.2s

################################################################################
                     [1m Learning iteration 862/3000 [0m                      

                       Computation: 92262 steps/s (collection: 0.941s, learning 0.124s)
               Value function loss: 1.0546
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8625
                     Learning rate: 0.0004
                       Mean reward: 95.85
               Mean episode length: 962.85
       Episode_Reward/keep_balance: 0.9690
     Episode_Reward/rew_lin_vel_xy: 4.0050
      Episode_Reward/rew_ang_vel_z: 2.5964
    Episode_Reward/pen_base_height: -0.3247
      Episode_Reward/pen_lin_vel_z: -0.0553
     Episode_Reward/pen_ang_vel_xy: -0.1655
   Episode_Reward/pen_joint_torque: -0.2209
    Episode_Reward/pen_joint_accel: -0.1048
    Episode_Reward/pen_action_rate: -0.0982
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0746
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2164
Episode_Reward/pen_flat_orientation: -0.1317
  Episode_Reward/pen_feet_distance: -0.0079
Episode_Reward/pen_feet_regulation: -0.2949
   Episode_Reward/foot_landing_vel: -0.1377
   Episode_Reward/test_gait_reward: -0.8882
Metrics/base_velocity/error_vel_xy: 2.1003
Metrics/base_velocity/error_vel_yaw: 1.1254
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 1.07s
                        Total time: 936.88s
                               ETA: 2321.0s

################################################################################
                     [1m Learning iteration 863/3000 [0m                      

                       Computation: 92890 steps/s (collection: 0.934s, learning 0.124s)
               Value function loss: 1.0615
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8633
                     Learning rate: 0.0009
                       Mean reward: 94.13
               Mean episode length: 942.75
       Episode_Reward/keep_balance: 0.9511
     Episode_Reward/rew_lin_vel_xy: 3.9643
      Episode_Reward/rew_ang_vel_z: 2.5477
    Episode_Reward/pen_base_height: -0.3316
      Episode_Reward/pen_lin_vel_z: -0.0583
     Episode_Reward/pen_ang_vel_xy: -0.1687
   Episode_Reward/pen_joint_torque: -0.2173
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.0983
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0475
   Episode_Reward/pen_joint_powers: -0.0759
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2164
Episode_Reward/pen_flat_orientation: -0.1485
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3078
   Episode_Reward/foot_landing_vel: -0.1455
   Episode_Reward/test_gait_reward: -0.8735
Metrics/base_velocity/error_vel_xy: 2.0385
Metrics/base_velocity/error_vel_yaw: 1.1162
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 1.06s
                        Total time: 937.94s
                               ETA: 2319.9s

################################################################################
                     [1m Learning iteration 864/3000 [0m                      

                       Computation: 91760 steps/s (collection: 0.948s, learning 0.124s)
               Value function loss: 1.0152
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8647
                     Learning rate: 0.0013
                       Mean reward: 92.67
               Mean episode length: 943.66
       Episode_Reward/keep_balance: 0.9183
     Episode_Reward/rew_lin_vel_xy: 3.8275
      Episode_Reward/rew_ang_vel_z: 2.3766
    Episode_Reward/pen_base_height: -0.3234
      Episode_Reward/pen_lin_vel_z: -0.0543
     Episode_Reward/pen_ang_vel_xy: -0.1590
   Episode_Reward/pen_joint_torque: -0.2048
    Episode_Reward/pen_joint_accel: -0.1013
    Episode_Reward/pen_action_rate: -0.0957
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0460
   Episode_Reward/pen_joint_powers: -0.0728
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2117
Episode_Reward/pen_flat_orientation: -0.1404
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3037
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.8459
Metrics/base_velocity/error_vel_xy: 2.0172
Metrics/base_velocity/error_vel_yaw: 1.1556
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 1.07s
                        Total time: 939.01s
                               ETA: 2318.8s

################################################################################
                     [1m Learning iteration 865/3000 [0m                      

                       Computation: 91588 steps/s (collection: 0.949s, learning 0.125s)
               Value function loss: 1.0881
                    Surrogate loss: 0.0002
             Mean action noise std: 0.8639
                     Learning rate: 0.0002
                       Mean reward: 99.45
               Mean episode length: 990.86
       Episode_Reward/keep_balance: 0.9773
     Episode_Reward/rew_lin_vel_xy: 4.1148
      Episode_Reward/rew_ang_vel_z: 2.5880
    Episode_Reward/pen_base_height: -0.3352
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1687
   Episode_Reward/pen_joint_torque: -0.2221
    Episode_Reward/pen_joint_accel: -0.1074
    Episode_Reward/pen_action_rate: -0.1012
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0488
   Episode_Reward/pen_joint_powers: -0.0774
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2218
Episode_Reward/pen_flat_orientation: -0.1455
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.3280
   Episode_Reward/foot_landing_vel: -0.1498
   Episode_Reward/test_gait_reward: -0.9026
Metrics/base_velocity/error_vel_xy: 2.0853
Metrics/base_velocity/error_vel_yaw: 1.1702
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 1.07s
                        Total time: 940.09s
                               ETA: 2317.7s

################################################################################
                     [1m Learning iteration 866/3000 [0m                      

                       Computation: 90241 steps/s (collection: 0.963s, learning 0.126s)
               Value function loss: 1.0580
                    Surrogate loss: 0.0030
             Mean action noise std: 0.8636
                     Learning rate: 0.0000
                       Mean reward: 95.57
               Mean episode length: 969.25
       Episode_Reward/keep_balance: 0.9655
     Episode_Reward/rew_lin_vel_xy: 4.0096
      Episode_Reward/rew_ang_vel_z: 2.5123
    Episode_Reward/pen_base_height: -0.3235
      Episode_Reward/pen_lin_vel_z: -0.0565
     Episode_Reward/pen_ang_vel_xy: -0.1639
   Episode_Reward/pen_joint_torque: -0.2208
    Episode_Reward/pen_joint_accel: -0.1082
    Episode_Reward/pen_action_rate: -0.0998
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0485
   Episode_Reward/pen_joint_powers: -0.0774
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2185
Episode_Reward/pen_flat_orientation: -0.1361
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.3187
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.8896
Metrics/base_velocity/error_vel_xy: 2.1022
Metrics/base_velocity/error_vel_yaw: 1.1894
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 1.09s
                        Total time: 941.18s
                               ETA: 2316.6s

################################################################################
                     [1m Learning iteration 867/3000 [0m                      

                       Computation: 91181 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.0297
                    Surrogate loss: 0.0053
             Mean action noise std: 0.8634
                     Learning rate: 0.0000
                       Mean reward: 90.27
               Mean episode length: 933.04
       Episode_Reward/keep_balance: 0.9209
     Episode_Reward/rew_lin_vel_xy: 3.8891
      Episode_Reward/rew_ang_vel_z: 2.4303
    Episode_Reward/pen_base_height: -0.3196
      Episode_Reward/pen_lin_vel_z: -0.0556
     Episode_Reward/pen_ang_vel_xy: -0.1591
   Episode_Reward/pen_joint_torque: -0.2153
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.0954
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0456
   Episode_Reward/pen_joint_powers: -0.0740
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2099
Episode_Reward/pen_flat_orientation: -0.1431
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.2934
   Episode_Reward/foot_landing_vel: -0.1358
   Episode_Reward/test_gait_reward: -0.8460
Metrics/base_velocity/error_vel_xy: 1.9535
Metrics/base_velocity/error_vel_yaw: 1.1041
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 1.08s
                        Total time: 942.26s
                               ETA: 2315.5s

################################################################################
                     [1m Learning iteration 868/3000 [0m                      

                       Computation: 90402 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 1.0555
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8631
                     Learning rate: 0.0002
                       Mean reward: 89.33
               Mean episode length: 939.84
       Episode_Reward/keep_balance: 0.9289
     Episode_Reward/rew_lin_vel_xy: 3.9540
      Episode_Reward/rew_ang_vel_z: 2.4029
    Episode_Reward/pen_base_height: -0.3335
      Episode_Reward/pen_lin_vel_z: -0.0522
     Episode_Reward/pen_ang_vel_xy: -0.1644
   Episode_Reward/pen_joint_torque: -0.2004
    Episode_Reward/pen_joint_accel: -0.1117
    Episode_Reward/pen_action_rate: -0.0970
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0475
   Episode_Reward/pen_joint_powers: -0.0726
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2149
Episode_Reward/pen_flat_orientation: -0.1436
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.3035
   Episode_Reward/foot_landing_vel: -0.1454
   Episode_Reward/test_gait_reward: -0.8634
Metrics/base_velocity/error_vel_xy: 1.9356
Metrics/base_velocity/error_vel_yaw: 1.1634
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 1.09s
                        Total time: 943.34s
                               ETA: 2314.4s

################################################################################
                     [1m Learning iteration 869/3000 [0m                      

                       Computation: 84238 steps/s (collection: 1.043s, learning 0.124s)
               Value function loss: 0.9959
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8636
                     Learning rate: 0.0006
                       Mean reward: 95.26
               Mean episode length: 937.44
       Episode_Reward/keep_balance: 0.9288
     Episode_Reward/rew_lin_vel_xy: 4.0325
      Episode_Reward/rew_ang_vel_z: 2.4391
    Episode_Reward/pen_base_height: -0.3188
      Episode_Reward/pen_lin_vel_z: -0.0504
     Episode_Reward/pen_ang_vel_xy: -0.1642
   Episode_Reward/pen_joint_torque: -0.1994
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.0966
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0445
   Episode_Reward/pen_joint_powers: -0.0704
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2140
Episode_Reward/pen_flat_orientation: -0.1345
  Episode_Reward/pen_feet_distance: -0.0030
Episode_Reward/pen_feet_regulation: -0.2818
   Episode_Reward/foot_landing_vel: -0.1263
   Episode_Reward/test_gait_reward: -0.8575
Metrics/base_velocity/error_vel_xy: 1.8953
Metrics/base_velocity/error_vel_yaw: 1.1266
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 1.17s
                        Total time: 944.51s
                               ETA: 2313.5s

################################################################################
                     [1m Learning iteration 870/3000 [0m                      

                       Computation: 89326 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 1.0885
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8653
                     Learning rate: 0.0006
                       Mean reward: 95.13
               Mean episode length: 962.97
       Episode_Reward/keep_balance: 0.9710
     Episode_Reward/rew_lin_vel_xy: 4.0722
      Episode_Reward/rew_ang_vel_z: 2.5538
    Episode_Reward/pen_base_height: -0.3315
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1650
   Episode_Reward/pen_joint_torque: -0.2170
    Episode_Reward/pen_joint_accel: -0.1104
    Episode_Reward/pen_action_rate: -0.1008
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0479
   Episode_Reward/pen_joint_powers: -0.0757
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2227
Episode_Reward/pen_flat_orientation: -0.1416
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.3138
   Episode_Reward/foot_landing_vel: -0.1451
   Episode_Reward/test_gait_reward: -0.8911
Metrics/base_velocity/error_vel_xy: 2.1305
Metrics/base_velocity/error_vel_yaw: 1.1718
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 1.10s
                        Total time: 945.61s
                               ETA: 2312.5s

################################################################################
                     [1m Learning iteration 871/3000 [0m                      

                       Computation: 89522 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 1.1266
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8672
                     Learning rate: 0.0013
                       Mean reward: 88.48
               Mean episode length: 933.64
       Episode_Reward/keep_balance: 0.9418
     Episode_Reward/rew_lin_vel_xy: 3.8462
      Episode_Reward/rew_ang_vel_z: 2.4748
    Episode_Reward/pen_base_height: -0.3321
      Episode_Reward/pen_lin_vel_z: -0.0535
     Episode_Reward/pen_ang_vel_xy: -0.1663
   Episode_Reward/pen_joint_torque: -0.2072
    Episode_Reward/pen_joint_accel: -0.1050
    Episode_Reward/pen_action_rate: -0.0986
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0470
   Episode_Reward/pen_joint_powers: -0.0742
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2188
Episode_Reward/pen_flat_orientation: -0.1453
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.3031
   Episode_Reward/foot_landing_vel: -0.1425
   Episode_Reward/test_gait_reward: -0.8652
Metrics/base_velocity/error_vel_xy: 2.0954
Metrics/base_velocity/error_vel_yaw: 1.1423
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 1.10s
                        Total time: 946.71s
                               ETA: 2311.4s

################################################################################
                     [1m Learning iteration 872/3000 [0m                      

                       Computation: 91407 steps/s (collection: 0.948s, learning 0.127s)
               Value function loss: 1.0767
                    Surrogate loss: -0.0001
             Mean action noise std: 0.8673
                     Learning rate: 0.0006
                       Mean reward: 94.34
               Mean episode length: 954.23
       Episode_Reward/keep_balance: 0.9610
     Episode_Reward/rew_lin_vel_xy: 4.1316
      Episode_Reward/rew_ang_vel_z: 2.5077
    Episode_Reward/pen_base_height: -0.3442
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1767
   Episode_Reward/pen_joint_torque: -0.2141
    Episode_Reward/pen_joint_accel: -0.1197
    Episode_Reward/pen_action_rate: -0.1009
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0489
   Episode_Reward/pen_joint_powers: -0.0761
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2235
Episode_Reward/pen_flat_orientation: -0.1472
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3060
   Episode_Reward/foot_landing_vel: -0.1475
   Episode_Reward/test_gait_reward: -0.8901
Metrics/base_velocity/error_vel_xy: 2.0670
Metrics/base_velocity/error_vel_yaw: 1.1804
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 1.08s
                        Total time: 947.78s
                               ETA: 2310.3s

################################################################################
                     [1m Learning iteration 873/3000 [0m                      

                       Computation: 90677 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 1.1400
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8677
                     Learning rate: 0.0009
                       Mean reward: 94.31
               Mean episode length: 973.39
       Episode_Reward/keep_balance: 0.9627
     Episode_Reward/rew_lin_vel_xy: 3.9872
      Episode_Reward/rew_ang_vel_z: 2.5276
    Episode_Reward/pen_base_height: -0.3462
      Episode_Reward/pen_lin_vel_z: -0.0589
     Episode_Reward/pen_ang_vel_xy: -0.1634
   Episode_Reward/pen_joint_torque: -0.2348
    Episode_Reward/pen_joint_accel: -0.1078
    Episode_Reward/pen_action_rate: -0.1004
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0495
   Episode_Reward/pen_joint_powers: -0.0800
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2198
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3320
   Episode_Reward/foot_landing_vel: -0.1508
   Episode_Reward/test_gait_reward: -0.8856
Metrics/base_velocity/error_vel_xy: 2.0623
Metrics/base_velocity/error_vel_yaw: 1.1674
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 1.08s
                        Total time: 948.87s
                               ETA: 2309.2s

################################################################################
                     [1m Learning iteration 874/3000 [0m                      

                       Computation: 89758 steps/s (collection: 0.969s, learning 0.126s)
               Value function loss: 1.1377
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8675
                     Learning rate: 0.0009
                       Mean reward: 89.64
               Mean episode length: 941.08
       Episode_Reward/keep_balance: 0.9225
     Episode_Reward/rew_lin_vel_xy: 3.8114
      Episode_Reward/rew_ang_vel_z: 2.4082
    Episode_Reward/pen_base_height: -0.3277
      Episode_Reward/pen_lin_vel_z: -0.0538
     Episode_Reward/pen_ang_vel_xy: -0.1657
   Episode_Reward/pen_joint_torque: -0.2057
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.0969
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0725
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2149
Episode_Reward/pen_flat_orientation: -0.1377
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.2938
   Episode_Reward/foot_landing_vel: -0.1412
   Episode_Reward/test_gait_reward: -0.8488
Metrics/base_velocity/error_vel_xy: 2.0438
Metrics/base_velocity/error_vel_yaw: 1.1344
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 1.10s
                        Total time: 949.96s
                               ETA: 2308.1s

################################################################################
                     [1m Learning iteration 875/3000 [0m                      

                       Computation: 89133 steps/s (collection: 0.978s, learning 0.125s)
               Value function loss: 1.1794
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8674
                     Learning rate: 0.0013
                       Mean reward: 102.53
               Mean episode length: 982.03
       Episode_Reward/keep_balance: 0.9873
     Episode_Reward/rew_lin_vel_xy: 4.4449
      Episode_Reward/rew_ang_vel_z: 2.6346
    Episode_Reward/pen_base_height: -0.3299
      Episode_Reward/pen_lin_vel_z: -0.0540
     Episode_Reward/pen_ang_vel_xy: -0.1655
   Episode_Reward/pen_joint_torque: -0.2172
    Episode_Reward/pen_joint_accel: -0.1086
    Episode_Reward/pen_action_rate: -0.1005
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0467
   Episode_Reward/pen_joint_powers: -0.0756
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2250
Episode_Reward/pen_flat_orientation: -0.1355
  Episode_Reward/pen_feet_distance: -0.0043
Episode_Reward/pen_feet_regulation: -0.2971
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.9034
Metrics/base_velocity/error_vel_xy: 1.9232
Metrics/base_velocity/error_vel_yaw: 1.1589
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 1.10s
                        Total time: 951.07s
                               ETA: 2307.1s

################################################################################
                     [1m Learning iteration 876/3000 [0m                      

                       Computation: 90539 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 1.0322
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8689
                     Learning rate: 0.0006
                       Mean reward: 87.50
               Mean episode length: 900.02
       Episode_Reward/keep_balance: 0.9057
     Episode_Reward/rew_lin_vel_xy: 3.9826
      Episode_Reward/rew_ang_vel_z: 2.3567
    Episode_Reward/pen_base_height: -0.3374
      Episode_Reward/pen_lin_vel_z: -0.0594
     Episode_Reward/pen_ang_vel_xy: -0.1666
   Episode_Reward/pen_joint_torque: -0.2111
    Episode_Reward/pen_joint_accel: -0.1054
    Episode_Reward/pen_action_rate: -0.0963
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0487
   Episode_Reward/pen_joint_powers: -0.0757
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2119
Episode_Reward/pen_flat_orientation: -0.1489
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3238
   Episode_Reward/foot_landing_vel: -0.1451
   Episode_Reward/test_gait_reward: -0.8469
Metrics/base_velocity/error_vel_xy: 1.9173
Metrics/base_velocity/error_vel_yaw: 1.1209
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 1.09s
                        Total time: 952.15s
                               ETA: 2306.0s

################################################################################
                     [1m Learning iteration 877/3000 [0m                      

                       Computation: 90702 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 1.0287
                    Surrogate loss: -0.0011
             Mean action noise std: 0.8698
                     Learning rate: 0.0002
                       Mean reward: 89.24
               Mean episode length: 921.10
       Episode_Reward/keep_balance: 0.8986
     Episode_Reward/rew_lin_vel_xy: 3.8389
      Episode_Reward/rew_ang_vel_z: 2.3267
    Episode_Reward/pen_base_height: -0.3347
      Episode_Reward/pen_lin_vel_z: -0.0528
     Episode_Reward/pen_ang_vel_xy: -0.1626
   Episode_Reward/pen_joint_torque: -0.2046
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.0949
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0466
   Episode_Reward/pen_joint_powers: -0.0731
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2100
Episode_Reward/pen_flat_orientation: -0.1503
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.2903
   Episode_Reward/foot_landing_vel: -0.1338
   Episode_Reward/test_gait_reward: -0.8334
Metrics/base_velocity/error_vel_xy: 1.8241
Metrics/base_velocity/error_vel_yaw: 1.1332
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 1.08s
                        Total time: 953.24s
                               ETA: 2304.9s

################################################################################
                     [1m Learning iteration 878/3000 [0m                      

                       Computation: 90777 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 1.1000
                    Surrogate loss: 0.0005
             Mean action noise std: 0.8702
                     Learning rate: 0.0001
                       Mean reward: 86.18
               Mean episode length: 943.93
       Episode_Reward/keep_balance: 0.9474
     Episode_Reward/rew_lin_vel_xy: 3.7137
      Episode_Reward/rew_ang_vel_z: 2.4089
    Episode_Reward/pen_base_height: -0.3499
      Episode_Reward/pen_lin_vel_z: -0.0571
     Episode_Reward/pen_ang_vel_xy: -0.1741
   Episode_Reward/pen_joint_torque: -0.2173
    Episode_Reward/pen_joint_accel: -0.1028
    Episode_Reward/pen_action_rate: -0.1010
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0489
   Episode_Reward/pen_joint_powers: -0.0776
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2224
Episode_Reward/pen_flat_orientation: -0.1450
  Episode_Reward/pen_feet_distance: -0.0066
Episode_Reward/pen_feet_regulation: -0.3267
   Episode_Reward/foot_landing_vel: -0.1367
   Episode_Reward/test_gait_reward: -0.8851
Metrics/base_velocity/error_vel_xy: 2.1532
Metrics/base_velocity/error_vel_yaw: 1.2181
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 1.08s
                        Total time: 954.32s
                               ETA: 2303.8s

################################################################################
                     [1m Learning iteration 879/3000 [0m                      

                       Computation: 89398 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 0.9895
                    Surrogate loss: 0.0058
             Mean action noise std: 0.8705
                     Learning rate: 0.0000
                       Mean reward: 89.40
               Mean episode length: 934.17
       Episode_Reward/keep_balance: 0.9381
     Episode_Reward/rew_lin_vel_xy: 3.9576
      Episode_Reward/rew_ang_vel_z: 2.4317
    Episode_Reward/pen_base_height: -0.3403
      Episode_Reward/pen_lin_vel_z: -0.0591
     Episode_Reward/pen_ang_vel_xy: -0.1711
   Episode_Reward/pen_joint_torque: -0.2143
    Episode_Reward/pen_joint_accel: -0.1058
    Episode_Reward/pen_action_rate: -0.0996
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0489
   Episode_Reward/pen_joint_powers: -0.0765
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2201
Episode_Reward/pen_flat_orientation: -0.1449
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3233
   Episode_Reward/foot_landing_vel: -0.1495
   Episode_Reward/test_gait_reward: -0.8684
Metrics/base_velocity/error_vel_xy: 2.0386
Metrics/base_velocity/error_vel_yaw: 1.1692
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 1.10s
                        Total time: 955.42s
                               ETA: 2302.8s

################################################################################
                     [1m Learning iteration 880/3000 [0m                      

                       Computation: 89763 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 0.9536
                    Surrogate loss: 0.0026
             Mean action noise std: 0.8705
                     Learning rate: 0.0000
                       Mean reward: 95.21
               Mean episode length: 959.95
       Episode_Reward/keep_balance: 0.9378
     Episode_Reward/rew_lin_vel_xy: 3.9912
      Episode_Reward/rew_ang_vel_z: 2.4522
    Episode_Reward/pen_base_height: -0.3449
      Episode_Reward/pen_lin_vel_z: -0.0550
     Episode_Reward/pen_ang_vel_xy: -0.1656
   Episode_Reward/pen_joint_torque: -0.2102
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.0988
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0477
   Episode_Reward/pen_joint_powers: -0.0750
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2188
Episode_Reward/pen_flat_orientation: -0.1459
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.3169
   Episode_Reward/foot_landing_vel: -0.1428
   Episode_Reward/test_gait_reward: -0.8693
Metrics/base_velocity/error_vel_xy: 2.0389
Metrics/base_velocity/error_vel_yaw: 1.1522
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 1.10s
                        Total time: 956.51s
                               ETA: 2301.7s

################################################################################
                     [1m Learning iteration 881/3000 [0m                      

                       Computation: 89583 steps/s (collection: 0.971s, learning 0.126s)
               Value function loss: 1.0055
                    Surrogate loss: 0.0033
             Mean action noise std: 0.8708
                     Learning rate: 0.0000
                       Mean reward: 103.24
               Mean episode length: 991.94
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 4.4341
      Episode_Reward/rew_ang_vel_z: 2.6439
    Episode_Reward/pen_base_height: -0.3339
      Episode_Reward/pen_lin_vel_z: -0.0570
     Episode_Reward/pen_ang_vel_xy: -0.1675
   Episode_Reward/pen_joint_torque: -0.2234
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1039
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0487
   Episode_Reward/pen_joint_powers: -0.0775
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2324
Episode_Reward/pen_flat_orientation: -0.1341
  Episode_Reward/pen_feet_distance: -0.0051
Episode_Reward/pen_feet_regulation: -0.3221
   Episode_Reward/foot_landing_vel: -0.1524
   Episode_Reward/test_gait_reward: -0.9262
Metrics/base_velocity/error_vel_xy: 1.9992
Metrics/base_velocity/error_vel_yaw: 1.1860
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 1.10s
                        Total time: 957.61s
                               ETA: 2300.7s

################################################################################
                     [1m Learning iteration 882/3000 [0m                      

                       Computation: 89864 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 1.0526
                    Surrogate loss: 0.0026
             Mean action noise std: 0.8707
                     Learning rate: 0.0000
                       Mean reward: 90.56
               Mean episode length: 928.93
       Episode_Reward/keep_balance: 0.9467
     Episode_Reward/rew_lin_vel_xy: 4.0035
      Episode_Reward/rew_ang_vel_z: 2.4864
    Episode_Reward/pen_base_height: -0.3261
      Episode_Reward/pen_lin_vel_z: -0.0538
     Episode_Reward/pen_ang_vel_xy: -0.1620
   Episode_Reward/pen_joint_torque: -0.2146
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.0980
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0470
   Episode_Reward/pen_joint_powers: -0.0748
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2182
Episode_Reward/pen_flat_orientation: -0.1331
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.2939
   Episode_Reward/foot_landing_vel: -0.1460
   Episode_Reward/test_gait_reward: -0.8677
Metrics/base_velocity/error_vel_xy: 2.0671
Metrics/base_velocity/error_vel_yaw: 1.1392
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 1.09s
                        Total time: 958.70s
                               ETA: 2299.6s

################################################################################
                     [1m Learning iteration 883/3000 [0m                      

                       Computation: 90015 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 1.0264
                    Surrogate loss: 0.0011
             Mean action noise std: 0.8702
                     Learning rate: 0.0000
                       Mean reward: 91.11
               Mean episode length: 952.32
       Episode_Reward/keep_balance: 0.9600
     Episode_Reward/rew_lin_vel_xy: 3.9924
      Episode_Reward/rew_ang_vel_z: 2.5022
    Episode_Reward/pen_base_height: -0.3239
      Episode_Reward/pen_lin_vel_z: -0.0567
     Episode_Reward/pen_ang_vel_xy: -0.1697
   Episode_Reward/pen_joint_torque: -0.2208
    Episode_Reward/pen_joint_accel: -0.1142
    Episode_Reward/pen_action_rate: -0.1007
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0488
   Episode_Reward/pen_joint_powers: -0.0780
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2248
Episode_Reward/pen_flat_orientation: -0.1358
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.3182
   Episode_Reward/foot_landing_vel: -0.1462
   Episode_Reward/test_gait_reward: -0.8827
Metrics/base_velocity/error_vel_xy: 2.1106
Metrics/base_velocity/error_vel_yaw: 1.1740
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 1.09s
                        Total time: 959.80s
                               ETA: 2298.5s

################################################################################
                     [1m Learning iteration 884/3000 [0m                      

                       Computation: 88307 steps/s (collection: 0.990s, learning 0.124s)
               Value function loss: 1.1742
                    Surrogate loss: 0.0004
             Mean action noise std: 0.8704
                     Learning rate: 0.0001
                       Mean reward: 97.31
               Mean episode length: 977.03
       Episode_Reward/keep_balance: 0.9755
     Episode_Reward/rew_lin_vel_xy: 4.2663
      Episode_Reward/rew_ang_vel_z: 2.5499
    Episode_Reward/pen_base_height: -0.3496
      Episode_Reward/pen_lin_vel_z: -0.0586
     Episode_Reward/pen_ang_vel_xy: -0.1741
   Episode_Reward/pen_joint_torque: -0.2205
    Episode_Reward/pen_joint_accel: -0.1096
    Episode_Reward/pen_action_rate: -0.1028
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0495
   Episode_Reward/pen_joint_powers: -0.0782
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2297
Episode_Reward/pen_flat_orientation: -0.1362
  Episode_Reward/pen_feet_distance: -0.0061
Episode_Reward/pen_feet_regulation: -0.3290
   Episode_Reward/foot_landing_vel: -0.1473
   Episode_Reward/test_gait_reward: -0.9107
Metrics/base_velocity/error_vel_xy: 2.0587
Metrics/base_velocity/error_vel_yaw: 1.1838
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 1.11s
                        Total time: 960.91s
                               ETA: 2297.5s

################################################################################
                     [1m Learning iteration 885/3000 [0m                      

                       Computation: 88845 steps/s (collection: 0.982s, learning 0.125s)
               Value function loss: 1.0938
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8706
                     Learning rate: 0.0002
                       Mean reward: 95.39
               Mean episode length: 956.09
       Episode_Reward/keep_balance: 0.9513
     Episode_Reward/rew_lin_vel_xy: 4.1797
      Episode_Reward/rew_ang_vel_z: 2.5003
    Episode_Reward/pen_base_height: -0.3371
      Episode_Reward/pen_lin_vel_z: -0.0569
     Episode_Reward/pen_ang_vel_xy: -0.1629
   Episode_Reward/pen_joint_torque: -0.2230
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.0990
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0485
   Episode_Reward/pen_joint_powers: -0.0777
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2194
Episode_Reward/pen_flat_orientation: -0.1406
  Episode_Reward/pen_feet_distance: -0.0069
Episode_Reward/pen_feet_regulation: -0.3124
   Episode_Reward/foot_landing_vel: -0.1495
   Episode_Reward/test_gait_reward: -0.8737
Metrics/base_velocity/error_vel_xy: 1.9690
Metrics/base_velocity/error_vel_yaw: 1.1458
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 1.11s
                        Total time: 962.02s
                               ETA: 2296.5s

################################################################################
                     [1m Learning iteration 886/3000 [0m                      

                       Computation: 91038 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.9168
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8692
                     Learning rate: 0.0004
                       Mean reward: 91.27
               Mean episode length: 926.83
       Episode_Reward/keep_balance: 0.9296
     Episode_Reward/rew_lin_vel_xy: 4.0083
      Episode_Reward/rew_ang_vel_z: 2.4475
    Episode_Reward/pen_base_height: -0.3373
      Episode_Reward/pen_lin_vel_z: -0.0556
     Episode_Reward/pen_ang_vel_xy: -0.1660
   Episode_Reward/pen_joint_torque: -0.2126
    Episode_Reward/pen_joint_accel: -0.0950
    Episode_Reward/pen_action_rate: -0.0982
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0473
   Episode_Reward/pen_joint_powers: -0.0758
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2177
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0072
Episode_Reward/pen_feet_regulation: -0.3162
   Episode_Reward/foot_landing_vel: -0.1467
   Episode_Reward/test_gait_reward: -0.8674
Metrics/base_velocity/error_vel_xy: 1.9747
Metrics/base_velocity/error_vel_yaw: 1.1263
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 1.08s
                        Total time: 963.10s
                               ETA: 2295.4s

################################################################################
                     [1m Learning iteration 887/3000 [0m                      

                       Computation: 90525 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 1.0121
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8694
                     Learning rate: 0.0009
                       Mean reward: 95.54
               Mean episode length: 993.15
       Episode_Reward/keep_balance: 0.9890
     Episode_Reward/rew_lin_vel_xy: 4.1189
      Episode_Reward/rew_ang_vel_z: 2.5624
    Episode_Reward/pen_base_height: -0.3439
      Episode_Reward/pen_lin_vel_z: -0.0586
     Episode_Reward/pen_ang_vel_xy: -0.1760
   Episode_Reward/pen_joint_torque: -0.2212
    Episode_Reward/pen_joint_accel: -0.1159
    Episode_Reward/pen_action_rate: -0.1044
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0507
   Episode_Reward/pen_joint_powers: -0.0795
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2326
Episode_Reward/pen_flat_orientation: -0.1405
  Episode_Reward/pen_feet_distance: -0.0064
Episode_Reward/pen_feet_regulation: -0.3330
   Episode_Reward/foot_landing_vel: -0.1550
   Episode_Reward/test_gait_reward: -0.9165
Metrics/base_velocity/error_vel_xy: 2.1402
Metrics/base_velocity/error_vel_yaw: 1.2266
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 1.09s
                        Total time: 964.18s
                               ETA: 2294.3s

################################################################################
                     [1m Learning iteration 888/3000 [0m                      

                       Computation: 89935 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.9887
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8702
                     Learning rate: 0.0006
                       Mean reward: 90.65
               Mean episode length: 929.90
       Episode_Reward/keep_balance: 0.9314
     Episode_Reward/rew_lin_vel_xy: 4.1079
      Episode_Reward/rew_ang_vel_z: 2.3974
    Episode_Reward/pen_base_height: -0.3417
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.1692
   Episode_Reward/pen_joint_torque: -0.2113
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.0997
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0485
   Episode_Reward/pen_joint_powers: -0.0765
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2219
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3185
   Episode_Reward/foot_landing_vel: -0.1365
   Episode_Reward/test_gait_reward: -0.8764
Metrics/base_velocity/error_vel_xy: 1.8676
Metrics/base_velocity/error_vel_yaw: 1.1721
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 1.09s
                        Total time: 965.27s
                               ETA: 2293.2s

################################################################################
                     [1m Learning iteration 889/3000 [0m                      

                       Computation: 89941 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 1.1406
                    Surrogate loss: -0.0016
             Mean action noise std: 0.8700
                     Learning rate: 0.0006
                       Mean reward: 91.24
               Mean episode length: 936.99
       Episode_Reward/keep_balance: 0.9337
     Episode_Reward/rew_lin_vel_xy: 4.0607
      Episode_Reward/rew_ang_vel_z: 2.4011
    Episode_Reward/pen_base_height: -0.3268
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1702
   Episode_Reward/pen_joint_torque: -0.2048
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.0997
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0498
   Episode_Reward/pen_joint_powers: -0.0768
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2217
Episode_Reward/pen_flat_orientation: -0.1424
  Episode_Reward/pen_feet_distance: -0.0069
Episode_Reward/pen_feet_regulation: -0.3265
   Episode_Reward/foot_landing_vel: -0.1569
   Episode_Reward/test_gait_reward: -0.8658
Metrics/base_velocity/error_vel_xy: 1.9301
Metrics/base_velocity/error_vel_yaw: 1.1763
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 1.09s
                        Total time: 966.37s
                               ETA: 2292.1s

################################################################################
                     [1m Learning iteration 890/3000 [0m                      

                       Computation: 89821 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 1.0048
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8705
                     Learning rate: 0.0009
                       Mean reward: 92.82
               Mean episode length: 943.40
       Episode_Reward/keep_balance: 0.9444
     Episode_Reward/rew_lin_vel_xy: 4.0796
      Episode_Reward/rew_ang_vel_z: 2.4476
    Episode_Reward/pen_base_height: -0.3249
      Episode_Reward/pen_lin_vel_z: -0.0527
     Episode_Reward/pen_ang_vel_xy: -0.1655
   Episode_Reward/pen_joint_torque: -0.2130
    Episode_Reward/pen_joint_accel: -0.0984
    Episode_Reward/pen_action_rate: -0.0992
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0470
   Episode_Reward/pen_joint_powers: -0.0753
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2221
Episode_Reward/pen_flat_orientation: -0.1368
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.3002
   Episode_Reward/foot_landing_vel: -0.1401
   Episode_Reward/test_gait_reward: -0.8732
Metrics/base_velocity/error_vel_xy: 1.9597
Metrics/base_velocity/error_vel_yaw: 1.1689
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 1.09s
                        Total time: 967.46s
                               ETA: 2291.1s

################################################################################
                     [1m Learning iteration 891/3000 [0m                      

                       Computation: 89985 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 1.1229
                    Surrogate loss: -0.0014
             Mean action noise std: 0.8712
                     Learning rate: 0.0006
                       Mean reward: 92.85
               Mean episode length: 973.76
       Episode_Reward/keep_balance: 0.9664
     Episode_Reward/rew_lin_vel_xy: 3.9801
      Episode_Reward/rew_ang_vel_z: 2.5041
    Episode_Reward/pen_base_height: -0.3176
      Episode_Reward/pen_lin_vel_z: -0.0537
     Episode_Reward/pen_ang_vel_xy: -0.1676
   Episode_Reward/pen_joint_torque: -0.2189
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.1027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0491
   Episode_Reward/pen_joint_powers: -0.0778
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2289
Episode_Reward/pen_flat_orientation: -0.1355
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.3072
   Episode_Reward/foot_landing_vel: -0.1490
   Episode_Reward/test_gait_reward: -0.8927
Metrics/base_velocity/error_vel_xy: 2.1084
Metrics/base_velocity/error_vel_yaw: 1.2057
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 1.09s
                        Total time: 968.55s
                               ETA: 2290.0s

################################################################################
                     [1m Learning iteration 892/3000 [0m                      

                       Computation: 91201 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.1769
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8712
                     Learning rate: 0.0006
                       Mean reward: 95.25
               Mean episode length: 951.18
       Episode_Reward/keep_balance: 0.9510
     Episode_Reward/rew_lin_vel_xy: 4.1895
      Episode_Reward/rew_ang_vel_z: 2.4902
    Episode_Reward/pen_base_height: -0.3428
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1697
   Episode_Reward/pen_joint_torque: -0.2096
    Episode_Reward/pen_joint_accel: -0.1006
    Episode_Reward/pen_action_rate: -0.1010
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0486
   Episode_Reward/pen_joint_powers: -0.0760
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2254
Episode_Reward/pen_flat_orientation: -0.1412
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.3182
   Episode_Reward/foot_landing_vel: -0.1497
   Episode_Reward/test_gait_reward: -0.8834
Metrics/base_velocity/error_vel_xy: 1.9553
Metrics/base_velocity/error_vel_yaw: 1.1645
      Episode_Termination/time_out: 4.9167
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 1.08s
                        Total time: 969.63s
                               ETA: 2288.9s

################################################################################
                     [1m Learning iteration 893/3000 [0m                      

                       Computation: 89651 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 1.1250
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8707
                     Learning rate: 0.0013
                       Mean reward: 91.58
               Mean episode length: 964.61
       Episode_Reward/keep_balance: 0.9707
     Episode_Reward/rew_lin_vel_xy: 3.9606
      Episode_Reward/rew_ang_vel_z: 2.5159
    Episode_Reward/pen_base_height: -0.3423
      Episode_Reward/pen_lin_vel_z: -0.0589
     Episode_Reward/pen_ang_vel_xy: -0.1797
   Episode_Reward/pen_joint_torque: -0.2240
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1049
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0518
   Episode_Reward/pen_joint_powers: -0.0815
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2325
Episode_Reward/pen_flat_orientation: -0.1449
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.3374
   Episode_Reward/foot_landing_vel: -0.1568
   Episode_Reward/test_gait_reward: -0.9025
Metrics/base_velocity/error_vel_xy: 2.1951
Metrics/base_velocity/error_vel_yaw: 1.2134
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 1.10s
                        Total time: 970.73s
                               ETA: 2287.8s

################################################################################
                     [1m Learning iteration 894/3000 [0m                      

                       Computation: 90384 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 1.1006
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8701
                     Learning rate: 0.0009
                       Mean reward: 94.31
               Mean episode length: 957.29
       Episode_Reward/keep_balance: 0.9616
     Episode_Reward/rew_lin_vel_xy: 4.2116
      Episode_Reward/rew_ang_vel_z: 2.5083
    Episode_Reward/pen_base_height: -0.3466
      Episode_Reward/pen_lin_vel_z: -0.0537
     Episode_Reward/pen_ang_vel_xy: -0.1693
   Episode_Reward/pen_joint_torque: -0.2144
    Episode_Reward/pen_joint_accel: -0.1116
    Episode_Reward/pen_action_rate: -0.1028
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0495
   Episode_Reward/pen_joint_powers: -0.0775
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2300
Episode_Reward/pen_flat_orientation: -0.1473
  Episode_Reward/pen_feet_distance: -0.0095
Episode_Reward/pen_feet_regulation: -0.3224
   Episode_Reward/foot_landing_vel: -0.1480
   Episode_Reward/test_gait_reward: -0.8985
Metrics/base_velocity/error_vel_xy: 1.9704
Metrics/base_velocity/error_vel_yaw: 1.1787
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 1.09s
                        Total time: 971.82s
                               ETA: 2286.8s

################################################################################
                     [1m Learning iteration 895/3000 [0m                      

                       Computation: 91026 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 1.1892
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8685
                     Learning rate: 0.0019
                       Mean reward: 94.07
               Mean episode length: 950.07
       Episode_Reward/keep_balance: 0.9637
     Episode_Reward/rew_lin_vel_xy: 4.2468
      Episode_Reward/rew_ang_vel_z: 2.4599
    Episode_Reward/pen_base_height: -0.3238
      Episode_Reward/pen_lin_vel_z: -0.0526
     Episode_Reward/pen_ang_vel_xy: -0.1771
   Episode_Reward/pen_joint_torque: -0.2075
    Episode_Reward/pen_joint_accel: -0.1097
    Episode_Reward/pen_action_rate: -0.1045
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0488
   Episode_Reward/pen_joint_powers: -0.0765
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2345
Episode_Reward/pen_flat_orientation: -0.1385
  Episode_Reward/pen_feet_distance: -0.0049
Episode_Reward/pen_feet_regulation: -0.3233
   Episode_Reward/foot_landing_vel: -0.1478
   Episode_Reward/test_gait_reward: -0.8924
Metrics/base_velocity/error_vel_xy: 1.9313
Metrics/base_velocity/error_vel_yaw: 1.2412
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 1.08s
                        Total time: 972.90s
                               ETA: 2285.7s

################################################################################
                     [1m Learning iteration 896/3000 [0m                      

                       Computation: 91615 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 1.2313
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8664
                     Learning rate: 0.0019
                       Mean reward: 96.20
               Mean episode length: 955.16
       Episode_Reward/keep_balance: 0.9702
     Episode_Reward/rew_lin_vel_xy: 4.1514
      Episode_Reward/rew_ang_vel_z: 2.5008
    Episode_Reward/pen_base_height: -0.3275
      Episode_Reward/pen_lin_vel_z: -0.0569
     Episode_Reward/pen_ang_vel_xy: -0.1748
   Episode_Reward/pen_joint_torque: -0.2142
    Episode_Reward/pen_joint_accel: -0.1133
    Episode_Reward/pen_action_rate: -0.1037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0503
   Episode_Reward/pen_joint_powers: -0.0791
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2306
Episode_Reward/pen_flat_orientation: -0.1350
  Episode_Reward/pen_feet_distance: -0.0064
Episode_Reward/pen_feet_regulation: -0.3191
   Episode_Reward/foot_landing_vel: -0.1518
   Episode_Reward/test_gait_reward: -0.9038
Metrics/base_velocity/error_vel_xy: 2.1067
Metrics/base_velocity/error_vel_yaw: 1.2158
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 1.07s
                        Total time: 973.97s
                               ETA: 2284.5s

################################################################################
                     [1m Learning iteration 897/3000 [0m                      

                       Computation: 91363 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 1.2244
                    Surrogate loss: -0.0007
             Mean action noise std: 0.8662
                     Learning rate: 0.0006
                       Mean reward: 95.29
               Mean episode length: 966.52
       Episode_Reward/keep_balance: 0.9689
     Episode_Reward/rew_lin_vel_xy: 4.2641
      Episode_Reward/rew_ang_vel_z: 2.5021
    Episode_Reward/pen_base_height: -0.3453
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1746
   Episode_Reward/pen_joint_torque: -0.2199
    Episode_Reward/pen_joint_accel: -0.1048
    Episode_Reward/pen_action_rate: -0.1037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0505
   Episode_Reward/pen_joint_powers: -0.0798
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2307
Episode_Reward/pen_flat_orientation: -0.1452
  Episode_Reward/pen_feet_distance: -0.0049
Episode_Reward/pen_feet_regulation: -0.3398
   Episode_Reward/foot_landing_vel: -0.1538
   Episode_Reward/test_gait_reward: -0.9113
Metrics/base_velocity/error_vel_xy: 1.9748
Metrics/base_velocity/error_vel_yaw: 1.2093
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 1.08s
                        Total time: 975.05s
                               ETA: 2283.4s

################################################################################
                     [1m Learning iteration 898/3000 [0m                      

                       Computation: 90628 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 1.1184
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8681
                     Learning rate: 0.0013
                       Mean reward: 96.49
               Mean episode length: 957.00
       Episode_Reward/keep_balance: 0.9418
     Episode_Reward/rew_lin_vel_xy: 4.2464
      Episode_Reward/rew_ang_vel_z: 2.4342
    Episode_Reward/pen_base_height: -0.3468
      Episode_Reward/pen_lin_vel_z: -0.0532
     Episode_Reward/pen_ang_vel_xy: -0.1715
   Episode_Reward/pen_joint_torque: -0.2046
    Episode_Reward/pen_joint_accel: -0.1033
    Episode_Reward/pen_action_rate: -0.1013
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0480
   Episode_Reward/pen_joint_powers: -0.0754
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2272
Episode_Reward/pen_flat_orientation: -0.1458
  Episode_Reward/pen_feet_distance: -0.0047
Episode_Reward/pen_feet_regulation: -0.3114
   Episode_Reward/foot_landing_vel: -0.1437
   Episode_Reward/test_gait_reward: -0.8838
Metrics/base_velocity/error_vel_xy: 1.9117
Metrics/base_velocity/error_vel_yaw: 1.1722
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 1.08s
                        Total time: 976.13s
                               ETA: 2282.3s

################################################################################
                     [1m Learning iteration 899/3000 [0m                      

                       Computation: 90827 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 1.0590
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8698
                     Learning rate: 0.0013
                       Mean reward: 101.59
               Mean episode length: 991.95
       Episode_Reward/keep_balance: 0.9681
     Episode_Reward/rew_lin_vel_xy: 4.2936
      Episode_Reward/rew_ang_vel_z: 2.4819
    Episode_Reward/pen_base_height: -0.3281
      Episode_Reward/pen_lin_vel_z: -0.0545
     Episode_Reward/pen_ang_vel_xy: -0.1736
   Episode_Reward/pen_joint_torque: -0.2138
    Episode_Reward/pen_joint_accel: -0.1104
    Episode_Reward/pen_action_rate: -0.1037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0485
   Episode_Reward/pen_joint_powers: -0.0774
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2322
Episode_Reward/pen_flat_orientation: -0.1391
  Episode_Reward/pen_feet_distance: -0.0055
Episode_Reward/pen_feet_regulation: -0.3081
   Episode_Reward/foot_landing_vel: -0.1363
   Episode_Reward/test_gait_reward: -0.9050
Metrics/base_velocity/error_vel_xy: 1.9174
Metrics/base_velocity/error_vel_yaw: 1.2272
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 1.08s
                        Total time: 977.21s
                               ETA: 2281.2s

################################################################################
                     [1m Learning iteration 900/3000 [0m                      

                       Computation: 91253 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 1.1001
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8703
                     Learning rate: 0.0019
                       Mean reward: 94.91
               Mean episode length: 968.43
       Episode_Reward/keep_balance: 0.9790
     Episode_Reward/rew_lin_vel_xy: 4.1904
      Episode_Reward/rew_ang_vel_z: 2.5749
    Episode_Reward/pen_base_height: -0.3218
      Episode_Reward/pen_lin_vel_z: -0.0525
     Episode_Reward/pen_ang_vel_xy: -0.1689
   Episode_Reward/pen_joint_torque: -0.2150
    Episode_Reward/pen_joint_accel: -0.1114
    Episode_Reward/pen_action_rate: -0.1038
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0485
   Episode_Reward/pen_joint_powers: -0.0769
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2328
Episode_Reward/pen_flat_orientation: -0.1376
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.3079
   Episode_Reward/foot_landing_vel: -0.1490
   Episode_Reward/test_gait_reward: -0.9067
Metrics/base_velocity/error_vel_xy: 2.0922
Metrics/base_velocity/error_vel_yaw: 1.1799
      Episode_Termination/time_out: 4.9583
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 1.08s
                        Total time: 978.29s
                               ETA: 2280.1s

################################################################################
                     [1m Learning iteration 901/3000 [0m                      

                       Computation: 91178 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.0693
                    Surrogate loss: 0.0037
             Mean action noise std: 0.8712
                     Learning rate: 0.0001
                       Mean reward: 97.96
               Mean episode length: 958.87
       Episode_Reward/keep_balance: 0.9633
     Episode_Reward/rew_lin_vel_xy: 4.2830
      Episode_Reward/rew_ang_vel_z: 2.5326
    Episode_Reward/pen_base_height: -0.3189
      Episode_Reward/pen_lin_vel_z: -0.0524
     Episode_Reward/pen_ang_vel_xy: -0.1645
   Episode_Reward/pen_joint_torque: -0.2072
    Episode_Reward/pen_joint_accel: -0.1048
    Episode_Reward/pen_action_rate: -0.1018
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0472
   Episode_Reward/pen_joint_powers: -0.0750
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2291
Episode_Reward/pen_flat_orientation: -0.1384
  Episode_Reward/pen_feet_distance: -0.0051
Episode_Reward/pen_feet_regulation: -0.2971
   Episode_Reward/foot_landing_vel: -0.1473
   Episode_Reward/test_gait_reward: -0.8940
Metrics/base_velocity/error_vel_xy: 1.9390
Metrics/base_velocity/error_vel_yaw: 1.1631
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 1.08s
                        Total time: 979.37s
                               ETA: 2279.0s

################################################################################
                     [1m Learning iteration 902/3000 [0m                      

                       Computation: 91922 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.9710
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8706
                     Learning rate: 0.0004
                       Mean reward: 98.28
               Mean episode length: 954.36
       Episode_Reward/keep_balance: 0.9431
     Episode_Reward/rew_lin_vel_xy: 4.2662
      Episode_Reward/rew_ang_vel_z: 2.4509
    Episode_Reward/pen_base_height: -0.3170
      Episode_Reward/pen_lin_vel_z: -0.0516
     Episode_Reward/pen_ang_vel_xy: -0.1740
   Episode_Reward/pen_joint_torque: -0.2003
    Episode_Reward/pen_joint_accel: -0.1083
    Episode_Reward/pen_action_rate: -0.1017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0484
   Episode_Reward/pen_joint_powers: -0.0747
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2277
Episode_Reward/pen_flat_orientation: -0.1308
  Episode_Reward/pen_feet_distance: -0.0048
Episode_Reward/pen_feet_regulation: -0.3059
   Episode_Reward/foot_landing_vel: -0.1425
   Episode_Reward/test_gait_reward: -0.8784
Metrics/base_velocity/error_vel_xy: 1.8826
Metrics/base_velocity/error_vel_yaw: 1.1697
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 1.07s
                        Total time: 980.44s
                               ETA: 2277.9s

################################################################################
                     [1m Learning iteration 903/3000 [0m                      

                       Computation: 90813 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.9713
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8720
                     Learning rate: 0.0009
                       Mean reward: 104.88
               Mean episode length: 988.66
       Episode_Reward/keep_balance: 0.9828
     Episode_Reward/rew_lin_vel_xy: 4.4138
      Episode_Reward/rew_ang_vel_z: 2.5542
    Episode_Reward/pen_base_height: -0.3390
      Episode_Reward/pen_lin_vel_z: -0.0542
     Episode_Reward/pen_ang_vel_xy: -0.1721
   Episode_Reward/pen_joint_torque: -0.2186
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.1051
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0489
   Episode_Reward/pen_joint_powers: -0.0781
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2332
Episode_Reward/pen_flat_orientation: -0.1388
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3130
   Episode_Reward/foot_landing_vel: -0.1412
   Episode_Reward/test_gait_reward: -0.9183
Metrics/base_velocity/error_vel_xy: 1.9116
Metrics/base_velocity/error_vel_yaw: 1.2132
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 1.08s
                        Total time: 981.52s
                               ETA: 2276.8s

################################################################################
                     [1m Learning iteration 904/3000 [0m                      

                       Computation: 90412 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 1.0096
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8744
                     Learning rate: 0.0013
                       Mean reward: 93.98
               Mean episode length: 964.82
       Episode_Reward/keep_balance: 0.9749
     Episode_Reward/rew_lin_vel_xy: 4.1845
      Episode_Reward/rew_ang_vel_z: 2.5343
    Episode_Reward/pen_base_height: -0.3376
      Episode_Reward/pen_lin_vel_z: -0.0546
     Episode_Reward/pen_ang_vel_xy: -0.1788
   Episode_Reward/pen_joint_torque: -0.2109
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1055
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0496
   Episode_Reward/pen_joint_powers: -0.0780
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2358
Episode_Reward/pen_flat_orientation: -0.1445
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3226
   Episode_Reward/foot_landing_vel: -0.1455
   Episode_Reward/test_gait_reward: -0.9123
Metrics/base_velocity/error_vel_xy: 2.1127
Metrics/base_velocity/error_vel_yaw: 1.2121
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 1.09s
                        Total time: 982.61s
                               ETA: 2275.7s

################################################################################
                     [1m Learning iteration 905/3000 [0m                      

                       Computation: 90275 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 1.0226
                    Surrogate loss: -0.0013
             Mean action noise std: 0.8763
                     Learning rate: 0.0006
                       Mean reward: 97.99
               Mean episode length: 956.42
       Episode_Reward/keep_balance: 0.9645
     Episode_Reward/rew_lin_vel_xy: 4.4839
      Episode_Reward/rew_ang_vel_z: 2.5034
    Episode_Reward/pen_base_height: -0.3141
      Episode_Reward/pen_lin_vel_z: -0.0571
     Episode_Reward/pen_ang_vel_xy: -0.1747
   Episode_Reward/pen_joint_torque: -0.2213
    Episode_Reward/pen_joint_accel: -0.1137
    Episode_Reward/pen_action_rate: -0.1049
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0516
   Episode_Reward/pen_joint_powers: -0.0811
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2344
Episode_Reward/pen_flat_orientation: -0.1298
  Episode_Reward/pen_feet_distance: -0.0044
Episode_Reward/pen_feet_regulation: -0.3463
   Episode_Reward/foot_landing_vel: -0.1575
   Episode_Reward/test_gait_reward: -0.9001
Metrics/base_velocity/error_vel_xy: 1.8040
Metrics/base_velocity/error_vel_yaw: 1.1921
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 1.09s
                        Total time: 983.70s
                               ETA: 2274.7s

################################################################################
                     [1m Learning iteration 906/3000 [0m                      

                       Computation: 89822 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 1.0531
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8782
                     Learning rate: 0.0009
                       Mean reward: 88.04
               Mean episode length: 926.83
       Episode_Reward/keep_balance: 0.9177
     Episode_Reward/rew_lin_vel_xy: 3.8510
      Episode_Reward/rew_ang_vel_z: 2.3639
    Episode_Reward/pen_base_height: -0.3265
      Episode_Reward/pen_lin_vel_z: -0.0534
     Episode_Reward/pen_ang_vel_xy: -0.1638
   Episode_Reward/pen_joint_torque: -0.2038
    Episode_Reward/pen_joint_accel: -0.0957
    Episode_Reward/pen_action_rate: -0.0995
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0475
   Episode_Reward/pen_joint_powers: -0.0748
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2231
Episode_Reward/pen_flat_orientation: -0.1456
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3070
   Episode_Reward/foot_landing_vel: -0.1365
   Episode_Reward/test_gait_reward: -0.8510
Metrics/base_velocity/error_vel_xy: 2.0197
Metrics/base_velocity/error_vel_yaw: 1.1652
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 1.09s
                        Total time: 984.79s
                               ETA: 2273.6s

################################################################################
                     [1m Learning iteration 907/3000 [0m                      

                       Computation: 90003 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 1.0817
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8803
                     Learning rate: 0.0013
                       Mean reward: 96.35
               Mean episode length: 943.23
       Episode_Reward/keep_balance: 0.9319
     Episode_Reward/rew_lin_vel_xy: 4.1822
      Episode_Reward/rew_ang_vel_z: 2.4175
    Episode_Reward/pen_base_height: -0.3151
      Episode_Reward/pen_lin_vel_z: -0.0546
     Episode_Reward/pen_ang_vel_xy: -0.1653
   Episode_Reward/pen_joint_torque: -0.2118
    Episode_Reward/pen_joint_accel: -0.1015
    Episode_Reward/pen_action_rate: -0.1008
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0483
   Episode_Reward/pen_joint_powers: -0.0764
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2241
Episode_Reward/pen_flat_orientation: -0.1337
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.3146
   Episode_Reward/foot_landing_vel: -0.1434
   Episode_Reward/test_gait_reward: -0.8683
Metrics/base_velocity/error_vel_xy: 1.8709
Metrics/base_velocity/error_vel_yaw: 1.1589
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 1.09s
                        Total time: 985.88s
                               ETA: 2272.5s

################################################################################
                     [1m Learning iteration 908/3000 [0m                      

                       Computation: 90056 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 1.0396
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8802
                     Learning rate: 0.0006
                       Mean reward: 90.93
               Mean episode length: 913.66
       Episode_Reward/keep_balance: 0.9290
     Episode_Reward/rew_lin_vel_xy: 4.1027
      Episode_Reward/rew_ang_vel_z: 2.3685
    Episode_Reward/pen_base_height: -0.3219
      Episode_Reward/pen_lin_vel_z: -0.0519
     Episode_Reward/pen_ang_vel_xy: -0.1685
   Episode_Reward/pen_joint_torque: -0.2090
    Episode_Reward/pen_joint_accel: -0.1142
    Episode_Reward/pen_action_rate: -0.1023
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0498
   Episode_Reward/pen_joint_powers: -0.0773
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2277
Episode_Reward/pen_flat_orientation: -0.1502
  Episode_Reward/pen_feet_distance: -0.0052
Episode_Reward/pen_feet_regulation: -0.3061
   Episode_Reward/foot_landing_vel: -0.1465
   Episode_Reward/test_gait_reward: -0.8634
Metrics/base_velocity/error_vel_xy: 1.8752
Metrics/base_velocity/error_vel_yaw: 1.2097
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 1.09s
                        Total time: 986.97s
                               ETA: 2271.5s

################################################################################
                     [1m Learning iteration 909/3000 [0m                      

                       Computation: 88239 steps/s (collection: 0.988s, learning 0.126s)
               Value function loss: 1.1727
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8794
                     Learning rate: 0.0013
                       Mean reward: 90.87
               Mean episode length: 929.88
       Episode_Reward/keep_balance: 0.9439
     Episode_Reward/rew_lin_vel_xy: 4.0318
      Episode_Reward/rew_ang_vel_z: 2.4710
    Episode_Reward/pen_base_height: -0.3142
      Episode_Reward/pen_lin_vel_z: -0.0496
     Episode_Reward/pen_ang_vel_xy: -0.1616
   Episode_Reward/pen_joint_torque: -0.2103
    Episode_Reward/pen_joint_accel: -0.1102
    Episode_Reward/pen_action_rate: -0.1014
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0472
   Episode_Reward/pen_joint_powers: -0.0754
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2277
Episode_Reward/pen_flat_orientation: -0.1357
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.2961
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.8757
Metrics/base_velocity/error_vel_xy: 2.0130
Metrics/base_velocity/error_vel_yaw: 1.1500
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 1.11s
                        Total time: 988.09s
                               ETA: 2270.4s

################################################################################
                     [1m Learning iteration 910/3000 [0m                      

                       Computation: 90122 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 1.1509
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8803
                     Learning rate: 0.0019
                       Mean reward: 96.41
               Mean episode length: 932.90
       Episode_Reward/keep_balance: 0.9378
     Episode_Reward/rew_lin_vel_xy: 4.2621
      Episode_Reward/rew_ang_vel_z: 2.4024
    Episode_Reward/pen_base_height: -0.3200
      Episode_Reward/pen_lin_vel_z: -0.0499
     Episode_Reward/pen_ang_vel_xy: -0.1599
   Episode_Reward/pen_joint_torque: -0.1974
    Episode_Reward/pen_joint_accel: -0.1068
    Episode_Reward/pen_action_rate: -0.1016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0469
   Episode_Reward/pen_joint_powers: -0.0733
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2304
Episode_Reward/pen_flat_orientation: -0.1399
  Episode_Reward/pen_feet_distance: -0.0055
Episode_Reward/pen_feet_regulation: -0.3024
   Episode_Reward/foot_landing_vel: -0.1343
   Episode_Reward/test_gait_reward: -0.8795
Metrics/base_velocity/error_vel_xy: 1.8497
Metrics/base_velocity/error_vel_yaw: 1.1936
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 1.09s
                        Total time: 989.18s
                               ETA: 2269.4s

################################################################################
                     [1m Learning iteration 911/3000 [0m                      

                       Computation: 90389 steps/s (collection: 0.957s, learning 0.131s)
               Value function loss: 1.1061
                    Surrogate loss: -0.0000
             Mean action noise std: 0.8811
                     Learning rate: 0.0004
                       Mean reward: 91.79
               Mean episode length: 907.56
       Episode_Reward/keep_balance: 0.9107
     Episode_Reward/rew_lin_vel_xy: 4.0756
      Episode_Reward/rew_ang_vel_z: 2.3535
    Episode_Reward/pen_base_height: -0.3058
      Episode_Reward/pen_lin_vel_z: -0.0472
     Episode_Reward/pen_ang_vel_xy: -0.1663
   Episode_Reward/pen_joint_torque: -0.1918
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.0990
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0461
   Episode_Reward/pen_joint_powers: -0.0717
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2219
Episode_Reward/pen_flat_orientation: -0.1333
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.2941
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.8459
Metrics/base_velocity/error_vel_xy: 1.8269
Metrics/base_velocity/error_vel_yaw: 1.1474
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 1.09s
                        Total time: 990.27s
                               ETA: 2268.3s

################################################################################
                     [1m Learning iteration 912/3000 [0m                      

                       Computation: 89484 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.9990
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8822
                     Learning rate: 0.0009
                       Mean reward: 90.36
               Mean episode length: 940.93
       Episode_Reward/keep_balance: 0.9366
     Episode_Reward/rew_lin_vel_xy: 4.0650
      Episode_Reward/rew_ang_vel_z: 2.3856
    Episode_Reward/pen_base_height: -0.3248
      Episode_Reward/pen_lin_vel_z: -0.0538
     Episode_Reward/pen_ang_vel_xy: -0.1705
   Episode_Reward/pen_joint_torque: -0.2082
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0493
   Episode_Reward/pen_joint_powers: -0.0773
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2335
Episode_Reward/pen_flat_orientation: -0.1418
  Episode_Reward/pen_feet_distance: -0.0058
Episode_Reward/pen_feet_regulation: -0.3150
   Episode_Reward/foot_landing_vel: -0.1396
   Episode_Reward/test_gait_reward: -0.8746
Metrics/base_velocity/error_vel_xy: 1.9622
Metrics/base_velocity/error_vel_yaw: 1.2110
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 1.10s
                        Total time: 991.37s
                               ETA: 2267.2s

################################################################################
                     [1m Learning iteration 913/3000 [0m                      

                       Computation: 90830 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 1.1208
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8831
                     Learning rate: 0.0013
                       Mean reward: 96.67
               Mean episode length: 953.72
       Episode_Reward/keep_balance: 0.9591
     Episode_Reward/rew_lin_vel_xy: 4.3367
      Episode_Reward/rew_ang_vel_z: 2.5116
    Episode_Reward/pen_base_height: -0.3249
      Episode_Reward/pen_lin_vel_z: -0.0545
     Episode_Reward/pen_ang_vel_xy: -0.1737
   Episode_Reward/pen_joint_torque: -0.2167
    Episode_Reward/pen_joint_accel: -0.1185
    Episode_Reward/pen_action_rate: -0.1047
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0505
   Episode_Reward/pen_joint_powers: -0.0794
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.2344
Episode_Reward/pen_flat_orientation: -0.1362
  Episode_Reward/pen_feet_distance: -0.0089
Episode_Reward/pen_feet_regulation: -0.3205
   Episode_Reward/foot_landing_vel: -0.1495
   Episode_Reward/test_gait_reward: -0.8975
Metrics/base_velocity/error_vel_xy: 1.9040
Metrics/base_velocity/error_vel_yaw: 1.1706
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 1.08s
                        Total time: 992.45s
                               ETA: 2266.1s

################################################################################
                     [1m Learning iteration 914/3000 [0m                      

                       Computation: 92407 steps/s (collection: 0.941s, learning 0.123s)
               Value function loss: 1.0317
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8840
                     Learning rate: 0.0006
                       Mean reward: 95.24
               Mean episode length: 951.42
       Episode_Reward/keep_balance: 0.9428
     Episode_Reward/rew_lin_vel_xy: 4.1708
      Episode_Reward/rew_ang_vel_z: 2.4228
    Episode_Reward/pen_base_height: -0.3084
      Episode_Reward/pen_lin_vel_z: -0.0504
     Episode_Reward/pen_ang_vel_xy: -0.1628
   Episode_Reward/pen_joint_torque: -0.2011
    Episode_Reward/pen_joint_accel: -0.1023
    Episode_Reward/pen_action_rate: -0.1017
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0465
   Episode_Reward/pen_joint_powers: -0.0741
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2291
Episode_Reward/pen_flat_orientation: -0.1332
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.2882
   Episode_Reward/foot_landing_vel: -0.1364
   Episode_Reward/test_gait_reward: -0.8716
Metrics/base_velocity/error_vel_xy: 1.9629
Metrics/base_velocity/error_vel_yaw: 1.1947
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 1.06s
                        Total time: 993.51s
                               ETA: 2265.0s

################################################################################
                     [1m Learning iteration 915/3000 [0m                      

                       Computation: 89643 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 1.0357
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8852
                     Learning rate: 0.0013
                       Mean reward: 92.51
               Mean episode length: 957.85
       Episode_Reward/keep_balance: 0.9661
     Episode_Reward/rew_lin_vel_xy: 4.1080
      Episode_Reward/rew_ang_vel_z: 2.5177
    Episode_Reward/pen_base_height: -0.3196
      Episode_Reward/pen_lin_vel_z: -0.0546
     Episode_Reward/pen_ang_vel_xy: -0.1734
   Episode_Reward/pen_joint_torque: -0.2199
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1063
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0502
   Episode_Reward/pen_joint_powers: -0.0792
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2388
Episode_Reward/pen_flat_orientation: -0.1315
  Episode_Reward/pen_feet_distance: -0.0047
Episode_Reward/pen_feet_regulation: -0.3336
   Episode_Reward/foot_landing_vel: -0.1487
   Episode_Reward/test_gait_reward: -0.9010
Metrics/base_velocity/error_vel_xy: 2.1882
Metrics/base_velocity/error_vel_yaw: 1.1927
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 1.10s
                        Total time: 994.61s
                               ETA: 2263.9s

################################################################################
                     [1m Learning iteration 916/3000 [0m                      

                       Computation: 90582 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 1.0755
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8870
                     Learning rate: 0.0009
                       Mean reward: 96.74
               Mean episode length: 945.46
       Episode_Reward/keep_balance: 0.9379
     Episode_Reward/rew_lin_vel_xy: 4.2270
      Episode_Reward/rew_ang_vel_z: 2.4393
    Episode_Reward/pen_base_height: -0.3265
      Episode_Reward/pen_lin_vel_z: -0.0548
     Episode_Reward/pen_ang_vel_xy: -0.1698
   Episode_Reward/pen_joint_torque: -0.2153
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1027
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0487
   Episode_Reward/pen_joint_powers: -0.0779
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2281
Episode_Reward/pen_flat_orientation: -0.1392
  Episode_Reward/pen_feet_distance: -0.0065
Episode_Reward/pen_feet_regulation: -0.3140
   Episode_Reward/foot_landing_vel: -0.1418
   Episode_Reward/test_gait_reward: -0.8811
Metrics/base_velocity/error_vel_xy: 1.9074
Metrics/base_velocity/error_vel_yaw: 1.1651
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 1.09s
                        Total time: 995.69s
                               ETA: 2262.8s

################################################################################
                     [1m Learning iteration 917/3000 [0m                      

                       Computation: 92135 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 1.0275
                    Surrogate loss: -0.0001
             Mean action noise std: 0.8871
                     Learning rate: 0.0003
                       Mean reward: 98.31
               Mean episode length: 961.63
       Episode_Reward/keep_balance: 0.9636
     Episode_Reward/rew_lin_vel_xy: 4.3266
      Episode_Reward/rew_ang_vel_z: 2.4822
    Episode_Reward/pen_base_height: -0.3147
      Episode_Reward/pen_lin_vel_z: -0.0516
     Episode_Reward/pen_ang_vel_xy: -0.1727
   Episode_Reward/pen_joint_torque: -0.2122
    Episode_Reward/pen_joint_accel: -0.1020
    Episode_Reward/pen_action_rate: -0.1058
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0496
   Episode_Reward/pen_joint_powers: -0.0785
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2386
Episode_Reward/pen_flat_orientation: -0.1301
  Episode_Reward/pen_feet_distance: -0.0079
Episode_Reward/pen_feet_regulation: -0.3322
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9004
Metrics/base_velocity/error_vel_xy: 1.8979
Metrics/base_velocity/error_vel_yaw: 1.2145
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 1.07s
                        Total time: 996.76s
                               ETA: 2261.7s

################################################################################
                     [1m Learning iteration 918/3000 [0m                      

                       Computation: 90475 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.9874
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8864
                     Learning rate: 0.0004
                       Mean reward: 98.50
               Mean episode length: 945.59
       Episode_Reward/keep_balance: 0.9512
     Episode_Reward/rew_lin_vel_xy: 4.3387
      Episode_Reward/rew_ang_vel_z: 2.4550
    Episode_Reward/pen_base_height: -0.3177
      Episode_Reward/pen_lin_vel_z: -0.0501
     Episode_Reward/pen_ang_vel_xy: -0.1678
   Episode_Reward/pen_joint_torque: -0.2080
    Episode_Reward/pen_joint_accel: -0.1027
    Episode_Reward/pen_action_rate: -0.1045
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0467
   Episode_Reward/pen_joint_powers: -0.0749
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2348
Episode_Reward/pen_flat_orientation: -0.1398
  Episode_Reward/pen_feet_distance: -0.0042
Episode_Reward/pen_feet_regulation: -0.2915
   Episode_Reward/foot_landing_vel: -0.1340
   Episode_Reward/test_gait_reward: -0.8765
Metrics/base_velocity/error_vel_xy: 1.8498
Metrics/base_velocity/error_vel_yaw: 1.2114
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 1.09s
                        Total time: 997.85s
                               ETA: 2260.6s

################################################################################
                     [1m Learning iteration 919/3000 [0m                      

                       Computation: 88885 steps/s (collection: 0.979s, learning 0.127s)
               Value function loss: 1.1327
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8846
                     Learning rate: 0.0009
                       Mean reward: 94.29
               Mean episode length: 921.09
       Episode_Reward/keep_balance: 0.9126
     Episode_Reward/rew_lin_vel_xy: 4.1678
      Episode_Reward/rew_ang_vel_z: 2.3225
    Episode_Reward/pen_base_height: -0.3214
      Episode_Reward/pen_lin_vel_z: -0.0511
     Episode_Reward/pen_ang_vel_xy: -0.1696
   Episode_Reward/pen_joint_torque: -0.2057
    Episode_Reward/pen_joint_accel: -0.1146
    Episode_Reward/pen_action_rate: -0.1030
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0497
   Episode_Reward/pen_joint_powers: -0.0769
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2293
Episode_Reward/pen_flat_orientation: -0.1398
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3283
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.8631
Metrics/base_velocity/error_vel_xy: 1.7797
Metrics/base_velocity/error_vel_yaw: 1.1740
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 1.11s
                        Total time: 998.95s
                               ETA: 2259.6s

################################################################################
                     [1m Learning iteration 920/3000 [0m                      

                       Computation: 89945 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 1.1591
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8851
                     Learning rate: 0.0003
                       Mean reward: 97.62
               Mean episode length: 964.13
       Episode_Reward/keep_balance: 0.9452
     Episode_Reward/rew_lin_vel_xy: 4.2913
      Episode_Reward/rew_ang_vel_z: 2.3842
    Episode_Reward/pen_base_height: -0.3142
      Episode_Reward/pen_lin_vel_z: -0.0550
     Episode_Reward/pen_ang_vel_xy: -0.1746
   Episode_Reward/pen_joint_torque: -0.2106
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1068
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0508
   Episode_Reward/pen_joint_powers: -0.0787
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2386
Episode_Reward/pen_flat_orientation: -0.1358
  Episode_Reward/pen_feet_distance: -0.0057
Episode_Reward/pen_feet_regulation: -0.3291
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.8947
Metrics/base_velocity/error_vel_xy: 1.8297
Metrics/base_velocity/error_vel_yaw: 1.2387
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 1.09s
                        Total time: 1000.05s
                               ETA: 2258.5s

################################################################################
                     [1m Learning iteration 921/3000 [0m                      

                       Computation: 89061 steps/s (collection: 0.977s, learning 0.126s)
               Value function loss: 0.9576
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8851
                     Learning rate: 0.0002
                       Mean reward: 94.80
               Mean episode length: 944.01
       Episode_Reward/keep_balance: 0.9370
     Episode_Reward/rew_lin_vel_xy: 4.2212
      Episode_Reward/rew_ang_vel_z: 2.4187
    Episode_Reward/pen_base_height: -0.3191
      Episode_Reward/pen_lin_vel_z: -0.0524
     Episode_Reward/pen_ang_vel_xy: -0.1670
   Episode_Reward/pen_joint_torque: -0.2081
    Episode_Reward/pen_joint_accel: -0.0985
    Episode_Reward/pen_action_rate: -0.1037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0476
   Episode_Reward/pen_joint_powers: -0.0759
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2312
Episode_Reward/pen_flat_orientation: -0.1333
  Episode_Reward/pen_feet_distance: -0.0058
Episode_Reward/pen_feet_regulation: -0.3171
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.8767
Metrics/base_velocity/error_vel_xy: 1.8892
Metrics/base_velocity/error_vel_yaw: 1.1788
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 1.10s
                        Total time: 1001.15s
                               ETA: 2257.5s

################################################################################
                     [1m Learning iteration 922/3000 [0m                      

                       Computation: 90150 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 1.0563
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8846
                     Learning rate: 0.0003
                       Mean reward: 94.65
               Mean episode length: 956.28
       Episode_Reward/keep_balance: 0.9553
     Episode_Reward/rew_lin_vel_xy: 4.2653
      Episode_Reward/rew_ang_vel_z: 2.4288
    Episode_Reward/pen_base_height: -0.3221
      Episode_Reward/pen_lin_vel_z: -0.0501
     Episode_Reward/pen_ang_vel_xy: -0.1750
   Episode_Reward/pen_joint_torque: -0.2077
    Episode_Reward/pen_joint_accel: -0.1087
    Episode_Reward/pen_action_rate: -0.1070
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0496
   Episode_Reward/pen_joint_powers: -0.0775
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2414
Episode_Reward/pen_flat_orientation: -0.1325
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3232
   Episode_Reward/foot_landing_vel: -0.1411
   Episode_Reward/test_gait_reward: -0.8984
Metrics/base_velocity/error_vel_xy: 1.9110
Metrics/base_velocity/error_vel_yaw: 1.2324
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 1.09s
                        Total time: 1002.24s
                               ETA: 2256.4s

################################################################################
                     [1m Learning iteration 923/3000 [0m                      

                       Computation: 90083 steps/s (collection: 0.967s, learning 0.125s)
               Value function loss: 1.0273
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8827
                     Learning rate: 0.0006
                       Mean reward: 98.54
               Mean episode length: 926.76
       Episode_Reward/keep_balance: 0.9252
     Episode_Reward/rew_lin_vel_xy: 4.3358
      Episode_Reward/rew_ang_vel_z: 2.3958
    Episode_Reward/pen_base_height: -0.3069
      Episode_Reward/pen_lin_vel_z: -0.0476
     Episode_Reward/pen_ang_vel_xy: -0.1623
   Episode_Reward/pen_joint_torque: -0.2009
    Episode_Reward/pen_joint_accel: -0.1005
    Episode_Reward/pen_action_rate: -0.1016
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0461
   Episode_Reward/pen_joint_powers: -0.0733
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2287
Episode_Reward/pen_flat_orientation: -0.1248
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.2903
   Episode_Reward/foot_landing_vel: -0.1326
   Episode_Reward/test_gait_reward: -0.8580
Metrics/base_velocity/error_vel_xy: 1.7152
Metrics/base_velocity/error_vel_yaw: 1.1568
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 1.09s
                        Total time: 1003.33s
                               ETA: 2255.3s

################################################################################
                     [1m Learning iteration 924/3000 [0m                      

                       Computation: 91521 steps/s (collection: 0.951s, learning 0.123s)
               Value function loss: 1.0559
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8859
                     Learning rate: 0.0013
                       Mean reward: 99.98
               Mean episode length: 948.34
       Episode_Reward/keep_balance: 0.9434
     Episode_Reward/rew_lin_vel_xy: 4.3542
      Episode_Reward/rew_ang_vel_z: 2.4312
    Episode_Reward/pen_base_height: -0.3125
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.1674
   Episode_Reward/pen_joint_torque: -0.2080
    Episode_Reward/pen_joint_accel: -0.1074
    Episode_Reward/pen_action_rate: -0.1045
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0478
   Episode_Reward/pen_joint_powers: -0.0761
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2355
Episode_Reward/pen_flat_orientation: -0.1299
  Episode_Reward/pen_feet_distance: -0.0050
Episode_Reward/pen_feet_regulation: -0.3013
   Episode_Reward/foot_landing_vel: -0.1375
   Episode_Reward/test_gait_reward: -0.8843
Metrics/base_velocity/error_vel_xy: 1.8587
Metrics/base_velocity/error_vel_yaw: 1.1855
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 1.07s
                        Total time: 1004.41s
                               ETA: 2254.2s

################################################################################
                     [1m Learning iteration 925/3000 [0m                      

                       Computation: 90067 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.9384
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8881
                     Learning rate: 0.0009
                       Mean reward: 97.48
               Mean episode length: 937.26
       Episode_Reward/keep_balance: 0.9501
     Episode_Reward/rew_lin_vel_xy: 4.3699
      Episode_Reward/rew_ang_vel_z: 2.4290
    Episode_Reward/pen_base_height: -0.3157
      Episode_Reward/pen_lin_vel_z: -0.0516
     Episode_Reward/pen_ang_vel_xy: -0.1747
   Episode_Reward/pen_joint_torque: -0.2077
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.1069
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0489
   Episode_Reward/pen_joint_powers: -0.0773
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2405
Episode_Reward/pen_flat_orientation: -0.1315
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3137
   Episode_Reward/foot_landing_vel: -0.1399
   Episode_Reward/test_gait_reward: -0.8865
Metrics/base_velocity/error_vel_xy: 1.8343
Metrics/base_velocity/error_vel_yaw: 1.2153
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 1.09s
                        Total time: 1005.50s
                               ETA: 2253.1s

################################################################################
                     [1m Learning iteration 926/3000 [0m                      

                       Computation: 89781 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 1.0881
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8874
                     Learning rate: 0.0013
                       Mean reward: 99.15
               Mean episode length: 950.65
       Episode_Reward/keep_balance: 0.9612
     Episode_Reward/rew_lin_vel_xy: 4.4110
      Episode_Reward/rew_ang_vel_z: 2.5008
    Episode_Reward/pen_base_height: -0.3110
      Episode_Reward/pen_lin_vel_z: -0.0492
     Episode_Reward/pen_ang_vel_xy: -0.1682
   Episode_Reward/pen_joint_torque: -0.2141
    Episode_Reward/pen_joint_accel: -0.0988
    Episode_Reward/pen_action_rate: -0.1048
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0465
   Episode_Reward/pen_joint_powers: -0.0755
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2377
Episode_Reward/pen_flat_orientation: -0.1227
  Episode_Reward/pen_feet_distance: -0.0047
Episode_Reward/pen_feet_regulation: -0.2961
   Episode_Reward/foot_landing_vel: -0.1325
   Episode_Reward/test_gait_reward: -0.8912
Metrics/base_velocity/error_vel_xy: 1.8147
Metrics/base_velocity/error_vel_yaw: 1.1828
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 1.09s
                        Total time: 1006.59s
                               ETA: 2252.1s

################################################################################
                     [1m Learning iteration 927/3000 [0m                      

                       Computation: 91774 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 1.0946
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8882
                     Learning rate: 0.0009
                       Mean reward: 97.14
               Mean episode length: 945.34
       Episode_Reward/keep_balance: 0.9323
     Episode_Reward/rew_lin_vel_xy: 4.1626
      Episode_Reward/rew_ang_vel_z: 2.4040
    Episode_Reward/pen_base_height: -0.3145
      Episode_Reward/pen_lin_vel_z: -0.0511
     Episode_Reward/pen_ang_vel_xy: -0.1662
   Episode_Reward/pen_joint_torque: -0.2057
    Episode_Reward/pen_joint_accel: -0.1019
    Episode_Reward/pen_action_rate: -0.1043
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0492
   Episode_Reward/pen_joint_powers: -0.0768
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2340
Episode_Reward/pen_flat_orientation: -0.1309
  Episode_Reward/pen_feet_distance: -0.0049
Episode_Reward/pen_feet_regulation: -0.3176
   Episode_Reward/foot_landing_vel: -0.1441
   Episode_Reward/test_gait_reward: -0.8699
Metrics/base_velocity/error_vel_xy: 1.9144
Metrics/base_velocity/error_vel_yaw: 1.1732
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 1.07s
                        Total time: 1007.66s
                               ETA: 2251.0s

################################################################################
                     [1m Learning iteration 928/3000 [0m                      

                       Computation: 90506 steps/s (collection: 0.961s, learning 0.125s)
               Value function loss: 1.0790
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8887
                     Learning rate: 0.0019
                       Mean reward: 99.08
               Mean episode length: 955.09
       Episode_Reward/keep_balance: 0.9571
     Episode_Reward/rew_lin_vel_xy: 4.4283
      Episode_Reward/rew_ang_vel_z: 2.4375
    Episode_Reward/pen_base_height: -0.3316
      Episode_Reward/pen_lin_vel_z: -0.0528
     Episode_Reward/pen_ang_vel_xy: -0.1718
   Episode_Reward/pen_joint_torque: -0.2188
    Episode_Reward/pen_joint_accel: -0.1042
    Episode_Reward/pen_action_rate: -0.1084
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0501
   Episode_Reward/pen_joint_powers: -0.0797
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2411
Episode_Reward/pen_flat_orientation: -0.1355
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3311
   Episode_Reward/foot_landing_vel: -0.1377
   Episode_Reward/test_gait_reward: -0.9045
Metrics/base_velocity/error_vel_xy: 1.7758
Metrics/base_velocity/error_vel_yaw: 1.2372
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 1.09s
                        Total time: 1008.75s
                               ETA: 2249.9s

################################################################################
                     [1m Learning iteration 929/3000 [0m                      

                       Computation: 90544 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 1.2060
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8878
                     Learning rate: 0.0019
                       Mean reward: 95.53
               Mean episode length: 960.35
       Episode_Reward/keep_balance: 0.9588
     Episode_Reward/rew_lin_vel_xy: 4.1881
      Episode_Reward/rew_ang_vel_z: 2.4650
    Episode_Reward/pen_base_height: -0.3191
      Episode_Reward/pen_lin_vel_z: -0.0519
     Episode_Reward/pen_ang_vel_xy: -0.1716
   Episode_Reward/pen_joint_torque: -0.2148
    Episode_Reward/pen_joint_accel: -0.1057
    Episode_Reward/pen_action_rate: -0.1072
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0489
   Episode_Reward/pen_joint_powers: -0.0780
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2412
Episode_Reward/pen_flat_orientation: -0.1315
  Episode_Reward/pen_feet_distance: -0.0048
Episode_Reward/pen_feet_regulation: -0.3223
   Episode_Reward/foot_landing_vel: -0.1390
   Episode_Reward/test_gait_reward: -0.8916
Metrics/base_velocity/error_vel_xy: 1.9820
Metrics/base_velocity/error_vel_yaw: 1.2115
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 1.09s
                        Total time: 1009.83s
                               ETA: 2248.8s

################################################################################
                     [1m Learning iteration 930/3000 [0m                      

                       Computation: 90429 steps/s (collection: 0.961s, learning 0.126s)
               Value function loss: 1.1892
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8890
                     Learning rate: 0.0019
                       Mean reward: 94.22
               Mean episode length: 943.01
       Episode_Reward/keep_balance: 0.9445
     Episode_Reward/rew_lin_vel_xy: 4.1555
      Episode_Reward/rew_ang_vel_z: 2.4046
    Episode_Reward/pen_base_height: -0.3051
      Episode_Reward/pen_lin_vel_z: -0.0469
     Episode_Reward/pen_ang_vel_xy: -0.1673
   Episode_Reward/pen_joint_torque: -0.2042
    Episode_Reward/pen_joint_accel: -0.1079
    Episode_Reward/pen_action_rate: -0.1059
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0479
   Episode_Reward/pen_joint_powers: -0.0749
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2414
Episode_Reward/pen_flat_orientation: -0.1302
  Episode_Reward/pen_feet_distance: -0.0061
Episode_Reward/pen_feet_regulation: -0.3008
   Episode_Reward/foot_landing_vel: -0.1315
   Episode_Reward/test_gait_reward: -0.8735
Metrics/base_velocity/error_vel_xy: 1.9281
Metrics/base_velocity/error_vel_yaw: 1.2153
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 1.09s
                        Total time: 1010.92s
                               ETA: 2247.7s

################################################################################
                     [1m Learning iteration 931/3000 [0m                      

                       Computation: 91639 steps/s (collection: 0.946s, learning 0.127s)
               Value function loss: 1.0955
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8895
                     Learning rate: 0.0013
                       Mean reward: 98.93
               Mean episode length: 940.49
       Episode_Reward/keep_balance: 0.9349
     Episode_Reward/rew_lin_vel_xy: 4.2769
      Episode_Reward/rew_ang_vel_z: 2.3889
    Episode_Reward/pen_base_height: -0.3060
      Episode_Reward/pen_lin_vel_z: -0.0496
     Episode_Reward/pen_ang_vel_xy: -0.1623
   Episode_Reward/pen_joint_torque: -0.2021
    Episode_Reward/pen_joint_accel: -0.1017
    Episode_Reward/pen_action_rate: -0.1043
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0473
   Episode_Reward/pen_joint_powers: -0.0740
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2357
Episode_Reward/pen_flat_orientation: -0.1239
  Episode_Reward/pen_feet_distance: -0.0033
Episode_Reward/pen_feet_regulation: -0.3119
   Episode_Reward/foot_landing_vel: -0.1425
   Episode_Reward/test_gait_reward: -0.8718
Metrics/base_velocity/error_vel_xy: 1.7979
Metrics/base_velocity/error_vel_yaw: 1.1893
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 1.07s
                        Total time: 1011.99s
                               ETA: 2246.6s

################################################################################
                     [1m Learning iteration 932/3000 [0m                      

                       Computation: 90448 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 1.0129
                    Surrogate loss: -0.0001
             Mean action noise std: 0.8899
                     Learning rate: 0.0004
                       Mean reward: 99.79
               Mean episode length: 959.40
       Episode_Reward/keep_balance: 0.9658
     Episode_Reward/rew_lin_vel_xy: 4.3614
      Episode_Reward/rew_ang_vel_z: 2.4583
    Episode_Reward/pen_base_height: -0.3043
      Episode_Reward/pen_lin_vel_z: -0.0485
     Episode_Reward/pen_ang_vel_xy: -0.1687
   Episode_Reward/pen_joint_torque: -0.2085
    Episode_Reward/pen_joint_accel: -0.1009
    Episode_Reward/pen_action_rate: -0.1075
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0480
   Episode_Reward/pen_joint_powers: -0.0758
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2444
Episode_Reward/pen_flat_orientation: -0.1168
  Episode_Reward/pen_feet_distance: -0.0052
Episode_Reward/pen_feet_regulation: -0.3036
   Episode_Reward/foot_landing_vel: -0.1415
   Episode_Reward/test_gait_reward: -0.8934
Metrics/base_velocity/error_vel_xy: 1.9597
Metrics/base_velocity/error_vel_yaw: 1.2365
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 1.09s
                        Total time: 1013.08s
                               ETA: 2245.5s

################################################################################
                     [1m Learning iteration 933/3000 [0m                      

                       Computation: 91408 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.9965
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8890
                     Learning rate: 0.0004
                       Mean reward: 93.40
               Mean episode length: 946.75
       Episode_Reward/keep_balance: 0.9416
     Episode_Reward/rew_lin_vel_xy: 4.0766
      Episode_Reward/rew_ang_vel_z: 2.3918
    Episode_Reward/pen_base_height: -0.3063
      Episode_Reward/pen_lin_vel_z: -0.0483
     Episode_Reward/pen_ang_vel_xy: -0.1691
   Episode_Reward/pen_joint_torque: -0.2052
    Episode_Reward/pen_joint_accel: -0.0959
    Episode_Reward/pen_action_rate: -0.1061
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0486
   Episode_Reward/pen_joint_powers: -0.0760
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2393
Episode_Reward/pen_flat_orientation: -0.1245
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.3148
   Episode_Reward/foot_landing_vel: -0.1401
   Episode_Reward/test_gait_reward: -0.8750
Metrics/base_velocity/error_vel_xy: 1.9073
Metrics/base_velocity/error_vel_yaw: 1.2165
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 1.08s
                        Total time: 1014.16s
                               ETA: 2244.4s

################################################################################
                     [1m Learning iteration 934/3000 [0m                      

                       Computation: 93364 steps/s (collection: 0.929s, learning 0.124s)
               Value function loss: 0.9723
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8884
                     Learning rate: 0.0006
                       Mean reward: 99.67
               Mean episode length: 947.64
       Episode_Reward/keep_balance: 0.9305
     Episode_Reward/rew_lin_vel_xy: 4.2034
      Episode_Reward/rew_ang_vel_z: 2.4208
    Episode_Reward/pen_base_height: -0.3147
      Episode_Reward/pen_lin_vel_z: -0.0517
     Episode_Reward/pen_ang_vel_xy: -0.1644
   Episode_Reward/pen_joint_torque: -0.2094
    Episode_Reward/pen_joint_accel: -0.0943
    Episode_Reward/pen_action_rate: -0.1040
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0476
   Episode_Reward/pen_joint_powers: -0.0755
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2329
Episode_Reward/pen_flat_orientation: -0.1273
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.3133
   Episode_Reward/foot_landing_vel: -0.1373
   Episode_Reward/test_gait_reward: -0.8672
Metrics/base_velocity/error_vel_xy: 1.7847
Metrics/base_velocity/error_vel_yaw: 1.1546
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 1.05s
                        Total time: 1015.21s
                               ETA: 2243.2s

################################################################################
                     [1m Learning iteration 935/3000 [0m                      

                       Computation: 90472 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 1.0259
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8881
                     Learning rate: 0.0006
                       Mean reward: 92.43
               Mean episode length: 936.80
       Episode_Reward/keep_balance: 0.9310
     Episode_Reward/rew_lin_vel_xy: 4.0790
      Episode_Reward/rew_ang_vel_z: 2.3837
    Episode_Reward/pen_base_height: -0.3238
      Episode_Reward/pen_lin_vel_z: -0.0494
     Episode_Reward/pen_ang_vel_xy: -0.1725
   Episode_Reward/pen_joint_torque: -0.2103
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1058
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0491
   Episode_Reward/pen_joint_powers: -0.0774
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2370
Episode_Reward/pen_flat_orientation: -0.1283
  Episode_Reward/pen_feet_distance: -0.0069
Episode_Reward/pen_feet_regulation: -0.3177
   Episode_Reward/foot_landing_vel: -0.1421
   Episode_Reward/test_gait_reward: -0.8744
Metrics/base_velocity/error_vel_xy: 1.8456
Metrics/base_velocity/error_vel_yaw: 1.1891
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 1.09s
                        Total time: 1016.30s
                               ETA: 2242.1s

################################################################################
                     [1m Learning iteration 936/3000 [0m                      

                       Computation: 91460 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 1.1047
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8889
                     Learning rate: 0.0009
                       Mean reward: 94.55
               Mean episode length: 958.14
       Episode_Reward/keep_balance: 0.9586
     Episode_Reward/rew_lin_vel_xy: 4.1969
      Episode_Reward/rew_ang_vel_z: 2.4041
    Episode_Reward/pen_base_height: -0.3215
      Episode_Reward/pen_lin_vel_z: -0.0496
     Episode_Reward/pen_ang_vel_xy: -0.1798
   Episode_Reward/pen_joint_torque: -0.2129
    Episode_Reward/pen_joint_accel: -0.1104
    Episode_Reward/pen_action_rate: -0.1115
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0523
   Episode_Reward/pen_joint_powers: -0.0802
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2511
Episode_Reward/pen_flat_orientation: -0.1330
  Episode_Reward/pen_feet_distance: -0.0038
Episode_Reward/pen_feet_regulation: -0.3480
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.9032
Metrics/base_velocity/error_vel_xy: 1.9446
Metrics/base_velocity/error_vel_yaw: 1.2717
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 1.07s
                        Total time: 1017.37s
                               ETA: 2241.0s

################################################################################
                     [1m Learning iteration 937/3000 [0m                      

                       Computation: 90406 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 1.0904
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8880
                     Learning rate: 0.0004
                       Mean reward: 91.72
               Mean episode length: 919.75
       Episode_Reward/keep_balance: 0.9366
     Episode_Reward/rew_lin_vel_xy: 4.2971
      Episode_Reward/rew_ang_vel_z: 2.3491
    Episode_Reward/pen_base_height: -0.3137
      Episode_Reward/pen_lin_vel_z: -0.0464
     Episode_Reward/pen_ang_vel_xy: -0.1713
   Episode_Reward/pen_joint_torque: -0.2031
    Episode_Reward/pen_joint_accel: -0.1021
    Episode_Reward/pen_action_rate: -0.1071
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0484
   Episode_Reward/pen_joint_powers: -0.0759
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2414
Episode_Reward/pen_flat_orientation: -0.1293
  Episode_Reward/pen_feet_distance: -0.0069
Episode_Reward/pen_feet_regulation: -0.3128
   Episode_Reward/foot_landing_vel: -0.1354
   Episode_Reward/test_gait_reward: -0.8767
Metrics/base_velocity/error_vel_xy: 1.7489
Metrics/base_velocity/error_vel_yaw: 1.2413
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 1.09s
                        Total time: 1018.46s
                               ETA: 2240.0s

################################################################################
                     [1m Learning iteration 938/3000 [0m                      

                       Computation: 92126 steps/s (collection: 0.943s, learning 0.124s)
               Value function loss: 1.0846
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8885
                     Learning rate: 0.0009
                       Mean reward: 96.94
               Mean episode length: 950.29
       Episode_Reward/keep_balance: 0.9436
     Episode_Reward/rew_lin_vel_xy: 4.2710
      Episode_Reward/rew_ang_vel_z: 2.3991
    Episode_Reward/pen_base_height: -0.3188
      Episode_Reward/pen_lin_vel_z: -0.0487
     Episode_Reward/pen_ang_vel_xy: -0.1689
   Episode_Reward/pen_joint_torque: -0.2132
    Episode_Reward/pen_joint_accel: -0.1048
    Episode_Reward/pen_action_rate: -0.1073
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0497
   Episode_Reward/pen_joint_powers: -0.0787
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2397
Episode_Reward/pen_flat_orientation: -0.1310
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3157
   Episode_Reward/foot_landing_vel: -0.1428
   Episode_Reward/test_gait_reward: -0.8892
Metrics/base_velocity/error_vel_xy: 1.8599
Metrics/base_velocity/error_vel_yaw: 1.2227
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 1.07s
                        Total time: 1019.53s
                               ETA: 2238.8s

################################################################################
                     [1m Learning iteration 939/3000 [0m                      

                       Computation: 91852 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.0107
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8885
                     Learning rate: 0.0009
                       Mean reward: 96.75
               Mean episode length: 956.55
       Episode_Reward/keep_balance: 0.9651
     Episode_Reward/rew_lin_vel_xy: 4.3017
      Episode_Reward/rew_ang_vel_z: 2.4094
    Episode_Reward/pen_base_height: -0.3285
      Episode_Reward/pen_lin_vel_z: -0.0470
     Episode_Reward/pen_ang_vel_xy: -0.1782
   Episode_Reward/pen_joint_torque: -0.2090
    Episode_Reward/pen_joint_accel: -0.0969
    Episode_Reward/pen_action_rate: -0.1116
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0501
   Episode_Reward/pen_joint_powers: -0.0786
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2520
Episode_Reward/pen_flat_orientation: -0.1274
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3263
   Episode_Reward/foot_landing_vel: -0.1406
   Episode_Reward/test_gait_reward: -0.9112
Metrics/base_velocity/error_vel_xy: 1.8597
Metrics/base_velocity/error_vel_yaw: 1.2843
      Episode_Termination/time_out: 3.0000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 1.07s
                        Total time: 1020.60s
                               ETA: 2237.7s

################################################################################
                     [1m Learning iteration 940/3000 [0m                      

                       Computation: 91643 steps/s (collection: 0.948s, learning 0.125s)
               Value function loss: 0.9585
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8870
                     Learning rate: 0.0009
                       Mean reward: 97.69
               Mean episode length: 973.17
       Episode_Reward/keep_balance: 0.9737
     Episode_Reward/rew_lin_vel_xy: 4.3491
      Episode_Reward/rew_ang_vel_z: 2.4701
    Episode_Reward/pen_base_height: -0.3265
      Episode_Reward/pen_lin_vel_z: -0.0506
     Episode_Reward/pen_ang_vel_xy: -0.1766
   Episode_Reward/pen_joint_torque: -0.2158
    Episode_Reward/pen_joint_accel: -0.1114
    Episode_Reward/pen_action_rate: -0.1113
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0506
   Episode_Reward/pen_joint_powers: -0.0790
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2495
Episode_Reward/pen_flat_orientation: -0.1303
  Episode_Reward/pen_feet_distance: -0.0082
Episode_Reward/pen_feet_regulation: -0.3325
   Episode_Reward/foot_landing_vel: -0.1409
   Episode_Reward/test_gait_reward: -0.9114
Metrics/base_velocity/error_vel_xy: 1.9457
Metrics/base_velocity/error_vel_yaw: 1.2643
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 1.07s
                        Total time: 1021.67s
                               ETA: 2236.6s

################################################################################
                     [1m Learning iteration 941/3000 [0m                      

                       Computation: 90053 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 1.0708
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8876
                     Learning rate: 0.0013
                       Mean reward: 103.99
               Mean episode length: 978.20
       Episode_Reward/keep_balance: 0.9824
     Episode_Reward/rew_lin_vel_xy: 4.5338
      Episode_Reward/rew_ang_vel_z: 2.5204
    Episode_Reward/pen_base_height: -0.3274
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.1773
   Episode_Reward/pen_joint_torque: -0.2096
    Episode_Reward/pen_joint_accel: -0.1058
    Episode_Reward/pen_action_rate: -0.1117
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0498
   Episode_Reward/pen_joint_powers: -0.0780
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2506
Episode_Reward/pen_flat_orientation: -0.1246
  Episode_Reward/pen_feet_distance: -0.0079
Episode_Reward/pen_feet_regulation: -0.3258
   Episode_Reward/foot_landing_vel: -0.1400
   Episode_Reward/test_gait_reward: -0.9249
Metrics/base_velocity/error_vel_xy: 1.7771
Metrics/base_velocity/error_vel_yaw: 1.2438
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 1.09s
                        Total time: 1022.76s
                               ETA: 2235.5s

################################################################################
                     [1m Learning iteration 942/3000 [0m                      

                       Computation: 92627 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 1.1317
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8885
                     Learning rate: 0.0004
                       Mean reward: 101.27
               Mean episode length: 952.24
       Episode_Reward/keep_balance: 0.9557
     Episode_Reward/rew_lin_vel_xy: 4.4702
      Episode_Reward/rew_ang_vel_z: 2.4564
    Episode_Reward/pen_base_height: -0.3167
      Episode_Reward/pen_lin_vel_z: -0.0486
     Episode_Reward/pen_ang_vel_xy: -0.1716
   Episode_Reward/pen_joint_torque: -0.2097
    Episode_Reward/pen_joint_accel: -0.1135
    Episode_Reward/pen_action_rate: -0.1074
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0481
   Episode_Reward/pen_joint_powers: -0.0762
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2432
Episode_Reward/pen_flat_orientation: -0.1224
  Episode_Reward/pen_feet_distance: -0.0045
Episode_Reward/pen_feet_regulation: -0.3042
   Episode_Reward/foot_landing_vel: -0.1370
   Episode_Reward/test_gait_reward: -0.8935
Metrics/base_velocity/error_vel_xy: 1.7817
Metrics/base_velocity/error_vel_yaw: 1.2105
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 1.06s
                        Total time: 1023.82s
                               ETA: 2234.4s

################################################################################
                     [1m Learning iteration 943/3000 [0m                      

                       Computation: 89916 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 1.0256
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8890
                     Learning rate: 0.0009
                       Mean reward: 99.45
               Mean episode length: 960.43
       Episode_Reward/keep_balance: 0.9572
     Episode_Reward/rew_lin_vel_xy: 4.3720
      Episode_Reward/rew_ang_vel_z: 2.4401
    Episode_Reward/pen_base_height: -0.3392
      Episode_Reward/pen_lin_vel_z: -0.0497
     Episode_Reward/pen_ang_vel_xy: -0.1749
   Episode_Reward/pen_joint_torque: -0.2117
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1101
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0501
   Episode_Reward/pen_joint_powers: -0.0787
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2461
Episode_Reward/pen_flat_orientation: -0.1301
  Episode_Reward/pen_feet_distance: -0.0086
Episode_Reward/pen_feet_regulation: -0.3289
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.9040
Metrics/base_velocity/error_vel_xy: 1.7846
Metrics/base_velocity/error_vel_yaw: 1.2289
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 1.09s
                        Total time: 1024.91s
                               ETA: 2233.3s

################################################################################
                     [1m Learning iteration 944/3000 [0m                      

                       Computation: 89594 steps/s (collection: 0.970s, learning 0.127s)
               Value function loss: 0.9544
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8882
                     Learning rate: 0.0009
                       Mean reward: 101.25
               Mean episode length: 981.33
       Episode_Reward/keep_balance: 0.9822
     Episode_Reward/rew_lin_vel_xy: 4.5130
      Episode_Reward/rew_ang_vel_z: 2.5095
    Episode_Reward/pen_base_height: -0.3248
      Episode_Reward/pen_lin_vel_z: -0.0497
     Episode_Reward/pen_ang_vel_xy: -0.1835
   Episode_Reward/pen_joint_torque: -0.2124
    Episode_Reward/pen_joint_accel: -0.1001
    Episode_Reward/pen_action_rate: -0.1133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0498
   Episode_Reward/pen_joint_powers: -0.0779
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2531
Episode_Reward/pen_flat_orientation: -0.1212
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.3204
   Episode_Reward/foot_landing_vel: -0.1395
   Episode_Reward/test_gait_reward: -0.9220
Metrics/base_velocity/error_vel_xy: 1.9317
Metrics/base_velocity/error_vel_yaw: 1.2602
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 1.10s
                        Total time: 1026.01s
                               ETA: 2232.3s

################################################################################
                     [1m Learning iteration 945/3000 [0m                      

                       Computation: 91054 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 1.1632
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8878
                     Learning rate: 0.0009
                       Mean reward: 96.64
               Mean episode length: 961.35
       Episode_Reward/keep_balance: 0.9589
     Episode_Reward/rew_lin_vel_xy: 4.3418
      Episode_Reward/rew_ang_vel_z: 2.4439
    Episode_Reward/pen_base_height: -0.3465
      Episode_Reward/pen_lin_vel_z: -0.0538
     Episode_Reward/pen_ang_vel_xy: -0.1802
   Episode_Reward/pen_joint_torque: -0.2143
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1117
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0519
   Episode_Reward/pen_joint_powers: -0.0803
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2475
Episode_Reward/pen_flat_orientation: -0.1355
  Episode_Reward/pen_feet_distance: -0.0052
Episode_Reward/pen_feet_regulation: -0.3446
   Episode_Reward/foot_landing_vel: -0.1463
   Episode_Reward/test_gait_reward: -0.9056
Metrics/base_velocity/error_vel_xy: 1.8328
Metrics/base_velocity/error_vel_yaw: 1.2405
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 1.08s
                        Total time: 1027.09s
                               ETA: 2231.2s

################################################################################
                     [1m Learning iteration 946/3000 [0m                      

                       Computation: 90987 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 1.0488
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8874
                     Learning rate: 0.0009
                       Mean reward: 92.82
               Mean episode length: 938.18
       Episode_Reward/keep_balance: 0.9378
     Episode_Reward/rew_lin_vel_xy: 4.0779
      Episode_Reward/rew_ang_vel_z: 2.4092
    Episode_Reward/pen_base_height: -0.3187
      Episode_Reward/pen_lin_vel_z: -0.0512
     Episode_Reward/pen_ang_vel_xy: -0.1750
   Episode_Reward/pen_joint_torque: -0.2146
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1073
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0490
   Episode_Reward/pen_joint_powers: -0.0779
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2398
Episode_Reward/pen_flat_orientation: -0.1232
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3193
   Episode_Reward/foot_landing_vel: -0.1439
   Episode_Reward/test_gait_reward: -0.8715
Metrics/base_velocity/error_vel_xy: 2.0034
Metrics/base_velocity/error_vel_yaw: 1.1877
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 1.08s
                        Total time: 1028.17s
                               ETA: 2230.1s

################################################################################
                     [1m Learning iteration 947/3000 [0m                      

                       Computation: 85758 steps/s (collection: 1.024s, learning 0.123s)
               Value function loss: 1.0432
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8893
                     Learning rate: 0.0009
                       Mean reward: 97.90
               Mean episode length: 949.45
       Episode_Reward/keep_balance: 0.9546
     Episode_Reward/rew_lin_vel_xy: 4.4655
      Episode_Reward/rew_ang_vel_z: 2.4003
    Episode_Reward/pen_base_height: -0.3272
      Episode_Reward/pen_lin_vel_z: -0.0493
     Episode_Reward/pen_ang_vel_xy: -0.1757
   Episode_Reward/pen_joint_torque: -0.2055
    Episode_Reward/pen_joint_accel: -0.1044
    Episode_Reward/pen_action_rate: -0.1097
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0500
   Episode_Reward/pen_joint_powers: -0.0775
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2484
Episode_Reward/pen_flat_orientation: -0.1297
  Episode_Reward/pen_feet_distance: -0.0051
Episode_Reward/pen_feet_regulation: -0.3238
   Episode_Reward/foot_landing_vel: -0.1478
   Episode_Reward/test_gait_reward: -0.8975
Metrics/base_velocity/error_vel_xy: 1.7272
Metrics/base_velocity/error_vel_yaw: 1.2669
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 1.15s
                        Total time: 1029.32s
                               ETA: 2229.1s

################################################################################
                     [1m Learning iteration 948/3000 [0m                      

                       Computation: 91275 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.9925
                    Surrogate loss: -0.0007
             Mean action noise std: 0.8921
                     Learning rate: 0.0004
                       Mean reward: 104.14
               Mean episode length: 983.12
       Episode_Reward/keep_balance: 0.9840
     Episode_Reward/rew_lin_vel_xy: 4.6223
      Episode_Reward/rew_ang_vel_z: 2.5221
    Episode_Reward/pen_base_height: -0.3186
      Episode_Reward/pen_lin_vel_z: -0.0511
     Episode_Reward/pen_ang_vel_xy: -0.1759
   Episode_Reward/pen_joint_torque: -0.2186
    Episode_Reward/pen_joint_accel: -0.1092
    Episode_Reward/pen_action_rate: -0.1123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0502
   Episode_Reward/pen_joint_powers: -0.0791
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2531
Episode_Reward/pen_flat_orientation: -0.1231
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3187
   Episode_Reward/foot_landing_vel: -0.1431
   Episode_Reward/test_gait_reward: -0.9244
Metrics/base_velocity/error_vel_xy: 1.8301
Metrics/base_velocity/error_vel_yaw: 1.2465
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 1.08s
                        Total time: 1030.40s
                               ETA: 2228.0s

################################################################################
                     [1m Learning iteration 949/3000 [0m                      

                       Computation: 89561 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.9912
                    Surrogate loss: -0.0056
             Mean action noise std: 0.8918
                     Learning rate: 0.0006
                       Mean reward: 100.25
               Mean episode length: 983.21
       Episode_Reward/keep_balance: 0.9814
     Episode_Reward/rew_lin_vel_xy: 4.5052
      Episode_Reward/rew_ang_vel_z: 2.4913
    Episode_Reward/pen_base_height: -0.3397
      Episode_Reward/pen_lin_vel_z: -0.0523
     Episode_Reward/pen_ang_vel_xy: -0.1769
   Episode_Reward/pen_joint_torque: -0.2240
    Episode_Reward/pen_joint_accel: -0.1090
    Episode_Reward/pen_action_rate: -0.1129
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0518
   Episode_Reward/pen_joint_powers: -0.0815
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2507
Episode_Reward/pen_flat_orientation: -0.1337
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3437
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.9282
Metrics/base_velocity/error_vel_xy: 1.9109
Metrics/base_velocity/error_vel_yaw: 1.2710
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 1.10s
                        Total time: 1031.49s
                               ETA: 2226.9s

################################################################################
                     [1m Learning iteration 950/3000 [0m                      

                       Computation: 91040 steps/s (collection: 0.953s, learning 0.127s)
               Value function loss: 0.9284
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8901
                     Learning rate: 0.0013
                       Mean reward: 105.18
               Mean episode length: 974.66
       Episode_Reward/keep_balance: 0.9812
     Episode_Reward/rew_lin_vel_xy: 4.7657
      Episode_Reward/rew_ang_vel_z: 2.5468
    Episode_Reward/pen_base_height: -0.3213
      Episode_Reward/pen_lin_vel_z: -0.0554
     Episode_Reward/pen_ang_vel_xy: -0.1704
   Episode_Reward/pen_joint_torque: -0.2262
    Episode_Reward/pen_joint_accel: -0.1136
    Episode_Reward/pen_action_rate: -0.1103
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0507
   Episode_Reward/pen_joint_powers: -0.0807
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2475
Episode_Reward/pen_flat_orientation: -0.1239
  Episode_Reward/pen_feet_distance: -0.0050
Episode_Reward/pen_feet_regulation: -0.3283
   Episode_Reward/foot_landing_vel: -0.1531
   Episode_Reward/test_gait_reward: -0.9121
Metrics/base_velocity/error_vel_xy: 1.7509
Metrics/base_velocity/error_vel_yaw: 1.2185
      Episode_Termination/time_out: 3.2500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 1.08s
                        Total time: 1032.57s
                               ETA: 2225.8s

################################################################################
                     [1m Learning iteration 951/3000 [0m                      

                       Computation: 90912 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 0.9423
                    Surrogate loss: 0.0011
             Mean action noise std: 0.8913
                     Learning rate: 0.0004
                       Mean reward: 104.08
               Mean episode length: 981.83
       Episode_Reward/keep_balance: 0.9877
     Episode_Reward/rew_lin_vel_xy: 4.5619
      Episode_Reward/rew_ang_vel_z: 2.5399
    Episode_Reward/pen_base_height: -0.3254
      Episode_Reward/pen_lin_vel_z: -0.0508
     Episode_Reward/pen_ang_vel_xy: -0.1766
   Episode_Reward/pen_joint_torque: -0.2142
    Episode_Reward/pen_joint_accel: -0.1158
    Episode_Reward/pen_action_rate: -0.1117
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0504
   Episode_Reward/pen_joint_powers: -0.0786
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2533
Episode_Reward/pen_flat_orientation: -0.1278
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3192
   Episode_Reward/foot_landing_vel: -0.1480
   Episode_Reward/test_gait_reward: -0.9223
Metrics/base_velocity/error_vel_xy: 1.9011
Metrics/base_velocity/error_vel_yaw: 1.2484
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 1.08s
                        Total time: 1033.65s
                               ETA: 2224.7s

################################################################################
                     [1m Learning iteration 952/3000 [0m                      

                       Computation: 88617 steps/s (collection: 0.983s, learning 0.127s)
               Value function loss: 1.0824
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8919
                     Learning rate: 0.0009
                       Mean reward: 101.82
               Mean episode length: 981.26
       Episode_Reward/keep_balance: 0.9712
     Episode_Reward/rew_lin_vel_xy: 4.5281
      Episode_Reward/rew_ang_vel_z: 2.4271
    Episode_Reward/pen_base_height: -0.3326
      Episode_Reward/pen_lin_vel_z: -0.0520
     Episode_Reward/pen_ang_vel_xy: -0.1742
   Episode_Reward/pen_joint_torque: -0.2133
    Episode_Reward/pen_joint_accel: -0.1174
    Episode_Reward/pen_action_rate: -0.1120
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0505
   Episode_Reward/pen_joint_powers: -0.0790
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2533
Episode_Reward/pen_flat_orientation: -0.1278
  Episode_Reward/pen_feet_distance: -0.0058
Episode_Reward/pen_feet_regulation: -0.3402
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.9142
Metrics/base_velocity/error_vel_xy: 1.8185
Metrics/base_velocity/error_vel_yaw: 1.2941
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 1.11s
                        Total time: 1034.76s
                               ETA: 2223.7s

################################################################################
                     [1m Learning iteration 953/3000 [0m                      

                       Computation: 90427 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 1.1208
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8923
                     Learning rate: 0.0006
                       Mean reward: 96.95
               Mean episode length: 948.14
       Episode_Reward/keep_balance: 0.9548
     Episode_Reward/rew_lin_vel_xy: 4.3482
      Episode_Reward/rew_ang_vel_z: 2.4452
    Episode_Reward/pen_base_height: -0.3455
      Episode_Reward/pen_lin_vel_z: -0.0522
     Episode_Reward/pen_ang_vel_xy: -0.1744
   Episode_Reward/pen_joint_torque: -0.2189
    Episode_Reward/pen_joint_accel: -0.1187
    Episode_Reward/pen_action_rate: -0.1095
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0509
   Episode_Reward/pen_joint_powers: -0.0796
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2440
Episode_Reward/pen_flat_orientation: -0.1337
  Episode_Reward/pen_feet_distance: -0.0066
Episode_Reward/pen_feet_regulation: -0.3383
   Episode_Reward/foot_landing_vel: -0.1517
   Episode_Reward/test_gait_reward: -0.8950
Metrics/base_velocity/error_vel_xy: 1.8481
Metrics/base_velocity/error_vel_yaw: 1.2225
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 1.09s
                        Total time: 1035.85s
                               ETA: 2222.6s

################################################################################
                     [1m Learning iteration 954/3000 [0m                      

                       Computation: 85678 steps/s (collection: 1.022s, learning 0.125s)
               Value function loss: 1.0512
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8936
                     Learning rate: 0.0006
                       Mean reward: 94.93
               Mean episode length: 908.95
       Episode_Reward/keep_balance: 0.9111
     Episode_Reward/rew_lin_vel_xy: 4.3260
      Episode_Reward/rew_ang_vel_z: 2.2926
    Episode_Reward/pen_base_height: -0.3238
      Episode_Reward/pen_lin_vel_z: -0.0525
     Episode_Reward/pen_ang_vel_xy: -0.1693
   Episode_Reward/pen_joint_torque: -0.2088
    Episode_Reward/pen_joint_accel: -0.1010
    Episode_Reward/pen_action_rate: -0.1059
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0500
   Episode_Reward/pen_joint_powers: -0.0779
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2370
Episode_Reward/pen_flat_orientation: -0.1315
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3260
   Episode_Reward/foot_landing_vel: -0.1445
   Episode_Reward/test_gait_reward: -0.8637
Metrics/base_velocity/error_vel_xy: 1.6484
Metrics/base_velocity/error_vel_yaw: 1.2024
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 1.15s
                        Total time: 1037.00s
                               ETA: 2221.7s

################################################################################
                     [1m Learning iteration 955/3000 [0m                      

                       Computation: 88574 steps/s (collection: 0.981s, learning 0.129s)
               Value function loss: 1.0661
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8932
                     Learning rate: 0.0004
                       Mean reward: 98.06
               Mean episode length: 956.99
       Episode_Reward/keep_balance: 0.9453
     Episode_Reward/rew_lin_vel_xy: 4.2767
      Episode_Reward/rew_ang_vel_z: 2.4283
    Episode_Reward/pen_base_height: -0.3303
      Episode_Reward/pen_lin_vel_z: -0.0508
     Episode_Reward/pen_ang_vel_xy: -0.1716
   Episode_Reward/pen_joint_torque: -0.2129
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1072
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0488
   Episode_Reward/pen_joint_powers: -0.0773
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2417
Episode_Reward/pen_flat_orientation: -0.1306
  Episode_Reward/pen_feet_distance: -0.0052
Episode_Reward/pen_feet_regulation: -0.3140
   Episode_Reward/foot_landing_vel: -0.1402
   Episode_Reward/test_gait_reward: -0.8792
Metrics/base_velocity/error_vel_xy: 1.8817
Metrics/base_velocity/error_vel_yaw: 1.2074
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 1.11s
                        Total time: 1038.11s
                               ETA: 2220.6s

################################################################################
                     [1m Learning iteration 956/3000 [0m                      

                       Computation: 89225 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 1.0303
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8926
                     Learning rate: 0.0009
                       Mean reward: 94.32
               Mean episode length: 940.80
       Episode_Reward/keep_balance: 0.9022
     Episode_Reward/rew_lin_vel_xy: 4.0051
      Episode_Reward/rew_ang_vel_z: 2.3058
    Episode_Reward/pen_base_height: -0.3249
      Episode_Reward/pen_lin_vel_z: -0.0533
     Episode_Reward/pen_ang_vel_xy: -0.1650
   Episode_Reward/pen_joint_torque: -0.2084
    Episode_Reward/pen_joint_accel: -0.1019
    Episode_Reward/pen_action_rate: -0.1032
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0485
   Episode_Reward/pen_joint_powers: -0.0759
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2300
Episode_Reward/pen_flat_orientation: -0.1273
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3246
   Episode_Reward/foot_landing_vel: -0.1463
   Episode_Reward/test_gait_reward: -0.8425
Metrics/base_velocity/error_vel_xy: 1.8677
Metrics/base_velocity/error_vel_yaw: 1.1543
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 1.10s
                        Total time: 1039.21s
                               ETA: 2219.6s

################################################################################
                     [1m Learning iteration 957/3000 [0m                      

                       Computation: 90272 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 1.0548
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8940
                     Learning rate: 0.0006
                       Mean reward: 97.73
               Mean episode length: 968.19
       Episode_Reward/keep_balance: 0.9410
     Episode_Reward/rew_lin_vel_xy: 4.2217
      Episode_Reward/rew_ang_vel_z: 2.3961
    Episode_Reward/pen_base_height: -0.3321
      Episode_Reward/pen_lin_vel_z: -0.0534
     Episode_Reward/pen_ang_vel_xy: -0.1802
   Episode_Reward/pen_joint_torque: -0.2183
    Episode_Reward/pen_joint_accel: -0.1147
    Episode_Reward/pen_action_rate: -0.1091
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0518
   Episode_Reward/pen_joint_powers: -0.0802
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2449
Episode_Reward/pen_flat_orientation: -0.1324
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.3350
   Episode_Reward/foot_landing_vel: -0.1499
   Episode_Reward/test_gait_reward: -0.8861
Metrics/base_velocity/error_vel_xy: 1.8550
Metrics/base_velocity/error_vel_yaw: 1.2267
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 1.09s
                        Total time: 1040.30s
                               ETA: 2218.5s

################################################################################
                     [1m Learning iteration 958/3000 [0m                      

                       Computation: 91544 steps/s (collection: 0.948s, learning 0.126s)
               Value function loss: 1.0145
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8962
                     Learning rate: 0.0009
                       Mean reward: 101.74
               Mean episode length: 952.70
       Episode_Reward/keep_balance: 0.9333
     Episode_Reward/rew_lin_vel_xy: 4.3853
      Episode_Reward/rew_ang_vel_z: 2.4068
    Episode_Reward/pen_base_height: -0.3342
      Episode_Reward/pen_lin_vel_z: -0.0511
     Episode_Reward/pen_ang_vel_xy: -0.1705
   Episode_Reward/pen_joint_torque: -0.2169
    Episode_Reward/pen_joint_accel: -0.1042
    Episode_Reward/pen_action_rate: -0.1056
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0486
   Episode_Reward/pen_joint_powers: -0.0776
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2356
Episode_Reward/pen_flat_orientation: -0.1269
  Episode_Reward/pen_feet_distance: -0.0089
Episode_Reward/pen_feet_regulation: -0.3188
   Episode_Reward/foot_landing_vel: -0.1358
   Episode_Reward/test_gait_reward: -0.8713
Metrics/base_velocity/error_vel_xy: 1.7841
Metrics/base_velocity/error_vel_yaw: 1.1759
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 1.07s
                        Total time: 1041.37s
                               ETA: 2217.4s

################################################################################
                     [1m Learning iteration 959/3000 [0m                      

                       Computation: 92380 steps/s (collection: 0.940s, learning 0.124s)
               Value function loss: 1.0304
                    Surrogate loss: 0.0007
             Mean action noise std: 0.8966
                     Learning rate: 0.0001
                       Mean reward: 102.78
               Mean episode length: 972.92
       Episode_Reward/keep_balance: 0.9587
     Episode_Reward/rew_lin_vel_xy: 4.4282
      Episode_Reward/rew_ang_vel_z: 2.4664
    Episode_Reward/pen_base_height: -0.3313
      Episode_Reward/pen_lin_vel_z: -0.0520
     Episode_Reward/pen_ang_vel_xy: -0.1758
   Episode_Reward/pen_joint_torque: -0.2158
    Episode_Reward/pen_joint_accel: -0.1004
    Episode_Reward/pen_action_rate: -0.1088
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0498
   Episode_Reward/pen_joint_powers: -0.0785
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2444
Episode_Reward/pen_flat_orientation: -0.1244
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3291
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.8958
Metrics/base_velocity/error_vel_xy: 1.8594
Metrics/base_velocity/error_vel_yaw: 1.2045
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 1.06s
                        Total time: 1042.44s
                               ETA: 2216.3s

################################################################################
                     [1m Learning iteration 960/3000 [0m                      

                       Computation: 90831 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 1.1070
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8974
                     Learning rate: 0.0002
                       Mean reward: 104.76
               Mean episode length: 967.44
       Episode_Reward/keep_balance: 0.9795
     Episode_Reward/rew_lin_vel_xy: 4.8526
      Episode_Reward/rew_ang_vel_z: 2.4338
    Episode_Reward/pen_base_height: -0.3304
      Episode_Reward/pen_lin_vel_z: -0.0489
     Episode_Reward/pen_ang_vel_xy: -0.1766
   Episode_Reward/pen_joint_torque: -0.2219
    Episode_Reward/pen_joint_accel: -0.1215
    Episode_Reward/pen_action_rate: -0.1138
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0512
   Episode_Reward/pen_joint_powers: -0.0802
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2572
Episode_Reward/pen_flat_orientation: -0.1260
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3249
   Episode_Reward/foot_landing_vel: -0.1450
   Episode_Reward/test_gait_reward: -0.9205
Metrics/base_velocity/error_vel_xy: 1.6315
Metrics/base_velocity/error_vel_yaw: 1.3248
      Episode_Termination/time_out: 2.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 1.08s
                        Total time: 1043.52s
                               ETA: 2215.2s

################################################################################
                     [1m Learning iteration 961/3000 [0m                      

                       Computation: 89122 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.9500
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8976
                     Learning rate: 0.0004
                       Mean reward: 100.02
               Mean episode length: 963.47
       Episode_Reward/keep_balance: 0.9532
     Episode_Reward/rew_lin_vel_xy: 4.2806
      Episode_Reward/rew_ang_vel_z: 2.4394
    Episode_Reward/pen_base_height: -0.3312
      Episode_Reward/pen_lin_vel_z: -0.0518
     Episode_Reward/pen_ang_vel_xy: -0.1753
   Episode_Reward/pen_joint_torque: -0.2145
    Episode_Reward/pen_joint_accel: -0.1022
    Episode_Reward/pen_action_rate: -0.1085
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0504
   Episode_Reward/pen_joint_powers: -0.0783
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2432
Episode_Reward/pen_flat_orientation: -0.1275
  Episode_Reward/pen_feet_distance: -0.0060
Episode_Reward/pen_feet_regulation: -0.3278
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.8904
Metrics/base_velocity/error_vel_xy: 1.9279
Metrics/base_velocity/error_vel_yaw: 1.2157
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 1.10s
                        Total time: 1044.62s
                               ETA: 2214.1s

################################################################################
                     [1m Learning iteration 962/3000 [0m                      

                       Computation: 89231 steps/s (collection: 0.977s, learning 0.125s)
               Value function loss: 0.9904
                    Surrogate loss: -0.0016
             Mean action noise std: 0.8960
                     Learning rate: 0.0006
                       Mean reward: 96.44
               Mean episode length: 953.81
       Episode_Reward/keep_balance: 0.9509
     Episode_Reward/rew_lin_vel_xy: 4.2502
      Episode_Reward/rew_ang_vel_z: 2.4094
    Episode_Reward/pen_base_height: -0.3267
      Episode_Reward/pen_lin_vel_z: -0.0507
     Episode_Reward/pen_ang_vel_xy: -0.1748
   Episode_Reward/pen_joint_torque: -0.2136
    Episode_Reward/pen_joint_accel: -0.1008
    Episode_Reward/pen_action_rate: -0.1079
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0484
   Episode_Reward/pen_joint_powers: -0.0773
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2426
Episode_Reward/pen_flat_orientation: -0.1274
  Episode_Reward/pen_feet_distance: -0.0113
Episode_Reward/pen_feet_regulation: -0.3126
   Episode_Reward/foot_landing_vel: -0.1346
   Episode_Reward/test_gait_reward: -0.8830
Metrics/base_velocity/error_vel_xy: 1.9463
Metrics/base_velocity/error_vel_yaw: 1.2344
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 1.10s
                        Total time: 1045.72s
                               ETA: 2213.1s

################################################################################
                     [1m Learning iteration 963/3000 [0m                      

                       Computation: 88879 steps/s (collection: 0.979s, learning 0.127s)
               Value function loss: 0.9803
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8958
                     Learning rate: 0.0003
                       Mean reward: 102.72
               Mean episode length: 980.59
       Episode_Reward/keep_balance: 0.9733
     Episode_Reward/rew_lin_vel_xy: 4.5179
      Episode_Reward/rew_ang_vel_z: 2.4892
    Episode_Reward/pen_base_height: -0.3484
      Episode_Reward/pen_lin_vel_z: -0.0531
     Episode_Reward/pen_ang_vel_xy: -0.1758
   Episode_Reward/pen_joint_torque: -0.2218
    Episode_Reward/pen_joint_accel: -0.1088
    Episode_Reward/pen_action_rate: -0.1105
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0506
   Episode_Reward/pen_joint_powers: -0.0802
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2481
Episode_Reward/pen_flat_orientation: -0.1261
  Episode_Reward/pen_feet_distance: -0.0075
Episode_Reward/pen_feet_regulation: -0.3364
   Episode_Reward/foot_landing_vel: -0.1458
   Episode_Reward/test_gait_reward: -0.9099
Metrics/base_velocity/error_vel_xy: 1.8031
Metrics/base_velocity/error_vel_yaw: 1.2436
      Episode_Termination/time_out: 5.2500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 1.11s
                        Total time: 1046.83s
                               ETA: 2212.0s

################################################################################
                     [1m Learning iteration 964/3000 [0m                      

                       Computation: 90570 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 1.0196
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8965
                     Learning rate: 0.0006
                       Mean reward: 100.38
               Mean episode length: 949.48
       Episode_Reward/keep_balance: 0.9477
     Episode_Reward/rew_lin_vel_xy: 4.4671
      Episode_Reward/rew_ang_vel_z: 2.4328
    Episode_Reward/pen_base_height: -0.3341
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.1725
   Episode_Reward/pen_joint_torque: -0.2122
    Episode_Reward/pen_joint_accel: -0.1113
    Episode_Reward/pen_action_rate: -0.1073
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0508
   Episode_Reward/pen_joint_powers: -0.0784
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2412
Episode_Reward/pen_flat_orientation: -0.1255
  Episode_Reward/pen_feet_distance: -0.0057
Episode_Reward/pen_feet_regulation: -0.3449
   Episode_Reward/foot_landing_vel: -0.1509
   Episode_Reward/test_gait_reward: -0.8875
Metrics/base_velocity/error_vel_xy: 1.8331
Metrics/base_velocity/error_vel_yaw: 1.1968
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 1.09s
                        Total time: 1047.91s
                               ETA: 2210.9s

################################################################################
                     [1m Learning iteration 965/3000 [0m                      

                       Computation: 88611 steps/s (collection: 0.983s, learning 0.126s)
               Value function loss: 1.0562
                    Surrogate loss: -0.0006
             Mean action noise std: 0.8964
                     Learning rate: 0.0002
                       Mean reward: 95.91
               Mean episode length: 947.66
       Episode_Reward/keep_balance: 0.9390
     Episode_Reward/rew_lin_vel_xy: 4.2612
      Episode_Reward/rew_ang_vel_z: 2.3814
    Episode_Reward/pen_base_height: -0.3355
      Episode_Reward/pen_lin_vel_z: -0.0548
     Episode_Reward/pen_ang_vel_xy: -0.1747
   Episode_Reward/pen_joint_torque: -0.2218
    Episode_Reward/pen_joint_accel: -0.1082
    Episode_Reward/pen_action_rate: -0.1089
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0511
   Episode_Reward/pen_joint_powers: -0.0800
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2426
Episode_Reward/pen_flat_orientation: -0.1265
  Episode_Reward/pen_feet_distance: -0.0052
Episode_Reward/pen_feet_regulation: -0.3488
   Episode_Reward/foot_landing_vel: -0.1494
   Episode_Reward/test_gait_reward: -0.8790
Metrics/base_velocity/error_vel_xy: 1.8160
Metrics/base_velocity/error_vel_yaw: 1.2162
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 1.11s
                        Total time: 1049.02s
                               ETA: 2209.9s

################################################################################
                     [1m Learning iteration 966/3000 [0m                      

                       Computation: 89930 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 1.0107
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8957
                     Learning rate: 0.0004
                       Mean reward: 94.76
               Mean episode length: 946.29
       Episode_Reward/keep_balance: 0.9350
     Episode_Reward/rew_lin_vel_xy: 4.2841
      Episode_Reward/rew_ang_vel_z: 2.3532
    Episode_Reward/pen_base_height: -0.3269
      Episode_Reward/pen_lin_vel_z: -0.0527
     Episode_Reward/pen_ang_vel_xy: -0.1769
   Episode_Reward/pen_joint_torque: -0.2128
    Episode_Reward/pen_joint_accel: -0.1131
    Episode_Reward/pen_action_rate: -0.1080
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0515
   Episode_Reward/pen_joint_powers: -0.0793
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2418
Episode_Reward/pen_flat_orientation: -0.1365
  Episode_Reward/pen_feet_distance: -0.0108
Episode_Reward/pen_feet_regulation: -0.3332
   Episode_Reward/foot_landing_vel: -0.1532
   Episode_Reward/test_gait_reward: -0.8712
Metrics/base_velocity/error_vel_xy: 1.8165
Metrics/base_velocity/error_vel_yaw: 1.2420
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 1.09s
                        Total time: 1050.12s
                               ETA: 2208.8s

################################################################################
                     [1m Learning iteration 967/3000 [0m                      

                       Computation: 89746 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.9771
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8995
                     Learning rate: 0.0009
                       Mean reward: 93.34
               Mean episode length: 937.65
       Episode_Reward/keep_balance: 0.9423
     Episode_Reward/rew_lin_vel_xy: 4.2622
      Episode_Reward/rew_ang_vel_z: 2.3792
    Episode_Reward/pen_base_height: -0.3327
      Episode_Reward/pen_lin_vel_z: -0.0514
     Episode_Reward/pen_ang_vel_xy: -0.1750
   Episode_Reward/pen_joint_torque: -0.2146
    Episode_Reward/pen_joint_accel: -0.1072
    Episode_Reward/pen_action_rate: -0.1085
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0503
   Episode_Reward/pen_joint_powers: -0.0791
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2421
Episode_Reward/pen_flat_orientation: -0.1257
  Episode_Reward/pen_feet_distance: -0.0085
Episode_Reward/pen_feet_regulation: -0.3287
   Episode_Reward/foot_landing_vel: -0.1413
   Episode_Reward/test_gait_reward: -0.8797
Metrics/base_velocity/error_vel_xy: 1.8328
Metrics/base_velocity/error_vel_yaw: 1.2368
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 1.10s
                        Total time: 1051.21s
                               ETA: 2207.8s

################################################################################
                     [1m Learning iteration 968/3000 [0m                      

                       Computation: 90403 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 1.0273
                    Surrogate loss: -0.0026
             Mean action noise std: 0.9002
                     Learning rate: 0.0009
                       Mean reward: 103.21
               Mean episode length: 980.88
       Episode_Reward/keep_balance: 0.9763
     Episode_Reward/rew_lin_vel_xy: 4.6319
      Episode_Reward/rew_ang_vel_z: 2.5163
    Episode_Reward/pen_base_height: -0.3323
      Episode_Reward/pen_lin_vel_z: -0.0544
     Episode_Reward/pen_ang_vel_xy: -0.1777
   Episode_Reward/pen_joint_torque: -0.2197
    Episode_Reward/pen_joint_accel: -0.1026
    Episode_Reward/pen_action_rate: -0.1087
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0503
   Episode_Reward/pen_joint_powers: -0.0802
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2446
Episode_Reward/pen_flat_orientation: -0.1224
  Episode_Reward/pen_feet_distance: -0.0087
Episode_Reward/pen_feet_regulation: -0.3312
   Episode_Reward/foot_landing_vel: -0.1462
   Episode_Reward/test_gait_reward: -0.9091
Metrics/base_velocity/error_vel_xy: 1.7890
Metrics/base_velocity/error_vel_yaw: 1.2210
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 1.09s
                        Total time: 1052.30s
                               ETA: 2206.7s

################################################################################
                     [1m Learning iteration 969/3000 [0m                      

                       Computation: 90610 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 0.9444
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8995
                     Learning rate: 0.0009
                       Mean reward: 95.66
               Mean episode length: 942.58
       Episode_Reward/keep_balance: 0.9614
     Episode_Reward/rew_lin_vel_xy: 4.4529
      Episode_Reward/rew_ang_vel_z: 2.4486
    Episode_Reward/pen_base_height: -0.3300
      Episode_Reward/pen_lin_vel_z: -0.0515
     Episode_Reward/pen_ang_vel_xy: -0.1737
   Episode_Reward/pen_joint_torque: -0.2183
    Episode_Reward/pen_joint_accel: -0.1014
    Episode_Reward/pen_action_rate: -0.1094
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0501
   Episode_Reward/pen_joint_powers: -0.0789
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2467
Episode_Reward/pen_flat_orientation: -0.1290
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3329
   Episode_Reward/foot_landing_vel: -0.1462
   Episode_Reward/test_gait_reward: -0.9018
Metrics/base_velocity/error_vel_xy: 1.8095
Metrics/base_velocity/error_vel_yaw: 1.2364
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 1.08s
                        Total time: 1053.38s
                               ETA: 2205.6s

################################################################################
                     [1m Learning iteration 970/3000 [0m                      

                       Computation: 90419 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.9575
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9007
                     Learning rate: 0.0009
                       Mean reward: 98.56
               Mean episode length: 961.92
       Episode_Reward/keep_balance: 0.9571
     Episode_Reward/rew_lin_vel_xy: 4.3611
      Episode_Reward/rew_ang_vel_z: 2.4014
    Episode_Reward/pen_base_height: -0.3376
      Episode_Reward/pen_lin_vel_z: -0.0528
     Episode_Reward/pen_ang_vel_xy: -0.1795
   Episode_Reward/pen_joint_torque: -0.2167
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.1104
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0518
   Episode_Reward/pen_joint_powers: -0.0803
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2484
Episode_Reward/pen_flat_orientation: -0.1287
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.3407
   Episode_Reward/foot_landing_vel: -0.1457
   Episode_Reward/test_gait_reward: -0.8922
Metrics/base_velocity/error_vel_xy: 1.8894
Metrics/base_velocity/error_vel_yaw: 1.2696
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 1.09s
                        Total time: 1054.47s
                               ETA: 2204.5s

################################################################################
                     [1m Learning iteration 971/3000 [0m                      

                       Computation: 90700 steps/s (collection: 0.959s, learning 0.125s)
               Value function loss: 0.9601
                    Surrogate loss: -0.0011
             Mean action noise std: 0.9004
                     Learning rate: 0.0006
                       Mean reward: 99.41
               Mean episode length: 971.13
       Episode_Reward/keep_balance: 0.9697
     Episode_Reward/rew_lin_vel_xy: 4.4831
      Episode_Reward/rew_ang_vel_z: 2.4872
    Episode_Reward/pen_base_height: -0.3397
      Episode_Reward/pen_lin_vel_z: -0.0519
     Episode_Reward/pen_ang_vel_xy: -0.1769
   Episode_Reward/pen_joint_torque: -0.2174
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1097
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0509
   Episode_Reward/pen_joint_powers: -0.0797
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2478
Episode_Reward/pen_flat_orientation: -0.1282
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3392
   Episode_Reward/foot_landing_vel: -0.1393
   Episode_Reward/test_gait_reward: -0.9047
Metrics/base_velocity/error_vel_xy: 1.9237
Metrics/base_velocity/error_vel_yaw: 1.2308
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 1.08s
                        Total time: 1055.56s
                               ETA: 2203.4s

################################################################################
                     [1m Learning iteration 972/3000 [0m                      

                       Computation: 90687 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.9067
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8992
                     Learning rate: 0.0009
                       Mean reward: 97.32
               Mean episode length: 952.41
       Episode_Reward/keep_balance: 0.9609
     Episode_Reward/rew_lin_vel_xy: 4.4870
      Episode_Reward/rew_ang_vel_z: 2.4227
    Episode_Reward/pen_base_height: -0.3311
      Episode_Reward/pen_lin_vel_z: -0.0532
     Episode_Reward/pen_ang_vel_xy: -0.1808
   Episode_Reward/pen_joint_torque: -0.2165
    Episode_Reward/pen_joint_accel: -0.1104
    Episode_Reward/pen_action_rate: -0.1092
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0515
   Episode_Reward/pen_joint_powers: -0.0798
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2461
Episode_Reward/pen_flat_orientation: -0.1342
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.3402
   Episode_Reward/foot_landing_vel: -0.1516
   Episode_Reward/test_gait_reward: -0.8996
Metrics/base_velocity/error_vel_xy: 1.8395
Metrics/base_velocity/error_vel_yaw: 1.2618
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 1.08s
                        Total time: 1056.64s
                               ETA: 2202.3s

################################################################################
                     [1m Learning iteration 973/3000 [0m                      

                       Computation: 92540 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 1.0493
                    Surrogate loss: -0.0017
             Mean action noise std: 0.9002
                     Learning rate: 0.0004
                       Mean reward: 96.57
               Mean episode length: 971.82
       Episode_Reward/keep_balance: 0.9641
     Episode_Reward/rew_lin_vel_xy: 4.2772
      Episode_Reward/rew_ang_vel_z: 2.3945
    Episode_Reward/pen_base_height: -0.3250
      Episode_Reward/pen_lin_vel_z: -0.0519
     Episode_Reward/pen_ang_vel_xy: -0.1803
   Episode_Reward/pen_joint_torque: -0.2117
    Episode_Reward/pen_joint_accel: -0.1121
    Episode_Reward/pen_action_rate: -0.1114
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0527
   Episode_Reward/pen_joint_powers: -0.0802
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2509
Episode_Reward/pen_flat_orientation: -0.1270
  Episode_Reward/pen_feet_distance: -0.0055
Episode_Reward/pen_feet_regulation: -0.3539
   Episode_Reward/foot_landing_vel: -0.1539
   Episode_Reward/test_gait_reward: -0.9029
Metrics/base_velocity/error_vel_xy: 1.9172
Metrics/base_velocity/error_vel_yaw: 1.2891
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 1.06s
                        Total time: 1057.70s
                               ETA: 2201.2s

################################################################################
                     [1m Learning iteration 974/3000 [0m                      

                       Computation: 90443 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 1.0700
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9034
                     Learning rate: 0.0009
                       Mean reward: 94.51
               Mean episode length: 930.09
       Episode_Reward/keep_balance: 0.9302
     Episode_Reward/rew_lin_vel_xy: 4.3378
      Episode_Reward/rew_ang_vel_z: 2.3454
    Episode_Reward/pen_base_height: -0.3133
      Episode_Reward/pen_lin_vel_z: -0.0524
     Episode_Reward/pen_ang_vel_xy: -0.1706
   Episode_Reward/pen_joint_torque: -0.2077
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.1060
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0498
   Episode_Reward/pen_joint_powers: -0.0771
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2391
Episode_Reward/pen_flat_orientation: -0.1254
  Episode_Reward/pen_feet_distance: -0.0077
Episode_Reward/pen_feet_regulation: -0.3268
   Episode_Reward/foot_landing_vel: -0.1487
   Episode_Reward/test_gait_reward: -0.8577
Metrics/base_velocity/error_vel_xy: 1.8142
Metrics/base_velocity/error_vel_yaw: 1.2134
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 1.09s
                        Total time: 1058.79s
                               ETA: 2200.1s

################################################################################
                     [1m Learning iteration 975/3000 [0m                      

                       Computation: 91458 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 1.0062
                    Surrogate loss: -0.0019
             Mean action noise std: 0.9038
                     Learning rate: 0.0006
                       Mean reward: 94.87
               Mean episode length: 943.90
       Episode_Reward/keep_balance: 0.9475
     Episode_Reward/rew_lin_vel_xy: 4.2512
      Episode_Reward/rew_ang_vel_z: 2.4054
    Episode_Reward/pen_base_height: -0.3291
      Episode_Reward/pen_lin_vel_z: -0.0526
     Episode_Reward/pen_ang_vel_xy: -0.1765
   Episode_Reward/pen_joint_torque: -0.2099
    Episode_Reward/pen_joint_accel: -0.1042
    Episode_Reward/pen_action_rate: -0.1091
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0507
   Episode_Reward/pen_joint_powers: -0.0783
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2441
Episode_Reward/pen_flat_orientation: -0.1323
  Episode_Reward/pen_feet_distance: -0.0096
Episode_Reward/pen_feet_regulation: -0.3416
   Episode_Reward/foot_landing_vel: -0.1453
   Episode_Reward/test_gait_reward: -0.8874
Metrics/base_velocity/error_vel_xy: 1.9260
Metrics/base_velocity/error_vel_yaw: 1.2349
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 1.07s
                        Total time: 1059.86s
                               ETA: 2199.0s

################################################################################
                     [1m Learning iteration 976/3000 [0m                      

                       Computation: 92816 steps/s (collection: 0.937s, learning 0.122s)
               Value function loss: 1.0142
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9055
                     Learning rate: 0.0009
                       Mean reward: 96.65
               Mean episode length: 935.34
       Episode_Reward/keep_balance: 0.9239
     Episode_Reward/rew_lin_vel_xy: 4.1778
      Episode_Reward/rew_ang_vel_z: 2.3636
    Episode_Reward/pen_base_height: -0.3282
      Episode_Reward/pen_lin_vel_z: -0.0532
     Episode_Reward/pen_ang_vel_xy: -0.1796
   Episode_Reward/pen_joint_torque: -0.2132
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.1057
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0514
   Episode_Reward/pen_joint_powers: -0.0785
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2358
Episode_Reward/pen_flat_orientation: -0.1370
  Episode_Reward/pen_feet_distance: -0.0107
Episode_Reward/pen_feet_regulation: -0.3311
   Episode_Reward/foot_landing_vel: -0.1467
   Episode_Reward/test_gait_reward: -0.8601
Metrics/base_velocity/error_vel_xy: 1.8310
Metrics/base_velocity/error_vel_yaw: 1.1846
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 1.06s
                        Total time: 1060.92s
                               ETA: 2197.9s

################################################################################
                     [1m Learning iteration 977/3000 [0m                      

                       Computation: 91195 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 1.0210
                    Surrogate loss: -0.0019
             Mean action noise std: 0.9051
                     Learning rate: 0.0009
                       Mean reward: 95.56
               Mean episode length: 942.53
       Episode_Reward/keep_balance: 0.9418
     Episode_Reward/rew_lin_vel_xy: 4.4303
      Episode_Reward/rew_ang_vel_z: 2.3717
    Episode_Reward/pen_base_height: -0.3324
      Episode_Reward/pen_lin_vel_z: -0.0539
     Episode_Reward/pen_ang_vel_xy: -0.1780
   Episode_Reward/pen_joint_torque: -0.2183
    Episode_Reward/pen_joint_accel: -0.1162
    Episode_Reward/pen_action_rate: -0.1096
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0534
   Episode_Reward/pen_joint_powers: -0.0817
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2433
Episode_Reward/pen_flat_orientation: -0.1327
  Episode_Reward/pen_feet_distance: -0.0078
Episode_Reward/pen_feet_regulation: -0.3595
   Episode_Reward/foot_landing_vel: -0.1546
   Episode_Reward/test_gait_reward: -0.8913
Metrics/base_velocity/error_vel_xy: 1.6929
Metrics/base_velocity/error_vel_yaw: 1.2418
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 1.08s
                        Total time: 1062.00s
                               ETA: 2196.8s

################################################################################
                     [1m Learning iteration 978/3000 [0m                      

                       Computation: 91204 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.9833
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9038
                     Learning rate: 0.0006
                       Mean reward: 96.16
               Mean episode length: 940.00
       Episode_Reward/keep_balance: 0.9520
     Episode_Reward/rew_lin_vel_xy: 4.4283
      Episode_Reward/rew_ang_vel_z: 2.3933
    Episode_Reward/pen_base_height: -0.3227
      Episode_Reward/pen_lin_vel_z: -0.0486
     Episode_Reward/pen_ang_vel_xy: -0.1839
   Episode_Reward/pen_joint_torque: -0.2124
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1104
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0514
   Episode_Reward/pen_joint_powers: -0.0793
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2487
Episode_Reward/pen_flat_orientation: -0.1312
  Episode_Reward/pen_feet_distance: -0.0053
Episode_Reward/pen_feet_regulation: -0.3436
   Episode_Reward/foot_landing_vel: -0.1421
   Episode_Reward/test_gait_reward: -0.8984
Metrics/base_velocity/error_vel_xy: 1.8739
Metrics/base_velocity/error_vel_yaw: 1.2528
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 1.08s
                        Total time: 1063.08s
                               ETA: 2195.7s

################################################################################
                     [1m Learning iteration 979/3000 [0m                      

                       Computation: 91524 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 1.0006
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9030
                     Learning rate: 0.0004
                       Mean reward: 99.98
               Mean episode length: 945.49
       Episode_Reward/keep_balance: 0.9360
     Episode_Reward/rew_lin_vel_xy: 4.4106
      Episode_Reward/rew_ang_vel_z: 2.4131
    Episode_Reward/pen_base_height: -0.3169
      Episode_Reward/pen_lin_vel_z: -0.0491
     Episode_Reward/pen_ang_vel_xy: -0.1712
   Episode_Reward/pen_joint_torque: -0.2122
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.1057
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0488
   Episode_Reward/pen_joint_powers: -0.0772
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2372
Episode_Reward/pen_flat_orientation: -0.1254
  Episode_Reward/pen_feet_distance: -0.0075
Episode_Reward/pen_feet_regulation: -0.3234
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.8711
Metrics/base_velocity/error_vel_xy: 1.7931
Metrics/base_velocity/error_vel_yaw: 1.1732
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 1.07s
                        Total time: 1064.15s
                               ETA: 2194.5s

################################################################################
                     [1m Learning iteration 980/3000 [0m                      

                       Computation: 92743 steps/s (collection: 0.939s, learning 0.121s)
               Value function loss: 0.9201
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9030
                     Learning rate: 0.0004
                       Mean reward: 101.11
               Mean episode length: 948.58
       Episode_Reward/keep_balance: 0.9690
     Episode_Reward/rew_lin_vel_xy: 4.7238
      Episode_Reward/rew_ang_vel_z: 2.4890
    Episode_Reward/pen_base_height: -0.3308
      Episode_Reward/pen_lin_vel_z: -0.0526
     Episode_Reward/pen_ang_vel_xy: -0.1770
   Episode_Reward/pen_joint_torque: -0.2251
    Episode_Reward/pen_joint_accel: -0.1003
    Episode_Reward/pen_action_rate: -0.1096
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0515
   Episode_Reward/pen_joint_powers: -0.0816
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2439
Episode_Reward/pen_flat_orientation: -0.1326
  Episode_Reward/pen_feet_distance: -0.0072
Episode_Reward/pen_feet_regulation: -0.3431
   Episode_Reward/foot_landing_vel: -0.1532
   Episode_Reward/test_gait_reward: -0.9084
Metrics/base_velocity/error_vel_xy: 1.7116
Metrics/base_velocity/error_vel_yaw: 1.2311
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 1.06s
                        Total time: 1065.21s
                               ETA: 2193.4s

################################################################################
                     [1m Learning iteration 981/3000 [0m                      

                       Computation: 90514 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 1.0563
                    Surrogate loss: -0.0038
             Mean action noise std: 0.9047
                     Learning rate: 0.0006
                       Mean reward: 97.54
               Mean episode length: 939.19
       Episode_Reward/keep_balance: 0.9436
     Episode_Reward/rew_lin_vel_xy: 4.5084
      Episode_Reward/rew_ang_vel_z: 2.3565
    Episode_Reward/pen_base_height: -0.3256
      Episode_Reward/pen_lin_vel_z: -0.0497
     Episode_Reward/pen_ang_vel_xy: -0.1783
   Episode_Reward/pen_joint_torque: -0.2091
    Episode_Reward/pen_joint_accel: -0.1098
    Episode_Reward/pen_action_rate: -0.1087
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0506
   Episode_Reward/pen_joint_powers: -0.0786
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2450
Episode_Reward/pen_flat_orientation: -0.1314
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3429
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.8881
Metrics/base_velocity/error_vel_xy: 1.7347
Metrics/base_velocity/error_vel_yaw: 1.2597
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 1.09s
                        Total time: 1066.30s
                               ETA: 2192.3s

################################################################################
                     [1m Learning iteration 982/3000 [0m                      

                       Computation: 89267 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 1.0301
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9051
                     Learning rate: 0.0004
                       Mean reward: 98.44
               Mean episode length: 945.88
       Episode_Reward/keep_balance: 0.9582
     Episode_Reward/rew_lin_vel_xy: 4.6621
      Episode_Reward/rew_ang_vel_z: 2.4109
    Episode_Reward/pen_base_height: -0.3236
      Episode_Reward/pen_lin_vel_z: -0.0513
     Episode_Reward/pen_ang_vel_xy: -0.1800
   Episode_Reward/pen_joint_torque: -0.2186
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.1102
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0502
   Episode_Reward/pen_joint_powers: -0.0789
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2455
Episode_Reward/pen_flat_orientation: -0.1347
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3348
   Episode_Reward/foot_landing_vel: -0.1380
   Episode_Reward/test_gait_reward: -0.8963
Metrics/base_velocity/error_vel_xy: 1.6201
Metrics/base_velocity/error_vel_yaw: 1.2643
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 1.10s
                        Total time: 1067.40s
                               ETA: 2191.3s

################################################################################
                     [1m Learning iteration 983/3000 [0m                      

                       Computation: 91046 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 1.0208
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9045
                     Learning rate: 0.0004
                       Mean reward: 97.33
               Mean episode length: 953.25
       Episode_Reward/keep_balance: 0.9297
     Episode_Reward/rew_lin_vel_xy: 4.1601
      Episode_Reward/rew_ang_vel_z: 2.3509
    Episode_Reward/pen_base_height: -0.3336
      Episode_Reward/pen_lin_vel_z: -0.0510
     Episode_Reward/pen_ang_vel_xy: -0.1803
   Episode_Reward/pen_joint_torque: -0.2148
    Episode_Reward/pen_joint_accel: -0.1126
    Episode_Reward/pen_action_rate: -0.1081
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0502
   Episode_Reward/pen_joint_powers: -0.0788
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.2411
Episode_Reward/pen_flat_orientation: -0.1346
  Episode_Reward/pen_feet_distance: -0.0112
Episode_Reward/pen_feet_regulation: -0.3242
   Episode_Reward/foot_landing_vel: -0.1414
   Episode_Reward/test_gait_reward: -0.8739
Metrics/base_velocity/error_vel_xy: 1.9377
Metrics/base_velocity/error_vel_yaw: 1.2110
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 1.08s
                        Total time: 1068.48s
                               ETA: 2190.2s

################################################################################
                     [1m Learning iteration 984/3000 [0m                      

                       Computation: 91382 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 1.0354
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9036
                     Learning rate: 0.0009
                       Mean reward: 104.19
               Mean episode length: 965.68
       Episode_Reward/keep_balance: 0.9703
     Episode_Reward/rew_lin_vel_xy: 4.7406
      Episode_Reward/rew_ang_vel_z: 2.4794
    Episode_Reward/pen_base_height: -0.3218
      Episode_Reward/pen_lin_vel_z: -0.0519
     Episode_Reward/pen_ang_vel_xy: -0.1844
   Episode_Reward/pen_joint_torque: -0.2173
    Episode_Reward/pen_joint_accel: -0.1174
    Episode_Reward/pen_action_rate: -0.1115
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0519
   Episode_Reward/pen_joint_powers: -0.0806
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2499
Episode_Reward/pen_flat_orientation: -0.1267
  Episode_Reward/pen_feet_distance: -0.0092
Episode_Reward/pen_feet_regulation: -0.3417
   Episode_Reward/foot_landing_vel: -0.1561
   Episode_Reward/test_gait_reward: -0.9075
Metrics/base_velocity/error_vel_xy: 1.6995
Metrics/base_velocity/error_vel_yaw: 1.2339
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 1.08s
                        Total time: 1069.56s
                               ETA: 2189.1s

################################################################################
                     [1m Learning iteration 985/3000 [0m                      

                       Computation: 85109 steps/s (collection: 1.027s, learning 0.128s)
               Value function loss: 0.9596
                    Surrogate loss: -0.0026
             Mean action noise std: 0.9041
                     Learning rate: 0.0009
                       Mean reward: 95.13
               Mean episode length: 926.41
       Episode_Reward/keep_balance: 0.9063
     Episode_Reward/rew_lin_vel_xy: 4.2936
      Episode_Reward/rew_ang_vel_z: 2.2859
    Episode_Reward/pen_base_height: -0.3185
      Episode_Reward/pen_lin_vel_z: -0.0488
     Episode_Reward/pen_ang_vel_xy: -0.1801
   Episode_Reward/pen_joint_torque: -0.2030
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1070
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0501
   Episode_Reward/pen_joint_powers: -0.0768
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2376
Episode_Reward/pen_flat_orientation: -0.1306
  Episode_Reward/pen_feet_distance: -0.0077
Episode_Reward/pen_feet_regulation: -0.3300
   Episode_Reward/foot_landing_vel: -0.1394
   Episode_Reward/test_gait_reward: -0.8573
Metrics/base_velocity/error_vel_xy: 1.6399
Metrics/base_velocity/error_vel_yaw: 1.2008
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 1.16s
                        Total time: 1070.71s
                               ETA: 2188.1s

################################################################################
                     [1m Learning iteration 986/3000 [0m                      

                       Computation: 88808 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 1.0276
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9041
                     Learning rate: 0.0004
                       Mean reward: 94.14
               Mean episode length: 935.75
       Episode_Reward/keep_balance: 0.9148
     Episode_Reward/rew_lin_vel_xy: 4.1613
      Episode_Reward/rew_ang_vel_z: 2.2721
    Episode_Reward/pen_base_height: -0.3262
      Episode_Reward/pen_lin_vel_z: -0.0488
     Episode_Reward/pen_ang_vel_xy: -0.1780
   Episode_Reward/pen_joint_torque: -0.2047
    Episode_Reward/pen_joint_accel: -0.1021
    Episode_Reward/pen_action_rate: -0.1080
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0494
   Episode_Reward/pen_joint_powers: -0.0765
Episode_Reward/pen_undesired_contacts: -0.0009
Episode_Reward/pen_action_smoothness: -0.2408
Episode_Reward/pen_flat_orientation: -0.1338
  Episode_Reward/pen_feet_distance: -0.0120
Episode_Reward/pen_feet_regulation: -0.3253
   Episode_Reward/foot_landing_vel: -0.1358
   Episode_Reward/test_gait_reward: -0.8593
Metrics/base_velocity/error_vel_xy: 1.8262
Metrics/base_velocity/error_vel_yaw: 1.2434
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 1.11s
                        Total time: 1071.82s
                               ETA: 2187.1s

################################################################################
                     [1m Learning iteration 987/3000 [0m                      

                       Computation: 81738 steps/s (collection: 1.066s, learning 0.136s)
               Value function loss: 0.9865
                    Surrogate loss: -0.0046
             Mean action noise std: 0.9058
                     Learning rate: 0.0004
                       Mean reward: 89.94
               Mean episode length: 887.47
       Episode_Reward/keep_balance: 0.8975
     Episode_Reward/rew_lin_vel_xy: 4.1933
      Episode_Reward/rew_ang_vel_z: 2.2990
    Episode_Reward/pen_base_height: -0.3007
      Episode_Reward/pen_lin_vel_z: -0.0468
     Episode_Reward/pen_ang_vel_xy: -0.1743
   Episode_Reward/pen_joint_torque: -0.1981
    Episode_Reward/pen_joint_accel: -0.1012
    Episode_Reward/pen_action_rate: -0.1037
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0476
   Episode_Reward/pen_joint_powers: -0.0738
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2325
Episode_Reward/pen_flat_orientation: -0.1286
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3011
   Episode_Reward/foot_landing_vel: -0.1346
   Episode_Reward/test_gait_reward: -0.8334
Metrics/base_velocity/error_vel_xy: 1.6946
Metrics/base_velocity/error_vel_yaw: 1.1509
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 1.20s
                        Total time: 1073.02s
                               ETA: 2186.2s

################################################################################
                     [1m Learning iteration 988/3000 [0m                      

                       Computation: 87971 steps/s (collection: 0.991s, learning 0.126s)
               Value function loss: 0.9828
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9051
                     Learning rate: 0.0006
                       Mean reward: 97.37
               Mean episode length: 942.37
       Episode_Reward/keep_balance: 0.9442
     Episode_Reward/rew_lin_vel_xy: 4.4359
      Episode_Reward/rew_ang_vel_z: 2.4080
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0485
     Episode_Reward/pen_ang_vel_xy: -0.1802
   Episode_Reward/pen_joint_torque: -0.2127
    Episode_Reward/pen_joint_accel: -0.1095
    Episode_Reward/pen_action_rate: -0.1096
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0502
   Episode_Reward/pen_joint_powers: -0.0785
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2447
Episode_Reward/pen_flat_orientation: -0.1315
  Episode_Reward/pen_feet_distance: -0.0114
Episode_Reward/pen_feet_regulation: -0.3245
   Episode_Reward/foot_landing_vel: -0.1448
   Episode_Reward/test_gait_reward: -0.8761
Metrics/base_velocity/error_vel_xy: 1.7290
Metrics/base_velocity/error_vel_yaw: 1.2149
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 1.12s
                        Total time: 1074.14s
                               ETA: 2185.2s

################################################################################
                     [1m Learning iteration 989/3000 [0m                      

                       Computation: 87875 steps/s (collection: 0.994s, learning 0.125s)
               Value function loss: 0.9682
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9054
                     Learning rate: 0.0003
                       Mean reward: 94.98
               Mean episode length: 919.78
       Episode_Reward/keep_balance: 0.9268
     Episode_Reward/rew_lin_vel_xy: 4.2445
      Episode_Reward/rew_ang_vel_z: 2.3271
    Episode_Reward/pen_base_height: -0.2987
      Episode_Reward/pen_lin_vel_z: -0.0456
     Episode_Reward/pen_ang_vel_xy: -0.1722
   Episode_Reward/pen_joint_torque: -0.1992
    Episode_Reward/pen_joint_accel: -0.0976
    Episode_Reward/pen_action_rate: -0.1060
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0479
   Episode_Reward/pen_joint_powers: -0.0744
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2394
Episode_Reward/pen_flat_orientation: -0.1223
  Episode_Reward/pen_feet_distance: -0.0116
Episode_Reward/pen_feet_regulation: -0.3076
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.8524
Metrics/base_velocity/error_vel_xy: 1.7826
Metrics/base_velocity/error_vel_yaw: 1.2239
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 1.12s
                        Total time: 1075.26s
                               ETA: 2184.2s

################################################################################
                     [1m Learning iteration 990/3000 [0m                      

                       Computation: 91238 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 1.0285
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9073
                     Learning rate: 0.0002
                       Mean reward: 97.49
               Mean episode length: 954.70
       Episode_Reward/keep_balance: 0.9583
     Episode_Reward/rew_lin_vel_xy: 4.4818
      Episode_Reward/rew_ang_vel_z: 2.4518
    Episode_Reward/pen_base_height: -0.3405
      Episode_Reward/pen_lin_vel_z: -0.0510
     Episode_Reward/pen_ang_vel_xy: -0.1879
   Episode_Reward/pen_joint_torque: -0.2231
    Episode_Reward/pen_joint_accel: -0.1138
    Episode_Reward/pen_action_rate: -0.1126
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0538
   Episode_Reward/pen_joint_powers: -0.0822
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2495
Episode_Reward/pen_flat_orientation: -0.1463
  Episode_Reward/pen_feet_distance: -0.0097
Episode_Reward/pen_feet_regulation: -0.3527
   Episode_Reward/foot_landing_vel: -0.1510
   Episode_Reward/test_gait_reward: -0.8990
Metrics/base_velocity/error_vel_xy: 1.8050
Metrics/base_velocity/error_vel_yaw: 1.2379
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 1.08s
                        Total time: 1076.33s
                               ETA: 2183.1s

################################################################################
                     [1m Learning iteration 991/3000 [0m                      

                       Computation: 91992 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 1.0097
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9073
                     Learning rate: 0.0004
                       Mean reward: 101.42
               Mean episode length: 958.84
       Episode_Reward/keep_balance: 0.9451
     Episode_Reward/rew_lin_vel_xy: 4.5120
      Episode_Reward/rew_ang_vel_z: 2.3869
    Episode_Reward/pen_base_height: -0.3160
      Episode_Reward/pen_lin_vel_z: -0.0505
     Episode_Reward/pen_ang_vel_xy: -0.1742
   Episode_Reward/pen_joint_torque: -0.2169
    Episode_Reward/pen_joint_accel: -0.1169
    Episode_Reward/pen_action_rate: -0.1097
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0517
   Episode_Reward/pen_joint_powers: -0.0796
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2441
Episode_Reward/pen_flat_orientation: -0.1333
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3362
   Episode_Reward/foot_landing_vel: -0.1473
   Episode_Reward/test_gait_reward: -0.8817
Metrics/base_velocity/error_vel_xy: 1.7494
Metrics/base_velocity/error_vel_yaw: 1.2299
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 1.07s
                        Total time: 1077.40s
                               ETA: 2182.0s

################################################################################
                     [1m Learning iteration 992/3000 [0m                      

                       Computation: 91160 steps/s (collection: 0.957s, learning 0.121s)
               Value function loss: 0.9466
                    Surrogate loss: -0.0032
             Mean action noise std: 0.9063
                     Learning rate: 0.0003
                       Mean reward: 97.16
               Mean episode length: 921.48
       Episode_Reward/keep_balance: 0.9351
     Episode_Reward/rew_lin_vel_xy: 4.4246
      Episode_Reward/rew_ang_vel_z: 2.3640
    Episode_Reward/pen_base_height: -0.3175
      Episode_Reward/pen_lin_vel_z: -0.0516
     Episode_Reward/pen_ang_vel_xy: -0.1772
   Episode_Reward/pen_joint_torque: -0.2211
    Episode_Reward/pen_joint_accel: -0.1119
    Episode_Reward/pen_action_rate: -0.1099
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0525
   Episode_Reward/pen_joint_powers: -0.0813
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2433
Episode_Reward/pen_flat_orientation: -0.1376
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.3486
   Episode_Reward/foot_landing_vel: -0.1455
   Episode_Reward/test_gait_reward: -0.8735
Metrics/base_velocity/error_vel_xy: 1.7620
Metrics/base_velocity/error_vel_yaw: 1.2248
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 1.08s
                        Total time: 1078.48s
                               ETA: 2180.9s

################################################################################
                     [1m Learning iteration 993/3000 [0m                      

                       Computation: 89185 steps/s (collection: 0.980s, learning 0.122s)
               Value function loss: 0.9160
                    Surrogate loss: -0.0021
             Mean action noise std: 0.9078
                     Learning rate: 0.0003
                       Mean reward: 96.31
               Mean episode length: 933.18
       Episode_Reward/keep_balance: 0.9455
     Episode_Reward/rew_lin_vel_xy: 4.5048
      Episode_Reward/rew_ang_vel_z: 2.3602
    Episode_Reward/pen_base_height: -0.3262
      Episode_Reward/pen_lin_vel_z: -0.0483
     Episode_Reward/pen_ang_vel_xy: -0.1808
   Episode_Reward/pen_joint_torque: -0.2071
    Episode_Reward/pen_joint_accel: -0.1204
    Episode_Reward/pen_action_rate: -0.1127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0527
   Episode_Reward/pen_joint_powers: -0.0798
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2517
Episode_Reward/pen_flat_orientation: -0.1419
  Episode_Reward/pen_feet_distance: -0.0096
Episode_Reward/pen_feet_regulation: -0.3458
   Episode_Reward/foot_landing_vel: -0.1441
   Episode_Reward/test_gait_reward: -0.8910
Metrics/base_velocity/error_vel_xy: 1.7019
Metrics/base_velocity/error_vel_yaw: 1.2754
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 1.10s
                        Total time: 1079.58s
                               ETA: 2179.8s

################################################################################
                     [1m Learning iteration 994/3000 [0m                      

                       Computation: 90756 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.9395
                    Surrogate loss: -0.0046
             Mean action noise std: 0.9091
                     Learning rate: 0.0006
                       Mean reward: 101.05
               Mean episode length: 949.27
       Episode_Reward/keep_balance: 0.9483
     Episode_Reward/rew_lin_vel_xy: 4.4278
      Episode_Reward/rew_ang_vel_z: 2.3855
    Episode_Reward/pen_base_height: -0.3101
      Episode_Reward/pen_lin_vel_z: -0.0480
     Episode_Reward/pen_ang_vel_xy: -0.1783
   Episode_Reward/pen_joint_torque: -0.2095
    Episode_Reward/pen_joint_accel: -0.1163
    Episode_Reward/pen_action_rate: -0.1109
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0502
   Episode_Reward/pen_joint_powers: -0.0776
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2484
Episode_Reward/pen_flat_orientation: -0.1288
  Episode_Reward/pen_feet_distance: -0.0122
Episode_Reward/pen_feet_regulation: -0.3321
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.8809
Metrics/base_velocity/error_vel_xy: 1.8454
Metrics/base_velocity/error_vel_yaw: 1.2466
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 1.08s
                        Total time: 1080.67s
                               ETA: 2178.7s

################################################################################
                     [1m Learning iteration 995/3000 [0m                      

                       Computation: 90393 steps/s (collection: 0.967s, learning 0.121s)
               Value function loss: 0.9447
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9081
                     Learning rate: 0.0009
                       Mean reward: 98.46
               Mean episode length: 946.70
       Episode_Reward/keep_balance: 0.9290
     Episode_Reward/rew_lin_vel_xy: 4.4934
      Episode_Reward/rew_ang_vel_z: 2.3303
    Episode_Reward/pen_base_height: -0.3306
      Episode_Reward/pen_lin_vel_z: -0.0524
     Episode_Reward/pen_ang_vel_xy: -0.1803
   Episode_Reward/pen_joint_torque: -0.2223
    Episode_Reward/pen_joint_accel: -0.1138
    Episode_Reward/pen_action_rate: -0.1105
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0531
   Episode_Reward/pen_joint_powers: -0.0821
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2432
Episode_Reward/pen_flat_orientation: -0.1354
  Episode_Reward/pen_feet_distance: -0.0090
Episode_Reward/pen_feet_regulation: -0.3656
   Episode_Reward/foot_landing_vel: -0.1535
   Episode_Reward/test_gait_reward: -0.8783
Metrics/base_velocity/error_vel_xy: 1.6317
Metrics/base_velocity/error_vel_yaw: 1.2288
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 1.09s
                        Total time: 1081.75s
                               ETA: 2177.6s

################################################################################
                     [1m Learning iteration 996/3000 [0m                      

                       Computation: 91457 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 1.0732
                    Surrogate loss: -0.0026
             Mean action noise std: 0.9066
                     Learning rate: 0.0006
                       Mean reward: 97.70
               Mean episode length: 953.40
       Episode_Reward/keep_balance: 0.9422
     Episode_Reward/rew_lin_vel_xy: 4.3825
      Episode_Reward/rew_ang_vel_z: 2.3878
    Episode_Reward/pen_base_height: -0.3216
      Episode_Reward/pen_lin_vel_z: -0.0495
     Episode_Reward/pen_ang_vel_xy: -0.1838
   Episode_Reward/pen_joint_torque: -0.2171
    Episode_Reward/pen_joint_accel: -0.1128
    Episode_Reward/pen_action_rate: -0.1118
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0529
   Episode_Reward/pen_joint_powers: -0.0813
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2488
Episode_Reward/pen_flat_orientation: -0.1325
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3488
   Episode_Reward/foot_landing_vel: -0.1522
   Episode_Reward/test_gait_reward: -0.8803
Metrics/base_velocity/error_vel_xy: 1.8461
Metrics/base_velocity/error_vel_yaw: 1.2222
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 1.07s
                        Total time: 1082.83s
                               ETA: 2176.5s

################################################################################
                     [1m Learning iteration 997/3000 [0m                      

                       Computation: 91833 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.0121
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9058
                     Learning rate: 0.0009
                       Mean reward: 97.26
               Mean episode length: 919.38
       Episode_Reward/keep_balance: 0.9352
     Episode_Reward/rew_lin_vel_xy: 4.6307
      Episode_Reward/rew_ang_vel_z: 2.3162
    Episode_Reward/pen_base_height: -0.3239
      Episode_Reward/pen_lin_vel_z: -0.0515
     Episode_Reward/pen_ang_vel_xy: -0.1894
   Episode_Reward/pen_joint_torque: -0.2109
    Episode_Reward/pen_joint_accel: -0.1205
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0816
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2539
Episode_Reward/pen_flat_orientation: -0.1395
  Episode_Reward/pen_feet_distance: -0.0117
Episode_Reward/pen_feet_regulation: -0.3707
   Episode_Reward/foot_landing_vel: -0.1581
   Episode_Reward/test_gait_reward: -0.8882
Metrics/base_velocity/error_vel_xy: 1.5594
Metrics/base_velocity/error_vel_yaw: 1.2843
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 1.07s
                        Total time: 1083.90s
                               ETA: 2175.4s

################################################################################
                     [1m Learning iteration 998/3000 [0m                      

                       Computation: 89659 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.9424
                    Surrogate loss: -0.0022
             Mean action noise std: 0.9064
                     Learning rate: 0.0009
                       Mean reward: 96.48
               Mean episode length: 938.06
       Episode_Reward/keep_balance: 0.9435
     Episode_Reward/rew_lin_vel_xy: 4.5054
      Episode_Reward/rew_ang_vel_z: 2.3735
    Episode_Reward/pen_base_height: -0.3211
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.1826
   Episode_Reward/pen_joint_torque: -0.2168
    Episode_Reward/pen_joint_accel: -0.1158
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0526
   Episode_Reward/pen_joint_powers: -0.0812
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2497
Episode_Reward/pen_flat_orientation: -0.1322
  Episode_Reward/pen_feet_distance: -0.0092
Episode_Reward/pen_feet_regulation: -0.3512
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.8874
Metrics/base_velocity/error_vel_xy: 1.7295
Metrics/base_velocity/error_vel_yaw: 1.2466
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 1.10s
                        Total time: 1085.00s
                               ETA: 2174.3s

################################################################################
                     [1m Learning iteration 999/3000 [0m                      

                       Computation: 91245 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 1.0163
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9086
                     Learning rate: 0.0013
                       Mean reward: 104.20
               Mean episode length: 990.29
       Episode_Reward/keep_balance: 0.9910
     Episode_Reward/rew_lin_vel_xy: 4.7806
      Episode_Reward/rew_ang_vel_z: 2.4841
    Episode_Reward/pen_base_height: -0.3163
      Episode_Reward/pen_lin_vel_z: -0.0497
     Episode_Reward/pen_ang_vel_xy: -0.1935
   Episode_Reward/pen_joint_torque: -0.2218
    Episode_Reward/pen_joint_accel: -0.1184
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0830
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2617
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0100
Episode_Reward/pen_feet_regulation: -0.3565
   Episode_Reward/foot_landing_vel: -0.1543
   Episode_Reward/test_gait_reward: -0.9286
Metrics/base_velocity/error_vel_xy: 1.7436
Metrics/base_velocity/error_vel_yaw: 1.3102
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 1.08s
                        Total time: 1086.07s
                               ETA: 2173.2s

################################################################################
                     [1m Learning iteration 1000/3000 [0m                     

                       Computation: 91642 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 1.0036
                    Surrogate loss: -0.0014
             Mean action noise std: 0.9103
                     Learning rate: 0.0006
                       Mean reward: 104.84
               Mean episode length: 969.83
       Episode_Reward/keep_balance: 0.9532
     Episode_Reward/rew_lin_vel_xy: 4.5857
      Episode_Reward/rew_ang_vel_z: 2.3965
    Episode_Reward/pen_base_height: -0.3139
      Episode_Reward/pen_lin_vel_z: -0.0478
     Episode_Reward/pen_ang_vel_xy: -0.1837
   Episode_Reward/pen_joint_torque: -0.2160
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1129
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0518
   Episode_Reward/pen_joint_powers: -0.0805
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2513
Episode_Reward/pen_flat_orientation: -0.1270
  Episode_Reward/pen_feet_distance: -0.0072
Episode_Reward/pen_feet_regulation: -0.3546
   Episode_Reward/foot_landing_vel: -0.1394
   Episode_Reward/test_gait_reward: -0.8962
Metrics/base_velocity/error_vel_xy: 1.6844
Metrics/base_velocity/error_vel_yaw: 1.2502
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 1.07s
                        Total time: 1087.15s
                               ETA: 2172.1s

################################################################################
                     [1m Learning iteration 1001/3000 [0m                     

                       Computation: 91247 steps/s (collection: 0.952s, learning 0.125s)
               Value function loss: 1.0022
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9110
                     Learning rate: 0.0009
                       Mean reward: 98.14
               Mean episode length: 947.22
       Episode_Reward/keep_balance: 0.9503
     Episode_Reward/rew_lin_vel_xy: 4.6329
      Episode_Reward/rew_ang_vel_z: 2.3987
    Episode_Reward/pen_base_height: -0.3323
      Episode_Reward/pen_lin_vel_z: -0.0533
     Episode_Reward/pen_ang_vel_xy: -0.1910
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.1143
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0556
   Episode_Reward/pen_joint_powers: -0.0854
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.2537
Episode_Reward/pen_flat_orientation: -0.1397
  Episode_Reward/pen_feet_distance: -0.0095
Episode_Reward/pen_feet_regulation: -0.3891
   Episode_Reward/foot_landing_vel: -0.1543
   Episode_Reward/test_gait_reward: -0.9008
Metrics/base_velocity/error_vel_xy: 1.6590
Metrics/base_velocity/error_vel_yaw: 1.2449
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 1.08s
                        Total time: 1088.22s
                               ETA: 2171.0s

################################################################################
                     [1m Learning iteration 1002/3000 [0m                     

                       Computation: 92541 steps/s (collection: 0.941s, learning 0.121s)
               Value function loss: 1.0822
                    Surrogate loss: -0.0022
             Mean action noise std: 0.9107
                     Learning rate: 0.0009
                       Mean reward: 100.21
               Mean episode length: 941.49
       Episode_Reward/keep_balance: 0.9266
     Episode_Reward/rew_lin_vel_xy: 4.8396
      Episode_Reward/rew_ang_vel_z: 2.2762
    Episode_Reward/pen_base_height: -0.3153
      Episode_Reward/pen_lin_vel_z: -0.0505
     Episode_Reward/pen_ang_vel_xy: -0.1896
   Episode_Reward/pen_joint_torque: -0.2060
    Episode_Reward/pen_joint_accel: -0.1296
    Episode_Reward/pen_action_rate: -0.1135
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0813
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2532
Episode_Reward/pen_flat_orientation: -0.1312
  Episode_Reward/pen_feet_distance: -0.0095
Episode_Reward/pen_feet_regulation: -0.3653
   Episode_Reward/foot_landing_vel: -0.1528
   Episode_Reward/test_gait_reward: -0.8785
Metrics/base_velocity/error_vel_xy: 1.4030
Metrics/base_velocity/error_vel_yaw: 1.2722
      Episode_Termination/time_out: 2.7917
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 1.06s
                        Total time: 1089.28s
                               ETA: 2169.9s

################################################################################
                     [1m Learning iteration 1003/3000 [0m                     

                       Computation: 91328 steps/s (collection: 0.955s, learning 0.121s)
               Value function loss: 0.9003
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9106
                     Learning rate: 0.0009
                       Mean reward: 93.60
               Mean episode length: 926.77
       Episode_Reward/keep_balance: 0.9366
     Episode_Reward/rew_lin_vel_xy: 4.3773
      Episode_Reward/rew_ang_vel_z: 2.2901
    Episode_Reward/pen_base_height: -0.3222
      Episode_Reward/pen_lin_vel_z: -0.0511
     Episode_Reward/pen_ang_vel_xy: -0.1958
   Episode_Reward/pen_joint_torque: -0.2137
    Episode_Reward/pen_joint_accel: -0.1161
    Episode_Reward/pen_action_rate: -0.1162
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0556
   Episode_Reward/pen_joint_powers: -0.0830
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2556
Episode_Reward/pen_flat_orientation: -0.1382
  Episode_Reward/pen_feet_distance: -0.0086
Episode_Reward/pen_feet_regulation: -0.3613
   Episode_Reward/foot_landing_vel: -0.1490
   Episode_Reward/test_gait_reward: -0.8829
Metrics/base_velocity/error_vel_xy: 1.7881
Metrics/base_velocity/error_vel_yaw: 1.2956
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 1.08s
                        Total time: 1090.36s
                               ETA: 2168.8s

################################################################################
                     [1m Learning iteration 1004/3000 [0m                     

                       Computation: 91336 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 1.0591
                    Surrogate loss: -0.0039
             Mean action noise std: 0.9102
                     Learning rate: 0.0009
                       Mean reward: 100.42
               Mean episode length: 958.60
       Episode_Reward/keep_balance: 0.9619
     Episode_Reward/rew_lin_vel_xy: 4.6378
      Episode_Reward/rew_ang_vel_z: 2.3901
    Episode_Reward/pen_base_height: -0.3367
      Episode_Reward/pen_lin_vel_z: -0.0519
     Episode_Reward/pen_ang_vel_xy: -0.1912
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0843
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2583
Episode_Reward/pen_flat_orientation: -0.1360
  Episode_Reward/pen_feet_distance: -0.0066
Episode_Reward/pen_feet_regulation: -0.3654
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.9045
Metrics/base_velocity/error_vel_xy: 1.7064
Metrics/base_velocity/error_vel_yaw: 1.2983
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 1.08s
                        Total time: 1091.44s
                               ETA: 2167.7s

################################################################################
                     [1m Learning iteration 1005/3000 [0m                     

                       Computation: 91369 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 1.0932
                    Surrogate loss: -0.0022
             Mean action noise std: 0.9095
                     Learning rate: 0.0006
                       Mean reward: 94.05
               Mean episode length: 905.50
       Episode_Reward/keep_balance: 0.9155
     Episode_Reward/rew_lin_vel_xy: 4.4232
      Episode_Reward/rew_ang_vel_z: 2.3124
    Episode_Reward/pen_base_height: -0.3165
      Episode_Reward/pen_lin_vel_z: -0.0474
     Episode_Reward/pen_ang_vel_xy: -0.1786
   Episode_Reward/pen_joint_torque: -0.2099
    Episode_Reward/pen_joint_accel: -0.1111
    Episode_Reward/pen_action_rate: -0.1101
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0516
   Episode_Reward/pen_joint_powers: -0.0788
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2431
Episode_Reward/pen_flat_orientation: -0.1313
  Episode_Reward/pen_feet_distance: -0.0082
Episode_Reward/pen_feet_regulation: -0.3489
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.8633
Metrics/base_velocity/error_vel_xy: 1.6346
Metrics/base_velocity/error_vel_yaw: 1.2010
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 1.08s
                        Total time: 1092.51s
                               ETA: 2166.6s

################################################################################
                     [1m Learning iteration 1006/3000 [0m                     

                       Computation: 90522 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 1.0116
                    Surrogate loss: -0.0022
             Mean action noise std: 0.9092
                     Learning rate: 0.0004
                       Mean reward: 97.70
               Mean episode length: 929.93
       Episode_Reward/keep_balance: 0.9291
     Episode_Reward/rew_lin_vel_xy: 4.5303
      Episode_Reward/rew_ang_vel_z: 2.3238
    Episode_Reward/pen_base_height: -0.3079
      Episode_Reward/pen_lin_vel_z: -0.0483
     Episode_Reward/pen_ang_vel_xy: -0.1850
   Episode_Reward/pen_joint_torque: -0.2082
    Episode_Reward/pen_joint_accel: -0.1087
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0522
   Episode_Reward/pen_joint_powers: -0.0790
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2517
Episode_Reward/pen_flat_orientation: -0.1329
  Episode_Reward/pen_feet_distance: -0.0065
Episode_Reward/pen_feet_regulation: -0.3533
   Episode_Reward/foot_landing_vel: -0.1444
   Episode_Reward/test_gait_reward: -0.8740
Metrics/base_velocity/error_vel_xy: 1.6099
Metrics/base_velocity/error_vel_yaw: 1.2420
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 1.09s
                        Total time: 1093.60s
                               ETA: 2165.5s

################################################################################
                     [1m Learning iteration 1007/3000 [0m                     

                       Computation: 90285 steps/s (collection: 0.960s, learning 0.129s)
               Value function loss: 0.8823
                    Surrogate loss: -0.0046
             Mean action noise std: 0.9075
                     Learning rate: 0.0006
                       Mean reward: 97.97
               Mean episode length: 937.98
       Episode_Reward/keep_balance: 0.9442
     Episode_Reward/rew_lin_vel_xy: 4.6530
      Episode_Reward/rew_ang_vel_z: 2.3747
    Episode_Reward/pen_base_height: -0.3072
      Episode_Reward/pen_lin_vel_z: -0.0474
     Episode_Reward/pen_ang_vel_xy: -0.1820
   Episode_Reward/pen_joint_torque: -0.2141
    Episode_Reward/pen_joint_accel: -0.1168
    Episode_Reward/pen_action_rate: -0.1131
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0524
   Episode_Reward/pen_joint_powers: -0.0799
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2515
Episode_Reward/pen_flat_orientation: -0.1336
  Episode_Reward/pen_feet_distance: -0.0065
Episode_Reward/pen_feet_regulation: -0.3397
   Episode_Reward/foot_landing_vel: -0.1472
   Episode_Reward/test_gait_reward: -0.8950
Metrics/base_velocity/error_vel_xy: 1.6187
Metrics/base_velocity/error_vel_yaw: 1.2446
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 1.09s
                        Total time: 1094.69s
                               ETA: 2164.4s

################################################################################
                     [1m Learning iteration 1008/3000 [0m                     

                       Computation: 89876 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 0.9330
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9093
                     Learning rate: 0.0013
                       Mean reward: 104.26
               Mean episode length: 978.03
       Episode_Reward/keep_balance: 0.9677
     Episode_Reward/rew_lin_vel_xy: 4.7783
      Episode_Reward/rew_ang_vel_z: 2.4086
    Episode_Reward/pen_base_height: -0.3124
      Episode_Reward/pen_lin_vel_z: -0.0498
     Episode_Reward/pen_ang_vel_xy: -0.1943
   Episode_Reward/pen_joint_torque: -0.2272
    Episode_Reward/pen_joint_accel: -0.1176
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2625
Episode_Reward/pen_flat_orientation: -0.1270
  Episode_Reward/pen_feet_distance: -0.0121
Episode_Reward/pen_feet_regulation: -0.3769
   Episode_Reward/foot_landing_vel: -0.1537
   Episode_Reward/test_gait_reward: -0.9111
Metrics/base_velocity/error_vel_xy: 1.6632
Metrics/base_velocity/error_vel_yaw: 1.2962
      Episode_Termination/time_out: 4.8750
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 1.09s
                        Total time: 1095.78s
                               ETA: 2163.3s

################################################################################
                     [1m Learning iteration 1009/3000 [0m                     

                       Computation: 91980 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 1.0191
                    Surrogate loss: -0.0027
             Mean action noise std: 0.9104
                     Learning rate: 0.0013
                       Mean reward: 101.30
               Mean episode length: 964.96
       Episode_Reward/keep_balance: 0.9701
     Episode_Reward/rew_lin_vel_xy: 4.7130
      Episode_Reward/rew_ang_vel_z: 2.4232
    Episode_Reward/pen_base_height: -0.3099
      Episode_Reward/pen_lin_vel_z: -0.0473
     Episode_Reward/pen_ang_vel_xy: -0.1935
   Episode_Reward/pen_joint_torque: -0.2154
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0529
   Episode_Reward/pen_joint_powers: -0.0814
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2617
Episode_Reward/pen_flat_orientation: -0.1297
  Episode_Reward/pen_feet_distance: -0.0088
Episode_Reward/pen_feet_regulation: -0.3466
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.9121
Metrics/base_velocity/error_vel_xy: 1.7568
Metrics/base_velocity/error_vel_yaw: 1.2882
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 1.07s
                        Total time: 1096.85s
                               ETA: 2162.2s

################################################################################
                     [1m Learning iteration 1010/3000 [0m                     

                       Computation: 91362 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 1.1129
                    Surrogate loss: -0.0050
             Mean action noise std: 0.9115
                     Learning rate: 0.0019
                       Mean reward: 102.44
               Mean episode length: 952.92
       Episode_Reward/keep_balance: 0.9491
     Episode_Reward/rew_lin_vel_xy: 4.7064
      Episode_Reward/rew_ang_vel_z: 2.3869
    Episode_Reward/pen_base_height: -0.3107
      Episode_Reward/pen_lin_vel_z: -0.0506
     Episode_Reward/pen_ang_vel_xy: -0.1831
   Episode_Reward/pen_joint_torque: -0.2214
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.1143
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0540
   Episode_Reward/pen_joint_powers: -0.0831
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2524
Episode_Reward/pen_flat_orientation: -0.1313
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.3623
   Episode_Reward/foot_landing_vel: -0.1560
   Episode_Reward/test_gait_reward: -0.8918
Metrics/base_velocity/error_vel_xy: 1.6253
Metrics/base_velocity/error_vel_yaw: 1.2480
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 1.08s
                        Total time: 1097.93s
                               ETA: 2161.1s

################################################################################
                     [1m Learning iteration 1011/3000 [0m                     

                       Computation: 91905 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.1020
                    Surrogate loss: 0.0036
             Mean action noise std: 0.9122
                     Learning rate: 0.0001
                       Mean reward: 99.75
               Mean episode length: 962.44
       Episode_Reward/keep_balance: 0.9561
     Episode_Reward/rew_lin_vel_xy: 4.6791
      Episode_Reward/rew_ang_vel_z: 2.3236
    Episode_Reward/pen_base_height: -0.3329
      Episode_Reward/pen_lin_vel_z: -0.0485
     Episode_Reward/pen_ang_vel_xy: -0.1941
   Episode_Reward/pen_joint_torque: -0.2114
    Episode_Reward/pen_joint_accel: -0.1068
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0834
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2671
Episode_Reward/pen_flat_orientation: -0.1456
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3780
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.9120
Metrics/base_velocity/error_vel_xy: 1.6331
Metrics/base_velocity/error_vel_yaw: 1.3462
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 1.07s
                        Total time: 1099.00s
                               ETA: 2160.0s

################################################################################
                     [1m Learning iteration 1012/3000 [0m                     

                       Computation: 91882 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 1.0276
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9120
                     Learning rate: 0.0004
                       Mean reward: 99.19
               Mean episode length: 936.83
       Episode_Reward/keep_balance: 0.9427
     Episode_Reward/rew_lin_vel_xy: 4.5820
      Episode_Reward/rew_ang_vel_z: 2.3022
    Episode_Reward/pen_base_height: -0.3104
      Episode_Reward/pen_lin_vel_z: -0.0471
     Episode_Reward/pen_ang_vel_xy: -0.1881
   Episode_Reward/pen_joint_torque: -0.2158
    Episode_Reward/pen_joint_accel: -0.1144
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0824
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2569
Episode_Reward/pen_flat_orientation: -0.1325
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3629
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.8945
Metrics/base_velocity/error_vel_xy: 1.6035
Metrics/base_velocity/error_vel_yaw: 1.3018
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 1.07s
                        Total time: 1100.07s
                               ETA: 2158.9s

################################################################################
                     [1m Learning iteration 1013/3000 [0m                     

                       Computation: 91460 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 1.0283
                    Surrogate loss: -0.0026
             Mean action noise std: 0.9111
                     Learning rate: 0.0003
                       Mean reward: 103.45
               Mean episode length: 967.49
       Episode_Reward/keep_balance: 0.9708
     Episode_Reward/rew_lin_vel_xy: 4.8421
      Episode_Reward/rew_ang_vel_z: 2.4330
    Episode_Reward/pen_base_height: -0.3049
      Episode_Reward/pen_lin_vel_z: -0.0462
     Episode_Reward/pen_ang_vel_xy: -0.1927
   Episode_Reward/pen_joint_torque: -0.2192
    Episode_Reward/pen_joint_accel: -0.1220
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0539
   Episode_Reward/pen_joint_powers: -0.0824
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2643
Episode_Reward/pen_flat_orientation: -0.1337
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.3571
   Episode_Reward/foot_landing_vel: -0.1414
   Episode_Reward/test_gait_reward: -0.9158
Metrics/base_velocity/error_vel_xy: 1.7277
Metrics/base_velocity/error_vel_yaw: 1.2849
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 1.07s
                        Total time: 1101.14s
                               ETA: 2157.8s

################################################################################
                     [1m Learning iteration 1014/3000 [0m                     

                       Computation: 91910 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.9588
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9110
                     Learning rate: 0.0006
                       Mean reward: 102.93
               Mean episode length: 960.81
       Episode_Reward/keep_balance: 0.9647
     Episode_Reward/rew_lin_vel_xy: 4.7365
      Episode_Reward/rew_ang_vel_z: 2.3699
    Episode_Reward/pen_base_height: -0.3143
      Episode_Reward/pen_lin_vel_z: -0.0479
     Episode_Reward/pen_ang_vel_xy: -0.1948
   Episode_Reward/pen_joint_torque: -0.2153
    Episode_Reward/pen_joint_accel: -0.1202
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0833
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2656
Episode_Reward/pen_flat_orientation: -0.1324
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.3770
   Episode_Reward/foot_landing_vel: -0.1596
   Episode_Reward/test_gait_reward: -0.9072
Metrics/base_velocity/error_vel_xy: 1.6476
Metrics/base_velocity/error_vel_yaw: 1.3137
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 1.07s
                        Total time: 1102.21s
                               ETA: 2156.6s

################################################################################
                     [1m Learning iteration 1015/3000 [0m                     

                       Computation: 91834 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 1.0758
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9107
                     Learning rate: 0.0004
                       Mean reward: 99.12
               Mean episode length: 943.32
       Episode_Reward/keep_balance: 0.9328
     Episode_Reward/rew_lin_vel_xy: 4.6238
      Episode_Reward/rew_ang_vel_z: 2.3337
    Episode_Reward/pen_base_height: -0.2891
      Episode_Reward/pen_lin_vel_z: -0.0461
     Episode_Reward/pen_ang_vel_xy: -0.1769
   Episode_Reward/pen_joint_torque: -0.2084
    Episode_Reward/pen_joint_accel: -0.1028
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0516
   Episode_Reward/pen_joint_powers: -0.0788
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2508
Episode_Reward/pen_flat_orientation: -0.1230
  Episode_Reward/pen_feet_distance: -0.0062
Episode_Reward/pen_feet_regulation: -0.3399
   Episode_Reward/foot_landing_vel: -0.1462
   Episode_Reward/test_gait_reward: -0.8831
Metrics/base_velocity/error_vel_xy: 1.6235
Metrics/base_velocity/error_vel_yaw: 1.2390
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 1.07s
                        Total time: 1103.28s
                               ETA: 2155.5s

################################################################################
                     [1m Learning iteration 1016/3000 [0m                     

                       Computation: 91361 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.8832
                    Surrogate loss: -0.0038
             Mean action noise std: 0.9091
                     Learning rate: 0.0006
                       Mean reward: 101.14
               Mean episode length: 948.91
       Episode_Reward/keep_balance: 0.9542
     Episode_Reward/rew_lin_vel_xy: 4.7655
      Episode_Reward/rew_ang_vel_z: 2.3588
    Episode_Reward/pen_base_height: -0.3072
      Episode_Reward/pen_lin_vel_z: -0.0461
     Episode_Reward/pen_ang_vel_xy: -0.1907
   Episode_Reward/pen_joint_torque: -0.2150
    Episode_Reward/pen_joint_accel: -0.1141
    Episode_Reward/pen_action_rate: -0.1180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0831
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2605
Episode_Reward/pen_flat_orientation: -0.1334
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.3625
   Episode_Reward/foot_landing_vel: -0.1497
   Episode_Reward/test_gait_reward: -0.9037
Metrics/base_velocity/error_vel_xy: 1.5634
Metrics/base_velocity/error_vel_yaw: 1.2981
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 1.08s
                        Total time: 1104.36s
                               ETA: 2154.4s

################################################################################
                     [1m Learning iteration 1017/3000 [0m                     

                       Computation: 92067 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 0.8603
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9081
                     Learning rate: 0.0006
                       Mean reward: 105.55
               Mean episode length: 966.77
       Episode_Reward/keep_balance: 0.9701
     Episode_Reward/rew_lin_vel_xy: 4.9576
      Episode_Reward/rew_ang_vel_z: 2.4407
    Episode_Reward/pen_base_height: -0.3098
      Episode_Reward/pen_lin_vel_z: -0.0477
     Episode_Reward/pen_ang_vel_xy: -0.1927
   Episode_Reward/pen_joint_torque: -0.2175
    Episode_Reward/pen_joint_accel: -0.1101
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0832
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2645
Episode_Reward/pen_flat_orientation: -0.1296
  Episode_Reward/pen_feet_distance: -0.0111
Episode_Reward/pen_feet_regulation: -0.3663
   Episode_Reward/foot_landing_vel: -0.1462
   Episode_Reward/test_gait_reward: -0.9145
Metrics/base_velocity/error_vel_xy: 1.5532
Metrics/base_velocity/error_vel_yaw: 1.2834
      Episode_Termination/time_out: 4.8333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 1.07s
                        Total time: 1105.42s
                               ETA: 2153.3s

################################################################################
                     [1m Learning iteration 1018/3000 [0m                     

                       Computation: 92047 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.8904
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9092
                     Learning rate: 0.0006
                       Mean reward: 105.74
               Mean episode length: 967.83
       Episode_Reward/keep_balance: 0.9704
     Episode_Reward/rew_lin_vel_xy: 4.8174
      Episode_Reward/rew_ang_vel_z: 2.4128
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0479
     Episode_Reward/pen_ang_vel_xy: -0.1994
   Episode_Reward/pen_joint_torque: -0.2211
    Episode_Reward/pen_joint_accel: -0.1206
    Episode_Reward/pen_action_rate: -0.1212
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2683
Episode_Reward/pen_flat_orientation: -0.1282
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.3789
   Episode_Reward/foot_landing_vel: -0.1588
   Episode_Reward/test_gait_reward: -0.9182
Metrics/base_velocity/error_vel_xy: 1.6697
Metrics/base_velocity/error_vel_yaw: 1.3010
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 1.07s
                        Total time: 1106.49s
                               ETA: 2152.2s

################################################################################
                     [1m Learning iteration 1019/3000 [0m                     

                       Computation: 91557 steps/s (collection: 0.952s, learning 0.121s)
               Value function loss: 0.8996
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9096
                     Learning rate: 0.0006
                       Mean reward: 104.72
               Mean episode length: 973.48
       Episode_Reward/keep_balance: 0.9753
     Episode_Reward/rew_lin_vel_xy: 4.9400
      Episode_Reward/rew_ang_vel_z: 2.4563
    Episode_Reward/pen_base_height: -0.3195
      Episode_Reward/pen_lin_vel_z: -0.0478
     Episode_Reward/pen_ang_vel_xy: -0.1915
   Episode_Reward/pen_joint_torque: -0.2242
    Episode_Reward/pen_joint_accel: -0.1111
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0853
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2644
Episode_Reward/pen_flat_orientation: -0.1369
  Episode_Reward/pen_feet_distance: -0.0118
Episode_Reward/pen_feet_regulation: -0.3803
   Episode_Reward/foot_landing_vel: -0.1606
   Episode_Reward/test_gait_reward: -0.9256
Metrics/base_velocity/error_vel_xy: 1.5925
Metrics/base_velocity/error_vel_yaw: 1.2779
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 1.07s
                        Total time: 1107.57s
                               ETA: 2151.1s

################################################################################
                     [1m Learning iteration 1020/3000 [0m                     

                       Computation: 90644 steps/s (collection: 0.963s, learning 0.121s)
               Value function loss: 1.0235
                    Surrogate loss: -0.0044
             Mean action noise std: 0.9097
                     Learning rate: 0.0006
                       Mean reward: 102.93
               Mean episode length: 967.23
       Episode_Reward/keep_balance: 0.9733
     Episode_Reward/rew_lin_vel_xy: 4.7543
      Episode_Reward/rew_ang_vel_z: 2.3940
    Episode_Reward/pen_base_height: -0.3095
      Episode_Reward/pen_lin_vel_z: -0.0451
     Episode_Reward/pen_ang_vel_xy: -0.2018
   Episode_Reward/pen_joint_torque: -0.2146
    Episode_Reward/pen_joint_accel: -0.1197
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0847
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2721
Episode_Reward/pen_flat_orientation: -0.1322
  Episode_Reward/pen_feet_distance: -0.0108
Episode_Reward/pen_feet_regulation: -0.3803
   Episode_Reward/foot_landing_vel: -0.1525
   Episode_Reward/test_gait_reward: -0.9165
Metrics/base_velocity/error_vel_xy: 1.7197
Metrics/base_velocity/error_vel_yaw: 1.3346
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 1.08s
                        Total time: 1108.65s
                               ETA: 2150.0s

################################################################################
                     [1m Learning iteration 1021/3000 [0m                     

                       Computation: 91168 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.9838
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9090
                     Learning rate: 0.0009
                       Mean reward: 92.85
               Mean episode length: 916.61
       Episode_Reward/keep_balance: 0.9173
     Episode_Reward/rew_lin_vel_xy: 4.3955
      Episode_Reward/rew_ang_vel_z: 2.2504
    Episode_Reward/pen_base_height: -0.3093
      Episode_Reward/pen_lin_vel_z: -0.0470
     Episode_Reward/pen_ang_vel_xy: -0.1877
   Episode_Reward/pen_joint_torque: -0.2200
    Episode_Reward/pen_joint_accel: -0.1135
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0844
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2533
Episode_Reward/pen_flat_orientation: -0.1426
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3732
   Episode_Reward/foot_landing_vel: -0.1421
   Episode_Reward/test_gait_reward: -0.8729
Metrics/base_velocity/error_vel_xy: 1.6759
Metrics/base_velocity/error_vel_yaw: 1.2714
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 1.08s
                        Total time: 1109.73s
                               ETA: 2148.9s

################################################################################
                     [1m Learning iteration 1022/3000 [0m                     

                       Computation: 91595 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 1.0405
                    Surrogate loss: -0.0038
             Mean action noise std: 0.9095
                     Learning rate: 0.0013
                       Mean reward: 97.33
               Mean episode length: 946.05
       Episode_Reward/keep_balance: 0.9577
     Episode_Reward/rew_lin_vel_xy: 4.6833
      Episode_Reward/rew_ang_vel_z: 2.3538
    Episode_Reward/pen_base_height: -0.3146
      Episode_Reward/pen_lin_vel_z: -0.0479
     Episode_Reward/pen_ang_vel_xy: -0.2020
   Episode_Reward/pen_joint_torque: -0.2173
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.1211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2668
Episode_Reward/pen_flat_orientation: -0.1372
  Episode_Reward/pen_feet_distance: -0.0117
Episode_Reward/pen_feet_regulation: -0.3841
   Episode_Reward/foot_landing_vel: -0.1516
   Episode_Reward/test_gait_reward: -0.9066
Metrics/base_velocity/error_vel_xy: 1.6848
Metrics/base_velocity/error_vel_yaw: 1.3065
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 1.07s
                        Total time: 1110.80s
                               ETA: 2147.8s

################################################################################
                     [1m Learning iteration 1023/3000 [0m                     

                       Computation: 90404 steps/s (collection: 0.959s, learning 0.128s)
               Value function loss: 1.1087
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9102
                     Learning rate: 0.0003
                       Mean reward: 101.71
               Mean episode length: 947.82
       Episode_Reward/keep_balance: 0.9396
     Episode_Reward/rew_lin_vel_xy: 4.7288
      Episode_Reward/rew_ang_vel_z: 2.3398
    Episode_Reward/pen_base_height: -0.2962
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.1863
   Episode_Reward/pen_joint_torque: -0.2077
    Episode_Reward/pen_joint_accel: -0.1068
    Episode_Reward/pen_action_rate: -0.1148
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0512
   Episode_Reward/pen_joint_powers: -0.0793
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2557
Episode_Reward/pen_flat_orientation: -0.1306
  Episode_Reward/pen_feet_distance: -0.0075
Episode_Reward/pen_feet_regulation: -0.3397
   Episode_Reward/foot_landing_vel: -0.1310
   Episode_Reward/test_gait_reward: -0.8871
Metrics/base_velocity/error_vel_xy: 1.5748
Metrics/base_velocity/error_vel_yaw: 1.2648
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 1.09s
                        Total time: 1111.89s
                               ETA: 2146.7s

################################################################################
                     [1m Learning iteration 1024/3000 [0m                     

                       Computation: 90489 steps/s (collection: 0.958s, learning 0.128s)
               Value function loss: 1.0164
                    Surrogate loss: -0.0059
             Mean action noise std: 0.9105
                     Learning rate: 0.0009
                       Mean reward: 104.23
               Mean episode length: 964.15
       Episode_Reward/keep_balance: 0.9717
     Episode_Reward/rew_lin_vel_xy: 4.9471
      Episode_Reward/rew_ang_vel_z: 2.3737
    Episode_Reward/pen_base_height: -0.3114
      Episode_Reward/pen_lin_vel_z: -0.0469
     Episode_Reward/pen_ang_vel_xy: -0.1953
   Episode_Reward/pen_joint_torque: -0.2186
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0556
   Episode_Reward/pen_joint_powers: -0.0836
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2682
Episode_Reward/pen_flat_orientation: -0.1361
  Episode_Reward/pen_feet_distance: -0.0059
Episode_Reward/pen_feet_regulation: -0.3615
   Episode_Reward/foot_landing_vel: -0.1445
   Episode_Reward/test_gait_reward: -0.9223
Metrics/base_velocity/error_vel_xy: 1.5783
Metrics/base_velocity/error_vel_yaw: 1.3429
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 1.09s
                        Total time: 1112.98s
                               ETA: 2145.6s

################################################################################
                     [1m Learning iteration 1025/3000 [0m                     

                       Computation: 90531 steps/s (collection: 0.958s, learning 0.128s)
               Value function loss: 1.0677
                    Surrogate loss: -0.0030
             Mean action noise std: 0.9118
                     Learning rate: 0.0006
                       Mean reward: 110.33
               Mean episode length: 981.59
       Episode_Reward/keep_balance: 0.9748
     Episode_Reward/rew_lin_vel_xy: 5.0396
      Episode_Reward/rew_ang_vel_z: 2.4579
    Episode_Reward/pen_base_height: -0.3069
      Episode_Reward/pen_lin_vel_z: -0.0452
     Episode_Reward/pen_ang_vel_xy: -0.1910
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.1240
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0537
   Episode_Reward/pen_joint_powers: -0.0831
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2623
Episode_Reward/pen_flat_orientation: -0.1280
  Episode_Reward/pen_feet_distance: -0.0096
Episode_Reward/pen_feet_regulation: -0.3514
   Episode_Reward/foot_landing_vel: -0.1449
   Episode_Reward/test_gait_reward: -0.9217
Metrics/base_velocity/error_vel_xy: 1.5271
Metrics/base_velocity/error_vel_yaw: 1.2678
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 1.09s
                        Total time: 1114.06s
                               ETA: 2144.5s

################################################################################
                     [1m Learning iteration 1026/3000 [0m                     

                       Computation: 89785 steps/s (collection: 0.965s, learning 0.130s)
               Value function loss: 0.9919
                    Surrogate loss: -0.0032
             Mean action noise std: 0.9118
                     Learning rate: 0.0009
                       Mean reward: 99.89
               Mean episode length: 920.83
       Episode_Reward/keep_balance: 0.9331
     Episode_Reward/rew_lin_vel_xy: 4.7481
      Episode_Reward/rew_ang_vel_z: 2.3333
    Episode_Reward/pen_base_height: -0.2943
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.1887
   Episode_Reward/pen_joint_torque: -0.2079
    Episode_Reward/pen_joint_accel: -0.1131
    Episode_Reward/pen_action_rate: -0.1147
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0534
   Episode_Reward/pen_joint_powers: -0.0812
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2540
Episode_Reward/pen_flat_orientation: -0.1293
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3493
   Episode_Reward/foot_landing_vel: -0.1448
   Episode_Reward/test_gait_reward: -0.8860
Metrics/base_velocity/error_vel_xy: 1.5451
Metrics/base_velocity/error_vel_yaw: 1.2435
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 1.09s
                        Total time: 1115.16s
                               ETA: 2143.4s

################################################################################
                     [1m Learning iteration 1027/3000 [0m                     

                       Computation: 89971 steps/s (collection: 0.964s, learning 0.128s)
               Value function loss: 0.9605
                    Surrogate loss: -0.0030
             Mean action noise std: 0.9106
                     Learning rate: 0.0006
                       Mean reward: 101.73
               Mean episode length: 950.34
       Episode_Reward/keep_balance: 0.9290
     Episode_Reward/rew_lin_vel_xy: 4.6664
      Episode_Reward/rew_ang_vel_z: 2.2724
    Episode_Reward/pen_base_height: -0.3078
      Episode_Reward/pen_lin_vel_z: -0.0432
     Episode_Reward/pen_ang_vel_xy: -0.1938
   Episode_Reward/pen_joint_torque: -0.2047
    Episode_Reward/pen_joint_accel: -0.1072
    Episode_Reward/pen_action_rate: -0.1168
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0529
   Episode_Reward/pen_joint_powers: -0.0801
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2587
Episode_Reward/pen_flat_orientation: -0.1354
  Episode_Reward/pen_feet_distance: -0.0100
Episode_Reward/pen_feet_regulation: -0.3495
   Episode_Reward/foot_landing_vel: -0.1360
   Episode_Reward/test_gait_reward: -0.8822
Metrics/base_velocity/error_vel_xy: 1.5468
Metrics/base_velocity/error_vel_yaw: 1.2963
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 1.09s
                        Total time: 1116.25s
                               ETA: 2142.4s

################################################################################
                     [1m Learning iteration 1028/3000 [0m                     

                       Computation: 90632 steps/s (collection: 0.956s, learning 0.128s)
               Value function loss: 1.0928
                    Surrogate loss: -0.0018
             Mean action noise std: 0.9103
                     Learning rate: 0.0004
                       Mean reward: 99.09
               Mean episode length: 926.82
       Episode_Reward/keep_balance: 0.9353
     Episode_Reward/rew_lin_vel_xy: 4.6800
      Episode_Reward/rew_ang_vel_z: 2.3043
    Episode_Reward/pen_base_height: -0.3088
      Episode_Reward/pen_lin_vel_z: -0.0469
     Episode_Reward/pen_ang_vel_xy: -0.1961
   Episode_Reward/pen_joint_torque: -0.2132
    Episode_Reward/pen_joint_accel: -0.1172
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0838
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2608
Episode_Reward/pen_flat_orientation: -0.1317
  Episode_Reward/pen_feet_distance: -0.0088
Episode_Reward/pen_feet_regulation: -0.3714
   Episode_Reward/foot_landing_vel: -0.1458
   Episode_Reward/test_gait_reward: -0.8922
Metrics/base_velocity/error_vel_xy: 1.5599
Metrics/base_velocity/error_vel_yaw: 1.2932
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 1.08s
                        Total time: 1117.33s
                               ETA: 2141.3s

################################################################################
                     [1m Learning iteration 1029/3000 [0m                     

                       Computation: 91174 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.9954
                    Surrogate loss: -0.0030
             Mean action noise std: 0.9077
                     Learning rate: 0.0006
                       Mean reward: 99.54
               Mean episode length: 938.20
       Episode_Reward/keep_balance: 0.9413
     Episode_Reward/rew_lin_vel_xy: 4.7545
      Episode_Reward/rew_ang_vel_z: 2.3097
    Episode_Reward/pen_base_height: -0.3048
      Episode_Reward/pen_lin_vel_z: -0.0440
     Episode_Reward/pen_ang_vel_xy: -0.2032
   Episode_Reward/pen_joint_torque: -0.2000
    Episode_Reward/pen_joint_accel: -0.1196
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0824
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2650
Episode_Reward/pen_flat_orientation: -0.1335
  Episode_Reward/pen_feet_distance: -0.0108
Episode_Reward/pen_feet_regulation: -0.3669
   Episode_Reward/foot_landing_vel: -0.1502
   Episode_Reward/test_gait_reward: -0.8948
Metrics/base_velocity/error_vel_xy: 1.5193
Metrics/base_velocity/error_vel_yaw: 1.3043
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 1.08s
                        Total time: 1118.41s
                               ETA: 2140.2s

################################################################################
                     [1m Learning iteration 1030/3000 [0m                     

                       Computation: 91014 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.9224
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9075
                     Learning rate: 0.0004
                       Mean reward: 102.94
               Mean episode length: 940.43
       Episode_Reward/keep_balance: 0.9404
     Episode_Reward/rew_lin_vel_xy: 4.8208
      Episode_Reward/rew_ang_vel_z: 2.3096
    Episode_Reward/pen_base_height: -0.3030
      Episode_Reward/pen_lin_vel_z: -0.0459
     Episode_Reward/pen_ang_vel_xy: -0.1935
   Episode_Reward/pen_joint_torque: -0.2102
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0831
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2633
Episode_Reward/pen_flat_orientation: -0.1318
  Episode_Reward/pen_feet_distance: -0.0078
Episode_Reward/pen_feet_regulation: -0.3698
   Episode_Reward/foot_landing_vel: -0.1537
   Episode_Reward/test_gait_reward: -0.8868
Metrics/base_velocity/error_vel_xy: 1.5098
Metrics/base_velocity/error_vel_yaw: 1.2936
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 1.08s
                        Total time: 1119.49s
                               ETA: 2139.1s

################################################################################
                     [1m Learning iteration 1031/3000 [0m                     

                       Computation: 90816 steps/s (collection: 0.958s, learning 0.125s)
               Value function loss: 0.9959
                    Surrogate loss: -0.0050
             Mean action noise std: 0.9078
                     Learning rate: 0.0006
                       Mean reward: 101.75
               Mean episode length: 943.67
       Episode_Reward/keep_balance: 0.9376
     Episode_Reward/rew_lin_vel_xy: 4.7388
      Episode_Reward/rew_ang_vel_z: 2.2820
    Episode_Reward/pen_base_height: -0.3050
      Episode_Reward/pen_lin_vel_z: -0.0467
     Episode_Reward/pen_ang_vel_xy: -0.1927
   Episode_Reward/pen_joint_torque: -0.2116
    Episode_Reward/pen_joint_accel: -0.1122
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0839
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2626
Episode_Reward/pen_flat_orientation: -0.1328
  Episode_Reward/pen_feet_distance: -0.0093
Episode_Reward/pen_feet_regulation: -0.3752
   Episode_Reward/foot_landing_vel: -0.1463
   Episode_Reward/test_gait_reward: -0.8862
Metrics/base_velocity/error_vel_xy: 1.5424
Metrics/base_velocity/error_vel_yaw: 1.3181
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 1.08s
                        Total time: 1120.57s
                               ETA: 2138.0s

################################################################################
                     [1m Learning iteration 1032/3000 [0m                     

                       Computation: 90461 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.9490
                    Surrogate loss: -0.0018
             Mean action noise std: 0.9070
                     Learning rate: 0.0006
                       Mean reward: 103.72
               Mean episode length: 935.54
       Episode_Reward/keep_balance: 0.9421
     Episode_Reward/rew_lin_vel_xy: 4.8558
      Episode_Reward/rew_ang_vel_z: 2.3618
    Episode_Reward/pen_base_height: -0.3089
      Episode_Reward/pen_lin_vel_z: -0.0459
     Episode_Reward/pen_ang_vel_xy: -0.1916
   Episode_Reward/pen_joint_torque: -0.2211
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0839
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2585
Episode_Reward/pen_flat_orientation: -0.1304
  Episode_Reward/pen_feet_distance: -0.0104
Episode_Reward/pen_feet_regulation: -0.3610
   Episode_Reward/foot_landing_vel: -0.1451
   Episode_Reward/test_gait_reward: -0.8874
Metrics/base_velocity/error_vel_xy: 1.5019
Metrics/base_velocity/error_vel_yaw: 1.2567
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 1.09s
                        Total time: 1121.66s
                               ETA: 2136.9s

################################################################################
                     [1m Learning iteration 1033/3000 [0m                     

                       Computation: 90228 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.8849
                    Surrogate loss: -0.0024
             Mean action noise std: 0.9061
                     Learning rate: 0.0004
                       Mean reward: 95.28
               Mean episode length: 920.32
       Episode_Reward/keep_balance: 0.9341
     Episode_Reward/rew_lin_vel_xy: 4.6259
      Episode_Reward/rew_ang_vel_z: 2.3262
    Episode_Reward/pen_base_height: -0.3068
      Episode_Reward/pen_lin_vel_z: -0.0472
     Episode_Reward/pen_ang_vel_xy: -0.1846
   Episode_Reward/pen_joint_torque: -0.2198
    Episode_Reward/pen_joint_accel: -0.1190
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0846
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2546
Episode_Reward/pen_flat_orientation: -0.1313
  Episode_Reward/pen_feet_distance: -0.0090
Episode_Reward/pen_feet_regulation: -0.3600
   Episode_Reward/foot_landing_vel: -0.1506
   Episode_Reward/test_gait_reward: -0.8810
Metrics/base_velocity/error_vel_xy: 1.6135
Metrics/base_velocity/error_vel_yaw: 1.2532
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 1.09s
                        Total time: 1122.75s
                               ETA: 2135.8s

################################################################################
                     [1m Learning iteration 1034/3000 [0m                     

                       Computation: 91447 steps/s (collection: 0.951s, learning 0.124s)
               Value function loss: 0.9689
                    Surrogate loss: -0.0053
             Mean action noise std: 0.9039
                     Learning rate: 0.0006
                       Mean reward: 106.95
               Mean episode length: 966.22
       Episode_Reward/keep_balance: 0.9725
     Episode_Reward/rew_lin_vel_xy: 5.1018
      Episode_Reward/rew_ang_vel_z: 2.3978
    Episode_Reward/pen_base_height: -0.3157
      Episode_Reward/pen_lin_vel_z: -0.0496
     Episode_Reward/pen_ang_vel_xy: -0.1978
   Episode_Reward/pen_joint_torque: -0.2256
    Episode_Reward/pen_joint_accel: -0.1192
    Episode_Reward/pen_action_rate: -0.1232
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2697
Episode_Reward/pen_flat_orientation: -0.1361
  Episode_Reward/pen_feet_distance: -0.0092
Episode_Reward/pen_feet_regulation: -0.3936
   Episode_Reward/foot_landing_vel: -0.1545
   Episode_Reward/test_gait_reward: -0.9224
Metrics/base_velocity/error_vel_xy: 1.4508
Metrics/base_velocity/error_vel_yaw: 1.3214
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 1.07s
                        Total time: 1123.83s
                               ETA: 2134.7s

################################################################################
                     [1m Learning iteration 1035/3000 [0m                     

                       Computation: 90269 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.9114
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9025
                     Learning rate: 0.0004
                       Mean reward: 103.67
               Mean episode length: 961.67
       Episode_Reward/keep_balance: 0.9632
     Episode_Reward/rew_lin_vel_xy: 4.9093
      Episode_Reward/rew_ang_vel_z: 2.3306
    Episode_Reward/pen_base_height: -0.3084
      Episode_Reward/pen_lin_vel_z: -0.0448
     Episode_Reward/pen_ang_vel_xy: -0.1961
   Episode_Reward/pen_joint_torque: -0.2105
    Episode_Reward/pen_joint_accel: -0.1222
    Episode_Reward/pen_action_rate: -0.1229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0848
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2724
Episode_Reward/pen_flat_orientation: -0.1357
  Episode_Reward/pen_feet_distance: -0.0089
Episode_Reward/pen_feet_regulation: -0.3800
   Episode_Reward/foot_landing_vel: -0.1505
   Episode_Reward/test_gait_reward: -0.9213
Metrics/base_velocity/error_vel_xy: 1.5667
Metrics/base_velocity/error_vel_yaw: 1.3692
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 1.09s
                        Total time: 1124.92s
                               ETA: 2133.6s

################################################################################
                     [1m Learning iteration 1036/3000 [0m                     

                       Computation: 91186 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.9742
                    Surrogate loss: -0.0030
             Mean action noise std: 0.9038
                     Learning rate: 0.0009
                       Mean reward: 108.03
               Mean episode length: 965.51
       Episode_Reward/keep_balance: 0.9541
     Episode_Reward/rew_lin_vel_xy: 4.8656
      Episode_Reward/rew_ang_vel_z: 2.3597
    Episode_Reward/pen_base_height: -0.2968
      Episode_Reward/pen_lin_vel_z: -0.0429
     Episode_Reward/pen_ang_vel_xy: -0.1918
   Episode_Reward/pen_joint_torque: -0.2078
    Episode_Reward/pen_joint_accel: -0.1228
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0819
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2644
Episode_Reward/pen_flat_orientation: -0.1288
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.3619
   Episode_Reward/foot_landing_vel: -0.1492
   Episode_Reward/test_gait_reward: -0.9049
Metrics/base_velocity/error_vel_xy: 1.5575
Metrics/base_velocity/error_vel_yaw: 1.2976
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 1.08s
                        Total time: 1125.99s
                               ETA: 2132.5s

################################################################################
                     [1m Learning iteration 1037/3000 [0m                     

                       Computation: 91384 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.9878
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9043
                     Learning rate: 0.0013
                       Mean reward: 101.92
               Mean episode length: 959.74
       Episode_Reward/keep_balance: 0.9697
     Episode_Reward/rew_lin_vel_xy: 4.7871
      Episode_Reward/rew_ang_vel_z: 2.3912
    Episode_Reward/pen_base_height: -0.3169
      Episode_Reward/pen_lin_vel_z: -0.0481
     Episode_Reward/pen_ang_vel_xy: -0.1949
   Episode_Reward/pen_joint_torque: -0.2318
    Episode_Reward/pen_joint_accel: -0.1189
    Episode_Reward/pen_action_rate: -0.1216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2671
Episode_Reward/pen_flat_orientation: -0.1307
  Episode_Reward/pen_feet_distance: -0.0085
Episode_Reward/pen_feet_regulation: -0.3762
   Episode_Reward/foot_landing_vel: -0.1493
   Episode_Reward/test_gait_reward: -0.9197
Metrics/base_velocity/error_vel_xy: 1.7361
Metrics/base_velocity/error_vel_yaw: 1.3188
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 1.08s
                        Total time: 1127.07s
                               ETA: 2131.4s

################################################################################
                     [1m Learning iteration 1038/3000 [0m                     

                       Computation: 90385 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 1.0310
                    Surrogate loss: -0.0021
             Mean action noise std: 0.9039
                     Learning rate: 0.0006
                       Mean reward: 105.87
               Mean episode length: 954.96
       Episode_Reward/keep_balance: 0.9668
     Episode_Reward/rew_lin_vel_xy: 5.0513
      Episode_Reward/rew_ang_vel_z: 2.4393
    Episode_Reward/pen_base_height: -0.3086
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.1928
   Episode_Reward/pen_joint_torque: -0.2197
    Episode_Reward/pen_joint_accel: -0.1159
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0841
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2615
Episode_Reward/pen_flat_orientation: -0.1279
  Episode_Reward/pen_feet_distance: -0.0140
Episode_Reward/pen_feet_regulation: -0.3645
   Episode_Reward/foot_landing_vel: -0.1470
   Episode_Reward/test_gait_reward: -0.9147
Metrics/base_velocity/error_vel_xy: 1.5076
Metrics/base_velocity/error_vel_yaw: 1.2593
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 1.09s
                        Total time: 1128.16s
                               ETA: 2130.4s

################################################################################
                     [1m Learning iteration 1039/3000 [0m                     

                       Computation: 91967 steps/s (collection: 0.945s, learning 0.124s)
               Value function loss: 0.8990
                    Surrogate loss: -0.0030
             Mean action noise std: 0.9038
                     Learning rate: 0.0006
                       Mean reward: 102.89
               Mean episode length: 943.89
       Episode_Reward/keep_balance: 0.9383
     Episode_Reward/rew_lin_vel_xy: 4.8418
      Episode_Reward/rew_ang_vel_z: 2.3039
    Episode_Reward/pen_base_height: -0.2953
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.1879
   Episode_Reward/pen_joint_torque: -0.2052
    Episode_Reward/pen_joint_accel: -0.1162
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0541
   Episode_Reward/pen_joint_powers: -0.0815
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2582
Episode_Reward/pen_flat_orientation: -0.1300
  Episode_Reward/pen_feet_distance: -0.0105
Episode_Reward/pen_feet_regulation: -0.3630
   Episode_Reward/foot_landing_vel: -0.1426
   Episode_Reward/test_gait_reward: -0.8947
Metrics/base_velocity/error_vel_xy: 1.4653
Metrics/base_velocity/error_vel_yaw: 1.2867
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 1.07s
                        Total time: 1129.23s
                               ETA: 2129.2s

################################################################################
                     [1m Learning iteration 1040/3000 [0m                     

                       Computation: 91665 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.9950
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9043
                     Learning rate: 0.0003
                       Mean reward: 103.56
               Mean episode length: 951.32
       Episode_Reward/keep_balance: 0.9624
     Episode_Reward/rew_lin_vel_xy: 4.8798
      Episode_Reward/rew_ang_vel_z: 2.3723
    Episode_Reward/pen_base_height: -0.3027
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.1928
   Episode_Reward/pen_joint_torque: -0.2129
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0827
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2675
Episode_Reward/pen_flat_orientation: -0.1190
  Episode_Reward/pen_feet_distance: -0.0068
Episode_Reward/pen_feet_regulation: -0.3509
   Episode_Reward/foot_landing_vel: -0.1444
   Episode_Reward/test_gait_reward: -0.9024
Metrics/base_velocity/error_vel_xy: 1.5964
Metrics/base_velocity/error_vel_yaw: 1.3126
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 1.07s
                        Total time: 1130.30s
                               ETA: 2128.1s

################################################################################
                     [1m Learning iteration 1041/3000 [0m                     

                       Computation: 91200 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.9256
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9039
                     Learning rate: 0.0004
                       Mean reward: 96.61
               Mean episode length: 957.46
       Episode_Reward/keep_balance: 0.9625
     Episode_Reward/rew_lin_vel_xy: 4.5170
      Episode_Reward/rew_ang_vel_z: 2.3470
    Episode_Reward/pen_base_height: -0.3234
      Episode_Reward/pen_lin_vel_z: -0.0474
     Episode_Reward/pen_ang_vel_xy: -0.1959
   Episode_Reward/pen_joint_torque: -0.2271
    Episode_Reward/pen_joint_accel: -0.1123
    Episode_Reward/pen_action_rate: -0.1225
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2689
Episode_Reward/pen_flat_orientation: -0.1358
  Episode_Reward/pen_feet_distance: -0.0124
Episode_Reward/pen_feet_regulation: -0.3920
   Episode_Reward/foot_landing_vel: -0.1510
   Episode_Reward/test_gait_reward: -0.9092
Metrics/base_velocity/error_vel_xy: 1.8494
Metrics/base_velocity/error_vel_yaw: 1.3433
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 1.08s
                        Total time: 1131.38s
                               ETA: 2127.0s

################################################################################
                     [1m Learning iteration 1042/3000 [0m                     

                       Computation: 91483 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.8671
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9049
                     Learning rate: 0.0006
                       Mean reward: 105.70
               Mean episode length: 944.96
       Episode_Reward/keep_balance: 0.9479
     Episode_Reward/rew_lin_vel_xy: 4.9210
      Episode_Reward/rew_ang_vel_z: 2.3614
    Episode_Reward/pen_base_height: -0.3091
      Episode_Reward/pen_lin_vel_z: -0.0440
     Episode_Reward/pen_ang_vel_xy: -0.1867
   Episode_Reward/pen_joint_torque: -0.2092
    Episode_Reward/pen_joint_accel: -0.1106
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0824
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2599
Episode_Reward/pen_flat_orientation: -0.1327
  Episode_Reward/pen_feet_distance: -0.0108
Episode_Reward/pen_feet_regulation: -0.3646
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.8946
Metrics/base_velocity/error_vel_xy: 1.4808
Metrics/base_velocity/error_vel_yaw: 1.2727
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 1.07s
                        Total time: 1132.45s
                               ETA: 2125.9s

################################################################################
                     [1m Learning iteration 1043/3000 [0m                     

                       Computation: 91331 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.8872
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9062
                     Learning rate: 0.0009
                       Mean reward: 107.85
               Mean episode length: 975.55
       Episode_Reward/keep_balance: 0.9739
     Episode_Reward/rew_lin_vel_xy: 5.1507
      Episode_Reward/rew_ang_vel_z: 2.4057
    Episode_Reward/pen_base_height: -0.3160
      Episode_Reward/pen_lin_vel_z: -0.0483
     Episode_Reward/pen_ang_vel_xy: -0.2006
   Episode_Reward/pen_joint_torque: -0.2251
    Episode_Reward/pen_joint_accel: -0.1294
    Episode_Reward/pen_action_rate: -0.1243
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2739
Episode_Reward/pen_flat_orientation: -0.1250
  Episode_Reward/pen_feet_distance: -0.0090
Episode_Reward/pen_feet_regulation: -0.3985
   Episode_Reward/foot_landing_vel: -0.1546
   Episode_Reward/test_gait_reward: -0.9224
Metrics/base_velocity/error_vel_xy: 1.4261
Metrics/base_velocity/error_vel_yaw: 1.3267
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 1.08s
                        Total time: 1133.53s
                               ETA: 2124.8s

################################################################################
                     [1m Learning iteration 1044/3000 [0m                     

                       Computation: 92331 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 0.9348
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9076
                     Learning rate: 0.0004
                       Mean reward: 100.10
               Mean episode length: 943.83
       Episode_Reward/keep_balance: 0.9384
     Episode_Reward/rew_lin_vel_xy: 4.6147
      Episode_Reward/rew_ang_vel_z: 2.2264
    Episode_Reward/pen_base_height: -0.3019
      Episode_Reward/pen_lin_vel_z: -0.0429
     Episode_Reward/pen_ang_vel_xy: -0.1982
   Episode_Reward/pen_joint_torque: -0.2061
    Episode_Reward/pen_joint_accel: -0.1326
    Episode_Reward/pen_action_rate: -0.1217
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0849
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2687
Episode_Reward/pen_flat_orientation: -0.1301
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.3819
   Episode_Reward/foot_landing_vel: -0.1586
   Episode_Reward/test_gait_reward: -0.8888
Metrics/base_velocity/error_vel_xy: 1.6419
Metrics/base_velocity/error_vel_yaw: 1.3699
      Episode_Termination/time_out: 3.0833
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 1.06s
                        Total time: 1134.59s
                               ETA: 2123.7s

################################################################################
                     [1m Learning iteration 1045/3000 [0m                     

                       Computation: 89764 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.9807
                    Surrogate loss: -0.0028
             Mean action noise std: 0.9088
                     Learning rate: 0.0004
                       Mean reward: 105.25
               Mean episode length: 937.27
       Episode_Reward/keep_balance: 0.9296
     Episode_Reward/rew_lin_vel_xy: 4.7685
      Episode_Reward/rew_ang_vel_z: 2.2889
    Episode_Reward/pen_base_height: -0.2921
      Episode_Reward/pen_lin_vel_z: -0.0428
     Episode_Reward/pen_ang_vel_xy: -0.1832
   Episode_Reward/pen_joint_torque: -0.2122
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.1149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0524
   Episode_Reward/pen_joint_powers: -0.0811
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2549
Episode_Reward/pen_flat_orientation: -0.1199
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.3351
   Episode_Reward/foot_landing_vel: -0.1320
   Episode_Reward/test_gait_reward: -0.8780
Metrics/base_velocity/error_vel_xy: 1.4686
Metrics/base_velocity/error_vel_yaw: 1.2718
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 1.10s
                        Total time: 1135.69s
                               ETA: 2122.6s

################################################################################
                     [1m Learning iteration 1046/3000 [0m                     

                       Computation: 90189 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.9334
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9101
                     Learning rate: 0.0006
                       Mean reward: 105.08
               Mean episode length: 959.23
       Episode_Reward/keep_balance: 0.9630
     Episode_Reward/rew_lin_vel_xy: 4.8762
      Episode_Reward/rew_ang_vel_z: 2.3860
    Episode_Reward/pen_base_height: -0.3083
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.1939
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.1170
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0855
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2659
Episode_Reward/pen_flat_orientation: -0.1278
  Episode_Reward/pen_feet_distance: -0.0092
Episode_Reward/pen_feet_regulation: -0.3693
   Episode_Reward/foot_landing_vel: -0.1472
   Episode_Reward/test_gait_reward: -0.9059
Metrics/base_velocity/error_vel_xy: 1.6142
Metrics/base_velocity/error_vel_yaw: 1.3181
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 1.09s
                        Total time: 1136.78s
                               ETA: 2121.5s

################################################################################
                     [1m Learning iteration 1047/3000 [0m                     

                       Computation: 90635 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.9602
                    Surrogate loss: -0.0001
             Mean action noise std: 0.9108
                     Learning rate: 0.0002
                       Mean reward: 107.23
               Mean episode length: 957.17
       Episode_Reward/keep_balance: 0.9640
     Episode_Reward/rew_lin_vel_xy: 4.9419
      Episode_Reward/rew_ang_vel_z: 2.3872
    Episode_Reward/pen_base_height: -0.2970
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.1930
   Episode_Reward/pen_joint_torque: -0.2152
    Episode_Reward/pen_joint_accel: -0.1169
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0847
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2655
Episode_Reward/pen_flat_orientation: -0.1255
  Episode_Reward/pen_feet_distance: -0.0082
Episode_Reward/pen_feet_regulation: -0.3735
   Episode_Reward/foot_landing_vel: -0.1466
   Episode_Reward/test_gait_reward: -0.9119
Metrics/base_velocity/error_vel_xy: 1.5159
Metrics/base_velocity/error_vel_yaw: 1.3030
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 1.08s
                        Total time: 1137.86s
                               ETA: 2120.5s

################################################################################
                     [1m Learning iteration 1048/3000 [0m                     

                       Computation: 90279 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.7951
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9110
                     Learning rate: 0.0003
                       Mean reward: 111.13
               Mean episode length: 970.67
       Episode_Reward/keep_balance: 0.9651
     Episode_Reward/rew_lin_vel_xy: 5.0864
      Episode_Reward/rew_ang_vel_z: 2.4326
    Episode_Reward/pen_base_height: -0.2947
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.1862
   Episode_Reward/pen_joint_torque: -0.2130
    Episode_Reward/pen_joint_accel: -0.1127
    Episode_Reward/pen_action_rate: -0.1177
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0533
   Episode_Reward/pen_joint_powers: -0.0812
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2633
Episode_Reward/pen_flat_orientation: -0.1156
  Episode_Reward/pen_feet_distance: -0.0084
Episode_Reward/pen_feet_regulation: -0.3511
   Episode_Reward/foot_landing_vel: -0.1473
   Episode_Reward/test_gait_reward: -0.9005
Metrics/base_velocity/error_vel_xy: 1.4858
Metrics/base_velocity/error_vel_yaw: 1.2616
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 1.09s
                        Total time: 1138.95s
                               ETA: 2119.4s

################################################################################
                     [1m Learning iteration 1049/3000 [0m                     

                       Computation: 90286 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 1.0137
                    Surrogate loss: -0.0056
             Mean action noise std: 0.9134
                     Learning rate: 0.0006
                       Mean reward: 105.47
               Mean episode length: 965.90
       Episode_Reward/keep_balance: 0.9687
     Episode_Reward/rew_lin_vel_xy: 4.8742
      Episode_Reward/rew_ang_vel_z: 2.3691
    Episode_Reward/pen_base_height: -0.3095
      Episode_Reward/pen_lin_vel_z: -0.0452
     Episode_Reward/pen_ang_vel_xy: -0.1962
   Episode_Reward/pen_joint_torque: -0.2183
    Episode_Reward/pen_joint_accel: -0.1219
    Episode_Reward/pen_action_rate: -0.1224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2688
Episode_Reward/pen_flat_orientation: -0.1286
  Episode_Reward/pen_feet_distance: -0.0119
Episode_Reward/pen_feet_regulation: -0.3709
   Episode_Reward/foot_landing_vel: -0.1541
   Episode_Reward/test_gait_reward: -0.9216
Metrics/base_velocity/error_vel_xy: 1.6069
Metrics/base_velocity/error_vel_yaw: 1.3413
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 1.09s
                        Total time: 1140.04s
                               ETA: 2118.3s

################################################################################
                     [1m Learning iteration 1050/3000 [0m                     

                       Computation: 88908 steps/s (collection: 0.981s, learning 0.124s)
               Value function loss: 0.9681
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9155
                     Learning rate: 0.0006
                       Mean reward: 101.72
               Mean episode length: 935.06
       Episode_Reward/keep_balance: 0.9359
     Episode_Reward/rew_lin_vel_xy: 4.8379
      Episode_Reward/rew_ang_vel_z: 2.2737
    Episode_Reward/pen_base_height: -0.2978
      Episode_Reward/pen_lin_vel_z: -0.0441
     Episode_Reward/pen_ang_vel_xy: -0.1916
   Episode_Reward/pen_joint_torque: -0.2111
    Episode_Reward/pen_joint_accel: -0.1147
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0838
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2621
Episode_Reward/pen_flat_orientation: -0.1245
  Episode_Reward/pen_feet_distance: -0.0106
Episode_Reward/pen_feet_regulation: -0.3719
   Episode_Reward/foot_landing_vel: -0.1437
   Episode_Reward/test_gait_reward: -0.8886
Metrics/base_velocity/error_vel_xy: 1.4883
Metrics/base_velocity/error_vel_yaw: 1.3117
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 1.11s
                        Total time: 1141.14s
                               ETA: 2117.3s

################################################################################
                     [1m Learning iteration 1051/3000 [0m                     

                       Computation: 90619 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 1.0227
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9165
                     Learning rate: 0.0006
                       Mean reward: 106.65
               Mean episode length: 963.10
       Episode_Reward/keep_balance: 0.9640
     Episode_Reward/rew_lin_vel_xy: 4.9991
      Episode_Reward/rew_ang_vel_z: 2.3790
    Episode_Reward/pen_base_height: -0.3060
      Episode_Reward/pen_lin_vel_z: -0.0456
     Episode_Reward/pen_ang_vel_xy: -0.1963
   Episode_Reward/pen_joint_torque: -0.2202
    Episode_Reward/pen_joint_accel: -0.1072
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2669
Episode_Reward/pen_flat_orientation: -0.1250
  Episode_Reward/pen_feet_distance: -0.0139
Episode_Reward/pen_feet_regulation: -0.3714
   Episode_Reward/foot_landing_vel: -0.1492
   Episode_Reward/test_gait_reward: -0.9157
Metrics/base_velocity/error_vel_xy: 1.5303
Metrics/base_velocity/error_vel_yaw: 1.3177
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 1.08s
                        Total time: 1142.23s
                               ETA: 2116.2s

################################################################################
                     [1m Learning iteration 1052/3000 [0m                     

                       Computation: 91421 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.8424
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9156
                     Learning rate: 0.0004
                       Mean reward: 104.32
               Mean episode length: 951.29
       Episode_Reward/keep_balance: 0.9557
     Episode_Reward/rew_lin_vel_xy: 4.9243
      Episode_Reward/rew_ang_vel_z: 2.3622
    Episode_Reward/pen_base_height: -0.3054
      Episode_Reward/pen_lin_vel_z: -0.0454
     Episode_Reward/pen_ang_vel_xy: -0.1902
   Episode_Reward/pen_joint_torque: -0.2127
    Episode_Reward/pen_joint_accel: -0.1104
    Episode_Reward/pen_action_rate: -0.1190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0843
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2639
Episode_Reward/pen_flat_orientation: -0.1293
  Episode_Reward/pen_feet_distance: -0.0109
Episode_Reward/pen_feet_regulation: -0.3683
   Episode_Reward/foot_landing_vel: -0.1516
   Episode_Reward/test_gait_reward: -0.9039
Metrics/base_velocity/error_vel_xy: 1.5118
Metrics/base_velocity/error_vel_yaw: 1.3108
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 1.08s
                        Total time: 1143.30s
                               ETA: 2115.1s

################################################################################
                     [1m Learning iteration 1053/3000 [0m                     

                       Computation: 90398 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.8951
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9181
                     Learning rate: 0.0006
                       Mean reward: 103.10
               Mean episode length: 919.27
       Episode_Reward/keep_balance: 0.8960
     Episode_Reward/rew_lin_vel_xy: 4.7209
      Episode_Reward/rew_ang_vel_z: 2.2033
    Episode_Reward/pen_base_height: -0.2917
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.1848
   Episode_Reward/pen_joint_torque: -0.1996
    Episode_Reward/pen_joint_accel: -0.1009
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0520
   Episode_Reward/pen_joint_powers: -0.0791
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2481
Episode_Reward/pen_flat_orientation: -0.1242
  Episode_Reward/pen_feet_distance: -0.0098
Episode_Reward/pen_feet_regulation: -0.3507
   Episode_Reward/foot_landing_vel: -0.1341
   Episode_Reward/test_gait_reward: -0.8453
Metrics/base_velocity/error_vel_xy: 1.3685
Metrics/base_velocity/error_vel_yaw: 1.2279
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 1.09s
                        Total time: 1144.39s
                               ETA: 2114.0s

################################################################################
                     [1m Learning iteration 1054/3000 [0m                     

                       Computation: 90660 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 1.0994
                    Surrogate loss: -0.0051
             Mean action noise std: 0.9178
                     Learning rate: 0.0009
                       Mean reward: 99.96
               Mean episode length: 908.19
       Episode_Reward/keep_balance: 0.9178
     Episode_Reward/rew_lin_vel_xy: 4.6478
      Episode_Reward/rew_ang_vel_z: 2.2910
    Episode_Reward/pen_base_height: -0.2932
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.1830
   Episode_Reward/pen_joint_torque: -0.2096
    Episode_Reward/pen_joint_accel: -0.1070
    Episode_Reward/pen_action_rate: -0.1140
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0530
   Episode_Reward/pen_joint_powers: -0.0809
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2517
Episode_Reward/pen_flat_orientation: -0.1212
  Episode_Reward/pen_feet_distance: -0.0113
Episode_Reward/pen_feet_regulation: -0.3447
   Episode_Reward/foot_landing_vel: -0.1400
   Episode_Reward/test_gait_reward: -0.8687
Metrics/base_velocity/error_vel_xy: 1.5349
Metrics/base_velocity/error_vel_yaw: 1.2343
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 1.08s
                        Total time: 1145.48s
                               ETA: 2112.9s

################################################################################
                     [1m Learning iteration 1055/3000 [0m                     

                       Computation: 93092 steps/s (collection: 0.933s, learning 0.122s)
               Value function loss: 1.0070
                    Surrogate loss: -0.0015
             Mean action noise std: 0.9166
                     Learning rate: 0.0004
                       Mean reward: 103.74
               Mean episode length: 943.76
       Episode_Reward/keep_balance: 0.9563
     Episode_Reward/rew_lin_vel_xy: 4.8939
      Episode_Reward/rew_ang_vel_z: 2.3647
    Episode_Reward/pen_base_height: -0.3036
      Episode_Reward/pen_lin_vel_z: -0.0456
     Episode_Reward/pen_ang_vel_xy: -0.1952
   Episode_Reward/pen_joint_torque: -0.2163
    Episode_Reward/pen_joint_accel: -0.1207
    Episode_Reward/pen_action_rate: -0.1212
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2674
Episode_Reward/pen_flat_orientation: -0.1298
  Episode_Reward/pen_feet_distance: -0.0127
Episode_Reward/pen_feet_regulation: -0.3809
   Episode_Reward/foot_landing_vel: -0.1469
   Episode_Reward/test_gait_reward: -0.8989
Metrics/base_velocity/error_vel_xy: 1.5366
Metrics/base_velocity/error_vel_yaw: 1.3064
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 1.06s
                        Total time: 1146.53s
                               ETA: 2111.7s

################################################################################
                     [1m Learning iteration 1056/3000 [0m                     

                       Computation: 89147 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.9166
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9145
                     Learning rate: 0.0006
                       Mean reward: 97.23
               Mean episode length: 920.46
       Episode_Reward/keep_balance: 0.9296
     Episode_Reward/rew_lin_vel_xy: 4.6474
      Episode_Reward/rew_ang_vel_z: 2.2458
    Episode_Reward/pen_base_height: -0.3025
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.1948
   Episode_Reward/pen_joint_torque: -0.2038
    Episode_Reward/pen_joint_accel: -0.1107
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0830
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2656
Episode_Reward/pen_flat_orientation: -0.1266
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.3796
   Episode_Reward/foot_landing_vel: -0.1574
   Episode_Reward/test_gait_reward: -0.8761
Metrics/base_velocity/error_vel_xy: 1.5483
Metrics/base_velocity/error_vel_yaw: 1.3247
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 1.10s
                        Total time: 1147.63s
                               ETA: 2110.7s

################################################################################
                     [1m Learning iteration 1057/3000 [0m                     

                       Computation: 90177 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.8908
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9142
                     Learning rate: 0.0006
                       Mean reward: 101.52
               Mean episode length: 927.92
       Episode_Reward/keep_balance: 0.9426
     Episode_Reward/rew_lin_vel_xy: 4.9275
      Episode_Reward/rew_ang_vel_z: 2.3160
    Episode_Reward/pen_base_height: -0.2981
      Episode_Reward/pen_lin_vel_z: -0.0472
     Episode_Reward/pen_ang_vel_xy: -0.1928
   Episode_Reward/pen_joint_torque: -0.2156
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0853
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2642
Episode_Reward/pen_flat_orientation: -0.1219
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.3799
   Episode_Reward/foot_landing_vel: -0.1590
   Episode_Reward/test_gait_reward: -0.8883
Metrics/base_velocity/error_vel_xy: 1.5071
Metrics/base_velocity/error_vel_yaw: 1.2962
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 1.09s
                        Total time: 1148.72s
                               ETA: 2109.6s

################################################################################
                     [1m Learning iteration 1058/3000 [0m                     

                       Computation: 91747 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 0.9120
                    Surrogate loss: -0.0018
             Mean action noise std: 0.9141
                     Learning rate: 0.0003
                       Mean reward: 106.17
               Mean episode length: 965.22
       Episode_Reward/keep_balance: 0.9641
     Episode_Reward/rew_lin_vel_xy: 4.9749
      Episode_Reward/rew_ang_vel_z: 2.3482
    Episode_Reward/pen_base_height: -0.3081
      Episode_Reward/pen_lin_vel_z: -0.0461
     Episode_Reward/pen_ang_vel_xy: -0.1978
   Episode_Reward/pen_joint_torque: -0.2156
    Episode_Reward/pen_joint_accel: -0.1177
    Episode_Reward/pen_action_rate: -0.1234
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2722
Episode_Reward/pen_flat_orientation: -0.1284
  Episode_Reward/pen_feet_distance: -0.0099
Episode_Reward/pen_feet_regulation: -0.3953
   Episode_Reward/foot_landing_vel: -0.1564
   Episode_Reward/test_gait_reward: -0.9188
Metrics/base_velocity/error_vel_xy: 1.5270
Metrics/base_velocity/error_vel_yaw: 1.3552
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 1.07s
                        Total time: 1149.80s
                               ETA: 2108.5s

################################################################################
                     [1m Learning iteration 1059/3000 [0m                     

                       Computation: 92601 steps/s (collection: 0.940s, learning 0.122s)
               Value function loss: 0.9706
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9144
                     Learning rate: 0.0004
                       Mean reward: 100.83
               Mean episode length: 939.11
       Episode_Reward/keep_balance: 0.9299
     Episode_Reward/rew_lin_vel_xy: 4.7112
      Episode_Reward/rew_ang_vel_z: 2.2843
    Episode_Reward/pen_base_height: -0.3103
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.1912
   Episode_Reward/pen_joint_torque: -0.2088
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0831
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2616
Episode_Reward/pen_flat_orientation: -0.1280
  Episode_Reward/pen_feet_distance: -0.0162
Episode_Reward/pen_feet_regulation: -0.3727
   Episode_Reward/foot_landing_vel: -0.1367
   Episode_Reward/test_gait_reward: -0.8789
Metrics/base_velocity/error_vel_xy: 1.5247
Metrics/base_velocity/error_vel_yaw: 1.2824
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 1.06s
                        Total time: 1150.86s
                               ETA: 2107.4s

################################################################################
                     [1m Learning iteration 1060/3000 [0m                     

                       Computation: 89237 steps/s (collection: 0.975s, learning 0.126s)
               Value function loss: 0.9334
                    Surrogate loss: 0.0017
             Mean action noise std: 0.9144
                     Learning rate: 0.0001
                       Mean reward: 92.88
               Mean episode length: 898.50
       Episode_Reward/keep_balance: 0.8761
     Episode_Reward/rew_lin_vel_xy: 4.4110
      Episode_Reward/rew_ang_vel_z: 2.1150
    Episode_Reward/pen_base_height: -0.3060
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1905
   Episode_Reward/pen_joint_torque: -0.1988
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.1156
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0822
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2544
Episode_Reward/pen_flat_orientation: -0.1308
  Episode_Reward/pen_feet_distance: -0.0115
Episode_Reward/pen_feet_regulation: -0.3828
   Episode_Reward/foot_landing_vel: -0.1503
   Episode_Reward/test_gait_reward: -0.8370
Metrics/base_velocity/error_vel_xy: 1.4301
Metrics/base_velocity/error_vel_yaw: 1.2658
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 1.10s
                        Total time: 1151.96s
                               ETA: 2106.3s

################################################################################
                     [1m Learning iteration 1061/3000 [0m                     

                       Computation: 89716 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.9810
                    Surrogate loss: -0.0053
             Mean action noise std: 0.9133
                     Learning rate: 0.0003
                       Mean reward: 103.73
               Mean episode length: 930.41
       Episode_Reward/keep_balance: 0.9336
     Episode_Reward/rew_lin_vel_xy: 4.9291
      Episode_Reward/rew_ang_vel_z: 2.2991
    Episode_Reward/pen_base_height: -0.2991
      Episode_Reward/pen_lin_vel_z: -0.0437
     Episode_Reward/pen_ang_vel_xy: -0.1954
   Episode_Reward/pen_joint_torque: -0.2168
    Episode_Reward/pen_joint_accel: -0.1142
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2619
Episode_Reward/pen_flat_orientation: -0.1264
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.3822
   Episode_Reward/foot_landing_vel: -0.1512
   Episode_Reward/test_gait_reward: -0.8831
Metrics/base_velocity/error_vel_xy: 1.4183
Metrics/base_velocity/error_vel_yaw: 1.2900
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 1.10s
                        Total time: 1153.06s
                               ETA: 2105.2s

################################################################################
                     [1m Learning iteration 1062/3000 [0m                     

                       Computation: 87949 steps/s (collection: 0.992s, learning 0.126s)
               Value function loss: 0.8596
                    Surrogate loss: -0.0052
             Mean action noise std: 0.9137
                     Learning rate: 0.0006
                       Mean reward: 101.74
               Mean episode length: 915.76
       Episode_Reward/keep_balance: 0.9175
     Episode_Reward/rew_lin_vel_xy: 4.7498
      Episode_Reward/rew_ang_vel_z: 2.2387
    Episode_Reward/pen_base_height: -0.3005
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.1877
   Episode_Reward/pen_joint_torque: -0.2080
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0822
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2585
Episode_Reward/pen_flat_orientation: -0.1272
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.3756
   Episode_Reward/foot_landing_vel: -0.1389
   Episode_Reward/test_gait_reward: -0.8699
Metrics/base_velocity/error_vel_xy: 1.4520
Metrics/base_velocity/error_vel_yaw: 1.2875
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 1.12s
                        Total time: 1154.17s
                               ETA: 2104.2s

################################################################################
                     [1m Learning iteration 1063/3000 [0m                     

                       Computation: 88057 steps/s (collection: 0.994s, learning 0.123s)
               Value function loss: 0.8805
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9166
                     Learning rate: 0.0009
                       Mean reward: 107.09
               Mean episode length: 975.01
       Episode_Reward/keep_balance: 0.9755
     Episode_Reward/rew_lin_vel_xy: 5.0775
      Episode_Reward/rew_ang_vel_z: 2.4005
    Episode_Reward/pen_base_height: -0.3112
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.1939
   Episode_Reward/pen_joint_torque: -0.2218
    Episode_Reward/pen_joint_accel: -0.1262
    Episode_Reward/pen_action_rate: -0.1245
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0597
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2746
Episode_Reward/pen_flat_orientation: -0.1270
  Episode_Reward/pen_feet_distance: -0.0118
Episode_Reward/pen_feet_regulation: -0.4054
   Episode_Reward/foot_landing_vel: -0.1634
   Episode_Reward/test_gait_reward: -0.9251
Metrics/base_velocity/error_vel_xy: 1.5021
Metrics/base_velocity/error_vel_yaw: 1.3459
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 1.12s
                        Total time: 1155.29s
                               ETA: 2103.2s

################################################################################
                     [1m Learning iteration 1064/3000 [0m                     

                       Computation: 91407 steps/s (collection: 0.946s, learning 0.129s)
               Value function loss: 0.8652
                    Surrogate loss: -0.0039
             Mean action noise std: 0.9156
                     Learning rate: 0.0009
                       Mean reward: 107.21
               Mean episode length: 957.15
       Episode_Reward/keep_balance: 0.9550
     Episode_Reward/rew_lin_vel_xy: 5.0603
      Episode_Reward/rew_ang_vel_z: 2.3534
    Episode_Reward/pen_base_height: -0.2962
      Episode_Reward/pen_lin_vel_z: -0.0415
     Episode_Reward/pen_ang_vel_xy: -0.1940
   Episode_Reward/pen_joint_torque: -0.2126
    Episode_Reward/pen_joint_accel: -0.1058
    Episode_Reward/pen_action_rate: -0.1201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0847
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2667
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0117
Episode_Reward/pen_feet_regulation: -0.3691
   Episode_Reward/foot_landing_vel: -0.1352
   Episode_Reward/test_gait_reward: -0.9020
Metrics/base_velocity/error_vel_xy: 1.4271
Metrics/base_velocity/error_vel_yaw: 1.3065
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 1.08s
                        Total time: 1156.36s
                               ETA: 2102.1s

################################################################################
                     [1m Learning iteration 1065/3000 [0m                     

                       Computation: 85956 steps/s (collection: 1.018s, learning 0.125s)
               Value function loss: 0.9266
                    Surrogate loss: -0.0028
             Mean action noise std: 0.9160
                     Learning rate: 0.0009
                       Mean reward: 106.21
               Mean episode length: 974.18
       Episode_Reward/keep_balance: 0.9790
     Episode_Reward/rew_lin_vel_xy: 5.0303
      Episode_Reward/rew_ang_vel_z: 2.3726
    Episode_Reward/pen_base_height: -0.3081
      Episode_Reward/pen_lin_vel_z: -0.0459
     Episode_Reward/pen_ang_vel_xy: -0.1984
   Episode_Reward/pen_joint_torque: -0.2214
    Episode_Reward/pen_joint_accel: -0.1244
    Episode_Reward/pen_action_rate: -0.1258
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0595
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2775
Episode_Reward/pen_flat_orientation: -0.1282
  Episode_Reward/pen_feet_distance: -0.0107
Episode_Reward/pen_feet_regulation: -0.4060
   Episode_Reward/foot_landing_vel: -0.1526
   Episode_Reward/test_gait_reward: -0.9311
Metrics/base_velocity/error_vel_xy: 1.5817
Metrics/base_velocity/error_vel_yaw: 1.3884
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 1.14s
                        Total time: 1157.51s
                               ETA: 2101.1s

################################################################################
                     [1m Learning iteration 1066/3000 [0m                     

                       Computation: 83893 steps/s (collection: 1.042s, learning 0.130s)
               Value function loss: 0.9134
                    Surrogate loss: -0.0026
             Mean action noise std: 0.9168
                     Learning rate: 0.0004
                       Mean reward: 108.06
               Mean episode length: 957.87
       Episode_Reward/keep_balance: 0.9398
     Episode_Reward/rew_lin_vel_xy: 5.0265
      Episode_Reward/rew_ang_vel_z: 2.2846
    Episode_Reward/pen_base_height: -0.3048
      Episode_Reward/pen_lin_vel_z: -0.0446
     Episode_Reward/pen_ang_vel_xy: -0.1964
   Episode_Reward/pen_joint_torque: -0.2095
    Episode_Reward/pen_joint_accel: -0.1111
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0856
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2680
Episode_Reward/pen_flat_orientation: -0.1308
  Episode_Reward/pen_feet_distance: -0.0094
Episode_Reward/pen_feet_regulation: -0.3937
   Episode_Reward/foot_landing_vel: -0.1485
   Episode_Reward/test_gait_reward: -0.8958
Metrics/base_velocity/error_vel_xy: 1.3669
Metrics/base_velocity/error_vel_yaw: 1.3188
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 1.17s
                        Total time: 1158.68s
                               ETA: 2100.2s

################################################################################
                     [1m Learning iteration 1067/3000 [0m                     

                       Computation: 85656 steps/s (collection: 1.025s, learning 0.122s)
               Value function loss: 0.9207
                    Surrogate loss: -0.0011
             Mean action noise std: 0.9187
                     Learning rate: 0.0003
                       Mean reward: 103.71
               Mean episode length: 949.62
       Episode_Reward/keep_balance: 0.9610
     Episode_Reward/rew_lin_vel_xy: 4.9313
      Episode_Reward/rew_ang_vel_z: 2.3819
    Episode_Reward/pen_base_height: -0.3047
      Episode_Reward/pen_lin_vel_z: -0.0464
     Episode_Reward/pen_ang_vel_xy: -0.1969
   Episode_Reward/pen_joint_torque: -0.2257
    Episode_Reward/pen_joint_accel: -0.1271
    Episode_Reward/pen_action_rate: -0.1225
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2696
Episode_Reward/pen_flat_orientation: -0.1194
  Episode_Reward/pen_feet_distance: -0.0123
Episode_Reward/pen_feet_regulation: -0.3806
   Episode_Reward/foot_landing_vel: -0.1543
   Episode_Reward/test_gait_reward: -0.9083
Metrics/base_velocity/error_vel_xy: 1.6685
Metrics/base_velocity/error_vel_yaw: 1.3062
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 1.15s
                        Total time: 1159.83s
                               ETA: 2099.2s

################################################################################
                     [1m Learning iteration 1068/3000 [0m                     

                       Computation: 86987 steps/s (collection: 1.006s, learning 0.124s)
               Value function loss: 0.8863
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9205
                     Learning rate: 0.0006
                       Mean reward: 106.10
               Mean episode length: 942.41
       Episode_Reward/keep_balance: 0.9457
     Episode_Reward/rew_lin_vel_xy: 5.0004
      Episode_Reward/rew_ang_vel_z: 2.3433
    Episode_Reward/pen_base_height: -0.3097
      Episode_Reward/pen_lin_vel_z: -0.0437
     Episode_Reward/pen_ang_vel_xy: -0.1912
   Episode_Reward/pen_joint_torque: -0.2104
    Episode_Reward/pen_joint_accel: -0.1159
    Episode_Reward/pen_action_rate: -0.1205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0844
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2660
Episode_Reward/pen_flat_orientation: -0.1270
  Episode_Reward/pen_feet_distance: -0.0134
Episode_Reward/pen_feet_regulation: -0.3784
   Episode_Reward/foot_landing_vel: -0.1490
   Episode_Reward/test_gait_reward: -0.8987
Metrics/base_velocity/error_vel_xy: 1.4032
Metrics/base_velocity/error_vel_yaw: 1.2908
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 1.13s
                        Total time: 1160.96s
                               ETA: 2098.2s

################################################################################
                     [1m Learning iteration 1069/3000 [0m                     

                       Computation: 86364 steps/s (collection: 1.014s, learning 0.124s)
               Value function loss: 0.9161
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9216
                     Learning rate: 0.0006
                       Mean reward: 103.38
               Mean episode length: 949.09
       Episode_Reward/keep_balance: 0.9370
     Episode_Reward/rew_lin_vel_xy: 4.9425
      Episode_Reward/rew_ang_vel_z: 2.2663
    Episode_Reward/pen_base_height: -0.3001
      Episode_Reward/pen_lin_vel_z: -0.0430
     Episode_Reward/pen_ang_vel_xy: -0.1985
   Episode_Reward/pen_joint_torque: -0.2053
    Episode_Reward/pen_joint_accel: -0.1102
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0835
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2706
Episode_Reward/pen_flat_orientation: -0.1254
  Episode_Reward/pen_feet_distance: -0.0101
Episode_Reward/pen_feet_regulation: -0.3707
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.8886
Metrics/base_velocity/error_vel_xy: 1.4169
Metrics/base_velocity/error_vel_yaw: 1.3438
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 1.14s
                        Total time: 1162.10s
                               ETA: 2097.2s

################################################################################
                     [1m Learning iteration 1070/3000 [0m                     

                       Computation: 89875 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 0.9501
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9236
                     Learning rate: 0.0013
                       Mean reward: 100.42
               Mean episode length: 921.56
       Episode_Reward/keep_balance: 0.9309
     Episode_Reward/rew_lin_vel_xy: 4.8752
      Episode_Reward/rew_ang_vel_z: 2.2834
    Episode_Reward/pen_base_height: -0.3001
      Episode_Reward/pen_lin_vel_z: -0.0430
     Episode_Reward/pen_ang_vel_xy: -0.1955
   Episode_Reward/pen_joint_torque: -0.2040
    Episode_Reward/pen_joint_accel: -0.1167
    Episode_Reward/pen_action_rate: -0.1213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0840
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2657
Episode_Reward/pen_flat_orientation: -0.1271
  Episode_Reward/pen_feet_distance: -0.0120
Episode_Reward/pen_feet_regulation: -0.3790
   Episode_Reward/foot_landing_vel: -0.1430
   Episode_Reward/test_gait_reward: -0.8851
Metrics/base_velocity/error_vel_xy: 1.4794
Metrics/base_velocity/error_vel_yaw: 1.3108
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 1.09s
                        Total time: 1163.19s
                               ETA: 2096.1s

################################################################################
                     [1m Learning iteration 1071/3000 [0m                     

                       Computation: 90921 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.9666
                    Surrogate loss: -0.0014
             Mean action noise std: 0.9223
                     Learning rate: 0.0003
                       Mean reward: 108.33
               Mean episode length: 949.92
       Episode_Reward/keep_balance: 0.9408
     Episode_Reward/rew_lin_vel_xy: 5.0731
      Episode_Reward/rew_ang_vel_z: 2.2775
    Episode_Reward/pen_base_height: -0.2923
      Episode_Reward/pen_lin_vel_z: -0.0427
     Episode_Reward/pen_ang_vel_xy: -0.1967
   Episode_Reward/pen_joint_torque: -0.2108
    Episode_Reward/pen_joint_accel: -0.1185
    Episode_Reward/pen_action_rate: -0.1228
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2706
Episode_Reward/pen_flat_orientation: -0.1167
  Episode_Reward/pen_feet_distance: -0.0126
Episode_Reward/pen_feet_regulation: -0.3915
   Episode_Reward/foot_landing_vel: -0.1497
   Episode_Reward/test_gait_reward: -0.8973
Metrics/base_velocity/error_vel_xy: 1.3322
Metrics/base_velocity/error_vel_yaw: 1.3347
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 1.08s
                        Total time: 1164.27s
                               ETA: 2095.0s

################################################################################
                     [1m Learning iteration 1072/3000 [0m                     

                       Computation: 90661 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.9113
                    Surrogate loss: -0.0038
             Mean action noise std: 0.9218
                     Learning rate: 0.0006
                       Mean reward: 104.02
               Mean episode length: 952.52
       Episode_Reward/keep_balance: 0.9507
     Episode_Reward/rew_lin_vel_xy: 4.9773
      Episode_Reward/rew_ang_vel_z: 2.2998
    Episode_Reward/pen_base_height: -0.3103
      Episode_Reward/pen_lin_vel_z: -0.0447
     Episode_Reward/pen_ang_vel_xy: -0.1934
   Episode_Reward/pen_joint_torque: -0.2077
    Episode_Reward/pen_joint_accel: -0.1122
    Episode_Reward/pen_action_rate: -0.1234
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0859
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2735
Episode_Reward/pen_flat_orientation: -0.1277
  Episode_Reward/pen_feet_distance: -0.0118
Episode_Reward/pen_feet_regulation: -0.4094
   Episode_Reward/foot_landing_vel: -0.1579
   Episode_Reward/test_gait_reward: -0.9047
Metrics/base_velocity/error_vel_xy: 1.4922
Metrics/base_velocity/error_vel_yaw: 1.3617
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 1.08s
                        Total time: 1165.36s
                               ETA: 2093.9s

################################################################################
                     [1m Learning iteration 1073/3000 [0m                     

                       Computation: 90931 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.9137
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9225
                     Learning rate: 0.0004
                       Mean reward: 112.21
               Mean episode length: 964.91
       Episode_Reward/keep_balance: 0.9705
     Episode_Reward/rew_lin_vel_xy: 5.0901
      Episode_Reward/rew_ang_vel_z: 2.4187
    Episode_Reward/pen_base_height: -0.2855
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.1845
   Episode_Reward/pen_joint_torque: -0.2200
    Episode_Reward/pen_joint_accel: -0.1177
    Episode_Reward/pen_action_rate: -0.1217
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0854
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2701
Episode_Reward/pen_flat_orientation: -0.1149
  Episode_Reward/pen_feet_distance: -0.0099
Episode_Reward/pen_feet_regulation: -0.3619
   Episode_Reward/foot_landing_vel: -0.1461
   Episode_Reward/test_gait_reward: -0.9092
Metrics/base_velocity/error_vel_xy: 1.5283
Metrics/base_velocity/error_vel_yaw: 1.3136
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 1.08s
                        Total time: 1166.44s
                               ETA: 2092.9s

################################################################################
                     [1m Learning iteration 1074/3000 [0m                     

                       Computation: 83090 steps/s (collection: 1.053s, learning 0.130s)
               Value function loss: 0.8867
                    Surrogate loss: -0.0027
             Mean action noise std: 0.9230
                     Learning rate: 0.0004
                       Mean reward: 104.62
               Mean episode length: 944.82
       Episode_Reward/keep_balance: 0.9544
     Episode_Reward/rew_lin_vel_xy: 5.0758
      Episode_Reward/rew_ang_vel_z: 2.3482
    Episode_Reward/pen_base_height: -0.3115
      Episode_Reward/pen_lin_vel_z: -0.0485
     Episode_Reward/pen_ang_vel_xy: -0.1949
   Episode_Reward/pen_joint_torque: -0.2273
    Episode_Reward/pen_joint_accel: -0.1283
    Episode_Reward/pen_action_rate: -0.1238
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0598
   Episode_Reward/pen_joint_powers: -0.0899
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2701
Episode_Reward/pen_flat_orientation: -0.1228
  Episode_Reward/pen_feet_distance: -0.0090
Episode_Reward/pen_feet_regulation: -0.4152
   Episode_Reward/foot_landing_vel: -0.1559
   Episode_Reward/test_gait_reward: -0.9036
Metrics/base_velocity/error_vel_xy: 1.4179
Metrics/base_velocity/error_vel_yaw: 1.3168
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 1.18s
                        Total time: 1167.62s
                               ETA: 2091.9s

################################################################################
                     [1m Learning iteration 1075/3000 [0m                     

                       Computation: 89519 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.8932
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9235
                     Learning rate: 0.0003
                       Mean reward: 107.70
               Mean episode length: 954.23
       Episode_Reward/keep_balance: 0.9658
     Episode_Reward/rew_lin_vel_xy: 5.1679
      Episode_Reward/rew_ang_vel_z: 2.4190
    Episode_Reward/pen_base_height: -0.2930
      Episode_Reward/pen_lin_vel_z: -0.0452
     Episode_Reward/pen_ang_vel_xy: -0.1843
   Episode_Reward/pen_joint_torque: -0.2202
    Episode_Reward/pen_joint_accel: -0.1212
    Episode_Reward/pen_action_rate: -0.1220
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0858
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2687
Episode_Reward/pen_flat_orientation: -0.1173
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3689
   Episode_Reward/foot_landing_vel: -0.1453
   Episode_Reward/test_gait_reward: -0.9183
Metrics/base_velocity/error_vel_xy: 1.4385
Metrics/base_velocity/error_vel_yaw: 1.2947
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 1.10s
                        Total time: 1168.72s
                               ETA: 2090.9s

################################################################################
                     [1m Learning iteration 1076/3000 [0m                     

                       Computation: 90605 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.8728
                    Surrogate loss: -0.0028
             Mean action noise std: 0.9244
                     Learning rate: 0.0003
                       Mean reward: 105.18
               Mean episode length: 942.23
       Episode_Reward/keep_balance: 0.9459
     Episode_Reward/rew_lin_vel_xy: 5.0302
      Episode_Reward/rew_ang_vel_z: 2.2714
    Episode_Reward/pen_base_height: -0.3039
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.1966
   Episode_Reward/pen_joint_torque: -0.2111
    Episode_Reward/pen_joint_accel: -0.1369
    Episode_Reward/pen_action_rate: -0.1263
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0605
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2764
Episode_Reward/pen_flat_orientation: -0.1281
  Episode_Reward/pen_feet_distance: -0.0107
Episode_Reward/pen_feet_regulation: -0.4102
   Episode_Reward/foot_landing_vel: -0.1557
   Episode_Reward/test_gait_reward: -0.9136
Metrics/base_velocity/error_vel_xy: 1.3730
Metrics/base_velocity/error_vel_yaw: 1.3697
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 1.08s
                        Total time: 1169.80s
                               ETA: 2089.8s

################################################################################
                     [1m Learning iteration 1077/3000 [0m                     

                       Computation: 91385 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.8643
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9260
                     Learning rate: 0.0006
                       Mean reward: 106.77
               Mean episode length: 930.15
       Episode_Reward/keep_balance: 0.9359
     Episode_Reward/rew_lin_vel_xy: 5.1046
      Episode_Reward/rew_ang_vel_z: 2.2668
    Episode_Reward/pen_base_height: -0.2894
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1838
   Episode_Reward/pen_joint_torque: -0.2015
    Episode_Reward/pen_joint_accel: -0.1232
    Episode_Reward/pen_action_rate: -0.1201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0814
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2684
Episode_Reward/pen_flat_orientation: -0.1154
  Episode_Reward/pen_feet_distance: -0.0098
Episode_Reward/pen_feet_regulation: -0.3680
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.8930
Metrics/base_velocity/error_vel_xy: 1.3231
Metrics/base_velocity/error_vel_yaw: 1.3380
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 1.08s
                        Total time: 1170.88s
                               ETA: 2088.7s

################################################################################
                     [1m Learning iteration 1078/3000 [0m                     

                       Computation: 83381 steps/s (collection: 1.045s, learning 0.134s)
               Value function loss: 0.8852
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9279
                     Learning rate: 0.0004
                       Mean reward: 113.58
               Mean episode length: 978.68
       Episode_Reward/keep_balance: 0.9801
     Episode_Reward/rew_lin_vel_xy: 5.3851
      Episode_Reward/rew_ang_vel_z: 2.4509
    Episode_Reward/pen_base_height: -0.2977
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.1921
   Episode_Reward/pen_joint_torque: -0.2184
    Episode_Reward/pen_joint_accel: -0.1334
    Episode_Reward/pen_action_rate: -0.1251
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2773
Episode_Reward/pen_flat_orientation: -0.1161
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.3890
   Episode_Reward/foot_landing_vel: -0.1598
   Episode_Reward/test_gait_reward: -0.9317
Metrics/base_velocity/error_vel_xy: 1.3742
Metrics/base_velocity/error_vel_yaw: 1.3211
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 1.18s
                        Total time: 1172.06s
                               ETA: 2087.8s

################################################################################
                     [1m Learning iteration 1079/3000 [0m                     

                       Computation: 87935 steps/s (collection: 0.989s, learning 0.129s)
               Value function loss: 0.8414
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9271
                     Learning rate: 0.0001
                       Mean reward: 106.33
               Mean episode length: 954.88
       Episode_Reward/keep_balance: 0.9582
     Episode_Reward/rew_lin_vel_xy: 5.0140
      Episode_Reward/rew_ang_vel_z: 2.3465
    Episode_Reward/pen_base_height: -0.3029
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.1836
   Episode_Reward/pen_joint_torque: -0.2210
    Episode_Reward/pen_joint_accel: -0.1117
    Episode_Reward/pen_action_rate: -0.1220
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2696
Episode_Reward/pen_flat_orientation: -0.1231
  Episode_Reward/pen_feet_distance: -0.0117
Episode_Reward/pen_feet_regulation: -0.3837
   Episode_Reward/foot_landing_vel: -0.1427
   Episode_Reward/test_gait_reward: -0.9193
Metrics/base_velocity/error_vel_xy: 1.4606
Metrics/base_velocity/error_vel_yaw: 1.3312
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 1.12s
                        Total time: 1173.18s
                               ETA: 2086.7s

################################################################################
                     [1m Learning iteration 1080/3000 [0m                     

                       Computation: 86083 steps/s (collection: 1.019s, learning 0.123s)
               Value function loss: 0.8540
                    Surrogate loss: -0.0013
             Mean action noise std: 0.9271
                     Learning rate: 0.0001
                       Mean reward: 106.58
               Mean episode length: 960.10
       Episode_Reward/keep_balance: 0.9502
     Episode_Reward/rew_lin_vel_xy: 5.0142
      Episode_Reward/rew_ang_vel_z: 2.3100
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0453
     Episode_Reward/pen_ang_vel_xy: -0.1961
   Episode_Reward/pen_joint_torque: -0.2181
    Episode_Reward/pen_joint_accel: -0.1237
    Episode_Reward/pen_action_rate: -0.1245
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0586
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2742
Episode_Reward/pen_flat_orientation: -0.1276
  Episode_Reward/pen_feet_distance: -0.0140
Episode_Reward/pen_feet_regulation: -0.4017
   Episode_Reward/foot_landing_vel: -0.1474
   Episode_Reward/test_gait_reward: -0.9054
Metrics/base_velocity/error_vel_xy: 1.4519
Metrics/base_velocity/error_vel_yaw: 1.3488
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 1.14s
                        Total time: 1174.32s
                               ETA: 2085.7s

################################################################################
                     [1m Learning iteration 1081/3000 [0m                     

                       Computation: 84982 steps/s (collection: 1.026s, learning 0.131s)
               Value function loss: 0.9026
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9256
                     Learning rate: 0.0002
                       Mean reward: 108.41
               Mean episode length: 965.79
       Episode_Reward/keep_balance: 0.9653
     Episode_Reward/rew_lin_vel_xy: 5.2423
      Episode_Reward/rew_ang_vel_z: 2.3507
    Episode_Reward/pen_base_height: -0.3131
      Episode_Reward/pen_lin_vel_z: -0.0451
     Episode_Reward/pen_ang_vel_xy: -0.1924
   Episode_Reward/pen_joint_torque: -0.2180
    Episode_Reward/pen_joint_accel: -0.1226
    Episode_Reward/pen_action_rate: -0.1259
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2777
Episode_Reward/pen_flat_orientation: -0.1255
  Episode_Reward/pen_feet_distance: -0.0143
Episode_Reward/pen_feet_regulation: -0.4008
   Episode_Reward/foot_landing_vel: -0.1523
   Episode_Reward/test_gait_reward: -0.9242
Metrics/base_velocity/error_vel_xy: 1.3210
Metrics/base_velocity/error_vel_yaw: 1.3672
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 1.16s
                        Total time: 1175.47s
                               ETA: 2084.8s

################################################################################
                     [1m Learning iteration 1082/3000 [0m                     

                       Computation: 86998 steps/s (collection: 1.005s, learning 0.125s)
               Value function loss: 0.7978
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9230
                     Learning rate: 0.0004
                       Mean reward: 102.45
               Mean episode length: 923.74
       Episode_Reward/keep_balance: 0.9279
     Episode_Reward/rew_lin_vel_xy: 4.9341
      Episode_Reward/rew_ang_vel_z: 2.2361
    Episode_Reward/pen_base_height: -0.2979
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.1867
   Episode_Reward/pen_joint_torque: -0.2090
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1219
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0853
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2721
Episode_Reward/pen_flat_orientation: -0.1225
  Episode_Reward/pen_feet_distance: -0.0104
Episode_Reward/pen_feet_regulation: -0.3842
   Episode_Reward/foot_landing_vel: -0.1431
   Episode_Reward/test_gait_reward: -0.8848
Metrics/base_velocity/error_vel_xy: 1.3773
Metrics/base_velocity/error_vel_yaw: 1.3295
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 1.13s
                        Total time: 1176.60s
                               ETA: 2083.8s

################################################################################
                     [1m Learning iteration 1083/3000 [0m                     

                       Computation: 81485 steps/s (collection: 1.077s, learning 0.130s)
               Value function loss: 0.7835
                    Surrogate loss: -0.0044
             Mean action noise std: 0.9234
                     Learning rate: 0.0006
                       Mean reward: 105.45
               Mean episode length: 938.38
       Episode_Reward/keep_balance: 0.9150
     Episode_Reward/rew_lin_vel_xy: 4.9017
      Episode_Reward/rew_ang_vel_z: 2.2105
    Episode_Reward/pen_base_height: -0.3012
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.1784
   Episode_Reward/pen_joint_torque: -0.2132
    Episode_Reward/pen_joint_accel: -0.1130
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0845
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2618
Episode_Reward/pen_flat_orientation: -0.1197
  Episode_Reward/pen_feet_distance: -0.0117
Episode_Reward/pen_feet_regulation: -0.3927
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.8810
Metrics/base_velocity/error_vel_xy: 1.3368
Metrics/base_velocity/error_vel_yaw: 1.3098
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 1.21s
                        Total time: 1177.81s
                               ETA: 2082.9s

################################################################################
                     [1m Learning iteration 1084/3000 [0m                     

                       Computation: 90799 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.8230
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9243
                     Learning rate: 0.0013
                       Mean reward: 110.55
               Mean episode length: 947.97
       Episode_Reward/keep_balance: 0.9489
     Episode_Reward/rew_lin_vel_xy: 5.2714
      Episode_Reward/rew_ang_vel_z: 2.3480
    Episode_Reward/pen_base_height: -0.3048
      Episode_Reward/pen_lin_vel_z: -0.0444
     Episode_Reward/pen_ang_vel_xy: -0.1932
   Episode_Reward/pen_joint_torque: -0.2162
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1239
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2724
Episode_Reward/pen_flat_orientation: -0.1203
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.4015
   Episode_Reward/foot_landing_vel: -0.1493
   Episode_Reward/test_gait_reward: -0.9102
Metrics/base_velocity/error_vel_xy: 1.3028
Metrics/base_velocity/error_vel_yaw: 1.3047
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 1.08s
                        Total time: 1178.89s
                               ETA: 2081.8s

################################################################################
                     [1m Learning iteration 1085/3000 [0m                     

                       Computation: 85705 steps/s (collection: 1.017s, learning 0.130s)
               Value function loss: 0.8746
                    Surrogate loss: -0.0011
             Mean action noise std: 0.9234
                     Learning rate: 0.0004
                       Mean reward: 109.54
               Mean episode length: 959.40
       Episode_Reward/keep_balance: 0.9580
     Episode_Reward/rew_lin_vel_xy: 5.2481
      Episode_Reward/rew_ang_vel_z: 2.2692
    Episode_Reward/pen_base_height: -0.3113
      Episode_Reward/pen_lin_vel_z: -0.0456
     Episode_Reward/pen_ang_vel_xy: -0.2061
   Episode_Reward/pen_joint_torque: -0.2174
    Episode_Reward/pen_joint_accel: -0.1440
    Episode_Reward/pen_action_rate: -0.1297
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0620
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2864
Episode_Reward/pen_flat_orientation: -0.1238
  Episode_Reward/pen_feet_distance: -0.0104
Episode_Reward/pen_feet_regulation: -0.4247
   Episode_Reward/foot_landing_vel: -0.1611
   Episode_Reward/test_gait_reward: -0.9256
Metrics/base_velocity/error_vel_xy: 1.2934
Metrics/base_velocity/error_vel_yaw: 1.4210
      Episode_Termination/time_out: 2.9167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 1.15s
                        Total time: 1180.04s
                               ETA: 2080.8s

################################################################################
                     [1m Learning iteration 1086/3000 [0m                     

                       Computation: 91221 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.8917
                    Surrogate loss: -0.0054
             Mean action noise std: 0.9222
                     Learning rate: 0.0009
                       Mean reward: 107.05
               Mean episode length: 955.99
       Episode_Reward/keep_balance: 0.9506
     Episode_Reward/rew_lin_vel_xy: 5.0565
      Episode_Reward/rew_ang_vel_z: 2.2981
    Episode_Reward/pen_base_height: -0.3047
      Episode_Reward/pen_lin_vel_z: -0.0451
     Episode_Reward/pen_ang_vel_xy: -0.1959
   Episode_Reward/pen_joint_torque: -0.2159
    Episode_Reward/pen_joint_accel: -0.1210
    Episode_Reward/pen_action_rate: -0.1254
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0879
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2768
Episode_Reward/pen_flat_orientation: -0.1289
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.4011
   Episode_Reward/foot_landing_vel: -0.1432
   Episode_Reward/test_gait_reward: -0.9144
Metrics/base_velocity/error_vel_xy: 1.4111
Metrics/base_velocity/error_vel_yaw: 1.3698
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 1.08s
                        Total time: 1181.12s
                               ETA: 2079.7s

################################################################################
                     [1m Learning iteration 1087/3000 [0m                     

                       Computation: 87188 steps/s (collection: 1.003s, learning 0.124s)
               Value function loss: 0.8867
                    Surrogate loss: -0.0039
             Mean action noise std: 0.9240
                     Learning rate: 0.0013
                       Mean reward: 101.16
               Mean episode length: 928.69
       Episode_Reward/keep_balance: 0.9372
     Episode_Reward/rew_lin_vel_xy: 4.9458
      Episode_Reward/rew_ang_vel_z: 2.2303
    Episode_Reward/pen_base_height: -0.2983
      Episode_Reward/pen_lin_vel_z: -0.0455
     Episode_Reward/pen_ang_vel_xy: -0.1905
   Episode_Reward/pen_joint_torque: -0.2202
    Episode_Reward/pen_joint_accel: -0.1173
    Episode_Reward/pen_action_rate: -0.1249
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2759
Episode_Reward/pen_flat_orientation: -0.1242
  Episode_Reward/pen_feet_distance: -0.0104
Episode_Reward/pen_feet_regulation: -0.3985
   Episode_Reward/foot_landing_vel: -0.1437
   Episode_Reward/test_gait_reward: -0.9020
Metrics/base_velocity/error_vel_xy: 1.4110
Metrics/base_velocity/error_vel_yaw: 1.3779
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 1.13s
                        Total time: 1182.25s
                               ETA: 2078.7s

################################################################################
                     [1m Learning iteration 1088/3000 [0m                     

                       Computation: 89948 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 1.0057
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9273
                     Learning rate: 0.0019
                       Mean reward: 107.91
               Mean episode length: 973.43
       Episode_Reward/keep_balance: 0.9692
     Episode_Reward/rew_lin_vel_xy: 5.1138
      Episode_Reward/rew_ang_vel_z: 2.3520
    Episode_Reward/pen_base_height: -0.3214
      Episode_Reward/pen_lin_vel_z: -0.0461
     Episode_Reward/pen_ang_vel_xy: -0.1973
   Episode_Reward/pen_joint_torque: -0.2282
    Episode_Reward/pen_joint_accel: -0.1259
    Episode_Reward/pen_action_rate: -0.1274
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2796
Episode_Reward/pen_flat_orientation: -0.1215
  Episode_Reward/pen_feet_distance: -0.0135
Episode_Reward/pen_feet_regulation: -0.4187
   Episode_Reward/foot_landing_vel: -0.1482
   Episode_Reward/test_gait_reward: -0.9341
Metrics/base_velocity/error_vel_xy: 1.4723
Metrics/base_velocity/error_vel_yaw: 1.3761
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 1.09s
                        Total time: 1183.34s
                               ETA: 2077.6s

################################################################################
                     [1m Learning iteration 1089/3000 [0m                     

                       Computation: 89127 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 0.9110
                    Surrogate loss: -0.0024
             Mean action noise std: 0.9278
                     Learning rate: 0.0009
                       Mean reward: 101.66
               Mean episode length: 923.07
       Episode_Reward/keep_balance: 0.9420
     Episode_Reward/rew_lin_vel_xy: 5.0315
      Episode_Reward/rew_ang_vel_z: 2.2896
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.1997
   Episode_Reward/pen_joint_torque: -0.2183
    Episode_Reward/pen_joint_accel: -0.1217
    Episode_Reward/pen_action_rate: -0.1254
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0593
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2767
Episode_Reward/pen_flat_orientation: -0.1302
  Episode_Reward/pen_feet_distance: -0.0088
Episode_Reward/pen_feet_regulation: -0.4178
   Episode_Reward/foot_landing_vel: -0.1548
   Episode_Reward/test_gait_reward: -0.8996
Metrics/base_velocity/error_vel_xy: 1.4269
Metrics/base_velocity/error_vel_yaw: 1.3416
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 1.10s
                        Total time: 1184.44s
                               ETA: 2076.6s

################################################################################
                     [1m Learning iteration 1090/3000 [0m                     

                       Computation: 88392 steps/s (collection: 0.985s, learning 0.127s)
               Value function loss: 0.8985
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9276
                     Learning rate: 0.0013
                       Mean reward: 108.87
               Mean episode length: 947.12
       Episode_Reward/keep_balance: 0.9444
     Episode_Reward/rew_lin_vel_xy: 5.1748
      Episode_Reward/rew_ang_vel_z: 2.3079
    Episode_Reward/pen_base_height: -0.3062
      Episode_Reward/pen_lin_vel_z: -0.0429
     Episode_Reward/pen_ang_vel_xy: -0.1885
   Episode_Reward/pen_joint_torque: -0.2232
    Episode_Reward/pen_joint_accel: -0.1201
    Episode_Reward/pen_action_rate: -0.1243
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2713
Episode_Reward/pen_flat_orientation: -0.1225
  Episode_Reward/pen_feet_distance: -0.0113
Episode_Reward/pen_feet_regulation: -0.3900
   Episode_Reward/foot_landing_vel: -0.1403
   Episode_Reward/test_gait_reward: -0.9083
Metrics/base_velocity/error_vel_xy: 1.3270
Metrics/base_velocity/error_vel_yaw: 1.3298
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 1.11s
                        Total time: 1185.55s
                               ETA: 2075.5s

################################################################################
                     [1m Learning iteration 1091/3000 [0m                     

                       Computation: 89159 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.8602
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9277
                     Learning rate: 0.0013
                       Mean reward: 107.30
               Mean episode length: 980.47
       Episode_Reward/keep_balance: 0.9751
     Episode_Reward/rew_lin_vel_xy: 5.2372
      Episode_Reward/rew_ang_vel_z: 2.3176
    Episode_Reward/pen_base_height: -0.3082
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.2021
   Episode_Reward/pen_joint_torque: -0.2194
    Episode_Reward/pen_joint_accel: -0.1243
    Episode_Reward/pen_action_rate: -0.1308
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0621
   Episode_Reward/pen_joint_powers: -0.0921
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2878
Episode_Reward/pen_flat_orientation: -0.1221
  Episode_Reward/pen_feet_distance: -0.0109
Episode_Reward/pen_feet_regulation: -0.4319
   Episode_Reward/foot_landing_vel: -0.1668
   Episode_Reward/test_gait_reward: -0.9330
Metrics/base_velocity/error_vel_xy: 1.4215
Metrics/base_velocity/error_vel_yaw: 1.4314
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 1.10s
                        Total time: 1186.66s
                               ETA: 2074.5s

################################################################################
                     [1m Learning iteration 1092/3000 [0m                     

                       Computation: 92408 steps/s (collection: 0.938s, learning 0.126s)
               Value function loss: 0.8812
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9284
                     Learning rate: 0.0013
                       Mean reward: 108.44
               Mean episode length: 966.35
       Episode_Reward/keep_balance: 0.9743
     Episode_Reward/rew_lin_vel_xy: 5.3365
      Episode_Reward/rew_ang_vel_z: 2.3556
    Episode_Reward/pen_base_height: -0.3018
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.1999
   Episode_Reward/pen_joint_torque: -0.2301
    Episode_Reward/pen_joint_accel: -0.1261
    Episode_Reward/pen_action_rate: -0.1295
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0602
   Episode_Reward/pen_joint_powers: -0.0920
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2829
Episode_Reward/pen_flat_orientation: -0.1206
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.4206
   Episode_Reward/foot_landing_vel: -0.1540
   Episode_Reward/test_gait_reward: -0.9423
Metrics/base_velocity/error_vel_xy: 1.3400
Metrics/base_velocity/error_vel_yaw: 1.3912
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 1.06s
                        Total time: 1187.72s
                               ETA: 2073.3s

################################################################################
                     [1m Learning iteration 1093/3000 [0m                     

                       Computation: 90156 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.7885
                    Surrogate loss: -0.0007
             Mean action noise std: 0.9293
                     Learning rate: 0.0004
                       Mean reward: 111.46
               Mean episode length: 963.40
       Episode_Reward/keep_balance: 0.9543
     Episode_Reward/rew_lin_vel_xy: 5.2429
      Episode_Reward/rew_ang_vel_z: 2.3078
    Episode_Reward/pen_base_height: -0.2952
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.1911
   Episode_Reward/pen_joint_torque: -0.2196
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1256
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2764
Episode_Reward/pen_flat_orientation: -0.1169
  Episode_Reward/pen_feet_distance: -0.0084
Episode_Reward/pen_feet_regulation: -0.3974
   Episode_Reward/foot_landing_vel: -0.1469
   Episode_Reward/test_gait_reward: -0.9159
Metrics/base_velocity/error_vel_xy: 1.3183
Metrics/base_velocity/error_vel_yaw: 1.3620
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 1.09s
                        Total time: 1188.81s
                               ETA: 2072.3s

################################################################################
                     [1m Learning iteration 1094/3000 [0m                     

                       Computation: 88963 steps/s (collection: 0.980s, learning 0.125s)
               Value function loss: 0.8523
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9307
                     Learning rate: 0.0004
                       Mean reward: 112.42
               Mean episode length: 970.83
       Episode_Reward/keep_balance: 0.9747
     Episode_Reward/rew_lin_vel_xy: 5.3302
      Episode_Reward/rew_ang_vel_z: 2.3779
    Episode_Reward/pen_base_height: -0.3049
      Episode_Reward/pen_lin_vel_z: -0.0446
     Episode_Reward/pen_ang_vel_xy: -0.1927
   Episode_Reward/pen_joint_torque: -0.2145
    Episode_Reward/pen_joint_accel: -0.1171
    Episode_Reward/pen_action_rate: -0.1276
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2828
Episode_Reward/pen_flat_orientation: -0.1218
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.4119
   Episode_Reward/foot_landing_vel: -0.1509
   Episode_Reward/test_gait_reward: -0.9334
Metrics/base_velocity/error_vel_xy: 1.3747
Metrics/base_velocity/error_vel_yaw: 1.3821
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 1.10s
                        Total time: 1189.91s
                               ETA: 2071.2s

################################################################################
                     [1m Learning iteration 1095/3000 [0m                     

                       Computation: 87451 steps/s (collection: 0.998s, learning 0.126s)
               Value function loss: 0.8111
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9329
                     Learning rate: 0.0006
                       Mean reward: 108.95
               Mean episode length: 953.15
       Episode_Reward/keep_balance: 0.9453
     Episode_Reward/rew_lin_vel_xy: 5.1872
      Episode_Reward/rew_ang_vel_z: 2.2714
    Episode_Reward/pen_base_height: -0.3054
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.1967
   Episode_Reward/pen_joint_torque: -0.2162
    Episode_Reward/pen_joint_accel: -0.1126
    Episode_Reward/pen_action_rate: -0.1262
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2784
Episode_Reward/pen_flat_orientation: -0.1251
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.4106
   Episode_Reward/foot_landing_vel: -0.1458
   Episode_Reward/test_gait_reward: -0.9179
Metrics/base_velocity/error_vel_xy: 1.3264
Metrics/base_velocity/error_vel_yaw: 1.3730
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 1.12s
                        Total time: 1191.04s
                               ETA: 2070.2s

################################################################################
                     [1m Learning iteration 1096/3000 [0m                     

                       Computation: 87111 steps/s (collection: 1.005s, learning 0.123s)
               Value function loss: 0.8266
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9329
                     Learning rate: 0.0006
                       Mean reward: 112.15
               Mean episode length: 980.22
       Episode_Reward/keep_balance: 0.9812
     Episode_Reward/rew_lin_vel_xy: 5.4007
      Episode_Reward/rew_ang_vel_z: 2.3808
    Episode_Reward/pen_base_height: -0.3071
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.2013
   Episode_Reward/pen_joint_torque: -0.2217
    Episode_Reward/pen_joint_accel: -0.1250
    Episode_Reward/pen_action_rate: -0.1300
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0911
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2867
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0099
Episode_Reward/pen_feet_regulation: -0.4200
   Episode_Reward/foot_landing_vel: -0.1451
   Episode_Reward/test_gait_reward: -0.9523
Metrics/base_velocity/error_vel_xy: 1.3279
Metrics/base_velocity/error_vel_yaw: 1.3972
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 1.13s
                        Total time: 1192.17s
                               ETA: 2069.2s

################################################################################
                     [1m Learning iteration 1097/3000 [0m                     

                       Computation: 88768 steps/s (collection: 0.977s, learning 0.130s)
               Value function loss: 0.7577
                    Surrogate loss: 0.0023
             Mean action noise std: 0.9330
                     Learning rate: 0.0001
                       Mean reward: 108.25
               Mean episode length: 974.52
       Episode_Reward/keep_balance: 0.9705
     Episode_Reward/rew_lin_vel_xy: 5.1687
      Episode_Reward/rew_ang_vel_z: 2.3369
    Episode_Reward/pen_base_height: -0.3065
      Episode_Reward/pen_lin_vel_z: -0.0467
     Episode_Reward/pen_ang_vel_xy: -0.2003
   Episode_Reward/pen_joint_torque: -0.2273
    Episode_Reward/pen_joint_accel: -0.1250
    Episode_Reward/pen_action_rate: -0.1301
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0616
   Episode_Reward/pen_joint_powers: -0.0923
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2845
Episode_Reward/pen_flat_orientation: -0.1231
  Episode_Reward/pen_feet_distance: -0.0065
Episode_Reward/pen_feet_regulation: -0.4328
   Episode_Reward/foot_landing_vel: -0.1602
   Episode_Reward/test_gait_reward: -0.9365
Metrics/base_velocity/error_vel_xy: 1.4539
Metrics/base_velocity/error_vel_yaw: 1.3946
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 1.11s
                        Total time: 1193.27s
                               ETA: 2068.1s

################################################################################
                     [1m Learning iteration 1098/3000 [0m                     

                       Computation: 89865 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.7899
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9334
                     Learning rate: 0.0003
                       Mean reward: 109.11
               Mean episode length: 950.24
       Episode_Reward/keep_balance: 0.9523
     Episode_Reward/rew_lin_vel_xy: 5.2976
      Episode_Reward/rew_ang_vel_z: 2.2565
    Episode_Reward/pen_base_height: -0.2964
      Episode_Reward/pen_lin_vel_z: -0.0428
     Episode_Reward/pen_ang_vel_xy: -0.1911
   Episode_Reward/pen_joint_torque: -0.2089
    Episode_Reward/pen_joint_accel: -0.1184
    Episode_Reward/pen_action_rate: -0.1259
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2802
Episode_Reward/pen_flat_orientation: -0.1170
  Episode_Reward/pen_feet_distance: -0.0064
Episode_Reward/pen_feet_regulation: -0.4101
   Episode_Reward/foot_landing_vel: -0.1536
   Episode_Reward/test_gait_reward: -0.9140
Metrics/base_velocity/error_vel_xy: 1.2724
Metrics/base_velocity/error_vel_yaw: 1.4079
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 1.09s
                        Total time: 1194.37s
                               ETA: 2067.1s

################################################################################
                     [1m Learning iteration 1099/3000 [0m                     

                       Computation: 87529 steps/s (collection: 1.001s, learning 0.122s)
               Value function loss: 0.7644
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9333
                     Learning rate: 0.0004
                       Mean reward: 109.77
               Mean episode length: 951.70
       Episode_Reward/keep_balance: 0.9484
     Episode_Reward/rew_lin_vel_xy: 5.2662
      Episode_Reward/rew_ang_vel_z: 2.2671
    Episode_Reward/pen_base_height: -0.2940
      Episode_Reward/pen_lin_vel_z: -0.0441
     Episode_Reward/pen_ang_vel_xy: -0.1943
   Episode_Reward/pen_joint_torque: -0.2175
    Episode_Reward/pen_joint_accel: -0.1194
    Episode_Reward/pen_action_rate: -0.1274
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2781
Episode_Reward/pen_flat_orientation: -0.1158
  Episode_Reward/pen_feet_distance: -0.0061
Episode_Reward/pen_feet_regulation: -0.4087
   Episode_Reward/foot_landing_vel: -0.1472
   Episode_Reward/test_gait_reward: -0.9263
Metrics/base_velocity/error_vel_xy: 1.2993
Metrics/base_velocity/error_vel_yaw: 1.3833
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 1.12s
                        Total time: 1195.49s
                               ETA: 2066.0s

################################################################################
                     [1m Learning iteration 1100/3000 [0m                     

                       Computation: 84672 steps/s (collection: 1.039s, learning 0.122s)
               Value function loss: 0.7172
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9340
                     Learning rate: 0.0006
                       Mean reward: 106.92
               Mean episode length: 970.45
       Episode_Reward/keep_balance: 0.9605
     Episode_Reward/rew_lin_vel_xy: 5.2065
      Episode_Reward/rew_ang_vel_z: 2.2551
    Episode_Reward/pen_base_height: -0.3124
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.2052
   Episode_Reward/pen_joint_torque: -0.2194
    Episode_Reward/pen_joint_accel: -0.1176
    Episode_Reward/pen_action_rate: -0.1308
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0603
   Episode_Reward/pen_joint_powers: -0.0915
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2875
Episode_Reward/pen_flat_orientation: -0.1297
  Episode_Reward/pen_feet_distance: -0.0095
Episode_Reward/pen_feet_regulation: -0.4389
   Episode_Reward/foot_landing_vel: -0.1493
   Episode_Reward/test_gait_reward: -0.9324
Metrics/base_velocity/error_vel_xy: 1.3637
Metrics/base_velocity/error_vel_yaw: 1.4577
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 1.16s
                        Total time: 1196.65s
                               ETA: 2065.1s

################################################################################
                     [1m Learning iteration 1101/3000 [0m                     

                       Computation: 87558 steps/s (collection: 0.992s, learning 0.130s)
               Value function loss: 0.7907
                    Surrogate loss: -0.0024
             Mean action noise std: 0.9347
                     Learning rate: 0.0009
                       Mean reward: 108.45
               Mean episode length: 954.58
       Episode_Reward/keep_balance: 0.9557
     Episode_Reward/rew_lin_vel_xy: 5.2698
      Episode_Reward/rew_ang_vel_z: 2.2937
    Episode_Reward/pen_base_height: -0.3168
      Episode_Reward/pen_lin_vel_z: -0.0453
     Episode_Reward/pen_ang_vel_xy: -0.1978
   Episode_Reward/pen_joint_torque: -0.2215
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1286
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0596
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2824
Episode_Reward/pen_flat_orientation: -0.1216
  Episode_Reward/pen_feet_distance: -0.0119
Episode_Reward/pen_feet_regulation: -0.4177
   Episode_Reward/foot_landing_vel: -0.1425
   Episode_Reward/test_gait_reward: -0.9220
Metrics/base_velocity/error_vel_xy: 1.3332
Metrics/base_velocity/error_vel_yaw: 1.3934
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 1.12s
                        Total time: 1197.78s
                               ETA: 2064.0s

################################################################################
                     [1m Learning iteration 1102/3000 [0m                     

                       Computation: 86950 steps/s (collection: 1.008s, learning 0.122s)
               Value function loss: 0.7625
                    Surrogate loss: -0.0006
             Mean action noise std: 0.9336
                     Learning rate: 0.0004
                       Mean reward: 107.15
               Mean episode length: 951.78
       Episode_Reward/keep_balance: 0.9521
     Episode_Reward/rew_lin_vel_xy: 5.2573
      Episode_Reward/rew_ang_vel_z: 2.2729
    Episode_Reward/pen_base_height: -0.3125
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.2007
   Episode_Reward/pen_joint_torque: -0.2210
    Episode_Reward/pen_joint_accel: -0.1167
    Episode_Reward/pen_action_rate: -0.1293
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0612
   Episode_Reward/pen_joint_powers: -0.0920
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2833
Episode_Reward/pen_flat_orientation: -0.1238
  Episode_Reward/pen_feet_distance: -0.0080
Episode_Reward/pen_feet_regulation: -0.4433
   Episode_Reward/foot_landing_vel: -0.1605
   Episode_Reward/test_gait_reward: -0.9286
Metrics/base_velocity/error_vel_xy: 1.2687
Metrics/base_velocity/error_vel_yaw: 1.3855
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 1.13s
                        Total time: 1198.91s
                               ETA: 2063.0s

################################################################################
                     [1m Learning iteration 1103/3000 [0m                     

                       Computation: 83504 steps/s (collection: 1.046s, learning 0.131s)
               Value function loss: 0.7781
                    Surrogate loss: -0.0016
             Mean action noise std: 0.9342
                     Learning rate: 0.0003
                       Mean reward: 110.67
               Mean episode length: 961.62
       Episode_Reward/keep_balance: 0.9627
     Episode_Reward/rew_lin_vel_xy: 5.4698
      Episode_Reward/rew_ang_vel_z: 2.3165
    Episode_Reward/pen_base_height: -0.3043
      Episode_Reward/pen_lin_vel_z: -0.0447
     Episode_Reward/pen_ang_vel_xy: -0.2032
   Episode_Reward/pen_joint_torque: -0.2264
    Episode_Reward/pen_joint_accel: -0.1178
    Episode_Reward/pen_action_rate: -0.1278
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2801
Episode_Reward/pen_flat_orientation: -0.1191
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.4296
   Episode_Reward/foot_landing_vel: -0.1550
   Episode_Reward/test_gait_reward: -0.9258
Metrics/base_velocity/error_vel_xy: 1.2438
Metrics/base_velocity/error_vel_yaw: 1.3809
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 1.18s
                        Total time: 1200.08s
                               ETA: 2062.1s

################################################################################
                     [1m Learning iteration 1104/3000 [0m                     

                       Computation: 84831 steps/s (collection: 1.029s, learning 0.130s)
               Value function loss: 0.8208
                    Surrogate loss: 0.0050
             Mean action noise std: 0.9347
                     Learning rate: 0.0001
                       Mean reward: 111.11
               Mean episode length: 955.06
       Episode_Reward/keep_balance: 0.9278
     Episode_Reward/rew_lin_vel_xy: 5.1264
      Episode_Reward/rew_ang_vel_z: 2.2580
    Episode_Reward/pen_base_height: -0.2990
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.1865
   Episode_Reward/pen_joint_torque: -0.2205
    Episode_Reward/pen_joint_accel: -0.1127
    Episode_Reward/pen_action_rate: -0.1230
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2688
Episode_Reward/pen_flat_orientation: -0.1190
  Episode_Reward/pen_feet_distance: -0.0085
Episode_Reward/pen_feet_regulation: -0.3986
   Episode_Reward/foot_landing_vel: -0.1393
   Episode_Reward/test_gait_reward: -0.9013
Metrics/base_velocity/error_vel_xy: 1.2600
Metrics/base_velocity/error_vel_yaw: 1.3170
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 1.16s
                        Total time: 1201.24s
                               ETA: 2061.1s

################################################################################
                     [1m Learning iteration 1105/3000 [0m                     

                       Computation: 87317 steps/s (collection: 1.003s, learning 0.123s)
               Value function loss: 0.7804
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9346
                     Learning rate: 0.0001
                       Mean reward: 107.29
               Mean episode length: 962.76
       Episode_Reward/keep_balance: 0.9611
     Episode_Reward/rew_lin_vel_xy: 5.2220
      Episode_Reward/rew_ang_vel_z: 2.3051
    Episode_Reward/pen_base_height: -0.3132
      Episode_Reward/pen_lin_vel_z: -0.0448
     Episode_Reward/pen_ang_vel_xy: -0.1968
   Episode_Reward/pen_joint_torque: -0.2245
    Episode_Reward/pen_joint_accel: -0.1082
    Episode_Reward/pen_action_rate: -0.1302
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0923
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2826
Episode_Reward/pen_flat_orientation: -0.1271
  Episode_Reward/pen_feet_distance: -0.0105
Episode_Reward/pen_feet_regulation: -0.4281
   Episode_Reward/foot_landing_vel: -0.1539
   Episode_Reward/test_gait_reward: -0.9345
Metrics/base_velocity/error_vel_xy: 1.3677
Metrics/base_velocity/error_vel_yaw: 1.4139
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 1.13s
                        Total time: 1202.37s
                               ETA: 2060.1s

################################################################################
                     [1m Learning iteration 1106/3000 [0m                     

                       Computation: 92308 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.7376
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9328
                     Learning rate: 0.0003
                       Mean reward: 108.62
               Mean episode length: 959.02
       Episode_Reward/keep_balance: 0.9645
     Episode_Reward/rew_lin_vel_xy: 5.2631
      Episode_Reward/rew_ang_vel_z: 2.2725
    Episode_Reward/pen_base_height: -0.3024
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.2030
   Episode_Reward/pen_joint_torque: -0.2199
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1300
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0598
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2862
Episode_Reward/pen_flat_orientation: -0.1209
  Episode_Reward/pen_feet_distance: -0.0100
Episode_Reward/pen_feet_regulation: -0.4273
   Episode_Reward/foot_landing_vel: -0.1454
   Episode_Reward/test_gait_reward: -0.9375
Metrics/base_velocity/error_vel_xy: 1.3330
Metrics/base_velocity/error_vel_yaw: 1.4396
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 1.06s
                        Total time: 1203.43s
                               ETA: 2059.0s

################################################################################
                     [1m Learning iteration 1107/3000 [0m                     

                       Computation: 82868 steps/s (collection: 1.057s, learning 0.130s)
               Value function loss: 0.8005
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9323
                     Learning rate: 0.0006
                       Mean reward: 109.12
               Mean episode length: 972.34
       Episode_Reward/keep_balance: 0.9724
     Episode_Reward/rew_lin_vel_xy: 5.3525
      Episode_Reward/rew_ang_vel_z: 2.3097
    Episode_Reward/pen_base_height: -0.3166
      Episode_Reward/pen_lin_vel_z: -0.0457
     Episode_Reward/pen_ang_vel_xy: -0.2013
   Episode_Reward/pen_joint_torque: -0.2279
    Episode_Reward/pen_joint_accel: -0.1167
    Episode_Reward/pen_action_rate: -0.1324
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0608
   Episode_Reward/pen_joint_powers: -0.0922
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2877
Episode_Reward/pen_flat_orientation: -0.1208
  Episode_Reward/pen_feet_distance: -0.0096
Episode_Reward/pen_feet_regulation: -0.4399
   Episode_Reward/foot_landing_vel: -0.1475
   Episode_Reward/test_gait_reward: -0.9451
Metrics/base_velocity/error_vel_xy: 1.3141
Metrics/base_velocity/error_vel_yaw: 1.4479
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 1.19s
                        Total time: 1204.62s
                               ETA: 2058.1s

################################################################################
                     [1m Learning iteration 1108/3000 [0m                     

                       Computation: 91117 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.7747
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9316
                     Learning rate: 0.0004
                       Mean reward: 108.45
               Mean episode length: 958.32
       Episode_Reward/keep_balance: 0.9582
     Episode_Reward/rew_lin_vel_xy: 5.2785
      Episode_Reward/rew_ang_vel_z: 2.2876
    Episode_Reward/pen_base_height: -0.3138
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.2019
   Episode_Reward/pen_joint_torque: -0.2208
    Episode_Reward/pen_joint_accel: -0.1136
    Episode_Reward/pen_action_rate: -0.1299
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2829
Episode_Reward/pen_flat_orientation: -0.1222
  Episode_Reward/pen_feet_distance: -0.0069
Episode_Reward/pen_feet_regulation: -0.4032
   Episode_Reward/foot_landing_vel: -0.1484
   Episode_Reward/test_gait_reward: -0.9244
Metrics/base_velocity/error_vel_xy: 1.3444
Metrics/base_velocity/error_vel_yaw: 1.4184
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 1.08s
                        Total time: 1205.70s
                               ETA: 2057.0s

################################################################################
                     [1m Learning iteration 1109/3000 [0m                     

                       Computation: 84741 steps/s (collection: 1.035s, learning 0.125s)
               Value function loss: 0.7832
                    Surrogate loss: -0.0038
             Mean action noise std: 0.9318
                     Learning rate: 0.0006
                       Mean reward: 115.01
               Mean episode length: 970.56
       Episode_Reward/keep_balance: 0.9619
     Episode_Reward/rew_lin_vel_xy: 5.5024
      Episode_Reward/rew_ang_vel_z: 2.3248
    Episode_Reward/pen_base_height: -0.2984
      Episode_Reward/pen_lin_vel_z: -0.0427
     Episode_Reward/pen_ang_vel_xy: -0.1964
   Episode_Reward/pen_joint_torque: -0.2163
    Episode_Reward/pen_joint_accel: -0.1275
    Episode_Reward/pen_action_rate: -0.1281
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2836
Episode_Reward/pen_flat_orientation: -0.1146
  Episode_Reward/pen_feet_distance: -0.0095
Episode_Reward/pen_feet_regulation: -0.4057
   Episode_Reward/foot_landing_vel: -0.1505
   Episode_Reward/test_gait_reward: -0.9254
Metrics/base_velocity/error_vel_xy: 1.1992
Metrics/base_velocity/error_vel_yaw: 1.3728
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 1.16s
                        Total time: 1206.86s
                               ETA: 2056.0s

################################################################################
                     [1m Learning iteration 1110/3000 [0m                     

                       Computation: 89512 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.7327
                    Surrogate loss: -0.0015
             Mean action noise std: 0.9312
                     Learning rate: 0.0002
                       Mean reward: 109.08
               Mean episode length: 968.16
       Episode_Reward/keep_balance: 0.9645
     Episode_Reward/rew_lin_vel_xy: 5.3535
      Episode_Reward/rew_ang_vel_z: 2.2916
    Episode_Reward/pen_base_height: -0.3129
      Episode_Reward/pen_lin_vel_z: -0.0433
     Episode_Reward/pen_ang_vel_xy: -0.2010
   Episode_Reward/pen_joint_torque: -0.2230
    Episode_Reward/pen_joint_accel: -0.1274
    Episode_Reward/pen_action_rate: -0.1308
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0605
   Episode_Reward/pen_joint_powers: -0.0916
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2847
Episode_Reward/pen_flat_orientation: -0.1248
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.4339
   Episode_Reward/foot_landing_vel: -0.1426
   Episode_Reward/test_gait_reward: -0.9420
Metrics/base_velocity/error_vel_xy: 1.3029
Metrics/base_velocity/error_vel_yaw: 1.4380
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 1.10s
                        Total time: 1207.96s
                               ETA: 2054.9s

################################################################################
                     [1m Learning iteration 1111/3000 [0m                     

                       Computation: 89916 steps/s (collection: 0.967s, learning 0.126s)
               Value function loss: 0.7579
                    Surrogate loss: -0.0016
             Mean action noise std: 0.9301
                     Learning rate: 0.0003
                       Mean reward: 109.14
               Mean episode length: 961.85
       Episode_Reward/keep_balance: 0.9678
     Episode_Reward/rew_lin_vel_xy: 5.4558
      Episode_Reward/rew_ang_vel_z: 2.2789
    Episode_Reward/pen_base_height: -0.3223
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.2086
   Episode_Reward/pen_joint_torque: -0.2259
    Episode_Reward/pen_joint_accel: -0.1163
    Episode_Reward/pen_action_rate: -0.1332
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0611
   Episode_Reward/pen_joint_powers: -0.0930
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2904
Episode_Reward/pen_flat_orientation: -0.1223
  Episode_Reward/pen_feet_distance: -0.0086
Episode_Reward/pen_feet_regulation: -0.4455
   Episode_Reward/foot_landing_vel: -0.1478
   Episode_Reward/test_gait_reward: -0.9479
Metrics/base_velocity/error_vel_xy: 1.2754
Metrics/base_velocity/error_vel_yaw: 1.4573
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 1.09s
                        Total time: 1209.05s
                               ETA: 2053.9s

################################################################################
                     [1m Learning iteration 1112/3000 [0m                     

                       Computation: 89276 steps/s (collection: 0.975s, learning 0.126s)
               Value function loss: 0.7348
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9313
                     Learning rate: 0.0004
                       Mean reward: 108.95
               Mean episode length: 969.49
       Episode_Reward/keep_balance: 0.9698
     Episode_Reward/rew_lin_vel_xy: 5.3845
      Episode_Reward/rew_ang_vel_z: 2.3010
    Episode_Reward/pen_base_height: -0.3154
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.2095
   Episode_Reward/pen_joint_torque: -0.2179
    Episode_Reward/pen_joint_accel: -0.1238
    Episode_Reward/pen_action_rate: -0.1335
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0617
   Episode_Reward/pen_joint_powers: -0.0921
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2935
Episode_Reward/pen_flat_orientation: -0.1233
  Episode_Reward/pen_feet_distance: -0.0079
Episode_Reward/pen_feet_regulation: -0.4287
   Episode_Reward/foot_landing_vel: -0.1527
   Episode_Reward/test_gait_reward: -0.9447
Metrics/base_velocity/error_vel_xy: 1.3108
Metrics/base_velocity/error_vel_yaw: 1.4500
      Episode_Termination/time_out: 4.9583
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 1.10s
                        Total time: 1210.15s
                               ETA: 2052.8s

################################################################################
                     [1m Learning iteration 1113/3000 [0m                     

                       Computation: 88932 steps/s (collection: 0.981s, learning 0.124s)
               Value function loss: 0.7565
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9336
                     Learning rate: 0.0009
                       Mean reward: 103.83
               Mean episode length: 951.18
       Episode_Reward/keep_balance: 0.9386
     Episode_Reward/rew_lin_vel_xy: 5.0736
      Episode_Reward/rew_ang_vel_z: 2.2034
    Episode_Reward/pen_base_height: -0.3070
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.2048
   Episode_Reward/pen_joint_torque: -0.2214
    Episode_Reward/pen_joint_accel: -0.1254
    Episode_Reward/pen_action_rate: -0.1301
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0610
   Episode_Reward/pen_joint_powers: -0.0921
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2826
Episode_Reward/pen_flat_orientation: -0.1265
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.4353
   Episode_Reward/foot_landing_vel: -0.1472
   Episode_Reward/test_gait_reward: -0.9072
Metrics/base_velocity/error_vel_xy: 1.3408
Metrics/base_velocity/error_vel_yaw: 1.4301
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 1.11s
                        Total time: 1211.26s
                               ETA: 2051.7s

################################################################################
                     [1m Learning iteration 1114/3000 [0m                     

                       Computation: 90118 steps/s (collection: 0.964s, learning 0.127s)
               Value function loss: 0.8211
                    Surrogate loss: -0.0014
             Mean action noise std: 0.9348
                     Learning rate: 0.0004
                       Mean reward: 111.48
               Mean episode length: 968.85
       Episode_Reward/keep_balance: 0.9575
     Episode_Reward/rew_lin_vel_xy: 5.3704
      Episode_Reward/rew_ang_vel_z: 2.2400
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.1999
   Episode_Reward/pen_joint_torque: -0.2177
    Episode_Reward/pen_joint_accel: -0.1145
    Episode_Reward/pen_action_rate: -0.1311
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0613
   Episode_Reward/pen_joint_powers: -0.0917
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2867
Episode_Reward/pen_flat_orientation: -0.1213
  Episode_Reward/pen_feet_distance: -0.0094
Episode_Reward/pen_feet_regulation: -0.4472
   Episode_Reward/foot_landing_vel: -0.1598
   Episode_Reward/test_gait_reward: -0.9274
Metrics/base_velocity/error_vel_xy: 1.2444
Metrics/base_velocity/error_vel_yaw: 1.4574
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 1.09s
                        Total time: 1212.35s
                               ETA: 2050.7s

################################################################################
                     [1m Learning iteration 1115/3000 [0m                     

                       Computation: 88753 steps/s (collection: 0.984s, learning 0.124s)
               Value function loss: 0.7814
                    Surrogate loss: -0.0052
             Mean action noise std: 0.9345
                     Learning rate: 0.0009
                       Mean reward: 109.50
               Mean episode length: 958.02
       Episode_Reward/keep_balance: 0.9563
     Episode_Reward/rew_lin_vel_xy: 5.3894
      Episode_Reward/rew_ang_vel_z: 2.2700
    Episode_Reward/pen_base_height: -0.3280
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.2044
   Episode_Reward/pen_joint_torque: -0.2317
    Episode_Reward/pen_joint_accel: -0.1270
    Episode_Reward/pen_action_rate: -0.1330
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0625
   Episode_Reward/pen_joint_powers: -0.0950
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2870
Episode_Reward/pen_flat_orientation: -0.1285
  Episode_Reward/pen_feet_distance: -0.0087
Episode_Reward/pen_feet_regulation: -0.4486
   Episode_Reward/foot_landing_vel: -0.1562
   Episode_Reward/test_gait_reward: -0.9316
Metrics/base_velocity/error_vel_xy: 1.2807
Metrics/base_velocity/error_vel_yaw: 1.4303
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 1.11s
                        Total time: 1213.45s
                               ETA: 2049.6s

################################################################################
                     [1m Learning iteration 1116/3000 [0m                     

                       Computation: 89833 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.7627
                    Surrogate loss: -0.0045
             Mean action noise std: 0.9361
                     Learning rate: 0.0013
                       Mean reward: 105.62
               Mean episode length: 947.50
       Episode_Reward/keep_balance: 0.9555
     Episode_Reward/rew_lin_vel_xy: 5.2314
      Episode_Reward/rew_ang_vel_z: 2.2320
    Episode_Reward/pen_base_height: -0.3218
      Episode_Reward/pen_lin_vel_z: -0.0451
     Episode_Reward/pen_ang_vel_xy: -0.2002
   Episode_Reward/pen_joint_torque: -0.2292
    Episode_Reward/pen_joint_accel: -0.1273
    Episode_Reward/pen_action_rate: -0.1321
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0631
   Episode_Reward/pen_joint_powers: -0.0948
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2858
Episode_Reward/pen_flat_orientation: -0.1257
  Episode_Reward/pen_feet_distance: -0.0092
Episode_Reward/pen_feet_regulation: -0.4407
   Episode_Reward/foot_landing_vel: -0.1561
   Episode_Reward/test_gait_reward: -0.9258
Metrics/base_velocity/error_vel_xy: 1.3352
Metrics/base_velocity/error_vel_yaw: 1.4675
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 1.09s
                        Total time: 1214.55s
                               ETA: 2048.5s

################################################################################
                     [1m Learning iteration 1117/3000 [0m                     

                       Computation: 88306 steps/s (collection: 0.990s, learning 0.124s)
               Value function loss: 0.7332
                    Surrogate loss: -0.0012
             Mean action noise std: 0.9356
                     Learning rate: 0.0006
                       Mean reward: 105.46
               Mean episode length: 943.67
       Episode_Reward/keep_balance: 0.9568
     Episode_Reward/rew_lin_vel_xy: 5.3093
      Episode_Reward/rew_ang_vel_z: 2.2176
    Episode_Reward/pen_base_height: -0.3076
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.2070
   Episode_Reward/pen_joint_torque: -0.2292
    Episode_Reward/pen_joint_accel: -0.1220
    Episode_Reward/pen_action_rate: -0.1340
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0636
   Episode_Reward/pen_joint_powers: -0.0960
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2876
Episode_Reward/pen_flat_orientation: -0.1266
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.4469
   Episode_Reward/foot_landing_vel: -0.1524
   Episode_Reward/test_gait_reward: -0.9325
Metrics/base_velocity/error_vel_xy: 1.2522
Metrics/base_velocity/error_vel_yaw: 1.4752
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 1.11s
                        Total time: 1215.66s
                               ETA: 2047.5s

################################################################################
                     [1m Learning iteration 1118/3000 [0m                     

                       Computation: 88636 steps/s (collection: 0.983s, learning 0.126s)
               Value function loss: 0.6567
                    Surrogate loss: -0.0054
             Mean action noise std: 0.9319
                     Learning rate: 0.0009
                       Mean reward: 110.72
               Mean episode length: 973.85
       Episode_Reward/keep_balance: 0.9774
     Episode_Reward/rew_lin_vel_xy: 5.4635
      Episode_Reward/rew_ang_vel_z: 2.3274
    Episode_Reward/pen_base_height: -0.3118
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.2006
   Episode_Reward/pen_joint_torque: -0.2196
    Episode_Reward/pen_joint_accel: -0.1343
    Episode_Reward/pen_action_rate: -0.1320
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0605
   Episode_Reward/pen_joint_powers: -0.0908
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2902
Episode_Reward/pen_flat_orientation: -0.1197
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.4326
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.9428
Metrics/base_velocity/error_vel_xy: 1.2799
Metrics/base_velocity/error_vel_yaw: 1.4456
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 1.11s
                        Total time: 1216.77s
                               ETA: 2046.4s

################################################################################
                     [1m Learning iteration 1119/3000 [0m                     

                       Computation: 89414 steps/s (collection: 0.974s, learning 0.126s)
               Value function loss: 0.7460
                    Surrogate loss: -0.0039
             Mean action noise std: 0.9321
                     Learning rate: 0.0006
                       Mean reward: 109.45
               Mean episode length: 959.48
       Episode_Reward/keep_balance: 0.9537
     Episode_Reward/rew_lin_vel_xy: 5.3455
      Episode_Reward/rew_ang_vel_z: 2.2001
    Episode_Reward/pen_base_height: -0.3063
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.2023
   Episode_Reward/pen_joint_torque: -0.2174
    Episode_Reward/pen_joint_accel: -0.1273
    Episode_Reward/pen_action_rate: -0.1334
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0606
   Episode_Reward/pen_joint_powers: -0.0910
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2917
Episode_Reward/pen_flat_orientation: -0.1176
  Episode_Reward/pen_feet_distance: -0.0079
Episode_Reward/pen_feet_regulation: -0.4310
   Episode_Reward/foot_landing_vel: -0.1429
   Episode_Reward/test_gait_reward: -0.9289
Metrics/base_velocity/error_vel_xy: 1.2336
Metrics/base_velocity/error_vel_yaw: 1.5009
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 1.10s
                        Total time: 1217.87s
                               ETA: 2045.4s

################################################################################
                     [1m Learning iteration 1120/3000 [0m                     

                       Computation: 91912 steps/s (collection: 0.943s, learning 0.127s)
               Value function loss: 0.6871
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9312
                     Learning rate: 0.0006
                       Mean reward: 110.97
               Mean episode length: 971.64
       Episode_Reward/keep_balance: 0.9736
     Episode_Reward/rew_lin_vel_xy: 5.4736
      Episode_Reward/rew_ang_vel_z: 2.2998
    Episode_Reward/pen_base_height: -0.3150
      Episode_Reward/pen_lin_vel_z: -0.0438
     Episode_Reward/pen_ang_vel_xy: -0.1972
   Episode_Reward/pen_joint_torque: -0.2377
    Episode_Reward/pen_joint_accel: -0.1274
    Episode_Reward/pen_action_rate: -0.1336
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0626
   Episode_Reward/pen_joint_powers: -0.0957
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2899
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.4521
   Episode_Reward/foot_landing_vel: -0.1504
   Episode_Reward/test_gait_reward: -0.9505
Metrics/base_velocity/error_vel_xy: 1.2570
Metrics/base_velocity/error_vel_yaw: 1.4631
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 1.07s
                        Total time: 1218.94s
                               ETA: 2044.3s

################################################################################
                     [1m Learning iteration 1121/3000 [0m                     

                       Computation: 89406 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.8053
                    Surrogate loss: 0.0018
             Mean action noise std: 0.9313
                     Learning rate: 0.0001
                       Mean reward: 114.74
               Mean episode length: 982.25
       Episode_Reward/keep_balance: 0.9842
     Episode_Reward/rew_lin_vel_xy: 5.6054
      Episode_Reward/rew_ang_vel_z: 2.3650
    Episode_Reward/pen_base_height: -0.3174
      Episode_Reward/pen_lin_vel_z: -0.0432
     Episode_Reward/pen_ang_vel_xy: -0.2033
   Episode_Reward/pen_joint_torque: -0.2319
    Episode_Reward/pen_joint_accel: -0.1142
    Episode_Reward/pen_action_rate: -0.1314
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0610
   Episode_Reward/pen_joint_powers: -0.0936
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2880
Episode_Reward/pen_flat_orientation: -0.1197
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.4323
   Episode_Reward/foot_landing_vel: -0.1516
   Episode_Reward/test_gait_reward: -0.9540
Metrics/base_velocity/error_vel_xy: 1.2550
Metrics/base_velocity/error_vel_yaw: 1.4244
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 1.10s
                        Total time: 1220.04s
                               ETA: 2043.2s

################################################################################
                     [1m Learning iteration 1122/3000 [0m                     

                       Computation: 84426 steps/s (collection: 1.032s, learning 0.132s)
               Value function loss: 0.7219
                    Surrogate loss: -0.0045
             Mean action noise std: 0.9300
                     Learning rate: 0.0003
                       Mean reward: 109.50
               Mean episode length: 937.95
       Episode_Reward/keep_balance: 0.9294
     Episode_Reward/rew_lin_vel_xy: 5.2815
      Episode_Reward/rew_ang_vel_z: 2.1745
    Episode_Reward/pen_base_height: -0.2984
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1990
   Episode_Reward/pen_joint_torque: -0.2109
    Episode_Reward/pen_joint_accel: -0.1195
    Episode_Reward/pen_action_rate: -0.1273
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2790
Episode_Reward/pen_flat_orientation: -0.1178
  Episode_Reward/pen_feet_distance: -0.0072
Episode_Reward/pen_feet_regulation: -0.4162
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.8985
Metrics/base_velocity/error_vel_xy: 1.1548
Metrics/base_velocity/error_vel_yaw: 1.4152
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 1.16s
                        Total time: 1221.20s
                               ETA: 2042.2s

################################################################################
                     [1m Learning iteration 1123/3000 [0m                     

                       Computation: 88127 steps/s (collection: 0.989s, learning 0.126s)
               Value function loss: 0.7963
                    Surrogate loss: -0.0039
             Mean action noise std: 0.9287
                     Learning rate: 0.0006
                       Mean reward: 106.88
               Mean episode length: 948.27
       Episode_Reward/keep_balance: 0.9557
     Episode_Reward/rew_lin_vel_xy: 5.4134
      Episode_Reward/rew_ang_vel_z: 2.2221
    Episode_Reward/pen_base_height: -0.3114
      Episode_Reward/pen_lin_vel_z: -0.0452
     Episode_Reward/pen_ang_vel_xy: -0.2020
   Episode_Reward/pen_joint_torque: -0.2299
    Episode_Reward/pen_joint_accel: -0.1276
    Episode_Reward/pen_action_rate: -0.1323
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0631
   Episode_Reward/pen_joint_powers: -0.0955
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2868
Episode_Reward/pen_flat_orientation: -0.1230
  Episode_Reward/pen_feet_distance: -0.0081
Episode_Reward/pen_feet_regulation: -0.4666
   Episode_Reward/foot_landing_vel: -0.1553
   Episode_Reward/test_gait_reward: -0.9403
Metrics/base_velocity/error_vel_xy: 1.2224
Metrics/base_velocity/error_vel_yaw: 1.4665
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 1.12s
                        Total time: 1222.32s
                               ETA: 2041.2s

################################################################################
                     [1m Learning iteration 1124/3000 [0m                     

                       Computation: 88489 steps/s (collection: 0.984s, learning 0.127s)
               Value function loss: 0.7767
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9293
                     Learning rate: 0.0003
                       Mean reward: 106.31
               Mean episode length: 947.06
       Episode_Reward/keep_balance: 0.9570
     Episode_Reward/rew_lin_vel_xy: 5.3360
      Episode_Reward/rew_ang_vel_z: 2.2422
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0448
     Episode_Reward/pen_ang_vel_xy: -0.1992
   Episode_Reward/pen_joint_torque: -0.2224
    Episode_Reward/pen_joint_accel: -0.1198
    Episode_Reward/pen_action_rate: -0.1302
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0613
   Episode_Reward/pen_joint_powers: -0.0924
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2844
Episode_Reward/pen_flat_orientation: -0.1180
  Episode_Reward/pen_feet_distance: -0.0073
Episode_Reward/pen_feet_regulation: -0.4511
   Episode_Reward/foot_landing_vel: -0.1481
   Episode_Reward/test_gait_reward: -0.9350
Metrics/base_velocity/error_vel_xy: 1.2633
Metrics/base_velocity/error_vel_yaw: 1.4454
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 1.11s
                        Total time: 1223.43s
                               ETA: 2040.1s

################################################################################
                     [1m Learning iteration 1125/3000 [0m                     

                       Computation: 88303 steps/s (collection: 0.988s, learning 0.125s)
               Value function loss: 0.8401
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9294
                     Learning rate: 0.0004
                       Mean reward: 109.05
               Mean episode length: 953.85
       Episode_Reward/keep_balance: 0.9619
     Episode_Reward/rew_lin_vel_xy: 5.4410
      Episode_Reward/rew_ang_vel_z: 2.2791
    Episode_Reward/pen_base_height: -0.3305
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.2005
   Episode_Reward/pen_joint_torque: -0.2287
    Episode_Reward/pen_joint_accel: -0.1181
    Episode_Reward/pen_action_rate: -0.1310
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0625
   Episode_Reward/pen_joint_powers: -0.0943
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2834
Episode_Reward/pen_flat_orientation: -0.1215
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.4631
   Episode_Reward/foot_landing_vel: -0.1514
   Episode_Reward/test_gait_reward: -0.9386
Metrics/base_velocity/error_vel_xy: 1.2310
Metrics/base_velocity/error_vel_yaw: 1.4278
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 1.11s
                        Total time: 1224.54s
                               ETA: 2039.1s

################################################################################
                     [1m Learning iteration 1126/3000 [0m                     

                       Computation: 89917 steps/s (collection: 0.966s, learning 0.128s)
               Value function loss: 0.9563
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9291
                     Learning rate: 0.0009
                       Mean reward: 109.39
               Mean episode length: 943.01
       Episode_Reward/keep_balance: 0.9138
     Episode_Reward/rew_lin_vel_xy: 5.1821
      Episode_Reward/rew_ang_vel_z: 2.1587
    Episode_Reward/pen_base_height: -0.3176
      Episode_Reward/pen_lin_vel_z: -0.0422
     Episode_Reward/pen_ang_vel_xy: -0.1938
   Episode_Reward/pen_joint_torque: -0.2160
    Episode_Reward/pen_joint_accel: -0.1169
    Episode_Reward/pen_action_rate: -0.1246
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2722
Episode_Reward/pen_flat_orientation: -0.1268
  Episode_Reward/pen_feet_distance: -0.0086
Episode_Reward/pen_feet_regulation: -0.4321
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.8940
Metrics/base_velocity/error_vel_xy: 1.1729
Metrics/base_velocity/error_vel_yaw: 1.3796
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 1.09s
                        Total time: 1225.64s
                               ETA: 2038.0s

################################################################################
                     [1m Learning iteration 1127/3000 [0m                     

                       Computation: 89895 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.7825
                    Surrogate loss: 0.0005
             Mean action noise std: 0.9282
                     Learning rate: 0.0003
                       Mean reward: 103.88
               Mean episode length: 894.70
       Episode_Reward/keep_balance: 0.9261
     Episode_Reward/rew_lin_vel_xy: 5.3503
      Episode_Reward/rew_ang_vel_z: 2.1440
    Episode_Reward/pen_base_height: -0.3005
      Episode_Reward/pen_lin_vel_z: -0.0414
     Episode_Reward/pen_ang_vel_xy: -0.1988
   Episode_Reward/pen_joint_torque: -0.2127
    Episode_Reward/pen_joint_accel: -0.1283
    Episode_Reward/pen_action_rate: -0.1262
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0896
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2781
Episode_Reward/pen_flat_orientation: -0.1158
  Episode_Reward/pen_feet_distance: -0.0056
Episode_Reward/pen_feet_regulation: -0.4260
   Episode_Reward/foot_landing_vel: -0.1513
   Episode_Reward/test_gait_reward: -0.8986
Metrics/base_velocity/error_vel_xy: 1.1187
Metrics/base_velocity/error_vel_yaw: 1.4249
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 1.09s
                        Total time: 1226.73s
                               ETA: 2036.9s

################################################################################
                     [1m Learning iteration 1128/3000 [0m                     

                       Computation: 88900 steps/s (collection: 0.979s, learning 0.127s)
               Value function loss: 0.8033
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9272
                     Learning rate: 0.0006
                       Mean reward: 104.65
               Mean episode length: 928.76
       Episode_Reward/keep_balance: 0.9217
     Episode_Reward/rew_lin_vel_xy: 5.1435
      Episode_Reward/rew_ang_vel_z: 2.1158
    Episode_Reward/pen_base_height: -0.3186
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.2008
   Episode_Reward/pen_joint_torque: -0.2216
    Episode_Reward/pen_joint_accel: -0.1130
    Episode_Reward/pen_action_rate: -0.1292
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0928
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2797
Episode_Reward/pen_flat_orientation: -0.1259
  Episode_Reward/pen_feet_distance: -0.0084
Episode_Reward/pen_feet_regulation: -0.4419
   Episode_Reward/foot_landing_vel: -0.1364
   Episode_Reward/test_gait_reward: -0.9070
Metrics/base_velocity/error_vel_xy: 1.2088
Metrics/base_velocity/error_vel_yaw: 1.4516
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 1.11s
                        Total time: 1227.84s
                               ETA: 2035.9s

################################################################################
                     [1m Learning iteration 1129/3000 [0m                     

                       Computation: 89219 steps/s (collection: 0.975s, learning 0.127s)
               Value function loss: 0.8282
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9276
                     Learning rate: 0.0009
                       Mean reward: 110.02
               Mean episode length: 951.57
       Episode_Reward/keep_balance: 0.9597
     Episode_Reward/rew_lin_vel_xy: 5.4422
      Episode_Reward/rew_ang_vel_z: 2.2454
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0429
     Episode_Reward/pen_ang_vel_xy: -0.1994
   Episode_Reward/pen_joint_torque: -0.2309
    Episode_Reward/pen_joint_accel: -0.1141
    Episode_Reward/pen_action_rate: -0.1322
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0609
   Episode_Reward/pen_joint_powers: -0.0938
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2889
Episode_Reward/pen_flat_orientation: -0.1200
  Episode_Reward/pen_feet_distance: -0.0070
Episode_Reward/pen_feet_regulation: -0.4335
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.9352
Metrics/base_velocity/error_vel_xy: 1.2281
Metrics/base_velocity/error_vel_yaw: 1.4704
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 1.10s
                        Total time: 1228.94s
                               ETA: 2034.8s

################################################################################
                     [1m Learning iteration 1130/3000 [0m                     

                       Computation: 89336 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 0.8132
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9289
                     Learning rate: 0.0013
                       Mean reward: 104.89
               Mean episode length: 927.39
       Episode_Reward/keep_balance: 0.9466
     Episode_Reward/rew_lin_vel_xy: 5.3387
      Episode_Reward/rew_ang_vel_z: 2.2306
    Episode_Reward/pen_base_height: -0.3232
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1994
   Episode_Reward/pen_joint_torque: -0.2274
    Episode_Reward/pen_joint_accel: -0.1203
    Episode_Reward/pen_action_rate: -0.1308
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0607
   Episode_Reward/pen_joint_powers: -0.0933
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2829
Episode_Reward/pen_flat_orientation: -0.1244
  Episode_Reward/pen_feet_distance: -0.0082
Episode_Reward/pen_feet_regulation: -0.4489
   Episode_Reward/foot_landing_vel: -0.1413
   Episode_Reward/test_gait_reward: -0.9273
Metrics/base_velocity/error_vel_xy: 1.2105
Metrics/base_velocity/error_vel_yaw: 1.4355
      Episode_Termination/time_out: 5.0417
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 1.10s
                        Total time: 1230.04s
                               ETA: 2033.8s

################################################################################
                     [1m Learning iteration 1131/3000 [0m                     

                       Computation: 90220 steps/s (collection: 0.964s, learning 0.126s)
               Value function loss: 0.8646
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9309
                     Learning rate: 0.0019
                       Mean reward: 114.46
               Mean episode length: 951.42
       Episode_Reward/keep_balance: 0.9477
     Episode_Reward/rew_lin_vel_xy: 5.5733
      Episode_Reward/rew_ang_vel_z: 2.2573
    Episode_Reward/pen_base_height: -0.3025
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1986
   Episode_Reward/pen_joint_torque: -0.2149
    Episode_Reward/pen_joint_accel: -0.1110
    Episode_Reward/pen_action_rate: -0.1266
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2796
Episode_Reward/pen_flat_orientation: -0.1144
  Episode_Reward/pen_feet_distance: -0.0063
Episode_Reward/pen_feet_regulation: -0.4149
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.9120
Metrics/base_velocity/error_vel_xy: 1.1013
Metrics/base_velocity/error_vel_yaw: 1.4007
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 1.09s
                        Total time: 1231.13s
                               ETA: 2032.7s

################################################################################
                     [1m Learning iteration 1132/3000 [0m                     

                       Computation: 88099 steps/s (collection: 0.987s, learning 0.128s)
               Value function loss: 0.7702
                    Surrogate loss: -0.0012
             Mean action noise std: 0.9313
                     Learning rate: 0.0009
                       Mean reward: 111.23
               Mean episode length: 964.65
       Episode_Reward/keep_balance: 0.9651
     Episode_Reward/rew_lin_vel_xy: 5.4734
      Episode_Reward/rew_ang_vel_z: 2.3111
    Episode_Reward/pen_base_height: -0.3402
      Episode_Reward/pen_lin_vel_z: -0.0443
     Episode_Reward/pen_ang_vel_xy: -0.2003
   Episode_Reward/pen_joint_torque: -0.2413
    Episode_Reward/pen_joint_accel: -0.1210
    Episode_Reward/pen_action_rate: -0.1309
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0622
   Episode_Reward/pen_joint_powers: -0.0962
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2807
Episode_Reward/pen_flat_orientation: -0.1254
  Episode_Reward/pen_feet_distance: -0.0100
Episode_Reward/pen_feet_regulation: -0.4504
   Episode_Reward/foot_landing_vel: -0.1526
   Episode_Reward/test_gait_reward: -0.9374
Metrics/base_velocity/error_vel_xy: 1.2502
Metrics/base_velocity/error_vel_yaw: 1.4126
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 1.12s
                        Total time: 1232.24s
                               ETA: 2031.6s

################################################################################
                     [1m Learning iteration 1133/3000 [0m                     

                       Computation: 82813 steps/s (collection: 1.065s, learning 0.122s)
               Value function loss: 0.8077
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9307
                     Learning rate: 0.0006
                       Mean reward: 111.24
               Mean episode length: 969.39
       Episode_Reward/keep_balance: 0.9745
     Episode_Reward/rew_lin_vel_xy: 5.5610
      Episode_Reward/rew_ang_vel_z: 2.2788
    Episode_Reward/pen_base_height: -0.3155
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.2109
   Episode_Reward/pen_joint_torque: -0.2302
    Episode_Reward/pen_joint_accel: -0.1143
    Episode_Reward/pen_action_rate: -0.1344
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0633
   Episode_Reward/pen_joint_powers: -0.0956
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2929
Episode_Reward/pen_flat_orientation: -0.1191
  Episode_Reward/pen_feet_distance: -0.0094
Episode_Reward/pen_feet_regulation: -0.4589
   Episode_Reward/foot_landing_vel: -0.1553
   Episode_Reward/test_gait_reward: -0.9446
Metrics/base_velocity/error_vel_xy: 1.2304
Metrics/base_velocity/error_vel_yaw: 1.4815
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 1.19s
                        Total time: 1233.43s
                               ETA: 2030.7s

################################################################################
                     [1m Learning iteration 1134/3000 [0m                     

                       Computation: 89753 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.7771
                    Surrogate loss: -0.0046
             Mean action noise std: 0.9311
                     Learning rate: 0.0013
                       Mean reward: 106.80
               Mean episode length: 935.72
       Episode_Reward/keep_balance: 0.9172
     Episode_Reward/rew_lin_vel_xy: 5.2877
      Episode_Reward/rew_ang_vel_z: 2.1308
    Episode_Reward/pen_base_height: -0.3192
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.2027
   Episode_Reward/pen_joint_torque: -0.2162
    Episode_Reward/pen_joint_accel: -0.1194
    Episode_Reward/pen_action_rate: -0.1285
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0917
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2794
Episode_Reward/pen_flat_orientation: -0.1256
  Episode_Reward/pen_feet_distance: -0.0082
Episode_Reward/pen_feet_regulation: -0.4445
   Episode_Reward/foot_landing_vel: -0.1532
   Episode_Reward/test_gait_reward: -0.8965
Metrics/base_velocity/error_vel_xy: 1.1099
Metrics/base_velocity/error_vel_yaw: 1.4086
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 1.10s
                        Total time: 1234.53s
                               ETA: 2029.6s

################################################################################
                     [1m Learning iteration 1135/3000 [0m                     

                       Computation: 88202 steps/s (collection: 0.991s, learning 0.123s)
               Value function loss: 0.9274
                    Surrogate loss: 0.0054
             Mean action noise std: 0.9317
                     Learning rate: 0.0000
                       Mean reward: 113.20
               Mean episode length: 964.58
       Episode_Reward/keep_balance: 0.9723
     Episode_Reward/rew_lin_vel_xy: 5.5858
      Episode_Reward/rew_ang_vel_z: 2.2971
    Episode_Reward/pen_base_height: -0.3201
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.1962
   Episode_Reward/pen_joint_torque: -0.2335
    Episode_Reward/pen_joint_accel: -0.1123
    Episode_Reward/pen_action_rate: -0.1317
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0606
   Episode_Reward/pen_joint_powers: -0.0942
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2863
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0075
Episode_Reward/pen_feet_regulation: -0.4470
   Episode_Reward/foot_landing_vel: -0.1433
   Episode_Reward/test_gait_reward: -0.9513
Metrics/base_velocity/error_vel_xy: 1.1967
Metrics/base_velocity/error_vel_yaw: 1.4515
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 1.11s
                        Total time: 1235.64s
                               ETA: 2028.6s

################################################################################
                     [1m Learning iteration 1136/3000 [0m                     

                       Computation: 85768 steps/s (collection: 1.024s, learning 0.123s)
               Value function loss: 0.7213
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9322
                     Learning rate: 0.0002
                       Mean reward: 102.92
               Mean episode length: 921.26
       Episode_Reward/keep_balance: 0.9158
     Episode_Reward/rew_lin_vel_xy: 5.1033
      Episode_Reward/rew_ang_vel_z: 2.1177
    Episode_Reward/pen_base_height: -0.3199
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.2012
   Episode_Reward/pen_joint_torque: -0.2132
    Episode_Reward/pen_joint_accel: -0.1095
    Episode_Reward/pen_action_rate: -0.1279
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0612
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2770
Episode_Reward/pen_flat_orientation: -0.1239
  Episode_Reward/pen_feet_distance: -0.0094
Episode_Reward/pen_feet_regulation: -0.4469
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.8942
Metrics/base_velocity/error_vel_xy: 1.2100
Metrics/base_velocity/error_vel_yaw: 1.4211
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 1.15s
                        Total time: 1236.79s
                               ETA: 2027.6s

################################################################################
                     [1m Learning iteration 1137/3000 [0m                     

                       Computation: 83655 steps/s (collection: 1.045s, learning 0.130s)
               Value function loss: 0.6954
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9315
                     Learning rate: 0.0004
                       Mean reward: 108.77
               Mean episode length: 952.93
       Episode_Reward/keep_balance: 0.9547
     Episode_Reward/rew_lin_vel_xy: 5.4285
      Episode_Reward/rew_ang_vel_z: 2.2452
    Episode_Reward/pen_base_height: -0.3277
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.2011
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.1152
    Episode_Reward/pen_action_rate: -0.1305
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0618
   Episode_Reward/pen_joint_powers: -0.0938
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2837
Episode_Reward/pen_flat_orientation: -0.1231
  Episode_Reward/pen_feet_distance: -0.0074
Episode_Reward/pen_feet_regulation: -0.4582
   Episode_Reward/foot_landing_vel: -0.1393
   Episode_Reward/test_gait_reward: -0.9423
Metrics/base_velocity/error_vel_xy: 1.1840
Metrics/base_velocity/error_vel_yaw: 1.4438
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 1.18s
                        Total time: 1237.96s
                               ETA: 2026.6s

################################################################################
                     [1m Learning iteration 1138/3000 [0m                     

                       Computation: 84219 steps/s (collection: 1.037s, learning 0.130s)
               Value function loss: 0.7377
                    Surrogate loss: -0.0022
             Mean action noise std: 0.9308
                     Learning rate: 0.0004
                       Mean reward: 117.48
               Mean episode length: 991.13
       Episode_Reward/keep_balance: 0.9926
     Episode_Reward/rew_lin_vel_xy: 5.8005
      Episode_Reward/rew_ang_vel_z: 2.3727
    Episode_Reward/pen_base_height: -0.3170
      Episode_Reward/pen_lin_vel_z: -0.0429
     Episode_Reward/pen_ang_vel_xy: -0.2042
   Episode_Reward/pen_joint_torque: -0.2307
    Episode_Reward/pen_joint_accel: -0.1261
    Episode_Reward/pen_action_rate: -0.1337
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0623
   Episode_Reward/pen_joint_powers: -0.0946
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2943
Episode_Reward/pen_flat_orientation: -0.1142
  Episode_Reward/pen_feet_distance: -0.0067
Episode_Reward/pen_feet_regulation: -0.4502
   Episode_Reward/foot_landing_vel: -0.1474
   Episode_Reward/test_gait_reward: -0.9667
Metrics/base_velocity/error_vel_xy: 1.1678
Metrics/base_velocity/error_vel_yaw: 1.4639
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 1.17s
                        Total time: 1239.13s
                               ETA: 2025.7s

################################################################################
                     [1m Learning iteration 1139/3000 [0m                     

                       Computation: 84841 steps/s (collection: 1.035s, learning 0.124s)
               Value function loss: 0.7503
                    Surrogate loss: 0.0015
             Mean action noise std: 0.9296
                     Learning rate: 0.0001
                       Mean reward: 110.83
               Mean episode length: 967.49
       Episode_Reward/keep_balance: 0.9709
     Episode_Reward/rew_lin_vel_xy: 5.5064
      Episode_Reward/rew_ang_vel_z: 2.2427
    Episode_Reward/pen_base_height: -0.3244
      Episode_Reward/pen_lin_vel_z: -0.0425
     Episode_Reward/pen_ang_vel_xy: -0.2104
   Episode_Reward/pen_joint_torque: -0.2276
    Episode_Reward/pen_joint_accel: -0.1269
    Episode_Reward/pen_action_rate: -0.1361
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0656
   Episode_Reward/pen_joint_powers: -0.0970
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2962
Episode_Reward/pen_flat_orientation: -0.1266
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.4786
   Episode_Reward/foot_landing_vel: -0.1564
   Episode_Reward/test_gait_reward: -0.9522
Metrics/base_velocity/error_vel_xy: 1.2221
Metrics/base_velocity/error_vel_yaw: 1.5252
      Episode_Termination/time_out: 3.1250
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 1.16s
                        Total time: 1240.29s
                               ETA: 2024.7s

################################################################################
                     [1m Learning iteration 1140/3000 [0m                     

                       Computation: 87308 steps/s (collection: 1.001s, learning 0.125s)
               Value function loss: 0.7248
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9287
                     Learning rate: 0.0003
                       Mean reward: 109.82
               Mean episode length: 978.45
       Episode_Reward/keep_balance: 0.9751
     Episode_Reward/rew_lin_vel_xy: 5.5728
      Episode_Reward/rew_ang_vel_z: 2.2856
    Episode_Reward/pen_base_height: -0.3221
      Episode_Reward/pen_lin_vel_z: -0.0465
     Episode_Reward/pen_ang_vel_xy: -0.2013
   Episode_Reward/pen_joint_torque: -0.2322
    Episode_Reward/pen_joint_accel: -0.1199
    Episode_Reward/pen_action_rate: -0.1333
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0634
   Episode_Reward/pen_joint_powers: -0.0959
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2896
Episode_Reward/pen_flat_orientation: -0.1180
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.4804
   Episode_Reward/foot_landing_vel: -0.1577
   Episode_Reward/test_gait_reward: -0.9553
Metrics/base_velocity/error_vel_xy: 1.2207
Metrics/base_velocity/error_vel_yaw: 1.4725
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 1.13s
                        Total time: 1241.41s
                               ETA: 2023.7s

################################################################################
                     [1m Learning iteration 1141/3000 [0m                     

                       Computation: 81983 steps/s (collection: 1.069s, learning 0.130s)
               Value function loss: 0.7491
                    Surrogate loss: -0.0045
             Mean action noise std: 0.9291
                     Learning rate: 0.0006
                       Mean reward: 106.81
               Mean episode length: 952.88
       Episode_Reward/keep_balance: 0.9581
     Episode_Reward/rew_lin_vel_xy: 5.3680
      Episode_Reward/rew_ang_vel_z: 2.1959
    Episode_Reward/pen_base_height: -0.3278
      Episode_Reward/pen_lin_vel_z: -0.0429
     Episode_Reward/pen_ang_vel_xy: -0.2107
   Episode_Reward/pen_joint_torque: -0.2246
    Episode_Reward/pen_joint_accel: -0.1205
    Episode_Reward/pen_action_rate: -0.1353
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0643
   Episode_Reward/pen_joint_powers: -0.0956
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2925
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0071
Episode_Reward/pen_feet_regulation: -0.4828
   Episode_Reward/foot_landing_vel: -0.1526
   Episode_Reward/test_gait_reward: -0.9422
Metrics/base_velocity/error_vel_xy: 1.2362
Metrics/base_velocity/error_vel_yaw: 1.5162
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 1.20s
                        Total time: 1242.61s
                               ETA: 2022.8s

################################################################################
                     [1m Learning iteration 1142/3000 [0m                     

                       Computation: 90611 steps/s (collection: 0.959s, learning 0.126s)
               Value function loss: 0.6738
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9290
                     Learning rate: 0.0006
                       Mean reward: 115.04
               Mean episode length: 970.14
       Episode_Reward/keep_balance: 0.9669
     Episode_Reward/rew_lin_vel_xy: 5.5718
      Episode_Reward/rew_ang_vel_z: 2.2803
    Episode_Reward/pen_base_height: -0.3032
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1996
   Episode_Reward/pen_joint_torque: -0.2163
    Episode_Reward/pen_joint_accel: -0.1107
    Episode_Reward/pen_action_rate: -0.1296
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2875
Episode_Reward/pen_flat_orientation: -0.1139
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.4266
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.9338
Metrics/base_velocity/error_vel_xy: 1.1689
Metrics/base_velocity/error_vel_yaw: 1.4579
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 1.08s
                        Total time: 1243.70s
                               ETA: 2021.7s

################################################################################
                     [1m Learning iteration 1143/3000 [0m                     

                       Computation: 89611 steps/s (collection: 0.969s, learning 0.128s)
               Value function loss: 0.6735
                    Surrogate loss: -0.0027
             Mean action noise std: 0.9288
                     Learning rate: 0.0009
                       Mean reward: 115.53
               Mean episode length: 981.79
       Episode_Reward/keep_balance: 0.9826
     Episode_Reward/rew_lin_vel_xy: 5.7029
      Episode_Reward/rew_ang_vel_z: 2.3081
    Episode_Reward/pen_base_height: -0.3453
      Episode_Reward/pen_lin_vel_z: -0.0449
     Episode_Reward/pen_ang_vel_xy: -0.2137
   Episode_Reward/pen_joint_torque: -0.2360
    Episode_Reward/pen_joint_accel: -0.1151
    Episode_Reward/pen_action_rate: -0.1358
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0640
   Episode_Reward/pen_joint_powers: -0.0969
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2965
Episode_Reward/pen_flat_orientation: -0.1235
  Episode_Reward/pen_feet_distance: -0.0086
Episode_Reward/pen_feet_regulation: -0.4818
   Episode_Reward/foot_landing_vel: -0.1520
   Episode_Reward/test_gait_reward: -0.9641
Metrics/base_velocity/error_vel_xy: 1.2104
Metrics/base_velocity/error_vel_yaw: 1.4890
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 1.10s
                        Total time: 1244.79s
                               ETA: 2020.6s

################################################################################
                     [1m Learning iteration 1144/3000 [0m                     

                       Computation: 88686 steps/s (collection: 0.978s, learning 0.131s)
               Value function loss: 0.7097
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9295
                     Learning rate: 0.0009
                       Mean reward: 117.48
               Mean episode length: 999.23
       Episode_Reward/keep_balance: 0.9992
     Episode_Reward/rew_lin_vel_xy: 5.7860
      Episode_Reward/rew_ang_vel_z: 2.3803
    Episode_Reward/pen_base_height: -0.3286
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.2082
   Episode_Reward/pen_joint_torque: -0.2455
    Episode_Reward/pen_joint_accel: -0.1197
    Episode_Reward/pen_action_rate: -0.1352
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0648
   Episode_Reward/pen_joint_powers: -0.0991
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2949
Episode_Reward/pen_flat_orientation: -0.1167
  Episode_Reward/pen_feet_distance: -0.0083
Episode_Reward/pen_feet_regulation: -0.4928
   Episode_Reward/foot_landing_vel: -0.1579
   Episode_Reward/test_gait_reward: -0.9751
Metrics/base_velocity/error_vel_xy: 1.2148
Metrics/base_velocity/error_vel_yaw: 1.4648
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 1.11s
                        Total time: 1245.90s
                               ETA: 2019.6s

################################################################################
                     [1m Learning iteration 1145/3000 [0m                     

                       Computation: 86197 steps/s (collection: 1.017s, learning 0.123s)
               Value function loss: 0.6987
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9272
                     Learning rate: 0.0003
                       Mean reward: 115.43
               Mean episode length: 979.42
       Episode_Reward/keep_balance: 0.9676
     Episode_Reward/rew_lin_vel_xy: 5.5907
      Episode_Reward/rew_ang_vel_z: 2.2842
    Episode_Reward/pen_base_height: -0.3219
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.2086
   Episode_Reward/pen_joint_torque: -0.2315
    Episode_Reward/pen_joint_accel: -0.1222
    Episode_Reward/pen_action_rate: -0.1326
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0623
   Episode_Reward/pen_joint_powers: -0.0944
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2883
Episode_Reward/pen_flat_orientation: -0.1166
  Episode_Reward/pen_feet_distance: -0.0091
Episode_Reward/pen_feet_regulation: -0.4715
   Episode_Reward/foot_landing_vel: -0.1544
   Episode_Reward/test_gait_reward: -0.9432
Metrics/base_velocity/error_vel_xy: 1.1772
Metrics/base_velocity/error_vel_yaw: 1.4440
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 1.14s
                        Total time: 1247.04s
                               ETA: 2018.6s

################################################################################
                     [1m Learning iteration 1146/3000 [0m                     

                       Computation: 91186 steps/s (collection: 0.953s, learning 0.125s)
               Value function loss: 0.7288
                    Surrogate loss: -0.0027
             Mean action noise std: 0.9265
                     Learning rate: 0.0004
                       Mean reward: 109.57
               Mean episode length: 943.37
       Episode_Reward/keep_balance: 0.9531
     Episode_Reward/rew_lin_vel_xy: 5.5166
      Episode_Reward/rew_ang_vel_z: 2.2288
    Episode_Reward/pen_base_height: -0.3153
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1969
   Episode_Reward/pen_joint_torque: -0.2289
    Episode_Reward/pen_joint_accel: -0.1258
    Episode_Reward/pen_action_rate: -0.1315
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0624
   Episode_Reward/pen_joint_powers: -0.0944
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2852
Episode_Reward/pen_flat_orientation: -0.1188
  Episode_Reward/pen_feet_distance: -0.0111
Episode_Reward/pen_feet_regulation: -0.4482
   Episode_Reward/foot_landing_vel: -0.1518
   Episode_Reward/test_gait_reward: -0.9268
Metrics/base_velocity/error_vel_xy: 1.1515
Metrics/base_velocity/error_vel_yaw: 1.4592
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 1.08s
                        Total time: 1248.12s
                               ETA: 2017.5s

################################################################################
                     [1m Learning iteration 1147/3000 [0m                     

                       Computation: 87734 steps/s (collection: 0.996s, learning 0.124s)
               Value function loss: 0.6813
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9266
                     Learning rate: 0.0004
                       Mean reward: 114.03
               Mean episode length: 971.79
       Episode_Reward/keep_balance: 0.9727
     Episode_Reward/rew_lin_vel_xy: 5.6924
      Episode_Reward/rew_ang_vel_z: 2.2566
    Episode_Reward/pen_base_height: -0.3118
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.2072
   Episode_Reward/pen_joint_torque: -0.2212
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1339
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0616
   Episode_Reward/pen_joint_powers: -0.0935
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2919
Episode_Reward/pen_flat_orientation: -0.1199
  Episode_Reward/pen_feet_distance: -0.0110
Episode_Reward/pen_feet_regulation: -0.4390
   Episode_Reward/foot_landing_vel: -0.1498
   Episode_Reward/test_gait_reward: -0.9428
Metrics/base_velocity/error_vel_xy: 1.1483
Metrics/base_velocity/error_vel_yaw: 1.5032
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 1.12s
                        Total time: 1249.24s
                               ETA: 2016.4s

################################################################################
                     [1m Learning iteration 1148/3000 [0m                     

                       Computation: 82625 steps/s (collection: 1.058s, learning 0.132s)
               Value function loss: 0.8003
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9270
                     Learning rate: 0.0003
                       Mean reward: 109.98
               Mean episode length: 961.04
       Episode_Reward/keep_balance: 0.9480
     Episode_Reward/rew_lin_vel_xy: 5.4965
      Episode_Reward/rew_ang_vel_z: 2.2183
    Episode_Reward/pen_base_height: -0.3242
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.2037
   Episode_Reward/pen_joint_torque: -0.2234
    Episode_Reward/pen_joint_accel: -0.1155
    Episode_Reward/pen_action_rate: -0.1311
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0621
   Episode_Reward/pen_joint_powers: -0.0937
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2854
Episode_Reward/pen_flat_orientation: -0.1246
  Episode_Reward/pen_feet_distance: -0.0122
Episode_Reward/pen_feet_regulation: -0.4767
   Episode_Reward/foot_landing_vel: -0.1480
   Episode_Reward/test_gait_reward: -0.9382
Metrics/base_velocity/error_vel_xy: 1.1537
Metrics/base_velocity/error_vel_yaw: 1.4416
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 1.19s
                        Total time: 1250.43s
                               ETA: 2015.5s

################################################################################
                     [1m Learning iteration 1149/3000 [0m                     

                       Computation: 90894 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.7076
                    Surrogate loss: -0.0015
             Mean action noise std: 0.9258
                     Learning rate: 0.0002
                       Mean reward: 109.47
               Mean episode length: 959.00
       Episode_Reward/keep_balance: 0.9552
     Episode_Reward/rew_lin_vel_xy: 5.4681
      Episode_Reward/rew_ang_vel_z: 2.2156
    Episode_Reward/pen_base_height: -0.3280
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.2013
   Episode_Reward/pen_joint_torque: -0.2271
    Episode_Reward/pen_joint_accel: -0.1184
    Episode_Reward/pen_action_rate: -0.1320
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0615
   Episode_Reward/pen_joint_powers: -0.0932
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2856
Episode_Reward/pen_flat_orientation: -0.1196
  Episode_Reward/pen_feet_distance: -0.0108
Episode_Reward/pen_feet_regulation: -0.4395
   Episode_Reward/foot_landing_vel: -0.1484
   Episode_Reward/test_gait_reward: -0.9321
Metrics/base_velocity/error_vel_xy: 1.2015
Metrics/base_velocity/error_vel_yaw: 1.4769
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 1.08s
                        Total time: 1251.51s
                               ETA: 2014.4s

################################################################################
                     [1m Learning iteration 1150/3000 [0m                     

                       Computation: 86180 steps/s (collection: 1.017s, learning 0.123s)
               Value function loss: 0.8315
                    Surrogate loss: -0.0044
             Mean action noise std: 0.9261
                     Learning rate: 0.0004
                       Mean reward: 108.56
               Mean episode length: 939.35
       Episode_Reward/keep_balance: 0.9424
     Episode_Reward/rew_lin_vel_xy: 5.4320
      Episode_Reward/rew_ang_vel_z: 2.2210
    Episode_Reward/pen_base_height: -0.3342
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.1997
   Episode_Reward/pen_joint_torque: -0.2304
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1296
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0609
   Episode_Reward/pen_joint_powers: -0.0934
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2810
Episode_Reward/pen_flat_orientation: -0.1277
  Episode_Reward/pen_feet_distance: -0.0123
Episode_Reward/pen_feet_regulation: -0.4469
   Episode_Reward/foot_landing_vel: -0.1483
   Episode_Reward/test_gait_reward: -0.9202
Metrics/base_velocity/error_vel_xy: 1.1400
Metrics/base_velocity/error_vel_yaw: 1.4226
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 1.14s
                        Total time: 1252.65s
                               ETA: 2013.4s

################################################################################
                     [1m Learning iteration 1151/3000 [0m                     

                       Computation: 87080 steps/s (collection: 0.995s, learning 0.134s)
               Value function loss: 0.7416
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9268
                     Learning rate: 0.0009
                       Mean reward: 111.57
               Mean episode length: 939.50
       Episode_Reward/keep_balance: 0.9474
     Episode_Reward/rew_lin_vel_xy: 5.5082
      Episode_Reward/rew_ang_vel_z: 2.2310
    Episode_Reward/pen_base_height: -0.3140
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.2017
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.1241
    Episode_Reward/pen_action_rate: -0.1303
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0617
   Episode_Reward/pen_joint_powers: -0.0932
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2840
Episode_Reward/pen_flat_orientation: -0.1182
  Episode_Reward/pen_feet_distance: -0.0112
Episode_Reward/pen_feet_regulation: -0.4410
   Episode_Reward/foot_landing_vel: -0.1475
   Episode_Reward/test_gait_reward: -0.9313
Metrics/base_velocity/error_vel_xy: 1.1507
Metrics/base_velocity/error_vel_yaw: 1.4347
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 1.13s
                        Total time: 1253.78s
                               ETA: 2012.4s

################################################################################
                     [1m Learning iteration 1152/3000 [0m                     

                       Computation: 85404 steps/s (collection: 1.021s, learning 0.130s)
               Value function loss: 0.7312
                    Surrogate loss: -0.0030
             Mean action noise std: 0.9267
                     Learning rate: 0.0009
                       Mean reward: 115.07
               Mean episode length: 972.77
       Episode_Reward/keep_balance: 0.9766
     Episode_Reward/rew_lin_vel_xy: 5.7972
      Episode_Reward/rew_ang_vel_z: 2.3064
    Episode_Reward/pen_base_height: -0.3120
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.2056
   Episode_Reward/pen_joint_torque: -0.2220
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1320
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0602
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2920
Episode_Reward/pen_flat_orientation: -0.1150
  Episode_Reward/pen_feet_distance: -0.0076
Episode_Reward/pen_feet_regulation: -0.4452
   Episode_Reward/foot_landing_vel: -0.1420
   Episode_Reward/test_gait_reward: -0.9548
Metrics/base_velocity/error_vel_xy: 1.0892
Metrics/base_velocity/error_vel_yaw: 1.4553
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 1.15s
                        Total time: 1254.93s
                               ETA: 2011.4s

################################################################################
                     [1m Learning iteration 1153/3000 [0m                     

                       Computation: 88536 steps/s (collection: 0.986s, learning 0.124s)
               Value function loss: 0.7613
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9256
                     Learning rate: 0.0006
                       Mean reward: 118.88
               Mean episode length: 969.82
       Episode_Reward/keep_balance: 0.9771
     Episode_Reward/rew_lin_vel_xy: 5.7407
      Episode_Reward/rew_ang_vel_z: 2.3505
    Episode_Reward/pen_base_height: -0.3229
      Episode_Reward/pen_lin_vel_z: -0.0420
     Episode_Reward/pen_ang_vel_xy: -0.2018
   Episode_Reward/pen_joint_torque: -0.2315
    Episode_Reward/pen_joint_accel: -0.1154
    Episode_Reward/pen_action_rate: -0.1314
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0593
   Episode_Reward/pen_joint_powers: -0.0927
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2866
Episode_Reward/pen_flat_orientation: -0.1158
  Episode_Reward/pen_feet_distance: -0.0103
Episode_Reward/pen_feet_regulation: -0.4417
   Episode_Reward/foot_landing_vel: -0.1360
   Episode_Reward/test_gait_reward: -0.9575
Metrics/base_velocity/error_vel_xy: 1.1354
Metrics/base_velocity/error_vel_yaw: 1.4246
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 1.11s
                        Total time: 1256.04s
                               ETA: 2010.3s

################################################################################
                     [1m Learning iteration 1154/3000 [0m                     

                       Computation: 85153 steps/s (collection: 1.020s, learning 0.135s)
               Value function loss: 0.7398
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9250
                     Learning rate: 0.0009
                       Mean reward: 110.20
               Mean episode length: 967.73
       Episode_Reward/keep_balance: 0.9756
     Episode_Reward/rew_lin_vel_xy: 5.6113
      Episode_Reward/rew_ang_vel_z: 2.2722
    Episode_Reward/pen_base_height: -0.3307
      Episode_Reward/pen_lin_vel_z: -0.0428
     Episode_Reward/pen_ang_vel_xy: -0.2196
   Episode_Reward/pen_joint_torque: -0.2215
    Episode_Reward/pen_joint_accel: -0.1219
    Episode_Reward/pen_action_rate: -0.1377
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0648
   Episode_Reward/pen_joint_powers: -0.0955
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2991
Episode_Reward/pen_flat_orientation: -0.1232
  Episode_Reward/pen_feet_distance: -0.0116
Episode_Reward/pen_feet_regulation: -0.4792
   Episode_Reward/foot_landing_vel: -0.1544
   Episode_Reward/test_gait_reward: -0.9551
Metrics/base_velocity/error_vel_xy: 1.2021
Metrics/base_velocity/error_vel_yaw: 1.5128
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 1.15s
                        Total time: 1257.20s
                               ETA: 2009.3s

################################################################################
                     [1m Learning iteration 1155/3000 [0m                     

                       Computation: 83181 steps/s (collection: 1.051s, learning 0.130s)
               Value function loss: 0.7530
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9247
                     Learning rate: 0.0006
                       Mean reward: 113.40
               Mean episode length: 969.10
       Episode_Reward/keep_balance: 0.9757
     Episode_Reward/rew_lin_vel_xy: 5.6243
      Episode_Reward/rew_ang_vel_z: 2.3023
    Episode_Reward/pen_base_height: -0.3221
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.2045
   Episode_Reward/pen_joint_torque: -0.2300
    Episode_Reward/pen_joint_accel: -0.1221
    Episode_Reward/pen_action_rate: -0.1327
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0622
   Episode_Reward/pen_joint_powers: -0.0947
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2907
Episode_Reward/pen_flat_orientation: -0.1186
  Episode_Reward/pen_feet_distance: -0.0119
Episode_Reward/pen_feet_regulation: -0.4481
   Episode_Reward/foot_landing_vel: -0.1487
   Episode_Reward/test_gait_reward: -0.9512
Metrics/base_velocity/error_vel_xy: 1.1760
Metrics/base_velocity/error_vel_yaw: 1.4555
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 1.18s
                        Total time: 1258.38s
                               ETA: 2008.4s

################################################################################
                     [1m Learning iteration 1156/3000 [0m                     

                       Computation: 84251 steps/s (collection: 1.044s, learning 0.123s)
               Value function loss: 0.7083
                    Surrogate loss: -0.0032
             Mean action noise std: 0.9254
                     Learning rate: 0.0006
                       Mean reward: 114.53
               Mean episode length: 964.98
       Episode_Reward/keep_balance: 0.9633
     Episode_Reward/rew_lin_vel_xy: 5.6178
      Episode_Reward/rew_ang_vel_z: 2.2727
    Episode_Reward/pen_base_height: -0.3205
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.1959
   Episode_Reward/pen_joint_torque: -0.2260
    Episode_Reward/pen_joint_accel: -0.1172
    Episode_Reward/pen_action_rate: -0.1298
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0931
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2848
Episode_Reward/pen_flat_orientation: -0.1155
  Episode_Reward/pen_feet_distance: -0.0093
Episode_Reward/pen_feet_regulation: -0.4441
   Episode_Reward/foot_landing_vel: -0.1430
   Episode_Reward/test_gait_reward: -0.9392
Metrics/base_velocity/error_vel_xy: 1.1397
Metrics/base_velocity/error_vel_yaw: 1.4497
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 1.17s
                        Total time: 1259.55s
                               ETA: 2007.4s

################################################################################
                     [1m Learning iteration 1157/3000 [0m                     

                       Computation: 88682 steps/s (collection: 0.987s, learning 0.122s)
               Value function loss: 0.6616
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9261
                     Learning rate: 0.0004
                       Mean reward: 111.44
               Mean episode length: 952.22
       Episode_Reward/keep_balance: 0.9472
     Episode_Reward/rew_lin_vel_xy: 5.4489
      Episode_Reward/rew_ang_vel_z: 2.2484
    Episode_Reward/pen_base_height: -0.3411
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.2003
   Episode_Reward/pen_joint_torque: -0.2340
    Episode_Reward/pen_joint_accel: -0.1183
    Episode_Reward/pen_action_rate: -0.1301
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0612
   Episode_Reward/pen_joint_powers: -0.0945
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2801
Episode_Reward/pen_flat_orientation: -0.1266
  Episode_Reward/pen_feet_distance: -0.0120
Episode_Reward/pen_feet_regulation: -0.4454
   Episode_Reward/foot_landing_vel: -0.1464
   Episode_Reward/test_gait_reward: -0.9282
Metrics/base_velocity/error_vel_xy: 1.1541
Metrics/base_velocity/error_vel_yaw: 1.4232
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 1.11s
                        Total time: 1260.66s
                               ETA: 2006.4s

################################################################################
                     [1m Learning iteration 1158/3000 [0m                     

                       Computation: 89307 steps/s (collection: 0.977s, learning 0.124s)
               Value function loss: 0.6889
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9258
                     Learning rate: 0.0006
                       Mean reward: 115.26
               Mean episode length: 998.87
       Episode_Reward/keep_balance: 0.9992
     Episode_Reward/rew_lin_vel_xy: 5.7653
      Episode_Reward/rew_ang_vel_z: 2.3394
    Episode_Reward/pen_base_height: -0.3263
      Episode_Reward/pen_lin_vel_z: -0.0454
     Episode_Reward/pen_ang_vel_xy: -0.2088
   Episode_Reward/pen_joint_torque: -0.2459
    Episode_Reward/pen_joint_accel: -0.1276
    Episode_Reward/pen_action_rate: -0.1381
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0659
   Episode_Reward/pen_joint_powers: -0.0999
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2987
Episode_Reward/pen_flat_orientation: -0.1190
  Episode_Reward/pen_feet_distance: -0.0126
Episode_Reward/pen_feet_regulation: -0.4736
   Episode_Reward/foot_landing_vel: -0.1566
   Episode_Reward/test_gait_reward: -0.9838
Metrics/base_velocity/error_vel_xy: 1.2211
Metrics/base_velocity/error_vel_yaw: 1.5210
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 1.10s
                        Total time: 1261.76s
                               ETA: 2005.3s

################################################################################
                     [1m Learning iteration 1159/3000 [0m                     

                       Computation: 91203 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.7494
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9256
                     Learning rate: 0.0009
                       Mean reward: 116.09
               Mean episode length: 982.95
       Episode_Reward/keep_balance: 0.9793
     Episode_Reward/rew_lin_vel_xy: 5.6217
      Episode_Reward/rew_ang_vel_z: 2.3245
    Episode_Reward/pen_base_height: -0.3235
      Episode_Reward/pen_lin_vel_z: -0.0420
     Episode_Reward/pen_ang_vel_xy: -0.2039
   Episode_Reward/pen_joint_torque: -0.2288
    Episode_Reward/pen_joint_accel: -0.1264
    Episode_Reward/pen_action_rate: -0.1333
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0625
   Episode_Reward/pen_joint_powers: -0.0947
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2872
Episode_Reward/pen_flat_orientation: -0.1211
  Episode_Reward/pen_feet_distance: -0.0095
Episode_Reward/pen_feet_regulation: -0.4607
   Episode_Reward/foot_landing_vel: -0.1458
   Episode_Reward/test_gait_reward: -0.9607
Metrics/base_velocity/error_vel_xy: 1.2245
Metrics/base_velocity/error_vel_yaw: 1.4652
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 1.08s
                        Total time: 1262.83s
                               ETA: 2004.2s

################################################################################
                     [1m Learning iteration 1160/3000 [0m                     

                       Computation: 80797 steps/s (collection: 1.090s, learning 0.126s)
               Value function loss: 0.7270
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9238
                     Learning rate: 0.0006
                       Mean reward: 114.05
               Mean episode length: 965.44
       Episode_Reward/keep_balance: 0.9692
     Episode_Reward/rew_lin_vel_xy: 5.6500
      Episode_Reward/rew_ang_vel_z: 2.3072
    Episode_Reward/pen_base_height: -0.3146
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.1957
   Episode_Reward/pen_joint_torque: -0.2202
    Episode_Reward/pen_joint_accel: -0.1243
    Episode_Reward/pen_action_rate: -0.1296
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0899
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2856
Episode_Reward/pen_flat_orientation: -0.1130
  Episode_Reward/pen_feet_distance: -0.0100
Episode_Reward/pen_feet_regulation: -0.4326
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.9508
Metrics/base_velocity/error_vel_xy: 1.1499
Metrics/base_velocity/error_vel_yaw: 1.4261
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 1.22s
                        Total time: 1264.05s
                               ETA: 2003.3s

################################################################################
                     [1m Learning iteration 1161/3000 [0m                     

                       Computation: 84525 steps/s (collection: 1.041s, learning 0.122s)
               Value function loss: 0.6808
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9219
                     Learning rate: 0.0009
                       Mean reward: 113.06
               Mean episode length: 953.17
       Episode_Reward/keep_balance: 0.9331
     Episode_Reward/rew_lin_vel_xy: 5.4976
      Episode_Reward/rew_ang_vel_z: 2.1899
    Episode_Reward/pen_base_height: -0.3077
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1988
   Episode_Reward/pen_joint_torque: -0.2151
    Episode_Reward/pen_joint_accel: -0.1290
    Episode_Reward/pen_action_rate: -0.1293
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2803
Episode_Reward/pen_flat_orientation: -0.1163
  Episode_Reward/pen_feet_distance: -0.0078
Episode_Reward/pen_feet_regulation: -0.4412
   Episode_Reward/foot_landing_vel: -0.1461
   Episode_Reward/test_gait_reward: -0.9184
Metrics/base_velocity/error_vel_xy: 1.1002
Metrics/base_velocity/error_vel_yaw: 1.4336
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 1.16s
                        Total time: 1265.21s
                               ETA: 2002.3s

################################################################################
                     [1m Learning iteration 1162/3000 [0m                     

                       Computation: 84199 steps/s (collection: 1.037s, learning 0.131s)
               Value function loss: 0.6710
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9224
                     Learning rate: 0.0009
                       Mean reward: 110.87
               Mean episode length: 951.66
       Episode_Reward/keep_balance: 0.9623
     Episode_Reward/rew_lin_vel_xy: 5.6429
      Episode_Reward/rew_ang_vel_z: 2.2492
    Episode_Reward/pen_base_height: -0.3349
      Episode_Reward/pen_lin_vel_z: -0.0414
     Episode_Reward/pen_ang_vel_xy: -0.1934
   Episode_Reward/pen_joint_torque: -0.2354
    Episode_Reward/pen_joint_accel: -0.1141
    Episode_Reward/pen_action_rate: -0.1312
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0948
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2843
Episode_Reward/pen_flat_orientation: -0.1217
  Episode_Reward/pen_feet_distance: -0.0111
Episode_Reward/pen_feet_regulation: -0.4500
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.9458
Metrics/base_velocity/error_vel_xy: 1.1521
Metrics/base_velocity/error_vel_yaw: 1.4754
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 1.17s
                        Total time: 1266.38s
                               ETA: 2001.4s

################################################################################
                     [1m Learning iteration 1163/3000 [0m                     

                       Computation: 85116 steps/s (collection: 1.025s, learning 0.130s)
               Value function loss: 0.7328
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9227
                     Learning rate: 0.0004
                       Mean reward: 117.53
               Mean episode length: 980.20
       Episode_Reward/keep_balance: 0.9825
     Episode_Reward/rew_lin_vel_xy: 5.6090
      Episode_Reward/rew_ang_vel_z: 2.3275
    Episode_Reward/pen_base_height: -0.3279
      Episode_Reward/pen_lin_vel_z: -0.0428
     Episode_Reward/pen_ang_vel_xy: -0.2038
   Episode_Reward/pen_joint_torque: -0.2324
    Episode_Reward/pen_joint_accel: -0.1208
    Episode_Reward/pen_action_rate: -0.1338
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0629
   Episode_Reward/pen_joint_powers: -0.0953
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2899
Episode_Reward/pen_flat_orientation: -0.1225
  Episode_Reward/pen_feet_distance: -0.0121
Episode_Reward/pen_feet_regulation: -0.4679
   Episode_Reward/foot_landing_vel: -0.1592
   Episode_Reward/test_gait_reward: -0.9622
Metrics/base_velocity/error_vel_xy: 1.2352
Metrics/base_velocity/error_vel_yaw: 1.4644
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 1.15s
                        Total time: 1267.54s
                               ETA: 2000.4s

################################################################################
                     [1m Learning iteration 1164/3000 [0m                     

                       Computation: 85006 steps/s (collection: 1.034s, learning 0.122s)
               Value function loss: 0.6512
                    Surrogate loss: -0.0019
             Mean action noise std: 0.9222
                     Learning rate: 0.0003
                       Mean reward: 110.11
               Mean episode length: 952.76
       Episode_Reward/keep_balance: 0.9367
     Episode_Reward/rew_lin_vel_xy: 5.3266
      Episode_Reward/rew_ang_vel_z: 2.1486
    Episode_Reward/pen_base_height: -0.3240
      Episode_Reward/pen_lin_vel_z: -0.0433
     Episode_Reward/pen_ang_vel_xy: -0.2018
   Episode_Reward/pen_joint_torque: -0.2207
    Episode_Reward/pen_joint_accel: -0.1239
    Episode_Reward/pen_action_rate: -0.1304
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0621
   Episode_Reward/pen_joint_powers: -0.0933
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2815
Episode_Reward/pen_flat_orientation: -0.1306
  Episode_Reward/pen_feet_distance: -0.0124
Episode_Reward/pen_feet_regulation: -0.4722
   Episode_Reward/foot_landing_vel: -0.1478
   Episode_Reward/test_gait_reward: -0.9230
Metrics/base_velocity/error_vel_xy: 1.1923
Metrics/base_velocity/error_vel_yaw: 1.4802
      Episode_Termination/time_out: 3.0000
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 1.16s
                        Total time: 1268.69s
                               ETA: 1999.4s

################################################################################
                     [1m Learning iteration 1165/3000 [0m                     

                       Computation: 90423 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.7881
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9244
                     Learning rate: 0.0006
                       Mean reward: 114.26
               Mean episode length: 964.53
       Episode_Reward/keep_balance: 0.9710
     Episode_Reward/rew_lin_vel_xy: 5.6910
      Episode_Reward/rew_ang_vel_z: 2.2886
    Episode_Reward/pen_base_height: -0.3089
      Episode_Reward/pen_lin_vel_z: -0.0427
     Episode_Reward/pen_ang_vel_xy: -0.2030
   Episode_Reward/pen_joint_torque: -0.2262
    Episode_Reward/pen_joint_accel: -0.1234
    Episode_Reward/pen_action_rate: -0.1322
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0622
   Episode_Reward/pen_joint_powers: -0.0941
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2898
Episode_Reward/pen_flat_orientation: -0.1147
  Episode_Reward/pen_feet_distance: -0.0133
Episode_Reward/pen_feet_regulation: -0.4487
   Episode_Reward/foot_landing_vel: -0.1557
   Episode_Reward/test_gait_reward: -0.9549
Metrics/base_velocity/error_vel_xy: 1.1479
Metrics/base_velocity/error_vel_yaw: 1.4553
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 1.09s
                        Total time: 1269.78s
                               ETA: 1998.3s

################################################################################
                     [1m Learning iteration 1166/3000 [0m                     

                       Computation: 90597 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.7658
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9254
                     Learning rate: 0.0004
                       Mean reward: 111.06
               Mean episode length: 968.03
       Episode_Reward/keep_balance: 0.9493
     Episode_Reward/rew_lin_vel_xy: 5.4857
      Episode_Reward/rew_ang_vel_z: 2.2555
    Episode_Reward/pen_base_height: -0.3352
      Episode_Reward/pen_lin_vel_z: -0.0447
     Episode_Reward/pen_ang_vel_xy: -0.1893
   Episode_Reward/pen_joint_torque: -0.2311
    Episode_Reward/pen_joint_accel: -0.1118
    Episode_Reward/pen_action_rate: -0.1290
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0938
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2773
Episode_Reward/pen_flat_orientation: -0.1215
  Episode_Reward/pen_feet_distance: -0.0138
Episode_Reward/pen_feet_regulation: -0.4639
   Episode_Reward/foot_landing_vel: -0.1442
   Episode_Reward/test_gait_reward: -0.9376
Metrics/base_velocity/error_vel_xy: 1.1729
Metrics/base_velocity/error_vel_yaw: 1.4164
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 1.09s
                        Total time: 1270.87s
                               ETA: 1997.2s

################################################################################
                     [1m Learning iteration 1167/3000 [0m                     

                       Computation: 90106 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.7592
                    Surrogate loss: -0.0024
             Mean action noise std: 0.9248
                     Learning rate: 0.0004
                       Mean reward: 114.38
               Mean episode length: 965.21
       Episode_Reward/keep_balance: 0.9644
     Episode_Reward/rew_lin_vel_xy: 5.6229
      Episode_Reward/rew_ang_vel_z: 2.3038
    Episode_Reward/pen_base_height: -0.3360
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.1943
   Episode_Reward/pen_joint_torque: -0.2260
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1307
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0618
   Episode_Reward/pen_joint_powers: -0.0940
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2813
Episode_Reward/pen_flat_orientation: -0.1248
  Episode_Reward/pen_feet_distance: -0.0153
Episode_Reward/pen_feet_regulation: -0.4673
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.9479
Metrics/base_velocity/error_vel_xy: 1.1677
Metrics/base_velocity/error_vel_yaw: 1.4259
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 1.09s
                        Total time: 1271.96s
                               ETA: 1996.1s

################################################################################
                     [1m Learning iteration 1168/3000 [0m                     

                       Computation: 91445 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.6608
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9249
                     Learning rate: 0.0006
                       Mean reward: 113.48
               Mean episode length: 979.05
       Episode_Reward/keep_balance: 0.9824
     Episode_Reward/rew_lin_vel_xy: 5.7606
      Episode_Reward/rew_ang_vel_z: 2.3191
    Episode_Reward/pen_base_height: -0.3132
      Episode_Reward/pen_lin_vel_z: -0.0434
     Episode_Reward/pen_ang_vel_xy: -0.2155
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1356
    Episode_Reward/pen_action_rate: -0.1343
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0640
   Episode_Reward/pen_joint_powers: -0.0957
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2946
Episode_Reward/pen_flat_orientation: -0.1210
  Episode_Reward/pen_feet_distance: -0.0125
Episode_Reward/pen_feet_regulation: -0.4624
   Episode_Reward/foot_landing_vel: -0.1548
   Episode_Reward/test_gait_reward: -0.9646
Metrics/base_velocity/error_vel_xy: 1.1446
Metrics/base_velocity/error_vel_yaw: 1.4816
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 1.08s
                        Total time: 1273.03s
                               ETA: 1995.0s

################################################################################
                     [1m Learning iteration 1169/3000 [0m                     

                       Computation: 90128 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.6547
                    Surrogate loss: -0.0015
             Mean action noise std: 0.9258
                     Learning rate: 0.0003
                       Mean reward: 116.87
               Mean episode length: 981.51
       Episode_Reward/keep_balance: 0.9691
     Episode_Reward/rew_lin_vel_xy: 5.6641
      Episode_Reward/rew_ang_vel_z: 2.2769
    Episode_Reward/pen_base_height: -0.3252
      Episode_Reward/pen_lin_vel_z: -0.0440
     Episode_Reward/pen_ang_vel_xy: -0.2030
   Episode_Reward/pen_joint_torque: -0.2329
    Episode_Reward/pen_joint_accel: -0.1317
    Episode_Reward/pen_action_rate: -0.1319
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0636
   Episode_Reward/pen_joint_powers: -0.0964
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2870
Episode_Reward/pen_flat_orientation: -0.1250
  Episode_Reward/pen_feet_distance: -0.0149
Episode_Reward/pen_feet_regulation: -0.4790
   Episode_Reward/foot_landing_vel: -0.1510
   Episode_Reward/test_gait_reward: -0.9557
Metrics/base_velocity/error_vel_xy: 1.1331
Metrics/base_velocity/error_vel_yaw: 1.4677
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 1.09s
                        Total time: 1274.12s
                               ETA: 1993.9s

################################################################################
                     [1m Learning iteration 1170/3000 [0m                     

                       Computation: 90488 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.6387
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9245
                     Learning rate: 0.0006
                       Mean reward: 117.66
               Mean episode length: 970.26
       Episode_Reward/keep_balance: 0.9759
     Episode_Reward/rew_lin_vel_xy: 5.7094
      Episode_Reward/rew_ang_vel_z: 2.3362
    Episode_Reward/pen_base_height: -0.3205
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.2013
   Episode_Reward/pen_joint_torque: -0.2330
    Episode_Reward/pen_joint_accel: -0.1129
    Episode_Reward/pen_action_rate: -0.1307
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2853
Episode_Reward/pen_flat_orientation: -0.1109
  Episode_Reward/pen_feet_distance: -0.0097
Episode_Reward/pen_feet_regulation: -0.4275
   Episode_Reward/foot_landing_vel: -0.1394
   Episode_Reward/test_gait_reward: -0.9589
Metrics/base_velocity/error_vel_xy: 1.1412
Metrics/base_velocity/error_vel_yaw: 1.4253
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 1.09s
                        Total time: 1275.21s
                               ETA: 1992.9s

################################################################################
                     [1m Learning iteration 1171/3000 [0m                     

                       Computation: 91504 steps/s (collection: 0.953s, learning 0.121s)
               Value function loss: 0.7224
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9243
                     Learning rate: 0.0003
                       Mean reward: 116.87
               Mean episode length: 992.11
       Episode_Reward/keep_balance: 0.9944
     Episode_Reward/rew_lin_vel_xy: 5.8076
      Episode_Reward/rew_ang_vel_z: 2.3442
    Episode_Reward/pen_base_height: -0.3265
      Episode_Reward/pen_lin_vel_z: -0.0443
     Episode_Reward/pen_ang_vel_xy: -0.2046
   Episode_Reward/pen_joint_torque: -0.2364
    Episode_Reward/pen_joint_accel: -0.1307
    Episode_Reward/pen_action_rate: -0.1356
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0643
   Episode_Reward/pen_joint_powers: -0.0974
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2948
Episode_Reward/pen_flat_orientation: -0.1178
  Episode_Reward/pen_feet_distance: -0.0120
Episode_Reward/pen_feet_regulation: -0.4796
   Episode_Reward/foot_landing_vel: -0.1552
   Episode_Reward/test_gait_reward: -0.9793
Metrics/base_velocity/error_vel_xy: 1.1638
Metrics/base_velocity/error_vel_yaw: 1.4907
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 1.07s
                        Total time: 1276.28s
                               ETA: 1991.7s

################################################################################
                     [1m Learning iteration 1172/3000 [0m                     

                       Computation: 91313 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.6957
                    Surrogate loss: -0.0012
             Mean action noise std: 0.9250
                     Learning rate: 0.0002
                       Mean reward: 114.46
               Mean episode length: 953.46
       Episode_Reward/keep_balance: 0.9488
     Episode_Reward/rew_lin_vel_xy: 5.5357
      Episode_Reward/rew_ang_vel_z: 2.2688
    Episode_Reward/pen_base_height: -0.3281
      Episode_Reward/pen_lin_vel_z: -0.0429
     Episode_Reward/pen_ang_vel_xy: -0.1948
   Episode_Reward/pen_joint_torque: -0.2279
    Episode_Reward/pen_joint_accel: -0.1207
    Episode_Reward/pen_action_rate: -0.1272
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0920
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2736
Episode_Reward/pen_flat_orientation: -0.1228
  Episode_Reward/pen_feet_distance: -0.0122
Episode_Reward/pen_feet_regulation: -0.4496
   Episode_Reward/foot_landing_vel: -0.1405
   Episode_Reward/test_gait_reward: -0.9346
Metrics/base_velocity/error_vel_xy: 1.1506
Metrics/base_velocity/error_vel_yaw: 1.3831
      Episode_Termination/time_out: 5.1250
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 1.08s
                        Total time: 1277.36s
                               ETA: 1990.6s

################################################################################
                     [1m Learning iteration 1173/3000 [0m                     

                       Computation: 90742 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.6714
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9245
                     Learning rate: 0.0003
                       Mean reward: 118.96
               Mean episode length: 981.94
       Episode_Reward/keep_balance: 0.9820
     Episode_Reward/rew_lin_vel_xy: 5.7712
      Episode_Reward/rew_ang_vel_z: 2.3846
    Episode_Reward/pen_base_height: -0.3297
      Episode_Reward/pen_lin_vel_z: -0.0425
     Episode_Reward/pen_ang_vel_xy: -0.2049
   Episode_Reward/pen_joint_torque: -0.2333
    Episode_Reward/pen_joint_accel: -0.1194
    Episode_Reward/pen_action_rate: -0.1318
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0937
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2844
Episode_Reward/pen_flat_orientation: -0.1169
  Episode_Reward/pen_feet_distance: -0.0153
Episode_Reward/pen_feet_regulation: -0.4518
   Episode_Reward/foot_landing_vel: -0.1493
   Episode_Reward/test_gait_reward: -0.9599
Metrics/base_velocity/error_vel_xy: 1.1489
Metrics/base_velocity/error_vel_yaw: 1.4054
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 1.08s
                        Total time: 1278.44s
                               ETA: 1989.5s

################################################################################
                     [1m Learning iteration 1174/3000 [0m                     

                       Computation: 91443 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.6567
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9240
                     Learning rate: 0.0006
                       Mean reward: 112.73
               Mean episode length: 959.53
       Episode_Reward/keep_balance: 0.9593
     Episode_Reward/rew_lin_vel_xy: 5.6159
      Episode_Reward/rew_ang_vel_z: 2.2983
    Episode_Reward/pen_base_height: -0.3207
      Episode_Reward/pen_lin_vel_z: -0.0437
     Episode_Reward/pen_ang_vel_xy: -0.1987
   Episode_Reward/pen_joint_torque: -0.2316
    Episode_Reward/pen_joint_accel: -0.1165
    Episode_Reward/pen_action_rate: -0.1292
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0936
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2788
Episode_Reward/pen_flat_orientation: -0.1148
  Episode_Reward/pen_feet_distance: -0.0150
Episode_Reward/pen_feet_regulation: -0.4472
   Episode_Reward/foot_landing_vel: -0.1583
   Episode_Reward/test_gait_reward: -0.9426
Metrics/base_velocity/error_vel_xy: 1.1391
Metrics/base_velocity/error_vel_yaw: 1.4076
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 1.08s
                        Total time: 1279.52s
                               ETA: 1988.4s

################################################################################
                     [1m Learning iteration 1175/3000 [0m                     

                       Computation: 90484 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.7623
                    Surrogate loss: -0.0007
             Mean action noise std: 0.9245
                     Learning rate: 0.0002
                       Mean reward: 113.85
               Mean episode length: 967.40
       Episode_Reward/keep_balance: 0.9760
     Episode_Reward/rew_lin_vel_xy: 5.7831
      Episode_Reward/rew_ang_vel_z: 2.2859
    Episode_Reward/pen_base_height: -0.3234
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.2013
   Episode_Reward/pen_joint_torque: -0.2299
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1325
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0610
   Episode_Reward/pen_joint_powers: -0.0941
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2854
Episode_Reward/pen_flat_orientation: -0.1177
  Episode_Reward/pen_feet_distance: -0.0172
Episode_Reward/pen_feet_regulation: -0.4564
   Episode_Reward/foot_landing_vel: -0.1502
   Episode_Reward/test_gait_reward: -0.9522
Metrics/base_velocity/error_vel_xy: 1.1223
Metrics/base_velocity/error_vel_yaw: 1.4758
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 1.09s
                        Total time: 1280.60s
                               ETA: 1987.3s

################################################################################
                     [1m Learning iteration 1176/3000 [0m                     

                       Computation: 91936 steps/s (collection: 0.948s, learning 0.121s)
               Value function loss: 0.7103
                    Surrogate loss: -0.0046
             Mean action noise std: 0.9232
                     Learning rate: 0.0004
                       Mean reward: 115.31
               Mean episode length: 961.06
       Episode_Reward/keep_balance: 0.9489
     Episode_Reward/rew_lin_vel_xy: 5.5281
      Episode_Reward/rew_ang_vel_z: 2.2711
    Episode_Reward/pen_base_height: -0.3117
      Episode_Reward/pen_lin_vel_z: -0.0415
     Episode_Reward/pen_ang_vel_xy: -0.1976
   Episode_Reward/pen_joint_torque: -0.2246
    Episode_Reward/pen_joint_accel: -0.1172
    Episode_Reward/pen_action_rate: -0.1272
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0602
   Episode_Reward/pen_joint_powers: -0.0915
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2777
Episode_Reward/pen_flat_orientation: -0.1131
  Episode_Reward/pen_feet_distance: -0.0143
Episode_Reward/pen_feet_regulation: -0.4363
   Episode_Reward/foot_landing_vel: -0.1552
   Episode_Reward/test_gait_reward: -0.9312
Metrics/base_velocity/error_vel_xy: 1.1272
Metrics/base_velocity/error_vel_yaw: 1.3926
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 1.07s
                        Total time: 1281.67s
                               ETA: 1986.2s

################################################################################
                     [1m Learning iteration 1177/3000 [0m                     

                       Computation: 90447 steps/s (collection: 0.966s, learning 0.121s)
               Value function loss: 0.7049
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9221
                     Learning rate: 0.0009
                       Mean reward: 114.70
               Mean episode length: 967.25
       Episode_Reward/keep_balance: 0.9747
     Episode_Reward/rew_lin_vel_xy: 5.6714
      Episode_Reward/rew_ang_vel_z: 2.3382
    Episode_Reward/pen_base_height: -0.3246
      Episode_Reward/pen_lin_vel_z: -0.0442
     Episode_Reward/pen_ang_vel_xy: -0.1966
   Episode_Reward/pen_joint_torque: -0.2321
    Episode_Reward/pen_joint_accel: -0.1190
    Episode_Reward/pen_action_rate: -0.1305
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0628
   Episode_Reward/pen_joint_powers: -0.0951
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2816
Episode_Reward/pen_flat_orientation: -0.1204
  Episode_Reward/pen_feet_distance: -0.0138
Episode_Reward/pen_feet_regulation: -0.4597
   Episode_Reward/foot_landing_vel: -0.1542
   Episode_Reward/test_gait_reward: -0.9587
Metrics/base_velocity/error_vel_xy: 1.1613
Metrics/base_velocity/error_vel_yaw: 1.4165
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 1.09s
                        Total time: 1282.76s
                               ETA: 1985.1s

################################################################################
                     [1m Learning iteration 1178/3000 [0m                     

                       Computation: 90716 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.6431
                    Surrogate loss: 0.0004
             Mean action noise std: 0.9213
                     Learning rate: 0.0002
                       Mean reward: 116.87
               Mean episode length: 961.61
       Episode_Reward/keep_balance: 0.9645
     Episode_Reward/rew_lin_vel_xy: 5.7156
      Episode_Reward/rew_ang_vel_z: 2.3325
    Episode_Reward/pen_base_height: -0.3076
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.1894
   Episode_Reward/pen_joint_torque: -0.2194
    Episode_Reward/pen_joint_accel: -0.1128
    Episode_Reward/pen_action_rate: -0.1278
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2751
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0151
Episode_Reward/pen_feet_regulation: -0.4463
   Episode_Reward/foot_landing_vel: -0.1396
   Episode_Reward/test_gait_reward: -0.9445
Metrics/base_velocity/error_vel_xy: 1.1176
Metrics/base_velocity/error_vel_yaw: 1.3785
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 1.08s
                        Total time: 1283.84s
                               ETA: 1984.0s

################################################################################
                     [1m Learning iteration 1179/3000 [0m                     

                       Computation: 91286 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.6847
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9203
                     Learning rate: 0.0004
                       Mean reward: 116.80
               Mean episode length: 977.91
       Episode_Reward/keep_balance: 0.9816
     Episode_Reward/rew_lin_vel_xy: 5.6826
      Episode_Reward/rew_ang_vel_z: 2.3212
    Episode_Reward/pen_base_height: -0.3183
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.2017
   Episode_Reward/pen_joint_torque: -0.2334
    Episode_Reward/pen_joint_accel: -0.1265
    Episode_Reward/pen_action_rate: -0.1331
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0633
   Episode_Reward/pen_joint_powers: -0.0962
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2881
Episode_Reward/pen_flat_orientation: -0.1216
  Episode_Reward/pen_feet_distance: -0.0133
Episode_Reward/pen_feet_regulation: -0.4764
   Episode_Reward/foot_landing_vel: -0.1483
   Episode_Reward/test_gait_reward: -0.9711
Metrics/base_velocity/error_vel_xy: 1.1835
Metrics/base_velocity/error_vel_yaw: 1.4488
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 1.08s
                        Total time: 1284.92s
                               ETA: 1982.9s

################################################################################
                     [1m Learning iteration 1180/3000 [0m                     

                       Computation: 89408 steps/s (collection: 0.975s, learning 0.125s)
               Value function loss: 0.7027
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9194
                     Learning rate: 0.0009
                       Mean reward: 115.79
               Mean episode length: 944.14
       Episode_Reward/keep_balance: 0.9263
     Episode_Reward/rew_lin_vel_xy: 5.4754
      Episode_Reward/rew_ang_vel_z: 2.2511
    Episode_Reward/pen_base_height: -0.3014
      Episode_Reward/pen_lin_vel_z: -0.0402
     Episode_Reward/pen_ang_vel_xy: -0.1888
   Episode_Reward/pen_joint_torque: -0.2154
    Episode_Reward/pen_joint_accel: -0.1119
    Episode_Reward/pen_action_rate: -0.1224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2654
Episode_Reward/pen_flat_orientation: -0.1134
  Episode_Reward/pen_feet_distance: -0.0140
Episode_Reward/pen_feet_regulation: -0.4143
   Episode_Reward/foot_landing_vel: -0.1324
   Episode_Reward/test_gait_reward: -0.9138
Metrics/base_velocity/error_vel_xy: 1.0629
Metrics/base_velocity/error_vel_yaw: 1.3155
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 1.10s
                        Total time: 1286.02s
                               ETA: 1981.8s

################################################################################
                     [1m Learning iteration 1181/3000 [0m                     

                       Computation: 87790 steps/s (collection: 0.998s, learning 0.122s)
               Value function loss: 0.8019
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9195
                     Learning rate: 0.0013
                       Mean reward: 110.52
               Mean episode length: 932.45
       Episode_Reward/keep_balance: 0.9390
     Episode_Reward/rew_lin_vel_xy: 5.4380
      Episode_Reward/rew_ang_vel_z: 2.2234
    Episode_Reward/pen_base_height: -0.2996
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1939
   Episode_Reward/pen_joint_torque: -0.2138
    Episode_Reward/pen_joint_accel: -0.1122
    Episode_Reward/pen_action_rate: -0.1265
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0602
   Episode_Reward/pen_joint_powers: -0.0900
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2738
Episode_Reward/pen_flat_orientation: -0.1178
  Episode_Reward/pen_feet_distance: -0.0149
Episode_Reward/pen_feet_regulation: -0.4526
   Episode_Reward/foot_landing_vel: -0.1456
   Episode_Reward/test_gait_reward: -0.9227
Metrics/base_velocity/error_vel_xy: 1.1336
Metrics/base_velocity/error_vel_yaw: 1.3919
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 1.12s
                        Total time: 1287.14s
                               ETA: 1980.8s

################################################################################
                     [1m Learning iteration 1182/3000 [0m                     

                       Computation: 91339 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.7720
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9194
                     Learning rate: 0.0013
                       Mean reward: 110.64
               Mean episode length: 955.29
       Episode_Reward/keep_balance: 0.9692
     Episode_Reward/rew_lin_vel_xy: 5.6410
      Episode_Reward/rew_ang_vel_z: 2.2868
    Episode_Reward/pen_base_height: -0.3134
      Episode_Reward/pen_lin_vel_z: -0.0451
     Episode_Reward/pen_ang_vel_xy: -0.1997
   Episode_Reward/pen_joint_torque: -0.2280
    Episode_Reward/pen_joint_accel: -0.1352
    Episode_Reward/pen_action_rate: -0.1310
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0635
   Episode_Reward/pen_joint_powers: -0.0950
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2828
Episode_Reward/pen_flat_orientation: -0.1182
  Episode_Reward/pen_feet_distance: -0.0143
Episode_Reward/pen_feet_regulation: -0.4772
   Episode_Reward/foot_landing_vel: -0.1614
   Episode_Reward/test_gait_reward: -0.9512
Metrics/base_velocity/error_vel_xy: 1.1717
Metrics/base_velocity/error_vel_yaw: 1.4395
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 1.08s
                        Total time: 1288.22s
                               ETA: 1979.7s

################################################################################
                     [1m Learning iteration 1183/3000 [0m                     

                       Computation: 92049 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.7549
                    Surrogate loss: 0.0018
             Mean action noise std: 0.9190
                     Learning rate: 0.0003
                       Mean reward: 122.11
               Mean episode length: 999.51
       Episode_Reward/keep_balance: 0.9993
     Episode_Reward/rew_lin_vel_xy: 5.8252
      Episode_Reward/rew_ang_vel_z: 2.3694
    Episode_Reward/pen_base_height: -0.3053
      Episode_Reward/pen_lin_vel_z: -0.0427
     Episode_Reward/pen_ang_vel_xy: -0.2039
   Episode_Reward/pen_joint_torque: -0.2204
    Episode_Reward/pen_joint_accel: -0.1213
    Episode_Reward/pen_action_rate: -0.1335
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0615
   Episode_Reward/pen_joint_powers: -0.0921
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2918
Episode_Reward/pen_flat_orientation: -0.1177
  Episode_Reward/pen_feet_distance: -0.0117
Episode_Reward/pen_feet_regulation: -0.4582
   Episode_Reward/foot_landing_vel: -0.1430
   Episode_Reward/test_gait_reward: -0.9768
Metrics/base_velocity/error_vel_xy: 1.1882
Metrics/base_velocity/error_vel_yaw: 1.4839
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 1.07s
                        Total time: 1289.28s
                               ETA: 1978.6s

################################################################################
                     [1m Learning iteration 1184/3000 [0m                     

                       Computation: 90986 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.6634
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9179
                     Learning rate: 0.0004
                       Mean reward: 112.74
               Mean episode length: 959.75
       Episode_Reward/keep_balance: 0.9418
     Episode_Reward/rew_lin_vel_xy: 5.4887
      Episode_Reward/rew_ang_vel_z: 2.2149
    Episode_Reward/pen_base_height: -0.3132
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.1994
   Episode_Reward/pen_joint_torque: -0.2239
    Episode_Reward/pen_joint_accel: -0.1151
    Episode_Reward/pen_action_rate: -0.1301
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0635
   Episode_Reward/pen_joint_powers: -0.0944
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2789
Episode_Reward/pen_flat_orientation: -0.1301
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.4893
   Episode_Reward/foot_landing_vel: -0.1458
   Episode_Reward/test_gait_reward: -0.9318
Metrics/base_velocity/error_vel_xy: 1.1424
Metrics/base_velocity/error_vel_yaw: 1.4235
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 1.08s
                        Total time: 1290.36s
                               ETA: 1977.5s

################################################################################
                     [1m Learning iteration 1185/3000 [0m                     

                       Computation: 90891 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.6830
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9164
                     Learning rate: 0.0004
                       Mean reward: 117.62
               Mean episode length: 973.97
       Episode_Reward/keep_balance: 0.9771
     Episode_Reward/rew_lin_vel_xy: 5.8062
      Episode_Reward/rew_ang_vel_z: 2.3518
    Episode_Reward/pen_base_height: -0.3167
      Episode_Reward/pen_lin_vel_z: -0.0437
     Episode_Reward/pen_ang_vel_xy: -0.2017
   Episode_Reward/pen_joint_torque: -0.2278
    Episode_Reward/pen_joint_accel: -0.1242
    Episode_Reward/pen_action_rate: -0.1302
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0626
   Episode_Reward/pen_joint_powers: -0.0938
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2818
Episode_Reward/pen_flat_orientation: -0.1162
  Episode_Reward/pen_feet_distance: -0.0161
Episode_Reward/pen_feet_regulation: -0.4738
   Episode_Reward/foot_landing_vel: -0.1606
   Episode_Reward/test_gait_reward: -0.9618
Metrics/base_velocity/error_vel_xy: 1.1084
Metrics/base_velocity/error_vel_yaw: 1.4096
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 1.08s
                        Total time: 1291.45s
                               ETA: 1976.4s

################################################################################
                     [1m Learning iteration 1186/3000 [0m                     

                       Computation: 90432 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.6971
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9159
                     Learning rate: 0.0003
                       Mean reward: 115.73
               Mean episode length: 967.70
       Episode_Reward/keep_balance: 0.9631
     Episode_Reward/rew_lin_vel_xy: 5.6350
      Episode_Reward/rew_ang_vel_z: 2.3103
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.2036
   Episode_Reward/pen_joint_torque: -0.2243
    Episode_Reward/pen_joint_accel: -0.1205
    Episode_Reward/pen_action_rate: -0.1288
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0621
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2788
Episode_Reward/pen_flat_orientation: -0.1226
  Episode_Reward/pen_feet_distance: -0.0154
Episode_Reward/pen_feet_regulation: -0.4744
   Episode_Reward/foot_landing_vel: -0.1534
   Episode_Reward/test_gait_reward: -0.9441
Metrics/base_velocity/error_vel_xy: 1.1454
Metrics/base_velocity/error_vel_yaw: 1.4010
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 1.09s
                        Total time: 1292.53s
                               ETA: 1975.3s

################################################################################
                     [1m Learning iteration 1187/3000 [0m                     

                       Computation: 88130 steps/s (collection: 0.994s, learning 0.122s)
               Value function loss: 0.6144
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9145
                     Learning rate: 0.0006
                       Mean reward: 116.07
               Mean episode length: 976.86
       Episode_Reward/keep_balance: 0.9699
     Episode_Reward/rew_lin_vel_xy: 5.6012
      Episode_Reward/rew_ang_vel_z: 2.3159
    Episode_Reward/pen_base_height: -0.3161
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.1988
   Episode_Reward/pen_joint_torque: -0.2336
    Episode_Reward/pen_joint_accel: -0.1293
    Episode_Reward/pen_action_rate: -0.1298
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0619
   Episode_Reward/pen_joint_powers: -0.0950
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2785
Episode_Reward/pen_flat_orientation: -0.1197
  Episode_Reward/pen_feet_distance: -0.0178
Episode_Reward/pen_feet_regulation: -0.4750
   Episode_Reward/foot_landing_vel: -0.1578
   Episode_Reward/test_gait_reward: -0.9533
Metrics/base_velocity/error_vel_xy: 1.1790
Metrics/base_velocity/error_vel_yaw: 1.4137
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 1.12s
                        Total time: 1293.65s
                               ETA: 1974.2s

################################################################################
                     [1m Learning iteration 1188/3000 [0m                     

                       Computation: 91177 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.6445
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9149
                     Learning rate: 0.0009
                       Mean reward: 114.55
               Mean episode length: 959.32
       Episode_Reward/keep_balance: 0.9614
     Episode_Reward/rew_lin_vel_xy: 5.6368
      Episode_Reward/rew_ang_vel_z: 2.3185
    Episode_Reward/pen_base_height: -0.3070
      Episode_Reward/pen_lin_vel_z: -0.0433
     Episode_Reward/pen_ang_vel_xy: -0.1906
   Episode_Reward/pen_joint_torque: -0.2298
    Episode_Reward/pen_joint_accel: -0.1182
    Episode_Reward/pen_action_rate: -0.1284
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0935
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2750
Episode_Reward/pen_flat_orientation: -0.1271
  Episode_Reward/pen_feet_distance: -0.0216
Episode_Reward/pen_feet_regulation: -0.4601
   Episode_Reward/foot_landing_vel: -0.1509
   Episode_Reward/test_gait_reward: -0.9459
Metrics/base_velocity/error_vel_xy: 1.1270
Metrics/base_velocity/error_vel_yaw: 1.3875
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 1.08s
                        Total time: 1294.73s
                               ETA: 1973.1s

################################################################################
                     [1m Learning iteration 1189/3000 [0m                     

                       Computation: 90855 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.7406
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9160
                     Learning rate: 0.0004
                       Mean reward: 119.07
               Mean episode length: 976.00
       Episode_Reward/keep_balance: 0.9884
     Episode_Reward/rew_lin_vel_xy: 5.8714
      Episode_Reward/rew_ang_vel_z: 2.3648
    Episode_Reward/pen_base_height: -0.3079
      Episode_Reward/pen_lin_vel_z: -0.0422
     Episode_Reward/pen_ang_vel_xy: -0.1993
   Episode_Reward/pen_joint_torque: -0.2274
    Episode_Reward/pen_joint_accel: -0.1105
    Episode_Reward/pen_action_rate: -0.1314
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0620
   Episode_Reward/pen_joint_powers: -0.0948
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2842
Episode_Reward/pen_flat_orientation: -0.1111
  Episode_Reward/pen_feet_distance: -0.0194
Episode_Reward/pen_feet_regulation: -0.4722
   Episode_Reward/foot_landing_vel: -0.1491
   Episode_Reward/test_gait_reward: -0.9663
Metrics/base_velocity/error_vel_xy: 1.1229
Metrics/base_velocity/error_vel_yaw: 1.4330
      Episode_Termination/time_out: 2.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 1.08s
                        Total time: 1295.81s
                               ETA: 1972.0s

################################################################################
                     [1m Learning iteration 1190/3000 [0m                     

                       Computation: 89989 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.7146
                    Surrogate loss: -0.0050
             Mean action noise std: 0.9151
                     Learning rate: 0.0006
                       Mean reward: 112.25
               Mean episode length: 959.11
       Episode_Reward/keep_balance: 0.9631
     Episode_Reward/rew_lin_vel_xy: 5.6356
      Episode_Reward/rew_ang_vel_z: 2.2832
    Episode_Reward/pen_base_height: -0.3093
      Episode_Reward/pen_lin_vel_z: -0.0415
     Episode_Reward/pen_ang_vel_xy: -0.1959
   Episode_Reward/pen_joint_torque: -0.2291
    Episode_Reward/pen_joint_accel: -0.1210
    Episode_Reward/pen_action_rate: -0.1296
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0619
   Episode_Reward/pen_joint_powers: -0.0944
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2775
Episode_Reward/pen_flat_orientation: -0.1187
  Episode_Reward/pen_feet_distance: -0.0210
Episode_Reward/pen_feet_regulation: -0.4723
   Episode_Reward/foot_landing_vel: -0.1455
   Episode_Reward/test_gait_reward: -0.9563
Metrics/base_velocity/error_vel_xy: 1.1440
Metrics/base_velocity/error_vel_yaw: 1.4288
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 1.09s
                        Total time: 1296.90s
                               ETA: 1970.9s

################################################################################
                     [1m Learning iteration 1191/3000 [0m                     

                       Computation: 90385 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.6902
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9149
                     Learning rate: 0.0006
                       Mean reward: 113.72
               Mean episode length: 956.11
       Episode_Reward/keep_balance: 0.9629
     Episode_Reward/rew_lin_vel_xy: 5.7206
      Episode_Reward/rew_ang_vel_z: 2.2777
    Episode_Reward/pen_base_height: -0.3008
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.1971
   Episode_Reward/pen_joint_torque: -0.2245
    Episode_Reward/pen_joint_accel: -0.1261
    Episode_Reward/pen_action_rate: -0.1290
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0611
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2778
Episode_Reward/pen_flat_orientation: -0.1173
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4586
   Episode_Reward/foot_landing_vel: -0.1528
   Episode_Reward/test_gait_reward: -0.9498
Metrics/base_velocity/error_vel_xy: 1.0852
Metrics/base_velocity/error_vel_yaw: 1.4281
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 1.09s
                        Total time: 1297.99s
                               ETA: 1969.9s

################################################################################
                     [1m Learning iteration 1192/3000 [0m                     

                       Computation: 88848 steps/s (collection: 0.982s, learning 0.125s)
               Value function loss: 0.7715
                    Surrogate loss: -0.0036
             Mean action noise std: 0.9140
                     Learning rate: 0.0004
                       Mean reward: 118.37
               Mean episode length: 975.73
       Episode_Reward/keep_balance: 0.9714
     Episode_Reward/rew_lin_vel_xy: 5.7901
      Episode_Reward/rew_ang_vel_z: 2.3298
    Episode_Reward/pen_base_height: -0.3145
      Episode_Reward/pen_lin_vel_z: -0.0419
     Episode_Reward/pen_ang_vel_xy: -0.2020
   Episode_Reward/pen_joint_torque: -0.2314
    Episode_Reward/pen_joint_accel: -0.1254
    Episode_Reward/pen_action_rate: -0.1303
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0618
   Episode_Reward/pen_joint_powers: -0.0947
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2795
Episode_Reward/pen_flat_orientation: -0.1186
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4782
   Episode_Reward/foot_landing_vel: -0.1429
   Episode_Reward/test_gait_reward: -0.9596
Metrics/base_velocity/error_vel_xy: 1.1056
Metrics/base_velocity/error_vel_yaw: 1.4094
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 1.11s
                        Total time: 1299.10s
                               ETA: 1968.8s

################################################################################
                     [1m Learning iteration 1193/3000 [0m                     

                       Computation: 87174 steps/s (collection: 1.004s, learning 0.124s)
               Value function loss: 0.6724
                    Surrogate loss: -0.0055
             Mean action noise std: 0.9135
                     Learning rate: 0.0006
                       Mean reward: 117.97
               Mean episode length: 948.53
       Episode_Reward/keep_balance: 0.9431
     Episode_Reward/rew_lin_vel_xy: 5.5934
      Episode_Reward/rew_ang_vel_z: 2.3015
    Episode_Reward/pen_base_height: -0.3069
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1891
   Episode_Reward/pen_joint_torque: -0.2173
    Episode_Reward/pen_joint_accel: -0.1243
    Episode_Reward/pen_action_rate: -0.1246
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0591
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2688
Episode_Reward/pen_flat_orientation: -0.1166
  Episode_Reward/pen_feet_distance: -0.0184
Episode_Reward/pen_feet_regulation: -0.4339
   Episode_Reward/foot_landing_vel: -0.1537
   Episode_Reward/test_gait_reward: -0.9216
Metrics/base_velocity/error_vel_xy: 1.0764
Metrics/base_velocity/error_vel_yaw: 1.3412
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 1.13s
                        Total time: 1300.22s
                               ETA: 1967.8s

################################################################################
                     [1m Learning iteration 1194/3000 [0m                     

                       Computation: 89787 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 0.7363
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9138
                     Learning rate: 0.0006
                       Mean reward: 118.14
               Mean episode length: 974.55
       Episode_Reward/keep_balance: 0.9833
     Episode_Reward/rew_lin_vel_xy: 5.8586
      Episode_Reward/rew_ang_vel_z: 2.3545
    Episode_Reward/pen_base_height: -0.3016
      Episode_Reward/pen_lin_vel_z: -0.0428
     Episode_Reward/pen_ang_vel_xy: -0.1992
   Episode_Reward/pen_joint_torque: -0.2225
    Episode_Reward/pen_joint_accel: -0.1166
    Episode_Reward/pen_action_rate: -0.1290
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0910
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2805
Episode_Reward/pen_flat_orientation: -0.1161
  Episode_Reward/pen_feet_distance: -0.0131
Episode_Reward/pen_feet_regulation: -0.4582
   Episode_Reward/foot_landing_vel: -0.1374
   Episode_Reward/test_gait_reward: -0.9631
Metrics/base_velocity/error_vel_xy: 1.0988
Metrics/base_velocity/error_vel_yaw: 1.4289
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 1.09s
                        Total time: 1301.32s
                               ETA: 1966.7s

################################################################################
                     [1m Learning iteration 1195/3000 [0m                     

                       Computation: 90232 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.7445
                    Surrogate loss: -0.0051
             Mean action noise std: 0.9120
                     Learning rate: 0.0009
                       Mean reward: 112.60
               Mean episode length: 957.97
       Episode_Reward/keep_balance: 0.9629
     Episode_Reward/rew_lin_vel_xy: 5.6087
      Episode_Reward/rew_ang_vel_z: 2.2857
    Episode_Reward/pen_base_height: -0.3081
      Episode_Reward/pen_lin_vel_z: -0.0419
     Episode_Reward/pen_ang_vel_xy: -0.2066
   Episode_Reward/pen_joint_torque: -0.2211
    Episode_Reward/pen_joint_accel: -0.1183
    Episode_Reward/pen_action_rate: -0.1321
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0632
   Episode_Reward/pen_joint_powers: -0.0948
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2797
Episode_Reward/pen_flat_orientation: -0.1252
  Episode_Reward/pen_feet_distance: -0.0226
Episode_Reward/pen_feet_regulation: -0.4933
   Episode_Reward/foot_landing_vel: -0.1511
   Episode_Reward/test_gait_reward: -0.9572
Metrics/base_velocity/error_vel_xy: 1.1642
Metrics/base_velocity/error_vel_yaw: 1.4371
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 1.09s
                        Total time: 1302.41s
                               ETA: 1965.6s

################################################################################
                     [1m Learning iteration 1196/3000 [0m                     

                       Computation: 90313 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 0.6528
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9123
                     Learning rate: 0.0006
                       Mean reward: 114.81
               Mean episode length: 956.37
       Episode_Reward/keep_balance: 0.9627
     Episode_Reward/rew_lin_vel_xy: 5.6949
      Episode_Reward/rew_ang_vel_z: 2.3112
    Episode_Reward/pen_base_height: -0.3026
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1977
   Episode_Reward/pen_joint_torque: -0.2250
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1281
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0613
   Episode_Reward/pen_joint_powers: -0.0929
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2764
Episode_Reward/pen_flat_orientation: -0.1156
  Episode_Reward/pen_feet_distance: -0.0173
Episode_Reward/pen_feet_regulation: -0.4642
   Episode_Reward/foot_landing_vel: -0.1477
   Episode_Reward/test_gait_reward: -0.9455
Metrics/base_velocity/error_vel_xy: 1.1065
Metrics/base_velocity/error_vel_yaw: 1.4015
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 1.09s
                        Total time: 1303.50s
                               ETA: 1964.5s

################################################################################
                     [1m Learning iteration 1197/3000 [0m                     

                       Computation: 89824 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.7067
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9118
                     Learning rate: 0.0006
                       Mean reward: 115.91
               Mean episode length: 968.16
       Episode_Reward/keep_balance: 0.9651
     Episode_Reward/rew_lin_vel_xy: 5.6513
      Episode_Reward/rew_ang_vel_z: 2.3093
    Episode_Reward/pen_base_height: -0.3047
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1989
   Episode_Reward/pen_joint_torque: -0.2212
    Episode_Reward/pen_joint_accel: -0.1142
    Episode_Reward/pen_action_rate: -0.1281
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2749
Episode_Reward/pen_flat_orientation: -0.1251
  Episode_Reward/pen_feet_distance: -0.0184
Episode_Reward/pen_feet_regulation: -0.4733
   Episode_Reward/foot_landing_vel: -0.1452
   Episode_Reward/test_gait_reward: -0.9522
Metrics/base_velocity/error_vel_xy: 1.1356
Metrics/base_velocity/error_vel_yaw: 1.4077
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 1.09s
                        Total time: 1304.59s
                               ETA: 1963.4s

################################################################################
                     [1m Learning iteration 1198/3000 [0m                     

                       Computation: 91348 steps/s (collection: 0.955s, learning 0.121s)
               Value function loss: 0.6200
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9109
                     Learning rate: 0.0006
                       Mean reward: 110.53
               Mean episode length: 946.18
       Episode_Reward/keep_balance: 0.9448
     Episode_Reward/rew_lin_vel_xy: 5.5253
      Episode_Reward/rew_ang_vel_z: 2.2685
    Episode_Reward/pen_base_height: -0.3125
      Episode_Reward/pen_lin_vel_z: -0.0430
     Episode_Reward/pen_ang_vel_xy: -0.1943
   Episode_Reward/pen_joint_torque: -0.2328
    Episode_Reward/pen_joint_accel: -0.1234
    Episode_Reward/pen_action_rate: -0.1274
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0633
   Episode_Reward/pen_joint_powers: -0.0960
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2705
Episode_Reward/pen_flat_orientation: -0.1228
  Episode_Reward/pen_feet_distance: -0.0223
Episode_Reward/pen_feet_regulation: -0.4777
   Episode_Reward/foot_landing_vel: -0.1609
   Episode_Reward/test_gait_reward: -0.9286
Metrics/base_velocity/error_vel_xy: 1.1275
Metrics/base_velocity/error_vel_yaw: 1.3811
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 1.08s
                        Total time: 1305.67s
                               ETA: 1962.3s

################################################################################
                     [1m Learning iteration 1199/3000 [0m                     

                       Computation: 91615 steps/s (collection: 0.952s, learning 0.121s)
               Value function loss: 0.7635
                    Surrogate loss: -0.0032
             Mean action noise std: 0.9112
                     Learning rate: 0.0006
                       Mean reward: 116.97
               Mean episode length: 942.57
       Episode_Reward/keep_balance: 0.9374
     Episode_Reward/rew_lin_vel_xy: 5.5978
      Episode_Reward/rew_ang_vel_z: 2.2677
    Episode_Reward/pen_base_height: -0.2945
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1866
   Episode_Reward/pen_joint_torque: -0.2225
    Episode_Reward/pen_joint_accel: -0.1092
    Episode_Reward/pen_action_rate: -0.1223
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2622
Episode_Reward/pen_flat_orientation: -0.1138
  Episode_Reward/pen_feet_distance: -0.0168
Episode_Reward/pen_feet_regulation: -0.4354
   Episode_Reward/foot_landing_vel: -0.1415
   Episode_Reward/test_gait_reward: -0.9172
Metrics/base_velocity/error_vel_xy: 1.0657
Metrics/base_velocity/error_vel_yaw: 1.3447
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 1.07s
                        Total time: 1306.74s
                               ETA: 1961.2s

################################################################################
                     [1m Learning iteration 1200/3000 [0m                     

                       Computation: 90476 steps/s (collection: 0.965s, learning 0.121s)
               Value function loss: 0.6861
                    Surrogate loss: -0.0045
             Mean action noise std: 0.9100
                     Learning rate: 0.0009
                       Mean reward: 117.91
               Mean episode length: 963.07
       Episode_Reward/keep_balance: 0.9720
     Episode_Reward/rew_lin_vel_xy: 5.7603
      Episode_Reward/rew_ang_vel_z: 2.3265
    Episode_Reward/pen_base_height: -0.3017
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.1947
   Episode_Reward/pen_joint_torque: -0.2295
    Episode_Reward/pen_joint_accel: -0.1220
    Episode_Reward/pen_action_rate: -0.1288
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0610
   Episode_Reward/pen_joint_powers: -0.0932
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2746
Episode_Reward/pen_flat_orientation: -0.1230
  Episode_Reward/pen_feet_distance: -0.0128
Episode_Reward/pen_feet_regulation: -0.4558
   Episode_Reward/foot_landing_vel: -0.1436
   Episode_Reward/test_gait_reward: -0.9584
Metrics/base_velocity/error_vel_xy: 1.1269
Metrics/base_velocity/error_vel_yaw: 1.4315
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 1.09s
                        Total time: 1307.83s
                               ETA: 1960.1s

################################################################################
                     [1m Learning iteration 1201/3000 [0m                     

                       Computation: 90555 steps/s (collection: 0.964s, learning 0.121s)
               Value function loss: 0.6951
                    Surrogate loss: 0.0010
             Mean action noise std: 0.9098
                     Learning rate: 0.0002
                       Mean reward: 113.21
               Mean episode length: 956.46
       Episode_Reward/keep_balance: 0.9347
     Episode_Reward/rew_lin_vel_xy: 5.5493
      Episode_Reward/rew_ang_vel_z: 2.2520
    Episode_Reward/pen_base_height: -0.2988
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.1908
   Episode_Reward/pen_joint_torque: -0.2144
    Episode_Reward/pen_joint_accel: -0.1242
    Episode_Reward/pen_action_rate: -0.1236
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2647
Episode_Reward/pen_flat_orientation: -0.1177
  Episode_Reward/pen_feet_distance: -0.0182
Episode_Reward/pen_feet_regulation: -0.4603
   Episode_Reward/foot_landing_vel: -0.1436
   Episode_Reward/test_gait_reward: -0.9236
Metrics/base_velocity/error_vel_xy: 1.0615
Metrics/base_velocity/error_vel_yaw: 1.3384
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 1.09s
                        Total time: 1308.91s
                               ETA: 1959.0s

################################################################################
                     [1m Learning iteration 1202/3000 [0m                     

                       Computation: 90245 steps/s (collection: 0.965s, learning 0.125s)
               Value function loss: 0.7341
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9104
                     Learning rate: 0.0006
                       Mean reward: 118.14
               Mean episode length: 965.80
       Episode_Reward/keep_balance: 0.9732
     Episode_Reward/rew_lin_vel_xy: 5.7445
      Episode_Reward/rew_ang_vel_z: 2.2945
    Episode_Reward/pen_base_height: -0.3036
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1971
   Episode_Reward/pen_joint_torque: -0.2173
    Episode_Reward/pen_joint_accel: -0.1354
    Episode_Reward/pen_action_rate: -0.1294
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0605
   Episode_Reward/pen_joint_powers: -0.0911
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2815
Episode_Reward/pen_flat_orientation: -0.1183
  Episode_Reward/pen_feet_distance: -0.0177
Episode_Reward/pen_feet_regulation: -0.4573
   Episode_Reward/foot_landing_vel: -0.1368
   Episode_Reward/test_gait_reward: -0.9597
Metrics/base_velocity/error_vel_xy: 1.1304
Metrics/base_velocity/error_vel_yaw: 1.4579
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 1.09s
                        Total time: 1310.00s
                               ETA: 1957.9s

################################################################################
                     [1m Learning iteration 1203/3000 [0m                     

                       Computation: 91197 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.6837
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9112
                     Learning rate: 0.0009
                       Mean reward: 115.58
               Mean episode length: 958.13
       Episode_Reward/keep_balance: 0.9405
     Episode_Reward/rew_lin_vel_xy: 5.5915
      Episode_Reward/rew_ang_vel_z: 2.2745
    Episode_Reward/pen_base_height: -0.3064
      Episode_Reward/pen_lin_vel_z: -0.0428
     Episode_Reward/pen_ang_vel_xy: -0.1909
   Episode_Reward/pen_joint_torque: -0.2304
    Episode_Reward/pen_joint_accel: -0.1281
    Episode_Reward/pen_action_rate: -0.1252
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0923
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2661
Episode_Reward/pen_flat_orientation: -0.1283
  Episode_Reward/pen_feet_distance: -0.0180
Episode_Reward/pen_feet_regulation: -0.4711
   Episode_Reward/foot_landing_vel: -0.1480
   Episode_Reward/test_gait_reward: -0.9248
Metrics/base_velocity/error_vel_xy: 1.0683
Metrics/base_velocity/error_vel_yaw: 1.3525
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 1.08s
                        Total time: 1311.08s
                               ETA: 1956.8s

################################################################################
                     [1m Learning iteration 1204/3000 [0m                     

                       Computation: 91443 steps/s (collection: 0.951s, learning 0.124s)
               Value function loss: 0.6914
                    Surrogate loss: -0.0018
             Mean action noise std: 0.9112
                     Learning rate: 0.0004
                       Mean reward: 117.01
               Mean episode length: 972.62
       Episode_Reward/keep_balance: 0.9690
     Episode_Reward/rew_lin_vel_xy: 5.7548
      Episode_Reward/rew_ang_vel_z: 2.2728
    Episode_Reward/pen_base_height: -0.3068
      Episode_Reward/pen_lin_vel_z: -0.0427
     Episode_Reward/pen_ang_vel_xy: -0.1970
   Episode_Reward/pen_joint_torque: -0.2285
    Episode_Reward/pen_joint_accel: -0.1171
    Episode_Reward/pen_action_rate: -0.1281
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0616
   Episode_Reward/pen_joint_powers: -0.0931
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2754
Episode_Reward/pen_flat_orientation: -0.1211
  Episode_Reward/pen_feet_distance: -0.0190
Episode_Reward/pen_feet_regulation: -0.4718
   Episode_Reward/foot_landing_vel: -0.1486
   Episode_Reward/test_gait_reward: -0.9585
Metrics/base_velocity/error_vel_xy: 1.1020
Metrics/base_velocity/error_vel_yaw: 1.4510
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 1.08s
                        Total time: 1312.15s
                               ETA: 1955.7s

################################################################################
                     [1m Learning iteration 1205/3000 [0m                     

                       Computation: 90611 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.7186
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9099
                     Learning rate: 0.0009
                       Mean reward: 118.87
               Mean episode length: 976.43
       Episode_Reward/keep_balance: 0.9617
     Episode_Reward/rew_lin_vel_xy: 5.6848
      Episode_Reward/rew_ang_vel_z: 2.3396
    Episode_Reward/pen_base_height: -0.3045
      Episode_Reward/pen_lin_vel_z: -0.0435
     Episode_Reward/pen_ang_vel_xy: -0.1911
   Episode_Reward/pen_joint_torque: -0.2304
    Episode_Reward/pen_joint_accel: -0.1303
    Episode_Reward/pen_action_rate: -0.1272
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0608
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2715
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4767
   Episode_Reward/foot_landing_vel: -0.1479
   Episode_Reward/test_gait_reward: -0.9505
Metrics/base_velocity/error_vel_xy: 1.1193
Metrics/base_velocity/error_vel_yaw: 1.3601
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 1.08s
                        Total time: 1313.24s
                               ETA: 1954.6s

################################################################################
                     [1m Learning iteration 1206/3000 [0m                     

                       Computation: 90338 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.6714
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9096
                     Learning rate: 0.0009
                       Mean reward: 110.04
               Mean episode length: 929.22
       Episode_Reward/keep_balance: 0.9336
     Episode_Reward/rew_lin_vel_xy: 5.4495
      Episode_Reward/rew_ang_vel_z: 2.2237
    Episode_Reward/pen_base_height: -0.2981
      Episode_Reward/pen_lin_vel_z: -0.0453
     Episode_Reward/pen_ang_vel_xy: -0.1952
   Episode_Reward/pen_joint_torque: -0.2233
    Episode_Reward/pen_joint_accel: -0.1335
    Episode_Reward/pen_action_rate: -0.1243
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0618
   Episode_Reward/pen_joint_powers: -0.0919
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2670
Episode_Reward/pen_flat_orientation: -0.1248
  Episode_Reward/pen_feet_distance: -0.0186
Episode_Reward/pen_feet_regulation: -0.4731
   Episode_Reward/foot_landing_vel: -0.1567
   Episode_Reward/test_gait_reward: -0.9186
Metrics/base_velocity/error_vel_xy: 1.1166
Metrics/base_velocity/error_vel_yaw: 1.3663
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 1.09s
                        Total time: 1314.33s
                               ETA: 1953.5s

################################################################################
                     [1m Learning iteration 1207/3000 [0m                     

                       Computation: 90242 steps/s (collection: 0.964s, learning 0.125s)
               Value function loss: 0.6489
                    Surrogate loss: -0.0034
             Mean action noise std: 0.9101
                     Learning rate: 0.0009
                       Mean reward: 120.65
               Mean episode length: 981.29
       Episode_Reward/keep_balance: 0.9868
     Episode_Reward/rew_lin_vel_xy: 5.8629
      Episode_Reward/rew_ang_vel_z: 2.3641
    Episode_Reward/pen_base_height: -0.3025
      Episode_Reward/pen_lin_vel_z: -0.0430
     Episode_Reward/pen_ang_vel_xy: -0.1991
   Episode_Reward/pen_joint_torque: -0.2296
    Episode_Reward/pen_joint_accel: -0.1206
    Episode_Reward/pen_action_rate: -0.1304
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0622
   Episode_Reward/pen_joint_powers: -0.0946
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2815
Episode_Reward/pen_flat_orientation: -0.1198
  Episode_Reward/pen_feet_distance: -0.0172
Episode_Reward/pen_feet_regulation: -0.4811
   Episode_Reward/foot_landing_vel: -0.1512
   Episode_Reward/test_gait_reward: -0.9718
Metrics/base_velocity/error_vel_xy: 1.1034
Metrics/base_velocity/error_vel_yaw: 1.4415
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 1.09s
                        Total time: 1315.42s
                               ETA: 1952.4s

################################################################################
                     [1m Learning iteration 1208/3000 [0m                     

                       Computation: 89457 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.7348
                    Surrogate loss: -0.0018
             Mean action noise std: 0.9108
                     Learning rate: 0.0009
                       Mean reward: 119.74
               Mean episode length: 969.77
       Episode_Reward/keep_balance: 0.9739
     Episode_Reward/rew_lin_vel_xy: 5.8087
      Episode_Reward/rew_ang_vel_z: 2.3557
    Episode_Reward/pen_base_height: -0.3071
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1917
   Episode_Reward/pen_joint_torque: -0.2244
    Episode_Reward/pen_joint_accel: -0.1135
    Episode_Reward/pen_action_rate: -0.1275
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0593
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2729
Episode_Reward/pen_flat_orientation: -0.1180
  Episode_Reward/pen_feet_distance: -0.0194
Episode_Reward/pen_feet_regulation: -0.4655
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.9495
Metrics/base_velocity/error_vel_xy: 1.0839
Metrics/base_velocity/error_vel_yaw: 1.4052
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 1.10s
                        Total time: 1316.51s
                               ETA: 1951.4s

################################################################################
                     [1m Learning iteration 1209/3000 [0m                     

                       Computation: 89404 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.7140
                    Surrogate loss: -0.0026
             Mean action noise std: 0.9097
                     Learning rate: 0.0006
                       Mean reward: 118.35
               Mean episode length: 962.53
       Episode_Reward/keep_balance: 0.9583
     Episode_Reward/rew_lin_vel_xy: 5.6752
      Episode_Reward/rew_ang_vel_z: 2.3181
    Episode_Reward/pen_base_height: -0.3150
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.1928
   Episode_Reward/pen_joint_torque: -0.2255
    Episode_Reward/pen_joint_accel: -0.1148
    Episode_Reward/pen_action_rate: -0.1258
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0612
   Episode_Reward/pen_joint_powers: -0.0928
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2696
Episode_Reward/pen_flat_orientation: -0.1280
  Episode_Reward/pen_feet_distance: -0.0161
Episode_Reward/pen_feet_regulation: -0.4721
   Episode_Reward/foot_landing_vel: -0.1440
   Episode_Reward/test_gait_reward: -0.9447
Metrics/base_velocity/error_vel_xy: 1.1012
Metrics/base_velocity/error_vel_yaw: 1.3772
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 1.10s
                        Total time: 1317.61s
                               ETA: 1950.3s

################################################################################
                     [1m Learning iteration 1210/3000 [0m                     

                       Computation: 91123 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.7359
                    Surrogate loss: -0.0003
             Mean action noise std: 0.9094
                     Learning rate: 0.0002
                       Mean reward: 115.43
               Mean episode length: 948.27
       Episode_Reward/keep_balance: 0.9585
     Episode_Reward/rew_lin_vel_xy: 5.6446
      Episode_Reward/rew_ang_vel_z: 2.2480
    Episode_Reward/pen_base_height: -0.2958
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.2061
   Episode_Reward/pen_joint_torque: -0.2252
    Episode_Reward/pen_joint_accel: -0.1242
    Episode_Reward/pen_action_rate: -0.1292
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0626
   Episode_Reward/pen_joint_powers: -0.0950
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2784
Episode_Reward/pen_flat_orientation: -0.1214
  Episode_Reward/pen_feet_distance: -0.0138
Episode_Reward/pen_feet_regulation: -0.4809
   Episode_Reward/foot_landing_vel: -0.1445
   Episode_Reward/test_gait_reward: -0.9467
Metrics/base_velocity/error_vel_xy: 1.1081
Metrics/base_velocity/error_vel_yaw: 1.4564
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 1.08s
                        Total time: 1318.69s
                               ETA: 1949.2s

################################################################################
                     [1m Learning iteration 1211/3000 [0m                     

                       Computation: 90027 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.6774
                    Surrogate loss: -0.0049
             Mean action noise std: 0.9084
                     Learning rate: 0.0004
                       Mean reward: 115.02
               Mean episode length: 954.15
       Episode_Reward/keep_balance: 0.9474
     Episode_Reward/rew_lin_vel_xy: 5.5803
      Episode_Reward/rew_ang_vel_z: 2.2369
    Episode_Reward/pen_base_height: -0.2972
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1931
   Episode_Reward/pen_joint_torque: -0.2190
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1255
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0610
   Episode_Reward/pen_joint_powers: -0.0922
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2691
Episode_Reward/pen_flat_orientation: -0.1288
  Episode_Reward/pen_feet_distance: -0.0197
Episode_Reward/pen_feet_regulation: -0.4827
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9402
Metrics/base_velocity/error_vel_xy: 1.1046
Metrics/base_velocity/error_vel_yaw: 1.4176
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 1.09s
                        Total time: 1319.79s
                               ETA: 1948.1s

################################################################################
                     [1m Learning iteration 1212/3000 [0m                     

                       Computation: 90602 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.6721
                    Surrogate loss: -0.0038
             Mean action noise std: 0.9077
                     Learning rate: 0.0006
                       Mean reward: 115.68
               Mean episode length: 969.26
       Episode_Reward/keep_balance: 0.9622
     Episode_Reward/rew_lin_vel_xy: 5.6535
      Episode_Reward/rew_ang_vel_z: 2.2471
    Episode_Reward/pen_base_height: -0.3092
      Episode_Reward/pen_lin_vel_z: -0.0438
     Episode_Reward/pen_ang_vel_xy: -0.2044
   Episode_Reward/pen_joint_torque: -0.2297
    Episode_Reward/pen_joint_accel: -0.1207
    Episode_Reward/pen_action_rate: -0.1293
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0629
   Episode_Reward/pen_joint_powers: -0.0949
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2797
Episode_Reward/pen_flat_orientation: -0.1214
  Episode_Reward/pen_feet_distance: -0.0174
Episode_Reward/pen_feet_regulation: -0.4727
   Episode_Reward/foot_landing_vel: -0.1482
   Episode_Reward/test_gait_reward: -0.9541
Metrics/base_velocity/error_vel_xy: 1.1110
Metrics/base_velocity/error_vel_yaw: 1.4614
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 1.08s
                        Total time: 1320.87s
                               ETA: 1947.0s

################################################################################
                     [1m Learning iteration 1213/3000 [0m                     

                       Computation: 91817 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.7140
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9074
                     Learning rate: 0.0006
                       Mean reward: 115.99
               Mean episode length: 973.00
       Episode_Reward/keep_balance: 0.9756
     Episode_Reward/rew_lin_vel_xy: 5.8001
      Episode_Reward/rew_ang_vel_z: 2.3197
    Episode_Reward/pen_base_height: -0.3100
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1910
   Episode_Reward/pen_joint_torque: -0.2266
    Episode_Reward/pen_joint_accel: -0.1207
    Episode_Reward/pen_action_rate: -0.1277
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0618
   Episode_Reward/pen_joint_powers: -0.0938
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2750
Episode_Reward/pen_flat_orientation: -0.1190
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4781
   Episode_Reward/foot_landing_vel: -0.1416
   Episode_Reward/test_gait_reward: -0.9613
Metrics/base_velocity/error_vel_xy: 1.1050
Metrics/base_velocity/error_vel_yaw: 1.4334
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 1.07s
                        Total time: 1321.94s
                               ETA: 1945.9s

################################################################################
                     [1m Learning iteration 1214/3000 [0m                     

                       Computation: 89463 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.6740
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9088
                     Learning rate: 0.0009
                       Mean reward: 111.87
               Mean episode length: 949.76
       Episode_Reward/keep_balance: 0.9565
     Episode_Reward/rew_lin_vel_xy: 5.5935
      Episode_Reward/rew_ang_vel_z: 2.2908
    Episode_Reward/pen_base_height: -0.3103
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1978
   Episode_Reward/pen_joint_torque: -0.2330
    Episode_Reward/pen_joint_accel: -0.1205
    Episode_Reward/pen_action_rate: -0.1265
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0619
   Episode_Reward/pen_joint_powers: -0.0944
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2703
Episode_Reward/pen_flat_orientation: -0.1261
  Episode_Reward/pen_feet_distance: -0.0179
Episode_Reward/pen_feet_regulation: -0.4849
   Episode_Reward/foot_landing_vel: -0.1452
   Episode_Reward/test_gait_reward: -0.9382
Metrics/base_velocity/error_vel_xy: 1.1435
Metrics/base_velocity/error_vel_yaw: 1.3908
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 1.10s
                        Total time: 1323.04s
                               ETA: 1944.8s

################################################################################
                     [1m Learning iteration 1215/3000 [0m                     

                       Computation: 90112 steps/s (collection: 0.965s, learning 0.126s)
               Value function loss: 0.6180
                    Surrogate loss: -0.0005
             Mean action noise std: 0.9098
                     Learning rate: 0.0004
                       Mean reward: 117.32
               Mean episode length: 958.47
       Episode_Reward/keep_balance: 0.9759
     Episode_Reward/rew_lin_vel_xy: 5.8365
      Episode_Reward/rew_ang_vel_z: 2.3804
    Episode_Reward/pen_base_height: -0.3082
      Episode_Reward/pen_lin_vel_z: -0.0439
     Episode_Reward/pen_ang_vel_xy: -0.1951
   Episode_Reward/pen_joint_torque: -0.2418
    Episode_Reward/pen_joint_accel: -0.1165
    Episode_Reward/pen_action_rate: -0.1270
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0611
   Episode_Reward/pen_joint_powers: -0.0950
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2705
Episode_Reward/pen_flat_orientation: -0.1141
  Episode_Reward/pen_feet_distance: -0.0156
Episode_Reward/pen_feet_regulation: -0.4817
   Episode_Reward/foot_landing_vel: -0.1439
   Episode_Reward/test_gait_reward: -0.9604
Metrics/base_velocity/error_vel_xy: 1.0938
Metrics/base_velocity/error_vel_yaw: 1.3758
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 1.09s
                        Total time: 1324.13s
                               ETA: 1943.7s

################################################################################
                     [1m Learning iteration 1216/3000 [0m                     

                       Computation: 89895 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.6967
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9106
                     Learning rate: 0.0009
                       Mean reward: 115.87
               Mean episode length: 965.67
       Episode_Reward/keep_balance: 0.9699
     Episode_Reward/rew_lin_vel_xy: 5.7391
      Episode_Reward/rew_ang_vel_z: 2.3266
    Episode_Reward/pen_base_height: -0.3001
      Episode_Reward/pen_lin_vel_z: -0.0428
     Episode_Reward/pen_ang_vel_xy: -0.1961
   Episode_Reward/pen_joint_torque: -0.2237
    Episode_Reward/pen_joint_accel: -0.1165
    Episode_Reward/pen_action_rate: -0.1269
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0617
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2747
Episode_Reward/pen_flat_orientation: -0.1200
  Episode_Reward/pen_feet_distance: -0.0161
Episode_Reward/pen_feet_regulation: -0.4629
   Episode_Reward/foot_landing_vel: -0.1543
   Episode_Reward/test_gait_reward: -0.9405
Metrics/base_velocity/error_vel_xy: 1.1255
Metrics/base_velocity/error_vel_yaw: 1.4101
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 1.09s
                        Total time: 1325.22s
                               ETA: 1942.6s

################################################################################
                     [1m Learning iteration 1217/3000 [0m                     

                       Computation: 87962 steps/s (collection: 0.994s, learning 0.124s)
               Value function loss: 0.6219
                    Surrogate loss: -0.0015
             Mean action noise std: 0.9117
                     Learning rate: 0.0004
                       Mean reward: 119.48
               Mean episode length: 972.12
       Episode_Reward/keep_balance: 0.9853
     Episode_Reward/rew_lin_vel_xy: 5.8602
      Episode_Reward/rew_ang_vel_z: 2.3512
    Episode_Reward/pen_base_height: -0.2985
      Episode_Reward/pen_lin_vel_z: -0.0423
     Episode_Reward/pen_ang_vel_xy: -0.1949
   Episode_Reward/pen_joint_torque: -0.2353
    Episode_Reward/pen_joint_accel: -0.1111
    Episode_Reward/pen_action_rate: -0.1288
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0615
   Episode_Reward/pen_joint_powers: -0.0955
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2760
Episode_Reward/pen_flat_orientation: -0.1186
  Episode_Reward/pen_feet_distance: -0.0184
Episode_Reward/pen_feet_regulation: -0.4827
   Episode_Reward/foot_landing_vel: -0.1487
   Episode_Reward/test_gait_reward: -0.9659
Metrics/base_velocity/error_vel_xy: 1.1208
Metrics/base_velocity/error_vel_yaw: 1.4415
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 1.12s
                        Total time: 1326.34s
                               ETA: 1941.6s

################################################################################
                     [1m Learning iteration 1218/3000 [0m                     

                       Computation: 90735 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.6212
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9116
                     Learning rate: 0.0003
                       Mean reward: 124.85
               Mean episode length: 993.56
       Episode_Reward/keep_balance: 0.9871
     Episode_Reward/rew_lin_vel_xy: 5.9649
      Episode_Reward/rew_ang_vel_z: 2.4019
    Episode_Reward/pen_base_height: -0.3030
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1925
   Episode_Reward/pen_joint_torque: -0.2346
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1273
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0930
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2734
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0174
Episode_Reward/pen_feet_regulation: -0.4632
   Episode_Reward/foot_landing_vel: -0.1468
   Episode_Reward/test_gait_reward: -0.9621
Metrics/base_velocity/error_vel_xy: 1.0768
Metrics/base_velocity/error_vel_yaw: 1.3976
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 1.08s
                        Total time: 1327.42s
                               ETA: 1940.5s

################################################################################
                     [1m Learning iteration 1219/3000 [0m                     

                       Computation: 89455 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.6476
                    Surrogate loss: -0.0052
             Mean action noise std: 0.9119
                     Learning rate: 0.0006
                       Mean reward: 118.24
               Mean episode length: 986.04
       Episode_Reward/keep_balance: 0.9874
     Episode_Reward/rew_lin_vel_xy: 5.7682
      Episode_Reward/rew_ang_vel_z: 2.3553
    Episode_Reward/pen_base_height: -0.3080
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.1982
   Episode_Reward/pen_joint_torque: -0.2319
    Episode_Reward/pen_joint_accel: -0.1169
    Episode_Reward/pen_action_rate: -0.1304
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0639
   Episode_Reward/pen_joint_powers: -0.0962
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2783
Episode_Reward/pen_flat_orientation: -0.1265
  Episode_Reward/pen_feet_distance: -0.0148
Episode_Reward/pen_feet_regulation: -0.4958
   Episode_Reward/foot_landing_vel: -0.1487
   Episode_Reward/test_gait_reward: -0.9732
Metrics/base_velocity/error_vel_xy: 1.1736
Metrics/base_velocity/error_vel_yaw: 1.4528
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 1.10s
                        Total time: 1328.52s
                               ETA: 1939.4s

################################################################################
                     [1m Learning iteration 1220/3000 [0m                     

                       Computation: 89615 steps/s (collection: 0.972s, learning 0.125s)
               Value function loss: 0.7380
                    Surrogate loss: -0.0045
             Mean action noise std: 0.9126
                     Learning rate: 0.0009
                       Mean reward: 117.92
               Mean episode length: 971.12
       Episode_Reward/keep_balance: 0.9749
     Episode_Reward/rew_lin_vel_xy: 5.8072
      Episode_Reward/rew_ang_vel_z: 2.3204
    Episode_Reward/pen_base_height: -0.2962
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1902
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1264
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0908
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2705
Episode_Reward/pen_flat_orientation: -0.1194
  Episode_Reward/pen_feet_distance: -0.0164
Episode_Reward/pen_feet_regulation: -0.4696
   Episode_Reward/foot_landing_vel: -0.1388
   Episode_Reward/test_gait_reward: -0.9656
Metrics/base_velocity/error_vel_xy: 1.0994
Metrics/base_velocity/error_vel_yaw: 1.4304
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 1.10s
                        Total time: 1329.62s
                               ETA: 1938.3s

################################################################################
                     [1m Learning iteration 1221/3000 [0m                     

                       Computation: 88525 steps/s (collection: 0.987s, learning 0.124s)
               Value function loss: 0.6052
                    Surrogate loss: -0.0003
             Mean action noise std: 0.9117
                     Learning rate: 0.0004
                       Mean reward: 115.16
               Mean episode length: 952.84
       Episode_Reward/keep_balance: 0.9602
     Episode_Reward/rew_lin_vel_xy: 5.7245
      Episode_Reward/rew_ang_vel_z: 2.3003
    Episode_Reward/pen_base_height: -0.3102
      Episode_Reward/pen_lin_vel_z: -0.0427
     Episode_Reward/pen_ang_vel_xy: -0.1931
   Episode_Reward/pen_joint_torque: -0.2289
    Episode_Reward/pen_joint_accel: -0.1200
    Episode_Reward/pen_action_rate: -0.1259
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0618
   Episode_Reward/pen_joint_powers: -0.0936
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2700
Episode_Reward/pen_flat_orientation: -0.1230
  Episode_Reward/pen_feet_distance: -0.0165
Episode_Reward/pen_feet_regulation: -0.4805
   Episode_Reward/foot_landing_vel: -0.1435
   Episode_Reward/test_gait_reward: -0.9540
Metrics/base_velocity/error_vel_xy: 1.0843
Metrics/base_velocity/error_vel_yaw: 1.3989
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 1.11s
                        Total time: 1330.73s
                               ETA: 1937.3s

################################################################################
                     [1m Learning iteration 1222/3000 [0m                     

                       Computation: 88810 steps/s (collection: 0.984s, learning 0.123s)
               Value function loss: 0.6550
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9102
                     Learning rate: 0.0003
                       Mean reward: 119.92
               Mean episode length: 970.76
       Episode_Reward/keep_balance: 0.9736
     Episode_Reward/rew_lin_vel_xy: 5.8288
      Episode_Reward/rew_ang_vel_z: 2.3964
    Episode_Reward/pen_base_height: -0.2976
      Episode_Reward/pen_lin_vel_z: -0.0447
     Episode_Reward/pen_ang_vel_xy: -0.1951
   Episode_Reward/pen_joint_torque: -0.2443
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1259
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0613
   Episode_Reward/pen_joint_powers: -0.0952
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2673
Episode_Reward/pen_flat_orientation: -0.1207
  Episode_Reward/pen_feet_distance: -0.0172
Episode_Reward/pen_feet_regulation: -0.4739
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.9557
Metrics/base_velocity/error_vel_xy: 1.0900
Metrics/base_velocity/error_vel_yaw: 1.3548
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 1.11s
                        Total time: 1331.84s
                               ETA: 1936.2s

################################################################################
                     [1m Learning iteration 1223/3000 [0m                     

                       Computation: 89073 steps/s (collection: 0.978s, learning 0.125s)
               Value function loss: 0.6847
                    Surrogate loss: -0.0049
             Mean action noise std: 0.9100
                     Learning rate: 0.0006
                       Mean reward: 123.90
               Mean episode length: 968.50
       Episode_Reward/keep_balance: 0.9654
     Episode_Reward/rew_lin_vel_xy: 5.9347
      Episode_Reward/rew_ang_vel_z: 2.3498
    Episode_Reward/pen_base_height: -0.2699
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1870
   Episode_Reward/pen_joint_torque: -0.2129
    Episode_Reward/pen_joint_accel: -0.1069
    Episode_Reward/pen_action_rate: -0.1212
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2662
Episode_Reward/pen_flat_orientation: -0.1096
  Episode_Reward/pen_feet_distance: -0.0168
Episode_Reward/pen_feet_regulation: -0.4306
   Episode_Reward/foot_landing_vel: -0.1362
   Episode_Reward/test_gait_reward: -0.9386
Metrics/base_velocity/error_vel_xy: 0.9844
Metrics/base_velocity/error_vel_yaw: 1.3615
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 1.10s
                        Total time: 1332.94s
                               ETA: 1935.2s

################################################################################
                     [1m Learning iteration 1224/3000 [0m                     

                       Computation: 88716 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 0.7388
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9100
                     Learning rate: 0.0006
                       Mean reward: 114.53
               Mean episode length: 942.54
       Episode_Reward/keep_balance: 0.9428
     Episode_Reward/rew_lin_vel_xy: 5.6239
      Episode_Reward/rew_ang_vel_z: 2.2341
    Episode_Reward/pen_base_height: -0.2858
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1925
   Episode_Reward/pen_joint_torque: -0.2180
    Episode_Reward/pen_joint_accel: -0.1162
    Episode_Reward/pen_action_rate: -0.1243
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2680
Episode_Reward/pen_flat_orientation: -0.1194
  Episode_Reward/pen_feet_distance: -0.0169
Episode_Reward/pen_feet_regulation: -0.4727
   Episode_Reward/foot_landing_vel: -0.1403
   Episode_Reward/test_gait_reward: -0.9325
Metrics/base_velocity/error_vel_xy: 1.0592
Metrics/base_velocity/error_vel_yaw: 1.4136
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 1.11s
                        Total time: 1334.05s
                               ETA: 1934.1s

################################################################################
                     [1m Learning iteration 1225/3000 [0m                     

                       Computation: 89349 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 0.6304
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9082
                     Learning rate: 0.0003
                       Mean reward: 117.34
               Mean episode length: 961.78
       Episode_Reward/keep_balance: 0.9568
     Episode_Reward/rew_lin_vel_xy: 5.7035
      Episode_Reward/rew_ang_vel_z: 2.2720
    Episode_Reward/pen_base_height: -0.2906
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.1925
   Episode_Reward/pen_joint_torque: -0.2191
    Episode_Reward/pen_joint_accel: -0.1126
    Episode_Reward/pen_action_rate: -0.1250
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0595
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2713
Episode_Reward/pen_flat_orientation: -0.1207
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4709
   Episode_Reward/foot_landing_vel: -0.1368
   Episode_Reward/test_gait_reward: -0.9367
Metrics/base_velocity/error_vel_xy: 1.0786
Metrics/base_velocity/error_vel_yaw: 1.4181
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 1.10s
                        Total time: 1335.15s
                               ETA: 1933.0s

################################################################################
                     [1m Learning iteration 1226/3000 [0m                     

                       Computation: 88498 steps/s (collection: 0.988s, learning 0.123s)
               Value function loss: 0.6365
                    Surrogate loss: -0.0053
             Mean action noise std: 0.9084
                     Learning rate: 0.0006
                       Mean reward: 117.43
               Mean episode length: 953.89
       Episode_Reward/keep_balance: 0.9498
     Episode_Reward/rew_lin_vel_xy: 5.7572
      Episode_Reward/rew_ang_vel_z: 2.2815
    Episode_Reward/pen_base_height: -0.2887
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1899
   Episode_Reward/pen_joint_torque: -0.2239
    Episode_Reward/pen_joint_accel: -0.1057
    Episode_Reward/pen_action_rate: -0.1226
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0597
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2665
Episode_Reward/pen_flat_orientation: -0.1168
  Episode_Reward/pen_feet_distance: -0.0158
Episode_Reward/pen_feet_regulation: -0.4628
   Episode_Reward/foot_landing_vel: -0.1368
   Episode_Reward/test_gait_reward: -0.9284
Metrics/base_velocity/error_vel_xy: 1.0419
Metrics/base_velocity/error_vel_yaw: 1.3794
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 1.11s
                        Total time: 1336.26s
                               ETA: 1932.0s

################################################################################
                     [1m Learning iteration 1227/3000 [0m                     

                       Computation: 88737 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 0.6901
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9095
                     Learning rate: 0.0006
                       Mean reward: 118.49
               Mean episode length: 970.80
       Episode_Reward/keep_balance: 0.9703
     Episode_Reward/rew_lin_vel_xy: 5.8299
      Episode_Reward/rew_ang_vel_z: 2.3367
    Episode_Reward/pen_base_height: -0.3006
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.1962
   Episode_Reward/pen_joint_torque: -0.2270
    Episode_Reward/pen_joint_accel: -0.1172
    Episode_Reward/pen_action_rate: -0.1263
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0623
   Episode_Reward/pen_joint_powers: -0.0942
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2728
Episode_Reward/pen_flat_orientation: -0.1214
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.4870
   Episode_Reward/foot_landing_vel: -0.1473
   Episode_Reward/test_gait_reward: -0.9591
Metrics/base_velocity/error_vel_xy: 1.0881
Metrics/base_velocity/error_vel_yaw: 1.4051
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 1.11s
                        Total time: 1337.37s
                               ETA: 1930.9s

################################################################################
                     [1m Learning iteration 1228/3000 [0m                     

                       Computation: 88086 steps/s (collection: 0.992s, learning 0.124s)
               Value function loss: 0.6863
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9107
                     Learning rate: 0.0009
                       Mean reward: 120.41
               Mean episode length: 977.17
       Episode_Reward/keep_balance: 0.9767
     Episode_Reward/rew_lin_vel_xy: 5.8402
      Episode_Reward/rew_ang_vel_z: 2.3575
    Episode_Reward/pen_base_height: -0.2970
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1964
   Episode_Reward/pen_joint_torque: -0.2272
    Episode_Reward/pen_joint_accel: -0.1165
    Episode_Reward/pen_action_rate: -0.1270
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0612
   Episode_Reward/pen_joint_powers: -0.0932
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2756
Episode_Reward/pen_flat_orientation: -0.1193
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4884
   Episode_Reward/foot_landing_vel: -0.1467
   Episode_Reward/test_gait_reward: -0.9536
Metrics/base_velocity/error_vel_xy: 1.0997
Metrics/base_velocity/error_vel_yaw: 1.4035
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 1.12s
                        Total time: 1338.48s
                               ETA: 1929.9s

################################################################################
                     [1m Learning iteration 1229/3000 [0m                     

                       Computation: 88752 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 0.6999
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9112
                     Learning rate: 0.0006
                       Mean reward: 117.06
               Mean episode length: 947.63
       Episode_Reward/keep_balance: 0.9366
     Episode_Reward/rew_lin_vel_xy: 5.6352
      Episode_Reward/rew_ang_vel_z: 2.3039
    Episode_Reward/pen_base_height: -0.2943
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.1855
   Episode_Reward/pen_joint_torque: -0.2286
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2578
Episode_Reward/pen_flat_orientation: -0.1200
  Episode_Reward/pen_feet_distance: -0.0151
Episode_Reward/pen_feet_regulation: -0.4553
   Episode_Reward/foot_landing_vel: -0.1420
   Episode_Reward/test_gait_reward: -0.9167
Metrics/base_velocity/error_vel_xy: 1.0339
Metrics/base_velocity/error_vel_yaw: 1.3042
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 1.11s
                        Total time: 1339.59s
                               ETA: 1928.8s

################################################################################
                     [1m Learning iteration 1230/3000 [0m                     

                       Computation: 88804 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 0.7147
                    Surrogate loss: -0.0024
             Mean action noise std: 0.9116
                     Learning rate: 0.0006
                       Mean reward: 120.99
               Mean episode length: 973.14
       Episode_Reward/keep_balance: 0.9767
     Episode_Reward/rew_lin_vel_xy: 5.8248
      Episode_Reward/rew_ang_vel_z: 2.3486
    Episode_Reward/pen_base_height: -0.2980
      Episode_Reward/pen_lin_vel_z: -0.0420
     Episode_Reward/pen_ang_vel_xy: -0.1911
   Episode_Reward/pen_joint_torque: -0.2300
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.1266
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0607
   Episode_Reward/pen_joint_powers: -0.0935
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2714
Episode_Reward/pen_flat_orientation: -0.1243
  Episode_Reward/pen_feet_distance: -0.0193
Episode_Reward/pen_feet_regulation: -0.4674
   Episode_Reward/foot_landing_vel: -0.1439
   Episode_Reward/test_gait_reward: -0.9542
Metrics/base_velocity/error_vel_xy: 1.0902
Metrics/base_velocity/error_vel_yaw: 1.4215
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 1.11s
                        Total time: 1340.70s
                               ETA: 1927.7s

################################################################################
                     [1m Learning iteration 1231/3000 [0m                     

                       Computation: 88363 steps/s (collection: 0.989s, learning 0.124s)
               Value function loss: 0.6010
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9105
                     Learning rate: 0.0006
                       Mean reward: 118.05
               Mean episode length: 973.07
       Episode_Reward/keep_balance: 0.9749
     Episode_Reward/rew_lin_vel_xy: 5.8593
      Episode_Reward/rew_ang_vel_z: 2.3203
    Episode_Reward/pen_base_height: -0.3040
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.1952
   Episode_Reward/pen_joint_torque: -0.2289
    Episode_Reward/pen_joint_accel: -0.1140
    Episode_Reward/pen_action_rate: -0.1281
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0619
   Episode_Reward/pen_joint_powers: -0.0951
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2761
Episode_Reward/pen_flat_orientation: -0.1253
  Episode_Reward/pen_feet_distance: -0.0181
Episode_Reward/pen_feet_regulation: -0.4882
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.9644
Metrics/base_velocity/error_vel_xy: 1.0821
Metrics/base_velocity/error_vel_yaw: 1.4463
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 1.11s
                        Total time: 1341.81s
                               ETA: 1926.7s

################################################################################
                     [1m Learning iteration 1232/3000 [0m                     

                       Computation: 89233 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.6498
                    Surrogate loss: -0.0025
             Mean action noise std: 0.9092
                     Learning rate: 0.0004
                       Mean reward: 119.74
               Mean episode length: 980.69
       Episode_Reward/keep_balance: 0.9897
     Episode_Reward/rew_lin_vel_xy: 5.8399
      Episode_Reward/rew_ang_vel_z: 2.3573
    Episode_Reward/pen_base_height: -0.3029
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.1969
   Episode_Reward/pen_joint_torque: -0.2444
    Episode_Reward/pen_joint_accel: -0.1093
    Episode_Reward/pen_action_rate: -0.1305
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0611
   Episode_Reward/pen_joint_powers: -0.0971
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2783
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0185
Episode_Reward/pen_feet_regulation: -0.4794
   Episode_Reward/foot_landing_vel: -0.1372
   Episode_Reward/test_gait_reward: -0.9781
Metrics/base_velocity/error_vel_xy: 1.1504
Metrics/base_velocity/error_vel_yaw: 1.4582
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 1.10s
                        Total time: 1342.91s
                               ETA: 1925.6s

################################################################################
                     [1m Learning iteration 1233/3000 [0m                     

                       Computation: 89410 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.6263
                    Surrogate loss: -0.0051
             Mean action noise std: 0.9107
                     Learning rate: 0.0009
                       Mean reward: 123.86
               Mean episode length: 988.35
       Episode_Reward/keep_balance: 0.9887
     Episode_Reward/rew_lin_vel_xy: 5.9748
      Episode_Reward/rew_ang_vel_z: 2.4141
    Episode_Reward/pen_base_height: -0.3134
      Episode_Reward/pen_lin_vel_z: -0.0426
     Episode_Reward/pen_ang_vel_xy: -0.1942
   Episode_Reward/pen_joint_torque: -0.2367
    Episode_Reward/pen_joint_accel: -0.1078
    Episode_Reward/pen_action_rate: -0.1264
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0932
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2718
Episode_Reward/pen_flat_orientation: -0.1193
  Episode_Reward/pen_feet_distance: -0.0211
Episode_Reward/pen_feet_regulation: -0.4686
   Episode_Reward/foot_landing_vel: -0.1430
   Episode_Reward/test_gait_reward: -0.9618
Metrics/base_velocity/error_vel_xy: 1.0780
Metrics/base_velocity/error_vel_yaw: 1.3848
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 1.10s
                        Total time: 1344.01s
                               ETA: 1924.5s

################################################################################
                     [1m Learning iteration 1234/3000 [0m                     

                       Computation: 89734 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.6373
                    Surrogate loss: -0.0035
             Mean action noise std: 0.9098
                     Learning rate: 0.0006
                       Mean reward: 122.39
               Mean episode length: 989.51
       Episode_Reward/keep_balance: 0.9907
     Episode_Reward/rew_lin_vel_xy: 5.9542
      Episode_Reward/rew_ang_vel_z: 2.3793
    Episode_Reward/pen_base_height: -0.3050
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1970
   Episode_Reward/pen_joint_torque: -0.2356
    Episode_Reward/pen_joint_accel: -0.1217
    Episode_Reward/pen_action_rate: -0.1296
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0620
   Episode_Reward/pen_joint_powers: -0.0961
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2790
Episode_Reward/pen_flat_orientation: -0.1213
  Episode_Reward/pen_feet_distance: -0.0188
Episode_Reward/pen_feet_regulation: -0.4787
   Episode_Reward/foot_landing_vel: -0.1354
   Episode_Reward/test_gait_reward: -0.9749
Metrics/base_velocity/error_vel_xy: 1.1046
Metrics/base_velocity/error_vel_yaw: 1.4342
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 1.10s
                        Total time: 1345.11s
                               ETA: 1923.5s

################################################################################
                     [1m Learning iteration 1235/3000 [0m                     

                       Computation: 89031 steps/s (collection: 0.979s, learning 0.125s)
               Value function loss: 0.6385
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9100
                     Learning rate: 0.0006
                       Mean reward: 123.87
               Mean episode length: 992.26
       Episode_Reward/keep_balance: 0.9893
     Episode_Reward/rew_lin_vel_xy: 5.9287
      Episode_Reward/rew_ang_vel_z: 2.3961
    Episode_Reward/pen_base_height: -0.2920
      Episode_Reward/pen_lin_vel_z: -0.0419
     Episode_Reward/pen_ang_vel_xy: -0.1926
   Episode_Reward/pen_joint_torque: -0.2332
    Episode_Reward/pen_joint_accel: -0.1214
    Episode_Reward/pen_action_rate: -0.1277
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0611
   Episode_Reward/pen_joint_powers: -0.0943
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2733
Episode_Reward/pen_flat_orientation: -0.1182
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4917
   Episode_Reward/foot_landing_vel: -0.1413
   Episode_Reward/test_gait_reward: -0.9769
Metrics/base_velocity/error_vel_xy: 1.0987
Metrics/base_velocity/error_vel_yaw: 1.4095
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 1.10s
                        Total time: 1346.21s
                               ETA: 1922.4s

################################################################################
                     [1m Learning iteration 1236/3000 [0m                     

                       Computation: 90531 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.6154
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9104
                     Learning rate: 0.0004
                       Mean reward: 120.84
               Mean episode length: 978.53
       Episode_Reward/keep_balance: 0.9793
     Episode_Reward/rew_lin_vel_xy: 5.9139
      Episode_Reward/rew_ang_vel_z: 2.3627
    Episode_Reward/pen_base_height: -0.3059
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.1933
   Episode_Reward/pen_joint_torque: -0.2271
    Episode_Reward/pen_joint_accel: -0.1182
    Episode_Reward/pen_action_rate: -0.1267
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0607
   Episode_Reward/pen_joint_powers: -0.0935
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2721
Episode_Reward/pen_flat_orientation: -0.1241
  Episode_Reward/pen_feet_distance: -0.0178
Episode_Reward/pen_feet_regulation: -0.4753
   Episode_Reward/foot_landing_vel: -0.1399
   Episode_Reward/test_gait_reward: -0.9618
Metrics/base_velocity/error_vel_xy: 1.0560
Metrics/base_velocity/error_vel_yaw: 1.4205
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 1.09s
                        Total time: 1347.30s
                               ETA: 1921.3s

################################################################################
                     [1m Learning iteration 1237/3000 [0m                     

                       Computation: 90121 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.6844
                    Surrogate loss: -0.0023
             Mean action noise std: 0.9093
                     Learning rate: 0.0004
                       Mean reward: 119.86
               Mean episode length: 982.44
       Episode_Reward/keep_balance: 0.9820
     Episode_Reward/rew_lin_vel_xy: 5.8615
      Episode_Reward/rew_ang_vel_z: 2.3414
    Episode_Reward/pen_base_height: -0.3029
      Episode_Reward/pen_lin_vel_z: -0.0440
     Episode_Reward/pen_ang_vel_xy: -0.2032
   Episode_Reward/pen_joint_torque: -0.2352
    Episode_Reward/pen_joint_accel: -0.1189
    Episode_Reward/pen_action_rate: -0.1309
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0631
   Episode_Reward/pen_joint_powers: -0.0959
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2787
Episode_Reward/pen_flat_orientation: -0.1231
  Episode_Reward/pen_feet_distance: -0.0191
Episode_Reward/pen_feet_regulation: -0.5005
   Episode_Reward/foot_landing_vel: -0.1495
   Episode_Reward/test_gait_reward: -0.9689
Metrics/base_velocity/error_vel_xy: 1.0954
Metrics/base_velocity/error_vel_yaw: 1.4506
      Episode_Termination/time_out: 4.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 1.09s
                        Total time: 1348.39s
                               ETA: 1920.2s

################################################################################
                     [1m Learning iteration 1238/3000 [0m                     

                       Computation: 88997 steps/s (collection: 0.980s, learning 0.125s)
               Value function loss: 0.6226
                    Surrogate loss: -0.0033
             Mean action noise std: 0.9074
                     Learning rate: 0.0003
                       Mean reward: 121.37
               Mean episode length: 969.66
       Episode_Reward/keep_balance: 0.9765
     Episode_Reward/rew_lin_vel_xy: 5.8195
      Episode_Reward/rew_ang_vel_z: 2.3934
    Episode_Reward/pen_base_height: -0.3037
      Episode_Reward/pen_lin_vel_z: -0.0436
     Episode_Reward/pen_ang_vel_xy: -0.1931
   Episode_Reward/pen_joint_torque: -0.2328
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1256
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2704
Episode_Reward/pen_flat_orientation: -0.1155
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4685
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.9557
Metrics/base_velocity/error_vel_xy: 1.0916
Metrics/base_velocity/error_vel_yaw: 1.3576
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 1.10s
                        Total time: 1349.49s
                               ETA: 1919.1s

################################################################################
                     [1m Learning iteration 1239/3000 [0m                     

                       Computation: 89329 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.6201
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9075
                     Learning rate: 0.0004
                       Mean reward: 122.36
               Mean episode length: 974.58
       Episode_Reward/keep_balance: 0.9797
     Episode_Reward/rew_lin_vel_xy: 5.9032
      Episode_Reward/rew_ang_vel_z: 2.3744
    Episode_Reward/pen_base_height: -0.3003
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1868
   Episode_Reward/pen_joint_torque: -0.2296
    Episode_Reward/pen_joint_accel: -0.1122
    Episode_Reward/pen_action_rate: -0.1255
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0595
   Episode_Reward/pen_joint_powers: -0.0924
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2714
Episode_Reward/pen_flat_orientation: -0.1140
  Episode_Reward/pen_feet_distance: -0.0208
Episode_Reward/pen_feet_regulation: -0.4629
   Episode_Reward/foot_landing_vel: -0.1393
   Episode_Reward/test_gait_reward: -0.9471
Metrics/base_velocity/error_vel_xy: 1.0748
Metrics/base_velocity/error_vel_yaw: 1.3889
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 1.10s
                        Total time: 1350.59s
                               ETA: 1918.1s

################################################################################
                     [1m Learning iteration 1240/3000 [0m                     

                       Computation: 88947 steps/s (collection: 0.980s, learning 0.125s)
               Value function loss: 0.6112
                    Surrogate loss: -0.0052
             Mean action noise std: 0.9057
                     Learning rate: 0.0004
                       Mean reward: 120.99
               Mean episode length: 975.08
       Episode_Reward/keep_balance: 0.9795
     Episode_Reward/rew_lin_vel_xy: 5.9285
      Episode_Reward/rew_ang_vel_z: 2.4041
    Episode_Reward/pen_base_height: -0.3123
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.1908
   Episode_Reward/pen_joint_torque: -0.2357
    Episode_Reward/pen_joint_accel: -0.1161
    Episode_Reward/pen_action_rate: -0.1260
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0945
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2690
Episode_Reward/pen_flat_orientation: -0.1242
  Episode_Reward/pen_feet_distance: -0.0243
Episode_Reward/pen_feet_regulation: -0.4722
   Episode_Reward/foot_landing_vel: -0.1392
   Episode_Reward/test_gait_reward: -0.9562
Metrics/base_velocity/error_vel_xy: 1.0542
Metrics/base_velocity/error_vel_yaw: 1.3826
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 1.11s
                        Total time: 1351.70s
                               ETA: 1917.0s

################################################################################
                     [1m Learning iteration 1241/3000 [0m                     

                       Computation: 90377 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.6373
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9042
                     Learning rate: 0.0006
                       Mean reward: 118.77
               Mean episode length: 962.87
       Episode_Reward/keep_balance: 0.9660
     Episode_Reward/rew_lin_vel_xy: 5.8148
      Episode_Reward/rew_ang_vel_z: 2.3227
    Episode_Reward/pen_base_height: -0.2980
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.1877
   Episode_Reward/pen_joint_torque: -0.2324
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1251
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0605
   Episode_Reward/pen_joint_powers: -0.0936
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2675
Episode_Reward/pen_flat_orientation: -0.1163
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4610
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9460
Metrics/base_velocity/error_vel_xy: 1.0578
Metrics/base_velocity/error_vel_yaw: 1.4014
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 1.09s
                        Total time: 1352.79s
                               ETA: 1915.9s

################################################################################
                     [1m Learning iteration 1242/3000 [0m                     

                       Computation: 91314 steps/s (collection: 0.956s, learning 0.121s)
               Value function loss: 0.7392
                    Surrogate loss: -0.0040
             Mean action noise std: 0.9052
                     Learning rate: 0.0006
                       Mean reward: 119.69
               Mean episode length: 962.69
       Episode_Reward/keep_balance: 0.9517
     Episode_Reward/rew_lin_vel_xy: 5.7371
      Episode_Reward/rew_ang_vel_z: 2.2991
    Episode_Reward/pen_base_height: -0.2864
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.1881
   Episode_Reward/pen_joint_torque: -0.2263
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1231
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2623
Episode_Reward/pen_flat_orientation: -0.1187
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4568
   Episode_Reward/foot_landing_vel: -0.1318
   Episode_Reward/test_gait_reward: -0.9303
Metrics/base_velocity/error_vel_xy: 1.0429
Metrics/base_velocity/error_vel_yaw: 1.3664
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 1.08s
                        Total time: 1353.86s
                               ETA: 1914.8s

################################################################################
                     [1m Learning iteration 1243/3000 [0m                     

                       Computation: 84381 steps/s (collection: 1.033s, learning 0.132s)
               Value function loss: 0.6078
                    Surrogate loss: -0.0021
             Mean action noise std: 0.9053
                     Learning rate: 0.0003
                       Mean reward: 116.18
               Mean episode length: 943.67
       Episode_Reward/keep_balance: 0.9441
     Episode_Reward/rew_lin_vel_xy: 5.6787
      Episode_Reward/rew_ang_vel_z: 2.2746
    Episode_Reward/pen_base_height: -0.2898
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1858
   Episode_Reward/pen_joint_torque: -0.2156
    Episode_Reward/pen_joint_accel: -0.1205
    Episode_Reward/pen_action_rate: -0.1215
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2633
Episode_Reward/pen_flat_orientation: -0.1199
  Episode_Reward/pen_feet_distance: -0.0163
Episode_Reward/pen_feet_regulation: -0.4481
   Episode_Reward/foot_landing_vel: -0.1319
   Episode_Reward/test_gait_reward: -0.9200
Metrics/base_velocity/error_vel_xy: 1.0296
Metrics/base_velocity/error_vel_yaw: 1.3649
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 1.17s
                        Total time: 1355.03s
                               ETA: 1913.8s

################################################################################
                     [1m Learning iteration 1244/3000 [0m                     

                       Computation: 87699 steps/s (collection: 0.996s, learning 0.125s)
               Value function loss: 0.7221
                    Surrogate loss: -0.0048
             Mean action noise std: 0.9050
                     Learning rate: 0.0006
                       Mean reward: 125.94
               Mean episode length: 999.38
       Episode_Reward/keep_balance: 0.9992
     Episode_Reward/rew_lin_vel_xy: 6.0192
      Episode_Reward/rew_ang_vel_z: 2.3883
    Episode_Reward/pen_base_height: -0.2993
      Episode_Reward/pen_lin_vel_z: -0.0423
     Episode_Reward/pen_ang_vel_xy: -0.1978
   Episode_Reward/pen_joint_torque: -0.2280
    Episode_Reward/pen_joint_accel: -0.1257
    Episode_Reward/pen_action_rate: -0.1292
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0619
   Episode_Reward/pen_joint_powers: -0.0939
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2806
Episode_Reward/pen_flat_orientation: -0.1114
  Episode_Reward/pen_feet_distance: -0.0165
Episode_Reward/pen_feet_regulation: -0.4869
   Episode_Reward/foot_landing_vel: -0.1448
   Episode_Reward/test_gait_reward: -0.9832
Metrics/base_velocity/error_vel_xy: 1.1067
Metrics/base_velocity/error_vel_yaw: 1.4645
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 1.12s
                        Total time: 1356.15s
                               ETA: 1912.8s

################################################################################
                     [1m Learning iteration 1245/3000 [0m                     

                       Computation: 91280 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.6004
                    Surrogate loss: -0.0047
             Mean action noise std: 0.9071
                     Learning rate: 0.0006
                       Mean reward: 118.03
               Mean episode length: 966.27
       Episode_Reward/keep_balance: 0.9710
     Episode_Reward/rew_lin_vel_xy: 5.7752
      Episode_Reward/rew_ang_vel_z: 2.3053
    Episode_Reward/pen_base_height: -0.3156
      Episode_Reward/pen_lin_vel_z: -0.0431
     Episode_Reward/pen_ang_vel_xy: -0.1877
   Episode_Reward/pen_joint_torque: -0.2459
    Episode_Reward/pen_joint_accel: -0.1226
    Episode_Reward/pen_action_rate: -0.1282
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0632
   Episode_Reward/pen_joint_powers: -0.0975
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2726
Episode_Reward/pen_flat_orientation: -0.1233
  Episode_Reward/pen_feet_distance: -0.0159
Episode_Reward/pen_feet_regulation: -0.4989
   Episode_Reward/foot_landing_vel: -0.1429
   Episode_Reward/test_gait_reward: -0.9605
Metrics/base_velocity/error_vel_xy: 1.0991
Metrics/base_velocity/error_vel_yaw: 1.4299
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 1.08s
                        Total time: 1357.23s
                               ETA: 1911.7s

################################################################################
                     [1m Learning iteration 1246/3000 [0m                     

                       Computation: 92626 steps/s (collection: 0.939s, learning 0.122s)
               Value function loss: 0.6135
                    Surrogate loss: -0.0029
             Mean action noise std: 0.9091
                     Learning rate: 0.0004
                       Mean reward: 117.73
               Mean episode length: 979.48
       Episode_Reward/keep_balance: 0.9801
     Episode_Reward/rew_lin_vel_xy: 5.8261
      Episode_Reward/rew_ang_vel_z: 2.3555
    Episode_Reward/pen_base_height: -0.3124
      Episode_Reward/pen_lin_vel_z: -0.0430
     Episode_Reward/pen_ang_vel_xy: -0.1998
   Episode_Reward/pen_joint_torque: -0.2322
    Episode_Reward/pen_joint_accel: -0.1277
    Episode_Reward/pen_action_rate: -0.1285
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0642
   Episode_Reward/pen_joint_powers: -0.0969
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2767
Episode_Reward/pen_flat_orientation: -0.1226
  Episode_Reward/pen_feet_distance: -0.0216
Episode_Reward/pen_feet_regulation: -0.5105
   Episode_Reward/foot_landing_vel: -0.1534
   Episode_Reward/test_gait_reward: -0.9590
Metrics/base_velocity/error_vel_xy: 1.1153
Metrics/base_velocity/error_vel_yaw: 1.4243
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 1.06s
                        Total time: 1358.29s
                               ETA: 1910.5s

################################################################################
                     [1m Learning iteration 1247/3000 [0m                     

                       Computation: 90281 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.5616
                    Surrogate loss: -0.0056
             Mean action noise std: 0.9093
                     Learning rate: 0.0006
                       Mean reward: 120.43
               Mean episode length: 973.95
       Episode_Reward/keep_balance: 0.9803
     Episode_Reward/rew_lin_vel_xy: 5.8214
      Episode_Reward/rew_ang_vel_z: 2.3473
    Episode_Reward/pen_base_height: -0.2984
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1904
   Episode_Reward/pen_joint_torque: -0.2308
    Episode_Reward/pen_joint_accel: -0.1137
    Episode_Reward/pen_action_rate: -0.1262
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0597
   Episode_Reward/pen_joint_powers: -0.0923
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2734
Episode_Reward/pen_flat_orientation: -0.1201
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4757
   Episode_Reward/foot_landing_vel: -0.1346
   Episode_Reward/test_gait_reward: -0.9587
Metrics/base_velocity/error_vel_xy: 1.0955
Metrics/base_velocity/error_vel_yaw: 1.4215
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 1.09s
                        Total time: 1359.38s
                               ETA: 1909.4s

################################################################################
                     [1m Learning iteration 1248/3000 [0m                     

                       Computation: 90674 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.6105
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9095
                     Learning rate: 0.0009
                       Mean reward: 121.23
               Mean episode length: 991.11
       Episode_Reward/keep_balance: 0.9919
     Episode_Reward/rew_lin_vel_xy: 5.9050
      Episode_Reward/rew_ang_vel_z: 2.3649
    Episode_Reward/pen_base_height: -0.3042
      Episode_Reward/pen_lin_vel_z: -0.0443
     Episode_Reward/pen_ang_vel_xy: -0.1970
   Episode_Reward/pen_joint_torque: -0.2379
    Episode_Reward/pen_joint_accel: -0.1254
    Episode_Reward/pen_action_rate: -0.1305
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0643
   Episode_Reward/pen_joint_powers: -0.0974
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2799
Episode_Reward/pen_flat_orientation: -0.1218
  Episode_Reward/pen_feet_distance: -0.0202
Episode_Reward/pen_feet_regulation: -0.5172
   Episode_Reward/foot_landing_vel: -0.1559
   Episode_Reward/test_gait_reward: -0.9792
Metrics/base_velocity/error_vel_xy: 1.1092
Metrics/base_velocity/error_vel_yaw: 1.4540
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 1.08s
                        Total time: 1360.46s
                               ETA: 1908.3s

################################################################################
                     [1m Learning iteration 1249/3000 [0m                     

                       Computation: 90723 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.6581
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9099
                     Learning rate: 0.0006
                       Mean reward: 121.78
               Mean episode length: 982.16
       Episode_Reward/keep_balance: 0.9833
     Episode_Reward/rew_lin_vel_xy: 5.8688
      Episode_Reward/rew_ang_vel_z: 2.3656
    Episode_Reward/pen_base_height: -0.3069
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.1931
   Episode_Reward/pen_joint_torque: -0.2269
    Episode_Reward/pen_joint_accel: -0.1143
    Episode_Reward/pen_action_rate: -0.1271
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0602
   Episode_Reward/pen_joint_powers: -0.0924
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2747
Episode_Reward/pen_flat_orientation: -0.1154
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4616
   Episode_Reward/foot_landing_vel: -0.1380
   Episode_Reward/test_gait_reward: -0.9519
Metrics/base_velocity/error_vel_xy: 1.0825
Metrics/base_velocity/error_vel_yaw: 1.4157
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 1.08s
                        Total time: 1361.54s
                               ETA: 1907.3s

################################################################################
                     [1m Learning iteration 1250/3000 [0m                     

                       Computation: 90974 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.6030
                    Surrogate loss: -0.0038
             Mean action noise std: 0.9085
                     Learning rate: 0.0009
                       Mean reward: 125.82
               Mean episode length: 970.62
       Episode_Reward/keep_balance: 0.9668
     Episode_Reward/rew_lin_vel_xy: 5.9189
      Episode_Reward/rew_ang_vel_z: 2.3976
    Episode_Reward/pen_base_height: -0.2927
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1803
   Episode_Reward/pen_joint_torque: -0.2242
    Episode_Reward/pen_joint_accel: -0.1011
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2612
Episode_Reward/pen_flat_orientation: -0.1088
  Episode_Reward/pen_feet_distance: -0.0193
Episode_Reward/pen_feet_regulation: -0.4372
   Episode_Reward/foot_landing_vel: -0.1242
   Episode_Reward/test_gait_reward: -0.9311
Metrics/base_velocity/error_vel_xy: 1.0059
Metrics/base_velocity/error_vel_yaw: 1.3262
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 1.08s
                        Total time: 1362.62s
                               ETA: 1906.2s

################################################################################
                     [1m Learning iteration 1251/3000 [0m                     

                       Computation: 88275 steps/s (collection: 0.984s, learning 0.129s)
               Value function loss: 0.6657
                    Surrogate loss: -0.0031
             Mean action noise std: 0.9083
                     Learning rate: 0.0006
                       Mean reward: 123.02
               Mean episode length: 973.88
       Episode_Reward/keep_balance: 0.9338
     Episode_Reward/rew_lin_vel_xy: 5.5543
      Episode_Reward/rew_ang_vel_z: 2.2299
    Episode_Reward/pen_base_height: -0.2930
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1851
   Episode_Reward/pen_joint_torque: -0.2194
    Episode_Reward/pen_joint_accel: -0.1141
    Episode_Reward/pen_action_rate: -0.1225
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2631
Episode_Reward/pen_flat_orientation: -0.1194
  Episode_Reward/pen_feet_distance: -0.0170
Episode_Reward/pen_feet_regulation: -0.4534
   Episode_Reward/foot_landing_vel: -0.1346
   Episode_Reward/test_gait_reward: -0.9087
Metrics/base_velocity/error_vel_xy: 1.0471
Metrics/base_velocity/error_vel_yaw: 1.3810
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 1.11s
                        Total time: 1363.74s
                               ETA: 1905.1s

################################################################################
                     [1m Learning iteration 1252/3000 [0m                     

                       Computation: 88378 steps/s (collection: 0.986s, learning 0.127s)
               Value function loss: 0.6106
                    Surrogate loss: -0.0042
             Mean action noise std: 0.9070
                     Learning rate: 0.0006
                       Mean reward: 117.35
               Mean episode length: 948.50
       Episode_Reward/keep_balance: 0.9486
     Episode_Reward/rew_lin_vel_xy: 5.7611
      Episode_Reward/rew_ang_vel_z: 2.3079
    Episode_Reward/pen_base_height: -0.2896
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1898
   Episode_Reward/pen_joint_torque: -0.2284
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2671
Episode_Reward/pen_flat_orientation: -0.1127
  Episode_Reward/pen_feet_distance: -0.0184
Episode_Reward/pen_feet_regulation: -0.4587
   Episode_Reward/foot_landing_vel: -0.1361
   Episode_Reward/test_gait_reward: -0.9214
Metrics/base_velocity/error_vel_xy: 1.0191
Metrics/base_velocity/error_vel_yaw: 1.3507
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 1.11s
                        Total time: 1364.85s
                               ETA: 1904.0s

################################################################################
                     [1m Learning iteration 1253/3000 [0m                     

                       Computation: 91078 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.6331
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9054
                     Learning rate: 0.0003
                       Mean reward: 123.12
               Mean episode length: 982.81
       Episode_Reward/keep_balance: 0.9900
     Episode_Reward/rew_lin_vel_xy: 5.8788
      Episode_Reward/rew_ang_vel_z: 2.3784
    Episode_Reward/pen_base_height: -0.3038
      Episode_Reward/pen_lin_vel_z: -0.0399
     Episode_Reward/pen_ang_vel_xy: -0.1958
   Episode_Reward/pen_joint_torque: -0.2314
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.1272
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2756
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0208
Episode_Reward/pen_feet_regulation: -0.4531
   Episode_Reward/foot_landing_vel: -0.1286
   Episode_Reward/test_gait_reward: -0.9653
Metrics/base_velocity/error_vel_xy: 1.1169
Metrics/base_velocity/error_vel_yaw: 1.4305
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 1.08s
                        Total time: 1365.93s
                               ETA: 1902.9s

################################################################################
                     [1m Learning iteration 1254/3000 [0m                     

                       Computation: 89996 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 0.7004
                    Surrogate loss: -0.0043
             Mean action noise std: 0.9054
                     Learning rate: 0.0004
                       Mean reward: 119.53
               Mean episode length: 974.49
       Episode_Reward/keep_balance: 0.9659
     Episode_Reward/rew_lin_vel_xy: 5.7594
      Episode_Reward/rew_ang_vel_z: 2.2989
    Episode_Reward/pen_base_height: -0.3067
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1957
   Episode_Reward/pen_joint_torque: -0.2251
    Episode_Reward/pen_joint_accel: -0.1136
    Episode_Reward/pen_action_rate: -0.1254
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0606
   Episode_Reward/pen_joint_powers: -0.0929
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2724
Episode_Reward/pen_flat_orientation: -0.1157
  Episode_Reward/pen_feet_distance: -0.0188
Episode_Reward/pen_feet_regulation: -0.4639
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.9377
Metrics/base_velocity/error_vel_xy: 1.0911
Metrics/base_velocity/error_vel_yaw: 1.4237
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 1.09s
                        Total time: 1367.02s
                               ETA: 1901.8s

################################################################################
                     [1m Learning iteration 1255/3000 [0m                     

                       Computation: 88473 steps/s (collection: 0.977s, learning 0.134s)
               Value function loss: 0.6088
                    Surrogate loss: -0.0050
             Mean action noise std: 0.9047
                     Learning rate: 0.0006
                       Mean reward: 118.93
               Mean episode length: 972.58
       Episode_Reward/keep_balance: 0.9804
     Episode_Reward/rew_lin_vel_xy: 5.8210
      Episode_Reward/rew_ang_vel_z: 2.3648
    Episode_Reward/pen_base_height: -0.3120
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1883
   Episode_Reward/pen_joint_torque: -0.2316
    Episode_Reward/pen_joint_accel: -0.1128
    Episode_Reward/pen_action_rate: -0.1256
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0598
   Episode_Reward/pen_joint_powers: -0.0924
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2715
Episode_Reward/pen_flat_orientation: -0.1192
  Episode_Reward/pen_feet_distance: -0.0224
Episode_Reward/pen_feet_regulation: -0.4840
   Episode_Reward/foot_landing_vel: -0.1373
   Episode_Reward/test_gait_reward: -0.9589
Metrics/base_velocity/error_vel_xy: 1.1173
Metrics/base_velocity/error_vel_yaw: 1.4070
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 1.11s
                        Total time: 1368.13s
                               ETA: 1900.8s

################################################################################
                     [1m Learning iteration 1256/3000 [0m                     

                       Computation: 89803 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.6337
                    Surrogate loss: -0.0020
             Mean action noise std: 0.9047
                     Learning rate: 0.0003
                       Mean reward: 120.13
               Mean episode length: 966.40
       Episode_Reward/keep_balance: 0.9723
     Episode_Reward/rew_lin_vel_xy: 5.8625
      Episode_Reward/rew_ang_vel_z: 2.3701
    Episode_Reward/pen_base_height: -0.3069
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.1873
   Episode_Reward/pen_joint_torque: -0.2330
    Episode_Reward/pen_joint_accel: -0.1130
    Episode_Reward/pen_action_rate: -0.1235
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0586
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2674
Episode_Reward/pen_flat_orientation: -0.1143
  Episode_Reward/pen_feet_distance: -0.0206
Episode_Reward/pen_feet_regulation: -0.4587
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.9434
Metrics/base_velocity/error_vel_xy: 1.0511
Metrics/base_velocity/error_vel_yaw: 1.3695
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 1.09s
                        Total time: 1369.23s
                               ETA: 1899.7s

################################################################################
                     [1m Learning iteration 1257/3000 [0m                     

                       Computation: 89279 steps/s (collection: 0.975s, learning 0.126s)
               Value function loss: 0.6819
                    Surrogate loss: -0.0044
             Mean action noise std: 0.9045
                     Learning rate: 0.0004
                       Mean reward: 117.61
               Mean episode length: 946.65
       Episode_Reward/keep_balance: 0.9484
     Episode_Reward/rew_lin_vel_xy: 5.6692
      Episode_Reward/rew_ang_vel_z: 2.3149
    Episode_Reward/pen_base_height: -0.3099
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1803
   Episode_Reward/pen_joint_torque: -0.2308
    Episode_Reward/pen_joint_accel: -0.1112
    Episode_Reward/pen_action_rate: -0.1209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2604
Episode_Reward/pen_flat_orientation: -0.1090
  Episode_Reward/pen_feet_distance: -0.0170
Episode_Reward/pen_feet_regulation: -0.4505
   Episode_Reward/foot_landing_vel: -0.1340
   Episode_Reward/test_gait_reward: -0.9271
Metrics/base_velocity/error_vel_xy: 1.0557
Metrics/base_velocity/error_vel_yaw: 1.3335
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 1.10s
                        Total time: 1370.33s
                               ETA: 1898.6s

################################################################################
                     [1m Learning iteration 1258/3000 [0m                     

                       Computation: 87375 steps/s (collection: 1.001s, learning 0.124s)
               Value function loss: 0.5536
                    Surrogate loss: -0.0041
             Mean action noise std: 0.9029
                     Learning rate: 0.0006
                       Mean reward: 122.30
               Mean episode length: 984.45
       Episode_Reward/keep_balance: 0.9799
     Episode_Reward/rew_lin_vel_xy: 5.8925
      Episode_Reward/rew_ang_vel_z: 2.3811
    Episode_Reward/pen_base_height: -0.3086
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.1946
   Episode_Reward/pen_joint_torque: -0.2343
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1259
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0597
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2736
Episode_Reward/pen_flat_orientation: -0.1102
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4685
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9501
Metrics/base_velocity/error_vel_xy: 1.0758
Metrics/base_velocity/error_vel_yaw: 1.3896
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 1.13s
                        Total time: 1371.45s
                               ETA: 1897.6s

################################################################################
                     [1m Learning iteration 1259/3000 [0m                     

                       Computation: 90207 steps/s (collection: 0.969s, learning 0.121s)
               Value function loss: 0.6221
                    Surrogate loss: -0.0037
             Mean action noise std: 0.9011
                     Learning rate: 0.0006
                       Mean reward: 124.46
               Mean episode length: 998.93
       Episode_Reward/keep_balance: 0.9989
     Episode_Reward/rew_lin_vel_xy: 5.9827
      Episode_Reward/rew_ang_vel_z: 2.4092
    Episode_Reward/pen_base_height: -0.3065
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.1935
   Episode_Reward/pen_joint_torque: -0.2335
    Episode_Reward/pen_joint_accel: -0.1227
    Episode_Reward/pen_action_rate: -0.1276
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0931
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2777
Episode_Reward/pen_flat_orientation: -0.1101
  Episode_Reward/pen_feet_distance: -0.0203
Episode_Reward/pen_feet_regulation: -0.4709
   Episode_Reward/foot_landing_vel: -0.1471
   Episode_Reward/test_gait_reward: -0.9671
Metrics/base_velocity/error_vel_xy: 1.0917
Metrics/base_velocity/error_vel_yaw: 1.4186
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 1.09s
                        Total time: 1372.54s
                               ETA: 1896.5s

################################################################################
                     [1m Learning iteration 1260/3000 [0m                     

                       Computation: 90872 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.6342
                    Surrogate loss: -0.0044
             Mean action noise std: 0.9000
                     Learning rate: 0.0006
                       Mean reward: 120.87
               Mean episode length: 982.28
       Episode_Reward/keep_balance: 0.9881
     Episode_Reward/rew_lin_vel_xy: 5.8927
      Episode_Reward/rew_ang_vel_z: 2.3858
    Episode_Reward/pen_base_height: -0.3146
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.1854
   Episode_Reward/pen_joint_torque: -0.2413
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1267
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0607
   Episode_Reward/pen_joint_powers: -0.0956
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2708
Episode_Reward/pen_flat_orientation: -0.1131
  Episode_Reward/pen_feet_distance: -0.0200
Episode_Reward/pen_feet_regulation: -0.4851
   Episode_Reward/foot_landing_vel: -0.1406
   Episode_Reward/test_gait_reward: -0.9653
Metrics/base_velocity/error_vel_xy: 1.1220
Metrics/base_velocity/error_vel_yaw: 1.4197
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 1.08s
                        Total time: 1373.63s
                               ETA: 1895.4s

################################################################################
                     [1m Learning iteration 1261/3000 [0m                     

                       Computation: 89750 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.6221
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8993
                     Learning rate: 0.0004
                       Mean reward: 123.59
               Mean episode length: 973.78
       Episode_Reward/keep_balance: 0.9756
     Episode_Reward/rew_lin_vel_xy: 5.8458
      Episode_Reward/rew_ang_vel_z: 2.3728
    Episode_Reward/pen_base_height: -0.3046
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1896
   Episode_Reward/pen_joint_torque: -0.2194
    Episode_Reward/pen_joint_accel: -0.1052
    Episode_Reward/pen_action_rate: -0.1237
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0897
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2684
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0211
Episode_Reward/pen_feet_regulation: -0.4684
   Episode_Reward/foot_landing_vel: -0.1367
   Episode_Reward/test_gait_reward: -0.9506
Metrics/base_velocity/error_vel_xy: 1.0729
Metrics/base_velocity/error_vel_yaw: 1.3830
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 1.10s
                        Total time: 1374.72s
                               ETA: 1894.3s

################################################################################
                     [1m Learning iteration 1262/3000 [0m                     

                       Computation: 91806 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.5721
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8984
                     Learning rate: 0.0004
                       Mean reward: 123.20
               Mean episode length: 979.36
       Episode_Reward/keep_balance: 0.9832
     Episode_Reward/rew_lin_vel_xy: 5.9864
      Episode_Reward/rew_ang_vel_z: 2.4318
    Episode_Reward/pen_base_height: -0.3091
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1802
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1059
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2650
Episode_Reward/pen_flat_orientation: -0.1103
  Episode_Reward/pen_feet_distance: -0.0205
Episode_Reward/pen_feet_regulation: -0.4408
   Episode_Reward/foot_landing_vel: -0.1246
   Episode_Reward/test_gait_reward: -0.9591
Metrics/base_velocity/error_vel_xy: 1.0416
Metrics/base_velocity/error_vel_yaw: 1.3468
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 1.07s
                        Total time: 1375.79s
                               ETA: 1893.2s

################################################################################
                     [1m Learning iteration 1263/3000 [0m                     

                       Computation: 89451 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.6375
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8976
                     Learning rate: 0.0006
                       Mean reward: 128.66
               Mean episode length: 991.82
       Episode_Reward/keep_balance: 0.9932
     Episode_Reward/rew_lin_vel_xy: 6.0807
      Episode_Reward/rew_ang_vel_z: 2.4530
    Episode_Reward/pen_base_height: -0.2973
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1831
   Episode_Reward/pen_joint_torque: -0.2312
    Episode_Reward/pen_joint_accel: -0.1089
    Episode_Reward/pen_action_rate: -0.1244
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2715
Episode_Reward/pen_flat_orientation: -0.1046
  Episode_Reward/pen_feet_distance: -0.0187
Episode_Reward/pen_feet_regulation: -0.4508
   Episode_Reward/foot_landing_vel: -0.1296
   Episode_Reward/test_gait_reward: -0.9683
Metrics/base_velocity/error_vel_xy: 1.0335
Metrics/base_velocity/error_vel_yaw: 1.3707
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 1.10s
                        Total time: 1376.89s
                               ETA: 1892.1s

################################################################################
                     [1m Learning iteration 1264/3000 [0m                     

                       Computation: 90940 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.6405
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8973
                     Learning rate: 0.0004
                       Mean reward: 119.06
               Mean episode length: 967.70
       Episode_Reward/keep_balance: 0.9690
     Episode_Reward/rew_lin_vel_xy: 5.8119
      Episode_Reward/rew_ang_vel_z: 2.3337
    Episode_Reward/pen_base_height: -0.2990
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.1886
   Episode_Reward/pen_joint_torque: -0.2326
    Episode_Reward/pen_joint_accel: -0.1100
    Episode_Reward/pen_action_rate: -0.1234
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0597
   Episode_Reward/pen_joint_powers: -0.0920
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2678
Episode_Reward/pen_flat_orientation: -0.1083
  Episode_Reward/pen_feet_distance: -0.0206
Episode_Reward/pen_feet_regulation: -0.4743
   Episode_Reward/foot_landing_vel: -0.1329
   Episode_Reward/test_gait_reward: -0.9469
Metrics/base_velocity/error_vel_xy: 1.0796
Metrics/base_velocity/error_vel_yaw: 1.3886
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 1.08s
                        Total time: 1377.97s
                               ETA: 1891.0s

################################################################################
                     [1m Learning iteration 1265/3000 [0m                     

                       Computation: 91193 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.6251
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8965
                     Learning rate: 0.0006
                       Mean reward: 122.56
               Mean episode length: 973.46
       Episode_Reward/keep_balance: 0.9818
     Episode_Reward/rew_lin_vel_xy: 5.9528
      Episode_Reward/rew_ang_vel_z: 2.3745
    Episode_Reward/pen_base_height: -0.2962
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1840
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1130
    Episode_Reward/pen_action_rate: -0.1237
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0586
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2688
Episode_Reward/pen_flat_orientation: -0.1103
  Episode_Reward/pen_feet_distance: -0.0218
Episode_Reward/pen_feet_regulation: -0.4598
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.9513
Metrics/base_velocity/error_vel_xy: 1.0383
Metrics/base_velocity/error_vel_yaw: 1.4009
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 1.08s
                        Total time: 1379.05s
                               ETA: 1889.9s

################################################################################
                     [1m Learning iteration 1266/3000 [0m                     

                       Computation: 90646 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.6200
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8962
                     Learning rate: 0.0004
                       Mean reward: 125.94
               Mean episode length: 988.26
       Episode_Reward/keep_balance: 0.9892
     Episode_Reward/rew_lin_vel_xy: 5.9433
      Episode_Reward/rew_ang_vel_z: 2.4272
    Episode_Reward/pen_base_height: -0.2967
      Episode_Reward/pen_lin_vel_z: -0.0414
     Episode_Reward/pen_ang_vel_xy: -0.1935
   Episode_Reward/pen_joint_torque: -0.2180
    Episode_Reward/pen_joint_accel: -0.1118
    Episode_Reward/pen_action_rate: -0.1241
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2745
Episode_Reward/pen_flat_orientation: -0.1085
  Episode_Reward/pen_feet_distance: -0.0176
Episode_Reward/pen_feet_regulation: -0.4629
   Episode_Reward/foot_landing_vel: -0.1325
   Episode_Reward/test_gait_reward: -0.9581
Metrics/base_velocity/error_vel_xy: 1.0737
Metrics/base_velocity/error_vel_yaw: 1.3789
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 1.08s
                        Total time: 1380.13s
                               ETA: 1888.8s

################################################################################
                     [1m Learning iteration 1267/3000 [0m                     

                       Computation: 88530 steps/s (collection: 0.986s, learning 0.124s)
               Value function loss: 0.6969
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8958
                     Learning rate: 0.0006
                       Mean reward: 119.45
               Mean episode length: 976.49
       Episode_Reward/keep_balance: 0.9699
     Episode_Reward/rew_lin_vel_xy: 5.7682
      Episode_Reward/rew_ang_vel_z: 2.3175
    Episode_Reward/pen_base_height: -0.3058
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1928
   Episode_Reward/pen_joint_torque: -0.2276
    Episode_Reward/pen_joint_accel: -0.1192
    Episode_Reward/pen_action_rate: -0.1258
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0616
   Episode_Reward/pen_joint_powers: -0.0930
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2733
Episode_Reward/pen_flat_orientation: -0.1197
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4870
   Episode_Reward/foot_landing_vel: -0.1367
   Episode_Reward/test_gait_reward: -0.9456
Metrics/base_velocity/error_vel_xy: 1.1056
Metrics/base_velocity/error_vel_yaw: 1.4232
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 1.11s
                        Total time: 1381.24s
                               ETA: 1887.8s

################################################################################
                     [1m Learning iteration 1268/3000 [0m                     

                       Computation: 88213 steps/s (collection: 0.992s, learning 0.123s)
               Value function loss: 0.6207
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8953
                     Learning rate: 0.0006
                       Mean reward: 120.06
               Mean episode length: 959.78
       Episode_Reward/keep_balance: 0.9415
     Episode_Reward/rew_lin_vel_xy: 5.7229
      Episode_Reward/rew_ang_vel_z: 2.2874
    Episode_Reward/pen_base_height: -0.3019
      Episode_Reward/pen_lin_vel_z: -0.0406
     Episode_Reward/pen_ang_vel_xy: -0.1847
   Episode_Reward/pen_joint_torque: -0.2225
    Episode_Reward/pen_joint_accel: -0.1043
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0892
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2651
Episode_Reward/pen_flat_orientation: -0.1138
  Episode_Reward/pen_feet_distance: -0.0168
Episode_Reward/pen_feet_regulation: -0.4719
   Episode_Reward/foot_landing_vel: -0.1390
   Episode_Reward/test_gait_reward: -0.9178
Metrics/base_velocity/error_vel_xy: 1.0295
Metrics/base_velocity/error_vel_yaw: 1.3352
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 1.11s
                        Total time: 1382.36s
                               ETA: 1886.7s

################################################################################
                     [1m Learning iteration 1269/3000 [0m                     

                       Computation: 90532 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.6355
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8945
                     Learning rate: 0.0006
                       Mean reward: 124.27
               Mean episode length: 992.16
       Episode_Reward/keep_balance: 0.9942
     Episode_Reward/rew_lin_vel_xy: 6.0232
      Episode_Reward/rew_ang_vel_z: 2.4180
    Episode_Reward/pen_base_height: -0.3165
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1929
   Episode_Reward/pen_joint_torque: -0.2361
    Episode_Reward/pen_joint_accel: -0.1152
    Episode_Reward/pen_action_rate: -0.1263
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0609
   Episode_Reward/pen_joint_powers: -0.0936
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2752
Episode_Reward/pen_flat_orientation: -0.1101
  Episode_Reward/pen_feet_distance: -0.0235
Episode_Reward/pen_feet_regulation: -0.4877
   Episode_Reward/foot_landing_vel: -0.1441
   Episode_Reward/test_gait_reward: -0.9729
Metrics/base_velocity/error_vel_xy: 1.0693
Metrics/base_velocity/error_vel_yaw: 1.3992
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 1.09s
                        Total time: 1383.45s
                               ETA: 1885.6s

################################################################################
                     [1m Learning iteration 1270/3000 [0m                     

                       Computation: 89124 steps/s (collection: 0.981s, learning 0.122s)
               Value function loss: 0.6677
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8951
                     Learning rate: 0.0009
                       Mean reward: 122.87
               Mean episode length: 979.08
       Episode_Reward/keep_balance: 0.9835
     Episode_Reward/rew_lin_vel_xy: 5.9481
      Episode_Reward/rew_ang_vel_z: 2.4231
    Episode_Reward/pen_base_height: -0.3035
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1891
   Episode_Reward/pen_joint_torque: -0.2298
    Episode_Reward/pen_joint_accel: -0.1173
    Episode_Reward/pen_action_rate: -0.1229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2687
Episode_Reward/pen_flat_orientation: -0.1086
  Episode_Reward/pen_feet_distance: -0.0232
Episode_Reward/pen_feet_regulation: -0.4673
   Episode_Reward/foot_landing_vel: -0.1401
   Episode_Reward/test_gait_reward: -0.9501
Metrics/base_velocity/error_vel_xy: 1.0478
Metrics/base_velocity/error_vel_yaw: 1.3602
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 1.10s
                        Total time: 1384.55s
                               ETA: 1884.6s

################################################################################
                     [1m Learning iteration 1271/3000 [0m                     

                       Computation: 91465 steps/s (collection: 0.950s, learning 0.125s)
               Value function loss: 0.6789
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8952
                     Learning rate: 0.0004
                       Mean reward: 126.65
               Mean episode length: 981.71
       Episode_Reward/keep_balance: 0.9833
     Episode_Reward/rew_lin_vel_xy: 5.9649
      Episode_Reward/rew_ang_vel_z: 2.4416
    Episode_Reward/pen_base_height: -0.2972
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.1801
   Episode_Reward/pen_joint_torque: -0.2331
    Episode_Reward/pen_joint_accel: -0.1237
    Episode_Reward/pen_action_rate: -0.1236
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2693
Episode_Reward/pen_flat_orientation: -0.1072
  Episode_Reward/pen_feet_distance: -0.0201
Episode_Reward/pen_feet_regulation: -0.4693
   Episode_Reward/foot_landing_vel: -0.1427
   Episode_Reward/test_gait_reward: -0.9556
Metrics/base_velocity/error_vel_xy: 1.0466
Metrics/base_velocity/error_vel_yaw: 1.3344
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 1.07s
                        Total time: 1385.62s
                               ETA: 1883.4s

################################################################################
                     [1m Learning iteration 1272/3000 [0m                     

                       Computation: 90719 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.5644
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8950
                     Learning rate: 0.0004
                       Mean reward: 124.07
               Mean episode length: 977.21
       Episode_Reward/keep_balance: 0.9751
     Episode_Reward/rew_lin_vel_xy: 5.8929
      Episode_Reward/rew_ang_vel_z: 2.3921
    Episode_Reward/pen_base_height: -0.3083
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1773
   Episode_Reward/pen_joint_torque: -0.2249
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2639
Episode_Reward/pen_flat_orientation: -0.1058
  Episode_Reward/pen_feet_distance: -0.0230
Episode_Reward/pen_feet_regulation: -0.4576
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.9453
Metrics/base_velocity/error_vel_xy: 1.0544
Metrics/base_velocity/error_vel_yaw: 1.3556
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 1.08s
                        Total time: 1386.71s
                               ETA: 1882.3s

################################################################################
                     [1m Learning iteration 1273/3000 [0m                     

                       Computation: 89950 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.6086
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8949
                     Learning rate: 0.0003
                       Mean reward: 120.92
               Mean episode length: 966.70
       Episode_Reward/keep_balance: 0.9764
     Episode_Reward/rew_lin_vel_xy: 5.9024
      Episode_Reward/rew_ang_vel_z: 2.3666
    Episode_Reward/pen_base_height: -0.3232
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1881
   Episode_Reward/pen_joint_torque: -0.2300
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1244
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0917
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2717
Episode_Reward/pen_flat_orientation: -0.1095
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4780
   Episode_Reward/foot_landing_vel: -0.1342
   Episode_Reward/test_gait_reward: -0.9629
Metrics/base_velocity/error_vel_xy: 1.0592
Metrics/base_velocity/error_vel_yaw: 1.3882
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 1.09s
                        Total time: 1387.80s
                               ETA: 1881.3s

################################################################################
                     [1m Learning iteration 1274/3000 [0m                     

                       Computation: 91322 steps/s (collection: 0.952s, learning 0.125s)
               Value function loss: 0.6116
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8957
                     Learning rate: 0.0006
                       Mean reward: 117.33
               Mean episode length: 962.15
       Episode_Reward/keep_balance: 0.9567
     Episode_Reward/rew_lin_vel_xy: 5.7201
      Episode_Reward/rew_ang_vel_z: 2.3008
    Episode_Reward/pen_base_height: -0.3317
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1832
   Episode_Reward/pen_joint_torque: -0.2388
    Episode_Reward/pen_joint_accel: -0.1068
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0924
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2611
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0218
Episode_Reward/pen_feet_regulation: -0.4728
   Episode_Reward/foot_landing_vel: -0.1301
   Episode_Reward/test_gait_reward: -0.9488
Metrics/base_velocity/error_vel_xy: 1.0857
Metrics/base_velocity/error_vel_yaw: 1.3676
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 1.08s
                        Total time: 1388.88s
                               ETA: 1880.2s

################################################################################
                     [1m Learning iteration 1275/3000 [0m                     

                       Computation: 88303 steps/s (collection: 0.975s, learning 0.138s)
               Value function loss: 0.6185
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8976
                     Learning rate: 0.0006
                       Mean reward: 124.78
               Mean episode length: 982.26
       Episode_Reward/keep_balance: 0.9846
     Episode_Reward/rew_lin_vel_xy: 5.9551
      Episode_Reward/rew_ang_vel_z: 2.3940
    Episode_Reward/pen_base_height: -0.3232
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1932
   Episode_Reward/pen_joint_torque: -0.2370
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1255
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0591
   Episode_Reward/pen_joint_powers: -0.0924
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2723
Episode_Reward/pen_flat_orientation: -0.1112
  Episode_Reward/pen_feet_distance: -0.0215
Episode_Reward/pen_feet_regulation: -0.4828
   Episode_Reward/foot_landing_vel: -0.1324
   Episode_Reward/test_gait_reward: -0.9578
Metrics/base_velocity/error_vel_xy: 1.0929
Metrics/base_velocity/error_vel_yaw: 1.3933
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 1.11s
                        Total time: 1389.99s
                               ETA: 1879.1s

################################################################################
                     [1m Learning iteration 1276/3000 [0m                     

                       Computation: 89713 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.6580
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8978
                     Learning rate: 0.0003
                       Mean reward: 122.44
               Mean episode length: 990.53
       Episode_Reward/keep_balance: 0.9894
     Episode_Reward/rew_lin_vel_xy: 5.9182
      Episode_Reward/rew_ang_vel_z: 2.3918
    Episode_Reward/pen_base_height: -0.3234
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1864
   Episode_Reward/pen_joint_torque: -0.2410
    Episode_Reward/pen_joint_accel: -0.1208
    Episode_Reward/pen_action_rate: -0.1272
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0949
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2741
Episode_Reward/pen_flat_orientation: -0.1091
  Episode_Reward/pen_feet_distance: -0.0232
Episode_Reward/pen_feet_regulation: -0.4816
   Episode_Reward/foot_landing_vel: -0.1319
   Episode_Reward/test_gait_reward: -0.9797
Metrics/base_velocity/error_vel_xy: 1.1033
Metrics/base_velocity/error_vel_yaw: 1.4174
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 1.10s
                        Total time: 1391.08s
                               ETA: 1878.0s

################################################################################
                     [1m Learning iteration 1277/3000 [0m                     

                       Computation: 90856 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.6361
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8992
                     Learning rate: 0.0006
                       Mean reward: 120.97
               Mean episode length: 974.12
       Episode_Reward/keep_balance: 0.9790
     Episode_Reward/rew_lin_vel_xy: 5.8607
      Episode_Reward/rew_ang_vel_z: 2.3835
    Episode_Reward/pen_base_height: -0.3264
      Episode_Reward/pen_lin_vel_z: -0.0415
     Episode_Reward/pen_ang_vel_xy: -0.1915
   Episode_Reward/pen_joint_torque: -0.2239
    Episode_Reward/pen_joint_accel: -0.1158
    Episode_Reward/pen_action_rate: -0.1243
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2722
Episode_Reward/pen_flat_orientation: -0.1067
  Episode_Reward/pen_feet_distance: -0.0214
Episode_Reward/pen_feet_regulation: -0.4916
   Episode_Reward/foot_landing_vel: -0.1435
   Episode_Reward/test_gait_reward: -0.9611
Metrics/base_velocity/error_vel_xy: 1.0878
Metrics/base_velocity/error_vel_yaw: 1.3770
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 1.08s
                        Total time: 1392.17s
                               ETA: 1876.9s

################################################################################
                     [1m Learning iteration 1278/3000 [0m                     

                       Computation: 91181 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.6823
                    Surrogate loss: -0.0022
             Mean action noise std: 0.9000
                     Learning rate: 0.0004
                       Mean reward: 121.40
               Mean episode length: 968.33
       Episode_Reward/keep_balance: 0.9732
     Episode_Reward/rew_lin_vel_xy: 5.9113
      Episode_Reward/rew_ang_vel_z: 2.3970
    Episode_Reward/pen_base_height: -0.3267
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1861
   Episode_Reward/pen_joint_torque: -0.2320
    Episode_Reward/pen_joint_accel: -0.1084
    Episode_Reward/pen_action_rate: -0.1233
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2654
Episode_Reward/pen_flat_orientation: -0.1096
  Episode_Reward/pen_feet_distance: -0.0235
Episode_Reward/pen_feet_regulation: -0.4691
   Episode_Reward/foot_landing_vel: -0.1257
   Episode_Reward/test_gait_reward: -0.9489
Metrics/base_velocity/error_vel_xy: 1.0461
Metrics/base_velocity/error_vel_yaw: 1.3542
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 1.08s
                        Total time: 1393.24s
                               ETA: 1875.8s

################################################################################
                     [1m Learning iteration 1279/3000 [0m                     

                       Computation: 91589 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.6836
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8979
                     Learning rate: 0.0009
                       Mean reward: 124.42
               Mean episode length: 974.30
       Episode_Reward/keep_balance: 0.9633
     Episode_Reward/rew_lin_vel_xy: 5.8836
      Episode_Reward/rew_ang_vel_z: 2.3860
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1896
   Episode_Reward/pen_joint_torque: -0.2250
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2657
Episode_Reward/pen_flat_orientation: -0.1101
  Episode_Reward/pen_feet_distance: -0.0179
Episode_Reward/pen_feet_regulation: -0.4530
   Episode_Reward/foot_landing_vel: -0.1337
   Episode_Reward/test_gait_reward: -0.9390
Metrics/base_velocity/error_vel_xy: 1.0100
Metrics/base_velocity/error_vel_yaw: 1.3305
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 1.07s
                        Total time: 1394.32s
                               ETA: 1874.7s

################################################################################
                     [1m Learning iteration 1280/3000 [0m                     

                       Computation: 89250 steps/s (collection: 0.977s, learning 0.125s)
               Value function loss: 0.7021
                    Surrogate loss: 0.0002
             Mean action noise std: 0.8984
                     Learning rate: 0.0003
                       Mean reward: 122.40
               Mean episode length: 974.80
       Episode_Reward/keep_balance: 0.9804
     Episode_Reward/rew_lin_vel_xy: 5.9771
      Episode_Reward/rew_ang_vel_z: 2.4260
    Episode_Reward/pen_base_height: -0.3078
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1853
   Episode_Reward/pen_joint_torque: -0.2368
    Episode_Reward/pen_joint_accel: -0.1083
    Episode_Reward/pen_action_rate: -0.1238
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2691
Episode_Reward/pen_flat_orientation: -0.1054
  Episode_Reward/pen_feet_distance: -0.0246
Episode_Reward/pen_feet_regulation: -0.4754
   Episode_Reward/foot_landing_vel: -0.1406
   Episode_Reward/test_gait_reward: -0.9616
Metrics/base_velocity/error_vel_xy: 1.0378
Metrics/base_velocity/error_vel_yaw: 1.3419
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 1.10s
                        Total time: 1395.42s
                               ETA: 1873.6s

################################################################################
                     [1m Learning iteration 1281/3000 [0m                     

                       Computation: 91094 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.6407
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8994
                     Learning rate: 0.0006
                       Mean reward: 122.98
               Mean episode length: 969.77
       Episode_Reward/keep_balance: 0.9602
     Episode_Reward/rew_lin_vel_xy: 5.7714
      Episode_Reward/rew_ang_vel_z: 2.3533
    Episode_Reward/pen_base_height: -0.3177
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1809
   Episode_Reward/pen_joint_torque: -0.2302
    Episode_Reward/pen_joint_accel: -0.1087
    Episode_Reward/pen_action_rate: -0.1211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0911
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2639
Episode_Reward/pen_flat_orientation: -0.1082
  Episode_Reward/pen_feet_distance: -0.0198
Episode_Reward/pen_feet_regulation: -0.4713
   Episode_Reward/foot_landing_vel: -0.1319
   Episode_Reward/test_gait_reward: -0.9348
Metrics/base_velocity/error_vel_xy: 1.0615
Metrics/base_velocity/error_vel_yaw: 1.3492
      Episode_Termination/time_out: 4.9167
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 1.08s
                        Total time: 1396.50s
                               ETA: 1872.5s

################################################################################
                     [1m Learning iteration 1282/3000 [0m                     

                       Computation: 90570 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.7365
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8989
                     Learning rate: 0.0009
                       Mean reward: 124.02
               Mean episode length: 974.36
       Episode_Reward/keep_balance: 0.9653
     Episode_Reward/rew_lin_vel_xy: 5.8670
      Episode_Reward/rew_ang_vel_z: 2.4146
    Episode_Reward/pen_base_height: -0.3171
      Episode_Reward/pen_lin_vel_z: -0.0399
     Episode_Reward/pen_ang_vel_xy: -0.1807
   Episode_Reward/pen_joint_torque: -0.2310
    Episode_Reward/pen_joint_accel: -0.1102
    Episode_Reward/pen_action_rate: -0.1209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0892
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2622
Episode_Reward/pen_flat_orientation: -0.1087
  Episode_Reward/pen_feet_distance: -0.0242
Episode_Reward/pen_feet_regulation: -0.4612
   Episode_Reward/foot_landing_vel: -0.1385
   Episode_Reward/test_gait_reward: -0.9373
Metrics/base_velocity/error_vel_xy: 1.0293
Metrics/base_velocity/error_vel_yaw: 1.3049
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 1.09s
                        Total time: 1397.58s
                               ETA: 1871.4s

################################################################################
                     [1m Learning iteration 1283/3000 [0m                     

                       Computation: 91212 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.6466
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8987
                     Learning rate: 0.0006
                       Mean reward: 116.07
               Mean episode length: 912.87
       Episode_Reward/keep_balance: 0.9068
     Episode_Reward/rew_lin_vel_xy: 5.5282
      Episode_Reward/rew_ang_vel_z: 2.2299
    Episode_Reward/pen_base_height: -0.3007
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.1676
   Episode_Reward/pen_joint_torque: -0.2159
    Episode_Reward/pen_joint_accel: -0.1079
    Episode_Reward/pen_action_rate: -0.1138
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0853
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2463
Episode_Reward/pen_flat_orientation: -0.1135
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4391
   Episode_Reward/foot_landing_vel: -0.1263
   Episode_Reward/test_gait_reward: -0.8895
Metrics/base_velocity/error_vel_xy: 0.9664
Metrics/base_velocity/error_vel_yaw: 1.2763
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 1.08s
                        Total time: 1398.66s
                               ETA: 1870.3s

################################################################################
                     [1m Learning iteration 1284/3000 [0m                     

                       Computation: 89561 steps/s (collection: 0.976s, learning 0.122s)
               Value function loss: 0.6182
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8967
                     Learning rate: 0.0009
                       Mean reward: 119.69
               Mean episode length: 955.48
       Episode_Reward/keep_balance: 0.9633
     Episode_Reward/rew_lin_vel_xy: 5.7677
      Episode_Reward/rew_ang_vel_z: 2.3695
    Episode_Reward/pen_base_height: -0.3149
      Episode_Reward/pen_lin_vel_z: -0.0389
     Episode_Reward/pen_ang_vel_xy: -0.1832
   Episode_Reward/pen_joint_torque: -0.2269
    Episode_Reward/pen_joint_accel: -0.1130
    Episode_Reward/pen_action_rate: -0.1224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2657
Episode_Reward/pen_flat_orientation: -0.1133
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4789
   Episode_Reward/foot_landing_vel: -0.1317
   Episode_Reward/test_gait_reward: -0.9364
Metrics/base_velocity/error_vel_xy: 1.0746
Metrics/base_velocity/error_vel_yaw: 1.3381
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 1.10s
                        Total time: 1399.76s
                               ETA: 1869.3s

################################################################################
                     [1m Learning iteration 1285/3000 [0m                     

                       Computation: 89656 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.6526
                    Surrogate loss: -0.0012
             Mean action noise std: 0.8962
                     Learning rate: 0.0004
                       Mean reward: 119.53
               Mean episode length: 961.49
       Episode_Reward/keep_balance: 0.9694
     Episode_Reward/rew_lin_vel_xy: 5.7752
      Episode_Reward/rew_ang_vel_z: 2.3457
    Episode_Reward/pen_base_height: -0.3156
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1863
   Episode_Reward/pen_joint_torque: -0.2219
    Episode_Reward/pen_joint_accel: -0.1235
    Episode_Reward/pen_action_rate: -0.1228
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2691
Episode_Reward/pen_flat_orientation: -0.1071
  Episode_Reward/pen_feet_distance: -0.0206
Episode_Reward/pen_feet_regulation: -0.4718
   Episode_Reward/foot_landing_vel: -0.1337
   Episode_Reward/test_gait_reward: -0.9442
Metrics/base_velocity/error_vel_xy: 1.1048
Metrics/base_velocity/error_vel_yaw: 1.3911
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 1.10s
                        Total time: 1400.86s
                               ETA: 1868.2s

################################################################################
                     [1m Learning iteration 1286/3000 [0m                     

                       Computation: 90463 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.6928
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8968
                     Learning rate: 0.0004
                       Mean reward: 121.98
               Mean episode length: 967.60
       Episode_Reward/keep_balance: 0.9600
     Episode_Reward/rew_lin_vel_xy: 5.8314
      Episode_Reward/rew_ang_vel_z: 2.3551
    Episode_Reward/pen_base_height: -0.3122
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1841
   Episode_Reward/pen_joint_torque: -0.2247
    Episode_Reward/pen_joint_accel: -0.1197
    Episode_Reward/pen_action_rate: -0.1224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2664
Episode_Reward/pen_flat_orientation: -0.1062
  Episode_Reward/pen_feet_distance: -0.0230
Episode_Reward/pen_feet_regulation: -0.4707
   Episode_Reward/foot_landing_vel: -0.1304
   Episode_Reward/test_gait_reward: -0.9400
Metrics/base_velocity/error_vel_xy: 1.0405
Metrics/base_velocity/error_vel_yaw: 1.3512
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 1.09s
                        Total time: 1401.94s
                               ETA: 1867.1s

################################################################################
                     [1m Learning iteration 1287/3000 [0m                     

                       Computation: 92291 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.6721
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8969
                     Learning rate: 0.0006
                       Mean reward: 121.47
               Mean episode length: 957.94
       Episode_Reward/keep_balance: 0.9502
     Episode_Reward/rew_lin_vel_xy: 5.8029
      Episode_Reward/rew_ang_vel_z: 2.3152
    Episode_Reward/pen_base_height: -0.3074
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1779
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0882
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2590
Episode_Reward/pen_flat_orientation: -0.1072
  Episode_Reward/pen_feet_distance: -0.0193
Episode_Reward/pen_feet_regulation: -0.4488
   Episode_Reward/foot_landing_vel: -0.1324
   Episode_Reward/test_gait_reward: -0.9227
Metrics/base_velocity/error_vel_xy: 1.0113
Metrics/base_velocity/error_vel_yaw: 1.3447
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 1.07s
                        Total time: 1403.01s
                               ETA: 1866.0s

################################################################################
                     [1m Learning iteration 1288/3000 [0m                     

                       Computation: 91181 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.6850
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8982
                     Learning rate: 0.0006
                       Mean reward: 119.29
               Mean episode length: 955.41
       Episode_Reward/keep_balance: 0.9537
     Episode_Reward/rew_lin_vel_xy: 5.6871
      Episode_Reward/rew_ang_vel_z: 2.3294
    Episode_Reward/pen_base_height: -0.3239
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.1840
   Episode_Reward/pen_joint_torque: -0.2315
    Episode_Reward/pen_joint_accel: -0.1125
    Episode_Reward/pen_action_rate: -0.1217
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0911
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2626
Episode_Reward/pen_flat_orientation: -0.1110
  Episode_Reward/pen_feet_distance: -0.0247
Episode_Reward/pen_feet_regulation: -0.4849
   Episode_Reward/foot_landing_vel: -0.1356
   Episode_Reward/test_gait_reward: -0.9347
Metrics/base_velocity/error_vel_xy: 1.0745
Metrics/base_velocity/error_vel_yaw: 1.3419
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 1.08s
                        Total time: 1404.09s
                               ETA: 1864.9s

################################################################################
                     [1m Learning iteration 1289/3000 [0m                     

                       Computation: 89256 steps/s (collection: 0.975s, learning 0.126s)
               Value function loss: 0.5790
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8980
                     Learning rate: 0.0004
                       Mean reward: 114.79
               Mean episode length: 908.61
       Episode_Reward/keep_balance: 0.8633
     Episode_Reward/rew_lin_vel_xy: 5.1958
      Episode_Reward/rew_ang_vel_z: 2.1198
    Episode_Reward/pen_base_height: -0.2773
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1705
   Episode_Reward/pen_joint_torque: -0.1960
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1083
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0516
   Episode_Reward/pen_joint_powers: -0.0791
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2382
Episode_Reward/pen_flat_orientation: -0.1092
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4263
   Episode_Reward/foot_landing_vel: -0.1188
   Episode_Reward/test_gait_reward: -0.8456
Metrics/base_velocity/error_vel_xy: 0.9538
Metrics/base_velocity/error_vel_yaw: 1.2003
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 1.10s
                        Total time: 1405.19s
                               ETA: 1863.8s

################################################################################
                     [1m Learning iteration 1290/3000 [0m                     

                       Computation: 89209 steps/s (collection: 0.977s, learning 0.125s)
               Value function loss: 0.6173
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8970
                     Learning rate: 0.0006
                       Mean reward: 126.65
               Mean episode length: 981.70
       Episode_Reward/keep_balance: 0.9852
     Episode_Reward/rew_lin_vel_xy: 5.9965
      Episode_Reward/rew_ang_vel_z: 2.4497
    Episode_Reward/pen_base_height: -0.3002
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1874
   Episode_Reward/pen_joint_torque: -0.2266
    Episode_Reward/pen_joint_accel: -0.1077
    Episode_Reward/pen_action_rate: -0.1233
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0908
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2701
Episode_Reward/pen_flat_orientation: -0.1034
  Episode_Reward/pen_feet_distance: -0.0267
Episode_Reward/pen_feet_regulation: -0.4668
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.9583
Metrics/base_velocity/error_vel_xy: 1.0455
Metrics/base_velocity/error_vel_yaw: 1.3342
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 1.10s
                        Total time: 1406.29s
                               ETA: 1862.7s

################################################################################
                     [1m Learning iteration 1291/3000 [0m                     

                       Computation: 91054 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.6614
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8970
                     Learning rate: 0.0006
                       Mean reward: 123.59
               Mean episode length: 978.62
       Episode_Reward/keep_balance: 0.9788
     Episode_Reward/rew_lin_vel_xy: 5.9325
      Episode_Reward/rew_ang_vel_z: 2.3878
    Episode_Reward/pen_base_height: -0.3285
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1835
   Episode_Reward/pen_joint_torque: -0.2356
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1237
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0921
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2671
Episode_Reward/pen_flat_orientation: -0.1070
  Episode_Reward/pen_feet_distance: -0.0223
Episode_Reward/pen_feet_regulation: -0.4797
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.9591
Metrics/base_velocity/error_vel_xy: 1.0476
Metrics/base_velocity/error_vel_yaw: 1.3699
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 1.08s
                        Total time: 1407.37s
                               ETA: 1861.6s

################################################################################
                     [1m Learning iteration 1292/3000 [0m                     

                       Computation: 89484 steps/s (collection: 0.967s, learning 0.132s)
               Value function loss: 0.5519
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8971
                     Learning rate: 0.0004
                       Mean reward: 123.19
               Mean episode length: 960.59
       Episode_Reward/keep_balance: 0.9607
     Episode_Reward/rew_lin_vel_xy: 5.8230
      Episode_Reward/rew_ang_vel_z: 2.3772
    Episode_Reward/pen_base_height: -0.3082
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1753
   Episode_Reward/pen_joint_torque: -0.2180
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2607
Episode_Reward/pen_flat_orientation: -0.1082
  Episode_Reward/pen_feet_distance: -0.0190
Episode_Reward/pen_feet_regulation: -0.4673
   Episode_Reward/foot_landing_vel: -0.1273
   Episode_Reward/test_gait_reward: -0.9360
Metrics/base_velocity/error_vel_xy: 1.0411
Metrics/base_velocity/error_vel_yaw: 1.3185
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 1.10s
                        Total time: 1408.47s
                               ETA: 1860.5s

################################################################################
                     [1m Learning iteration 1293/3000 [0m                     

                       Computation: 91074 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.6417
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8971
                     Learning rate: 0.0006
                       Mean reward: 126.30
               Mean episode length: 985.35
       Episode_Reward/keep_balance: 0.9933
     Episode_Reward/rew_lin_vel_xy: 6.0142
      Episode_Reward/rew_ang_vel_z: 2.4103
    Episode_Reward/pen_base_height: -0.3253
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1949
   Episode_Reward/pen_joint_torque: -0.2351
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1268
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0603
   Episode_Reward/pen_joint_powers: -0.0920
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2768
Episode_Reward/pen_flat_orientation: -0.1103
  Episode_Reward/pen_feet_distance: -0.0169
Episode_Reward/pen_feet_regulation: -0.4831
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9666
Metrics/base_velocity/error_vel_xy: 1.0611
Metrics/base_velocity/error_vel_yaw: 1.4171
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 1.08s
                        Total time: 1409.55s
                               ETA: 1859.4s

################################################################################
                     [1m Learning iteration 1294/3000 [0m                     

                       Computation: 91059 steps/s (collection: 0.959s, learning 0.121s)
               Value function loss: 0.6089
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8957
                     Learning rate: 0.0003
                       Mean reward: 122.45
               Mean episode length: 967.69
       Episode_Reward/keep_balance: 0.9788
     Episode_Reward/rew_lin_vel_xy: 5.9009
      Episode_Reward/rew_ang_vel_z: 2.4407
    Episode_Reward/pen_base_height: -0.3165
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.1829
   Episode_Reward/pen_joint_torque: -0.2339
    Episode_Reward/pen_joint_accel: -0.1227
    Episode_Reward/pen_action_rate: -0.1225
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0915
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2672
Episode_Reward/pen_flat_orientation: -0.1034
  Episode_Reward/pen_feet_distance: -0.0267
Episode_Reward/pen_feet_regulation: -0.4769
   Episode_Reward/foot_landing_vel: -0.1381
   Episode_Reward/test_gait_reward: -0.9551
Metrics/base_velocity/error_vel_xy: 1.0722
Metrics/base_velocity/error_vel_yaw: 1.3246
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 1.08s
                        Total time: 1410.63s
                               ETA: 1858.3s

################################################################################
                     [1m Learning iteration 1295/3000 [0m                     

                       Computation: 88738 steps/s (collection: 0.980s, learning 0.128s)
               Value function loss: 0.6706
                    Surrogate loss: -0.0056
             Mean action noise std: 0.8959
                     Learning rate: 0.0004
                       Mean reward: 125.71
               Mean episode length: 974.88
       Episode_Reward/keep_balance: 0.9789
     Episode_Reward/rew_lin_vel_xy: 5.8982
      Episode_Reward/rew_ang_vel_z: 2.3947
    Episode_Reward/pen_base_height: -0.3175
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1909
   Episode_Reward/pen_joint_torque: -0.2298
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.1224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2663
Episode_Reward/pen_flat_orientation: -0.1093
  Episode_Reward/pen_feet_distance: -0.0173
Episode_Reward/pen_feet_regulation: -0.4542
   Episode_Reward/foot_landing_vel: -0.1285
   Episode_Reward/test_gait_reward: -0.9537
Metrics/base_velocity/error_vel_xy: 1.0775
Metrics/base_velocity/error_vel_yaw: 1.3842
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 1.11s
                        Total time: 1411.73s
                               ETA: 1857.3s

################################################################################
                     [1m Learning iteration 1296/3000 [0m                     

                       Computation: 89685 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.6741
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8955
                     Learning rate: 0.0009
                       Mean reward: 118.84
               Mean episode length: 951.85
       Episode_Reward/keep_balance: 0.9490
     Episode_Reward/rew_lin_vel_xy: 5.7333
      Episode_Reward/rew_ang_vel_z: 2.2959
    Episode_Reward/pen_base_height: -0.3204
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1851
   Episode_Reward/pen_joint_torque: -0.2208
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0591
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2619
Episode_Reward/pen_flat_orientation: -0.1083
  Episode_Reward/pen_feet_distance: -0.0187
Episode_Reward/pen_feet_regulation: -0.4781
   Episode_Reward/foot_landing_vel: -0.1360
   Episode_Reward/test_gait_reward: -0.9319
Metrics/base_velocity/error_vel_xy: 1.0423
Metrics/base_velocity/error_vel_yaw: 1.3616
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 1.10s
                        Total time: 1412.83s
                               ETA: 1856.2s

################################################################################
                     [1m Learning iteration 1297/3000 [0m                     

                       Computation: 91324 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.7299
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8955
                     Learning rate: 0.0004
                       Mean reward: 124.59
               Mean episode length: 965.96
       Episode_Reward/keep_balance: 0.9765
     Episode_Reward/rew_lin_vel_xy: 5.9879
      Episode_Reward/rew_ang_vel_z: 2.4317
    Episode_Reward/pen_base_height: -0.3104
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1843
   Episode_Reward/pen_joint_torque: -0.2326
    Episode_Reward/pen_joint_accel: -0.1110
    Episode_Reward/pen_action_rate: -0.1209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2639
Episode_Reward/pen_flat_orientation: -0.1067
  Episode_Reward/pen_feet_distance: -0.0163
Episode_Reward/pen_feet_regulation: -0.4667
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.9530
Metrics/base_velocity/error_vel_xy: 1.0147
Metrics/base_velocity/error_vel_yaw: 1.3232
      Episode_Termination/time_out: 4.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 1.08s
                        Total time: 1413.91s
                               ETA: 1855.1s

################################################################################
                     [1m Learning iteration 1298/3000 [0m                     

                       Computation: 88762 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 0.5719
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8968
                     Learning rate: 0.0002
                       Mean reward: 123.08
               Mean episode length: 956.12
       Episode_Reward/keep_balance: 0.9361
     Episode_Reward/rew_lin_vel_xy: 5.7140
      Episode_Reward/rew_ang_vel_z: 2.3339
    Episode_Reward/pen_base_height: -0.3057
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1801
   Episode_Reward/pen_joint_torque: -0.2202
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0869
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2528
Episode_Reward/pen_flat_orientation: -0.1098
  Episode_Reward/pen_feet_distance: -0.0211
Episode_Reward/pen_feet_regulation: -0.4434
   Episode_Reward/foot_landing_vel: -0.1286
   Episode_Reward/test_gait_reward: -0.9073
Metrics/base_velocity/error_vel_xy: 0.9773
Metrics/base_velocity/error_vel_yaw: 1.2708
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 1.11s
                        Total time: 1415.01s
                               ETA: 1854.0s

################################################################################
                     [1m Learning iteration 1299/3000 [0m                     

                       Computation: 89492 steps/s (collection: 0.972s, learning 0.127s)
               Value function loss: 0.6278
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8977
                     Learning rate: 0.0004
                       Mean reward: 124.60
               Mean episode length: 974.93
       Episode_Reward/keep_balance: 0.9752
     Episode_Reward/rew_lin_vel_xy: 5.9039
      Episode_Reward/rew_ang_vel_z: 2.4247
    Episode_Reward/pen_base_height: -0.3133
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1791
   Episode_Reward/pen_joint_torque: -0.2351
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.1201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2608
Episode_Reward/pen_flat_orientation: -0.1067
  Episode_Reward/pen_feet_distance: -0.0185
Episode_Reward/pen_feet_regulation: -0.4528
   Episode_Reward/foot_landing_vel: -0.1370
   Episode_Reward/test_gait_reward: -0.9460
Metrics/base_velocity/error_vel_xy: 1.0564
Metrics/base_velocity/error_vel_yaw: 1.3215
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 1.10s
                        Total time: 1416.11s
                               ETA: 1852.9s

################################################################################
                     [1m Learning iteration 1300/3000 [0m                     

                       Computation: 89749 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.5786
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8970
                     Learning rate: 0.0004
                       Mean reward: 125.48
               Mean episode length: 987.63
       Episode_Reward/keep_balance: 0.9893
     Episode_Reward/rew_lin_vel_xy: 5.9694
      Episode_Reward/rew_ang_vel_z: 2.3926
    Episode_Reward/pen_base_height: -0.3269
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1880
   Episode_Reward/pen_joint_torque: -0.2327
    Episode_Reward/pen_joint_accel: -0.1070
    Episode_Reward/pen_action_rate: -0.1245
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2685
Episode_Reward/pen_flat_orientation: -0.1093
  Episode_Reward/pen_feet_distance: -0.0191
Episode_Reward/pen_feet_regulation: -0.4842
   Episode_Reward/foot_landing_vel: -0.1399
   Episode_Reward/test_gait_reward: -0.9661
Metrics/base_velocity/error_vel_xy: 1.0917
Metrics/base_velocity/error_vel_yaw: 1.4160
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 1.10s
                        Total time: 1417.21s
                               ETA: 1851.8s

################################################################################
                     [1m Learning iteration 1301/3000 [0m                     

                       Computation: 89538 steps/s (collection: 0.973s, learning 0.125s)
               Value function loss: 0.5689
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8980
                     Learning rate: 0.0006
                       Mean reward: 121.97
               Mean episode length: 974.33
       Episode_Reward/keep_balance: 0.9685
     Episode_Reward/rew_lin_vel_xy: 5.8124
      Episode_Reward/rew_ang_vel_z: 2.3692
    Episode_Reward/pen_base_height: -0.3243
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1917
   Episode_Reward/pen_joint_torque: -0.2317
    Episode_Reward/pen_joint_accel: -0.1198
    Episode_Reward/pen_action_rate: -0.1222
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2647
Episode_Reward/pen_flat_orientation: -0.1114
  Episode_Reward/pen_feet_distance: -0.0246
Episode_Reward/pen_feet_regulation: -0.4830
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9426
Metrics/base_velocity/error_vel_xy: 1.0784
Metrics/base_velocity/error_vel_yaw: 1.3550
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 1.10s
                        Total time: 1418.31s
                               ETA: 1850.8s

################################################################################
                     [1m Learning iteration 1302/3000 [0m                     

                       Computation: 89682 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.6431
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8963
                     Learning rate: 0.0006
                       Mean reward: 123.74
               Mean episode length: 972.36
       Episode_Reward/keep_balance: 0.9762
     Episode_Reward/rew_lin_vel_xy: 5.8987
      Episode_Reward/rew_ang_vel_z: 2.4258
    Episode_Reward/pen_base_height: -0.3118
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1809
   Episode_Reward/pen_joint_torque: -0.2322
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2640
Episode_Reward/pen_flat_orientation: -0.1043
  Episode_Reward/pen_feet_distance: -0.0229
Episode_Reward/pen_feet_regulation: -0.4704
   Episode_Reward/foot_landing_vel: -0.1331
   Episode_Reward/test_gait_reward: -0.9556
Metrics/base_velocity/error_vel_xy: 1.0361
Metrics/base_velocity/error_vel_yaw: 1.3268
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 1.10s
                        Total time: 1419.40s
                               ETA: 1849.7s

################################################################################
                     [1m Learning iteration 1303/3000 [0m                     

                       Computation: 91673 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.6134
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8944
                     Learning rate: 0.0009
                       Mean reward: 121.59
               Mean episode length: 958.06
       Episode_Reward/keep_balance: 0.9390
     Episode_Reward/rew_lin_vel_xy: 5.6871
      Episode_Reward/rew_ang_vel_z: 2.2936
    Episode_Reward/pen_base_height: -0.3133
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1729
   Episode_Reward/pen_joint_torque: -0.2113
    Episode_Reward/pen_joint_accel: -0.0954
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0852
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2523
Episode_Reward/pen_flat_orientation: -0.1105
  Episode_Reward/pen_feet_distance: -0.0194
Episode_Reward/pen_feet_regulation: -0.4512
   Episode_Reward/foot_landing_vel: -0.1172
   Episode_Reward/test_gait_reward: -0.9099
Metrics/base_velocity/error_vel_xy: 1.0153
Metrics/base_velocity/error_vel_yaw: 1.3357
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 1.07s
                        Total time: 1420.47s
                               ETA: 1848.6s

################################################################################
                     [1m Learning iteration 1304/3000 [0m                     

                       Computation: 89543 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.6319
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8955
                     Learning rate: 0.0006
                       Mean reward: 124.08
               Mean episode length: 981.68
       Episode_Reward/keep_balance: 0.9933
     Episode_Reward/rew_lin_vel_xy: 5.9933
      Episode_Reward/rew_ang_vel_z: 2.4477
    Episode_Reward/pen_base_height: -0.3161
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1843
   Episode_Reward/pen_joint_torque: -0.2354
    Episode_Reward/pen_joint_accel: -0.1181
    Episode_Reward/pen_action_rate: -0.1241
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0606
   Episode_Reward/pen_joint_powers: -0.0933
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2704
Episode_Reward/pen_flat_orientation: -0.1076
  Episode_Reward/pen_feet_distance: -0.0157
Episode_Reward/pen_feet_regulation: -0.4947
   Episode_Reward/foot_landing_vel: -0.1373
   Episode_Reward/test_gait_reward: -0.9740
Metrics/base_velocity/error_vel_xy: 1.0808
Metrics/base_velocity/error_vel_yaw: 1.3735
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 1.10s
                        Total time: 1421.57s
                               ETA: 1847.5s

################################################################################
                     [1m Learning iteration 1305/3000 [0m                     

                       Computation: 90848 steps/s (collection: 0.957s, learning 0.125s)
               Value function loss: 0.6328
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8955
                     Learning rate: 0.0004
                       Mean reward: 123.01
               Mean episode length: 960.71
       Episode_Reward/keep_balance: 0.9675
     Episode_Reward/rew_lin_vel_xy: 5.8861
      Episode_Reward/rew_ang_vel_z: 2.4042
    Episode_Reward/pen_base_height: -0.3055
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1818
   Episode_Reward/pen_joint_torque: -0.2259
    Episode_Reward/pen_joint_accel: -0.1095
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2608
Episode_Reward/pen_flat_orientation: -0.1077
  Episode_Reward/pen_feet_distance: -0.0192
Episode_Reward/pen_feet_regulation: -0.4626
   Episode_Reward/foot_landing_vel: -0.1294
   Episode_Reward/test_gait_reward: -0.9348
Metrics/base_velocity/error_vel_xy: 1.0353
Metrics/base_velocity/error_vel_yaw: 1.3289
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 1.08s
                        Total time: 1422.65s
                               ETA: 1846.4s

################################################################################
                     [1m Learning iteration 1306/3000 [0m                     

                       Computation: 90929 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.5715
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8953
                     Learning rate: 0.0006
                       Mean reward: 120.61
               Mean episode length: 952.96
       Episode_Reward/keep_balance: 0.9686
     Episode_Reward/rew_lin_vel_xy: 5.8414
      Episode_Reward/rew_ang_vel_z: 2.3744
    Episode_Reward/pen_base_height: -0.3000
      Episode_Reward/pen_lin_vel_z: -0.0415
     Episode_Reward/pen_ang_vel_xy: -0.1830
   Episode_Reward/pen_joint_torque: -0.2253
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.1208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2635
Episode_Reward/pen_flat_orientation: -0.1092
  Episode_Reward/pen_feet_distance: -0.0178
Episode_Reward/pen_feet_regulation: -0.4949
   Episode_Reward/foot_landing_vel: -0.1363
   Episode_Reward/test_gait_reward: -0.9397
Metrics/base_velocity/error_vel_xy: 1.0545
Metrics/base_velocity/error_vel_yaw: 1.3481
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 1.08s
                        Total time: 1423.74s
                               ETA: 1845.3s

################################################################################
                     [1m Learning iteration 1307/3000 [0m                     

                       Computation: 92422 steps/s (collection: 0.942s, learning 0.122s)
               Value function loss: 0.6397
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8942
                     Learning rate: 0.0004
                       Mean reward: 121.07
               Mean episode length: 973.16
       Episode_Reward/keep_balance: 0.9726
     Episode_Reward/rew_lin_vel_xy: 5.8627
      Episode_Reward/rew_ang_vel_z: 2.3439
    Episode_Reward/pen_base_height: -0.3016
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1851
   Episode_Reward/pen_joint_torque: -0.2273
    Episode_Reward/pen_joint_accel: -0.1225
    Episode_Reward/pen_action_rate: -0.1229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0609
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2660
Episode_Reward/pen_flat_orientation: -0.1096
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4939
   Episode_Reward/foot_landing_vel: -0.1445
   Episode_Reward/test_gait_reward: -0.9454
Metrics/base_velocity/error_vel_xy: 1.0726
Metrics/base_velocity/error_vel_yaw: 1.3991
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 1.06s
                        Total time: 1424.80s
                               ETA: 1844.2s

################################################################################
                     [1m Learning iteration 1308/3000 [0m                     

                       Computation: 89361 steps/s (collection: 0.979s, learning 0.121s)
               Value function loss: 0.5724
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8924
                     Learning rate: 0.0004
                       Mean reward: 125.04
               Mean episode length: 971.19
       Episode_Reward/keep_balance: 0.9466
     Episode_Reward/rew_lin_vel_xy: 5.7889
      Episode_Reward/rew_ang_vel_z: 2.3234
    Episode_Reward/pen_base_height: -0.2929
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1826
   Episode_Reward/pen_joint_torque: -0.2093
    Episode_Reward/pen_joint_accel: -0.1069
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2570
Episode_Reward/pen_flat_orientation: -0.1080
  Episode_Reward/pen_feet_distance: -0.0182
Episode_Reward/pen_feet_regulation: -0.4599
   Episode_Reward/foot_landing_vel: -0.1269
   Episode_Reward/test_gait_reward: -0.9192
Metrics/base_velocity/error_vel_xy: 0.9958
Metrics/base_velocity/error_vel_yaw: 1.3261
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 1.10s
                        Total time: 1425.90s
                               ETA: 1843.1s

################################################################################
                     [1m Learning iteration 1309/3000 [0m                     

                       Computation: 89752 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.7018
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8914
                     Learning rate: 0.0006
                       Mean reward: 128.68
               Mean episode length: 991.72
       Episode_Reward/keep_balance: 0.9822
     Episode_Reward/rew_lin_vel_xy: 6.0614
      Episode_Reward/rew_ang_vel_z: 2.4127
    Episode_Reward/pen_base_height: -0.3028
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1834
   Episode_Reward/pen_joint_torque: -0.2300
    Episode_Reward/pen_joint_accel: -0.1134
    Episode_Reward/pen_action_rate: -0.1213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2651
Episode_Reward/pen_flat_orientation: -0.1073
  Episode_Reward/pen_feet_distance: -0.0202
Episode_Reward/pen_feet_regulation: -0.4681
   Episode_Reward/foot_landing_vel: -0.1341
   Episode_Reward/test_gait_reward: -0.9526
Metrics/base_velocity/error_vel_xy: 1.0073
Metrics/base_velocity/error_vel_yaw: 1.3621
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 1.10s
                        Total time: 1426.99s
                               ETA: 1842.0s

################################################################################
                     [1m Learning iteration 1310/3000 [0m                     

                       Computation: 83201 steps/s (collection: 1.058s, learning 0.124s)
               Value function loss: 0.6169
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8908
                     Learning rate: 0.0006
                       Mean reward: 123.83
               Mean episode length: 962.86
       Episode_Reward/keep_balance: 0.9559
     Episode_Reward/rew_lin_vel_xy: 5.8647
      Episode_Reward/rew_ang_vel_z: 2.3841
    Episode_Reward/pen_base_height: -0.3006
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1833
   Episode_Reward/pen_joint_torque: -0.2282
    Episode_Reward/pen_joint_accel: -0.1082
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2575
Episode_Reward/pen_flat_orientation: -0.1069
  Episode_Reward/pen_feet_distance: -0.0182
Episode_Reward/pen_feet_regulation: -0.4768
   Episode_Reward/foot_landing_vel: -0.1445
   Episode_Reward/test_gait_reward: -0.9339
Metrics/base_velocity/error_vel_xy: 0.9913
Metrics/base_velocity/error_vel_yaw: 1.2902
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 1.18s
                        Total time: 1428.18s
                               ETA: 1841.1s

################################################################################
                     [1m Learning iteration 1311/3000 [0m                     

                       Computation: 89696 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 0.6199
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8898
                     Learning rate: 0.0009
                       Mean reward: 119.59
               Mean episode length: 946.82
       Episode_Reward/keep_balance: 0.9536
     Episode_Reward/rew_lin_vel_xy: 5.8051
      Episode_Reward/rew_ang_vel_z: 2.3250
    Episode_Reward/pen_base_height: -0.3121
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.1818
   Episode_Reward/pen_joint_torque: -0.2185
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.1180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2576
Episode_Reward/pen_flat_orientation: -0.1111
  Episode_Reward/pen_feet_distance: -0.0189
Episode_Reward/pen_feet_regulation: -0.4703
   Episode_Reward/foot_landing_vel: -0.1370
   Episode_Reward/test_gait_reward: -0.9186
Metrics/base_velocity/error_vel_xy: 1.0285
Metrics/base_velocity/error_vel_yaw: 1.3497
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 1.10s
                        Total time: 1429.27s
                               ETA: 1840.0s

################################################################################
                     [1m Learning iteration 1312/3000 [0m                     

                       Computation: 90135 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.6698
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8893
                     Learning rate: 0.0006
                       Mean reward: 120.94
               Mean episode length: 958.63
       Episode_Reward/keep_balance: 0.9620
     Episode_Reward/rew_lin_vel_xy: 5.7726
      Episode_Reward/rew_ang_vel_z: 2.3656
    Episode_Reward/pen_base_height: -0.3242
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.1768
   Episode_Reward/pen_joint_torque: -0.2288
    Episode_Reward/pen_joint_accel: -0.1261
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0917
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2599
Episode_Reward/pen_flat_orientation: -0.1087
  Episode_Reward/pen_feet_distance: -0.0206
Episode_Reward/pen_feet_regulation: -0.4890
   Episode_Reward/foot_landing_vel: -0.1462
   Episode_Reward/test_gait_reward: -0.9358
Metrics/base_velocity/error_vel_xy: 1.0776
Metrics/base_velocity/error_vel_yaw: 1.3341
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 1.09s
                        Total time: 1430.36s
                               ETA: 1838.9s

################################################################################
                     [1m Learning iteration 1313/3000 [0m                     

                       Computation: 90566 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.6551
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8898
                     Learning rate: 0.0004
                       Mean reward: 119.45
               Mean episode length: 950.05
       Episode_Reward/keep_balance: 0.9716
     Episode_Reward/rew_lin_vel_xy: 5.8676
      Episode_Reward/rew_ang_vel_z: 2.3744
    Episode_Reward/pen_base_height: -0.3098
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1757
   Episode_Reward/pen_joint_torque: -0.2370
    Episode_Reward/pen_joint_accel: -0.1103
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0602
   Episode_Reward/pen_joint_powers: -0.0932
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2632
Episode_Reward/pen_flat_orientation: -0.1155
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4858
   Episode_Reward/foot_landing_vel: -0.1398
   Episode_Reward/test_gait_reward: -0.9462
Metrics/base_velocity/error_vel_xy: 1.0507
Metrics/base_velocity/error_vel_yaw: 1.3665
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 1.09s
                        Total time: 1431.45s
                               ETA: 1837.8s

################################################################################
                     [1m Learning iteration 1314/3000 [0m                     

                       Computation: 89027 steps/s (collection: 0.980s, learning 0.124s)
               Value function loss: 0.6364
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8890
                     Learning rate: 0.0003
                       Mean reward: 115.50
               Mean episode length: 919.54
       Episode_Reward/keep_balance: 0.9212
     Episode_Reward/rew_lin_vel_xy: 5.5986
      Episode_Reward/rew_ang_vel_z: 2.2228
    Episode_Reward/pen_base_height: -0.3067
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1802
   Episode_Reward/pen_joint_torque: -0.2119
    Episode_Reward/pen_joint_accel: -0.1041
    Episode_Reward/pen_action_rate: -0.1157
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2520
Episode_Reward/pen_flat_orientation: -0.1195
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.4623
   Episode_Reward/foot_landing_vel: -0.1274
   Episode_Reward/test_gait_reward: -0.8889
Metrics/base_velocity/error_vel_xy: 0.9944
Metrics/base_velocity/error_vel_yaw: 1.3378
      Episode_Termination/time_out: 3.0833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 1.10s
                        Total time: 1432.55s
                               ETA: 1836.7s

################################################################################
                     [1m Learning iteration 1315/3000 [0m                     

                       Computation: 88992 steps/s (collection: 0.979s, learning 0.125s)
               Value function loss: 0.6691
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8902
                     Learning rate: 0.0006
                       Mean reward: 121.98
               Mean episode length: 974.95
       Episode_Reward/keep_balance: 0.9722
     Episode_Reward/rew_lin_vel_xy: 5.8542
      Episode_Reward/rew_ang_vel_z: 2.3748
    Episode_Reward/pen_base_height: -0.3204
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1795
   Episode_Reward/pen_joint_torque: -0.2346
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1215
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0921
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2619
Episode_Reward/pen_flat_orientation: -0.1152
  Episode_Reward/pen_feet_distance: -0.0191
Episode_Reward/pen_feet_regulation: -0.4741
   Episode_Reward/foot_landing_vel: -0.1398
   Episode_Reward/test_gait_reward: -0.9509
Metrics/base_velocity/error_vel_xy: 1.0779
Metrics/base_velocity/error_vel_yaw: 1.3682
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 1.10s
                        Total time: 1433.66s
                               ETA: 1835.6s

################################################################################
                     [1m Learning iteration 1316/3000 [0m                     

                       Computation: 89080 steps/s (collection: 0.979s, learning 0.125s)
               Value function loss: 0.6457
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8920
                     Learning rate: 0.0009
                       Mean reward: 119.23
               Mean episode length: 945.40
       Episode_Reward/keep_balance: 0.9234
     Episode_Reward/rew_lin_vel_xy: 5.5965
      Episode_Reward/rew_ang_vel_z: 2.2789
    Episode_Reward/pen_base_height: -0.3211
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1758
   Episode_Reward/pen_joint_torque: -0.2276
    Episode_Reward/pen_joint_accel: -0.1059
    Episode_Reward/pen_action_rate: -0.1139
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2445
Episode_Reward/pen_flat_orientation: -0.1117
  Episode_Reward/pen_feet_distance: -0.0204
Episode_Reward/pen_feet_regulation: -0.4557
   Episode_Reward/foot_landing_vel: -0.1250
   Episode_Reward/test_gait_reward: -0.9004
Metrics/base_velocity/error_vel_xy: 1.0044
Metrics/base_velocity/error_vel_yaw: 1.2744
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 1.10s
                        Total time: 1434.76s
                               ETA: 1834.6s

################################################################################
                     [1m Learning iteration 1317/3000 [0m                     

                       Computation: 89539 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.6398
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8901
                     Learning rate: 0.0009
                       Mean reward: 126.19
               Mean episode length: 981.22
       Episode_Reward/keep_balance: 0.9838
     Episode_Reward/rew_lin_vel_xy: 6.0293
      Episode_Reward/rew_ang_vel_z: 2.4224
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1820
   Episode_Reward/pen_joint_torque: -0.2313
    Episode_Reward/pen_joint_accel: -0.1128
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0586
   Episode_Reward/pen_joint_powers: -0.0911
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2639
Episode_Reward/pen_flat_orientation: -0.1091
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4731
   Episode_Reward/foot_landing_vel: -0.1330
   Episode_Reward/test_gait_reward: -0.9551
Metrics/base_velocity/error_vel_xy: 1.0306
Metrics/base_velocity/error_vel_yaw: 1.3640
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 1.10s
                        Total time: 1435.86s
                               ETA: 1833.5s

################################################################################
                     [1m Learning iteration 1318/3000 [0m                     

                       Computation: 88582 steps/s (collection: 0.987s, learning 0.122s)
               Value function loss: 0.5977
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8890
                     Learning rate: 0.0006
                       Mean reward: 122.54
               Mean episode length: 961.93
       Episode_Reward/keep_balance: 0.9727
     Episode_Reward/rew_lin_vel_xy: 5.9622
      Episode_Reward/rew_ang_vel_z: 2.4323
    Episode_Reward/pen_base_height: -0.3068
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1783
   Episode_Reward/pen_joint_torque: -0.2294
    Episode_Reward/pen_joint_accel: -0.1191
    Episode_Reward/pen_action_rate: -0.1198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0900
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2588
Episode_Reward/pen_flat_orientation: -0.1143
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4679
   Episode_Reward/foot_landing_vel: -0.1447
   Episode_Reward/test_gait_reward: -0.9415
Metrics/base_velocity/error_vel_xy: 1.0161
Metrics/base_velocity/error_vel_yaw: 1.3183
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 1.11s
                        Total time: 1436.97s
                               ETA: 1832.4s

################################################################################
                     [1m Learning iteration 1319/3000 [0m                     

                       Computation: 90159 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.5493
                    Surrogate loss: -0.0009
             Mean action noise std: 0.8882
                     Learning rate: 0.0001
                       Mean reward: 127.38
               Mean episode length: 987.83
       Episode_Reward/keep_balance: 0.9747
     Episode_Reward/rew_lin_vel_xy: 5.9831
      Episode_Reward/rew_ang_vel_z: 2.4195
    Episode_Reward/pen_base_height: -0.2991
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1756
   Episode_Reward/pen_joint_torque: -0.2236
    Episode_Reward/pen_joint_accel: -0.1140
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2582
Episode_Reward/pen_flat_orientation: -0.1092
  Episode_Reward/pen_feet_distance: -0.0188
Episode_Reward/pen_feet_regulation: -0.4619
   Episode_Reward/foot_landing_vel: -0.1297
   Episode_Reward/test_gait_reward: -0.9415
Metrics/base_velocity/error_vel_xy: 1.0140
Metrics/base_velocity/error_vel_yaw: 1.3301
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 1.09s
                        Total time: 1438.06s
                               ETA: 1831.3s

################################################################################
                     [1m Learning iteration 1320/3000 [0m                     

                       Computation: 89815 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.6273
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8891
                     Learning rate: 0.0003
                       Mean reward: 123.49
               Mean episode length: 959.26
       Episode_Reward/keep_balance: 0.9683
     Episode_Reward/rew_lin_vel_xy: 5.8954
      Episode_Reward/rew_ang_vel_z: 2.4219
    Episode_Reward/pen_base_height: -0.3101
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1814
   Episode_Reward/pen_joint_torque: -0.2248
    Episode_Reward/pen_joint_accel: -0.1076
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0892
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2569
Episode_Reward/pen_flat_orientation: -0.1082
  Episode_Reward/pen_feet_distance: -0.0226
Episode_Reward/pen_feet_regulation: -0.4687
   Episode_Reward/foot_landing_vel: -0.1316
   Episode_Reward/test_gait_reward: -0.9381
Metrics/base_velocity/error_vel_xy: 1.0306
Metrics/base_velocity/error_vel_yaw: 1.3084
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 1.09s
                        Total time: 1439.15s
                               ETA: 1830.3s

################################################################################
                     [1m Learning iteration 1321/3000 [0m                     

                       Computation: 89536 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.6307
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8891
                     Learning rate: 0.0006
                       Mean reward: 125.37
               Mean episode length: 982.46
       Episode_Reward/keep_balance: 0.9824
     Episode_Reward/rew_lin_vel_xy: 5.9996
      Episode_Reward/rew_ang_vel_z: 2.4581
    Episode_Reward/pen_base_height: -0.3109
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1821
   Episode_Reward/pen_joint_torque: -0.2345
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0920
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2615
Episode_Reward/pen_flat_orientation: -0.1070
  Episode_Reward/pen_feet_distance: -0.0189
Episode_Reward/pen_feet_regulation: -0.4702
   Episode_Reward/foot_landing_vel: -0.1400
   Episode_Reward/test_gait_reward: -0.9474
Metrics/base_velocity/error_vel_xy: 1.0353
Metrics/base_velocity/error_vel_yaw: 1.3189
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 1.10s
                        Total time: 1440.25s
                               ETA: 1829.2s

################################################################################
                     [1m Learning iteration 1322/3000 [0m                     

                       Computation: 89167 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.6577
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8891
                     Learning rate: 0.0006
                       Mean reward: 125.17
               Mean episode length: 980.84
       Episode_Reward/keep_balance: 0.9735
     Episode_Reward/rew_lin_vel_xy: 5.9159
      Episode_Reward/rew_ang_vel_z: 2.3991
    Episode_Reward/pen_base_height: -0.3035
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1774
   Episode_Reward/pen_joint_torque: -0.2238
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2580
Episode_Reward/pen_flat_orientation: -0.1088
  Episode_Reward/pen_feet_distance: -0.0201
Episode_Reward/pen_feet_regulation: -0.4695
   Episode_Reward/foot_landing_vel: -0.1377
   Episode_Reward/test_gait_reward: -0.9432
Metrics/base_velocity/error_vel_xy: 1.0282
Metrics/base_velocity/error_vel_yaw: 1.3491
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 1.10s
                        Total time: 1441.35s
                               ETA: 1828.1s

################################################################################
                     [1m Learning iteration 1323/3000 [0m                     

                       Computation: 89896 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.5735
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8888
                     Learning rate: 0.0006
                       Mean reward: 121.74
               Mean episode length: 959.15
       Episode_Reward/keep_balance: 0.9709
     Episode_Reward/rew_lin_vel_xy: 5.9052
      Episode_Reward/rew_ang_vel_z: 2.4153
    Episode_Reward/pen_base_height: -0.3232
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.1745
   Episode_Reward/pen_joint_torque: -0.2393
    Episode_Reward/pen_joint_accel: -0.1186
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0596
   Episode_Reward/pen_joint_powers: -0.0936
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2573
Episode_Reward/pen_flat_orientation: -0.1140
  Episode_Reward/pen_feet_distance: -0.0248
Episode_Reward/pen_feet_regulation: -0.4941
   Episode_Reward/foot_landing_vel: -0.1468
   Episode_Reward/test_gait_reward: -0.9410
Metrics/base_velocity/error_vel_xy: 1.0340
Metrics/base_velocity/error_vel_yaw: 1.3175
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 1.09s
                        Total time: 1442.45s
                               ETA: 1827.0s

################################################################################
                     [1m Learning iteration 1324/3000 [0m                     

                       Computation: 90276 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.6047
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8903
                     Learning rate: 0.0003
                       Mean reward: 125.76
               Mean episode length: 980.60
       Episode_Reward/keep_balance: 0.9863
     Episode_Reward/rew_lin_vel_xy: 6.0194
      Episode_Reward/rew_ang_vel_z: 2.4037
    Episode_Reward/pen_base_height: -0.3132
      Episode_Reward/pen_lin_vel_z: -0.0402
     Episode_Reward/pen_ang_vel_xy: -0.1770
   Episode_Reward/pen_joint_torque: -0.2321
    Episode_Reward/pen_joint_accel: -0.1125
    Episode_Reward/pen_action_rate: -0.1227
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0593
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2632
Episode_Reward/pen_flat_orientation: -0.1116
  Episode_Reward/pen_feet_distance: -0.0218
Episode_Reward/pen_feet_regulation: -0.4874
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.9558
Metrics/base_velocity/error_vel_xy: 1.0511
Metrics/base_velocity/error_vel_yaw: 1.3942
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 1.09s
                        Total time: 1443.54s
                               ETA: 1825.9s

################################################################################
                     [1m Learning iteration 1325/3000 [0m                     

                       Computation: 89580 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.6174
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8875
                     Learning rate: 0.0004
                       Mean reward: 125.00
               Mean episode length: 986.57
       Episode_Reward/keep_balance: 0.9921
     Episode_Reward/rew_lin_vel_xy: 6.0177
      Episode_Reward/rew_ang_vel_z: 2.4531
    Episode_Reward/pen_base_height: -0.3099
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1765
   Episode_Reward/pen_joint_torque: -0.2375
    Episode_Reward/pen_joint_accel: -0.1230
    Episode_Reward/pen_action_rate: -0.1227
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0927
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2634
Episode_Reward/pen_flat_orientation: -0.1131
  Episode_Reward/pen_feet_distance: -0.0207
Episode_Reward/pen_feet_regulation: -0.4888
   Episode_Reward/foot_landing_vel: -0.1350
   Episode_Reward/test_gait_reward: -0.9616
Metrics/base_velocity/error_vel_xy: 1.0666
Metrics/base_velocity/error_vel_yaw: 1.3580
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 1.10s
                        Total time: 1444.63s
                               ETA: 1824.9s

################################################################################
                     [1m Learning iteration 1326/3000 [0m                     

                       Computation: 90001 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.5476
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8860
                     Learning rate: 0.0003
                       Mean reward: 124.16
               Mean episode length: 990.22
       Episode_Reward/keep_balance: 0.9815
     Episode_Reward/rew_lin_vel_xy: 5.9175
      Episode_Reward/rew_ang_vel_z: 2.4129
    Episode_Reward/pen_base_height: -0.3183
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1834
   Episode_Reward/pen_joint_torque: -0.2302
    Episode_Reward/pen_joint_accel: -0.1207
    Episode_Reward/pen_action_rate: -0.1220
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2620
Episode_Reward/pen_flat_orientation: -0.1177
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4921
   Episode_Reward/foot_landing_vel: -0.1395
   Episode_Reward/test_gait_reward: -0.9532
Metrics/base_velocity/error_vel_xy: 1.0738
Metrics/base_velocity/error_vel_yaw: 1.3676
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 1.09s
                        Total time: 1445.73s
                               ETA: 1823.8s

################################################################################
                     [1m Learning iteration 1327/3000 [0m                     

                       Computation: 89642 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.5985
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8846
                     Learning rate: 0.0004
                       Mean reward: 120.84
               Mean episode length: 979.92
       Episode_Reward/keep_balance: 0.9811
     Episode_Reward/rew_lin_vel_xy: 5.8756
      Episode_Reward/rew_ang_vel_z: 2.3388
    Episode_Reward/pen_base_height: -0.3250
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1901
   Episode_Reward/pen_joint_torque: -0.2273
    Episode_Reward/pen_joint_accel: -0.1261
    Episode_Reward/pen_action_rate: -0.1262
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0626
   Episode_Reward/pen_joint_powers: -0.0947
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2722
Episode_Reward/pen_flat_orientation: -0.1165
  Episode_Reward/pen_feet_distance: -0.0219
Episode_Reward/pen_feet_regulation: -0.5281
   Episode_Reward/foot_landing_vel: -0.1361
   Episode_Reward/test_gait_reward: -0.9674
Metrics/base_velocity/error_vel_xy: 1.1184
Metrics/base_velocity/error_vel_yaw: 1.4537
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 1.10s
                        Total time: 1446.82s
                               ETA: 1822.7s

################################################################################
                     [1m Learning iteration 1328/3000 [0m                     

                       Computation: 90322 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.6091
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8839
                     Learning rate: 0.0006
                       Mean reward: 128.18
               Mean episode length: 966.62
       Episode_Reward/keep_balance: 0.9556
     Episode_Reward/rew_lin_vel_xy: 5.9219
      Episode_Reward/rew_ang_vel_z: 2.4217
    Episode_Reward/pen_base_height: -0.2980
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1679
   Episode_Reward/pen_joint_torque: -0.2256
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2483
Episode_Reward/pen_flat_orientation: -0.1073
  Episode_Reward/pen_feet_distance: -0.0210
Episode_Reward/pen_feet_regulation: -0.4324
   Episode_Reward/foot_landing_vel: -0.1357
   Episode_Reward/test_gait_reward: -0.9121
Metrics/base_velocity/error_vel_xy: 0.9734
Metrics/base_velocity/error_vel_yaw: 1.2591
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 1.09s
                        Total time: 1447.91s
                               ETA: 1821.6s

################################################################################
                     [1m Learning iteration 1329/3000 [0m                     

                       Computation: 90967 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 0.6649
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8834
                     Learning rate: 0.0002
                       Mean reward: 125.99
               Mean episode length: 968.81
       Episode_Reward/keep_balance: 0.9657
     Episode_Reward/rew_lin_vel_xy: 5.9266
      Episode_Reward/rew_ang_vel_z: 2.3628
    Episode_Reward/pen_base_height: -0.3022
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1717
   Episode_Reward/pen_joint_torque: -0.2253
    Episode_Reward/pen_joint_accel: -0.1074
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2559
Episode_Reward/pen_flat_orientation: -0.1043
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4526
   Episode_Reward/foot_landing_vel: -0.1362
   Episode_Reward/test_gait_reward: -0.9260
Metrics/base_velocity/error_vel_xy: 1.0058
Metrics/base_velocity/error_vel_yaw: 1.3458
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 1.08s
                        Total time: 1448.99s
                               ETA: 1820.5s

################################################################################
                     [1m Learning iteration 1330/3000 [0m                     

                       Computation: 88334 steps/s (collection: 0.989s, learning 0.124s)
               Value function loss: 0.5867
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8824
                     Learning rate: 0.0006
                       Mean reward: 124.38
               Mean episode length: 978.71
       Episode_Reward/keep_balance: 0.9745
     Episode_Reward/rew_lin_vel_xy: 5.8946
      Episode_Reward/rew_ang_vel_z: 2.4083
    Episode_Reward/pen_base_height: -0.3154
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1748
   Episode_Reward/pen_joint_torque: -0.2321
    Episode_Reward/pen_joint_accel: -0.1193
    Episode_Reward/pen_action_rate: -0.1202
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2580
Episode_Reward/pen_flat_orientation: -0.1085
  Episode_Reward/pen_feet_distance: -0.0216
Episode_Reward/pen_feet_regulation: -0.4797
   Episode_Reward/foot_landing_vel: -0.1449
   Episode_Reward/test_gait_reward: -0.9343
Metrics/base_velocity/error_vel_xy: 1.0520
Metrics/base_velocity/error_vel_yaw: 1.3285
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 1.11s
                        Total time: 1450.10s
                               ETA: 1819.4s

################################################################################
                     [1m Learning iteration 1331/3000 [0m                     

                       Computation: 92439 steps/s (collection: 0.940s, learning 0.124s)
               Value function loss: 0.6299
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8826
                     Learning rate: 0.0006
                       Mean reward: 125.71
               Mean episode length: 982.16
       Episode_Reward/keep_balance: 0.9842
     Episode_Reward/rew_lin_vel_xy: 6.0174
      Episode_Reward/rew_ang_vel_z: 2.4350
    Episode_Reward/pen_base_height: -0.2955
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1753
   Episode_Reward/pen_joint_torque: -0.2195
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.1198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2611
Episode_Reward/pen_flat_orientation: -0.1086
  Episode_Reward/pen_feet_distance: -0.0237
Episode_Reward/pen_feet_regulation: -0.4647
   Episode_Reward/foot_landing_vel: -0.1528
   Episode_Reward/test_gait_reward: -0.9385
Metrics/base_velocity/error_vel_xy: 1.0381
Metrics/base_velocity/error_vel_yaw: 1.3512
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 1.06s
                        Total time: 1451.17s
                               ETA: 1818.3s

################################################################################
                     [1m Learning iteration 1332/3000 [0m                     

                       Computation: 89671 steps/s (collection: 0.975s, learning 0.122s)
               Value function loss: 0.6306
                    Surrogate loss: 0.0005
             Mean action noise std: 0.8819
                     Learning rate: 0.0001
                       Mean reward: 129.47
               Mean episode length: 991.49
       Episode_Reward/keep_balance: 0.9880
     Episode_Reward/rew_lin_vel_xy: 6.0765
      Episode_Reward/rew_ang_vel_z: 2.4486
    Episode_Reward/pen_base_height: -0.3223
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1707
   Episode_Reward/pen_joint_torque: -0.2353
    Episode_Reward/pen_joint_accel: -0.1081
    Episode_Reward/pen_action_rate: -0.1215
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0916
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2615
Episode_Reward/pen_flat_orientation: -0.1122
  Episode_Reward/pen_feet_distance: -0.0211
Episode_Reward/pen_feet_regulation: -0.4722
   Episode_Reward/foot_landing_vel: -0.1362
   Episode_Reward/test_gait_reward: -0.9575
Metrics/base_velocity/error_vel_xy: 1.0170
Metrics/base_velocity/error_vel_yaw: 1.3612
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 1.10s
                        Total time: 1452.26s
                               ETA: 1817.2s

################################################################################
                     [1m Learning iteration 1333/3000 [0m                     

                       Computation: 89253 steps/s (collection: 0.979s, learning 0.122s)
               Value function loss: 0.5573
                    Surrogate loss: -0.0006
             Mean action noise std: 0.8820
                     Learning rate: 0.0001
                       Mean reward: 128.77
               Mean episode length: 979.35
       Episode_Reward/keep_balance: 0.9851
     Episode_Reward/rew_lin_vel_xy: 6.0668
      Episode_Reward/rew_ang_vel_z: 2.4505
    Episode_Reward/pen_base_height: -0.3240
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1748
   Episode_Reward/pen_joint_torque: -0.2250
    Episode_Reward/pen_joint_accel: -0.1066
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2594
Episode_Reward/pen_flat_orientation: -0.1061
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4671
   Episode_Reward/foot_landing_vel: -0.1264
   Episode_Reward/test_gait_reward: -0.9415
Metrics/base_velocity/error_vel_xy: 1.0174
Metrics/base_velocity/error_vel_yaw: 1.3474
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 1.10s
                        Total time: 1453.36s
                               ETA: 1816.2s

################################################################################
                     [1m Learning iteration 1334/3000 [0m                     

                       Computation: 90603 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 0.6435
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8819
                     Learning rate: 0.0001
                       Mean reward: 127.78
               Mean episode length: 986.18
       Episode_Reward/keep_balance: 0.9920
     Episode_Reward/rew_lin_vel_xy: 6.0715
      Episode_Reward/rew_ang_vel_z: 2.5088
    Episode_Reward/pen_base_height: -0.3261
      Episode_Reward/pen_lin_vel_z: -0.0425
     Episode_Reward/pen_ang_vel_xy: -0.1760
   Episode_Reward/pen_joint_torque: -0.2311
    Episode_Reward/pen_joint_accel: -0.1241
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0918
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2607
Episode_Reward/pen_flat_orientation: -0.1081
  Episode_Reward/pen_feet_distance: -0.0195
Episode_Reward/pen_feet_regulation: -0.4851
   Episode_Reward/foot_landing_vel: -0.1490
   Episode_Reward/test_gait_reward: -0.9583
Metrics/base_velocity/error_vel_xy: 1.0489
Metrics/base_velocity/error_vel_yaw: 1.3130
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 1.08s
                        Total time: 1454.45s
                               ETA: 1815.1s

################################################################################
                     [1m Learning iteration 1335/3000 [0m                     

                       Computation: 88366 steps/s (collection: 0.990s, learning 0.123s)
               Value function loss: 0.5785
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8802
                     Learning rate: 0.0003
                       Mean reward: 126.44
               Mean episode length: 978.08
       Episode_Reward/keep_balance: 0.9752
     Episode_Reward/rew_lin_vel_xy: 5.9981
      Episode_Reward/rew_ang_vel_z: 2.3749
    Episode_Reward/pen_base_height: -0.2975
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1787
   Episode_Reward/pen_joint_torque: -0.2217
    Episode_Reward/pen_joint_accel: -0.1086
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2598
Episode_Reward/pen_flat_orientation: -0.1124
  Episode_Reward/pen_feet_distance: -0.0153
Episode_Reward/pen_feet_regulation: -0.4693
   Episode_Reward/foot_landing_vel: -0.1422
   Episode_Reward/test_gait_reward: -0.9371
Metrics/base_velocity/error_vel_xy: 1.0123
Metrics/base_velocity/error_vel_yaw: 1.3928
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 1.11s
                        Total time: 1455.56s
                               ETA: 1814.0s

################################################################################
                     [1m Learning iteration 1336/3000 [0m                     

                       Computation: 90483 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.5722
                    Surrogate loss: -0.0055
             Mean action noise std: 0.8796
                     Learning rate: 0.0006
                       Mean reward: 128.49
               Mean episode length: 990.33
       Episode_Reward/keep_balance: 0.9875
     Episode_Reward/rew_lin_vel_xy: 6.0288
      Episode_Reward/rew_ang_vel_z: 2.4253
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1759
   Episode_Reward/pen_joint_torque: -0.2305
    Episode_Reward/pen_joint_accel: -0.1144
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2600
Episode_Reward/pen_flat_orientation: -0.1090
  Episode_Reward/pen_feet_distance: -0.0255
Episode_Reward/pen_feet_regulation: -0.4834
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9501
Metrics/base_velocity/error_vel_xy: 1.0432
Metrics/base_velocity/error_vel_yaw: 1.3700
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 1.09s
                        Total time: 1456.65s
                               ETA: 1812.9s

################################################################################
                     [1m Learning iteration 1337/3000 [0m                     

                       Computation: 89846 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.6232
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8814
                     Learning rate: 0.0004
                       Mean reward: 124.89
               Mean episode length: 979.39
       Episode_Reward/keep_balance: 0.9838
     Episode_Reward/rew_lin_vel_xy: 6.0162
      Episode_Reward/rew_ang_vel_z: 2.3826
    Episode_Reward/pen_base_height: -0.3100
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.1808
   Episode_Reward/pen_joint_torque: -0.2252
    Episode_Reward/pen_joint_accel: -0.1138
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2612
Episode_Reward/pen_flat_orientation: -0.1077
  Episode_Reward/pen_feet_distance: -0.0182
Episode_Reward/pen_feet_regulation: -0.4547
   Episode_Reward/foot_landing_vel: -0.1351
   Episode_Reward/test_gait_reward: -0.9522
Metrics/base_velocity/error_vel_xy: 1.0365
Metrics/base_velocity/error_vel_yaw: 1.4003
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 1.09s
                        Total time: 1457.74s
                               ETA: 1811.8s

################################################################################
                     [1m Learning iteration 1338/3000 [0m                     

                       Computation: 90641 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.5799
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8812
                     Learning rate: 0.0004
                       Mean reward: 129.11
               Mean episode length: 985.53
       Episode_Reward/keep_balance: 0.9789
     Episode_Reward/rew_lin_vel_xy: 6.0453
      Episode_Reward/rew_ang_vel_z: 2.4262
    Episode_Reward/pen_base_height: -0.3147
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1757
   Episode_Reward/pen_joint_torque: -0.2252
    Episode_Reward/pen_joint_accel: -0.1163
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0595
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2552
Episode_Reward/pen_flat_orientation: -0.1061
  Episode_Reward/pen_feet_distance: -0.0227
Episode_Reward/pen_feet_regulation: -0.4734
   Episode_Reward/foot_landing_vel: -0.1400
   Episode_Reward/test_gait_reward: -0.9367
Metrics/base_velocity/error_vel_xy: 1.0131
Metrics/base_velocity/error_vel_yaw: 1.3353
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 1.08s
                        Total time: 1458.83s
                               ETA: 1810.7s

################################################################################
                     [1m Learning iteration 1339/3000 [0m                     

                       Computation: 92326 steps/s (collection: 0.943s, learning 0.122s)
               Value function loss: 0.5570
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8801
                     Learning rate: 0.0006
                       Mean reward: 125.04
               Mean episode length: 975.36
       Episode_Reward/keep_balance: 0.9864
     Episode_Reward/rew_lin_vel_xy: 6.0020
      Episode_Reward/rew_ang_vel_z: 2.4315
    Episode_Reward/pen_base_height: -0.3198
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1766
   Episode_Reward/pen_joint_torque: -0.2361
    Episode_Reward/pen_joint_accel: -0.1220
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2597
Episode_Reward/pen_flat_orientation: -0.1096
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4821
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9475
Metrics/base_velocity/error_vel_xy: 1.0540
Metrics/base_velocity/error_vel_yaw: 1.3553
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 1.06s
                        Total time: 1459.89s
                               ETA: 1809.6s

################################################################################
                     [1m Learning iteration 1340/3000 [0m                     

                       Computation: 89960 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.5653
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8792
                     Learning rate: 0.0006
                       Mean reward: 124.50
               Mean episode length: 975.98
       Episode_Reward/keep_balance: 0.9719
     Episode_Reward/rew_lin_vel_xy: 5.9378
      Episode_Reward/rew_ang_vel_z: 2.4129
    Episode_Reward/pen_base_height: -0.3164
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1777
   Episode_Reward/pen_joint_torque: -0.2352
    Episode_Reward/pen_joint_accel: -0.1058
    Episode_Reward/pen_action_rate: -0.1178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0593
   Episode_Reward/pen_joint_powers: -0.0922
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2520
Episode_Reward/pen_flat_orientation: -0.1112
  Episode_Reward/pen_feet_distance: -0.0230
Episode_Reward/pen_feet_regulation: -0.4863
   Episode_Reward/foot_landing_vel: -0.1426
   Episode_Reward/test_gait_reward: -0.9335
Metrics/base_velocity/error_vel_xy: 1.0289
Metrics/base_velocity/error_vel_yaw: 1.3244
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 1.09s
                        Total time: 1460.98s
                               ETA: 1808.5s

################################################################################
                     [1m Learning iteration 1341/3000 [0m                     

                       Computation: 89686 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.6398
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8792
                     Learning rate: 0.0003
                       Mean reward: 124.55
               Mean episode length: 979.48
       Episode_Reward/keep_balance: 0.9836
     Episode_Reward/rew_lin_vel_xy: 5.9788
      Episode_Reward/rew_ang_vel_z: 2.3980
    Episode_Reward/pen_base_height: -0.3101
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1796
   Episode_Reward/pen_joint_torque: -0.2333
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1230
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0617
   Episode_Reward/pen_joint_powers: -0.0936
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2632
Episode_Reward/pen_flat_orientation: -0.1161
  Episode_Reward/pen_feet_distance: -0.0233
Episode_Reward/pen_feet_regulation: -0.4958
   Episode_Reward/foot_landing_vel: -0.1555
   Episode_Reward/test_gait_reward: -0.9533
Metrics/base_velocity/error_vel_xy: 1.0545
Metrics/base_velocity/error_vel_yaw: 1.3917
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 1.10s
                        Total time: 1462.08s
                               ETA: 1807.4s

################################################################################
                     [1m Learning iteration 1342/3000 [0m                     

                       Computation: 90971 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.6451
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8793
                     Learning rate: 0.0006
                       Mean reward: 125.08
               Mean episode length: 976.16
       Episode_Reward/keep_balance: 0.9793
     Episode_Reward/rew_lin_vel_xy: 5.9968
      Episode_Reward/rew_ang_vel_z: 2.4256
    Episode_Reward/pen_base_height: -0.3197
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.1717
   Episode_Reward/pen_joint_torque: -0.2348
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2545
Episode_Reward/pen_flat_orientation: -0.1064
  Episode_Reward/pen_feet_distance: -0.0197
Episode_Reward/pen_feet_regulation: -0.4755
   Episode_Reward/foot_landing_vel: -0.1349
   Episode_Reward/test_gait_reward: -0.9386
Metrics/base_velocity/error_vel_xy: 1.0306
Metrics/base_velocity/error_vel_yaw: 1.3434
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 1.08s
                        Total time: 1463.16s
                               ETA: 1806.3s

################################################################################
                     [1m Learning iteration 1343/3000 [0m                     

                       Computation: 89302 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.5147
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8803
                     Learning rate: 0.0003
                       Mean reward: 129.28
               Mean episode length: 989.41
       Episode_Reward/keep_balance: 0.9890
     Episode_Reward/rew_lin_vel_xy: 6.1272
      Episode_Reward/rew_ang_vel_z: 2.4613
    Episode_Reward/pen_base_height: -0.3143
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1777
   Episode_Reward/pen_joint_torque: -0.2321
    Episode_Reward/pen_joint_accel: -0.1131
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2578
Episode_Reward/pen_flat_orientation: -0.1109
  Episode_Reward/pen_feet_distance: -0.0210
Episode_Reward/pen_feet_regulation: -0.4708
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.9492
Metrics/base_velocity/error_vel_xy: 0.9944
Metrics/base_velocity/error_vel_yaw: 1.3392
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 1.10s
                        Total time: 1464.26s
                               ETA: 1805.3s

################################################################################
                     [1m Learning iteration 1344/3000 [0m                     

                       Computation: 89519 steps/s (collection: 0.976s, learning 0.122s)
               Value function loss: 0.5758
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8793
                     Learning rate: 0.0006
                       Mean reward: 122.02
               Mean episode length: 967.26
       Episode_Reward/keep_balance: 0.9438
     Episode_Reward/rew_lin_vel_xy: 5.6772
      Episode_Reward/rew_ang_vel_z: 2.3232
    Episode_Reward/pen_base_height: -0.3042
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1698
   Episode_Reward/pen_joint_torque: -0.2195
    Episode_Reward/pen_joint_accel: -0.1072
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2481
Episode_Reward/pen_flat_orientation: -0.1082
  Episode_Reward/pen_feet_distance: -0.0186
Episode_Reward/pen_feet_regulation: -0.4665
   Episode_Reward/foot_landing_vel: -0.1352
   Episode_Reward/test_gait_reward: -0.9120
Metrics/base_velocity/error_vel_xy: 1.0442
Metrics/base_velocity/error_vel_yaw: 1.3126
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 1.10s
                        Total time: 1465.36s
                               ETA: 1804.2s

################################################################################
                     [1m Learning iteration 1345/3000 [0m                     

                       Computation: 90569 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 0.5613
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8780
                     Learning rate: 0.0004
                       Mean reward: 128.21
               Mean episode length: 994.27
       Episode_Reward/keep_balance: 0.9927
     Episode_Reward/rew_lin_vel_xy: 6.0742
      Episode_Reward/rew_ang_vel_z: 2.4479
    Episode_Reward/pen_base_height: -0.3253
      Episode_Reward/pen_lin_vel_z: -0.0399
     Episode_Reward/pen_ang_vel_xy: -0.1733
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.1213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2597
Episode_Reward/pen_flat_orientation: -0.1112
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4901
   Episode_Reward/foot_landing_vel: -0.1374
   Episode_Reward/test_gait_reward: -0.9601
Metrics/base_velocity/error_vel_xy: 1.0467
Metrics/base_velocity/error_vel_yaw: 1.3586
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 1.09s
                        Total time: 1466.45s
                               ETA: 1803.1s

################################################################################
                     [1m Learning iteration 1346/3000 [0m                     

                       Computation: 89990 steps/s (collection: 0.971s, learning 0.121s)
               Value function loss: 0.5470
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8777
                     Learning rate: 0.0006
                       Mean reward: 131.87
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.2005
      Episode_Reward/rew_ang_vel_z: 2.4816
    Episode_Reward/pen_base_height: -0.3151
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1729
   Episode_Reward/pen_joint_torque: -0.2328
    Episode_Reward/pen_joint_accel: -0.1148
    Episode_Reward/pen_action_rate: -0.1198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2591
Episode_Reward/pen_flat_orientation: -0.1016
  Episode_Reward/pen_feet_distance: -0.0180
Episode_Reward/pen_feet_regulation: -0.4679
   Episode_Reward/foot_landing_vel: -0.1394
   Episode_Reward/test_gait_reward: -0.9537
Metrics/base_velocity/error_vel_xy: 1.0147
Metrics/base_velocity/error_vel_yaw: 1.3578
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 1.09s
                        Total time: 1467.54s
                               ETA: 1802.0s

################################################################################
                     [1m Learning iteration 1347/3000 [0m                     

                       Computation: 90901 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.6248
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8778
                     Learning rate: 0.0004
                       Mean reward: 123.04
               Mean episode length: 953.88
       Episode_Reward/keep_balance: 0.9673
     Episode_Reward/rew_lin_vel_xy: 5.9559
      Episode_Reward/rew_ang_vel_z: 2.4312
    Episode_Reward/pen_base_height: -0.2960
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1727
   Episode_Reward/pen_joint_torque: -0.2336
    Episode_Reward/pen_joint_accel: -0.1005
    Episode_Reward/pen_action_rate: -0.1170
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2494
Episode_Reward/pen_flat_orientation: -0.1098
  Episode_Reward/pen_feet_distance: -0.0212
Episode_Reward/pen_feet_regulation: -0.4626
   Episode_Reward/foot_landing_vel: -0.1293
   Episode_Reward/test_gait_reward: -0.9258
Metrics/base_velocity/error_vel_xy: 0.9956
Metrics/base_velocity/error_vel_yaw: 1.2992
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 1.08s
                        Total time: 1468.62s
                               ETA: 1800.9s

################################################################################
                     [1m Learning iteration 1348/3000 [0m                     

                       Computation: 90904 steps/s (collection: 0.960s, learning 0.121s)
               Value function loss: 0.5567
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8763
                     Learning rate: 0.0004
                       Mean reward: 128.75
               Mean episode length: 976.82
       Episode_Reward/keep_balance: 0.9693
     Episode_Reward/rew_lin_vel_xy: 5.9917
      Episode_Reward/rew_ang_vel_z: 2.3904
    Episode_Reward/pen_base_height: -0.2951
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1683
   Episode_Reward/pen_joint_torque: -0.2176
    Episode_Reward/pen_joint_accel: -0.1105
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2525
Episode_Reward/pen_flat_orientation: -0.1056
  Episode_Reward/pen_feet_distance: -0.0180
Episode_Reward/pen_feet_regulation: -0.4523
   Episode_Reward/foot_landing_vel: -0.1387
   Episode_Reward/test_gait_reward: -0.9250
Metrics/base_velocity/error_vel_xy: 0.9859
Metrics/base_velocity/error_vel_yaw: 1.3438
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 1.08s
                        Total time: 1469.70s
                               ETA: 1799.8s

################################################################################
                     [1m Learning iteration 1349/3000 [0m                     

                       Computation: 90205 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.5616
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8759
                     Learning rate: 0.0001
                       Mean reward: 125.87
               Mean episode length: 970.15
       Episode_Reward/keep_balance: 0.9347
     Episode_Reward/rew_lin_vel_xy: 5.7024
      Episode_Reward/rew_ang_vel_z: 2.3005
    Episode_Reward/pen_base_height: -0.2862
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1722
   Episode_Reward/pen_joint_torque: -0.2109
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.1134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0848
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2451
Episode_Reward/pen_flat_orientation: -0.1078
  Episode_Reward/pen_feet_distance: -0.0191
Episode_Reward/pen_feet_regulation: -0.4634
   Episode_Reward/foot_landing_vel: -0.1317
   Episode_Reward/test_gait_reward: -0.8942
Metrics/base_velocity/error_vel_xy: 0.9864
Metrics/base_velocity/error_vel_yaw: 1.3044
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 1.09s
                        Total time: 1470.79s
                               ETA: 1798.7s

################################################################################
                     [1m Learning iteration 1350/3000 [0m                     

                       Computation: 90628 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.6037
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8765
                     Learning rate: 0.0003
                       Mean reward: 127.90
               Mean episode length: 975.95
       Episode_Reward/keep_balance: 0.9822
     Episode_Reward/rew_lin_vel_xy: 6.0297
      Episode_Reward/rew_ang_vel_z: 2.4696
    Episode_Reward/pen_base_height: -0.3033
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1775
   Episode_Reward/pen_joint_torque: -0.2222
    Episode_Reward/pen_joint_accel: -0.1161
    Episode_Reward/pen_action_rate: -0.1172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2548
Episode_Reward/pen_flat_orientation: -0.1050
  Episode_Reward/pen_feet_distance: -0.0173
Episode_Reward/pen_feet_regulation: -0.4657
   Episode_Reward/foot_landing_vel: -0.1385
   Episode_Reward/test_gait_reward: -0.9313
Metrics/base_velocity/error_vel_xy: 1.0251
Metrics/base_velocity/error_vel_yaw: 1.3106
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 1.08s
                        Total time: 1471.88s
                               ETA: 1797.6s

################################################################################
                     [1m Learning iteration 1351/3000 [0m                     

                       Computation: 89680 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.5254
                    Surrogate loss: -0.0056
             Mean action noise std: 0.8751
                     Learning rate: 0.0004
                       Mean reward: 127.55
               Mean episode length: 979.28
       Episode_Reward/keep_balance: 0.9774
     Episode_Reward/rew_lin_vel_xy: 6.0400
      Episode_Reward/rew_ang_vel_z: 2.4444
    Episode_Reward/pen_base_height: -0.3050
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1733
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1066
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2536
Episode_Reward/pen_flat_orientation: -0.1062
  Episode_Reward/pen_feet_distance: -0.0194
Episode_Reward/pen_feet_regulation: -0.4739
   Episode_Reward/foot_landing_vel: -0.1398
   Episode_Reward/test_gait_reward: -0.9321
Metrics/base_velocity/error_vel_xy: 1.0061
Metrics/base_velocity/error_vel_yaw: 1.3201
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 1.10s
                        Total time: 1472.97s
                               ETA: 1796.5s

################################################################################
                     [1m Learning iteration 1352/3000 [0m                     

                       Computation: 90257 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.6270
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8754
                     Learning rate: 0.0009
                       Mean reward: 128.50
               Mean episode length: 981.81
       Episode_Reward/keep_balance: 0.9807
     Episode_Reward/rew_lin_vel_xy: 6.0071
      Episode_Reward/rew_ang_vel_z: 2.4628
    Episode_Reward/pen_base_height: -0.3118
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1762
   Episode_Reward/pen_joint_torque: -0.2298
    Episode_Reward/pen_joint_accel: -0.1130
    Episode_Reward/pen_action_rate: -0.1179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2527
Episode_Reward/pen_flat_orientation: -0.1086
  Episode_Reward/pen_feet_distance: -0.0247
Episode_Reward/pen_feet_regulation: -0.4871
   Episode_Reward/foot_landing_vel: -0.1439
   Episode_Reward/test_gait_reward: -0.9429
Metrics/base_velocity/error_vel_xy: 1.0291
Metrics/base_velocity/error_vel_yaw: 1.3069
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 1.09s
                        Total time: 1474.06s
                               ETA: 1795.5s

################################################################################
                     [1m Learning iteration 1353/3000 [0m                     

                       Computation: 90680 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.6486
                    Surrogate loss: 0.0042
             Mean action noise std: 0.8758
                     Learning rate: 0.0001
                       Mean reward: 123.97
               Mean episode length: 952.31
       Episode_Reward/keep_balance: 0.9582
     Episode_Reward/rew_lin_vel_xy: 5.9120
      Episode_Reward/rew_ang_vel_z: 2.3295
    Episode_Reward/pen_base_height: -0.3026
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1718
   Episode_Reward/pen_joint_torque: -0.2207
    Episode_Reward/pen_joint_accel: -0.1180
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2515
Episode_Reward/pen_flat_orientation: -0.1087
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4844
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.9146
Metrics/base_velocity/error_vel_xy: 0.9894
Metrics/base_velocity/error_vel_yaw: 1.3594
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 1.08s
                        Total time: 1475.14s
                               ETA: 1794.4s

################################################################################
                     [1m Learning iteration 1354/3000 [0m                     

                       Computation: 92095 steps/s (collection: 0.944s, learning 0.123s)
               Value function loss: 0.5761
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8752
                     Learning rate: 0.0003
                       Mean reward: 122.57
               Mean episode length: 934.90
       Episode_Reward/keep_balance: 0.9368
     Episode_Reward/rew_lin_vel_xy: 5.7750
      Episode_Reward/rew_ang_vel_z: 2.3723
    Episode_Reward/pen_base_height: -0.2986
      Episode_Reward/pen_lin_vel_z: -0.0389
     Episode_Reward/pen_ang_vel_xy: -0.1623
   Episode_Reward/pen_joint_torque: -0.2267
    Episode_Reward/pen_joint_accel: -0.1200
    Episode_Reward/pen_action_rate: -0.1128
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2401
Episode_Reward/pen_flat_orientation: -0.1021
  Episode_Reward/pen_feet_distance: -0.0169
Episode_Reward/pen_feet_regulation: -0.4522
   Episode_Reward/foot_landing_vel: -0.1436
   Episode_Reward/test_gait_reward: -0.8903
Metrics/base_velocity/error_vel_xy: 0.9644
Metrics/base_velocity/error_vel_yaw: 1.2377
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 1.07s
                        Total time: 1476.21s
                               ETA: 1793.2s

################################################################################
                     [1m Learning iteration 1355/3000 [0m                     

                       Computation: 90444 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.6901
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8746
                     Learning rate: 0.0006
                       Mean reward: 128.08
               Mean episode length: 983.54
       Episode_Reward/keep_balance: 0.9866
     Episode_Reward/rew_lin_vel_xy: 6.0142
      Episode_Reward/rew_ang_vel_z: 2.4355
    Episode_Reward/pen_base_height: -0.3093
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1704
   Episode_Reward/pen_joint_torque: -0.2318
    Episode_Reward/pen_joint_accel: -0.1074
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2560
Episode_Reward/pen_flat_orientation: -0.1084
  Episode_Reward/pen_feet_distance: -0.0203
Episode_Reward/pen_feet_regulation: -0.4780
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.9418
Metrics/base_velocity/error_vel_xy: 1.0467
Metrics/base_velocity/error_vel_yaw: 1.3587
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 1.09s
                        Total time: 1477.30s
                               ETA: 1792.2s

################################################################################
                     [1m Learning iteration 1356/3000 [0m                     

                       Computation: 90317 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 0.5534
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8729
                     Learning rate: 0.0004
                       Mean reward: 127.23
               Mean episode length: 981.78
       Episode_Reward/keep_balance: 0.9833
     Episode_Reward/rew_lin_vel_xy: 6.0991
      Episode_Reward/rew_ang_vel_z: 2.4227
    Episode_Reward/pen_base_height: -0.3123
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1792
   Episode_Reward/pen_joint_torque: -0.2251
    Episode_Reward/pen_joint_accel: -0.1123
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2587
Episode_Reward/pen_flat_orientation: -0.1045
  Episode_Reward/pen_feet_distance: -0.0181
Episode_Reward/pen_feet_regulation: -0.4576
   Episode_Reward/foot_landing_vel: -0.1396
   Episode_Reward/test_gait_reward: -0.9402
Metrics/base_velocity/error_vel_xy: 0.9815
Metrics/base_velocity/error_vel_yaw: 1.3609
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 1.09s
                        Total time: 1478.39s
                               ETA: 1791.1s

################################################################################
                     [1m Learning iteration 1357/3000 [0m                     

                       Computation: 89701 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 0.6086
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8713
                     Learning rate: 0.0004
                       Mean reward: 128.02
               Mean episode length: 993.97
       Episode_Reward/keep_balance: 0.9937
     Episode_Reward/rew_lin_vel_xy: 6.0477
      Episode_Reward/rew_ang_vel_z: 2.4505
    Episode_Reward/pen_base_height: -0.3291
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1682
   Episode_Reward/pen_joint_torque: -0.2474
    Episode_Reward/pen_joint_accel: -0.1083
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0950
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2545
Episode_Reward/pen_flat_orientation: -0.1115
  Episode_Reward/pen_feet_distance: -0.0260
Episode_Reward/pen_feet_regulation: -0.4888
   Episode_Reward/foot_landing_vel: -0.1409
   Episode_Reward/test_gait_reward: -0.9545
Metrics/base_velocity/error_vel_xy: 1.0643
Metrics/base_velocity/error_vel_yaw: 1.3765
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 1.10s
                        Total time: 1479.48s
                               ETA: 1790.0s

################################################################################
                     [1m Learning iteration 1358/3000 [0m                     

                       Computation: 90576 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 0.5732
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8711
                     Learning rate: 0.0004
                       Mean reward: 127.31
               Mean episode length: 979.87
       Episode_Reward/keep_balance: 0.9868
     Episode_Reward/rew_lin_vel_xy: 6.0060
      Episode_Reward/rew_ang_vel_z: 2.4601
    Episode_Reward/pen_base_height: -0.3266
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1797
   Episode_Reward/pen_joint_torque: -0.2401
    Episode_Reward/pen_joint_accel: -0.1197
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0595
   Episode_Reward/pen_joint_powers: -0.0920
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2556
Episode_Reward/pen_flat_orientation: -0.1072
  Episode_Reward/pen_feet_distance: -0.0192
Episode_Reward/pen_feet_regulation: -0.4888
   Episode_Reward/foot_landing_vel: -0.1377
   Episode_Reward/test_gait_reward: -0.9483
Metrics/base_velocity/error_vel_xy: 1.0820
Metrics/base_velocity/error_vel_yaw: 1.3351
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 1.09s
                        Total time: 1480.57s
                               ETA: 1788.9s

################################################################################
                     [1m Learning iteration 1359/3000 [0m                     

                       Computation: 89425 steps/s (collection: 0.977s, learning 0.122s)
               Value function loss: 0.6148
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8726
                     Learning rate: 0.0006
                       Mean reward: 128.33
               Mean episode length: 977.75
       Episode_Reward/keep_balance: 0.9668
     Episode_Reward/rew_lin_vel_xy: 5.9638
      Episode_Reward/rew_ang_vel_z: 2.4060
    Episode_Reward/pen_base_height: -0.3192
      Episode_Reward/pen_lin_vel_z: -0.0415
     Episode_Reward/pen_ang_vel_xy: -0.1741
   Episode_Reward/pen_joint_torque: -0.2308
    Episode_Reward/pen_joint_accel: -0.1228
    Episode_Reward/pen_action_rate: -0.1177
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0591
   Episode_Reward/pen_joint_powers: -0.0910
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2525
Episode_Reward/pen_flat_orientation: -0.1076
  Episode_Reward/pen_feet_distance: -0.0211
Episode_Reward/pen_feet_regulation: -0.4720
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.9296
Metrics/base_velocity/error_vel_xy: 0.9904
Metrics/base_velocity/error_vel_yaw: 1.3185
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 1.10s
                        Total time: 1481.67s
                               ETA: 1787.8s

################################################################################
                     [1m Learning iteration 1360/3000 [0m                     

                       Computation: 89716 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 0.5923
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8735
                     Learning rate: 0.0006
                       Mean reward: 129.59
               Mean episode length: 966.37
       Episode_Reward/keep_balance: 0.9548
     Episode_Reward/rew_lin_vel_xy: 5.9127
      Episode_Reward/rew_ang_vel_z: 2.4462
    Episode_Reward/pen_base_height: -0.2963
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1669
   Episode_Reward/pen_joint_torque: -0.2233
    Episode_Reward/pen_joint_accel: -0.1155
    Episode_Reward/pen_action_rate: -0.1138
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2434
Episode_Reward/pen_flat_orientation: -0.1048
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4502
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.9124
Metrics/base_velocity/error_vel_xy: 0.9759
Metrics/base_velocity/error_vel_yaw: 1.2311
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 1.10s
                        Total time: 1482.76s
                               ETA: 1786.7s

################################################################################
                     [1m Learning iteration 1361/3000 [0m                     

                       Computation: 91110 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.6921
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8727
                     Learning rate: 0.0006
                       Mean reward: 129.47
               Mean episode length: 990.80
       Episode_Reward/keep_balance: 0.9923
     Episode_Reward/rew_lin_vel_xy: 6.1863
      Episode_Reward/rew_ang_vel_z: 2.4802
    Episode_Reward/pen_base_height: -0.3131
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1751
   Episode_Reward/pen_joint_torque: -0.2274
    Episode_Reward/pen_joint_accel: -0.1151
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2552
Episode_Reward/pen_flat_orientation: -0.1031
  Episode_Reward/pen_feet_distance: -0.0163
Episode_Reward/pen_feet_regulation: -0.4813
   Episode_Reward/foot_landing_vel: -0.1398
   Episode_Reward/test_gait_reward: -0.9462
Metrics/base_velocity/error_vel_xy: 0.9987
Metrics/base_velocity/error_vel_yaw: 1.3380
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 1.08s
                        Total time: 1483.84s
                               ETA: 1785.6s

################################################################################
                     [1m Learning iteration 1362/3000 [0m                     

                       Computation: 91107 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.5595
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8713
                     Learning rate: 0.0009
                       Mean reward: 126.41
               Mean episode length: 979.94
       Episode_Reward/keep_balance: 0.9812
     Episode_Reward/rew_lin_vel_xy: 6.0125
      Episode_Reward/rew_ang_vel_z: 2.4361
    Episode_Reward/pen_base_height: -0.3108
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1791
   Episode_Reward/pen_joint_torque: -0.2348
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0608
   Episode_Reward/pen_joint_powers: -0.0932
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2573
Episode_Reward/pen_flat_orientation: -0.1119
  Episode_Reward/pen_feet_distance: -0.0204
Episode_Reward/pen_feet_regulation: -0.4990
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.9470
Metrics/base_velocity/error_vel_xy: 1.0420
Metrics/base_velocity/error_vel_yaw: 1.3440
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 1.08s
                        Total time: 1484.92s
                               ETA: 1784.5s

################################################################################
                     [1m Learning iteration 1363/3000 [0m                     

                       Computation: 90915 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.5468
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8722
                     Learning rate: 0.0006
                       Mean reward: 132.17
               Mean episode length: 992.47
       Episode_Reward/keep_balance: 0.9896
     Episode_Reward/rew_lin_vel_xy: 6.1113
      Episode_Reward/rew_ang_vel_z: 2.4974
    Episode_Reward/pen_base_height: -0.3017
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1734
   Episode_Reward/pen_joint_torque: -0.2303
    Episode_Reward/pen_joint_accel: -0.1104
    Episode_Reward/pen_action_rate: -0.1179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2519
Episode_Reward/pen_flat_orientation: -0.0984
  Episode_Reward/pen_feet_distance: -0.0181
Episode_Reward/pen_feet_regulation: -0.4593
   Episode_Reward/foot_landing_vel: -0.1395
   Episode_Reward/test_gait_reward: -0.9360
Metrics/base_velocity/error_vel_xy: 1.0138
Metrics/base_velocity/error_vel_yaw: 1.3051
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 1.08s
                        Total time: 1486.00s
                               ETA: 1783.4s

################################################################################
                     [1m Learning iteration 1364/3000 [0m                     

                       Computation: 91241 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.6532
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8746
                     Learning rate: 0.0009
                       Mean reward: 128.01
               Mean episode length: 983.28
       Episode_Reward/keep_balance: 0.9877
     Episode_Reward/rew_lin_vel_xy: 6.1084
      Episode_Reward/rew_ang_vel_z: 2.4914
    Episode_Reward/pen_base_height: -0.3149
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1691
   Episode_Reward/pen_joint_torque: -0.2339
    Episode_Reward/pen_joint_accel: -0.1071
    Episode_Reward/pen_action_rate: -0.1174
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0899
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2517
Episode_Reward/pen_flat_orientation: -0.1067
  Episode_Reward/pen_feet_distance: -0.0189
Episode_Reward/pen_feet_regulation: -0.4629
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9376
Metrics/base_velocity/error_vel_xy: 1.0203
Metrics/base_velocity/error_vel_yaw: 1.3048
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 1.08s
                        Total time: 1487.08s
                               ETA: 1782.3s

################################################################################
                     [1m Learning iteration 1365/3000 [0m                     

                       Computation: 89241 steps/s (collection: 0.977s, learning 0.125s)
               Value function loss: 0.6845
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8749
                     Learning rate: 0.0006
                       Mean reward: 128.36
               Mean episode length: 978.09
       Episode_Reward/keep_balance: 0.9852
     Episode_Reward/rew_lin_vel_xy: 6.0445
      Episode_Reward/rew_ang_vel_z: 2.4898
    Episode_Reward/pen_base_height: -0.3204
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1714
   Episode_Reward/pen_joint_torque: -0.2360
    Episode_Reward/pen_joint_accel: -0.1185
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2527
Episode_Reward/pen_flat_orientation: -0.1051
  Episode_Reward/pen_feet_distance: -0.0222
Episode_Reward/pen_feet_regulation: -0.4700
   Episode_Reward/foot_landing_vel: -0.1440
   Episode_Reward/test_gait_reward: -0.9353
Metrics/base_velocity/error_vel_xy: 1.0292
Metrics/base_velocity/error_vel_yaw: 1.3076
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 1.10s
                        Total time: 1488.18s
                               ETA: 1781.2s

################################################################################
                     [1m Learning iteration 1366/3000 [0m                     

                       Computation: 90177 steps/s (collection: 0.964s, learning 0.127s)
               Value function loss: 0.5704
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8765
                     Learning rate: 0.0006
                       Mean reward: 124.14
               Mean episode length: 936.62
       Episode_Reward/keep_balance: 0.9479
     Episode_Reward/rew_lin_vel_xy: 5.8470
      Episode_Reward/rew_ang_vel_z: 2.3756
    Episode_Reward/pen_base_height: -0.3022
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1666
   Episode_Reward/pen_joint_torque: -0.2293
    Episode_Reward/pen_joint_accel: -0.1122
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2451
Episode_Reward/pen_flat_orientation: -0.1080
  Episode_Reward/pen_feet_distance: -0.0160
Episode_Reward/pen_feet_regulation: -0.4456
   Episode_Reward/foot_landing_vel: -0.1356
   Episode_Reward/test_gait_reward: -0.9071
Metrics/base_velocity/error_vel_xy: 0.9768
Metrics/base_velocity/error_vel_yaw: 1.2784
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 1.09s
                        Total time: 1489.27s
                               ETA: 1780.2s

################################################################################
                     [1m Learning iteration 1367/3000 [0m                     

                       Computation: 90774 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.6493
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8767
                     Learning rate: 0.0004
                       Mean reward: 133.79
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.2238
      Episode_Reward/rew_ang_vel_z: 2.5372
    Episode_Reward/pen_base_height: -0.2879
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1687
   Episode_Reward/pen_joint_torque: -0.2353
    Episode_Reward/pen_joint_accel: -0.1238
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2552
Episode_Reward/pen_flat_orientation: -0.1015
  Episode_Reward/pen_feet_distance: -0.0173
Episode_Reward/pen_feet_regulation: -0.4667
   Episode_Reward/foot_landing_vel: -0.1397
   Episode_Reward/test_gait_reward: -0.9401
Metrics/base_velocity/error_vel_xy: 1.0007
Metrics/base_velocity/error_vel_yaw: 1.3072
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 1.08s
                        Total time: 1490.35s
                               ETA: 1779.1s

################################################################################
                     [1m Learning iteration 1368/3000 [0m                     

                       Computation: 91866 steps/s (collection: 0.947s, learning 0.123s)
               Value function loss: 0.6200
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8763
                     Learning rate: 0.0006
                       Mean reward: 123.78
               Mean episode length: 957.52
       Episode_Reward/keep_balance: 0.9554
     Episode_Reward/rew_lin_vel_xy: 5.8614
      Episode_Reward/rew_ang_vel_z: 2.3815
    Episode_Reward/pen_base_height: -0.2864
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1700
   Episode_Reward/pen_joint_torque: -0.2125
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0855
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2494
Episode_Reward/pen_flat_orientation: -0.1078
  Episode_Reward/pen_feet_distance: -0.0187
Episode_Reward/pen_feet_regulation: -0.4507
   Episode_Reward/foot_landing_vel: -0.1341
   Episode_Reward/test_gait_reward: -0.9117
Metrics/base_velocity/error_vel_xy: 0.9989
Metrics/base_velocity/error_vel_yaw: 1.3067
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 1.07s
                        Total time: 1491.42s
                               ETA: 1777.9s

################################################################################
                     [1m Learning iteration 1369/3000 [0m                     

                       Computation: 89881 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.5972
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8763
                     Learning rate: 0.0006
                       Mean reward: 130.32
               Mean episode length: 990.57
       Episode_Reward/keep_balance: 0.9869
     Episode_Reward/rew_lin_vel_xy: 6.0771
      Episode_Reward/rew_ang_vel_z: 2.4480
    Episode_Reward/pen_base_height: -0.3017
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1782
   Episode_Reward/pen_joint_torque: -0.2219
    Episode_Reward/pen_joint_accel: -0.1182
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2585
Episode_Reward/pen_flat_orientation: -0.1029
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.4745
   Episode_Reward/foot_landing_vel: -0.1320
   Episode_Reward/test_gait_reward: -0.9423
Metrics/base_velocity/error_vel_xy: 1.0239
Metrics/base_velocity/error_vel_yaw: 1.3636
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 1.09s
                        Total time: 1492.52s
                               ETA: 1776.9s

################################################################################
                     [1m Learning iteration 1370/3000 [0m                     

                       Computation: 90457 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.6769
                    Surrogate loss: -0.0013
             Mean action noise std: 0.8771
                     Learning rate: 0.0001
                       Mean reward: 129.48
               Mean episode length: 975.55
       Episode_Reward/keep_balance: 0.9728
     Episode_Reward/rew_lin_vel_xy: 6.0561
      Episode_Reward/rew_ang_vel_z: 2.4436
    Episode_Reward/pen_base_height: -0.3024
      Episode_Reward/pen_lin_vel_z: -0.0399
     Episode_Reward/pen_ang_vel_xy: -0.1638
   Episode_Reward/pen_joint_torque: -0.2416
    Episode_Reward/pen_joint_accel: -0.1113
    Episode_Reward/pen_action_rate: -0.1172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2493
Episode_Reward/pen_flat_orientation: -0.1050
  Episode_Reward/pen_feet_distance: -0.0202
Episode_Reward/pen_feet_regulation: -0.4649
   Episode_Reward/foot_landing_vel: -0.1470
   Episode_Reward/test_gait_reward: -0.9275
Metrics/base_velocity/error_vel_xy: 0.9912
Metrics/base_velocity/error_vel_yaw: 1.3074
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 1.09s
                        Total time: 1493.61s
                               ETA: 1775.8s

################################################################################
                     [1m Learning iteration 1371/3000 [0m                     

                       Computation: 91376 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.6750
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8774
                     Learning rate: 0.0001
                       Mean reward: 122.42
               Mean episode length: 957.01
       Episode_Reward/keep_balance: 0.9326
     Episode_Reward/rew_lin_vel_xy: 5.6310
      Episode_Reward/rew_ang_vel_z: 2.3108
    Episode_Reward/pen_base_height: -0.3048
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1701
   Episode_Reward/pen_joint_torque: -0.2179
    Episode_Reward/pen_joint_accel: -0.1095
    Episode_Reward/pen_action_rate: -0.1133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2425
Episode_Reward/pen_flat_orientation: -0.1093
  Episode_Reward/pen_feet_distance: -0.0181
Episode_Reward/pen_feet_regulation: -0.4571
   Episode_Reward/foot_landing_vel: -0.1350
   Episode_Reward/test_gait_reward: -0.8969
Metrics/base_velocity/error_vel_xy: 1.0435
Metrics/base_velocity/error_vel_yaw: 1.3026
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 1.08s
                        Total time: 1494.68s
                               ETA: 1774.7s

################################################################################
                     [1m Learning iteration 1372/3000 [0m                     

                       Computation: 89772 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.6014
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8772
                     Learning rate: 0.0003
                       Mean reward: 126.50
               Mean episode length: 963.45
       Episode_Reward/keep_balance: 0.9660
     Episode_Reward/rew_lin_vel_xy: 5.9552
      Episode_Reward/rew_ang_vel_z: 2.3974
    Episode_Reward/pen_base_height: -0.2859
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1720
   Episode_Reward/pen_joint_torque: -0.2170
    Episode_Reward/pen_joint_accel: -0.1110
    Episode_Reward/pen_action_rate: -0.1167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2515
Episode_Reward/pen_flat_orientation: -0.1106
  Episode_Reward/pen_feet_distance: -0.0173
Episode_Reward/pen_feet_regulation: -0.4572
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.9163
Metrics/base_velocity/error_vel_xy: 0.9831
Metrics/base_velocity/error_vel_yaw: 1.3208
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 1.10s
                        Total time: 1495.78s
                               ETA: 1773.6s

################################################################################
                     [1m Learning iteration 1373/3000 [0m                     

                       Computation: 89530 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.5966
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8762
                     Learning rate: 0.0003
                       Mean reward: 126.79
               Mean episode length: 977.23
       Episode_Reward/keep_balance: 0.9689
     Episode_Reward/rew_lin_vel_xy: 5.9065
      Episode_Reward/rew_ang_vel_z: 2.4080
    Episode_Reward/pen_base_height: -0.2965
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.1779
   Episode_Reward/pen_joint_torque: -0.2275
    Episode_Reward/pen_joint_accel: -0.1133
    Episode_Reward/pen_action_rate: -0.1184
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0601
   Episode_Reward/pen_joint_powers: -0.0910
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2523
Episode_Reward/pen_flat_orientation: -0.1121
  Episode_Reward/pen_feet_distance: -0.0185
Episode_Reward/pen_feet_regulation: -0.4820
   Episode_Reward/foot_landing_vel: -0.1491
   Episode_Reward/test_gait_reward: -0.9242
Metrics/base_velocity/error_vel_xy: 1.0647
Metrics/base_velocity/error_vel_yaw: 1.3452
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 1.10s
                        Total time: 1496.87s
                               ETA: 1772.5s

################################################################################
                     [1m Learning iteration 1374/3000 [0m                     

                       Computation: 89689 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.6068
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8762
                     Learning rate: 0.0004
                       Mean reward: 124.28
               Mean episode length: 967.39
       Episode_Reward/keep_balance: 0.9749
     Episode_Reward/rew_lin_vel_xy: 6.0050
      Episode_Reward/rew_ang_vel_z: 2.4122
    Episode_Reward/pen_base_height: -0.3039
      Episode_Reward/pen_lin_vel_z: -0.0422
     Episode_Reward/pen_ang_vel_xy: -0.1720
   Episode_Reward/pen_joint_torque: -0.2353
    Episode_Reward/pen_joint_accel: -0.1083
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2535
Episode_Reward/pen_flat_orientation: -0.1077
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4803
   Episode_Reward/foot_landing_vel: -0.1373
   Episode_Reward/test_gait_reward: -0.9326
Metrics/base_velocity/error_vel_xy: 1.0166
Metrics/base_velocity/error_vel_yaw: 1.3377
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 1.10s
                        Total time: 1497.97s
                               ETA: 1771.4s

################################################################################
                     [1m Learning iteration 1375/3000 [0m                     

                       Computation: 90289 steps/s (collection: 0.964s, learning 0.125s)
               Value function loss: 0.5721
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8756
                     Learning rate: 0.0006
                       Mean reward: 127.44
               Mean episode length: 980.59
       Episode_Reward/keep_balance: 0.9814
     Episode_Reward/rew_lin_vel_xy: 6.0515
      Episode_Reward/rew_ang_vel_z: 2.4738
    Episode_Reward/pen_base_height: -0.3071
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1725
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2524
Episode_Reward/pen_flat_orientation: -0.1047
  Episode_Reward/pen_feet_distance: -0.0181
Episode_Reward/pen_feet_regulation: -0.4929
   Episode_Reward/foot_landing_vel: -0.1364
   Episode_Reward/test_gait_reward: -0.9340
Metrics/base_velocity/error_vel_xy: 1.0209
Metrics/base_velocity/error_vel_yaw: 1.3135
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 1.09s
                        Total time: 1499.06s
                               ETA: 1770.3s

################################################################################
                     [1m Learning iteration 1376/3000 [0m                     

                       Computation: 90821 steps/s (collection: 0.958s, learning 0.125s)
               Value function loss: 0.5608
                    Surrogate loss: -0.0005
             Mean action noise std: 0.8761
                     Learning rate: 0.0002
                       Mean reward: 128.43
               Mean episode length: 982.92
       Episode_Reward/keep_balance: 0.9800
     Episode_Reward/rew_lin_vel_xy: 5.9908
      Episode_Reward/rew_ang_vel_z: 2.4279
    Episode_Reward/pen_base_height: -0.2999
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1773
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1239
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0617
   Episode_Reward/pen_joint_powers: -0.0917
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2564
Episode_Reward/pen_flat_orientation: -0.1044
  Episode_Reward/pen_feet_distance: -0.0178
Episode_Reward/pen_feet_regulation: -0.4927
   Episode_Reward/foot_landing_vel: -0.1515
   Episode_Reward/test_gait_reward: -0.9356
Metrics/base_velocity/error_vel_xy: 1.0461
Metrics/base_velocity/error_vel_yaw: 1.3610
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 1.08s
                        Total time: 1500.14s
                               ETA: 1769.2s

################################################################################
                     [1m Learning iteration 1377/3000 [0m                     

                       Computation: 90180 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.5524
                    Surrogate loss: -0.0055
             Mean action noise std: 0.8746
                     Learning rate: 0.0004
                       Mean reward: 131.35
               Mean episode length: 990.29
       Episode_Reward/keep_balance: 0.9940
     Episode_Reward/rew_lin_vel_xy: 6.1894
      Episode_Reward/rew_ang_vel_z: 2.4723
    Episode_Reward/pen_base_height: -0.2950
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.1768
   Episode_Reward/pen_joint_torque: -0.2320
    Episode_Reward/pen_joint_accel: -0.1166
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0596
   Episode_Reward/pen_joint_powers: -0.0908
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2601
Episode_Reward/pen_flat_orientation: -0.1014
  Episode_Reward/pen_feet_distance: -0.0159
Episode_Reward/pen_feet_regulation: -0.4818
   Episode_Reward/foot_landing_vel: -0.1465
   Episode_Reward/test_gait_reward: -0.9467
Metrics/base_velocity/error_vel_xy: 1.0050
Metrics/base_velocity/error_vel_yaw: 1.3534
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 1.09s
                        Total time: 1501.23s
                               ETA: 1768.1s

################################################################################
                     [1m Learning iteration 1378/3000 [0m                     

                       Computation: 88569 steps/s (collection: 0.986s, learning 0.124s)
               Value function loss: 0.6148
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8742
                     Learning rate: 0.0002
                       Mean reward: 127.12
               Mean episode length: 977.60
       Episode_Reward/keep_balance: 0.9831
     Episode_Reward/rew_lin_vel_xy: 6.0187
      Episode_Reward/rew_ang_vel_z: 2.4510
    Episode_Reward/pen_base_height: -0.3037
      Episode_Reward/pen_lin_vel_z: -0.0421
     Episode_Reward/pen_ang_vel_xy: -0.1797
   Episode_Reward/pen_joint_torque: -0.2321
    Episode_Reward/pen_joint_accel: -0.1096
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0917
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2560
Episode_Reward/pen_flat_orientation: -0.1066
  Episode_Reward/pen_feet_distance: -0.0148
Episode_Reward/pen_feet_regulation: -0.4772
   Episode_Reward/foot_landing_vel: -0.1429
   Episode_Reward/test_gait_reward: -0.9361
Metrics/base_velocity/error_vel_xy: 1.0402
Metrics/base_velocity/error_vel_yaw: 1.3407
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 1.11s
                        Total time: 1502.34s
                               ETA: 1767.1s

################################################################################
                     [1m Learning iteration 1379/3000 [0m                     

                       Computation: 89631 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.6680
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8736
                     Learning rate: 0.0003
                       Mean reward: 129.72
               Mean episode length: 989.14
       Episode_Reward/keep_balance: 0.9914
     Episode_Reward/rew_lin_vel_xy: 6.1769
      Episode_Reward/rew_ang_vel_z: 2.4137
    Episode_Reward/pen_base_height: -0.2988
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1779
   Episode_Reward/pen_joint_torque: -0.2247
    Episode_Reward/pen_joint_accel: -0.1190
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0603
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2604
Episode_Reward/pen_flat_orientation: -0.1017
  Episode_Reward/pen_feet_distance: -0.0168
Episode_Reward/pen_feet_regulation: -0.4826
   Episode_Reward/foot_landing_vel: -0.1446
   Episode_Reward/test_gait_reward: -0.9446
Metrics/base_velocity/error_vel_xy: 0.9910
Metrics/base_velocity/error_vel_yaw: 1.3935
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 1.10s
                        Total time: 1503.44s
                               ETA: 1766.0s

################################################################################
                     [1m Learning iteration 1380/3000 [0m                     

                       Computation: 90539 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.6336
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8741
                     Learning rate: 0.0004
                       Mean reward: 127.88
               Mean episode length: 974.46
       Episode_Reward/keep_balance: 0.9574
     Episode_Reward/rew_lin_vel_xy: 5.8782
      Episode_Reward/rew_ang_vel_z: 2.4115
    Episode_Reward/pen_base_height: -0.2973
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1703
   Episode_Reward/pen_joint_torque: -0.2243
    Episode_Reward/pen_joint_accel: -0.1122
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2488
Episode_Reward/pen_flat_orientation: -0.1064
  Episode_Reward/pen_feet_distance: -0.0148
Episode_Reward/pen_feet_regulation: -0.4658
   Episode_Reward/foot_landing_vel: -0.1343
   Episode_Reward/test_gait_reward: -0.9107
Metrics/base_velocity/error_vel_xy: 1.0085
Metrics/base_velocity/error_vel_yaw: 1.2808
      Episode_Termination/time_out: 4.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 1.09s
                        Total time: 1504.52s
                               ETA: 1764.9s

################################################################################
                     [1m Learning iteration 1381/3000 [0m                     

                       Computation: 89728 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.6966
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8755
                     Learning rate: 0.0003
                       Mean reward: 128.95
               Mean episode length: 976.00
       Episode_Reward/keep_balance: 0.9787
     Episode_Reward/rew_lin_vel_xy: 6.0348
      Episode_Reward/rew_ang_vel_z: 2.4464
    Episode_Reward/pen_base_height: -0.3041
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1725
   Episode_Reward/pen_joint_torque: -0.2331
    Episode_Reward/pen_joint_accel: -0.1167
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2540
Episode_Reward/pen_flat_orientation: -0.1091
  Episode_Reward/pen_feet_distance: -0.0162
Episode_Reward/pen_feet_regulation: -0.4711
   Episode_Reward/foot_landing_vel: -0.1430
   Episode_Reward/test_gait_reward: -0.9266
Metrics/base_velocity/error_vel_xy: 1.0187
Metrics/base_velocity/error_vel_yaw: 1.3196
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 1.10s
                        Total time: 1505.62s
                               ETA: 1763.8s

################################################################################
                     [1m Learning iteration 1382/3000 [0m                     

                       Computation: 90363 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.5891
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8752
                     Learning rate: 0.0001
                       Mean reward: 121.12
               Mean episode length: 939.55
       Episode_Reward/keep_balance: 0.9496
     Episode_Reward/rew_lin_vel_xy: 5.8519
      Episode_Reward/rew_ang_vel_z: 2.3752
    Episode_Reward/pen_base_height: -0.3004
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1684
   Episode_Reward/pen_joint_torque: -0.2333
    Episode_Reward/pen_joint_accel: -0.1060
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2453
Episode_Reward/pen_flat_orientation: -0.1104
  Episode_Reward/pen_feet_distance: -0.0177
Episode_Reward/pen_feet_regulation: -0.4607
   Episode_Reward/foot_landing_vel: -0.1419
   Episode_Reward/test_gait_reward: -0.9040
Metrics/base_velocity/error_vel_xy: 0.9952
Metrics/base_velocity/error_vel_yaw: 1.2905
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 1.09s
                        Total time: 1506.71s
                               ETA: 1762.7s

################################################################################
                     [1m Learning iteration 1383/3000 [0m                     

                       Computation: 89980 steps/s (collection: 0.968s, learning 0.125s)
               Value function loss: 0.6505
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8764
                     Learning rate: 0.0004
                       Mean reward: 126.43
               Mean episode length: 988.08
       Episode_Reward/keep_balance: 0.9870
     Episode_Reward/rew_lin_vel_xy: 5.9945
      Episode_Reward/rew_ang_vel_z: 2.4469
    Episode_Reward/pen_base_height: -0.3060
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.1792
   Episode_Reward/pen_joint_torque: -0.2391
    Episode_Reward/pen_joint_accel: -0.1097
    Episode_Reward/pen_action_rate: -0.1213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0614
   Episode_Reward/pen_joint_powers: -0.0937
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2575
Episode_Reward/pen_flat_orientation: -0.1073
  Episode_Reward/pen_feet_distance: -0.0172
Episode_Reward/pen_feet_regulation: -0.4940
   Episode_Reward/foot_landing_vel: -0.1517
   Episode_Reward/test_gait_reward: -0.9439
Metrics/base_velocity/error_vel_xy: 1.0708
Metrics/base_velocity/error_vel_yaw: 1.3545
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 1.09s
                        Total time: 1507.80s
                               ETA: 1761.6s

################################################################################
                     [1m Learning iteration 1384/3000 [0m                     

                       Computation: 90558 steps/s (collection: 0.960s, learning 0.126s)
               Value function loss: 0.6949
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8775
                     Learning rate: 0.0009
                       Mean reward: 125.11
               Mean episode length: 957.70
       Episode_Reward/keep_balance: 0.9526
     Episode_Reward/rew_lin_vel_xy: 5.7712
      Episode_Reward/rew_ang_vel_z: 2.3491
    Episode_Reward/pen_base_height: -0.2900
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1728
   Episode_Reward/pen_joint_torque: -0.2267
    Episode_Reward/pen_joint_accel: -0.1102
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0897
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2480
Episode_Reward/pen_flat_orientation: -0.1109
  Episode_Reward/pen_feet_distance: -0.0163
Episode_Reward/pen_feet_regulation: -0.4760
   Episode_Reward/foot_landing_vel: -0.1408
   Episode_Reward/test_gait_reward: -0.9050
Metrics/base_velocity/error_vel_xy: 1.0380
Metrics/base_velocity/error_vel_yaw: 1.3160
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 1.09s
                        Total time: 1508.89s
                               ETA: 1760.5s

################################################################################
                     [1m Learning iteration 1385/3000 [0m                     

                       Computation: 89085 steps/s (collection: 0.981s, learning 0.123s)
               Value function loss: 0.6866
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8775
                     Learning rate: 0.0004
                       Mean reward: 126.89
               Mean episode length: 967.96
       Episode_Reward/keep_balance: 0.9718
     Episode_Reward/rew_lin_vel_xy: 5.9373
      Episode_Reward/rew_ang_vel_z: 2.4284
    Episode_Reward/pen_base_height: -0.2960
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1665
   Episode_Reward/pen_joint_torque: -0.2387
    Episode_Reward/pen_joint_accel: -0.1016
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2502
Episode_Reward/pen_flat_orientation: -0.1055
  Episode_Reward/pen_feet_distance: -0.0168
Episode_Reward/pen_feet_regulation: -0.4669
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.9223
Metrics/base_velocity/error_vel_xy: 1.0366
Metrics/base_velocity/error_vel_yaw: 1.3258
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 1.10s
                        Total time: 1509.99s
                               ETA: 1759.5s

################################################################################
                     [1m Learning iteration 1386/3000 [0m                     

                       Computation: 89533 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.6668
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8764
                     Learning rate: 0.0009
                       Mean reward: 128.01
               Mean episode length: 968.02
       Episode_Reward/keep_balance: 0.9725
     Episode_Reward/rew_lin_vel_xy: 6.0353
      Episode_Reward/rew_ang_vel_z: 2.4490
    Episode_Reward/pen_base_height: -0.2875
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1669
   Episode_Reward/pen_joint_torque: -0.2174
    Episode_Reward/pen_joint_accel: -0.1077
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2494
Episode_Reward/pen_flat_orientation: -0.1012
  Episode_Reward/pen_feet_distance: -0.0160
Episode_Reward/pen_feet_regulation: -0.4577
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.9237
Metrics/base_velocity/error_vel_xy: 0.9932
Metrics/base_velocity/error_vel_yaw: 1.2997
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 1.10s
                        Total time: 1511.09s
                               ETA: 1758.4s

################################################################################
                     [1m Learning iteration 1387/3000 [0m                     

                       Computation: 90005 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.5987
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8756
                     Learning rate: 0.0006
                       Mean reward: 122.54
               Mean episode length: 950.09
       Episode_Reward/keep_balance: 0.9644
     Episode_Reward/rew_lin_vel_xy: 5.8759
      Episode_Reward/rew_ang_vel_z: 2.3866
    Episode_Reward/pen_base_height: -0.3061
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1679
   Episode_Reward/pen_joint_torque: -0.2251
    Episode_Reward/pen_joint_accel: -0.1081
    Episode_Reward/pen_action_rate: -0.1176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2503
Episode_Reward/pen_flat_orientation: -0.1120
  Episode_Reward/pen_feet_distance: -0.0182
Episode_Reward/pen_feet_regulation: -0.4730
   Episode_Reward/foot_landing_vel: -0.1302
   Episode_Reward/test_gait_reward: -0.9225
Metrics/base_velocity/error_vel_xy: 1.0274
Metrics/base_velocity/error_vel_yaw: 1.3421
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 1.09s
                        Total time: 1512.18s
                               ETA: 1757.3s

################################################################################
                     [1m Learning iteration 1388/3000 [0m                     

                       Computation: 90161 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.6631
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8762
                     Learning rate: 0.0006
                       Mean reward: 128.33
               Mean episode length: 977.08
       Episode_Reward/keep_balance: 0.9784
     Episode_Reward/rew_lin_vel_xy: 6.0764
      Episode_Reward/rew_ang_vel_z: 2.4511
    Episode_Reward/pen_base_height: -0.2976
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1700
   Episode_Reward/pen_joint_torque: -0.2339
    Episode_Reward/pen_joint_accel: -0.1077
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2554
Episode_Reward/pen_flat_orientation: -0.1051
  Episode_Reward/pen_feet_distance: -0.0160
Episode_Reward/pen_feet_regulation: -0.4794
   Episode_Reward/foot_landing_vel: -0.1361
   Episode_Reward/test_gait_reward: -0.9340
Metrics/base_velocity/error_vel_xy: 0.9941
Metrics/base_velocity/error_vel_yaw: 1.3279
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 1.09s
                        Total time: 1513.27s
                               ETA: 1756.2s

################################################################################
                     [1m Learning iteration 1389/3000 [0m                     

                       Computation: 90213 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.6285
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8762
                     Learning rate: 0.0004
                       Mean reward: 123.78
               Mean episode length: 955.23
       Episode_Reward/keep_balance: 0.9205
     Episode_Reward/rew_lin_vel_xy: 5.6205
      Episode_Reward/rew_ang_vel_z: 2.2851
    Episode_Reward/pen_base_height: -0.3058
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.1689
   Episode_Reward/pen_joint_torque: -0.2281
    Episode_Reward/pen_joint_accel: -0.1035
    Episode_Reward/pen_action_rate: -0.1130
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.2420
Episode_Reward/pen_flat_orientation: -0.1184
  Episode_Reward/pen_feet_distance: -0.0170
Episode_Reward/pen_feet_regulation: -0.4444
   Episode_Reward/foot_landing_vel: -0.1311
   Episode_Reward/test_gait_reward: -0.8760
Metrics/base_velocity/error_vel_xy: 0.9900
Metrics/base_velocity/error_vel_yaw: 1.2786
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 1.09s
                        Total time: 1514.36s
                               ETA: 1755.1s

################################################################################
                     [1m Learning iteration 1390/3000 [0m                     

                       Computation: 91330 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.5911
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8757
                     Learning rate: 0.0009
                       Mean reward: 130.39
               Mean episode length: 988.40
       Episode_Reward/keep_balance: 0.9948
     Episode_Reward/rew_lin_vel_xy: 6.1336
      Episode_Reward/rew_ang_vel_z: 2.4602
    Episode_Reward/pen_base_height: -0.2981
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1715
   Episode_Reward/pen_joint_torque: -0.2315
    Episode_Reward/pen_joint_accel: -0.1077
    Episode_Reward/pen_action_rate: -0.1214
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0595
   Episode_Reward/pen_joint_powers: -0.0912
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2596
Episode_Reward/pen_flat_orientation: -0.1086
  Episode_Reward/pen_feet_distance: -0.0167
Episode_Reward/pen_feet_regulation: -0.4878
   Episode_Reward/foot_landing_vel: -0.1434
   Episode_Reward/test_gait_reward: -0.9416
Metrics/base_velocity/error_vel_xy: 1.0271
Metrics/base_velocity/error_vel_yaw: 1.3904
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 1.08s
                        Total time: 1515.44s
                               ETA: 1754.0s

################################################################################
                     [1m Learning iteration 1391/3000 [0m                     

                       Computation: 88249 steps/s (collection: 0.991s, learning 0.123s)
               Value function loss: 0.6536
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8762
                     Learning rate: 0.0006
                       Mean reward: 130.48
               Mean episode length: 991.91
       Episode_Reward/keep_balance: 0.9946
     Episode_Reward/rew_lin_vel_xy: 6.1342
      Episode_Reward/rew_ang_vel_z: 2.4882
    Episode_Reward/pen_base_height: -0.2833
      Episode_Reward/pen_lin_vel_z: -0.0406
     Episode_Reward/pen_ang_vel_xy: -0.1771
   Episode_Reward/pen_joint_torque: -0.2180
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1189
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2594
Episode_Reward/pen_flat_orientation: -0.0959
  Episode_Reward/pen_feet_distance: -0.0142
Episode_Reward/pen_feet_regulation: -0.4582
   Episode_Reward/foot_landing_vel: -0.1384
   Episode_Reward/test_gait_reward: -0.9387
Metrics/base_velocity/error_vel_xy: 1.0280
Metrics/base_velocity/error_vel_yaw: 1.3503
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 1.11s
                        Total time: 1516.55s
                               ETA: 1753.0s

################################################################################
                     [1m Learning iteration 1392/3000 [0m                     

                       Computation: 88419 steps/s (collection: 0.988s, learning 0.124s)
               Value function loss: 0.5513
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8757
                     Learning rate: 0.0009
                       Mean reward: 130.63
               Mean episode length: 976.61
       Episode_Reward/keep_balance: 0.9772
     Episode_Reward/rew_lin_vel_xy: 6.0769
      Episode_Reward/rew_ang_vel_z: 2.4416
    Episode_Reward/pen_base_height: -0.2820
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1661
   Episode_Reward/pen_joint_torque: -0.2230
    Episode_Reward/pen_joint_accel: -0.1187
    Episode_Reward/pen_action_rate: -0.1174
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2542
Episode_Reward/pen_flat_orientation: -0.0995
  Episode_Reward/pen_feet_distance: -0.0135
Episode_Reward/pen_feet_regulation: -0.4655
   Episode_Reward/foot_landing_vel: -0.1371
   Episode_Reward/test_gait_reward: -0.9241
Metrics/base_velocity/error_vel_xy: 0.9812
Metrics/base_velocity/error_vel_yaw: 1.3334
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 1.11s
                        Total time: 1517.66s
                               ETA: 1751.9s

################################################################################
                     [1m Learning iteration 1393/3000 [0m                     

                       Computation: 89622 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.7052
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8756
                     Learning rate: 0.0004
                       Mean reward: 125.23
               Mean episode length: 963.17
       Episode_Reward/keep_balance: 0.9545
     Episode_Reward/rew_lin_vel_xy: 5.9252
      Episode_Reward/rew_ang_vel_z: 2.3901
    Episode_Reward/pen_base_height: -0.3036
      Episode_Reward/pen_lin_vel_z: -0.0420
     Episode_Reward/pen_ang_vel_xy: -0.1731
   Episode_Reward/pen_joint_torque: -0.2291
    Episode_Reward/pen_joint_accel: -0.1044
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2512
Episode_Reward/pen_flat_orientation: -0.1088
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4898
   Episode_Reward/foot_landing_vel: -0.1481
   Episode_Reward/test_gait_reward: -0.9120
Metrics/base_velocity/error_vel_xy: 0.9839
Metrics/base_velocity/error_vel_yaw: 1.2982
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 1.10s
                        Total time: 1518.76s
                               ETA: 1750.8s

################################################################################
                     [1m Learning iteration 1394/3000 [0m                     

                       Computation: 90110 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.6281
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8750
                     Learning rate: 0.0003
                       Mean reward: 126.87
               Mean episode length: 972.02
       Episode_Reward/keep_balance: 0.9883
     Episode_Reward/rew_lin_vel_xy: 6.1024
      Episode_Reward/rew_ang_vel_z: 2.4688
    Episode_Reward/pen_base_height: -0.3150
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1711
   Episode_Reward/pen_joint_torque: -0.2500
    Episode_Reward/pen_joint_accel: -0.1179
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0605
   Episode_Reward/pen_joint_powers: -0.0940
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2558
Episode_Reward/pen_flat_orientation: -0.1079
  Episode_Reward/pen_feet_distance: -0.0181
Episode_Reward/pen_feet_regulation: -0.5028
   Episode_Reward/foot_landing_vel: -0.1447
   Episode_Reward/test_gait_reward: -0.9477
Metrics/base_velocity/error_vel_xy: 1.0174
Metrics/base_velocity/error_vel_yaw: 1.3282
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 1.09s
                        Total time: 1519.85s
                               ETA: 1749.7s

################################################################################
                     [1m Learning iteration 1395/3000 [0m                     

                       Computation: 90299 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.7233
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8761
                     Learning rate: 0.0004
                       Mean reward: 129.86
               Mean episode length: 983.51
       Episode_Reward/keep_balance: 0.9738
     Episode_Reward/rew_lin_vel_xy: 6.0159
      Episode_Reward/rew_ang_vel_z: 2.4376
    Episode_Reward/pen_base_height: -0.2881
      Episode_Reward/pen_lin_vel_z: -0.0417
     Episode_Reward/pen_ang_vel_xy: -0.1723
   Episode_Reward/pen_joint_torque: -0.2303
    Episode_Reward/pen_joint_accel: -0.1252
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2536
Episode_Reward/pen_flat_orientation: -0.0999
  Episode_Reward/pen_feet_distance: -0.0162
Episode_Reward/pen_feet_regulation: -0.4762
   Episode_Reward/foot_landing_vel: -0.1500
   Episode_Reward/test_gait_reward: -0.9130
Metrics/base_velocity/error_vel_xy: 0.9880
Metrics/base_velocity/error_vel_yaw: 1.3197
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 1.09s
                        Total time: 1520.94s
                               ETA: 1748.6s

################################################################################
                     [1m Learning iteration 1396/3000 [0m                     

                       Computation: 90233 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.6157
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8768
                     Learning rate: 0.0004
                       Mean reward: 128.97
               Mean episode length: 956.62
       Episode_Reward/keep_balance: 0.9446
     Episode_Reward/rew_lin_vel_xy: 5.9008
      Episode_Reward/rew_ang_vel_z: 2.3768
    Episode_Reward/pen_base_height: -0.2889
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1595
   Episode_Reward/pen_joint_torque: -0.2210
    Episode_Reward/pen_joint_accel: -0.1070
    Episode_Reward/pen_action_rate: -0.1150
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2452
Episode_Reward/pen_flat_orientation: -0.1058
  Episode_Reward/pen_feet_distance: -0.0184
Episode_Reward/pen_feet_regulation: -0.4703
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.8992
Metrics/base_velocity/error_vel_xy: 0.9487
Metrics/base_velocity/error_vel_yaw: 1.2726
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 1.09s
                        Total time: 1522.03s
                               ETA: 1747.6s

################################################################################
                     [1m Learning iteration 1397/3000 [0m                     

                       Computation: 91403 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.6469
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8757
                     Learning rate: 0.0009
                       Mean reward: 128.70
               Mean episode length: 978.50
       Episode_Reward/keep_balance: 0.9790
     Episode_Reward/rew_lin_vel_xy: 6.0706
      Episode_Reward/rew_ang_vel_z: 2.4246
    Episode_Reward/pen_base_height: -0.2966
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1664
   Episode_Reward/pen_joint_torque: -0.2310
    Episode_Reward/pen_joint_accel: -0.1146
    Episode_Reward/pen_action_rate: -0.1192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2563
Episode_Reward/pen_flat_orientation: -0.1004
  Episode_Reward/pen_feet_distance: -0.0172
Episode_Reward/pen_feet_regulation: -0.4686
   Episode_Reward/foot_landing_vel: -0.1435
   Episode_Reward/test_gait_reward: -0.9277
Metrics/base_velocity/error_vel_xy: 1.0010
Metrics/base_velocity/error_vel_yaw: 1.3512
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 1.08s
                        Total time: 1523.10s
                               ETA: 1746.4s

################################################################################
                     [1m Learning iteration 1398/3000 [0m                     

                       Computation: 88744 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 0.7194
                    Surrogate loss: 0.0020
             Mean action noise std: 0.8759
                     Learning rate: 0.0001
                       Mean reward: 127.52
               Mean episode length: 988.05
       Episode_Reward/keep_balance: 0.9904
     Episode_Reward/rew_lin_vel_xy: 6.1384
      Episode_Reward/rew_ang_vel_z: 2.4380
    Episode_Reward/pen_base_height: -0.2948
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1736
   Episode_Reward/pen_joint_torque: -0.2337
    Episode_Reward/pen_joint_accel: -0.1106
    Episode_Reward/pen_action_rate: -0.1215
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0915
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2623
Episode_Reward/pen_flat_orientation: -0.1047
  Episode_Reward/pen_feet_distance: -0.0205
Episode_Reward/pen_feet_regulation: -0.4832
   Episode_Reward/foot_landing_vel: -0.1401
   Episode_Reward/test_gait_reward: -0.9506
Metrics/base_velocity/error_vel_xy: 1.0024
Metrics/base_velocity/error_vel_yaw: 1.3784
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 1.11s
                        Total time: 1524.21s
                               ETA: 1745.4s

################################################################################
                     [1m Learning iteration 1399/3000 [0m                     

                       Computation: 89272 steps/s (collection: 0.977s, learning 0.124s)
               Value function loss: 0.6573
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8762
                     Learning rate: 0.0003
                       Mean reward: 125.09
               Mean episode length: 953.25
       Episode_Reward/keep_balance: 0.9532
     Episode_Reward/rew_lin_vel_xy: 5.8292
      Episode_Reward/rew_ang_vel_z: 2.3905
    Episode_Reward/pen_base_height: -0.2952
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1609
   Episode_Reward/pen_joint_torque: -0.2438
    Episode_Reward/pen_joint_accel: -0.1134
    Episode_Reward/pen_action_rate: -0.1160
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2447
Episode_Reward/pen_flat_orientation: -0.1096
  Episode_Reward/pen_feet_distance: -0.0184
Episode_Reward/pen_feet_regulation: -0.4561
   Episode_Reward/foot_landing_vel: -0.1326
   Episode_Reward/test_gait_reward: -0.9014
Metrics/base_velocity/error_vel_xy: 0.9966
Metrics/base_velocity/error_vel_yaw: 1.2919
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 1.10s
                        Total time: 1525.31s
                               ETA: 1744.3s

################################################################################
                     [1m Learning iteration 1400/3000 [0m                     

                       Computation: 89074 steps/s (collection: 0.978s, learning 0.125s)
               Value function loss: 0.6912
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8767
                     Learning rate: 0.0006
                       Mean reward: 128.05
               Mean episode length: 967.13
       Episode_Reward/keep_balance: 0.9667
     Episode_Reward/rew_lin_vel_xy: 6.0159
      Episode_Reward/rew_ang_vel_z: 2.4105
    Episode_Reward/pen_base_height: -0.3013
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1687
   Episode_Reward/pen_joint_torque: -0.2286
    Episode_Reward/pen_joint_accel: -0.1132
    Episode_Reward/pen_action_rate: -0.1176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2523
Episode_Reward/pen_flat_orientation: -0.1051
  Episode_Reward/pen_feet_distance: -0.0198
Episode_Reward/pen_feet_regulation: -0.4623
   Episode_Reward/foot_landing_vel: -0.1260
   Episode_Reward/test_gait_reward: -0.9158
Metrics/base_velocity/error_vel_xy: 0.9731
Metrics/base_velocity/error_vel_yaw: 1.3188
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 1.10s
                        Total time: 1526.41s
                               ETA: 1743.2s

################################################################################
                     [1m Learning iteration 1401/3000 [0m                     

                       Computation: 88711 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 0.6946
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8782
                     Learning rate: 0.0006
                       Mean reward: 124.14
               Mean episode length: 950.03
       Episode_Reward/keep_balance: 0.9365
     Episode_Reward/rew_lin_vel_xy: 5.7777
      Episode_Reward/rew_ang_vel_z: 2.3559
    Episode_Reward/pen_base_height: -0.2908
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1635
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.1168
    Episode_Reward/pen_action_rate: -0.1143
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2433
Episode_Reward/pen_flat_orientation: -0.1092
  Episode_Reward/pen_feet_distance: -0.0206
Episode_Reward/pen_feet_regulation: -0.4549
   Episode_Reward/foot_landing_vel: -0.1351
   Episode_Reward/test_gait_reward: -0.8893
Metrics/base_velocity/error_vel_xy: 0.9848
Metrics/base_velocity/error_vel_yaw: 1.2733
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 1.11s
                        Total time: 1527.52s
                               ETA: 1742.2s

################################################################################
                     [1m Learning iteration 1402/3000 [0m                     

                       Computation: 87934 steps/s (collection: 0.994s, learning 0.124s)
               Value function loss: 0.6594
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8776
                     Learning rate: 0.0009
                       Mean reward: 125.44
               Mean episode length: 966.15
       Episode_Reward/keep_balance: 0.9683
     Episode_Reward/rew_lin_vel_xy: 5.9315
      Episode_Reward/rew_ang_vel_z: 2.4154
    Episode_Reward/pen_base_height: -0.3009
      Episode_Reward/pen_lin_vel_z: -0.0416
     Episode_Reward/pen_ang_vel_xy: -0.1666
   Episode_Reward/pen_joint_torque: -0.2256
    Episode_Reward/pen_joint_accel: -0.1123
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2541
Episode_Reward/pen_flat_orientation: -0.1111
  Episode_Reward/pen_feet_distance: -0.0174
Episode_Reward/pen_feet_regulation: -0.4978
   Episode_Reward/foot_landing_vel: -0.1436
   Episode_Reward/test_gait_reward: -0.9240
Metrics/base_velocity/error_vel_xy: 1.0296
Metrics/base_velocity/error_vel_yaw: 1.3255
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 1.12s
                        Total time: 1528.64s
                               ETA: 1741.1s

################################################################################
                     [1m Learning iteration 1403/3000 [0m                     

                       Computation: 89468 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.6141
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8757
                     Learning rate: 0.0009
                       Mean reward: 129.75
               Mean episode length: 988.92
       Episode_Reward/keep_balance: 0.9929
     Episode_Reward/rew_lin_vel_xy: 6.1580
      Episode_Reward/rew_ang_vel_z: 2.5263
    Episode_Reward/pen_base_height: -0.2985
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.1664
   Episode_Reward/pen_joint_torque: -0.2382
    Episode_Reward/pen_joint_accel: -0.1070
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2548
Episode_Reward/pen_flat_orientation: -0.1014
  Episode_Reward/pen_feet_distance: -0.0190
Episode_Reward/pen_feet_regulation: -0.4789
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9383
Metrics/base_velocity/error_vel_xy: 1.0186
Metrics/base_velocity/error_vel_yaw: 1.3173
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 1.10s
                        Total time: 1529.74s
                               ETA: 1740.0s

################################################################################
                     [1m Learning iteration 1404/3000 [0m                     

                       Computation: 90034 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.6239
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8757
                     Learning rate: 0.0006
                       Mean reward: 128.52
               Mean episode length: 978.40
       Episode_Reward/keep_balance: 0.9819
     Episode_Reward/rew_lin_vel_xy: 6.0937
      Episode_Reward/rew_ang_vel_z: 2.4952
    Episode_Reward/pen_base_height: -0.2972
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1757
   Episode_Reward/pen_joint_torque: -0.2299
    Episode_Reward/pen_joint_accel: -0.1143
    Episode_Reward/pen_action_rate: -0.1202
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0900
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2575
Episode_Reward/pen_flat_orientation: -0.1003
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4748
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.9330
Metrics/base_velocity/error_vel_xy: 0.9920
Metrics/base_velocity/error_vel_yaw: 1.3041
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 1.09s
                        Total time: 1530.83s
                               ETA: 1738.9s

################################################################################
                     [1m Learning iteration 1405/3000 [0m                     

                       Computation: 88838 steps/s (collection: 0.982s, learning 0.124s)
               Value function loss: 0.6340
                    Surrogate loss: -0.0061
             Mean action noise std: 0.8761
                     Learning rate: 0.0009
                       Mean reward: 127.68
               Mean episode length: 983.79
       Episode_Reward/keep_balance: 0.9860
     Episode_Reward/rew_lin_vel_xy: 6.0086
      Episode_Reward/rew_ang_vel_z: 2.4730
    Episode_Reward/pen_base_height: -0.3056
      Episode_Reward/pen_lin_vel_z: -0.0406
     Episode_Reward/pen_ang_vel_xy: -0.1700
   Episode_Reward/pen_joint_torque: -0.2359
    Episode_Reward/pen_joint_accel: -0.1100
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0922
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2594
Episode_Reward/pen_flat_orientation: -0.1066
  Episode_Reward/pen_feet_distance: -0.0224
Episode_Reward/pen_feet_regulation: -0.4810
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.9394
Metrics/base_velocity/error_vel_xy: 1.0604
Metrics/base_velocity/error_vel_yaw: 1.3338
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 1.11s
                        Total time: 1531.94s
                               ETA: 1737.9s

################################################################################
                     [1m Learning iteration 1406/3000 [0m                     

                       Computation: 89617 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.6448
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8776
                     Learning rate: 0.0004
                       Mean reward: 128.79
               Mean episode length: 982.38
       Episode_Reward/keep_balance: 0.9861
     Episode_Reward/rew_lin_vel_xy: 6.0786
      Episode_Reward/rew_ang_vel_z: 2.4565
    Episode_Reward/pen_base_height: -0.2909
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1649
   Episode_Reward/pen_joint_torque: -0.2404
    Episode_Reward/pen_joint_accel: -0.1171
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0931
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2569
Episode_Reward/pen_flat_orientation: -0.1013
  Episode_Reward/pen_feet_distance: -0.0209
Episode_Reward/pen_feet_regulation: -0.4873
   Episode_Reward/foot_landing_vel: -0.1450
   Episode_Reward/test_gait_reward: -0.9371
Metrics/base_velocity/error_vel_xy: 1.0110
Metrics/base_velocity/error_vel_yaw: 1.3497
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 1.10s
                        Total time: 1533.04s
                               ETA: 1736.8s

################################################################################
                     [1m Learning iteration 1407/3000 [0m                     

                       Computation: 90857 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.6416
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8777
                     Learning rate: 0.0006
                       Mean reward: 128.22
               Mean episode length: 965.55
       Episode_Reward/keep_balance: 0.9698
     Episode_Reward/rew_lin_vel_xy: 6.0306
      Episode_Reward/rew_ang_vel_z: 2.4500
    Episode_Reward/pen_base_height: -0.2931
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1608
   Episode_Reward/pen_joint_torque: -0.2332
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2517
Episode_Reward/pen_flat_orientation: -0.0976
  Episode_Reward/pen_feet_distance: -0.0203
Episode_Reward/pen_feet_regulation: -0.4654
   Episode_Reward/foot_landing_vel: -0.1370
   Episode_Reward/test_gait_reward: -0.9231
Metrics/base_velocity/error_vel_xy: 0.9859
Metrics/base_velocity/error_vel_yaw: 1.2979
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 1.08s
                        Total time: 1534.12s
                               ETA: 1735.7s

################################################################################
                     [1m Learning iteration 1408/3000 [0m                     

                       Computation: 90298 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.6211
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8788
                     Learning rate: 0.0006
                       Mean reward: 132.58
               Mean episode length: 993.74
       Episode_Reward/keep_balance: 0.9943
     Episode_Reward/rew_lin_vel_xy: 6.1488
      Episode_Reward/rew_ang_vel_z: 2.5143
    Episode_Reward/pen_base_height: -0.2910
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.1610
   Episode_Reward/pen_joint_torque: -0.2413
    Episode_Reward/pen_joint_accel: -0.1173
    Episode_Reward/pen_action_rate: -0.1211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0591
   Episode_Reward/pen_joint_powers: -0.0923
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2579
Episode_Reward/pen_flat_orientation: -0.1025
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4734
   Episode_Reward/foot_landing_vel: -0.1446
   Episode_Reward/test_gait_reward: -0.9465
Metrics/base_velocity/error_vel_xy: 1.0192
Metrics/base_velocity/error_vel_yaw: 1.3243
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 1.09s
                        Total time: 1535.21s
                               ETA: 1734.6s

################################################################################
                     [1m Learning iteration 1409/3000 [0m                     

                       Computation: 88708 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 0.6392
                    Surrogate loss: -0.0056
             Mean action noise std: 0.8811
                     Learning rate: 0.0009
                       Mean reward: 130.29
               Mean episode length: 973.97
       Episode_Reward/keep_balance: 0.9732
     Episode_Reward/rew_lin_vel_xy: 6.0130
      Episode_Reward/rew_ang_vel_z: 2.4728
    Episode_Reward/pen_base_height: -0.2846
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1635
   Episode_Reward/pen_joint_torque: -0.2287
    Episode_Reward/pen_joint_accel: -0.1097
    Episode_Reward/pen_action_rate: -0.1176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0882
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2505
Episode_Reward/pen_flat_orientation: -0.0968
  Episode_Reward/pen_feet_distance: -0.0160
Episode_Reward/pen_feet_regulation: -0.4609
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.9228
Metrics/base_velocity/error_vel_xy: 1.0035
Metrics/base_velocity/error_vel_yaw: 1.2796
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 1.11s
                        Total time: 1536.31s
                               ETA: 1733.5s

################################################################################
                     [1m Learning iteration 1410/3000 [0m                     

                       Computation: 89912 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.6365
                    Surrogate loss: -0.0009
             Mean action noise std: 0.8825
                     Learning rate: 0.0003
                       Mean reward: 125.50
               Mean episode length: 971.91
       Episode_Reward/keep_balance: 0.9687
     Episode_Reward/rew_lin_vel_xy: 5.9191
      Episode_Reward/rew_ang_vel_z: 2.4079
    Episode_Reward/pen_base_height: -0.3073
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1679
   Episode_Reward/pen_joint_torque: -0.2210
    Episode_Reward/pen_joint_accel: -0.1120
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2571
Episode_Reward/pen_flat_orientation: -0.1097
  Episode_Reward/pen_feet_distance: -0.0178
Episode_Reward/pen_feet_regulation: -0.4742
   Episode_Reward/foot_landing_vel: -0.1346
   Episode_Reward/test_gait_reward: -0.9256
Metrics/base_velocity/error_vel_xy: 1.0421
Metrics/base_velocity/error_vel_yaw: 1.3717
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 1.09s
                        Total time: 1537.41s
                               ETA: 1732.4s

################################################################################
                     [1m Learning iteration 1411/3000 [0m                     

                       Computation: 89660 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.7145
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8832
                     Learning rate: 0.0003
                       Mean reward: 127.71
               Mean episode length: 977.63
       Episode_Reward/keep_balance: 0.9821
     Episode_Reward/rew_lin_vel_xy: 6.1302
      Episode_Reward/rew_ang_vel_z: 2.4433
    Episode_Reward/pen_base_height: -0.3009
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1672
   Episode_Reward/pen_joint_torque: -0.2323
    Episode_Reward/pen_joint_accel: -0.1175
    Episode_Reward/pen_action_rate: -0.1213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0892
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2583
Episode_Reward/pen_flat_orientation: -0.0974
  Episode_Reward/pen_feet_distance: -0.0178
Episode_Reward/pen_feet_regulation: -0.4889
   Episode_Reward/foot_landing_vel: -0.1364
   Episode_Reward/test_gait_reward: -0.9335
Metrics/base_velocity/error_vel_xy: 0.9960
Metrics/base_velocity/error_vel_yaw: 1.3470
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 1.10s
                        Total time: 1538.50s
                               ETA: 1731.4s

################################################################################
                     [1m Learning iteration 1412/3000 [0m                     

                       Computation: 90120 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.5805
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8830
                     Learning rate: 0.0004
                       Mean reward: 121.94
               Mean episode length: 956.32
       Episode_Reward/keep_balance: 0.9624
     Episode_Reward/rew_lin_vel_xy: 5.9084
      Episode_Reward/rew_ang_vel_z: 2.3549
    Episode_Reward/pen_base_height: -0.3003
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1645
   Episode_Reward/pen_joint_torque: -0.2367
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0915
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2534
Episode_Reward/pen_flat_orientation: -0.1081
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.4814
   Episode_Reward/foot_landing_vel: -0.1401
   Episode_Reward/test_gait_reward: -0.9278
Metrics/base_velocity/error_vel_xy: 1.0170
Metrics/base_velocity/error_vel_yaw: 1.3614
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 1.09s
                        Total time: 1539.59s
                               ETA: 1730.3s

################################################################################
                     [1m Learning iteration 1413/3000 [0m                     

                       Computation: 90245 steps/s (collection: 0.963s, learning 0.127s)
               Value function loss: 0.5641
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8820
                     Learning rate: 0.0001
                       Mean reward: 128.88
               Mean episode length: 978.18
       Episode_Reward/keep_balance: 0.9857
     Episode_Reward/rew_lin_vel_xy: 6.0513
      Episode_Reward/rew_ang_vel_z: 2.4978
    Episode_Reward/pen_base_height: -0.3108
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.1660
   Episode_Reward/pen_joint_torque: -0.2377
    Episode_Reward/pen_joint_accel: -0.1113
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2548
Episode_Reward/pen_flat_orientation: -0.0999
  Episode_Reward/pen_feet_distance: -0.0170
Episode_Reward/pen_feet_regulation: -0.4731
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9379
Metrics/base_velocity/error_vel_xy: 1.0330
Metrics/base_velocity/error_vel_yaw: 1.3005
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 1.09s
                        Total time: 1540.68s
                               ETA: 1729.2s

################################################################################
                     [1m Learning iteration 1414/3000 [0m                     

                       Computation: 91271 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 0.6213
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8816
                     Learning rate: 0.0003
                       Mean reward: 132.02
               Mean episode length: 991.67
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.2216
      Episode_Reward/rew_ang_vel_z: 2.4884
    Episode_Reward/pen_base_height: -0.2819
      Episode_Reward/pen_lin_vel_z: -0.0399
     Episode_Reward/pen_ang_vel_xy: -0.1673
   Episode_Reward/pen_joint_torque: -0.2218
    Episode_Reward/pen_joint_accel: -0.1095
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2612
Episode_Reward/pen_flat_orientation: -0.0953
  Episode_Reward/pen_feet_distance: -0.0158
Episode_Reward/pen_feet_regulation: -0.4773
   Episode_Reward/foot_landing_vel: -0.1446
   Episode_Reward/test_gait_reward: -0.9422
Metrics/base_velocity/error_vel_xy: 1.0112
Metrics/base_velocity/error_vel_yaw: 1.3642
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 1.08s
                        Total time: 1541.76s
                               ETA: 1728.1s

################################################################################
                     [1m Learning iteration 1415/3000 [0m                     

                       Computation: 90089 steps/s (collection: 0.964s, learning 0.128s)
               Value function loss: 0.6207
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8813
                     Learning rate: 0.0006
                       Mean reward: 126.14
               Mean episode length: 961.01
       Episode_Reward/keep_balance: 0.9670
     Episode_Reward/rew_lin_vel_xy: 5.9635
      Episode_Reward/rew_ang_vel_z: 2.4107
    Episode_Reward/pen_base_height: -0.2928
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1702
   Episode_Reward/pen_joint_torque: -0.2292
    Episode_Reward/pen_joint_accel: -0.1168
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2553
Episode_Reward/pen_flat_orientation: -0.1048
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4676
   Episode_Reward/foot_landing_vel: -0.1426
   Episode_Reward/test_gait_reward: -0.9212
Metrics/base_velocity/error_vel_xy: 1.0105
Metrics/base_velocity/error_vel_yaw: 1.3175
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 1.09s
                        Total time: 1542.85s
                               ETA: 1727.0s

################################################################################
                     [1m Learning iteration 1416/3000 [0m                     

                       Computation: 89183 steps/s (collection: 0.975s, learning 0.127s)
               Value function loss: 0.6407
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8812
                     Learning rate: 0.0004
                       Mean reward: 129.64
               Mean episode length: 992.00
       Episode_Reward/keep_balance: 0.9933
     Episode_Reward/rew_lin_vel_xy: 6.1525
      Episode_Reward/rew_ang_vel_z: 2.4927
    Episode_Reward/pen_base_height: -0.3039
      Episode_Reward/pen_lin_vel_z: -0.0422
     Episode_Reward/pen_ang_vel_xy: -0.1639
   Episode_Reward/pen_joint_torque: -0.2424
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1217
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0919
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2587
Episode_Reward/pen_flat_orientation: -0.1007
  Episode_Reward/pen_feet_distance: -0.0170
Episode_Reward/pen_feet_regulation: -0.4834
   Episode_Reward/foot_landing_vel: -0.1376
   Episode_Reward/test_gait_reward: -0.9489
Metrics/base_velocity/error_vel_xy: 1.0101
Metrics/base_velocity/error_vel_yaw: 1.3369
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 1.10s
                        Total time: 1543.95s
                               ETA: 1725.9s

################################################################################
                     [1m Learning iteration 1417/3000 [0m                     

                       Computation: 87352 steps/s (collection: 0.997s, learning 0.129s)
               Value function loss: 0.5450
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8812
                     Learning rate: 0.0006
                       Mean reward: 131.45
               Mean episode length: 969.74
       Episode_Reward/keep_balance: 0.9775
     Episode_Reward/rew_lin_vel_xy: 6.1531
      Episode_Reward/rew_ang_vel_z: 2.4968
    Episode_Reward/pen_base_height: -0.3024
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1624
   Episode_Reward/pen_joint_torque: -0.2243
    Episode_Reward/pen_joint_accel: -0.1032
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2512
Episode_Reward/pen_flat_orientation: -0.1039
  Episode_Reward/pen_feet_distance: -0.0165
Episode_Reward/pen_feet_regulation: -0.4576
   Episode_Reward/foot_landing_vel: -0.1272
   Episode_Reward/test_gait_reward: -0.9232
Metrics/base_velocity/error_vel_xy: 0.9467
Metrics/base_velocity/error_vel_yaw: 1.2855
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 1.13s
                        Total time: 1545.08s
                               ETA: 1724.9s

################################################################################
                     [1m Learning iteration 1418/3000 [0m                     

                       Computation: 90232 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.6044
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8812
                     Learning rate: 0.0006
                       Mean reward: 129.37
               Mean episode length: 972.89
       Episode_Reward/keep_balance: 0.9728
     Episode_Reward/rew_lin_vel_xy: 6.0288
      Episode_Reward/rew_ang_vel_z: 2.3806
    Episode_Reward/pen_base_height: -0.2941
      Episode_Reward/pen_lin_vel_z: -0.0402
     Episode_Reward/pen_ang_vel_xy: -0.1729
   Episode_Reward/pen_joint_torque: -0.2273
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2589
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0189
Episode_Reward/pen_feet_regulation: -0.4821
   Episode_Reward/foot_landing_vel: -0.1414
   Episode_Reward/test_gait_reward: -0.9325
Metrics/base_velocity/error_vel_xy: 1.0045
Metrics/base_velocity/error_vel_yaw: 1.3838
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 1.09s
                        Total time: 1546.17s
                               ETA: 1723.8s

################################################################################
                     [1m Learning iteration 1419/3000 [0m                     

                       Computation: 88677 steps/s (collection: 0.981s, learning 0.127s)
               Value function loss: 0.5876
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8814
                     Learning rate: 0.0004
                       Mean reward: 130.91
               Mean episode length: 974.98
       Episode_Reward/keep_balance: 0.9823
     Episode_Reward/rew_lin_vel_xy: 6.1098
      Episode_Reward/rew_ang_vel_z: 2.4996
    Episode_Reward/pen_base_height: -0.2912
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1638
   Episode_Reward/pen_joint_torque: -0.2321
    Episode_Reward/pen_joint_accel: -0.1144
    Episode_Reward/pen_action_rate: -0.1172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2543
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0161
Episode_Reward/pen_feet_regulation: -0.4504
   Episode_Reward/foot_landing_vel: -0.1304
   Episode_Reward/test_gait_reward: -0.9266
Metrics/base_velocity/error_vel_xy: 0.9732
Metrics/base_velocity/error_vel_yaw: 1.2896
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 1.11s
                        Total time: 1547.28s
                               ETA: 1722.7s

################################################################################
                     [1m Learning iteration 1420/3000 [0m                     

                       Computation: 87822 steps/s (collection: 0.991s, learning 0.129s)
               Value function loss: 0.5968
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8795
                     Learning rate: 0.0009
                       Mean reward: 129.45
               Mean episode length: 983.96
       Episode_Reward/keep_balance: 0.9788
     Episode_Reward/rew_lin_vel_xy: 6.0791
      Episode_Reward/rew_ang_vel_z: 2.4430
    Episode_Reward/pen_base_height: -0.2990
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1774
   Episode_Reward/pen_joint_torque: -0.2303
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2588
Episode_Reward/pen_flat_orientation: -0.1017
  Episode_Reward/pen_feet_distance: -0.0205
Episode_Reward/pen_feet_regulation: -0.4714
   Episode_Reward/foot_landing_vel: -0.1381
   Episode_Reward/test_gait_reward: -0.9274
Metrics/base_velocity/error_vel_xy: 1.0098
Metrics/base_velocity/error_vel_yaw: 1.3444
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 1.12s
                        Total time: 1548.40s
                               ETA: 1721.7s

################################################################################
                     [1m Learning iteration 1421/3000 [0m                     

                       Computation: 88906 steps/s (collection: 0.980s, learning 0.126s)
               Value function loss: 0.5868
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8806
                     Learning rate: 0.0006
                       Mean reward: 127.89
               Mean episode length: 979.17
       Episode_Reward/keep_balance: 0.9846
     Episode_Reward/rew_lin_vel_xy: 6.0916
      Episode_Reward/rew_ang_vel_z: 2.4575
    Episode_Reward/pen_base_height: -0.3039
      Episode_Reward/pen_lin_vel_z: -0.0410
     Episode_Reward/pen_ang_vel_xy: -0.1723
   Episode_Reward/pen_joint_torque: -0.2285
    Episode_Reward/pen_joint_accel: -0.1171
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2596
Episode_Reward/pen_flat_orientation: -0.1071
  Episode_Reward/pen_feet_distance: -0.0172
Episode_Reward/pen_feet_regulation: -0.4746
   Episode_Reward/foot_landing_vel: -0.1371
   Episode_Reward/test_gait_reward: -0.9365
Metrics/base_velocity/error_vel_xy: 1.0022
Metrics/base_velocity/error_vel_yaw: 1.3417
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 1.11s
                        Total time: 1549.50s
                               ETA: 1720.6s

################################################################################
                     [1m Learning iteration 1422/3000 [0m                     

                       Computation: 90236 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.5748
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8810
                     Learning rate: 0.0004
                       Mean reward: 126.94
               Mean episode length: 990.46
       Episode_Reward/keep_balance: 0.9879
     Episode_Reward/rew_lin_vel_xy: 6.0735
      Episode_Reward/rew_ang_vel_z: 2.4518
    Episode_Reward/pen_base_height: -0.3033
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.1744
   Episode_Reward/pen_joint_torque: -0.2366
    Episode_Reward/pen_joint_accel: -0.1130
    Episode_Reward/pen_action_rate: -0.1228
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0605
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2626
Episode_Reward/pen_flat_orientation: -0.1033
  Episode_Reward/pen_feet_distance: -0.0167
Episode_Reward/pen_feet_regulation: -0.5135
   Episode_Reward/foot_landing_vel: -0.1461
   Episode_Reward/test_gait_reward: -0.9366
Metrics/base_velocity/error_vel_xy: 1.0418
Metrics/base_velocity/error_vel_yaw: 1.3557
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 1.09s
                        Total time: 1550.59s
                               ETA: 1719.5s

################################################################################
                     [1m Learning iteration 1423/3000 [0m                     

                       Computation: 90955 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.5762
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8821
                     Learning rate: 0.0006
                       Mean reward: 128.60
               Mean episode length: 980.36
       Episode_Reward/keep_balance: 0.9880
     Episode_Reward/rew_lin_vel_xy: 6.1020
      Episode_Reward/rew_ang_vel_z: 2.4492
    Episode_Reward/pen_base_height: -0.3185
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.1741
   Episode_Reward/pen_joint_torque: -0.2431
    Episode_Reward/pen_joint_accel: -0.1110
    Episode_Reward/pen_action_rate: -0.1232
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0609
   Episode_Reward/pen_joint_powers: -0.0940
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2628
Episode_Reward/pen_flat_orientation: -0.1106
  Episode_Reward/pen_feet_distance: -0.0176
Episode_Reward/pen_feet_regulation: -0.5000
   Episode_Reward/foot_landing_vel: -0.1451
   Episode_Reward/test_gait_reward: -0.9426
Metrics/base_velocity/error_vel_xy: 1.0194
Metrics/base_velocity/error_vel_yaw: 1.3627
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 1.08s
                        Total time: 1551.67s
                               ETA: 1718.4s

################################################################################
                     [1m Learning iteration 1424/3000 [0m                     

                       Computation: 89300 steps/s (collection: 0.977s, learning 0.124s)
               Value function loss: 0.6222
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8816
                     Learning rate: 0.0004
                       Mean reward: 130.56
               Mean episode length: 980.91
       Episode_Reward/keep_balance: 0.9809
     Episode_Reward/rew_lin_vel_xy: 6.0954
      Episode_Reward/rew_ang_vel_z: 2.4809
    Episode_Reward/pen_base_height: -0.2968
      Episode_Reward/pen_lin_vel_z: -0.0413
     Episode_Reward/pen_ang_vel_xy: -0.1637
   Episode_Reward/pen_joint_torque: -0.2378
    Episode_Reward/pen_joint_accel: -0.1112
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2537
Episode_Reward/pen_flat_orientation: -0.1033
  Episode_Reward/pen_feet_distance: -0.0197
Episode_Reward/pen_feet_regulation: -0.4541
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.9300
Metrics/base_velocity/error_vel_xy: 0.9925
Metrics/base_velocity/error_vel_yaw: 1.3161
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 1.10s
                        Total time: 1552.77s
                               ETA: 1717.3s

################################################################################
                     [1m Learning iteration 1425/3000 [0m                     

                       Computation: 87954 steps/s (collection: 0.990s, learning 0.127s)
               Value function loss: 0.5827
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8801
                     Learning rate: 0.0006
                       Mean reward: 131.55
               Mean episode length: 983.94
       Episode_Reward/keep_balance: 0.9873
     Episode_Reward/rew_lin_vel_xy: 6.1459
      Episode_Reward/rew_ang_vel_z: 2.4722
    Episode_Reward/pen_base_height: -0.3051
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1667
   Episode_Reward/pen_joint_torque: -0.2332
    Episode_Reward/pen_joint_accel: -0.1015
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2552
Episode_Reward/pen_flat_orientation: -0.1019
  Episode_Reward/pen_feet_distance: -0.0190
Episode_Reward/pen_feet_regulation: -0.4842
   Episode_Reward/foot_landing_vel: -0.1411
   Episode_Reward/test_gait_reward: -0.9390
Metrics/base_velocity/error_vel_xy: 0.9937
Metrics/base_velocity/error_vel_yaw: 1.3468
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 1.12s
                        Total time: 1553.89s
                               ETA: 1716.3s

################################################################################
                     [1m Learning iteration 1426/3000 [0m                     

                       Computation: 89920 steps/s (collection: 0.966s, learning 0.127s)
               Value function loss: 0.6060
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8822
                     Learning rate: 0.0004
                       Mean reward: 131.69
               Mean episode length: 988.75
       Episode_Reward/keep_balance: 0.9903
     Episode_Reward/rew_lin_vel_xy: 6.0859
      Episode_Reward/rew_ang_vel_z: 2.5212
    Episode_Reward/pen_base_height: -0.3027
      Episode_Reward/pen_lin_vel_z: -0.0419
     Episode_Reward/pen_ang_vel_xy: -0.1724
   Episode_Reward/pen_joint_torque: -0.2441
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.1209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0916
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2580
Episode_Reward/pen_flat_orientation: -0.1029
  Episode_Reward/pen_feet_distance: -0.0187
Episode_Reward/pen_feet_regulation: -0.4831
   Episode_Reward/foot_landing_vel: -0.1380
   Episode_Reward/test_gait_reward: -0.9389
Metrics/base_velocity/error_vel_xy: 1.0260
Metrics/base_velocity/error_vel_yaw: 1.2963
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 1.09s
                        Total time: 1554.98s
                               ETA: 1715.2s

################################################################################
                     [1m Learning iteration 1427/3000 [0m                     

                       Computation: 88591 steps/s (collection: 0.985s, learning 0.125s)
               Value function loss: 0.6027
                    Surrogate loss: -0.0057
             Mean action noise std: 0.8829
                     Learning rate: 0.0006
                       Mean reward: 130.54
               Mean episode length: 980.52
       Episode_Reward/keep_balance: 0.9561
     Episode_Reward/rew_lin_vel_xy: 5.9199
      Episode_Reward/rew_ang_vel_z: 2.4248
    Episode_Reward/pen_base_height: -0.2860
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1609
   Episode_Reward/pen_joint_torque: -0.2313
    Episode_Reward/pen_joint_accel: -0.1035
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2460
Episode_Reward/pen_flat_orientation: -0.1045
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4657
   Episode_Reward/foot_landing_vel: -0.1375
   Episode_Reward/test_gait_reward: -0.9058
Metrics/base_velocity/error_vel_xy: 0.9764
Metrics/base_velocity/error_vel_yaw: 1.2724
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 1.11s
                        Total time: 1556.09s
                               ETA: 1714.1s

################################################################################
                     [1m Learning iteration 1428/3000 [0m                     

                       Computation: 89803 steps/s (collection: 0.966s, learning 0.129s)
               Value function loss: 0.6042
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8820
                     Learning rate: 0.0009
                       Mean reward: 129.97
               Mean episode length: 986.55
       Episode_Reward/keep_balance: 0.9906
     Episode_Reward/rew_lin_vel_xy: 6.1294
      Episode_Reward/rew_ang_vel_z: 2.4918
    Episode_Reward/pen_base_height: -0.3186
      Episode_Reward/pen_lin_vel_z: -0.0411
     Episode_Reward/pen_ang_vel_xy: -0.1645
   Episode_Reward/pen_joint_torque: -0.2305
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2542
Episode_Reward/pen_flat_orientation: -0.1040
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.4869
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9431
Metrics/base_velocity/error_vel_xy: 1.0196
Metrics/base_velocity/error_vel_yaw: 1.3377
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 1.09s
                        Total time: 1557.19s
                               ETA: 1713.0s

################################################################################
                     [1m Learning iteration 1429/3000 [0m                     

                       Computation: 89414 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 0.5775
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8792
                     Learning rate: 0.0013
                       Mean reward: 130.32
               Mean episode length: 979.94
       Episode_Reward/keep_balance: 0.9725
     Episode_Reward/rew_lin_vel_xy: 6.0603
      Episode_Reward/rew_ang_vel_z: 2.4514
    Episode_Reward/pen_base_height: -0.2954
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.1617
   Episode_Reward/pen_joint_torque: -0.2351
    Episode_Reward/pen_joint_accel: -0.1070
    Episode_Reward/pen_action_rate: -0.1172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2516
Episode_Reward/pen_flat_orientation: -0.1019
  Episode_Reward/pen_feet_distance: -0.0198
Episode_Reward/pen_feet_regulation: -0.4687
   Episode_Reward/foot_landing_vel: -0.1308
   Episode_Reward/test_gait_reward: -0.9298
Metrics/base_velocity/error_vel_xy: 0.9735
Metrics/base_velocity/error_vel_yaw: 1.3058
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 1.10s
                        Total time: 1558.29s
                               ETA: 1711.9s

################################################################################
                     [1m Learning iteration 1430/3000 [0m                     

                       Computation: 91924 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.6659
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8799
                     Learning rate: 0.0013
                       Mean reward: 132.11
               Mean episode length: 981.39
       Episode_Reward/keep_balance: 0.9807
     Episode_Reward/rew_lin_vel_xy: 6.1488
      Episode_Reward/rew_ang_vel_z: 2.5048
    Episode_Reward/pen_base_height: -0.3002
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1594
   Episode_Reward/pen_joint_torque: -0.2291
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1164
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2508
Episode_Reward/pen_flat_orientation: -0.0971
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4428
   Episode_Reward/foot_landing_vel: -0.1269
   Episode_Reward/test_gait_reward: -0.9256
Metrics/base_velocity/error_vel_xy: 0.9511
Metrics/base_velocity/error_vel_yaw: 1.2835
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 1.07s
                        Total time: 1559.36s
                               ETA: 1710.8s

################################################################################
                     [1m Learning iteration 1431/3000 [0m                     

                       Computation: 89698 steps/s (collection: 0.970s, learning 0.126s)
               Value function loss: 0.5674
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8807
                     Learning rate: 0.0004
                       Mean reward: 127.80
               Mean episode length: 963.94
       Episode_Reward/keep_balance: 0.9449
     Episode_Reward/rew_lin_vel_xy: 5.8170
      Episode_Reward/rew_ang_vel_z: 2.3581
    Episode_Reward/pen_base_height: -0.2851
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1660
   Episode_Reward/pen_joint_torque: -0.2176
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.1157
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2491
Episode_Reward/pen_flat_orientation: -0.1050
  Episode_Reward/pen_feet_distance: -0.0166
Episode_Reward/pen_feet_regulation: -0.4550
   Episode_Reward/foot_landing_vel: -0.1350
   Episode_Reward/test_gait_reward: -0.9035
Metrics/base_velocity/error_vel_xy: 0.9712
Metrics/base_velocity/error_vel_yaw: 1.2927
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 1.10s
                        Total time: 1560.45s
                               ETA: 1709.7s

################################################################################
                     [1m Learning iteration 1432/3000 [0m                     

                       Computation: 89261 steps/s (collection: 0.975s, learning 0.126s)
               Value function loss: 0.6055
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8791
                     Learning rate: 0.0004
                       Mean reward: 129.05
               Mean episode length: 983.91
       Episode_Reward/keep_balance: 0.9806
     Episode_Reward/rew_lin_vel_xy: 6.0286
      Episode_Reward/rew_ang_vel_z: 2.4296
    Episode_Reward/pen_base_height: -0.2916
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.1685
   Episode_Reward/pen_joint_torque: -0.2314
    Episode_Reward/pen_joint_accel: -0.1150
    Episode_Reward/pen_action_rate: -0.1198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0916
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2576
Episode_Reward/pen_flat_orientation: -0.0982
  Episode_Reward/pen_feet_distance: -0.0224
Episode_Reward/pen_feet_regulation: -0.5014
   Episode_Reward/foot_landing_vel: -0.1446
   Episode_Reward/test_gait_reward: -0.9395
Metrics/base_velocity/error_vel_xy: 1.0398
Metrics/base_velocity/error_vel_yaw: 1.3534
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 1.10s
                        Total time: 1561.55s
                               ETA: 1708.7s

################################################################################
                     [1m Learning iteration 1433/3000 [0m                     

                       Computation: 90396 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.5875
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8791
                     Learning rate: 0.0003
                       Mean reward: 129.52
               Mean episode length: 979.50
       Episode_Reward/keep_balance: 0.9756
     Episode_Reward/rew_lin_vel_xy: 5.9902
      Episode_Reward/rew_ang_vel_z: 2.4246
    Episode_Reward/pen_base_height: -0.3023
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1762
   Episode_Reward/pen_joint_torque: -0.2185
    Episode_Reward/pen_joint_accel: -0.1127
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0603
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2586
Episode_Reward/pen_flat_orientation: -0.1056
  Episode_Reward/pen_feet_distance: -0.0221
Episode_Reward/pen_feet_regulation: -0.4929
   Episode_Reward/foot_landing_vel: -0.1352
   Episode_Reward/test_gait_reward: -0.9297
Metrics/base_velocity/error_vel_xy: 1.0267
Metrics/base_velocity/error_vel_yaw: 1.3442
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 1.09s
                        Total time: 1562.64s
                               ETA: 1707.6s

################################################################################
                     [1m Learning iteration 1434/3000 [0m                     

                       Computation: 90752 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.5770
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8787
                     Learning rate: 0.0004
                       Mean reward: 133.39
               Mean episode length: 991.91
       Episode_Reward/keep_balance: 0.9871
     Episode_Reward/rew_lin_vel_xy: 6.1372
      Episode_Reward/rew_ang_vel_z: 2.4883
    Episode_Reward/pen_base_height: -0.2894
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1680
   Episode_Reward/pen_joint_torque: -0.2312
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0900
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2579
Episode_Reward/pen_flat_orientation: -0.1027
  Episode_Reward/pen_feet_distance: -0.0219
Episode_Reward/pen_feet_regulation: -0.4778
   Episode_Reward/foot_landing_vel: -0.1359
   Episode_Reward/test_gait_reward: -0.9308
Metrics/base_velocity/error_vel_xy: 1.0046
Metrics/base_velocity/error_vel_yaw: 1.3187
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 1.08s
                        Total time: 1563.73s
                               ETA: 1706.5s

################################################################################
                     [1m Learning iteration 1435/3000 [0m                     

                       Computation: 90471 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.5795
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8788
                     Learning rate: 0.0006
                       Mean reward: 132.49
               Mean episode length: 982.94
       Episode_Reward/keep_balance: 0.9763
     Episode_Reward/rew_lin_vel_xy: 6.0611
      Episode_Reward/rew_ang_vel_z: 2.4928
    Episode_Reward/pen_base_height: -0.3151
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1640
   Episode_Reward/pen_joint_torque: -0.2406
    Episode_Reward/pen_joint_accel: -0.1050
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0908
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2528
Episode_Reward/pen_flat_orientation: -0.0995
  Episode_Reward/pen_feet_distance: -0.0219
Episode_Reward/pen_feet_regulation: -0.4637
   Episode_Reward/foot_landing_vel: -0.1442
   Episode_Reward/test_gait_reward: -0.9287
Metrics/base_velocity/error_vel_xy: 0.9925
Metrics/base_velocity/error_vel_yaw: 1.2828
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 1.09s
                        Total time: 1564.81s
                               ETA: 1705.4s

################################################################################
                     [1m Learning iteration 1436/3000 [0m                     

                       Computation: 90887 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.6626
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8793
                     Learning rate: 0.0006
                       Mean reward: 127.57
               Mean episode length: 968.85
       Episode_Reward/keep_balance: 0.9681
     Episode_Reward/rew_lin_vel_xy: 6.0071
      Episode_Reward/rew_ang_vel_z: 2.4117
    Episode_Reward/pen_base_height: -0.2922
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1700
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1125
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0891
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2559
Episode_Reward/pen_flat_orientation: -0.0990
  Episode_Reward/pen_feet_distance: -0.0200
Episode_Reward/pen_feet_regulation: -0.4803
   Episode_Reward/foot_landing_vel: -0.1409
   Episode_Reward/test_gait_reward: -0.9174
Metrics/base_velocity/error_vel_xy: 0.9831
Metrics/base_velocity/error_vel_yaw: 1.3261
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 1.08s
                        Total time: 1565.89s
                               ETA: 1704.3s

################################################################################
                     [1m Learning iteration 1437/3000 [0m                     

                       Computation: 91371 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.6620
                    Surrogate loss: -0.0005
             Mean action noise std: 0.8786
                     Learning rate: 0.0002
                       Mean reward: 127.65
               Mean episode length: 967.08
       Episode_Reward/keep_balance: 0.9482
     Episode_Reward/rew_lin_vel_xy: 5.8759
      Episode_Reward/rew_ang_vel_z: 2.3845
    Episode_Reward/pen_base_height: -0.2924
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1626
   Episode_Reward/pen_joint_torque: -0.2230
    Episode_Reward/pen_joint_accel: -0.1190
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2490
Episode_Reward/pen_flat_orientation: -0.0983
  Episode_Reward/pen_feet_distance: -0.0191
Episode_Reward/pen_feet_regulation: -0.4715
   Episode_Reward/foot_landing_vel: -0.1438
   Episode_Reward/test_gait_reward: -0.9004
Metrics/base_velocity/error_vel_xy: 0.9668
Metrics/base_velocity/error_vel_yaw: 1.2683
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 1.08s
                        Total time: 1566.97s
                               ETA: 1703.2s

################################################################################
                     [1m Learning iteration 1438/3000 [0m                     

                       Computation: 92002 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 0.5882
                    Surrogate loss: -0.0055
             Mean action noise std: 0.8765
                     Learning rate: 0.0004
                       Mean reward: 128.04
               Mean episode length: 980.09
       Episode_Reward/keep_balance: 0.9850
     Episode_Reward/rew_lin_vel_xy: 6.0635
      Episode_Reward/rew_ang_vel_z: 2.4425
    Episode_Reward/pen_base_height: -0.3072
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1609
   Episode_Reward/pen_joint_torque: -0.2334
    Episode_Reward/pen_joint_accel: -0.1030
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2564
Episode_Reward/pen_flat_orientation: -0.1064
  Episode_Reward/pen_feet_distance: -0.0270
Episode_Reward/pen_feet_regulation: -0.4950
   Episode_Reward/foot_landing_vel: -0.1302
   Episode_Reward/test_gait_reward: -0.9492
Metrics/base_velocity/error_vel_xy: 1.0303
Metrics/base_velocity/error_vel_yaw: 1.3595
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 1.07s
                        Total time: 1568.04s
                               ETA: 1702.1s

################################################################################
                     [1m Learning iteration 1439/3000 [0m                     

                       Computation: 90697 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.5954
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8774
                     Learning rate: 0.0006
                       Mean reward: 126.90
               Mean episode length: 994.31
       Episode_Reward/keep_balance: 0.9957
     Episode_Reward/rew_lin_vel_xy: 6.1331
      Episode_Reward/rew_ang_vel_z: 2.4545
    Episode_Reward/pen_base_height: -0.3191
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1805
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.1111
    Episode_Reward/pen_action_rate: -0.1226
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0919
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2659
Episode_Reward/pen_flat_orientation: -0.1127
  Episode_Reward/pen_feet_distance: -0.0222
Episode_Reward/pen_feet_regulation: -0.4909
   Episode_Reward/foot_landing_vel: -0.1411
   Episode_Reward/test_gait_reward: -0.9544
Metrics/base_velocity/error_vel_xy: 1.0493
Metrics/base_velocity/error_vel_yaw: 1.3888
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 1.08s
                        Total time: 1569.12s
                               ETA: 1701.0s

################################################################################
                     [1m Learning iteration 1440/3000 [0m                     

                       Computation: 91413 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.5349
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8775
                     Learning rate: 0.0003
                       Mean reward: 129.51
               Mean episode length: 984.89
       Episode_Reward/keep_balance: 0.9694
     Episode_Reward/rew_lin_vel_xy: 5.9819
      Episode_Reward/rew_ang_vel_z: 2.3986
    Episode_Reward/pen_base_height: -0.3064
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.1650
   Episode_Reward/pen_joint_torque: -0.2363
    Episode_Reward/pen_joint_accel: -0.1092
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0922
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2549
Episode_Reward/pen_flat_orientation: -0.1064
  Episode_Reward/pen_feet_distance: -0.0232
Episode_Reward/pen_feet_regulation: -0.4866
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9259
Metrics/base_velocity/error_vel_xy: 1.0071
Metrics/base_velocity/error_vel_yaw: 1.3469
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 1.08s
                        Total time: 1570.20s
                               ETA: 1699.9s

################################################################################
                     [1m Learning iteration 1441/3000 [0m                     

                       Computation: 89953 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.5753
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8757
                     Learning rate: 0.0006
                       Mean reward: 131.89
               Mean episode length: 995.98
       Episode_Reward/keep_balance: 0.9958
     Episode_Reward/rew_lin_vel_xy: 6.1773
      Episode_Reward/rew_ang_vel_z: 2.5190
    Episode_Reward/pen_base_height: -0.3281
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1688
   Episode_Reward/pen_joint_torque: -0.2459
    Episode_Reward/pen_joint_accel: -0.1122
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0586
   Episode_Reward/pen_joint_powers: -0.0929
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2576
Episode_Reward/pen_flat_orientation: -0.1009
  Episode_Reward/pen_feet_distance: -0.0274
Episode_Reward/pen_feet_regulation: -0.4878
   Episode_Reward/foot_landing_vel: -0.1351
   Episode_Reward/test_gait_reward: -0.9480
Metrics/base_velocity/error_vel_xy: 1.0142
Metrics/base_velocity/error_vel_yaw: 1.3152
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 1.09s
                        Total time: 1571.29s
                               ETA: 1698.8s

################################################################################
                     [1m Learning iteration 1442/3000 [0m                     

                       Computation: 91057 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.5803
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8744
                     Learning rate: 0.0004
                       Mean reward: 130.06
               Mean episode length: 991.88
       Episode_Reward/keep_balance: 0.9921
     Episode_Reward/rew_lin_vel_xy: 6.1409
      Episode_Reward/rew_ang_vel_z: 2.4510
    Episode_Reward/pen_base_height: -0.3257
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1755
   Episode_Reward/pen_joint_torque: -0.2377
    Episode_Reward/pen_joint_accel: -0.1164
    Episode_Reward/pen_action_rate: -0.1229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0611
   Episode_Reward/pen_joint_powers: -0.0934
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2633
Episode_Reward/pen_flat_orientation: -0.1074
  Episode_Reward/pen_feet_distance: -0.0270
Episode_Reward/pen_feet_regulation: -0.5032
   Episode_Reward/foot_landing_vel: -0.1357
   Episode_Reward/test_gait_reward: -0.9493
Metrics/base_velocity/error_vel_xy: 1.0246
Metrics/base_velocity/error_vel_yaw: 1.3768
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 1.08s
                        Total time: 1572.37s
                               ETA: 1697.7s

################################################################################
                     [1m Learning iteration 1443/3000 [0m                     

                       Computation: 90847 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.6463
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8754
                     Learning rate: 0.0002
                       Mean reward: 135.75
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 0.9953
     Episode_Reward/rew_lin_vel_xy: 6.2864
      Episode_Reward/rew_ang_vel_z: 2.5483
    Episode_Reward/pen_base_height: -0.2947
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1629
   Episode_Reward/pen_joint_torque: -0.2302
    Episode_Reward/pen_joint_accel: -0.1191
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2549
Episode_Reward/pen_flat_orientation: -0.0944
  Episode_Reward/pen_feet_distance: -0.0218
Episode_Reward/pen_feet_regulation: -0.4658
   Episode_Reward/foot_landing_vel: -0.1483
   Episode_Reward/test_gait_reward: -0.9393
Metrics/base_velocity/error_vel_xy: 0.9521
Metrics/base_velocity/error_vel_yaw: 1.2915
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 1.08s
                        Total time: 1573.45s
                               ETA: 1696.6s

################################################################################
                     [1m Learning iteration 1444/3000 [0m                     

                       Computation: 90289 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.6311
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8765
                     Learning rate: 0.0002
                       Mean reward: 132.61
               Mean episode length: 988.23
       Episode_Reward/keep_balance: 0.9887
     Episode_Reward/rew_lin_vel_xy: 6.1976
      Episode_Reward/rew_ang_vel_z: 2.4851
    Episode_Reward/pen_base_height: -0.3066
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1654
   Episode_Reward/pen_joint_torque: -0.2305
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2561
Episode_Reward/pen_flat_orientation: -0.1043
  Episode_Reward/pen_feet_distance: -0.0207
Episode_Reward/pen_feet_regulation: -0.4928
   Episode_Reward/foot_landing_vel: -0.1309
   Episode_Reward/test_gait_reward: -0.9506
Metrics/base_velocity/error_vel_xy: 0.9737
Metrics/base_velocity/error_vel_yaw: 1.3375
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 1.09s
                        Total time: 1574.54s
                               ETA: 1695.5s

################################################################################
                     [1m Learning iteration 1445/3000 [0m                     

                       Computation: 90156 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.6535
                    Surrogate loss: -0.0012
             Mean action noise std: 0.8775
                     Learning rate: 0.0002
                       Mean reward: 132.03
               Mean episode length: 980.78
       Episode_Reward/keep_balance: 0.9563
     Episode_Reward/rew_lin_vel_xy: 5.9952
      Episode_Reward/rew_ang_vel_z: 2.4560
    Episode_Reward/pen_base_height: -0.3109
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1679
   Episode_Reward/pen_joint_torque: -0.2272
    Episode_Reward/pen_joint_accel: -0.1028
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2470
Episode_Reward/pen_flat_orientation: -0.0954
  Episode_Reward/pen_feet_distance: -0.0176
Episode_Reward/pen_feet_regulation: -0.4556
   Episode_Reward/foot_landing_vel: -0.1303
   Episode_Reward/test_gait_reward: -0.9040
Metrics/base_velocity/error_vel_xy: 0.9499
Metrics/base_velocity/error_vel_yaw: 1.2414
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 1.09s
                        Total time: 1575.63s
                               ETA: 1694.4s

################################################################################
                     [1m Learning iteration 1446/3000 [0m                     

                       Computation: 90381 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 0.5986
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8773
                     Learning rate: 0.0004
                       Mean reward: 130.23
               Mean episode length: 980.12
       Episode_Reward/keep_balance: 0.9799
     Episode_Reward/rew_lin_vel_xy: 6.1013
      Episode_Reward/rew_ang_vel_z: 2.4762
    Episode_Reward/pen_base_height: -0.3144
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1683
   Episode_Reward/pen_joint_torque: -0.2357
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1195
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0911
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2537
Episode_Reward/pen_flat_orientation: -0.1014
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4777
   Episode_Reward/foot_landing_vel: -0.1357
   Episode_Reward/test_gait_reward: -0.9307
Metrics/base_velocity/error_vel_xy: 0.9935
Metrics/base_velocity/error_vel_yaw: 1.3114
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 1.09s
                        Total time: 1576.72s
                               ETA: 1693.3s

################################################################################
                     [1m Learning iteration 1447/3000 [0m                     

                       Computation: 90770 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.5987
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8773
                     Learning rate: 0.0003
                       Mean reward: 127.97
               Mean episode length: 971.72
       Episode_Reward/keep_balance: 0.9762
     Episode_Reward/rew_lin_vel_xy: 6.0822
      Episode_Reward/rew_ang_vel_z: 2.4468
    Episode_Reward/pen_base_height: -0.3078
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1667
   Episode_Reward/pen_joint_torque: -0.2308
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.1187
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0593
   Episode_Reward/pen_joint_powers: -0.0915
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2537
Episode_Reward/pen_flat_orientation: -0.1059
  Episode_Reward/pen_feet_distance: -0.0255
Episode_Reward/pen_feet_regulation: -0.5004
   Episode_Reward/foot_landing_vel: -0.1425
   Episode_Reward/test_gait_reward: -0.9335
Metrics/base_velocity/error_vel_xy: 0.9866
Metrics/base_velocity/error_vel_yaw: 1.3321
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 1.08s
                        Total time: 1577.80s
                               ETA: 1692.2s

################################################################################
                     [1m Learning iteration 1448/3000 [0m                     

                       Computation: 90621 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 0.6298
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8768
                     Learning rate: 0.0006
                       Mean reward: 129.06
               Mean episode length: 988.82
       Episode_Reward/keep_balance: 0.9904
     Episode_Reward/rew_lin_vel_xy: 6.0750
      Episode_Reward/rew_ang_vel_z: 2.5034
    Episode_Reward/pen_base_height: -0.3259
      Episode_Reward/pen_lin_vel_z: -0.0406
     Episode_Reward/pen_ang_vel_xy: -0.1644
   Episode_Reward/pen_joint_torque: -0.2517
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1219
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0951
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2579
Episode_Reward/pen_flat_orientation: -0.1055
  Episode_Reward/pen_feet_distance: -0.0261
Episode_Reward/pen_feet_regulation: -0.4925
   Episode_Reward/foot_landing_vel: -0.1505
   Episode_Reward/test_gait_reward: -0.9415
Metrics/base_velocity/error_vel_xy: 1.0431
Metrics/base_velocity/error_vel_yaw: 1.3214
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 1.08s
                        Total time: 1578.89s
                               ETA: 1691.1s

################################################################################
                     [1m Learning iteration 1449/3000 [0m                     

                       Computation: 91150 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.5801
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8769
                     Learning rate: 0.0003
                       Mean reward: 129.21
               Mean episode length: 978.92
       Episode_Reward/keep_balance: 0.9882
     Episode_Reward/rew_lin_vel_xy: 6.1891
      Episode_Reward/rew_ang_vel_z: 2.4877
    Episode_Reward/pen_base_height: -0.3153
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1651
   Episode_Reward/pen_joint_torque: -0.2355
    Episode_Reward/pen_joint_accel: -0.1071
    Episode_Reward/pen_action_rate: -0.1202
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2562
Episode_Reward/pen_flat_orientation: -0.0981
  Episode_Reward/pen_feet_distance: -0.0222
Episode_Reward/pen_feet_regulation: -0.4810
   Episode_Reward/foot_landing_vel: -0.1417
   Episode_Reward/test_gait_reward: -0.9388
Metrics/base_velocity/error_vel_xy: 0.9896
Metrics/base_velocity/error_vel_yaw: 1.3283
      Episode_Termination/time_out: 4.8333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 1.08s
                        Total time: 1579.96s
                               ETA: 1690.0s

################################################################################
                     [1m Learning iteration 1450/3000 [0m                     

                       Computation: 91126 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.6943
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8751
                     Learning rate: 0.0009
                       Mean reward: 127.73
               Mean episode length: 964.24
       Episode_Reward/keep_balance: 0.9771
     Episode_Reward/rew_lin_vel_xy: 6.0924
      Episode_Reward/rew_ang_vel_z: 2.5004
    Episode_Reward/pen_base_height: -0.3023
      Episode_Reward/pen_lin_vel_z: -0.0419
     Episode_Reward/pen_ang_vel_xy: -0.1636
   Episode_Reward/pen_joint_torque: -0.2357
    Episode_Reward/pen_joint_accel: -0.1089
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2514
Episode_Reward/pen_flat_orientation: -0.0973
  Episode_Reward/pen_feet_distance: -0.0151
Episode_Reward/pen_feet_regulation: -0.4730
   Episode_Reward/foot_landing_vel: -0.1416
   Episode_Reward/test_gait_reward: -0.9264
Metrics/base_velocity/error_vel_xy: 0.9845
Metrics/base_velocity/error_vel_yaw: 1.2661
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 1.08s
                        Total time: 1581.04s
                               ETA: 1688.9s

################################################################################
                     [1m Learning iteration 1451/3000 [0m                     

                       Computation: 90436 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.6373
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8745
                     Learning rate: 0.0004
                       Mean reward: 130.02
               Mean episode length: 978.35
       Episode_Reward/keep_balance: 0.9752
     Episode_Reward/rew_lin_vel_xy: 6.0125
      Episode_Reward/rew_ang_vel_z: 2.4486
    Episode_Reward/pen_base_height: -0.3090
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1654
   Episode_Reward/pen_joint_torque: -0.2213
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2509
Episode_Reward/pen_flat_orientation: -0.1027
  Episode_Reward/pen_feet_distance: -0.0217
Episode_Reward/pen_feet_regulation: -0.4765
   Episode_Reward/foot_landing_vel: -0.1407
   Episode_Reward/test_gait_reward: -0.9226
Metrics/base_velocity/error_vel_xy: 1.0047
Metrics/base_velocity/error_vel_yaw: 1.3128
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 1.09s
                        Total time: 1582.13s
                               ETA: 1687.8s

################################################################################
                     [1m Learning iteration 1452/3000 [0m                     

                       Computation: 89799 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 0.5141
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8734
                     Learning rate: 0.0006
                       Mean reward: 130.27
               Mean episode length: 973.04
       Episode_Reward/keep_balance: 0.9587
     Episode_Reward/rew_lin_vel_xy: 5.9650
      Episode_Reward/rew_ang_vel_z: 2.4028
    Episode_Reward/pen_base_height: -0.3170
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1684
   Episode_Reward/pen_joint_torque: -0.2289
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2522
Episode_Reward/pen_flat_orientation: -0.1047
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4787
   Episode_Reward/foot_landing_vel: -0.1294
   Episode_Reward/test_gait_reward: -0.9183
Metrics/base_velocity/error_vel_xy: 0.9786
Metrics/base_velocity/error_vel_yaw: 1.3137
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 1.09s
                        Total time: 1583.23s
                               ETA: 1686.7s

################################################################################
                     [1m Learning iteration 1453/3000 [0m                     

                       Computation: 90269 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.6655
                    Surrogate loss: 0.0005
             Mean action noise std: 0.8733
                     Learning rate: 0.0002
                       Mean reward: 128.43
               Mean episode length: 975.00
       Episode_Reward/keep_balance: 0.9721
     Episode_Reward/rew_lin_vel_xy: 6.0965
      Episode_Reward/rew_ang_vel_z: 2.4509
    Episode_Reward/pen_base_height: -0.3242
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1635
   Episode_Reward/pen_joint_torque: -0.2335
    Episode_Reward/pen_joint_accel: -0.1078
    Episode_Reward/pen_action_rate: -0.1187
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0896
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2518
Episode_Reward/pen_flat_orientation: -0.1013
  Episode_Reward/pen_feet_distance: -0.0193
Episode_Reward/pen_feet_regulation: -0.4922
   Episode_Reward/foot_landing_vel: -0.1452
   Episode_Reward/test_gait_reward: -0.9182
Metrics/base_velocity/error_vel_xy: 0.9820
Metrics/base_velocity/error_vel_yaw: 1.3240
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 1.09s
                        Total time: 1584.31s
                               ETA: 1685.6s

################################################################################
                     [1m Learning iteration 1454/3000 [0m                     

                       Computation: 91694 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.5289
                    Surrogate loss: -0.0055
             Mean action noise std: 0.8728
                     Learning rate: 0.0004
                       Mean reward: 128.09
               Mean episode length: 975.88
       Episode_Reward/keep_balance: 0.9684
     Episode_Reward/rew_lin_vel_xy: 6.0432
      Episode_Reward/rew_ang_vel_z: 2.3848
    Episode_Reward/pen_base_height: -0.3166
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1653
   Episode_Reward/pen_joint_torque: -0.2330
    Episode_Reward/pen_joint_accel: -0.1033
    Episode_Reward/pen_action_rate: -0.1178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2536
Episode_Reward/pen_flat_orientation: -0.1038
  Episode_Reward/pen_feet_distance: -0.0231
Episode_Reward/pen_feet_regulation: -0.4772
   Episode_Reward/foot_landing_vel: -0.1342
   Episode_Reward/test_gait_reward: -0.9214
Metrics/base_velocity/error_vel_xy: 0.9774
Metrics/base_velocity/error_vel_yaw: 1.3552
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 1.07s
                        Total time: 1585.39s
                               ETA: 1684.5s

################################################################################
                     [1m Learning iteration 1455/3000 [0m                     

                       Computation: 91652 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.6552
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8724
                     Learning rate: 0.0006
                       Mean reward: 131.05
               Mean episode length: 981.33
       Episode_Reward/keep_balance: 0.9634
     Episode_Reward/rew_lin_vel_xy: 6.0235
      Episode_Reward/rew_ang_vel_z: 2.4284
    Episode_Reward/pen_base_height: -0.3205
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1621
   Episode_Reward/pen_joint_torque: -0.2344
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2495
Episode_Reward/pen_flat_orientation: -0.1038
  Episode_Reward/pen_feet_distance: -0.0224
Episode_Reward/pen_feet_regulation: -0.4766
   Episode_Reward/foot_landing_vel: -0.1314
   Episode_Reward/test_gait_reward: -0.9224
Metrics/base_velocity/error_vel_xy: 0.9610
Metrics/base_velocity/error_vel_yaw: 1.2947
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 1.07s
                        Total time: 1586.46s
                               ETA: 1683.4s

################################################################################
                     [1m Learning iteration 1456/3000 [0m                     

                       Computation: 89382 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.6061
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8722
                     Learning rate: 0.0004
                       Mean reward: 130.31
               Mean episode length: 967.23
       Episode_Reward/keep_balance: 0.9303
     Episode_Reward/rew_lin_vel_xy: 5.7869
      Episode_Reward/rew_ang_vel_z: 2.3571
    Episode_Reward/pen_base_height: -0.2990
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1624
   Episode_Reward/pen_joint_torque: -0.2132
    Episode_Reward/pen_joint_accel: -0.1017
    Episode_Reward/pen_action_rate: -0.1122
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2413
Episode_Reward/pen_flat_orientation: -0.1133
  Episode_Reward/pen_feet_distance: -0.0228
Episode_Reward/pen_feet_regulation: -0.4401
   Episode_Reward/foot_landing_vel: -0.1476
   Episode_Reward/test_gait_reward: -0.8711
Metrics/base_velocity/error_vel_xy: 0.9348
Metrics/base_velocity/error_vel_yaw: 1.2494
      Episode_Termination/time_out: 3.0833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 1.10s
                        Total time: 1587.56s
                               ETA: 1682.4s

################################################################################
                     [1m Learning iteration 1457/3000 [0m                     

                       Computation: 90981 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 0.6573
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8733
                     Learning rate: 0.0004
                       Mean reward: 129.96
               Mean episode length: 979.51
       Episode_Reward/keep_balance: 0.9852
     Episode_Reward/rew_lin_vel_xy: 6.1153
      Episode_Reward/rew_ang_vel_z: 2.4649
    Episode_Reward/pen_base_height: -0.3247
      Episode_Reward/pen_lin_vel_z: -0.0415
     Episode_Reward/pen_ang_vel_xy: -0.1669
   Episode_Reward/pen_joint_torque: -0.2406
    Episode_Reward/pen_joint_accel: -0.1050
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0915
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2569
Episode_Reward/pen_flat_orientation: -0.0989
  Episode_Reward/pen_feet_distance: -0.0213
Episode_Reward/pen_feet_regulation: -0.4921
   Episode_Reward/foot_landing_vel: -0.1387
   Episode_Reward/test_gait_reward: -0.9384
Metrics/base_velocity/error_vel_xy: 1.0011
Metrics/base_velocity/error_vel_yaw: 1.3268
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 1.08s
                        Total time: 1588.64s
                               ETA: 1681.3s

################################################################################
                     [1m Learning iteration 1458/3000 [0m                     

                       Computation: 89467 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.5831
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8733
                     Learning rate: 0.0009
                       Mean reward: 128.99
               Mean episode length: 966.43
       Episode_Reward/keep_balance: 0.9753
     Episode_Reward/rew_lin_vel_xy: 6.0975
      Episode_Reward/rew_ang_vel_z: 2.4718
    Episode_Reward/pen_base_height: -0.3267
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1632
   Episode_Reward/pen_joint_torque: -0.2326
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.1178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2511
Episode_Reward/pen_flat_orientation: -0.0972
  Episode_Reward/pen_feet_distance: -0.0226
Episode_Reward/pen_feet_regulation: -0.4928
   Episode_Reward/foot_landing_vel: -0.1349
   Episode_Reward/test_gait_reward: -0.9256
Metrics/base_velocity/error_vel_xy: 0.9788
Metrics/base_velocity/error_vel_yaw: 1.2953
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 1.10s
                        Total time: 1589.74s
                               ETA: 1680.2s

################################################################################
                     [1m Learning iteration 1459/3000 [0m                     

                       Computation: 92063 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.5699
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8728
                     Learning rate: 0.0006
                       Mean reward: 128.59
               Mean episode length: 973.70
       Episode_Reward/keep_balance: 0.9694
     Episode_Reward/rew_lin_vel_xy: 6.0223
      Episode_Reward/rew_ang_vel_z: 2.4449
    Episode_Reward/pen_base_height: -0.3240
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1646
   Episode_Reward/pen_joint_torque: -0.2226
    Episode_Reward/pen_joint_accel: -0.1005
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2482
Episode_Reward/pen_flat_orientation: -0.1009
  Episode_Reward/pen_feet_distance: -0.0220
Episode_Reward/pen_feet_regulation: -0.4666
   Episode_Reward/foot_landing_vel: -0.1326
   Episode_Reward/test_gait_reward: -0.9203
Metrics/base_velocity/error_vel_xy: 1.0033
Metrics/base_velocity/error_vel_yaw: 1.2946
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 1.07s
                        Total time: 1590.81s
                               ETA: 1679.1s

################################################################################
                     [1m Learning iteration 1460/3000 [0m                     

                       Computation: 91881 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 0.6110
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8739
                     Learning rate: 0.0004
                       Mean reward: 125.88
               Mean episode length: 961.95
       Episode_Reward/keep_balance: 0.9527
     Episode_Reward/rew_lin_vel_xy: 5.9511
      Episode_Reward/rew_ang_vel_z: 2.3484
    Episode_Reward/pen_base_height: -0.3057
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1719
   Episode_Reward/pen_joint_torque: -0.2247
    Episode_Reward/pen_joint_accel: -0.1052
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2507
Episode_Reward/pen_flat_orientation: -0.0986
  Episode_Reward/pen_feet_distance: -0.0174
Episode_Reward/pen_feet_regulation: -0.4558
   Episode_Reward/foot_landing_vel: -0.1413
   Episode_Reward/test_gait_reward: -0.8977
Metrics/base_velocity/error_vel_xy: 0.9557
Metrics/base_velocity/error_vel_yaw: 1.3410
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 1.07s
                        Total time: 1591.88s
                               ETA: 1678.0s

################################################################################
                     [1m Learning iteration 1461/3000 [0m                     

                       Computation: 90514 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.6094
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8744
                     Learning rate: 0.0003
                       Mean reward: 130.30
               Mean episode length: 975.40
       Episode_Reward/keep_balance: 0.9662
     Episode_Reward/rew_lin_vel_xy: 6.0164
      Episode_Reward/rew_ang_vel_z: 2.4485
    Episode_Reward/pen_base_height: -0.3202
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.1640
   Episode_Reward/pen_joint_torque: -0.2301
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.1168
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2491
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0200
Episode_Reward/pen_feet_regulation: -0.4744
   Episode_Reward/foot_landing_vel: -0.1268
   Episode_Reward/test_gait_reward: -0.9161
Metrics/base_velocity/error_vel_xy: 0.9773
Metrics/base_velocity/error_vel_yaw: 1.2946
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 1.09s
                        Total time: 1592.96s
                               ETA: 1676.9s

################################################################################
                     [1m Learning iteration 1462/3000 [0m                     

                       Computation: 90702 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.6143
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8745
                     Learning rate: 0.0004
                       Mean reward: 132.08
               Mean episode length: 978.86
       Episode_Reward/keep_balance: 0.9832
     Episode_Reward/rew_lin_vel_xy: 6.2065
      Episode_Reward/rew_ang_vel_z: 2.4780
    Episode_Reward/pen_base_height: -0.3046
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1701
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.1082
    Episode_Reward/pen_action_rate: -0.1180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2557
Episode_Reward/pen_flat_orientation: -0.0929
  Episode_Reward/pen_feet_distance: -0.0167
Episode_Reward/pen_feet_regulation: -0.4412
   Episode_Reward/foot_landing_vel: -0.1377
   Episode_Reward/test_gait_reward: -0.9228
Metrics/base_velocity/error_vel_xy: 0.9423
Metrics/base_velocity/error_vel_yaw: 1.3160
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 1.08s
                        Total time: 1594.05s
                               ETA: 1675.8s

################################################################################
                     [1m Learning iteration 1463/3000 [0m                     

                       Computation: 89644 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.7133
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8746
                     Learning rate: 0.0003
                       Mean reward: 131.18
               Mean episode length: 977.95
       Episode_Reward/keep_balance: 0.9719
     Episode_Reward/rew_lin_vel_xy: 6.0771
      Episode_Reward/rew_ang_vel_z: 2.4611
    Episode_Reward/pen_base_height: -0.3198
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1634
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1163
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2509
Episode_Reward/pen_flat_orientation: -0.0955
  Episode_Reward/pen_feet_distance: -0.0195
Episode_Reward/pen_feet_regulation: -0.4677
   Episode_Reward/foot_landing_vel: -0.1328
   Episode_Reward/test_gait_reward: -0.9214
Metrics/base_velocity/error_vel_xy: 0.9560
Metrics/base_velocity/error_vel_yaw: 1.2865
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 1.10s
                        Total time: 1595.14s
                               ETA: 1674.7s

################################################################################
                     [1m Learning iteration 1464/3000 [0m                     

                       Computation: 90586 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.6531
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8756
                     Learning rate: 0.0003
                       Mean reward: 129.09
               Mean episode length: 952.79
       Episode_Reward/keep_balance: 0.9480
     Episode_Reward/rew_lin_vel_xy: 5.9230
      Episode_Reward/rew_ang_vel_z: 2.3880
    Episode_Reward/pen_base_height: -0.3157
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1611
   Episode_Reward/pen_joint_torque: -0.2239
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.1133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0846
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2448
Episode_Reward/pen_flat_orientation: -0.0972
  Episode_Reward/pen_feet_distance: -0.0169
Episode_Reward/pen_feet_regulation: -0.4383
   Episode_Reward/foot_landing_vel: -0.1320
   Episode_Reward/test_gait_reward: -0.8942
Metrics/base_velocity/error_vel_xy: 0.9499
Metrics/base_velocity/error_vel_yaw: 1.2854
      Episode_Termination/time_out: 4.9583
  Episode_Termination/base_contact: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 1.09s
                        Total time: 1596.23s
                               ETA: 1673.6s

################################################################################
                     [1m Learning iteration 1465/3000 [0m                     

                       Computation: 90307 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.6024
                    Surrogate loss: -0.0056
             Mean action noise std: 0.8752
                     Learning rate: 0.0006
                       Mean reward: 126.83
               Mean episode length: 954.49
       Episode_Reward/keep_balance: 0.9480
     Episode_Reward/rew_lin_vel_xy: 5.9208
      Episode_Reward/rew_ang_vel_z: 2.3749
    Episode_Reward/pen_base_height: -0.3414
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1638
   Episode_Reward/pen_joint_torque: -0.2385
    Episode_Reward/pen_joint_accel: -0.1015
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2477
Episode_Reward/pen_flat_orientation: -0.1070
  Episode_Reward/pen_feet_distance: -0.0202
Episode_Reward/pen_feet_regulation: -0.4724
   Episode_Reward/foot_landing_vel: -0.1428
   Episode_Reward/test_gait_reward: -0.9080
Metrics/base_velocity/error_vel_xy: 0.9434
Metrics/base_velocity/error_vel_yaw: 1.2971
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 1.09s
                        Total time: 1597.32s
                               ETA: 1672.5s

################################################################################
                     [1m Learning iteration 1466/3000 [0m                     

                       Computation: 87930 steps/s (collection: 0.995s, learning 0.123s)
               Value function loss: 0.6251
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8745
                     Learning rate: 0.0004
                       Mean reward: 128.58
               Mean episode length: 967.87
       Episode_Reward/keep_balance: 0.9785
     Episode_Reward/rew_lin_vel_xy: 6.0793
      Episode_Reward/rew_ang_vel_z: 2.4766
    Episode_Reward/pen_base_height: -0.3136
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1639
   Episode_Reward/pen_joint_torque: -0.2304
    Episode_Reward/pen_joint_accel: -0.1029
    Episode_Reward/pen_action_rate: -0.1179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2529
Episode_Reward/pen_flat_orientation: -0.0998
  Episode_Reward/pen_feet_distance: -0.0208
Episode_Reward/pen_feet_regulation: -0.4693
   Episode_Reward/foot_landing_vel: -0.1510
   Episode_Reward/test_gait_reward: -0.9216
Metrics/base_velocity/error_vel_xy: 0.9970
Metrics/base_velocity/error_vel_yaw: 1.3033
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 1.12s
                        Total time: 1598.43s
                               ETA: 1671.4s

################################################################################
                     [1m Learning iteration 1467/3000 [0m                     

                       Computation: 87540 steps/s (collection: 0.996s, learning 0.127s)
               Value function loss: 0.6476
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8758
                     Learning rate: 0.0006
                       Mean reward: 129.93
               Mean episode length: 980.45
       Episode_Reward/keep_balance: 0.9762
     Episode_Reward/rew_lin_vel_xy: 5.9899
      Episode_Reward/rew_ang_vel_z: 2.4639
    Episode_Reward/pen_base_height: -0.3415
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1680
   Episode_Reward/pen_joint_torque: -0.2370
    Episode_Reward/pen_joint_accel: -0.0983
    Episode_Reward/pen_action_rate: -0.1184
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2510
Episode_Reward/pen_flat_orientation: -0.1000
  Episode_Reward/pen_feet_distance: -0.0217
Episode_Reward/pen_feet_regulation: -0.4802
   Episode_Reward/foot_landing_vel: -0.1328
   Episode_Reward/test_gait_reward: -0.9256
Metrics/base_velocity/error_vel_xy: 1.0298
Metrics/base_velocity/error_vel_yaw: 1.2982
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 1.12s
                        Total time: 1599.56s
                               ETA: 1670.4s

################################################################################
                     [1m Learning iteration 1468/3000 [0m                     

                       Computation: 87346 steps/s (collection: 0.999s, learning 0.127s)
               Value function loss: 0.5224
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8768
                     Learning rate: 0.0006
                       Mean reward: 130.97
               Mean episode length: 982.13
       Episode_Reward/keep_balance: 0.9865
     Episode_Reward/rew_lin_vel_xy: 6.2159
      Episode_Reward/rew_ang_vel_z: 2.4847
    Episode_Reward/pen_base_height: -0.3424
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1664
   Episode_Reward/pen_joint_torque: -0.2422
    Episode_Reward/pen_joint_accel: -0.1017
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2543
Episode_Reward/pen_flat_orientation: -0.1027
  Episode_Reward/pen_feet_distance: -0.0231
Episode_Reward/pen_feet_regulation: -0.4873
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.9323
Metrics/base_velocity/error_vel_xy: 0.9790
Metrics/base_velocity/error_vel_yaw: 1.3199
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 1.13s
                        Total time: 1600.68s
                               ETA: 1669.3s

################################################################################
                     [1m Learning iteration 1469/3000 [0m                     

                       Computation: 89244 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.6553
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8768
                     Learning rate: 0.0004
                       Mean reward: 128.59
               Mean episode length: 973.20
       Episode_Reward/keep_balance: 0.9782
     Episode_Reward/rew_lin_vel_xy: 6.0827
      Episode_Reward/rew_ang_vel_z: 2.4544
    Episode_Reward/pen_base_height: -0.3231
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.1598
   Episode_Reward/pen_joint_torque: -0.2360
    Episode_Reward/pen_joint_accel: -0.1098
    Episode_Reward/pen_action_rate: -0.1182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2515
Episode_Reward/pen_flat_orientation: -0.0998
  Episode_Reward/pen_feet_distance: -0.0204
Episode_Reward/pen_feet_regulation: -0.4816
   Episode_Reward/foot_landing_vel: -0.1411
   Episode_Reward/test_gait_reward: -0.9298
Metrics/base_velocity/error_vel_xy: 0.9914
Metrics/base_velocity/error_vel_yaw: 1.3220
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 1.10s
                        Total time: 1601.78s
                               ETA: 1668.3s

################################################################################
                     [1m Learning iteration 1470/3000 [0m                     

                       Computation: 81608 steps/s (collection: 1.069s, learning 0.135s)
               Value function loss: 0.6565
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8762
                     Learning rate: 0.0003
                       Mean reward: 130.08
               Mean episode length: 985.40
       Episode_Reward/keep_balance: 0.9872
     Episode_Reward/rew_lin_vel_xy: 6.1675
      Episode_Reward/rew_ang_vel_z: 2.5071
    Episode_Reward/pen_base_height: -0.3260
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1637
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.1059
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2535
Episode_Reward/pen_flat_orientation: -0.0980
  Episode_Reward/pen_feet_distance: -0.0219
Episode_Reward/pen_feet_regulation: -0.4779
   Episode_Reward/foot_landing_vel: -0.1343
   Episode_Reward/test_gait_reward: -0.9325
Metrics/base_velocity/error_vel_xy: 0.9874
Metrics/base_velocity/error_vel_yaw: 1.3074
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 1.20s
                        Total time: 1602.99s
                               ETA: 1667.3s

################################################################################
                     [1m Learning iteration 1471/3000 [0m                     

                       Computation: 91409 steps/s (collection: 0.952s, learning 0.124s)
               Value function loss: 0.5413
                    Surrogate loss: -0.0007
             Mean action noise std: 0.8763
                     Learning rate: 0.0002
                       Mean reward: 122.23
               Mean episode length: 942.56
       Episode_Reward/keep_balance: 0.9404
     Episode_Reward/rew_lin_vel_xy: 5.8244
      Episode_Reward/rew_ang_vel_z: 2.3461
    Episode_Reward/pen_base_height: -0.3239
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1548
   Episode_Reward/pen_joint_torque: -0.2341
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.1142
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2441
Episode_Reward/pen_flat_orientation: -0.0984
  Episode_Reward/pen_feet_distance: -0.0202
Episode_Reward/pen_feet_regulation: -0.4614
   Episode_Reward/foot_landing_vel: -0.1334
   Episode_Reward/test_gait_reward: -0.8961
Metrics/base_velocity/error_vel_xy: 0.9750
Metrics/base_velocity/error_vel_yaw: 1.2890
      Episode_Termination/time_out: 3.1667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 1.08s
                        Total time: 1604.06s
                               ETA: 1666.2s

################################################################################
                     [1m Learning iteration 1472/3000 [0m                     

                       Computation: 89816 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 0.6377
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8767
                     Learning rate: 0.0004
                       Mean reward: 131.65
               Mean episode length: 994.84
       Episode_Reward/keep_balance: 0.9810
     Episode_Reward/rew_lin_vel_xy: 6.1089
      Episode_Reward/rew_ang_vel_z: 2.4570
    Episode_Reward/pen_base_height: -0.3351
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.1620
   Episode_Reward/pen_joint_torque: -0.2430
    Episode_Reward/pen_joint_accel: -0.1037
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2545
Episode_Reward/pen_flat_orientation: -0.0996
  Episode_Reward/pen_feet_distance: -0.0215
Episode_Reward/pen_feet_regulation: -0.4826
   Episode_Reward/foot_landing_vel: -0.1351
   Episode_Reward/test_gait_reward: -0.9338
Metrics/base_velocity/error_vel_xy: 0.9956
Metrics/base_velocity/error_vel_yaw: 1.3340
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 1.09s
                        Total time: 1605.16s
                               ETA: 1665.1s

################################################################################
                     [1m Learning iteration 1473/3000 [0m                     

                       Computation: 91436 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.5208
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8752
                     Learning rate: 0.0006
                       Mean reward: 130.32
               Mean episode length: 987.44
       Episode_Reward/keep_balance: 0.9855
     Episode_Reward/rew_lin_vel_xy: 6.1311
      Episode_Reward/rew_ang_vel_z: 2.4458
    Episode_Reward/pen_base_height: -0.3072
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1654
   Episode_Reward/pen_joint_torque: -0.2271
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2577
Episode_Reward/pen_flat_orientation: -0.0975
  Episode_Reward/pen_feet_distance: -0.0236
Episode_Reward/pen_feet_regulation: -0.4957
   Episode_Reward/foot_landing_vel: -0.1433
   Episode_Reward/test_gait_reward: -0.9415
Metrics/base_velocity/error_vel_xy: 1.0005
Metrics/base_velocity/error_vel_yaw: 1.3574
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 1.08s
                        Total time: 1606.23s
                               ETA: 1664.0s

################################################################################
                     [1m Learning iteration 1474/3000 [0m                     

                       Computation: 90767 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.5846
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8752
                     Learning rate: 0.0006
                       Mean reward: 131.81
               Mean episode length: 987.16
       Episode_Reward/keep_balance: 0.9869
     Episode_Reward/rew_lin_vel_xy: 6.2317
      Episode_Reward/rew_ang_vel_z: 2.4606
    Episode_Reward/pen_base_height: -0.3136
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1687
   Episode_Reward/pen_joint_torque: -0.2272
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2583
Episode_Reward/pen_flat_orientation: -0.0948
  Episode_Reward/pen_feet_distance: -0.0198
Episode_Reward/pen_feet_regulation: -0.4895
   Episode_Reward/foot_landing_vel: -0.1380
   Episode_Reward/test_gait_reward: -0.9436
Metrics/base_velocity/error_vel_xy: 0.9607
Metrics/base_velocity/error_vel_yaw: 1.3417
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 1.08s
                        Total time: 1607.32s
                               ETA: 1662.9s

################################################################################
                     [1m Learning iteration 1475/3000 [0m                     

                       Computation: 91804 steps/s (collection: 0.949s, learning 0.121s)
               Value function loss: 0.5745
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8751
                     Learning rate: 0.0006
                       Mean reward: 132.45
               Mean episode length: 992.18
       Episode_Reward/keep_balance: 0.9954
     Episode_Reward/rew_lin_vel_xy: 6.2179
      Episode_Reward/rew_ang_vel_z: 2.4919
    Episode_Reward/pen_base_height: -0.3184
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1673
   Episode_Reward/pen_joint_torque: -0.2293
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2586
Episode_Reward/pen_flat_orientation: -0.0954
  Episode_Reward/pen_feet_distance: -0.0185
Episode_Reward/pen_feet_regulation: -0.4908
   Episode_Reward/foot_landing_vel: -0.1381
   Episode_Reward/test_gait_reward: -0.9473
Metrics/base_velocity/error_vel_xy: 0.9927
Metrics/base_velocity/error_vel_yaw: 1.3540
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 1.07s
                        Total time: 1608.39s
                               ETA: 1661.8s

################################################################################
                     [1m Learning iteration 1476/3000 [0m                     

                       Computation: 91149 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.6503
                    Surrogate loss: -0.0059
             Mean action noise std: 0.8747
                     Learning rate: 0.0009
                       Mean reward: 131.02
               Mean episode length: 989.20
       Episode_Reward/keep_balance: 0.9899
     Episode_Reward/rew_lin_vel_xy: 6.1590
      Episode_Reward/rew_ang_vel_z: 2.4911
    Episode_Reward/pen_base_height: -0.3318
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.1680
   Episode_Reward/pen_joint_torque: -0.2399
    Episode_Reward/pen_joint_accel: -0.1113
    Episode_Reward/pen_action_rate: -0.1207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2582
Episode_Reward/pen_flat_orientation: -0.1028
  Episode_Reward/pen_feet_distance: -0.0236
Episode_Reward/pen_feet_regulation: -0.5010
   Episode_Reward/foot_landing_vel: -0.1470
   Episode_Reward/test_gait_reward: -0.9455
Metrics/base_velocity/error_vel_xy: 1.0148
Metrics/base_velocity/error_vel_yaw: 1.3387
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 1.08s
                        Total time: 1609.47s
                               ETA: 1660.7s

################################################################################
                     [1m Learning iteration 1477/3000 [0m                     

                       Computation: 91092 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.6646
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8747
                     Learning rate: 0.0013
                       Mean reward: 128.87
               Mean episode length: 972.17
       Episode_Reward/keep_balance: 0.9770
     Episode_Reward/rew_lin_vel_xy: 6.0981
      Episode_Reward/rew_ang_vel_z: 2.4535
    Episode_Reward/pen_base_height: -0.3373
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1624
   Episode_Reward/pen_joint_torque: -0.2412
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2522
Episode_Reward/pen_flat_orientation: -0.1011
  Episode_Reward/pen_feet_distance: -0.0218
Episode_Reward/pen_feet_regulation: -0.4815
   Episode_Reward/foot_landing_vel: -0.1402
   Episode_Reward/test_gait_reward: -0.9354
Metrics/base_velocity/error_vel_xy: 0.9821
Metrics/base_velocity/error_vel_yaw: 1.3291
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 1.08s
                        Total time: 1610.55s
                               ETA: 1659.6s

################################################################################
                     [1m Learning iteration 1478/3000 [0m                     

                       Computation: 91782 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.6353
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8748
                     Learning rate: 0.0009
                       Mean reward: 131.07
               Mean episode length: 980.15
       Episode_Reward/keep_balance: 0.9742
     Episode_Reward/rew_lin_vel_xy: 6.1250
      Episode_Reward/rew_ang_vel_z: 2.4369
    Episode_Reward/pen_base_height: -0.3194
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1669
   Episode_Reward/pen_joint_torque: -0.2246
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1163
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2539
Episode_Reward/pen_flat_orientation: -0.0967
  Episode_Reward/pen_feet_distance: -0.0207
Episode_Reward/pen_feet_regulation: -0.4764
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9248
Metrics/base_velocity/error_vel_xy: 0.9605
Metrics/base_velocity/error_vel_yaw: 1.3218
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 1.07s
                        Total time: 1611.62s
                               ETA: 1658.5s

################################################################################
                     [1m Learning iteration 1479/3000 [0m                     

                       Computation: 84709 steps/s (collection: 1.037s, learning 0.123s)
               Value function loss: 0.6503
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8766
                     Learning rate: 0.0004
                       Mean reward: 130.51
               Mean episode length: 978.57
       Episode_Reward/keep_balance: 0.9772
     Episode_Reward/rew_lin_vel_xy: 6.1367
      Episode_Reward/rew_ang_vel_z: 2.4630
    Episode_Reward/pen_base_height: -0.3275
      Episode_Reward/pen_lin_vel_z: -0.0389
     Episode_Reward/pen_ang_vel_xy: -0.1640
   Episode_Reward/pen_joint_torque: -0.2365
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.1189
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2536
Episode_Reward/pen_flat_orientation: -0.0991
  Episode_Reward/pen_feet_distance: -0.0218
Episode_Reward/pen_feet_regulation: -0.4821
   Episode_Reward/foot_landing_vel: -0.1414
   Episode_Reward/test_gait_reward: -0.9371
Metrics/base_velocity/error_vel_xy: 0.9611
Metrics/base_velocity/error_vel_yaw: 1.3058
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 1.16s
                        Total time: 1612.78s
                               ETA: 1657.5s

################################################################################
                     [1m Learning iteration 1480/3000 [0m                     

                       Computation: 91186 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.6060
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8769
                     Learning rate: 0.0004
                       Mean reward: 131.40
               Mean episode length: 971.40
       Episode_Reward/keep_balance: 0.9716
     Episode_Reward/rew_lin_vel_xy: 6.1058
      Episode_Reward/rew_ang_vel_z: 2.4552
    Episode_Reward/pen_base_height: -0.3277
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1588
   Episode_Reward/pen_joint_torque: -0.2292
    Episode_Reward/pen_joint_accel: -0.1008
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2502
Episode_Reward/pen_flat_orientation: -0.0985
  Episode_Reward/pen_feet_distance: -0.0207
Episode_Reward/pen_feet_regulation: -0.4668
   Episode_Reward/foot_landing_vel: -0.1300
   Episode_Reward/test_gait_reward: -0.9255
Metrics/base_velocity/error_vel_xy: 0.9473
Metrics/base_velocity/error_vel_yaw: 1.2981
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 1.08s
                        Total time: 1613.85s
                               ETA: 1656.4s

################################################################################
                     [1m Learning iteration 1481/3000 [0m                     

                       Computation: 91177 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.5945
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8767
                     Learning rate: 0.0004
                       Mean reward: 131.16
               Mean episode length: 989.35
       Episode_Reward/keep_balance: 0.9892
     Episode_Reward/rew_lin_vel_xy: 6.2498
      Episode_Reward/rew_ang_vel_z: 2.4707
    Episode_Reward/pen_base_height: -0.3313
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1695
   Episode_Reward/pen_joint_torque: -0.2273
    Episode_Reward/pen_joint_accel: -0.1049
    Episode_Reward/pen_action_rate: -0.1189
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2586
Episode_Reward/pen_flat_orientation: -0.0967
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4750
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.9413
Metrics/base_velocity/error_vel_xy: 0.9531
Metrics/base_velocity/error_vel_yaw: 1.3535
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 1.08s
                        Total time: 1614.93s
                               ETA: 1655.3s

################################################################################
                     [1m Learning iteration 1482/3000 [0m                     

                       Computation: 90575 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.5316
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8770
                     Learning rate: 0.0006
                       Mean reward: 129.82
               Mean episode length: 979.97
       Episode_Reward/keep_balance: 0.9895
     Episode_Reward/rew_lin_vel_xy: 6.1842
      Episode_Reward/rew_ang_vel_z: 2.4642
    Episode_Reward/pen_base_height: -0.3522
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1584
   Episode_Reward/pen_joint_torque: -0.2487
    Episode_Reward/pen_joint_accel: -0.1078
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0912
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2550
Episode_Reward/pen_flat_orientation: -0.0961
  Episode_Reward/pen_feet_distance: -0.0257
Episode_Reward/pen_feet_regulation: -0.4949
   Episode_Reward/foot_landing_vel: -0.1395
   Episode_Reward/test_gait_reward: -0.9465
Metrics/base_velocity/error_vel_xy: 0.9905
Metrics/base_velocity/error_vel_yaw: 1.3504
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 1.09s
                        Total time: 1616.02s
                               ETA: 1654.2s

################################################################################
                     [1m Learning iteration 1483/3000 [0m                     

                       Computation: 90963 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.5470
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8774
                     Learning rate: 0.0001
                       Mean reward: 135.92
               Mean episode length: 991.66
       Episode_Reward/keep_balance: 0.9911
     Episode_Reward/rew_lin_vel_xy: 6.2863
      Episode_Reward/rew_ang_vel_z: 2.5189
    Episode_Reward/pen_base_height: -0.3430
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1625
   Episode_Reward/pen_joint_torque: -0.2383
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.1178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2538
Episode_Reward/pen_flat_orientation: -0.0934
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4662
   Episode_Reward/foot_landing_vel: -0.1291
   Episode_Reward/test_gait_reward: -0.9445
Metrics/base_velocity/error_vel_xy: 0.9325
Metrics/base_velocity/error_vel_yaw: 1.2986
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 1.08s
                        Total time: 1617.10s
                               ETA: 1653.1s

################################################################################
                     [1m Learning iteration 1484/3000 [0m                     

                       Computation: 91075 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.5629
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8766
                     Learning rate: 0.0002
                       Mean reward: 131.71
               Mean episode length: 982.91
       Episode_Reward/keep_balance: 0.9880
     Episode_Reward/rew_lin_vel_xy: 6.2796
      Episode_Reward/rew_ang_vel_z: 2.4558
    Episode_Reward/pen_base_height: -0.3170
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1626
   Episode_Reward/pen_joint_torque: -0.2299
    Episode_Reward/pen_joint_accel: -0.1191
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2600
Episode_Reward/pen_flat_orientation: -0.0954
  Episode_Reward/pen_feet_distance: -0.0232
Episode_Reward/pen_feet_regulation: -0.4828
   Episode_Reward/foot_landing_vel: -0.1371
   Episode_Reward/test_gait_reward: -0.9451
Metrics/base_velocity/error_vel_xy: 0.9389
Metrics/base_velocity/error_vel_yaw: 1.3587
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 1.08s
                        Total time: 1618.18s
                               ETA: 1652.0s

################################################################################
                     [1m Learning iteration 1485/3000 [0m                     

                       Computation: 91152 steps/s (collection: 0.957s, learning 0.121s)
               Value function loss: 0.6749
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8765
                     Learning rate: 0.0004
                       Mean reward: 130.08
               Mean episode length: 971.42
       Episode_Reward/keep_balance: 0.9675
     Episode_Reward/rew_lin_vel_xy: 6.0970
      Episode_Reward/rew_ang_vel_z: 2.4806
    Episode_Reward/pen_base_height: -0.3238
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1600
   Episode_Reward/pen_joint_torque: -0.2248
    Episode_Reward/pen_joint_accel: -0.1079
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0856
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2482
Episode_Reward/pen_flat_orientation: -0.0959
  Episode_Reward/pen_feet_distance: -0.0215
Episode_Reward/pen_feet_regulation: -0.4635
   Episode_Reward/foot_landing_vel: -0.1343
   Episode_Reward/test_gait_reward: -0.9238
Metrics/base_velocity/error_vel_xy: 0.9485
Metrics/base_velocity/error_vel_yaw: 1.2667
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 1.08s
                        Total time: 1619.26s
                               ETA: 1650.9s

################################################################################
                     [1m Learning iteration 1486/3000 [0m                     

                       Computation: 91609 steps/s (collection: 0.952s, learning 0.121s)
               Value function loss: 0.6387
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8755
                     Learning rate: 0.0003
                       Mean reward: 133.93
               Mean episode length: 990.60
       Episode_Reward/keep_balance: 0.9898
     Episode_Reward/rew_lin_vel_xy: 6.2652
      Episode_Reward/rew_ang_vel_z: 2.5098
    Episode_Reward/pen_base_height: -0.3353
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1583
   Episode_Reward/pen_joint_torque: -0.2293
    Episode_Reward/pen_joint_accel: -0.1049
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2541
Episode_Reward/pen_flat_orientation: -0.0915
  Episode_Reward/pen_feet_distance: -0.0207
Episode_Reward/pen_feet_regulation: -0.4711
   Episode_Reward/foot_landing_vel: -0.1259
   Episode_Reward/test_gait_reward: -0.9467
Metrics/base_velocity/error_vel_xy: 0.9458
Metrics/base_velocity/error_vel_yaw: 1.3212
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 1.07s
                        Total time: 1620.33s
                               ETA: 1649.8s

################################################################################
                     [1m Learning iteration 1487/3000 [0m                     

                       Computation: 90066 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.6840
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8760
                     Learning rate: 0.0006
                       Mean reward: 134.55
               Mean episode length: 986.24
       Episode_Reward/keep_balance: 0.9797
     Episode_Reward/rew_lin_vel_xy: 6.1824
      Episode_Reward/rew_ang_vel_z: 2.4760
    Episode_Reward/pen_base_height: -0.3393
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1671
   Episode_Reward/pen_joint_torque: -0.2353
    Episode_Reward/pen_joint_accel: -0.1123
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2576
Episode_Reward/pen_flat_orientation: -0.0969
  Episode_Reward/pen_feet_distance: -0.0219
Episode_Reward/pen_feet_regulation: -0.4733
   Episode_Reward/foot_landing_vel: -0.1316
   Episode_Reward/test_gait_reward: -0.9356
Metrics/base_velocity/error_vel_xy: 0.9466
Metrics/base_velocity/error_vel_yaw: 1.3091
      Episode_Termination/time_out: 4.8333
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 1.09s
                        Total time: 1621.42s
                               ETA: 1648.7s

################################################################################
                     [1m Learning iteration 1488/3000 [0m                     

                       Computation: 89622 steps/s (collection: 0.975s, learning 0.122s)
               Value function loss: 0.5630
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8785
                     Learning rate: 0.0009
                       Mean reward: 131.42
               Mean episode length: 978.12
       Episode_Reward/keep_balance: 0.9824
     Episode_Reward/rew_lin_vel_xy: 6.1784
      Episode_Reward/rew_ang_vel_z: 2.4925
    Episode_Reward/pen_base_height: -0.3259
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1643
   Episode_Reward/pen_joint_torque: -0.2352
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0891
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2546
Episode_Reward/pen_flat_orientation: -0.0900
  Episode_Reward/pen_feet_distance: -0.0180
Episode_Reward/pen_feet_regulation: -0.4647
   Episode_Reward/foot_landing_vel: -0.1387
   Episode_Reward/test_gait_reward: -0.9265
Metrics/base_velocity/error_vel_xy: 0.9584
Metrics/base_velocity/error_vel_yaw: 1.2938
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 1.10s
                        Total time: 1622.52s
                               ETA: 1647.6s

################################################################################
                     [1m Learning iteration 1489/3000 [0m                     

                       Computation: 89405 steps/s (collection: 0.974s, learning 0.126s)
               Value function loss: 0.5589
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8790
                     Learning rate: 0.0006
                       Mean reward: 127.76
               Mean episode length: 955.68
       Episode_Reward/keep_balance: 0.9638
     Episode_Reward/rew_lin_vel_xy: 6.0962
      Episode_Reward/rew_ang_vel_z: 2.4420
    Episode_Reward/pen_base_height: -0.3251
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1545
   Episode_Reward/pen_joint_torque: -0.2322
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.1156
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2465
Episode_Reward/pen_flat_orientation: -0.0925
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4697
   Episode_Reward/foot_landing_vel: -0.1373
   Episode_Reward/test_gait_reward: -0.9190
Metrics/base_velocity/error_vel_xy: 0.9272
Metrics/base_velocity/error_vel_yaw: 1.2761
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 1.10s
                        Total time: 1623.62s
                               ETA: 1646.5s

################################################################################
                     [1m Learning iteration 1490/3000 [0m                     

                       Computation: 89342 steps/s (collection: 0.978s, learning 0.122s)
               Value function loss: 0.6092
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8791
                     Learning rate: 0.0009
                       Mean reward: 132.54
               Mean episode length: 989.73
       Episode_Reward/keep_balance: 0.9940
     Episode_Reward/rew_lin_vel_xy: 6.2576
      Episode_Reward/rew_ang_vel_z: 2.5296
    Episode_Reward/pen_base_height: -0.3587
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1587
   Episode_Reward/pen_joint_torque: -0.2471
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2549
Episode_Reward/pen_flat_orientation: -0.0944
  Episode_Reward/pen_feet_distance: -0.0262
Episode_Reward/pen_feet_regulation: -0.4863
   Episode_Reward/foot_landing_vel: -0.1386
   Episode_Reward/test_gait_reward: -0.9466
Metrics/base_velocity/error_vel_xy: 0.9693
Metrics/base_velocity/error_vel_yaw: 1.3109
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 1.10s
                        Total time: 1624.72s
                               ETA: 1645.4s

################################################################################
                     [1m Learning iteration 1491/3000 [0m                     

                       Computation: 90539 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.5341
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8782
                     Learning rate: 0.0004
                       Mean reward: 129.18
               Mean episode length: 966.76
       Episode_Reward/keep_balance: 0.9597
     Episode_Reward/rew_lin_vel_xy: 5.9877
      Episode_Reward/rew_ang_vel_z: 2.4427
    Episode_Reward/pen_base_height: -0.3266
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1537
   Episode_Reward/pen_joint_torque: -0.2333
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1160
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2471
Episode_Reward/pen_flat_orientation: -0.0943
  Episode_Reward/pen_feet_distance: -0.0208
Episode_Reward/pen_feet_regulation: -0.4480
   Episode_Reward/foot_landing_vel: -0.1421
   Episode_Reward/test_gait_reward: -0.9052
Metrics/base_velocity/error_vel_xy: 0.9602
Metrics/base_velocity/error_vel_yaw: 1.2571
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 1.09s
                        Total time: 1625.80s
                               ETA: 1644.3s

################################################################################
                     [1m Learning iteration 1492/3000 [0m                     

                       Computation: 89982 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 0.5592
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8797
                     Learning rate: 0.0004
                       Mean reward: 130.76
               Mean episode length: 983.67
       Episode_Reward/keep_balance: 0.9789
     Episode_Reward/rew_lin_vel_xy: 6.1063
      Episode_Reward/rew_ang_vel_z: 2.4510
    Episode_Reward/pen_base_height: -0.3237
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1638
   Episode_Reward/pen_joint_torque: -0.2389
    Episode_Reward/pen_joint_accel: -0.1093
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2551
Episode_Reward/pen_flat_orientation: -0.0947
  Episode_Reward/pen_feet_distance: -0.0172
Episode_Reward/pen_feet_regulation: -0.5004
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.9369
Metrics/base_velocity/error_vel_xy: 0.9903
Metrics/base_velocity/error_vel_yaw: 1.3146
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 1.09s
                        Total time: 1626.90s
                               ETA: 1643.2s

################################################################################
                     [1m Learning iteration 1493/3000 [0m                     

                       Computation: 90662 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.5611
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8805
                     Learning rate: 0.0006
                       Mean reward: 132.49
               Mean episode length: 974.64
       Episode_Reward/keep_balance: 0.9768
     Episode_Reward/rew_lin_vel_xy: 6.1358
      Episode_Reward/rew_ang_vel_z: 2.4788
    Episode_Reward/pen_base_height: -0.3161
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.1587
   Episode_Reward/pen_joint_torque: -0.2214
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.1164
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0852
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2521
Episode_Reward/pen_flat_orientation: -0.0939
  Episode_Reward/pen_feet_distance: -0.0249
Episode_Reward/pen_feet_regulation: -0.4656
   Episode_Reward/foot_landing_vel: -0.1269
   Episode_Reward/test_gait_reward: -0.9328
Metrics/base_velocity/error_vel_xy: 0.9549
Metrics/base_velocity/error_vel_yaw: 1.2930
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 1.08s
                        Total time: 1627.98s
                               ETA: 1642.1s

################################################################################
                     [1m Learning iteration 1494/3000 [0m                     

                       Computation: 90125 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.5545
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8805
                     Learning rate: 0.0004
                       Mean reward: 133.21
               Mean episode length: 990.75
       Episode_Reward/keep_balance: 0.9965
     Episode_Reward/rew_lin_vel_xy: 6.2351
      Episode_Reward/rew_ang_vel_z: 2.4828
    Episode_Reward/pen_base_height: -0.3511
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1673
   Episode_Reward/pen_joint_torque: -0.2337
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1223
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2619
Episode_Reward/pen_flat_orientation: -0.0932
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4906
   Episode_Reward/foot_landing_vel: -0.1336
   Episode_Reward/test_gait_reward: -0.9560
Metrics/base_velocity/error_vel_xy: 0.9889
Metrics/base_velocity/error_vel_yaw: 1.3713
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 1.09s
                        Total time: 1629.07s
                               ETA: 1641.1s

################################################################################
                     [1m Learning iteration 1495/3000 [0m                     

                       Computation: 90565 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.5397
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8792
                     Learning rate: 0.0004
                       Mean reward: 129.72
               Mean episode length: 966.13
       Episode_Reward/keep_balance: 0.9529
     Episode_Reward/rew_lin_vel_xy: 6.0480
      Episode_Reward/rew_ang_vel_z: 2.4112
    Episode_Reward/pen_base_height: -0.3163
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1536
   Episode_Reward/pen_joint_torque: -0.2328
    Episode_Reward/pen_joint_accel: -0.1052
    Episode_Reward/pen_action_rate: -0.1157
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2483
Episode_Reward/pen_flat_orientation: -0.0880
  Episode_Reward/pen_feet_distance: -0.0202
Episode_Reward/pen_feet_regulation: -0.4672
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.9072
Metrics/base_velocity/error_vel_xy: 0.9131
Metrics/base_velocity/error_vel_yaw: 1.2648
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 1.09s
                        Total time: 1630.16s
                               ETA: 1640.0s

################################################################################
                     [1m Learning iteration 1496/3000 [0m                     

                       Computation: 92058 steps/s (collection: 0.946s, learning 0.122s)
               Value function loss: 0.6344
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8790
                     Learning rate: 0.0006
                       Mean reward: 130.88
               Mean episode length: 982.58
       Episode_Reward/keep_balance: 0.9824
     Episode_Reward/rew_lin_vel_xy: 6.1279
      Episode_Reward/rew_ang_vel_z: 2.4963
    Episode_Reward/pen_base_height: -0.3452
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1608
   Episode_Reward/pen_joint_torque: -0.2344
    Episode_Reward/pen_joint_accel: -0.1061
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2554
Episode_Reward/pen_flat_orientation: -0.0910
  Episode_Reward/pen_feet_distance: -0.0233
Episode_Reward/pen_feet_regulation: -0.4640
   Episode_Reward/foot_landing_vel: -0.1335
   Episode_Reward/test_gait_reward: -0.9342
Metrics/base_velocity/error_vel_xy: 0.9810
Metrics/base_velocity/error_vel_yaw: 1.2886
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 1.07s
                        Total time: 1631.22s
                               ETA: 1638.9s

################################################################################
                     [1m Learning iteration 1497/3000 [0m                     

                       Computation: 90302 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.6145
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8795
                     Learning rate: 0.0006
                       Mean reward: 130.14
               Mean episode length: 974.90
       Episode_Reward/keep_balance: 0.9745
     Episode_Reward/rew_lin_vel_xy: 6.1409
      Episode_Reward/rew_ang_vel_z: 2.4625
    Episode_Reward/pen_base_height: -0.3208
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1651
   Episode_Reward/pen_joint_torque: -0.2229
    Episode_Reward/pen_joint_accel: -0.1058
    Episode_Reward/pen_action_rate: -0.1177
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2537
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0222
Episode_Reward/pen_feet_regulation: -0.4679
   Episode_Reward/foot_landing_vel: -0.1380
   Episode_Reward/test_gait_reward: -0.9320
Metrics/base_velocity/error_vel_xy: 0.9467
Metrics/base_velocity/error_vel_yaw: 1.2992
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 1.09s
                        Total time: 1632.31s
                               ETA: 1637.8s

################################################################################
                     [1m Learning iteration 1498/3000 [0m                     

                       Computation: 89995 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 0.5710
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8788
                     Learning rate: 0.0004
                       Mean reward: 135.00
               Mean episode length: 994.25
       Episode_Reward/keep_balance: 0.9954
     Episode_Reward/rew_lin_vel_xy: 6.2943
      Episode_Reward/rew_ang_vel_z: 2.5470
    Episode_Reward/pen_base_height: -0.3088
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1616
   Episode_Reward/pen_joint_torque: -0.2338
    Episode_Reward/pen_joint_accel: -0.1106
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2585
Episode_Reward/pen_flat_orientation: -0.0911
  Episode_Reward/pen_feet_distance: -0.0209
Episode_Reward/pen_feet_regulation: -0.4618
   Episode_Reward/foot_landing_vel: -0.1532
   Episode_Reward/test_gait_reward: -0.9380
Metrics/base_velocity/error_vel_xy: 0.9518
Metrics/base_velocity/error_vel_yaw: 1.2899
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 1.09s
                        Total time: 1633.41s
                               ETA: 1636.7s

################################################################################
                     [1m Learning iteration 1499/3000 [0m                     

                       Computation: 90400 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.5943
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8778
                     Learning rate: 0.0006
                       Mean reward: 126.45
               Mean episode length: 969.42
       Episode_Reward/keep_balance: 0.9708
     Episode_Reward/rew_lin_vel_xy: 6.0082
      Episode_Reward/rew_ang_vel_z: 2.4484
    Episode_Reward/pen_base_height: -0.3427
      Episode_Reward/pen_lin_vel_z: -0.0389
     Episode_Reward/pen_ang_vel_xy: -0.1572
   Episode_Reward/pen_joint_torque: -0.2364
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1189
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2547
Episode_Reward/pen_flat_orientation: -0.0954
  Episode_Reward/pen_feet_distance: -0.0187
Episode_Reward/pen_feet_regulation: -0.4820
   Episode_Reward/foot_landing_vel: -0.1313
   Episode_Reward/test_gait_reward: -0.9271
Metrics/base_velocity/error_vel_xy: 1.0081
Metrics/base_velocity/error_vel_yaw: 1.2937
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 1.09s
                        Total time: 1634.49s
                               ETA: 1635.6s

################################################################################
                     [1m Learning iteration 1500/3000 [0m                     

                       Computation: 91970 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 0.5719
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8765
                     Learning rate: 0.0006
                       Mean reward: 131.97
               Mean episode length: 994.68
       Episode_Reward/keep_balance: 0.9965
     Episode_Reward/rew_lin_vel_xy: 6.2282
      Episode_Reward/rew_ang_vel_z: 2.5487
    Episode_Reward/pen_base_height: -0.3524
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1643
   Episode_Reward/pen_joint_torque: -0.2404
    Episode_Reward/pen_joint_accel: -0.1089
    Episode_Reward/pen_action_rate: -0.1209
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2592
Episode_Reward/pen_flat_orientation: -0.0925
  Episode_Reward/pen_feet_distance: -0.0245
Episode_Reward/pen_feet_regulation: -0.5006
   Episode_Reward/foot_landing_vel: -0.1300
   Episode_Reward/test_gait_reward: -0.9533
Metrics/base_velocity/error_vel_xy: 0.9977
Metrics/base_velocity/error_vel_yaw: 1.2938
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 147554304
                    Iteration time: 1.07s
                        Total time: 1635.56s
                               ETA: 1634.5s

################################################################################
                     [1m Learning iteration 1501/3000 [0m                     

                       Computation: 93239 steps/s (collection: 0.933s, learning 0.122s)
               Value function loss: 0.5650
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8764
                     Learning rate: 0.0004
                       Mean reward: 132.56
               Mean episode length: 972.98
       Episode_Reward/keep_balance: 0.9476
     Episode_Reward/rew_lin_vel_xy: 5.9961
      Episode_Reward/rew_ang_vel_z: 2.3815
    Episode_Reward/pen_base_height: -0.2971
      Episode_Reward/pen_lin_vel_z: -0.0343
     Episode_Reward/pen_ang_vel_xy: -0.1551
   Episode_Reward/pen_joint_torque: -0.2118
    Episode_Reward/pen_joint_accel: -0.0997
    Episode_Reward/pen_action_rate: -0.1143
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0537
   Episode_Reward/pen_joint_powers: -0.0828
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2483
Episode_Reward/pen_flat_orientation: -0.0913
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4426
   Episode_Reward/foot_landing_vel: -0.1332
   Episode_Reward/test_gait_reward: -0.8996
Metrics/base_velocity/error_vel_xy: 0.8998
Metrics/base_velocity/error_vel_yaw: 1.2964
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 147652608
                    Iteration time: 1.05s
                        Total time: 1636.62s
                               ETA: 1633.3s

################################################################################
                     [1m Learning iteration 1502/3000 [0m                     

                       Computation: 90883 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.5801
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8760
                     Learning rate: 0.0004
                       Mean reward: 131.80
               Mean episode length: 990.31
       Episode_Reward/keep_balance: 0.9906
     Episode_Reward/rew_lin_vel_xy: 6.1864
      Episode_Reward/rew_ang_vel_z: 2.4819
    Episode_Reward/pen_base_height: -0.3288
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.1647
   Episode_Reward/pen_joint_torque: -0.2355
    Episode_Reward/pen_joint_accel: -0.1193
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2607
Episode_Reward/pen_flat_orientation: -0.0936
  Episode_Reward/pen_feet_distance: -0.0263
Episode_Reward/pen_feet_regulation: -0.4902
   Episode_Reward/foot_landing_vel: -0.1424
   Episode_Reward/test_gait_reward: -0.9467
Metrics/base_velocity/error_vel_xy: 1.0080
Metrics/base_velocity/error_vel_yaw: 1.3281
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 147750912
                    Iteration time: 1.08s
                        Total time: 1637.70s
                               ETA: 1632.2s

################################################################################
                     [1m Learning iteration 1503/3000 [0m                     

                       Computation: 90316 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.6413
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8764
                     Learning rate: 0.0006
                       Mean reward: 133.34
               Mean episode length: 988.85
       Episode_Reward/keep_balance: 0.9906
     Episode_Reward/rew_lin_vel_xy: 6.2176
      Episode_Reward/rew_ang_vel_z: 2.5035
    Episode_Reward/pen_base_height: -0.3192
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1688
   Episode_Reward/pen_joint_torque: -0.2324
    Episode_Reward/pen_joint_accel: -0.1057
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2584
Episode_Reward/pen_flat_orientation: -0.0948
  Episode_Reward/pen_feet_distance: -0.0229
Episode_Reward/pen_feet_regulation: -0.4671
   Episode_Reward/foot_landing_vel: -0.1406
   Episode_Reward/test_gait_reward: -0.9326
Metrics/base_velocity/error_vel_xy: 0.9664
Metrics/base_velocity/error_vel_yaw: 1.3191
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 147849216
                    Iteration time: 1.09s
                        Total time: 1638.79s
                               ETA: 1631.2s

################################################################################
                     [1m Learning iteration 1504/3000 [0m                     

                       Computation: 91375 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.5461
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8770
                     Learning rate: 0.0004
                       Mean reward: 131.54
               Mean episode length: 964.07
       Episode_Reward/keep_balance: 0.9722
     Episode_Reward/rew_lin_vel_xy: 6.2166
      Episode_Reward/rew_ang_vel_z: 2.4386
    Episode_Reward/pen_base_height: -0.3159
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.1602
   Episode_Reward/pen_joint_torque: -0.2193
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0848
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2531
Episode_Reward/pen_flat_orientation: -0.0873
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4418
   Episode_Reward/foot_landing_vel: -0.1368
   Episode_Reward/test_gait_reward: -0.9194
Metrics/base_velocity/error_vel_xy: 0.9110
Metrics/base_velocity/error_vel_yaw: 1.3131
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147947520
                    Iteration time: 1.08s
                        Total time: 1639.86s
                               ETA: 1630.1s

################################################################################
                     [1m Learning iteration 1505/3000 [0m                     

                       Computation: 91376 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 0.5229
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8776
                     Learning rate: 0.0004
                       Mean reward: 136.16
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.3249
      Episode_Reward/rew_ang_vel_z: 2.5776
    Episode_Reward/pen_base_height: -0.3335
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1589
   Episode_Reward/pen_joint_torque: -0.2346
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.1184
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2556
Episode_Reward/pen_flat_orientation: -0.0861
  Episode_Reward/pen_feet_distance: -0.0212
Episode_Reward/pen_feet_regulation: -0.4625
   Episode_Reward/foot_landing_vel: -0.1306
   Episode_Reward/test_gait_reward: -0.9449
Metrics/base_velocity/error_vel_xy: 0.9636
Metrics/base_velocity/error_vel_yaw: 1.2840
      Episode_Termination/time_out: 5.0417
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 148045824
                    Iteration time: 1.08s
                        Total time: 1640.94s
                               ETA: 1629.0s

################################################################################
                     [1m Learning iteration 1506/3000 [0m                     

                       Computation: 90696 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.5380
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8788
                     Learning rate: 0.0006
                       Mean reward: 136.57
               Mean episode length: 988.84
       Episode_Reward/keep_balance: 0.9933
     Episode_Reward/rew_lin_vel_xy: 6.3094
      Episode_Reward/rew_ang_vel_z: 2.5301
    Episode_Reward/pen_base_height: -0.3247
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1613
   Episode_Reward/pen_joint_torque: -0.2345
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2571
Episode_Reward/pen_flat_orientation: -0.0883
  Episode_Reward/pen_feet_distance: -0.0171
Episode_Reward/pen_feet_regulation: -0.4583
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.9409
Metrics/base_velocity/error_vel_xy: 0.9348
Metrics/base_velocity/error_vel_yaw: 1.2916
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 148144128
                    Iteration time: 1.08s
                        Total time: 1642.02s
                               ETA: 1627.9s

################################################################################
                     [1m Learning iteration 1507/3000 [0m                     

                       Computation: 90385 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.5976
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8803
                     Learning rate: 0.0006
                       Mean reward: 130.26
               Mean episode length: 989.48
       Episode_Reward/keep_balance: 0.9945
     Episode_Reward/rew_lin_vel_xy: 6.1926
      Episode_Reward/rew_ang_vel_z: 2.4975
    Episode_Reward/pen_base_height: -0.3407
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1654
   Episode_Reward/pen_joint_torque: -0.2435
    Episode_Reward/pen_joint_accel: -0.1076
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0594
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2628
Episode_Reward/pen_flat_orientation: -0.0975
  Episode_Reward/pen_feet_distance: -0.0217
Episode_Reward/pen_feet_regulation: -0.4942
   Episode_Reward/foot_landing_vel: -0.1442
   Episode_Reward/test_gait_reward: -0.9476
Metrics/base_velocity/error_vel_xy: 1.0102
Metrics/base_velocity/error_vel_yaw: 1.3538
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 148242432
                    Iteration time: 1.09s
                        Total time: 1643.11s
                               ETA: 1626.8s

################################################################################
                     [1m Learning iteration 1508/3000 [0m                     

                       Computation: 91216 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.5591
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8797
                     Learning rate: 0.0009
                       Mean reward: 129.95
               Mean episode length: 977.69
       Episode_Reward/keep_balance: 0.9743
     Episode_Reward/rew_lin_vel_xy: 6.0812
      Episode_Reward/rew_ang_vel_z: 2.4331
    Episode_Reward/pen_base_height: -0.3202
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1655
   Episode_Reward/pen_joint_torque: -0.2340
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.1192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0896
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2561
Episode_Reward/pen_flat_orientation: -0.0950
  Episode_Reward/pen_feet_distance: -0.0212
Episode_Reward/pen_feet_regulation: -0.4833
   Episode_Reward/foot_landing_vel: -0.1483
   Episode_Reward/test_gait_reward: -0.9227
Metrics/base_velocity/error_vel_xy: 0.9809
Metrics/base_velocity/error_vel_yaw: 1.3278
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 148340736
                    Iteration time: 1.08s
                        Total time: 1644.19s
                               ETA: 1625.7s

################################################################################
                     [1m Learning iteration 1509/3000 [0m                     

                       Computation: 89810 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.5295
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8788
                     Learning rate: 0.0003
                       Mean reward: 132.17
               Mean episode length: 994.84
       Episode_Reward/keep_balance: 0.9936
     Episode_Reward/rew_lin_vel_xy: 6.0963
      Episode_Reward/rew_ang_vel_z: 2.5137
    Episode_Reward/pen_base_height: -0.3338
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1633
   Episode_Reward/pen_joint_torque: -0.2388
    Episode_Reward/pen_joint_accel: -0.1016
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2582
Episode_Reward/pen_flat_orientation: -0.0891
  Episode_Reward/pen_feet_distance: -0.0241
Episode_Reward/pen_feet_regulation: -0.4739
   Episode_Reward/foot_landing_vel: -0.1393
   Episode_Reward/test_gait_reward: -0.9373
Metrics/base_velocity/error_vel_xy: 1.0242
Metrics/base_velocity/error_vel_yaw: 1.3143
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 148439040
                    Iteration time: 1.09s
                        Total time: 1645.28s
                               ETA: 1624.6s

################################################################################
                     [1m Learning iteration 1510/3000 [0m                     

                       Computation: 91226 steps/s (collection: 0.955s, learning 0.123s)
               Value function loss: 0.5573
                    Surrogate loss: -0.0006
             Mean action noise std: 0.8782
                     Learning rate: 0.0002
                       Mean reward: 133.99
               Mean episode length: 986.14
       Episode_Reward/keep_balance: 0.9910
     Episode_Reward/rew_lin_vel_xy: 6.2051
      Episode_Reward/rew_ang_vel_z: 2.5289
    Episode_Reward/pen_base_height: -0.3274
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1608
   Episode_Reward/pen_joint_torque: -0.2385
    Episode_Reward/pen_joint_accel: -0.0999
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2533
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0207
Episode_Reward/pen_feet_regulation: -0.4638
   Episode_Reward/foot_landing_vel: -0.1338
   Episode_Reward/test_gait_reward: -0.9324
Metrics/base_velocity/error_vel_xy: 0.9752
Metrics/base_velocity/error_vel_yaw: 1.2997
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 148537344
                    Iteration time: 1.08s
                        Total time: 1646.36s
                               ETA: 1623.5s

################################################################################
                     [1m Learning iteration 1511/3000 [0m                     

                       Computation: 88244 steps/s (collection: 0.990s, learning 0.124s)
               Value function loss: 0.4630
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8762
                     Learning rate: 0.0004
                       Mean reward: 130.52
               Mean episode length: 974.86
       Episode_Reward/keep_balance: 0.9768
     Episode_Reward/rew_lin_vel_xy: 6.0818
      Episode_Reward/rew_ang_vel_z: 2.4597
    Episode_Reward/pen_base_height: -0.3081
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.1575
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.1155
    Episode_Reward/pen_action_rate: -0.1180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2534
Episode_Reward/pen_flat_orientation: -0.0931
  Episode_Reward/pen_feet_distance: -0.0204
Episode_Reward/pen_feet_regulation: -0.4910
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.9221
Metrics/base_velocity/error_vel_xy: 0.9787
Metrics/base_velocity/error_vel_yaw: 1.3088
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 148635648
                    Iteration time: 1.11s
                        Total time: 1647.47s
                               ETA: 1622.4s

################################################################################
                     [1m Learning iteration 1512/3000 [0m                     

                       Computation: 90968 steps/s (collection: 0.959s, learning 0.121s)
               Value function loss: 0.5253
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8755
                     Learning rate: 0.0003
                       Mean reward: 132.65
               Mean episode length: 997.91
       Episode_Reward/keep_balance: 0.9971
     Episode_Reward/rew_lin_vel_xy: 6.2425
      Episode_Reward/rew_ang_vel_z: 2.5349
    Episode_Reward/pen_base_height: -0.3269
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.1631
   Episode_Reward/pen_joint_torque: -0.2346
    Episode_Reward/pen_joint_accel: -0.1111
    Episode_Reward/pen_action_rate: -0.1201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2603
Episode_Reward/pen_flat_orientation: -0.0959
  Episode_Reward/pen_feet_distance: -0.0186
Episode_Reward/pen_feet_regulation: -0.4721
   Episode_Reward/foot_landing_vel: -0.1378
   Episode_Reward/test_gait_reward: -0.9505
Metrics/base_velocity/error_vel_xy: 0.9934
Metrics/base_velocity/error_vel_yaw: 1.3197
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 148733952
                    Iteration time: 1.08s
                        Total time: 1648.55s
                               ETA: 1621.3s

################################################################################
                     [1m Learning iteration 1513/3000 [0m                     

                       Computation: 89844 steps/s (collection: 0.973s, learning 0.121s)
               Value function loss: 0.5237
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8740
                     Learning rate: 0.0006
                       Mean reward: 133.59
               Mean episode length: 976.85
       Episode_Reward/keep_balance: 0.9570
     Episode_Reward/rew_lin_vel_xy: 5.9977
      Episode_Reward/rew_ang_vel_z: 2.4684
    Episode_Reward/pen_base_height: -0.3131
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1519
   Episode_Reward/pen_joint_torque: -0.2325
    Episode_Reward/pen_joint_accel: -0.1049
    Episode_Reward/pen_action_rate: -0.1144
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0859
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2460
Episode_Reward/pen_flat_orientation: -0.0981
  Episode_Reward/pen_feet_distance: -0.0179
Episode_Reward/pen_feet_regulation: -0.4506
   Episode_Reward/foot_landing_vel: -0.1383
   Episode_Reward/test_gait_reward: -0.9018
Metrics/base_velocity/error_vel_xy: 0.9507
Metrics/base_velocity/error_vel_yaw: 1.2277
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 148832256
                    Iteration time: 1.09s
                        Total time: 1649.65s
                               ETA: 1620.2s

################################################################################
                     [1m Learning iteration 1514/3000 [0m                     

                       Computation: 90953 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.6156
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8740
                     Learning rate: 0.0009
                       Mean reward: 134.84
               Mean episode length: 983.45
       Episode_Reward/keep_balance: 0.9800
     Episode_Reward/rew_lin_vel_xy: 6.1810
      Episode_Reward/rew_ang_vel_z: 2.4867
    Episode_Reward/pen_base_height: -0.3135
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1622
   Episode_Reward/pen_joint_torque: -0.2299
    Episode_Reward/pen_joint_accel: -0.1066
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2556
Episode_Reward/pen_flat_orientation: -0.0881
  Episode_Reward/pen_feet_distance: -0.0264
Episode_Reward/pen_feet_regulation: -0.4538
   Episode_Reward/foot_landing_vel: -0.1361
   Episode_Reward/test_gait_reward: -0.9239
Metrics/base_velocity/error_vel_xy: 0.9491
Metrics/base_velocity/error_vel_yaw: 1.2932
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 148930560
                    Iteration time: 1.08s
                        Total time: 1650.73s
                               ETA: 1619.1s

################################################################################
                     [1m Learning iteration 1515/3000 [0m                     

                       Computation: 91220 steps/s (collection: 0.957s, learning 0.121s)
               Value function loss: 0.5788
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8751
                     Learning rate: 0.0006
                       Mean reward: 129.07
               Mean episode length: 963.00
       Episode_Reward/keep_balance: 0.9741
     Episode_Reward/rew_lin_vel_xy: 6.1114
      Episode_Reward/rew_ang_vel_z: 2.4494
    Episode_Reward/pen_base_height: -0.3063
      Episode_Reward/pen_lin_vel_z: -0.0348
     Episode_Reward/pen_ang_vel_xy: -0.1572
   Episode_Reward/pen_joint_torque: -0.2215
    Episode_Reward/pen_joint_accel: -0.1014
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0855
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2511
Episode_Reward/pen_flat_orientation: -0.0924
  Episode_Reward/pen_feet_distance: -0.0230
Episode_Reward/pen_feet_regulation: -0.4509
   Episode_Reward/foot_landing_vel: -0.1293
   Episode_Reward/test_gait_reward: -0.9145
Metrics/base_velocity/error_vel_xy: 0.9510
Metrics/base_velocity/error_vel_yaw: 1.3080
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 149028864
                    Iteration time: 1.08s
                        Total time: 1651.81s
                               ETA: 1618.0s

################################################################################
                     [1m Learning iteration 1516/3000 [0m                     

                       Computation: 90711 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.6495
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8753
                     Learning rate: 0.0009
                       Mean reward: 134.63
               Mean episode length: 997.22
       Episode_Reward/keep_balance: 0.9979
     Episode_Reward/rew_lin_vel_xy: 6.3078
      Episode_Reward/rew_ang_vel_z: 2.5280
    Episode_Reward/pen_base_height: -0.2964
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1681
   Episode_Reward/pen_joint_torque: -0.2164
    Episode_Reward/pen_joint_accel: -0.1061
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2613
Episode_Reward/pen_flat_orientation: -0.0888
  Episode_Reward/pen_feet_distance: -0.0185
Episode_Reward/pen_feet_regulation: -0.4662
   Episode_Reward/foot_landing_vel: -0.1330
   Episode_Reward/test_gait_reward: -0.9414
Metrics/base_velocity/error_vel_xy: 0.9449
Metrics/base_velocity/error_vel_yaw: 1.3180
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 149127168
                    Iteration time: 1.08s
                        Total time: 1652.89s
                               ETA: 1616.9s

################################################################################
                     [1m Learning iteration 1517/3000 [0m                     

                       Computation: 89565 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.5482
                    Surrogate loss: 0.0012
             Mean action noise std: 0.8753
                     Learning rate: 0.0001
                       Mean reward: 133.18
               Mean episode length: 979.07
       Episode_Reward/keep_balance: 0.9886
     Episode_Reward/rew_lin_vel_xy: 6.2963
      Episode_Reward/rew_ang_vel_z: 2.4916
    Episode_Reward/pen_base_height: -0.3057
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1639
   Episode_Reward/pen_joint_torque: -0.2286
    Episode_Reward/pen_joint_accel: -0.1129
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2594
Episode_Reward/pen_flat_orientation: -0.0935
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4862
   Episode_Reward/foot_landing_vel: -0.1316
   Episode_Reward/test_gait_reward: -0.9348
Metrics/base_velocity/error_vel_xy: 0.9320
Metrics/base_velocity/error_vel_yaw: 1.3276
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 149225472
                    Iteration time: 1.10s
                        Total time: 1653.99s
                               ETA: 1615.9s

################################################################################
                     [1m Learning iteration 1518/3000 [0m                     

                       Computation: 90987 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.5687
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8733
                     Learning rate: 0.0004
                       Mean reward: 132.39
               Mean episode length: 983.25
       Episode_Reward/keep_balance: 0.9861
     Episode_Reward/rew_lin_vel_xy: 6.1600
      Episode_Reward/rew_ang_vel_z: 2.5169
    Episode_Reward/pen_base_height: -0.3095
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.1651
   Episode_Reward/pen_joint_torque: -0.2300
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2578
Episode_Reward/pen_flat_orientation: -0.0889
  Episode_Reward/pen_feet_distance: -0.0228
Episode_Reward/pen_feet_regulation: -0.4565
   Episode_Reward/foot_landing_vel: -0.1489
   Episode_Reward/test_gait_reward: -0.9262
Metrics/base_velocity/error_vel_xy: 0.9629
Metrics/base_velocity/error_vel_yaw: 1.2827
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 149323776
                    Iteration time: 1.08s
                        Total time: 1655.07s
                               ETA: 1614.8s

################################################################################
                     [1m Learning iteration 1519/3000 [0m                     

                       Computation: 90069 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.5046
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8720
                     Learning rate: 0.0001
                       Mean reward: 131.31
               Mean episode length: 982.81
       Episode_Reward/keep_balance: 0.9792
     Episode_Reward/rew_lin_vel_xy: 6.0892
      Episode_Reward/rew_ang_vel_z: 2.4542
    Episode_Reward/pen_base_height: -0.3262
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1619
   Episode_Reward/pen_joint_torque: -0.2387
    Episode_Reward/pen_joint_accel: -0.1141
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2560
Episode_Reward/pen_flat_orientation: -0.1006
  Episode_Reward/pen_feet_distance: -0.0256
Episode_Reward/pen_feet_regulation: -0.4937
   Episode_Reward/foot_landing_vel: -0.1402
   Episode_Reward/test_gait_reward: -0.9291
Metrics/base_velocity/error_vel_xy: 0.9980
Metrics/base_velocity/error_vel_yaw: 1.3150
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 149422080
                    Iteration time: 1.09s
                        Total time: 1656.16s
                               ETA: 1613.7s

################################################################################
                     [1m Learning iteration 1520/3000 [0m                     

                       Computation: 88793 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 0.5722
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8719
                     Learning rate: 0.0003
                       Mean reward: 132.30
               Mean episode length: 983.28
       Episode_Reward/keep_balance: 0.9824
     Episode_Reward/rew_lin_vel_xy: 6.1597
      Episode_Reward/rew_ang_vel_z: 2.5038
    Episode_Reward/pen_base_height: -0.3079
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1676
   Episode_Reward/pen_joint_torque: -0.2269
    Episode_Reward/pen_joint_accel: -0.1287
    Episode_Reward/pen_action_rate: -0.1179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2563
Episode_Reward/pen_flat_orientation: -0.0926
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4820
   Episode_Reward/foot_landing_vel: -0.1461
   Episode_Reward/test_gait_reward: -0.9209
Metrics/base_velocity/error_vel_xy: 0.9681
Metrics/base_velocity/error_vel_yaw: 1.2817
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 149520384
                    Iteration time: 1.11s
                        Total time: 1657.27s
                               ETA: 1612.6s

################################################################################
                     [1m Learning iteration 1521/3000 [0m                     

                       Computation: 90922 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.5801
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8712
                     Learning rate: 0.0006
                       Mean reward: 129.22
               Mean episode length: 968.37
       Episode_Reward/keep_balance: 0.9743
     Episode_Reward/rew_lin_vel_xy: 6.1182
      Episode_Reward/rew_ang_vel_z: 2.4749
    Episode_Reward/pen_base_height: -0.3054
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1616
   Episode_Reward/pen_joint_torque: -0.2281
    Episode_Reward/pen_joint_accel: -0.1153
    Episode_Reward/pen_action_rate: -0.1177
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2544
Episode_Reward/pen_flat_orientation: -0.0962
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4755
   Episode_Reward/foot_landing_vel: -0.1411
   Episode_Reward/test_gait_reward: -0.9221
Metrics/base_velocity/error_vel_xy: 0.9690
Metrics/base_velocity/error_vel_yaw: 1.2807
      Episode_Termination/time_out: 4.9167
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 149618688
                    Iteration time: 1.08s
                        Total time: 1658.35s
                               ETA: 1611.5s

################################################################################
                     [1m Learning iteration 1522/3000 [0m                     

                       Computation: 90578 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.5891
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8713
                     Learning rate: 0.0006
                       Mean reward: 128.85
               Mean episode length: 968.72
       Episode_Reward/keep_balance: 0.9660
     Episode_Reward/rew_lin_vel_xy: 6.0115
      Episode_Reward/rew_ang_vel_z: 2.4364
    Episode_Reward/pen_base_height: -0.3132
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1597
   Episode_Reward/pen_joint_torque: -0.2272
    Episode_Reward/pen_joint_accel: -0.1121
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2521
Episode_Reward/pen_flat_orientation: -0.0985
  Episode_Reward/pen_feet_distance: -0.0212
Episode_Reward/pen_feet_regulation: -0.4835
   Episode_Reward/foot_landing_vel: -0.1426
   Episode_Reward/test_gait_reward: -0.9098
Metrics/base_velocity/error_vel_xy: 0.9755
Metrics/base_velocity/error_vel_yaw: 1.2818
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 149716992
                    Iteration time: 1.09s
                        Total time: 1659.43s
                               ETA: 1610.4s

################################################################################
                     [1m Learning iteration 1523/3000 [0m                     

                       Computation: 89802 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 0.5279
                    Surrogate loss: -0.0016
             Mean action noise std: 0.8705
                     Learning rate: 0.0003
                       Mean reward: 133.01
               Mean episode length: 986.40
       Episode_Reward/keep_balance: 0.9823
     Episode_Reward/rew_lin_vel_xy: 6.1907
      Episode_Reward/rew_ang_vel_z: 2.4829
    Episode_Reward/pen_base_height: -0.3165
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.1631
   Episode_Reward/pen_joint_torque: -0.2260
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.1177
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2568
Episode_Reward/pen_flat_orientation: -0.0935
  Episode_Reward/pen_feet_distance: -0.0272
Episode_Reward/pen_feet_regulation: -0.4606
   Episode_Reward/foot_landing_vel: -0.1372
   Episode_Reward/test_gait_reward: -0.9286
Metrics/base_velocity/error_vel_xy: 0.9553
Metrics/base_velocity/error_vel_yaw: 1.3036
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 149815296
                    Iteration time: 1.09s
                        Total time: 1660.53s
                               ETA: 1609.3s

################################################################################
                     [1m Learning iteration 1524/3000 [0m                     

                       Computation: 89977 steps/s (collection: 0.968s, learning 0.125s)
               Value function loss: 0.5751
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8693
                     Learning rate: 0.0003
                       Mean reward: 131.18
               Mean episode length: 989.64
       Episode_Reward/keep_balance: 0.9897
     Episode_Reward/rew_lin_vel_xy: 6.1888
      Episode_Reward/rew_ang_vel_z: 2.5268
    Episode_Reward/pen_base_height: -0.3260
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1579
   Episode_Reward/pen_joint_torque: -0.2409
    Episode_Reward/pen_joint_accel: -0.1168
    Episode_Reward/pen_action_rate: -0.1180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2533
Episode_Reward/pen_flat_orientation: -0.0920
  Episode_Reward/pen_feet_distance: -0.0176
Episode_Reward/pen_feet_regulation: -0.4565
   Episode_Reward/foot_landing_vel: -0.1403
   Episode_Reward/test_gait_reward: -0.9296
Metrics/base_velocity/error_vel_xy: 0.9786
Metrics/base_velocity/error_vel_yaw: 1.2874
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 149913600
                    Iteration time: 1.09s
                        Total time: 1661.62s
                               ETA: 1608.2s

################################################################################
                     [1m Learning iteration 1525/3000 [0m                     

                       Computation: 88775 steps/s (collection: 0.984s, learning 0.124s)
               Value function loss: 0.5552
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8685
                     Learning rate: 0.0006
                       Mean reward: 134.73
               Mean episode length: 996.05
       Episode_Reward/keep_balance: 0.9974
     Episode_Reward/rew_lin_vel_xy: 6.2840
      Episode_Reward/rew_ang_vel_z: 2.5317
    Episode_Reward/pen_base_height: -0.3336
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1645
   Episode_Reward/pen_joint_torque: -0.2362
    Episode_Reward/pen_joint_accel: -0.1147
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0891
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2606
Episode_Reward/pen_flat_orientation: -0.0959
  Episode_Reward/pen_feet_distance: -0.0267
Episode_Reward/pen_feet_regulation: -0.4940
   Episode_Reward/foot_landing_vel: -0.1343
   Episode_Reward/test_gait_reward: -0.9473
Metrics/base_velocity/error_vel_xy: 0.9647
Metrics/base_velocity/error_vel_yaw: 1.3141
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 150011904
                    Iteration time: 1.11s
                        Total time: 1662.73s
                               ETA: 1607.2s

################################################################################
                     [1m Learning iteration 1526/3000 [0m                     

                       Computation: 88322 steps/s (collection: 0.991s, learning 0.123s)
               Value function loss: 0.5495
                    Surrogate loss: -0.0001
             Mean action noise std: 0.8686
                     Learning rate: 0.0003
                       Mean reward: 135.78
               Mean episode length: 990.66
       Episode_Reward/keep_balance: 0.9756
     Episode_Reward/rew_lin_vel_xy: 6.1714
      Episode_Reward/rew_ang_vel_z: 2.4892
    Episode_Reward/pen_base_height: -0.2986
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1613
   Episode_Reward/pen_joint_torque: -0.2265
    Episode_Reward/pen_joint_accel: -0.1222
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2541
Episode_Reward/pen_flat_orientation: -0.0918
  Episode_Reward/pen_feet_distance: -0.0220
Episode_Reward/pen_feet_regulation: -0.4660
   Episode_Reward/foot_landing_vel: -0.1402
   Episode_Reward/test_gait_reward: -0.9254
Metrics/base_velocity/error_vel_xy: 0.9407
Metrics/base_velocity/error_vel_yaw: 1.2655
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 150110208
                    Iteration time: 1.11s
                        Total time: 1663.84s
                               ETA: 1606.1s

################################################################################
                     [1m Learning iteration 1527/3000 [0m                     

                       Computation: 89978 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 0.5529
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8683
                     Learning rate: 0.0004
                       Mean reward: 137.49
               Mean episode length: 981.61
       Episode_Reward/keep_balance: 0.9762
     Episode_Reward/rew_lin_vel_xy: 6.2405
      Episode_Reward/rew_ang_vel_z: 2.5574
    Episode_Reward/pen_base_height: -0.2965
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.1516
   Episode_Reward/pen_joint_torque: -0.2190
    Episode_Reward/pen_joint_accel: -0.1023
    Episode_Reward/pen_action_rate: -0.1138
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0527
   Episode_Reward/pen_joint_powers: -0.0823
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2482
Episode_Reward/pen_flat_orientation: -0.0892
  Episode_Reward/pen_feet_distance: -0.0210
Episode_Reward/pen_feet_regulation: -0.4396
   Episode_Reward/foot_landing_vel: -0.1329
   Episode_Reward/test_gait_reward: -0.9110
Metrics/base_velocity/error_vel_xy: 0.9073
Metrics/base_velocity/error_vel_yaw: 1.2147
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 150208512
                    Iteration time: 1.09s
                        Total time: 1664.93s
                               ETA: 1605.0s

################################################################################
                     [1m Learning iteration 1528/3000 [0m                     

                       Computation: 90214 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.5266
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8686
                     Learning rate: 0.0003
                       Mean reward: 136.19
               Mean episode length: 996.81
       Episode_Reward/keep_balance: 0.9967
     Episode_Reward/rew_lin_vel_xy: 6.2766
      Episode_Reward/rew_ang_vel_z: 2.5759
    Episode_Reward/pen_base_height: -0.3262
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1606
   Episode_Reward/pen_joint_torque: -0.2382
    Episode_Reward/pen_joint_accel: -0.1131
    Episode_Reward/pen_action_rate: -0.1201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2564
Episode_Reward/pen_flat_orientation: -0.0920
  Episode_Reward/pen_feet_distance: -0.0217
Episode_Reward/pen_feet_regulation: -0.4848
   Episode_Reward/foot_landing_vel: -0.1341
   Episode_Reward/test_gait_reward: -0.9395
Metrics/base_velocity/error_vel_xy: 0.9811
Metrics/base_velocity/error_vel_yaw: 1.2745
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 150306816
                    Iteration time: 1.09s
                        Total time: 1666.02s
                               ETA: 1603.9s

################################################################################
                     [1m Learning iteration 1529/3000 [0m                     

                       Computation: 91183 steps/s (collection: 0.953s, learning 0.125s)
               Value function loss: 0.5635
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8709
                     Learning rate: 0.0006
                       Mean reward: 133.21
               Mean episode length: 982.31
       Episode_Reward/keep_balance: 0.9859
     Episode_Reward/rew_lin_vel_xy: 6.2109
      Episode_Reward/rew_ang_vel_z: 2.5324
    Episode_Reward/pen_base_height: -0.3135
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1661
   Episode_Reward/pen_joint_torque: -0.2295
    Episode_Reward/pen_joint_accel: -0.1174
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2577
Episode_Reward/pen_flat_orientation: -0.0911
  Episode_Reward/pen_feet_distance: -0.0219
Episode_Reward/pen_feet_regulation: -0.4709
   Episode_Reward/foot_landing_vel: -0.1401
   Episode_Reward/test_gait_reward: -0.9290
Metrics/base_velocity/error_vel_xy: 0.9591
Metrics/base_velocity/error_vel_yaw: 1.2719
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 150405120
                    Iteration time: 1.08s
                        Total time: 1667.10s
                               ETA: 1602.8s

################################################################################
                     [1m Learning iteration 1530/3000 [0m                     

                       Computation: 90384 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.5207
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8718
                     Learning rate: 0.0003
                       Mean reward: 129.25
               Mean episode length: 962.54
       Episode_Reward/keep_balance: 0.9740
     Episode_Reward/rew_lin_vel_xy: 6.0804
      Episode_Reward/rew_ang_vel_z: 2.4818
    Episode_Reward/pen_base_height: -0.3071
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1612
   Episode_Reward/pen_joint_torque: -0.2324
    Episode_Reward/pen_joint_accel: -0.1154
    Episode_Reward/pen_action_rate: -0.1180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0593
   Episode_Reward/pen_joint_powers: -0.0897
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2539
Episode_Reward/pen_flat_orientation: -0.0965
  Episode_Reward/pen_feet_distance: -0.0232
Episode_Reward/pen_feet_regulation: -0.4745
   Episode_Reward/foot_landing_vel: -0.1531
   Episode_Reward/test_gait_reward: -0.9235
Metrics/base_velocity/error_vel_xy: 0.9695
Metrics/base_velocity/error_vel_yaw: 1.2748
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 150503424
                    Iteration time: 1.09s
                        Total time: 1668.19s
                               ETA: 1601.7s

################################################################################
                     [1m Learning iteration 1531/3000 [0m                     

                       Computation: 89556 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.5416
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8704
                     Learning rate: 0.0003
                       Mean reward: 135.64
               Mean episode length: 989.50
       Episode_Reward/keep_balance: 0.9913
     Episode_Reward/rew_lin_vel_xy: 6.2612
      Episode_Reward/rew_ang_vel_z: 2.5538
    Episode_Reward/pen_base_height: -0.3041
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1552
   Episode_Reward/pen_joint_torque: -0.2368
    Episode_Reward/pen_joint_accel: -0.1134
    Episode_Reward/pen_action_rate: -0.1174
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2532
Episode_Reward/pen_flat_orientation: -0.0901
  Episode_Reward/pen_feet_distance: -0.0190
Episode_Reward/pen_feet_regulation: -0.4528
   Episode_Reward/foot_landing_vel: -0.1419
   Episode_Reward/test_gait_reward: -0.9308
Metrics/base_velocity/error_vel_xy: 0.9530
Metrics/base_velocity/error_vel_yaw: 1.2660
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 150601728
                    Iteration time: 1.10s
                        Total time: 1669.29s
                               ETA: 1600.6s

################################################################################
                     [1m Learning iteration 1532/3000 [0m                     

                       Computation: 90115 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.5611
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8696
                     Learning rate: 0.0003
                       Mean reward: 132.51
               Mean episode length: 982.99
       Episode_Reward/keep_balance: 0.9876
     Episode_Reward/rew_lin_vel_xy: 6.1956
      Episode_Reward/rew_ang_vel_z: 2.5165
    Episode_Reward/pen_base_height: -0.3245
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.1550
   Episode_Reward/pen_joint_torque: -0.2397
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2557
Episode_Reward/pen_flat_orientation: -0.0936
  Episode_Reward/pen_feet_distance: -0.0255
Episode_Reward/pen_feet_regulation: -0.4829
   Episode_Reward/foot_landing_vel: -0.1389
   Episode_Reward/test_gait_reward: -0.9378
Metrics/base_velocity/error_vel_xy: 0.9696
Metrics/base_velocity/error_vel_yaw: 1.2923
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 150700032
                    Iteration time: 1.09s
                        Total time: 1670.38s
                               ETA: 1599.6s

################################################################################
                     [1m Learning iteration 1533/3000 [0m                     

                       Computation: 89852 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.5849
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8684
                     Learning rate: 0.0006
                       Mean reward: 132.17
               Mean episode length: 972.58
       Episode_Reward/keep_balance: 0.9582
     Episode_Reward/rew_lin_vel_xy: 6.0489
      Episode_Reward/rew_ang_vel_z: 2.4659
    Episode_Reward/pen_base_height: -0.2958
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1543
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1076
    Episode_Reward/pen_action_rate: -0.1152
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2477
Episode_Reward/pen_flat_orientation: -0.0927
  Episode_Reward/pen_feet_distance: -0.0191
Episode_Reward/pen_feet_regulation: -0.4513
   Episode_Reward/foot_landing_vel: -0.1423
   Episode_Reward/test_gait_reward: -0.9077
Metrics/base_velocity/error_vel_xy: 0.9317
Metrics/base_velocity/error_vel_yaw: 1.2344
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 150798336
                    Iteration time: 1.09s
                        Total time: 1671.47s
                               ETA: 1598.5s

################################################################################
                     [1m Learning iteration 1534/3000 [0m                     

                       Computation: 89636 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.5354
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8684
                     Learning rate: 0.0009
                       Mean reward: 135.02
               Mean episode length: 974.78
       Episode_Reward/keep_balance: 0.9847
     Episode_Reward/rew_lin_vel_xy: 6.2669
      Episode_Reward/rew_ang_vel_z: 2.5383
    Episode_Reward/pen_base_height: -0.2961
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1584
   Episode_Reward/pen_joint_torque: -0.2228
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2544
Episode_Reward/pen_flat_orientation: -0.0929
  Episode_Reward/pen_feet_distance: -0.0175
Episode_Reward/pen_feet_regulation: -0.4703
   Episode_Reward/foot_landing_vel: -0.1406
   Episode_Reward/test_gait_reward: -0.9253
Metrics/base_velocity/error_vel_xy: 0.9291
Metrics/base_velocity/error_vel_yaw: 1.2577
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 150896640
                    Iteration time: 1.10s
                        Total time: 1672.57s
                               ETA: 1597.4s

################################################################################
                     [1m Learning iteration 1535/3000 [0m                     

                       Computation: 89038 steps/s (collection: 0.979s, learning 0.125s)
               Value function loss: 0.5247
                    Surrogate loss: 0.0008
             Mean action noise std: 0.8680
                     Learning rate: 0.0002
                       Mean reward: 132.22
               Mean episode length: 977.49
       Episode_Reward/keep_balance: 0.9637
     Episode_Reward/rew_lin_vel_xy: 6.0392
      Episode_Reward/rew_ang_vel_z: 2.4409
    Episode_Reward/pen_base_height: -0.3033
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.1665
   Episode_Reward/pen_joint_torque: -0.2202
    Episode_Reward/pen_joint_accel: -0.1076
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2542
Episode_Reward/pen_flat_orientation: -0.1007
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4688
   Episode_Reward/foot_landing_vel: -0.1332
   Episode_Reward/test_gait_reward: -0.9156
Metrics/base_velocity/error_vel_xy: 0.9589
Metrics/base_velocity/error_vel_yaw: 1.2933
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 150994944
                    Iteration time: 1.10s
                        Total time: 1673.67s
                               ETA: 1596.3s

################################################################################
                     [1m Learning iteration 1536/3000 [0m                     

                       Computation: 90066 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.4859
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8663
                     Learning rate: 0.0006
                       Mean reward: 136.76
               Mean episode length: 997.10
       Episode_Reward/keep_balance: 0.9970
     Episode_Reward/rew_lin_vel_xy: 6.3373
      Episode_Reward/rew_ang_vel_z: 2.5144
    Episode_Reward/pen_base_height: -0.3248
      Episode_Reward/pen_lin_vel_z: -0.0349
     Episode_Reward/pen_ang_vel_xy: -0.1625
   Episode_Reward/pen_joint_torque: -0.2304
    Episode_Reward/pen_joint_accel: -0.1151
    Episode_Reward/pen_action_rate: -0.1208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2608
Episode_Reward/pen_flat_orientation: -0.0900
  Episode_Reward/pen_feet_distance: -0.0189
Episode_Reward/pen_feet_regulation: -0.4776
   Episode_Reward/foot_landing_vel: -0.1333
   Episode_Reward/test_gait_reward: -0.9421
Metrics/base_velocity/error_vel_xy: 0.9572
Metrics/base_velocity/error_vel_yaw: 1.3371
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 151093248
                    Iteration time: 1.09s
                        Total time: 1674.76s
                               ETA: 1595.2s

################################################################################
                     [1m Learning iteration 1537/3000 [0m                     

                       Computation: 89705 steps/s (collection: 0.970s, learning 0.126s)
               Value function loss: 0.5663
                    Surrogate loss: 0.0012
             Mean action noise std: 0.8661
                     Learning rate: 0.0002
                       Mean reward: 129.43
               Mean episode length: 985.32
       Episode_Reward/keep_balance: 0.9872
     Episode_Reward/rew_lin_vel_xy: 6.1868
      Episode_Reward/rew_ang_vel_z: 2.4413
    Episode_Reward/pen_base_height: -0.3139
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1630
   Episode_Reward/pen_joint_torque: -0.2353
    Episode_Reward/pen_joint_accel: -0.1050
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2601
Episode_Reward/pen_flat_orientation: -0.0984
  Episode_Reward/pen_feet_distance: -0.0273
Episode_Reward/pen_feet_regulation: -0.4913
   Episode_Reward/foot_landing_vel: -0.1392
   Episode_Reward/test_gait_reward: -0.9374
Metrics/base_velocity/error_vel_xy: 0.9913
Metrics/base_velocity/error_vel_yaw: 1.3610
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 151191552
                    Iteration time: 1.10s
                        Total time: 1675.86s
                               ETA: 1594.1s

################################################################################
                     [1m Learning iteration 1538/3000 [0m                     

                       Computation: 89887 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.5205
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8651
                     Learning rate: 0.0006
                       Mean reward: 134.59
               Mean episode length: 991.12
       Episode_Reward/keep_balance: 0.9929
     Episode_Reward/rew_lin_vel_xy: 6.2413
      Episode_Reward/rew_ang_vel_z: 2.5357
    Episode_Reward/pen_base_height: -0.3209
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1597
   Episode_Reward/pen_joint_torque: -0.2387
    Episode_Reward/pen_joint_accel: -0.1097
    Episode_Reward/pen_action_rate: -0.1192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2573
Episode_Reward/pen_flat_orientation: -0.0962
  Episode_Reward/pen_feet_distance: -0.0222
Episode_Reward/pen_feet_regulation: -0.4684
   Episode_Reward/foot_landing_vel: -0.1335
   Episode_Reward/test_gait_reward: -0.9356
Metrics/base_velocity/error_vel_xy: 0.9804
Metrics/base_velocity/error_vel_yaw: 1.2885
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 151289856
                    Iteration time: 1.09s
                        Total time: 1676.95s
                               ETA: 1593.1s

################################################################################
                     [1m Learning iteration 1539/3000 [0m                     

                       Computation: 89674 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.5491
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8655
                     Learning rate: 0.0004
                       Mean reward: 135.37
               Mean episode length: 984.50
       Episode_Reward/keep_balance: 0.9836
     Episode_Reward/rew_lin_vel_xy: 6.2477
      Episode_Reward/rew_ang_vel_z: 2.5230
    Episode_Reward/pen_base_height: -0.2879
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.1629
   Episode_Reward/pen_joint_torque: -0.2114
    Episode_Reward/pen_joint_accel: -0.1083
    Episode_Reward/pen_action_rate: -0.1168
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0841
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2571
Episode_Reward/pen_flat_orientation: -0.0942
  Episode_Reward/pen_feet_distance: -0.0230
Episode_Reward/pen_feet_regulation: -0.4518
   Episode_Reward/foot_landing_vel: -0.1483
   Episode_Reward/test_gait_reward: -0.9180
Metrics/base_velocity/error_vel_xy: 0.9357
Metrics/base_velocity/error_vel_yaw: 1.2910
      Episode_Termination/time_out: 3.2500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 151388160
                    Iteration time: 1.10s
                        Total time: 1678.05s
                               ETA: 1592.0s

################################################################################
                     [1m Learning iteration 1540/3000 [0m                     

                       Computation: 89704 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.5820
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8649
                     Learning rate: 0.0006
                       Mean reward: 134.43
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.2723
      Episode_Reward/rew_ang_vel_z: 2.5303
    Episode_Reward/pen_base_height: -0.3010
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1638
   Episode_Reward/pen_joint_torque: -0.2382
    Episode_Reward/pen_joint_accel: -0.1220
    Episode_Reward/pen_action_rate: -0.1227
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0608
   Episode_Reward/pen_joint_powers: -0.0921
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2643
Episode_Reward/pen_flat_orientation: -0.0925
  Episode_Reward/pen_feet_distance: -0.0214
Episode_Reward/pen_feet_regulation: -0.4980
   Episode_Reward/foot_landing_vel: -0.1600
   Episode_Reward/test_gait_reward: -0.9505
Metrics/base_velocity/error_vel_xy: 0.9914
Metrics/base_velocity/error_vel_yaw: 1.3129
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 151486464
                    Iteration time: 1.10s
                        Total time: 1679.14s
                               ETA: 1590.9s

################################################################################
                     [1m Learning iteration 1541/3000 [0m                     

                       Computation: 90327 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.5350
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8651
                     Learning rate: 0.0003
                       Mean reward: 130.67
               Mean episode length: 980.43
       Episode_Reward/keep_balance: 0.9795
     Episode_Reward/rew_lin_vel_xy: 6.0634
      Episode_Reward/rew_ang_vel_z: 2.4771
    Episode_Reward/pen_base_height: -0.3309
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1618
   Episode_Reward/pen_joint_torque: -0.2398
    Episode_Reward/pen_joint_accel: -0.1036
    Episode_Reward/pen_action_rate: -0.1216
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0926
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2593
Episode_Reward/pen_flat_orientation: -0.0993
  Episode_Reward/pen_feet_distance: -0.0194
Episode_Reward/pen_feet_regulation: -0.5018
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.9380
Metrics/base_velocity/error_vel_xy: 1.0117
Metrics/base_velocity/error_vel_yaw: 1.3044
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 151584768
                    Iteration time: 1.09s
                        Total time: 1680.23s
                               ETA: 1589.8s

################################################################################
                     [1m Learning iteration 1542/3000 [0m                     

                       Computation: 89700 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.5695
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8650
                     Learning rate: 0.0006
                       Mean reward: 131.20
               Mean episode length: 982.36
       Episode_Reward/keep_balance: 0.9842
     Episode_Reward/rew_lin_vel_xy: 6.1967
      Episode_Reward/rew_ang_vel_z: 2.5187
    Episode_Reward/pen_base_height: -0.3196
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1586
   Episode_Reward/pen_joint_torque: -0.2295
    Episode_Reward/pen_joint_accel: -0.1100
    Episode_Reward/pen_action_rate: -0.1190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2562
Episode_Reward/pen_flat_orientation: -0.0934
  Episode_Reward/pen_feet_distance: -0.0238
Episode_Reward/pen_feet_regulation: -0.4815
   Episode_Reward/foot_landing_vel: -0.1356
   Episode_Reward/test_gait_reward: -0.9382
Metrics/base_velocity/error_vel_xy: 0.9751
Metrics/base_velocity/error_vel_yaw: 1.2754
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 151683072
                    Iteration time: 1.10s
                        Total time: 1681.33s
                               ETA: 1588.7s

################################################################################
                     [1m Learning iteration 1543/3000 [0m                     

                       Computation: 91764 steps/s (collection: 0.948s, learning 0.123s)
               Value function loss: 0.6536
                    Surrogate loss: 0.0042
             Mean action noise std: 0.8653
                     Learning rate: 0.0000
                       Mean reward: 130.95
               Mean episode length: 974.98
       Episode_Reward/keep_balance: 0.9719
     Episode_Reward/rew_lin_vel_xy: 6.0580
      Episode_Reward/rew_ang_vel_z: 2.4276
    Episode_Reward/pen_base_height: -0.2961
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1681
   Episode_Reward/pen_joint_torque: -0.2239
    Episode_Reward/pen_joint_accel: -0.1118
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2602
Episode_Reward/pen_flat_orientation: -0.0945
  Episode_Reward/pen_feet_distance: -0.0191
Episode_Reward/pen_feet_regulation: -0.4656
   Episode_Reward/foot_landing_vel: -0.1486
   Episode_Reward/test_gait_reward: -0.9253
Metrics/base_velocity/error_vel_xy: 0.9803
Metrics/base_velocity/error_vel_yaw: 1.3260
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 151781376
                    Iteration time: 1.07s
                        Total time: 1682.40s
                               ETA: 1587.6s

################################################################################
                     [1m Learning iteration 1544/3000 [0m                     

                       Computation: 89383 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.5901
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8650
                     Learning rate: 0.0001
                       Mean reward: 129.37
               Mean episode length: 976.77
       Episode_Reward/keep_balance: 0.9826
     Episode_Reward/rew_lin_vel_xy: 6.1445
      Episode_Reward/rew_ang_vel_z: 2.4906
    Episode_Reward/pen_base_height: -0.3218
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1650
   Episode_Reward/pen_joint_torque: -0.2343
    Episode_Reward/pen_joint_accel: -0.1269
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0615
   Episode_Reward/pen_joint_powers: -0.0919
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2605
Episode_Reward/pen_flat_orientation: -0.1020
  Episode_Reward/pen_feet_distance: -0.0240
Episode_Reward/pen_feet_regulation: -0.5089
   Episode_Reward/foot_landing_vel: -0.1498
   Episode_Reward/test_gait_reward: -0.9353
Metrics/base_velocity/error_vel_xy: 1.0069
Metrics/base_velocity/error_vel_yaw: 1.2914
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 151879680
                    Iteration time: 1.10s
                        Total time: 1683.50s
                               ETA: 1586.5s

################################################################################
                     [1m Learning iteration 1545/3000 [0m                     

                       Computation: 90165 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.5031
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8640
                     Learning rate: 0.0004
                       Mean reward: 137.03
               Mean episode length: 993.28
       Episode_Reward/keep_balance: 0.9921
     Episode_Reward/rew_lin_vel_xy: 6.2885
      Episode_Reward/rew_ang_vel_z: 2.5468
    Episode_Reward/pen_base_height: -0.2904
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1661
   Episode_Reward/pen_joint_torque: -0.2304
    Episode_Reward/pen_joint_accel: -0.1089
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2603
Episode_Reward/pen_flat_orientation: -0.0908
  Episode_Reward/pen_feet_distance: -0.0202
Episode_Reward/pen_feet_regulation: -0.4581
   Episode_Reward/foot_landing_vel: -0.1445
   Episode_Reward/test_gait_reward: -0.9358
Metrics/base_velocity/error_vel_xy: 0.9340
Metrics/base_velocity/error_vel_yaw: 1.2759
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 151977984
                    Iteration time: 1.09s
                        Total time: 1684.59s
                               ETA: 1585.4s

################################################################################
                     [1m Learning iteration 1546/3000 [0m                     

                       Computation: 91101 steps/s (collection: 0.954s, learning 0.125s)
               Value function loss: 0.6145
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8640
                     Learning rate: 0.0004
                       Mean reward: 132.73
               Mean episode length: 994.18
       Episode_Reward/keep_balance: 0.9952
     Episode_Reward/rew_lin_vel_xy: 6.3046
      Episode_Reward/rew_ang_vel_z: 2.5146
    Episode_Reward/pen_base_height: -0.3233
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1576
   Episode_Reward/pen_joint_torque: -0.2342
    Episode_Reward/pen_joint_accel: -0.1110
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0586
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2593
Episode_Reward/pen_flat_orientation: -0.0923
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4861
   Episode_Reward/foot_landing_vel: -0.1399
   Episode_Reward/test_gait_reward: -0.9435
Metrics/base_velocity/error_vel_xy: 0.9632
Metrics/base_velocity/error_vel_yaw: 1.3188
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 152076288
                    Iteration time: 1.08s
                        Total time: 1685.67s
                               ETA: 1584.3s

################################################################################
                     [1m Learning iteration 1547/3000 [0m                     

                       Computation: 88947 steps/s (collection: 0.982s, learning 0.123s)
               Value function loss: 0.6075
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8645
                     Learning rate: 0.0003
                       Mean reward: 130.00
               Mean episode length: 972.74
       Episode_Reward/keep_balance: 0.9758
     Episode_Reward/rew_lin_vel_xy: 6.1426
      Episode_Reward/rew_ang_vel_z: 2.4657
    Episode_Reward/pen_base_height: -0.3103
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1678
   Episode_Reward/pen_joint_torque: -0.2262
    Episode_Reward/pen_joint_accel: -0.1137
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2576
Episode_Reward/pen_flat_orientation: -0.0966
  Episode_Reward/pen_feet_distance: -0.0178
Episode_Reward/pen_feet_regulation: -0.4848
   Episode_Reward/foot_landing_vel: -0.1444
   Episode_Reward/test_gait_reward: -0.9245
Metrics/base_velocity/error_vel_xy: 0.9596
Metrics/base_velocity/error_vel_yaw: 1.3000
      Episode_Termination/time_out: 5.0417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 152174592
                    Iteration time: 1.11s
                        Total time: 1686.77s
                               ETA: 1583.3s

################################################################################
                     [1m Learning iteration 1548/3000 [0m                     

                       Computation: 89548 steps/s (collection: 0.973s, learning 0.125s)
               Value function loss: 0.5589
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8643
                     Learning rate: 0.0004
                       Mean reward: 134.72
               Mean episode length: 991.39
       Episode_Reward/keep_balance: 0.9897
     Episode_Reward/rew_lin_vel_xy: 6.2591
      Episode_Reward/rew_ang_vel_z: 2.5166
    Episode_Reward/pen_base_height: -0.3230
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1678
   Episode_Reward/pen_joint_torque: -0.2389
    Episode_Reward/pen_joint_accel: -0.1078
    Episode_Reward/pen_action_rate: -0.1208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2609
Episode_Reward/pen_flat_orientation: -0.1003
  Episode_Reward/pen_feet_distance: -0.0229
Episode_Reward/pen_feet_regulation: -0.4794
   Episode_Reward/foot_landing_vel: -0.1496
   Episode_Reward/test_gait_reward: -0.9314
Metrics/base_velocity/error_vel_xy: 0.9569
Metrics/base_velocity/error_vel_yaw: 1.3013
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 152272896
                    Iteration time: 1.10s
                        Total time: 1687.87s
                               ETA: 1582.2s

################################################################################
                     [1m Learning iteration 1549/3000 [0m                     

                       Computation: 89443 steps/s (collection: 0.973s, learning 0.126s)
               Value function loss: 0.5796
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8646
                     Learning rate: 0.0006
                       Mean reward: 128.96
               Mean episode length: 974.82
       Episode_Reward/keep_balance: 0.9699
     Episode_Reward/rew_lin_vel_xy: 6.0868
      Episode_Reward/rew_ang_vel_z: 2.4174
    Episode_Reward/pen_base_height: -0.3133
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1604
   Episode_Reward/pen_joint_torque: -0.2359
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1195
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0602
   Episode_Reward/pen_joint_powers: -0.0919
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2565
Episode_Reward/pen_flat_orientation: -0.0988
  Episode_Reward/pen_feet_distance: -0.0227
Episode_Reward/pen_feet_regulation: -0.4861
   Episode_Reward/foot_landing_vel: -0.1516
   Episode_Reward/test_gait_reward: -0.9243
Metrics/base_velocity/error_vel_xy: 0.9657
Metrics/base_velocity/error_vel_yaw: 1.3220
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 152371200
                    Iteration time: 1.10s
                        Total time: 1688.97s
                               ETA: 1581.1s

################################################################################
                     [1m Learning iteration 1550/3000 [0m                     

                       Computation: 89349 steps/s (collection: 0.975s, learning 0.126s)
               Value function loss: 0.5987
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8657
                     Learning rate: 0.0009
                       Mean reward: 134.87
               Mean episode length: 982.81
       Episode_Reward/keep_balance: 0.9904
     Episode_Reward/rew_lin_vel_xy: 6.3248
      Episode_Reward/rew_ang_vel_z: 2.5595
    Episode_Reward/pen_base_height: -0.3231
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1603
   Episode_Reward/pen_joint_torque: -0.2303
    Episode_Reward/pen_joint_accel: -0.1041
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2531
Episode_Reward/pen_flat_orientation: -0.0938
  Episode_Reward/pen_feet_distance: -0.0209
Episode_Reward/pen_feet_regulation: -0.4497
   Episode_Reward/foot_landing_vel: -0.1420
   Episode_Reward/test_gait_reward: -0.9313
Metrics/base_velocity/error_vel_xy: 0.9227
Metrics/base_velocity/error_vel_yaw: 1.2661
      Episode_Termination/time_out: 4.9583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 152469504
                    Iteration time: 1.10s
                        Total time: 1690.07s
                               ETA: 1580.0s

################################################################################
                     [1m Learning iteration 1551/3000 [0m                     

                       Computation: 88220 steps/s (collection: 0.990s, learning 0.125s)
               Value function loss: 0.6311
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8659
                     Learning rate: 0.0009
                       Mean reward: 131.32
               Mean episode length: 972.26
       Episode_Reward/keep_balance: 0.9809
     Episode_Reward/rew_lin_vel_xy: 6.0848
      Episode_Reward/rew_ang_vel_z: 2.4979
    Episode_Reward/pen_base_height: -0.3259
      Episode_Reward/pen_lin_vel_z: -0.0389
     Episode_Reward/pen_ang_vel_xy: -0.1575
   Episode_Reward/pen_joint_torque: -0.2459
    Episode_Reward/pen_joint_accel: -0.1091
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2561
Episode_Reward/pen_flat_orientation: -0.0971
  Episode_Reward/pen_feet_distance: -0.0221
Episode_Reward/pen_feet_regulation: -0.4818
   Episode_Reward/foot_landing_vel: -0.1436
   Episode_Reward/test_gait_reward: -0.9271
Metrics/base_velocity/error_vel_xy: 1.0258
Metrics/base_velocity/error_vel_yaw: 1.2797
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 152567808
                    Iteration time: 1.11s
                        Total time: 1691.19s
                               ETA: 1578.9s

################################################################################
                     [1m Learning iteration 1552/3000 [0m                     

                       Computation: 89520 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.5394
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8652
                     Learning rate: 0.0004
                       Mean reward: 134.78
               Mean episode length: 984.53
       Episode_Reward/keep_balance: 0.9878
     Episode_Reward/rew_lin_vel_xy: 6.2655
      Episode_Reward/rew_ang_vel_z: 2.5511
    Episode_Reward/pen_base_height: -0.3073
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1552
   Episode_Reward/pen_joint_torque: -0.2301
    Episode_Reward/pen_joint_accel: -0.1050
    Episode_Reward/pen_action_rate: -0.1163
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2508
Episode_Reward/pen_flat_orientation: -0.0926
  Episode_Reward/pen_feet_distance: -0.0206
Episode_Reward/pen_feet_regulation: -0.4493
   Episode_Reward/foot_landing_vel: -0.1394
   Episode_Reward/test_gait_reward: -0.9336
Metrics/base_velocity/error_vel_xy: 0.9351
Metrics/base_velocity/error_vel_yaw: 1.2574
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 152666112
                    Iteration time: 1.10s
                        Total time: 1692.28s
                               ETA: 1577.9s

################################################################################
                     [1m Learning iteration 1553/3000 [0m                     

                       Computation: 90876 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.5073
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8648
                     Learning rate: 0.0006
                       Mean reward: 134.74
               Mean episode length: 986.94
       Episode_Reward/keep_balance: 0.9875
     Episode_Reward/rew_lin_vel_xy: 6.2229
      Episode_Reward/rew_ang_vel_z: 2.5211
    Episode_Reward/pen_base_height: -0.3126
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.1555
   Episode_Reward/pen_joint_torque: -0.2228
    Episode_Reward/pen_joint_accel: -0.1098
    Episode_Reward/pen_action_rate: -0.1180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2525
Episode_Reward/pen_flat_orientation: -0.0913
  Episode_Reward/pen_feet_distance: -0.0233
Episode_Reward/pen_feet_regulation: -0.4705
   Episode_Reward/foot_landing_vel: -0.1367
   Episode_Reward/test_gait_reward: -0.9380
Metrics/base_velocity/error_vel_xy: 0.9677
Metrics/base_velocity/error_vel_yaw: 1.2883
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 152764416
                    Iteration time: 1.08s
                        Total time: 1693.37s
                               ETA: 1576.8s

################################################################################
                     [1m Learning iteration 1554/3000 [0m                     

                       Computation: 90023 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.6148
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8662
                     Learning rate: 0.0009
                       Mean reward: 132.03
               Mean episode length: 982.90
       Episode_Reward/keep_balance: 0.9793
     Episode_Reward/rew_lin_vel_xy: 6.2033
      Episode_Reward/rew_ang_vel_z: 2.5080
    Episode_Reward/pen_base_height: -0.3102
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1561
   Episode_Reward/pen_joint_torque: -0.2398
    Episode_Reward/pen_joint_accel: -0.1175
    Episode_Reward/pen_action_rate: -0.1180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2546
Episode_Reward/pen_flat_orientation: -0.0915
  Episode_Reward/pen_feet_distance: -0.0213
Episode_Reward/pen_feet_regulation: -0.4705
   Episode_Reward/foot_landing_vel: -0.1447
   Episode_Reward/test_gait_reward: -0.9275
Metrics/base_velocity/error_vel_xy: 0.9473
Metrics/base_velocity/error_vel_yaw: 1.2672
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 152862720
                    Iteration time: 1.09s
                        Total time: 1694.46s
                               ETA: 1575.7s

################################################################################
                     [1m Learning iteration 1555/3000 [0m                     

                       Computation: 89250 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.6290
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8681
                     Learning rate: 0.0006
                       Mean reward: 133.43
               Mean episode length: 978.31
       Episode_Reward/keep_balance: 0.9828
     Episode_Reward/rew_lin_vel_xy: 6.2311
      Episode_Reward/rew_ang_vel_z: 2.4970
    Episode_Reward/pen_base_height: -0.3212
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1605
   Episode_Reward/pen_joint_torque: -0.2344
    Episode_Reward/pen_joint_accel: -0.1188
    Episode_Reward/pen_action_rate: -0.1212
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0591
   Episode_Reward/pen_joint_powers: -0.0896
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2591
Episode_Reward/pen_flat_orientation: -0.0937
  Episode_Reward/pen_feet_distance: -0.0206
Episode_Reward/pen_feet_regulation: -0.4857
   Episode_Reward/foot_landing_vel: -0.1328
   Episode_Reward/test_gait_reward: -0.9361
Metrics/base_velocity/error_vel_xy: 0.9557
Metrics/base_velocity/error_vel_yaw: 1.2880
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 152961024
                    Iteration time: 1.10s
                        Total time: 1695.56s
                               ETA: 1574.6s

################################################################################
                     [1m Learning iteration 1556/3000 [0m                     

                       Computation: 90433 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.6034
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8707
                     Learning rate: 0.0006
                       Mean reward: 134.16
               Mean episode length: 987.30
       Episode_Reward/keep_balance: 0.9911
     Episode_Reward/rew_lin_vel_xy: 6.2455
      Episode_Reward/rew_ang_vel_z: 2.5237
    Episode_Reward/pen_base_height: -0.3039
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1657
   Episode_Reward/pen_joint_torque: -0.2259
    Episode_Reward/pen_joint_accel: -0.1120
    Episode_Reward/pen_action_rate: -0.1211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0593
   Episode_Reward/pen_joint_powers: -0.0897
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2629
Episode_Reward/pen_flat_orientation: -0.0904
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4888
   Episode_Reward/foot_landing_vel: -0.1426
   Episode_Reward/test_gait_reward: -0.9486
Metrics/base_velocity/error_vel_xy: 0.9798
Metrics/base_velocity/error_vel_yaw: 1.2981
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 153059328
                    Iteration time: 1.09s
                        Total time: 1696.65s
                               ETA: 1573.5s

################################################################################
                     [1m Learning iteration 1557/3000 [0m                     

                       Computation: 89897 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.6732
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8711
                     Learning rate: 0.0006
                       Mean reward: 133.22
               Mean episode length: 981.86
       Episode_Reward/keep_balance: 0.9896
     Episode_Reward/rew_lin_vel_xy: 6.2136
      Episode_Reward/rew_ang_vel_z: 2.5357
    Episode_Reward/pen_base_height: -0.3018
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1609
   Episode_Reward/pen_joint_torque: -0.2284
    Episode_Reward/pen_joint_accel: -0.1141
    Episode_Reward/pen_action_rate: -0.1184
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2558
Episode_Reward/pen_flat_orientation: -0.0890
  Episode_Reward/pen_feet_distance: -0.0201
Episode_Reward/pen_feet_regulation: -0.4769
   Episode_Reward/foot_landing_vel: -0.1533
   Episode_Reward/test_gait_reward: -0.9284
Metrics/base_velocity/error_vel_xy: 0.9749
Metrics/base_velocity/error_vel_yaw: 1.2767
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 153157632
                    Iteration time: 1.09s
                        Total time: 1697.74s
                               ETA: 1572.4s

################################################################################
                     [1m Learning iteration 1558/3000 [0m                     

                       Computation: 90228 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.6155
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8732
                     Learning rate: 0.0006
                       Mean reward: 133.75
               Mean episode length: 968.87
       Episode_Reward/keep_balance: 0.9632
     Episode_Reward/rew_lin_vel_xy: 6.1337
      Episode_Reward/rew_ang_vel_z: 2.4829
    Episode_Reward/pen_base_height: -0.2965
      Episode_Reward/pen_lin_vel_z: -0.0347
     Episode_Reward/pen_ang_vel_xy: -0.1545
   Episode_Reward/pen_joint_torque: -0.2111
    Episode_Reward/pen_joint_accel: -0.1022
    Episode_Reward/pen_action_rate: -0.1134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0820
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2479
Episode_Reward/pen_flat_orientation: -0.0888
  Episode_Reward/pen_feet_distance: -0.0198
Episode_Reward/pen_feet_regulation: -0.4392
   Episode_Reward/foot_landing_vel: -0.1315
   Episode_Reward/test_gait_reward: -0.9028
Metrics/base_velocity/error_vel_xy: 0.9126
Metrics/base_velocity/error_vel_yaw: 1.2371
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 153255936
                    Iteration time: 1.09s
                        Total time: 1698.83s
                               ETA: 1571.3s

################################################################################
                     [1m Learning iteration 1559/3000 [0m                     

                       Computation: 89194 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.6168
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8737
                     Learning rate: 0.0003
                       Mean reward: 131.27
               Mean episode length: 963.42
       Episode_Reward/keep_balance: 0.9688
     Episode_Reward/rew_lin_vel_xy: 6.1338
      Episode_Reward/rew_ang_vel_z: 2.4779
    Episode_Reward/pen_base_height: -0.3121
      Episode_Reward/pen_lin_vel_z: -0.0344
     Episode_Reward/pen_ang_vel_xy: -0.1552
   Episode_Reward/pen_joint_torque: -0.2278
    Episode_Reward/pen_joint_accel: -0.1001
    Episode_Reward/pen_action_rate: -0.1170
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2531
Episode_Reward/pen_flat_orientation: -0.0926
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4536
   Episode_Reward/foot_landing_vel: -0.1234
   Episode_Reward/test_gait_reward: -0.9143
Metrics/base_velocity/error_vel_xy: 0.9417
Metrics/base_velocity/error_vel_yaw: 1.2669
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 153354240
                    Iteration time: 1.10s
                        Total time: 1699.93s
                               ETA: 1570.3s

################################################################################
                     [1m Learning iteration 1560/3000 [0m                     

                       Computation: 89215 steps/s (collection: 0.974s, learning 0.128s)
               Value function loss: 0.5401
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8729
                     Learning rate: 0.0006
                       Mean reward: 128.10
               Mean episode length: 961.19
       Episode_Reward/keep_balance: 0.9384
     Episode_Reward/rew_lin_vel_xy: 5.8948
      Episode_Reward/rew_ang_vel_z: 2.3886
    Episode_Reward/pen_base_height: -0.3298
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1609
   Episode_Reward/pen_joint_torque: -0.2314
    Episode_Reward/pen_joint_accel: -0.1176
    Episode_Reward/pen_action_rate: -0.1156
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2467
Episode_Reward/pen_flat_orientation: -0.0983
  Episode_Reward/pen_feet_distance: -0.0243
Episode_Reward/pen_feet_regulation: -0.4696
   Episode_Reward/foot_landing_vel: -0.1538
   Episode_Reward/test_gait_reward: -0.8942
Metrics/base_velocity/error_vel_xy: 0.9244
Metrics/base_velocity/error_vel_yaw: 1.2357
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 153452544
                    Iteration time: 1.10s
                        Total time: 1701.03s
                               ETA: 1569.2s

################################################################################
                     [1m Learning iteration 1561/3000 [0m                     

                       Computation: 88482 steps/s (collection: 0.987s, learning 0.124s)
               Value function loss: 0.5399
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8740
                     Learning rate: 0.0004
                       Mean reward: 133.72
               Mean episode length: 982.22
       Episode_Reward/keep_balance: 0.9808
     Episode_Reward/rew_lin_vel_xy: 6.1879
      Episode_Reward/rew_ang_vel_z: 2.4769
    Episode_Reward/pen_base_height: -0.3008
      Episode_Reward/pen_lin_vel_z: -0.0349
     Episode_Reward/pen_ang_vel_xy: -0.1637
   Episode_Reward/pen_joint_torque: -0.2252
    Episode_Reward/pen_joint_accel: -0.1146
    Episode_Reward/pen_action_rate: -0.1177
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2575
Episode_Reward/pen_flat_orientation: -0.0910
  Episode_Reward/pen_feet_distance: -0.0205
Episode_Reward/pen_feet_regulation: -0.4767
   Episode_Reward/foot_landing_vel: -0.1455
   Episode_Reward/test_gait_reward: -0.9232
Metrics/base_velocity/error_vel_xy: 0.9493
Metrics/base_velocity/error_vel_yaw: 1.2913
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 153550848
                    Iteration time: 1.11s
                        Total time: 1702.14s
                               ETA: 1568.1s

################################################################################
                     [1m Learning iteration 1562/3000 [0m                     

                       Computation: 89746 steps/s (collection: 0.968s, learning 0.128s)
               Value function loss: 0.5945
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8731
                     Learning rate: 0.0006
                       Mean reward: 135.80
               Mean episode length: 998.84
       Episode_Reward/keep_balance: 0.9995
     Episode_Reward/rew_lin_vel_xy: 6.2955
      Episode_Reward/rew_ang_vel_z: 2.5352
    Episode_Reward/pen_base_height: -0.3172
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1657
   Episode_Reward/pen_joint_torque: -0.2365
    Episode_Reward/pen_joint_accel: -0.1223
    Episode_Reward/pen_action_rate: -0.1228
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0918
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2639
Episode_Reward/pen_flat_orientation: -0.0900
  Episode_Reward/pen_feet_distance: -0.0220
Episode_Reward/pen_feet_regulation: -0.4969
   Episode_Reward/foot_landing_vel: -0.1430
   Episode_Reward/test_gait_reward: -0.9553
Metrics/base_velocity/error_vel_xy: 0.9708
Metrics/base_velocity/error_vel_yaw: 1.3230
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 153649152
                    Iteration time: 1.10s
                        Total time: 1703.24s
                               ETA: 1567.0s

################################################################################
                     [1m Learning iteration 1563/3000 [0m                     

                       Computation: 90025 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.6470
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8731
                     Learning rate: 0.0003
                       Mean reward: 132.58
               Mean episode length: 971.03
       Episode_Reward/keep_balance: 0.9048
     Episode_Reward/rew_lin_vel_xy: 5.6727
      Episode_Reward/rew_ang_vel_z: 2.3004
    Episode_Reward/pen_base_height: -0.3118
      Episode_Reward/pen_lin_vel_z: -0.0346
     Episode_Reward/pen_ang_vel_xy: -0.1466
   Episode_Reward/pen_joint_torque: -0.2160
    Episode_Reward/pen_joint_accel: -0.1039
    Episode_Reward/pen_action_rate: -0.1095
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0834
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2356
Episode_Reward/pen_flat_orientation: -0.0965
  Episode_Reward/pen_feet_distance: -0.0231
Episode_Reward/pen_feet_regulation: -0.4457
   Episode_Reward/foot_landing_vel: -0.1328
   Episode_Reward/test_gait_reward: -0.8572
Metrics/base_velocity/error_vel_xy: 0.9120
Metrics/base_velocity/error_vel_yaw: 1.1857
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 153747456
                    Iteration time: 1.09s
                        Total time: 1704.33s
                               ETA: 1565.9s

################################################################################
                     [1m Learning iteration 1564/3000 [0m                     

                       Computation: 89847 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.5782
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8720
                     Learning rate: 0.0006
                       Mean reward: 131.33
               Mean episode length: 983.01
       Episode_Reward/keep_balance: 0.9838
     Episode_Reward/rew_lin_vel_xy: 6.1853
      Episode_Reward/rew_ang_vel_z: 2.4782
    Episode_Reward/pen_base_height: -0.3179
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1680
   Episode_Reward/pen_joint_torque: -0.2251
    Episode_Reward/pen_joint_accel: -0.1127
    Episode_Reward/pen_action_rate: -0.1202
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0896
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2603
Episode_Reward/pen_flat_orientation: -0.0976
  Episode_Reward/pen_feet_distance: -0.0232
Episode_Reward/pen_feet_regulation: -0.4915
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.9379
Metrics/base_velocity/error_vel_xy: 0.9746
Metrics/base_velocity/error_vel_yaw: 1.3265
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 153845760
                    Iteration time: 1.09s
                        Total time: 1705.43s
                               ETA: 1564.9s

################################################################################
                     [1m Learning iteration 1565/3000 [0m                     

                       Computation: 89225 steps/s (collection: 0.976s, learning 0.126s)
               Value function loss: 0.5549
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8718
                     Learning rate: 0.0006
                       Mean reward: 129.58
               Mean episode length: 971.23
       Episode_Reward/keep_balance: 0.9725
     Episode_Reward/rew_lin_vel_xy: 6.1318
      Episode_Reward/rew_ang_vel_z: 2.4313
    Episode_Reward/pen_base_height: -0.3182
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1588
   Episode_Reward/pen_joint_torque: -0.2336
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0897
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2567
Episode_Reward/pen_flat_orientation: -0.0918
  Episode_Reward/pen_feet_distance: -0.0224
Episode_Reward/pen_feet_regulation: -0.4839
   Episode_Reward/foot_landing_vel: -0.1444
   Episode_Reward/test_gait_reward: -0.9241
Metrics/base_velocity/error_vel_xy: 0.9593
Metrics/base_velocity/error_vel_yaw: 1.3098
      Episode_Termination/time_out: 4.8333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 153944064
                    Iteration time: 1.10s
                        Total time: 1706.53s
                               ETA: 1563.8s

################################################################################
                     [1m Learning iteration 1566/3000 [0m                     

                       Computation: 90273 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.6457
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8702
                     Learning rate: 0.0013
                       Mean reward: 130.92
               Mean episode length: 965.96
       Episode_Reward/keep_balance: 0.9782
     Episode_Reward/rew_lin_vel_xy: 6.1616
      Episode_Reward/rew_ang_vel_z: 2.5048
    Episode_Reward/pen_base_height: -0.3283
      Episode_Reward/pen_lin_vel_z: -0.0353
     Episode_Reward/pen_ang_vel_xy: -0.1601
   Episode_Reward/pen_joint_torque: -0.2351
    Episode_Reward/pen_joint_accel: -0.1088
    Episode_Reward/pen_action_rate: -0.1192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2550
Episode_Reward/pen_flat_orientation: -0.0907
  Episode_Reward/pen_feet_distance: -0.0253
Episode_Reward/pen_feet_regulation: -0.4681
   Episode_Reward/foot_landing_vel: -0.1390
   Episode_Reward/test_gait_reward: -0.9368
Metrics/base_velocity/error_vel_xy: 0.9666
Metrics/base_velocity/error_vel_yaw: 1.2653
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 154042368
                    Iteration time: 1.09s
                        Total time: 1707.62s
                               ETA: 1562.7s

################################################################################
                     [1m Learning iteration 1567/3000 [0m                     

                       Computation: 89078 steps/s (collection: 0.978s, learning 0.125s)
               Value function loss: 0.5463
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8683
                     Learning rate: 0.0006
                       Mean reward: 129.61
               Mean episode length: 959.81
       Episode_Reward/keep_balance: 0.9632
     Episode_Reward/rew_lin_vel_xy: 6.1190
      Episode_Reward/rew_ang_vel_z: 2.4307
    Episode_Reward/pen_base_height: -0.3190
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1625
   Episode_Reward/pen_joint_torque: -0.2307
    Episode_Reward/pen_joint_accel: -0.1095
    Episode_Reward/pen_action_rate: -0.1182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2553
Episode_Reward/pen_flat_orientation: -0.0935
  Episode_Reward/pen_feet_distance: -0.0209
Episode_Reward/pen_feet_regulation: -0.4579
   Episode_Reward/foot_landing_vel: -0.1297
   Episode_Reward/test_gait_reward: -0.9114
Metrics/base_velocity/error_vel_xy: 0.9233
Metrics/base_velocity/error_vel_yaw: 1.2835
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 154140672
                    Iteration time: 1.10s
                        Total time: 1708.72s
                               ETA: 1561.6s

################################################################################
                     [1m Learning iteration 1568/3000 [0m                     

                       Computation: 89404 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 0.5680
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8684
                     Learning rate: 0.0006
                       Mean reward: 133.84
               Mean episode length: 975.18
       Episode_Reward/keep_balance: 0.9705
     Episode_Reward/rew_lin_vel_xy: 6.1803
      Episode_Reward/rew_ang_vel_z: 2.5153
    Episode_Reward/pen_base_height: -0.3070
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1541
   Episode_Reward/pen_joint_torque: -0.2246
    Episode_Reward/pen_joint_accel: -0.1166
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0859
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2513
Episode_Reward/pen_flat_orientation: -0.0895
  Episode_Reward/pen_feet_distance: -0.0212
Episode_Reward/pen_feet_regulation: -0.4624
   Episode_Reward/foot_landing_vel: -0.1458
   Episode_Reward/test_gait_reward: -0.9176
Metrics/base_velocity/error_vel_xy: 0.9199
Metrics/base_velocity/error_vel_yaw: 1.2189
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 154238976
                    Iteration time: 1.10s
                        Total time: 1709.82s
                               ETA: 1560.5s

################################################################################
                     [1m Learning iteration 1569/3000 [0m                     

                       Computation: 90227 steps/s (collection: 0.965s, learning 0.125s)
               Value function loss: 0.5084
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8681
                     Learning rate: 0.0004
                       Mean reward: 132.79
               Mean episode length: 984.46
       Episode_Reward/keep_balance: 0.9875
     Episode_Reward/rew_lin_vel_xy: 6.2032
      Episode_Reward/rew_ang_vel_z: 2.5241
    Episode_Reward/pen_base_height: -0.3188
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1584
   Episode_Reward/pen_joint_torque: -0.2334
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2593
Episode_Reward/pen_flat_orientation: -0.0900
  Episode_Reward/pen_feet_distance: -0.0220
Episode_Reward/pen_feet_regulation: -0.4785
   Episode_Reward/foot_landing_vel: -0.1393
   Episode_Reward/test_gait_reward: -0.9424
Metrics/base_velocity/error_vel_xy: 0.9882
Metrics/base_velocity/error_vel_yaw: 1.2871
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 154337280
                    Iteration time: 1.09s
                        Total time: 1710.91s
                               ETA: 1559.4s

################################################################################
                     [1m Learning iteration 1570/3000 [0m                     

                       Computation: 90167 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.5275
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8646
                     Learning rate: 0.0004
                       Mean reward: 134.97
               Mean episode length: 986.78
       Episode_Reward/keep_balance: 0.9889
     Episode_Reward/rew_lin_vel_xy: 6.2947
      Episode_Reward/rew_ang_vel_z: 2.5488
    Episode_Reward/pen_base_height: -0.3137
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1616
   Episode_Reward/pen_joint_torque: -0.2325
    Episode_Reward/pen_joint_accel: -0.1117
    Episode_Reward/pen_action_rate: -0.1205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2574
Episode_Reward/pen_flat_orientation: -0.0876
  Episode_Reward/pen_feet_distance: -0.0180
Episode_Reward/pen_feet_regulation: -0.4742
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9357
Metrics/base_velocity/error_vel_xy: 0.9312
Metrics/base_velocity/error_vel_yaw: 1.2639
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 154435584
                    Iteration time: 1.09s
                        Total time: 1712.00s
                               ETA: 1558.3s

################################################################################
                     [1m Learning iteration 1571/3000 [0m                     

                       Computation: 88526 steps/s (collection: 0.983s, learning 0.127s)
               Value function loss: 0.4616
                    Surrogate loss: 0.0006
             Mean action noise std: 0.8640
                     Learning rate: 0.0001
                       Mean reward: 136.63
               Mean episode length: 994.54
       Episode_Reward/keep_balance: 0.9949
     Episode_Reward/rew_lin_vel_xy: 6.3256
      Episode_Reward/rew_ang_vel_z: 2.5605
    Episode_Reward/pen_base_height: -0.3088
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1605
   Episode_Reward/pen_joint_torque: -0.2389
    Episode_Reward/pen_joint_accel: -0.1110
    Episode_Reward/pen_action_rate: -0.1211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2599
Episode_Reward/pen_flat_orientation: -0.0898
  Episode_Reward/pen_feet_distance: -0.0208
Episode_Reward/pen_feet_regulation: -0.4526
   Episode_Reward/foot_landing_vel: -0.1426
   Episode_Reward/test_gait_reward: -0.9379
Metrics/base_velocity/error_vel_xy: 0.9404
Metrics/base_velocity/error_vel_yaw: 1.2756
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 154533888
                    Iteration time: 1.11s
                        Total time: 1713.11s
                               ETA: 1557.3s

################################################################################
                     [1m Learning iteration 1572/3000 [0m                     

                       Computation: 89083 steps/s (collection: 0.979s, learning 0.125s)
               Value function loss: 0.4913
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8641
                     Learning rate: 0.0003
                       Mean reward: 136.40
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.3384
      Episode_Reward/rew_ang_vel_z: 2.5778
    Episode_Reward/pen_base_height: -0.3107
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1614
   Episode_Reward/pen_joint_torque: -0.2302
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2590
Episode_Reward/pen_flat_orientation: -0.0879
  Episode_Reward/pen_feet_distance: -0.0246
Episode_Reward/pen_feet_regulation: -0.4699
   Episode_Reward/foot_landing_vel: -0.1480
   Episode_Reward/test_gait_reward: -0.9388
Metrics/base_velocity/error_vel_xy: 0.9565
Metrics/base_velocity/error_vel_yaw: 1.2752
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 154632192
                    Iteration time: 1.10s
                        Total time: 1714.21s
                               ETA: 1556.2s

################################################################################
                     [1m Learning iteration 1573/3000 [0m                     

                       Computation: 87684 steps/s (collection: 0.997s, learning 0.124s)
               Value function loss: 0.5762
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8640
                     Learning rate: 0.0004
                       Mean reward: 131.33
               Mean episode length: 991.36
       Episode_Reward/keep_balance: 0.9910
     Episode_Reward/rew_lin_vel_xy: 6.2440
      Episode_Reward/rew_ang_vel_z: 2.5172
    Episode_Reward/pen_base_height: -0.3301
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.1605
   Episode_Reward/pen_joint_torque: -0.2542
    Episode_Reward/pen_joint_accel: -0.1180
    Episode_Reward/pen_action_rate: -0.1240
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0617
   Episode_Reward/pen_joint_powers: -0.0953
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2622
Episode_Reward/pen_flat_orientation: -0.0931
  Episode_Reward/pen_feet_distance: -0.0230
Episode_Reward/pen_feet_regulation: -0.5108
   Episode_Reward/foot_landing_vel: -0.1558
   Episode_Reward/test_gait_reward: -0.9409
Metrics/base_velocity/error_vel_xy: 0.9841
Metrics/base_velocity/error_vel_yaw: 1.2895
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 154730496
                    Iteration time: 1.12s
                        Total time: 1715.33s
                               ETA: 1555.1s

################################################################################
                     [1m Learning iteration 1574/3000 [0m                     

                       Computation: 89892 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.5180
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8660
                     Learning rate: 0.0006
                       Mean reward: 133.74
               Mean episode length: 978.06
       Episode_Reward/keep_balance: 0.9823
     Episode_Reward/rew_lin_vel_xy: 6.2303
      Episode_Reward/rew_ang_vel_z: 2.5218
    Episode_Reward/pen_base_height: -0.3187
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1559
   Episode_Reward/pen_joint_torque: -0.2375
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2550
Episode_Reward/pen_flat_orientation: -0.0908
  Episode_Reward/pen_feet_distance: -0.0161
Episode_Reward/pen_feet_regulation: -0.4619
   Episode_Reward/foot_landing_vel: -0.1399
   Episode_Reward/test_gait_reward: -0.9228
Metrics/base_velocity/error_vel_xy: 0.9466
Metrics/base_velocity/error_vel_yaw: 1.2622
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 154828800
                    Iteration time: 1.09s
                        Total time: 1716.43s
                               ETA: 1554.0s

################################################################################
                     [1m Learning iteration 1575/3000 [0m                     

                       Computation: 89735 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 0.5233
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8657
                     Learning rate: 0.0001
                       Mean reward: 130.12
               Mean episode length: 970.54
       Episode_Reward/keep_balance: 0.9555
     Episode_Reward/rew_lin_vel_xy: 5.9513
      Episode_Reward/rew_ang_vel_z: 2.4063
    Episode_Reward/pen_base_height: -0.3035
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.1615
   Episode_Reward/pen_joint_torque: -0.2328
    Episode_Reward/pen_joint_accel: -0.1110
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2570
Episode_Reward/pen_flat_orientation: -0.0969
  Episode_Reward/pen_feet_distance: -0.0191
Episode_Reward/pen_feet_regulation: -0.4753
   Episode_Reward/foot_landing_vel: -0.1333
   Episode_Reward/test_gait_reward: -0.9144
Metrics/base_velocity/error_vel_xy: 0.9840
Metrics/base_velocity/error_vel_yaw: 1.2903
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 154927104
                    Iteration time: 1.10s
                        Total time: 1717.52s
                               ETA: 1553.0s

################################################################################
                     [1m Learning iteration 1576/3000 [0m                     

                       Computation: 89444 steps/s (collection: 0.972s, learning 0.127s)
               Value function loss: 0.5169
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8647
                     Learning rate: 0.0004
                       Mean reward: 136.02
               Mean episode length: 985.73
       Episode_Reward/keep_balance: 0.9904
     Episode_Reward/rew_lin_vel_xy: 6.3039
      Episode_Reward/rew_ang_vel_z: 2.5527
    Episode_Reward/pen_base_height: -0.2962
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1561
   Episode_Reward/pen_joint_torque: -0.2231
    Episode_Reward/pen_joint_accel: -0.1200
    Episode_Reward/pen_action_rate: -0.1187
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2558
Episode_Reward/pen_flat_orientation: -0.0880
  Episode_Reward/pen_feet_distance: -0.0231
Episode_Reward/pen_feet_regulation: -0.4745
   Episode_Reward/foot_landing_vel: -0.1475
   Episode_Reward/test_gait_reward: -0.9393
Metrics/base_velocity/error_vel_xy: 0.9464
Metrics/base_velocity/error_vel_yaw: 1.2559
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 155025408
                    Iteration time: 1.10s
                        Total time: 1718.62s
                               ETA: 1551.9s

################################################################################
                     [1m Learning iteration 1577/3000 [0m                     

                       Computation: 89355 steps/s (collection: 0.975s, learning 0.125s)
               Value function loss: 0.5813
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8644
                     Learning rate: 0.0004
                       Mean reward: 138.75
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.3738
      Episode_Reward/rew_ang_vel_z: 2.5723
    Episode_Reward/pen_base_height: -0.3110
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1660
   Episode_Reward/pen_joint_torque: -0.2302
    Episode_Reward/pen_joint_accel: -0.1125
    Episode_Reward/pen_action_rate: -0.1205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2611
Episode_Reward/pen_flat_orientation: -0.0897
  Episode_Reward/pen_feet_distance: -0.0221
Episode_Reward/pen_feet_regulation: -0.4715
   Episode_Reward/foot_landing_vel: -0.1289
   Episode_Reward/test_gait_reward: -0.9439
Metrics/base_velocity/error_vel_xy: 0.9456
Metrics/base_velocity/error_vel_yaw: 1.2785
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 155123712
                    Iteration time: 1.10s
                        Total time: 1719.72s
                               ETA: 1550.8s

################################################################################
                     [1m Learning iteration 1578/3000 [0m                     

                       Computation: 89228 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.5958
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8628
                     Learning rate: 0.0003
                       Mean reward: 132.48
               Mean episode length: 975.64
       Episode_Reward/keep_balance: 0.9709
     Episode_Reward/rew_lin_vel_xy: 6.1810
      Episode_Reward/rew_ang_vel_z: 2.4417
    Episode_Reward/pen_base_height: -0.3224
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.1571
   Episode_Reward/pen_joint_torque: -0.2307
    Episode_Reward/pen_joint_accel: -0.1117
    Episode_Reward/pen_action_rate: -0.1211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2572
Episode_Reward/pen_flat_orientation: -0.0937
  Episode_Reward/pen_feet_distance: -0.0201
Episode_Reward/pen_feet_regulation: -0.4830
   Episode_Reward/foot_landing_vel: -0.1362
   Episode_Reward/test_gait_reward: -0.9262
Metrics/base_velocity/error_vel_xy: 0.9374
Metrics/base_velocity/error_vel_yaw: 1.3021
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 155222016
                    Iteration time: 1.10s
                        Total time: 1720.82s
                               ETA: 1549.7s

################################################################################
                     [1m Learning iteration 1579/3000 [0m                     

                       Computation: 90570 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.5290
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8621
                     Learning rate: 0.0004
                       Mean reward: 131.16
               Mean episode length: 978.80
       Episode_Reward/keep_balance: 0.9836
     Episode_Reward/rew_lin_vel_xy: 6.1791
      Episode_Reward/rew_ang_vel_z: 2.4535
    Episode_Reward/pen_base_height: -0.3253
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1656
   Episode_Reward/pen_joint_torque: -0.2386
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.1214
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0919
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2613
Episode_Reward/pen_flat_orientation: -0.0998
  Episode_Reward/pen_feet_distance: -0.0206
Episode_Reward/pen_feet_regulation: -0.4821
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.9394
Metrics/base_velocity/error_vel_xy: 0.9753
Metrics/base_velocity/error_vel_yaw: 1.3308
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 155320320
                    Iteration time: 1.09s
                        Total time: 1721.91s
                               ETA: 1548.6s

################################################################################
                     [1m Learning iteration 1580/3000 [0m                     

                       Computation: 89514 steps/s (collection: 0.976s, learning 0.122s)
               Value function loss: 0.6093
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8626
                     Learning rate: 0.0003
                       Mean reward: 137.03
               Mean episode length: 980.51
       Episode_Reward/keep_balance: 0.9874
     Episode_Reward/rew_lin_vel_xy: 6.3554
      Episode_Reward/rew_ang_vel_z: 2.5486
    Episode_Reward/pen_base_height: -0.2907
      Episode_Reward/pen_lin_vel_z: -0.0336
     Episode_Reward/pen_ang_vel_xy: -0.1562
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1039
    Episode_Reward/pen_action_rate: -0.1180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2552
Episode_Reward/pen_flat_orientation: -0.0859
  Episode_Reward/pen_feet_distance: -0.0185
Episode_Reward/pen_feet_regulation: -0.4338
   Episode_Reward/foot_landing_vel: -0.1292
   Episode_Reward/test_gait_reward: -0.9184
Metrics/base_velocity/error_vel_xy: 0.8921
Metrics/base_velocity/error_vel_yaw: 1.2493
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 155418624
                    Iteration time: 1.10s
                        Total time: 1723.01s
                               ETA: 1547.5s

################################################################################
                     [1m Learning iteration 1581/3000 [0m                     

                       Computation: 89199 steps/s (collection: 0.978s, learning 0.124s)
               Value function loss: 0.6279
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8622
                     Learning rate: 0.0004
                       Mean reward: 135.76
               Mean episode length: 989.04
       Episode_Reward/keep_balance: 0.9976
     Episode_Reward/rew_lin_vel_xy: 6.3200
      Episode_Reward/rew_ang_vel_z: 2.5640
    Episode_Reward/pen_base_height: -0.2879
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1612
   Episode_Reward/pen_joint_torque: -0.2260
    Episode_Reward/pen_joint_accel: -0.1159
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2604
Episode_Reward/pen_flat_orientation: -0.0900
  Episode_Reward/pen_feet_distance: -0.0214
Episode_Reward/pen_feet_regulation: -0.4561
   Episode_Reward/foot_landing_vel: -0.1596
   Episode_Reward/test_gait_reward: -0.9309
Metrics/base_velocity/error_vel_xy: 0.9542
Metrics/base_velocity/error_vel_yaw: 1.2717
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 155516928
                    Iteration time: 1.10s
                        Total time: 1724.11s
                               ETA: 1546.5s

################################################################################
                     [1m Learning iteration 1582/3000 [0m                     

                       Computation: 90117 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.5711
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8620
                     Learning rate: 0.0006
                       Mean reward: 129.35
               Mean episode length: 956.26
       Episode_Reward/keep_balance: 0.9528
     Episode_Reward/rew_lin_vel_xy: 6.0063
      Episode_Reward/rew_ang_vel_z: 2.4164
    Episode_Reward/pen_base_height: -0.3017
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1554
   Episode_Reward/pen_joint_torque: -0.2272
    Episode_Reward/pen_joint_accel: -0.1138
    Episode_Reward/pen_action_rate: -0.1176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2529
Episode_Reward/pen_flat_orientation: -0.0964
  Episode_Reward/pen_feet_distance: -0.0214
Episode_Reward/pen_feet_regulation: -0.4652
   Episode_Reward/foot_landing_vel: -0.1333
   Episode_Reward/test_gait_reward: -0.9019
Metrics/base_velocity/error_vel_xy: 0.9361
Metrics/base_velocity/error_vel_yaw: 1.2621
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 155615232
                    Iteration time: 1.09s
                        Total time: 1725.20s
                               ETA: 1545.4s

################################################################################
                     [1m Learning iteration 1583/3000 [0m                     

                       Computation: 90828 steps/s (collection: 0.957s, learning 0.126s)
               Value function loss: 0.5444
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8613
                     Learning rate: 0.0006
                       Mean reward: 135.39
               Mean episode length: 983.19
       Episode_Reward/keep_balance: 0.9799
     Episode_Reward/rew_lin_vel_xy: 6.2161
      Episode_Reward/rew_ang_vel_z: 2.5106
    Episode_Reward/pen_base_height: -0.3195
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1606
   Episode_Reward/pen_joint_torque: -0.2302
    Episode_Reward/pen_joint_accel: -0.1132
    Episode_Reward/pen_action_rate: -0.1198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2571
Episode_Reward/pen_flat_orientation: -0.0980
  Episode_Reward/pen_feet_distance: -0.0206
Episode_Reward/pen_feet_regulation: -0.4780
   Episode_Reward/foot_landing_vel: -0.1293
   Episode_Reward/test_gait_reward: -0.9283
Metrics/base_velocity/error_vel_xy: 0.9424
Metrics/base_velocity/error_vel_yaw: 1.2680
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 155713536
                    Iteration time: 1.08s
                        Total time: 1726.28s
                               ETA: 1544.3s

################################################################################
                     [1m Learning iteration 1584/3000 [0m                     

                       Computation: 84782 steps/s (collection: 1.036s, learning 0.123s)
               Value function loss: 0.5487
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8608
                     Learning rate: 0.0009
                       Mean reward: 130.42
               Mean episode length: 988.04
       Episode_Reward/keep_balance: 0.9951
     Episode_Reward/rew_lin_vel_xy: 6.1905
      Episode_Reward/rew_ang_vel_z: 2.5300
    Episode_Reward/pen_base_height: -0.3175
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1683
   Episode_Reward/pen_joint_torque: -0.2347
    Episode_Reward/pen_joint_accel: -0.1092
    Episode_Reward/pen_action_rate: -0.1235
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0611
   Episode_Reward/pen_joint_powers: -0.0922
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2642
Episode_Reward/pen_flat_orientation: -0.0959
  Episode_Reward/pen_feet_distance: -0.0179
Episode_Reward/pen_feet_regulation: -0.4989
   Episode_Reward/foot_landing_vel: -0.1466
   Episode_Reward/test_gait_reward: -0.9463
Metrics/base_velocity/error_vel_xy: 1.0131
Metrics/base_velocity/error_vel_yaw: 1.2978
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 155811840
                    Iteration time: 1.16s
                        Total time: 1727.44s
                               ETA: 1543.3s

################################################################################
                     [1m Learning iteration 1585/3000 [0m                     

                       Computation: 88359 steps/s (collection: 0.986s, learning 0.126s)
               Value function loss: 0.5034
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8607
                     Learning rate: 0.0009
                       Mean reward: 129.31
               Mean episode length: 966.69
       Episode_Reward/keep_balance: 0.9287
     Episode_Reward/rew_lin_vel_xy: 5.8018
      Episode_Reward/rew_ang_vel_z: 2.3021
    Episode_Reward/pen_base_height: -0.2964
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1607
   Episode_Reward/pen_joint_torque: -0.2205
    Episode_Reward/pen_joint_accel: -0.1150
    Episode_Reward/pen_action_rate: -0.1153
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0857
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2480
Episode_Reward/pen_flat_orientation: -0.0951
  Episode_Reward/pen_feet_distance: -0.0159
Episode_Reward/pen_feet_regulation: -0.4513
   Episode_Reward/foot_landing_vel: -0.1431
   Episode_Reward/test_gait_reward: -0.8834
Metrics/base_velocity/error_vel_xy: 0.9352
Metrics/base_velocity/error_vel_yaw: 1.2825
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 155910144
                    Iteration time: 1.11s
                        Total time: 1728.56s
                               ETA: 1542.2s

################################################################################
                     [1m Learning iteration 1586/3000 [0m                     

                       Computation: 90344 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.5458
                    Surrogate loss: -0.0014
             Mean action noise std: 0.8612
                     Learning rate: 0.0004
                       Mean reward: 133.83
               Mean episode length: 975.75
       Episode_Reward/keep_balance: 0.9781
     Episode_Reward/rew_lin_vel_xy: 6.2220
      Episode_Reward/rew_ang_vel_z: 2.5034
    Episode_Reward/pen_base_height: -0.3027
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1564
   Episode_Reward/pen_joint_torque: -0.2295
    Episode_Reward/pen_joint_accel: -0.1161
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2548
Episode_Reward/pen_flat_orientation: -0.0891
  Episode_Reward/pen_feet_distance: -0.0157
Episode_Reward/pen_feet_regulation: -0.4621
   Episode_Reward/foot_landing_vel: -0.1418
   Episode_Reward/test_gait_reward: -0.9177
Metrics/base_velocity/error_vel_xy: 0.9366
Metrics/base_velocity/error_vel_yaw: 1.2687
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 156008448
                    Iteration time: 1.09s
                        Total time: 1729.64s
                               ETA: 1541.1s

################################################################################
                     [1m Learning iteration 1587/3000 [0m                     

                       Computation: 91621 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.5447
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8619
                     Learning rate: 0.0006
                       Mean reward: 133.92
               Mean episode length: 987.28
       Episode_Reward/keep_balance: 0.9855
     Episode_Reward/rew_lin_vel_xy: 6.2413
      Episode_Reward/rew_ang_vel_z: 2.4916
    Episode_Reward/pen_base_height: -0.3076
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1676
   Episode_Reward/pen_joint_torque: -0.2338
    Episode_Reward/pen_joint_accel: -0.1088
    Episode_Reward/pen_action_rate: -0.1222
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2603
Episode_Reward/pen_flat_orientation: -0.0942
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4760
   Episode_Reward/foot_landing_vel: -0.1419
   Episode_Reward/test_gait_reward: -0.9352
Metrics/base_velocity/error_vel_xy: 0.9559
Metrics/base_velocity/error_vel_yaw: 1.3032
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 156106752
                    Iteration time: 1.07s
                        Total time: 1730.72s
                               ETA: 1540.0s

################################################################################
                     [1m Learning iteration 1588/3000 [0m                     

                       Computation: 89069 steps/s (collection: 0.981s, learning 0.123s)
               Value function loss: 0.5494
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8631
                     Learning rate: 0.0006
                       Mean reward: 130.92
               Mean episode length: 986.68
       Episode_Reward/keep_balance: 0.9852
     Episode_Reward/rew_lin_vel_xy: 6.2227
      Episode_Reward/rew_ang_vel_z: 2.4866
    Episode_Reward/pen_base_height: -0.3173
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1610
   Episode_Reward/pen_joint_torque: -0.2379
    Episode_Reward/pen_joint_accel: -0.1231
    Episode_Reward/pen_action_rate: -0.1229
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0600
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2624
Episode_Reward/pen_flat_orientation: -0.0964
  Episode_Reward/pen_feet_distance: -0.0193
Episode_Reward/pen_feet_regulation: -0.4868
   Episode_Reward/foot_landing_vel: -0.1406
   Episode_Reward/test_gait_reward: -0.9278
Metrics/base_velocity/error_vel_xy: 0.9621
Metrics/base_velocity/error_vel_yaw: 1.3107
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 156205056
                    Iteration time: 1.10s
                        Total time: 1731.82s
                               ETA: 1538.9s

################################################################################
                     [1m Learning iteration 1589/3000 [0m                     

                       Computation: 91482 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.5004
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8643
                     Learning rate: 0.0006
                       Mean reward: 134.94
               Mean episode length: 988.05
       Episode_Reward/keep_balance: 0.9781
     Episode_Reward/rew_lin_vel_xy: 6.1770
      Episode_Reward/rew_ang_vel_z: 2.4741
    Episode_Reward/pen_base_height: -0.3116
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.1621
   Episode_Reward/pen_joint_torque: -0.2263
    Episode_Reward/pen_joint_accel: -0.1121
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2563
Episode_Reward/pen_flat_orientation: -0.0968
  Episode_Reward/pen_feet_distance: -0.0161
Episode_Reward/pen_feet_regulation: -0.4620
   Episode_Reward/foot_landing_vel: -0.1299
   Episode_Reward/test_gait_reward: -0.9272
Metrics/base_velocity/error_vel_xy: 0.9465
Metrics/base_velocity/error_vel_yaw: 1.3071
      Episode_Termination/time_out: 5.1250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 156303360
                    Iteration time: 1.07s
                        Total time: 1732.89s
                               ETA: 1537.8s

################################################################################
                     [1m Learning iteration 1590/3000 [0m                     

                       Computation: 90672 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.5046
                    Surrogate loss: 0.0012
             Mean action noise std: 0.8645
                     Learning rate: 0.0001
                       Mean reward: 135.36
               Mean episode length: 992.50
       Episode_Reward/keep_balance: 0.9952
     Episode_Reward/rew_lin_vel_xy: 6.3347
      Episode_Reward/rew_ang_vel_z: 2.5114
    Episode_Reward/pen_base_height: -0.3167
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1623
   Episode_Reward/pen_joint_torque: -0.2474
    Episode_Reward/pen_joint_accel: -0.1137
    Episode_Reward/pen_action_rate: -0.1228
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0591
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2625
Episode_Reward/pen_flat_orientation: -0.0944
  Episode_Reward/pen_feet_distance: -0.0192
Episode_Reward/pen_feet_regulation: -0.4655
   Episode_Reward/foot_landing_vel: -0.1407
   Episode_Reward/test_gait_reward: -0.9331
Metrics/base_velocity/error_vel_xy: 0.9412
Metrics/base_velocity/error_vel_yaw: 1.3220
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 156401664
                    Iteration time: 1.08s
                        Total time: 1733.98s
                               ETA: 1536.7s

################################################################################
                     [1m Learning iteration 1591/3000 [0m                     

                       Computation: 90636 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.5050
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8632
                     Learning rate: 0.0003
                       Mean reward: 135.85
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.3280
      Episode_Reward/rew_ang_vel_z: 2.5426
    Episode_Reward/pen_base_height: -0.3011
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1630
   Episode_Reward/pen_joint_torque: -0.2360
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1236
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2648
Episode_Reward/pen_flat_orientation: -0.0893
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4797
   Episode_Reward/foot_landing_vel: -0.1606
   Episode_Reward/test_gait_reward: -0.9444
Metrics/base_velocity/error_vel_xy: 0.9595
Metrics/base_velocity/error_vel_yaw: 1.3015
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 156499968
                    Iteration time: 1.08s
                        Total time: 1735.06s
                               ETA: 1535.6s

################################################################################
                     [1m Learning iteration 1592/3000 [0m                     

                       Computation: 90468 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.5091
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8629
                     Learning rate: 0.0003
                       Mean reward: 133.22
               Mean episode length: 978.53
       Episode_Reward/keep_balance: 0.9818
     Episode_Reward/rew_lin_vel_xy: 6.0960
      Episode_Reward/rew_ang_vel_z: 2.5251
    Episode_Reward/pen_base_height: -0.3161
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1568
   Episode_Reward/pen_joint_torque: -0.2353
    Episode_Reward/pen_joint_accel: -0.1013
    Episode_Reward/pen_action_rate: -0.1189
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2537
Episode_Reward/pen_flat_orientation: -0.0902
  Episode_Reward/pen_feet_distance: -0.0216
Episode_Reward/pen_feet_regulation: -0.4631
   Episode_Reward/foot_landing_vel: -0.1322
   Episode_Reward/test_gait_reward: -0.9183
Metrics/base_velocity/error_vel_xy: 0.9826
Metrics/base_velocity/error_vel_yaw: 1.2541
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 156598272
                    Iteration time: 1.09s
                        Total time: 1736.15s
                               ETA: 1534.5s

################################################################################
                     [1m Learning iteration 1593/3000 [0m                     

                       Computation: 89698 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 0.5528
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8635
                     Learning rate: 0.0006
                       Mean reward: 134.01
               Mean episode length: 980.80
       Episode_Reward/keep_balance: 0.9834
     Episode_Reward/rew_lin_vel_xy: 6.2692
      Episode_Reward/rew_ang_vel_z: 2.4869
    Episode_Reward/pen_base_height: -0.3076
      Episode_Reward/pen_lin_vel_z: -0.0353
     Episode_Reward/pen_ang_vel_xy: -0.1614
   Episode_Reward/pen_joint_torque: -0.2403
    Episode_Reward/pen_joint_accel: -0.1098
    Episode_Reward/pen_action_rate: -0.1207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0891
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2575
Episode_Reward/pen_flat_orientation: -0.0962
  Episode_Reward/pen_feet_distance: -0.0192
Episode_Reward/pen_feet_regulation: -0.4661
   Episode_Reward/foot_landing_vel: -0.1373
   Episode_Reward/test_gait_reward: -0.9247
Metrics/base_velocity/error_vel_xy: 0.9341
Metrics/base_velocity/error_vel_yaw: 1.2945
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 156696576
                    Iteration time: 1.10s
                        Total time: 1737.25s
                               ETA: 1533.4s

################################################################################
                     [1m Learning iteration 1594/3000 [0m                     

                       Computation: 86998 steps/s (collection: 1.004s, learning 0.126s)
               Value function loss: 0.5547
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8637
                     Learning rate: 0.0006
                       Mean reward: 135.12
               Mean episode length: 983.35
       Episode_Reward/keep_balance: 0.9902
     Episode_Reward/rew_lin_vel_xy: 6.2911
      Episode_Reward/rew_ang_vel_z: 2.5510
    Episode_Reward/pen_base_height: -0.3009
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.1554
   Episode_Reward/pen_joint_torque: -0.2356
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2572
Episode_Reward/pen_flat_orientation: -0.0931
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4660
   Episode_Reward/foot_landing_vel: -0.1330
   Episode_Reward/test_gait_reward: -0.9319
Metrics/base_velocity/error_vel_xy: 0.9315
Metrics/base_velocity/error_vel_yaw: 1.2673
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 156794880
                    Iteration time: 1.13s
                        Total time: 1738.38s
                               ETA: 1532.4s

################################################################################
                     [1m Learning iteration 1595/3000 [0m                     

                       Computation: 85398 steps/s (collection: 1.023s, learning 0.128s)
               Value function loss: 0.5151
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8638
                     Learning rate: 0.0003
                       Mean reward: 131.54
               Mean episode length: 977.90
       Episode_Reward/keep_balance: 0.9749
     Episode_Reward/rew_lin_vel_xy: 6.1756
      Episode_Reward/rew_ang_vel_z: 2.4755
    Episode_Reward/pen_base_height: -0.2999
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1572
   Episode_Reward/pen_joint_torque: -0.2264
    Episode_Reward/pen_joint_accel: -0.1106
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2559
Episode_Reward/pen_flat_orientation: -0.0917
  Episode_Reward/pen_feet_distance: -0.0210
Episode_Reward/pen_feet_regulation: -0.4816
   Episode_Reward/foot_landing_vel: -0.1358
   Episode_Reward/test_gait_reward: -0.9277
Metrics/base_velocity/error_vel_xy: 0.9333
Metrics/base_velocity/error_vel_yaw: 1.2775
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 156893184
                    Iteration time: 1.15s
                        Total time: 1739.53s
                               ETA: 1531.4s

################################################################################
                     [1m Learning iteration 1596/3000 [0m                     

                       Computation: 85203 steps/s (collection: 1.023s, learning 0.131s)
               Value function loss: 0.5527
                    Surrogate loss: 0.0008
             Mean action noise std: 0.8638
                     Learning rate: 0.0001
                       Mean reward: 133.84
               Mean episode length: 981.13
       Episode_Reward/keep_balance: 0.9844
     Episode_Reward/rew_lin_vel_xy: 6.2328
      Episode_Reward/rew_ang_vel_z: 2.5151
    Episode_Reward/pen_base_height: -0.3014
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1561
   Episode_Reward/pen_joint_torque: -0.2368
    Episode_Reward/pen_joint_accel: -0.1213
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0586
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2571
Episode_Reward/pen_flat_orientation: -0.0982
  Episode_Reward/pen_feet_distance: -0.0169
Episode_Reward/pen_feet_regulation: -0.4759
   Episode_Reward/foot_landing_vel: -0.1327
   Episode_Reward/test_gait_reward: -0.9314
Metrics/base_velocity/error_vel_xy: 0.9516
Metrics/base_velocity/error_vel_yaw: 1.2685
      Episode_Termination/time_out: 3.0000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 156991488
                    Iteration time: 1.15s
                        Total time: 1740.68s
                               ETA: 1530.3s

################################################################################
                     [1m Learning iteration 1597/3000 [0m                     

                       Computation: 88159 steps/s (collection: 0.981s, learning 0.134s)
               Value function loss: 0.5632
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8640
                     Learning rate: 0.0002
                       Mean reward: 131.83
               Mean episode length: 974.49
       Episode_Reward/keep_balance: 0.9779
     Episode_Reward/rew_lin_vel_xy: 6.1841
      Episode_Reward/rew_ang_vel_z: 2.5093
    Episode_Reward/pen_base_height: -0.3117
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1634
   Episode_Reward/pen_joint_torque: -0.2433
    Episode_Reward/pen_joint_accel: -0.1118
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0598
   Episode_Reward/pen_joint_powers: -0.0919
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2591
Episode_Reward/pen_flat_orientation: -0.1024
  Episode_Reward/pen_feet_distance: -0.0191
Episode_Reward/pen_feet_regulation: -0.4849
   Episode_Reward/foot_landing_vel: -0.1432
   Episode_Reward/test_gait_reward: -0.9248
Metrics/base_velocity/error_vel_xy: 0.9576
Metrics/base_velocity/error_vel_yaw: 1.2609
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 157089792
                    Iteration time: 1.12s
                        Total time: 1741.80s
                               ETA: 1529.2s

################################################################################
                     [1m Learning iteration 1598/3000 [0m                     

                       Computation: 82592 steps/s (collection: 1.061s, learning 0.130s)
               Value function loss: 0.5661
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8639
                     Learning rate: 0.0003
                       Mean reward: 135.31
               Mean episode length: 990.99
       Episode_Reward/keep_balance: 0.9878
     Episode_Reward/rew_lin_vel_xy: 6.1838
      Episode_Reward/rew_ang_vel_z: 2.4743
    Episode_Reward/pen_base_height: -0.2859
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.1636
   Episode_Reward/pen_joint_torque: -0.2215
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.1208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2614
Episode_Reward/pen_flat_orientation: -0.0932
  Episode_Reward/pen_feet_distance: -0.0219
Episode_Reward/pen_feet_regulation: -0.4771
   Episode_Reward/foot_landing_vel: -0.1421
   Episode_Reward/test_gait_reward: -0.9237
Metrics/base_velocity/error_vel_xy: 0.9693
Metrics/base_velocity/error_vel_yaw: 1.3308
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 157188096
                    Iteration time: 1.19s
                        Total time: 1742.99s
                               ETA: 1528.2s

################################################################################
                     [1m Learning iteration 1599/3000 [0m                     

                       Computation: 89008 steps/s (collection: 0.981s, learning 0.123s)
               Value function loss: 0.5583
                    Surrogate loss: -0.0067
             Mean action noise std: 0.8633
                     Learning rate: 0.0006
                       Mean reward: 131.04
               Mean episode length: 969.89
       Episode_Reward/keep_balance: 0.9491
     Episode_Reward/rew_lin_vel_xy: 5.9854
      Episode_Reward/rew_ang_vel_z: 2.4021
    Episode_Reward/pen_base_height: -0.2888
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1587
   Episode_Reward/pen_joint_torque: -0.2183
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.1162
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2493
Episode_Reward/pen_flat_orientation: -0.0996
  Episode_Reward/pen_feet_distance: -0.0230
Episode_Reward/pen_feet_regulation: -0.4566
   Episode_Reward/foot_landing_vel: -0.1361
   Episode_Reward/test_gait_reward: -0.8938
Metrics/base_velocity/error_vel_xy: 0.9203
Metrics/base_velocity/error_vel_yaw: 1.2607
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 157286400
                    Iteration time: 1.10s
                        Total time: 1744.09s
                               ETA: 1527.2s

################################################################################
                     [1m Learning iteration 1600/3000 [0m                     

                       Computation: 88223 steps/s (collection: 0.988s, learning 0.126s)
               Value function loss: 0.5627
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8656
                     Learning rate: 0.0006
                       Mean reward: 135.33
               Mean episode length: 987.14
       Episode_Reward/keep_balance: 0.9894
     Episode_Reward/rew_lin_vel_xy: 6.2603
      Episode_Reward/rew_ang_vel_z: 2.5279
    Episode_Reward/pen_base_height: -0.2930
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1604
   Episode_Reward/pen_joint_torque: -0.2267
    Episode_Reward/pen_joint_accel: -0.1100
    Episode_Reward/pen_action_rate: -0.1199
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2588
Episode_Reward/pen_flat_orientation: -0.0969
  Episode_Reward/pen_feet_distance: -0.0183
Episode_Reward/pen_feet_regulation: -0.4688
   Episode_Reward/foot_landing_vel: -0.1337
   Episode_Reward/test_gait_reward: -0.9327
Metrics/base_velocity/error_vel_xy: 0.9619
Metrics/base_velocity/error_vel_yaw: 1.2802
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 157384704
                    Iteration time: 1.11s
                        Total time: 1745.20s
                               ETA: 1526.1s

################################################################################
                     [1m Learning iteration 1601/3000 [0m                     

                       Computation: 90142 steps/s (collection: 0.969s, learning 0.121s)
               Value function loss: 0.6050
                    Surrogate loss: -0.0006
             Mean action noise std: 0.8658
                     Learning rate: 0.0002
                       Mean reward: 134.12
               Mean episode length: 967.07
       Episode_Reward/keep_balance: 0.9774
     Episode_Reward/rew_lin_vel_xy: 6.2631
      Episode_Reward/rew_ang_vel_z: 2.5160
    Episode_Reward/pen_base_height: -0.2972
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1579
   Episode_Reward/pen_joint_torque: -0.2307
    Episode_Reward/pen_joint_accel: -0.1032
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0556
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2518
Episode_Reward/pen_flat_orientation: -0.0915
  Episode_Reward/pen_feet_distance: -0.0184
Episode_Reward/pen_feet_regulation: -0.4361
   Episode_Reward/foot_landing_vel: -0.1347
   Episode_Reward/test_gait_reward: -0.9168
Metrics/base_velocity/error_vel_xy: 0.9101
Metrics/base_velocity/error_vel_yaw: 1.2547
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 157483008
                    Iteration time: 1.09s
                        Total time: 1746.30s
                               ETA: 1525.0s

################################################################################
                     [1m Learning iteration 1602/3000 [0m                     

                       Computation: 90197 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.5789
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8650
                     Learning rate: 0.0004
                       Mean reward: 133.13
               Mean episode length: 965.92
       Episode_Reward/keep_balance: 0.9673
     Episode_Reward/rew_lin_vel_xy: 6.1443
      Episode_Reward/rew_ang_vel_z: 2.4861
    Episode_Reward/pen_base_height: -0.2976
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1557
   Episode_Reward/pen_joint_torque: -0.2330
    Episode_Reward/pen_joint_accel: -0.1187
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2517
Episode_Reward/pen_flat_orientation: -0.0955
  Episode_Reward/pen_feet_distance: -0.0176
Episode_Reward/pen_feet_regulation: -0.4520
   Episode_Reward/foot_landing_vel: -0.1399
   Episode_Reward/test_gait_reward: -0.9070
Metrics/base_velocity/error_vel_xy: 0.9138
Metrics/base_velocity/error_vel_yaw: 1.2445
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 157581312
                    Iteration time: 1.09s
                        Total time: 1747.39s
                               ETA: 1523.9s

################################################################################
                     [1m Learning iteration 1603/3000 [0m                     

                       Computation: 89827 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 0.5636
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8652
                     Learning rate: 0.0004
                       Mean reward: 136.79
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.2999
      Episode_Reward/rew_ang_vel_z: 2.5387
    Episode_Reward/pen_base_height: -0.2895
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1654
   Episode_Reward/pen_joint_torque: -0.2248
    Episode_Reward/pen_joint_accel: -0.1224
    Episode_Reward/pen_action_rate: -0.1198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2607
Episode_Reward/pen_flat_orientation: -0.0973
  Episode_Reward/pen_feet_distance: -0.0214
Episode_Reward/pen_feet_regulation: -0.4776
   Episode_Reward/foot_landing_vel: -0.1463
   Episode_Reward/test_gait_reward: -0.9383
Metrics/base_velocity/error_vel_xy: 0.9726
Metrics/base_velocity/error_vel_yaw: 1.3069
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 157679616
                    Iteration time: 1.09s
                        Total time: 1748.48s
                               ETA: 1522.8s

################################################################################
                     [1m Learning iteration 1604/3000 [0m                     

                       Computation: 91212 steps/s (collection: 0.956s, learning 0.121s)
               Value function loss: 0.6374
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8637
                     Learning rate: 0.0009
                       Mean reward: 132.00
               Mean episode length: 973.05
       Episode_Reward/keep_balance: 0.9677
     Episode_Reward/rew_lin_vel_xy: 6.0830
      Episode_Reward/rew_ang_vel_z: 2.4664
    Episode_Reward/pen_base_height: -0.3138
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1581
   Episode_Reward/pen_joint_torque: -0.2356
    Episode_Reward/pen_joint_accel: -0.1106
    Episode_Reward/pen_action_rate: -0.1180
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2515
Episode_Reward/pen_flat_orientation: -0.1012
  Episode_Reward/pen_feet_distance: -0.0204
Episode_Reward/pen_feet_regulation: -0.4520
   Episode_Reward/foot_landing_vel: -0.1323
   Episode_Reward/test_gait_reward: -0.9111
Metrics/base_velocity/error_vel_xy: 0.9568
Metrics/base_velocity/error_vel_yaw: 1.2683
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 157777920
                    Iteration time: 1.08s
                        Total time: 1749.56s
                               ETA: 1521.7s

################################################################################
                     [1m Learning iteration 1605/3000 [0m                     

                       Computation: 89849 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.5975
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8632
                     Learning rate: 0.0003
                       Mean reward: 136.42
               Mean episode length: 982.50
       Episode_Reward/keep_balance: 0.9792
     Episode_Reward/rew_lin_vel_xy: 6.2505
      Episode_Reward/rew_ang_vel_z: 2.5301
    Episode_Reward/pen_base_height: -0.3025
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1552
   Episode_Reward/pen_joint_torque: -0.2324
    Episode_Reward/pen_joint_accel: -0.1071
    Episode_Reward/pen_action_rate: -0.1172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2509
Episode_Reward/pen_flat_orientation: -0.1002
  Episode_Reward/pen_feet_distance: -0.0236
Episode_Reward/pen_feet_regulation: -0.4489
   Episode_Reward/foot_landing_vel: -0.1413
   Episode_Reward/test_gait_reward: -0.9273
Metrics/base_velocity/error_vel_xy: 0.9137
Metrics/base_velocity/error_vel_yaw: 1.2517
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 157876224
                    Iteration time: 1.09s
                        Total time: 1750.65s
                               ETA: 1520.6s

################################################################################
                     [1m Learning iteration 1606/3000 [0m                     

                       Computation: 90399 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.5908
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8634
                     Learning rate: 0.0006
                       Mean reward: 131.89
               Mean episode length: 963.96
       Episode_Reward/keep_balance: 0.9605
     Episode_Reward/rew_lin_vel_xy: 6.1223
      Episode_Reward/rew_ang_vel_z: 2.4131
    Episode_Reward/pen_base_height: -0.3030
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1602
   Episode_Reward/pen_joint_torque: -0.2208
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0846
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2510
Episode_Reward/pen_flat_orientation: -0.1087
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4624
   Episode_Reward/foot_landing_vel: -0.1312
   Episode_Reward/test_gait_reward: -0.9058
Metrics/base_velocity/error_vel_xy: 0.9127
Metrics/base_velocity/error_vel_yaw: 1.2944
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 157974528
                    Iteration time: 1.09s
                        Total time: 1751.74s
                               ETA: 1519.6s

################################################################################
                     [1m Learning iteration 1607/3000 [0m                     

                       Computation: 87925 steps/s (collection: 0.994s, learning 0.124s)
               Value function loss: 0.5890
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8636
                     Learning rate: 0.0006
                       Mean reward: 132.09
               Mean episode length: 977.35
       Episode_Reward/keep_balance: 0.9834
     Episode_Reward/rew_lin_vel_xy: 6.2216
      Episode_Reward/rew_ang_vel_z: 2.4922
    Episode_Reward/pen_base_height: -0.3238
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.1563
   Episode_Reward/pen_joint_torque: -0.2435
    Episode_Reward/pen_joint_accel: -0.1060
    Episode_Reward/pen_action_rate: -0.1202
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0896
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.2551
Episode_Reward/pen_flat_orientation: -0.1021
  Episode_Reward/pen_feet_distance: -0.0220
Episode_Reward/pen_feet_regulation: -0.4616
   Episode_Reward/foot_landing_vel: -0.1282
   Episode_Reward/test_gait_reward: -0.9295
Metrics/base_velocity/error_vel_xy: 0.9449
Metrics/base_velocity/error_vel_yaw: 1.2953
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 158072832
                    Iteration time: 1.12s
                        Total time: 1752.86s
                               ETA: 1518.5s

################################################################################
                     [1m Learning iteration 1608/3000 [0m                     

                       Computation: 90735 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.4736
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8641
                     Learning rate: 0.0004
                       Mean reward: 134.37
               Mean episode length: 975.80
       Episode_Reward/keep_balance: 0.9767
     Episode_Reward/rew_lin_vel_xy: 6.2105
      Episode_Reward/rew_ang_vel_z: 2.4765
    Episode_Reward/pen_base_height: -0.3115
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1613
   Episode_Reward/pen_joint_torque: -0.2344
    Episode_Reward/pen_joint_accel: -0.1057
    Episode_Reward/pen_action_rate: -0.1192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0556
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2539
Episode_Reward/pen_flat_orientation: -0.0952
  Episode_Reward/pen_feet_distance: -0.0233
Episode_Reward/pen_feet_regulation: -0.4621
   Episode_Reward/foot_landing_vel: -0.1293
   Episode_Reward/test_gait_reward: -0.9215
Metrics/base_velocity/error_vel_xy: 0.9309
Metrics/base_velocity/error_vel_yaw: 1.2879
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 158171136
                    Iteration time: 1.08s
                        Total time: 1753.94s
                               ETA: 1517.4s

################################################################################
                     [1m Learning iteration 1609/3000 [0m                     

                       Computation: 89763 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.5345
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8642
                     Learning rate: 0.0006
                       Mean reward: 136.89
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.3923
      Episode_Reward/rew_ang_vel_z: 2.5651
    Episode_Reward/pen_base_height: -0.3029
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1645
   Episode_Reward/pen_joint_torque: -0.2396
    Episode_Reward/pen_joint_accel: -0.1245
    Episode_Reward/pen_action_rate: -0.1219
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0908
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2619
Episode_Reward/pen_flat_orientation: -0.0946
  Episode_Reward/pen_feet_distance: -0.0232
Episode_Reward/pen_feet_regulation: -0.4804
   Episode_Reward/foot_landing_vel: -0.1381
   Episode_Reward/test_gait_reward: -0.9457
Metrics/base_velocity/error_vel_xy: 0.9341
Metrics/base_velocity/error_vel_yaw: 1.2867
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 158269440
                    Iteration time: 1.10s
                        Total time: 1755.04s
                               ETA: 1516.3s

################################################################################
                     [1m Learning iteration 1610/3000 [0m                     

                       Computation: 89520 steps/s (collection: 0.976s, learning 0.122s)
               Value function loss: 0.5315
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8637
                     Learning rate: 0.0004
                       Mean reward: 139.41
               Mean episode length: 998.81
       Episode_Reward/keep_balance: 0.9994
     Episode_Reward/rew_lin_vel_xy: 6.3866
      Episode_Reward/rew_ang_vel_z: 2.6259
    Episode_Reward/pen_base_height: -0.2974
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1568
   Episode_Reward/pen_joint_torque: -0.2310
    Episode_Reward/pen_joint_accel: -0.1158
    Episode_Reward/pen_action_rate: -0.1192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0863
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2535
Episode_Reward/pen_flat_orientation: -0.0940
  Episode_Reward/pen_feet_distance: -0.0214
Episode_Reward/pen_feet_regulation: -0.4649
   Episode_Reward/foot_landing_vel: -0.1369
   Episode_Reward/test_gait_reward: -0.9379
Metrics/base_velocity/error_vel_xy: 0.9328
Metrics/base_velocity/error_vel_yaw: 1.2348
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 158367744
                    Iteration time: 1.10s
                        Total time: 1756.13s
                               ETA: 1515.2s

################################################################################
                     [1m Learning iteration 1611/3000 [0m                     

                       Computation: 87948 steps/s (collection: 0.995s, learning 0.123s)
               Value function loss: 0.6077
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8639
                     Learning rate: 0.0004
                       Mean reward: 139.19
               Mean episode length: 994.83
       Episode_Reward/keep_balance: 0.9964
     Episode_Reward/rew_lin_vel_xy: 6.3638
      Episode_Reward/rew_ang_vel_z: 2.5850
    Episode_Reward/pen_base_height: -0.3041
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1581
   Episode_Reward/pen_joint_torque: -0.2338
    Episode_Reward/pen_joint_accel: -0.1063
    Episode_Reward/pen_action_rate: -0.1201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2543
Episode_Reward/pen_flat_orientation: -0.0973
  Episode_Reward/pen_feet_distance: -0.0233
Episode_Reward/pen_feet_regulation: -0.4754
   Episode_Reward/foot_landing_vel: -0.1291
   Episode_Reward/test_gait_reward: -0.9426
Metrics/base_velocity/error_vel_xy: 0.9271
Metrics/base_velocity/error_vel_yaw: 1.2530
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 158466048
                    Iteration time: 1.12s
                        Total time: 1757.25s
                               ETA: 1514.2s

################################################################################
                     [1m Learning iteration 1612/3000 [0m                     

                       Computation: 88916 steps/s (collection: 0.983s, learning 0.123s)
               Value function loss: 0.5735
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8648
                     Learning rate: 0.0006
                       Mean reward: 132.06
               Mean episode length: 962.22
       Episode_Reward/keep_balance: 0.9716
     Episode_Reward/rew_lin_vel_xy: 6.2025
      Episode_Reward/rew_ang_vel_z: 2.5146
    Episode_Reward/pen_base_height: -0.2996
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1569
   Episode_Reward/pen_joint_torque: -0.2310
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.1167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0855
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2499
Episode_Reward/pen_flat_orientation: -0.0970
  Episode_Reward/pen_feet_distance: -0.0197
Episode_Reward/pen_feet_regulation: -0.4448
   Episode_Reward/foot_landing_vel: -0.1249
   Episode_Reward/test_gait_reward: -0.9107
Metrics/base_velocity/error_vel_xy: 0.9150
Metrics/base_velocity/error_vel_yaw: 1.2400
      Episode_Termination/time_out: 4.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 158564352
                    Iteration time: 1.11s
                        Total time: 1758.36s
                               ETA: 1513.1s

################################################################################
                     [1m Learning iteration 1613/3000 [0m                     

                       Computation: 88315 steps/s (collection: 0.989s, learning 0.124s)
               Value function loss: 0.5454
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8645
                     Learning rate: 0.0009
                       Mean reward: 137.16
               Mean episode length: 984.00
       Episode_Reward/keep_balance: 0.9838
     Episode_Reward/rew_lin_vel_xy: 6.2708
      Episode_Reward/rew_ang_vel_z: 2.5452
    Episode_Reward/pen_base_height: -0.2948
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1606
   Episode_Reward/pen_joint_torque: -0.2385
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2560
Episode_Reward/pen_flat_orientation: -0.0922
  Episode_Reward/pen_feet_distance: -0.0214
Episode_Reward/pen_feet_regulation: -0.4518
   Episode_Reward/foot_landing_vel: -0.1378
   Episode_Reward/test_gait_reward: -0.9264
Metrics/base_velocity/error_vel_xy: 0.9197
Metrics/base_velocity/error_vel_yaw: 1.2498
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 158662656
                    Iteration time: 1.11s
                        Total time: 1759.47s
                               ETA: 1512.0s

################################################################################
                     [1m Learning iteration 1614/3000 [0m                     

                       Computation: 89782 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.6184
                    Surrogate loss: 0.0056
             Mean action noise std: 0.8636
                     Learning rate: 0.0000
                       Mean reward: 138.57
               Mean episode length: 991.68
       Episode_Reward/keep_balance: 0.9931
     Episode_Reward/rew_lin_vel_xy: 6.3164
      Episode_Reward/rew_ang_vel_z: 2.6040
    Episode_Reward/pen_base_height: -0.2924
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1575
   Episode_Reward/pen_joint_torque: -0.2345
    Episode_Reward/pen_joint_accel: -0.1053
    Episode_Reward/pen_action_rate: -0.1179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2514
Episode_Reward/pen_flat_orientation: -0.0953
  Episode_Reward/pen_feet_distance: -0.0257
Episode_Reward/pen_feet_regulation: -0.4547
   Episode_Reward/foot_landing_vel: -0.1395
   Episode_Reward/test_gait_reward: -0.9272
Metrics/base_velocity/error_vel_xy: 0.9516
Metrics/base_velocity/error_vel_yaw: 1.2289
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 158760960
                    Iteration time: 1.09s
                        Total time: 1760.56s
                               ETA: 1510.9s

################################################################################
                     [1m Learning iteration 1615/3000 [0m                     

                       Computation: 89211 steps/s (collection: 0.977s, learning 0.125s)
               Value function loss: 0.5487
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8628
                     Learning rate: 0.0002
                       Mean reward: 137.05
               Mean episode length: 991.57
       Episode_Reward/keep_balance: 0.9928
     Episode_Reward/rew_lin_vel_xy: 6.2946
      Episode_Reward/rew_ang_vel_z: 2.5852
    Episode_Reward/pen_base_height: -0.3230
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1583
   Episode_Reward/pen_joint_torque: -0.2522
    Episode_Reward/pen_joint_accel: -0.1137
    Episode_Reward/pen_action_rate: -0.1212
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0921
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2551
Episode_Reward/pen_flat_orientation: -0.0973
  Episode_Reward/pen_feet_distance: -0.0298
Episode_Reward/pen_feet_regulation: -0.4769
   Episode_Reward/foot_landing_vel: -0.1382
   Episode_Reward/test_gait_reward: -0.9335
Metrics/base_velocity/error_vel_xy: 0.9503
Metrics/base_velocity/error_vel_yaw: 1.2424
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 158859264
                    Iteration time: 1.10s
                        Total time: 1761.67s
                               ETA: 1509.8s

################################################################################
                     [1m Learning iteration 1616/3000 [0m                     

                       Computation: 88506 steps/s (collection: 0.988s, learning 0.122s)
               Value function loss: 0.5326
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8623
                     Learning rate: 0.0004
                       Mean reward: 132.41
               Mean episode length: 979.16
       Episode_Reward/keep_balance: 0.9831
     Episode_Reward/rew_lin_vel_xy: 6.1862
      Episode_Reward/rew_ang_vel_z: 2.5044
    Episode_Reward/pen_base_height: -0.2962
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1558
   Episode_Reward/pen_joint_torque: -0.2389
    Episode_Reward/pen_joint_accel: -0.1184
    Episode_Reward/pen_action_rate: -0.1207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0596
   Episode_Reward/pen_joint_powers: -0.0912
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2540
Episode_Reward/pen_flat_orientation: -0.1000
  Episode_Reward/pen_feet_distance: -0.0237
Episode_Reward/pen_feet_regulation: -0.4788
   Episode_Reward/foot_landing_vel: -0.1419
   Episode_Reward/test_gait_reward: -0.9273
Metrics/base_velocity/error_vel_xy: 0.9521
Metrics/base_velocity/error_vel_yaw: 1.2815
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 158957568
                    Iteration time: 1.11s
                        Total time: 1762.78s
                               ETA: 1508.8s

################################################################################
                     [1m Learning iteration 1617/3000 [0m                     

                       Computation: 89629 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.4881
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8630
                     Learning rate: 0.0004
                       Mean reward: 135.65
               Mean episode length: 988.34
       Episode_Reward/keep_balance: 0.9802
     Episode_Reward/rew_lin_vel_xy: 6.2472
      Episode_Reward/rew_ang_vel_z: 2.5347
    Episode_Reward/pen_base_height: -0.2890
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1607
   Episode_Reward/pen_joint_torque: -0.2336
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.1189
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0892
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2536
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0284
Episode_Reward/pen_feet_regulation: -0.4698
   Episode_Reward/foot_landing_vel: -0.1388
   Episode_Reward/test_gait_reward: -0.9222
Metrics/base_velocity/error_vel_xy: 0.9227
Metrics/base_velocity/error_vel_yaw: 1.2575
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 159055872
                    Iteration time: 1.10s
                        Total time: 1763.87s
                               ETA: 1507.7s

################################################################################
                     [1m Learning iteration 1618/3000 [0m                     

                       Computation: 89576 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.5634
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8637
                     Learning rate: 0.0006
                       Mean reward: 136.84
               Mean episode length: 990.29
       Episode_Reward/keep_balance: 0.9865
     Episode_Reward/rew_lin_vel_xy: 6.2993
      Episode_Reward/rew_ang_vel_z: 2.5622
    Episode_Reward/pen_base_height: -0.2810
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.1604
   Episode_Reward/pen_joint_torque: -0.2219
    Episode_Reward/pen_joint_accel: -0.1071
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2514
Episode_Reward/pen_flat_orientation: -0.0944
  Episode_Reward/pen_feet_distance: -0.0258
Episode_Reward/pen_feet_regulation: -0.4562
   Episode_Reward/foot_landing_vel: -0.1321
   Episode_Reward/test_gait_reward: -0.9180
Metrics/base_velocity/error_vel_xy: 0.9195
Metrics/base_velocity/error_vel_yaw: 1.2360
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 159154176
                    Iteration time: 1.10s
                        Total time: 1764.97s
                               ETA: 1506.6s

################################################################################
                     [1m Learning iteration 1619/3000 [0m                     

                       Computation: 89492 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.6006
                    Surrogate loss: -0.0003
             Mean action noise std: 0.8640
                     Learning rate: 0.0000
                       Mean reward: 133.85
               Mean episode length: 992.97
       Episode_Reward/keep_balance: 0.9937
     Episode_Reward/rew_lin_vel_xy: 6.2781
      Episode_Reward/rew_ang_vel_z: 2.5263
    Episode_Reward/pen_base_height: -0.3213
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1659
   Episode_Reward/pen_joint_torque: -0.2332
    Episode_Reward/pen_joint_accel: -0.1128
    Episode_Reward/pen_action_rate: -0.1207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0891
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2564
Episode_Reward/pen_flat_orientation: -0.1054
  Episode_Reward/pen_feet_distance: -0.0214
Episode_Reward/pen_feet_regulation: -0.4800
   Episode_Reward/foot_landing_vel: -0.1247
   Episode_Reward/test_gait_reward: -0.9404
Metrics/base_velocity/error_vel_xy: 0.9743
Metrics/base_velocity/error_vel_yaw: 1.3111
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 159252480
                    Iteration time: 1.10s
                        Total time: 1766.07s
                               ETA: 1505.5s

################################################################################
                     [1m Learning iteration 1620/3000 [0m                     

                       Computation: 88868 steps/s (collection: 0.983s, learning 0.123s)
               Value function loss: 0.5698
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8633
                     Learning rate: 0.0002
                       Mean reward: 134.30
               Mean episode length: 972.06
       Episode_Reward/keep_balance: 0.9726
     Episode_Reward/rew_lin_vel_xy: 6.2309
      Episode_Reward/rew_ang_vel_z: 2.5128
    Episode_Reward/pen_base_height: -0.2947
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1519
   Episode_Reward/pen_joint_torque: -0.2381
    Episode_Reward/pen_joint_accel: -0.1101
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2513
Episode_Reward/pen_flat_orientation: -0.0972
  Episode_Reward/pen_feet_distance: -0.0185
Episode_Reward/pen_feet_regulation: -0.4525
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.9148
Metrics/base_velocity/error_vel_xy: 0.9118
Metrics/base_velocity/error_vel_yaw: 1.2402
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 159350784
                    Iteration time: 1.11s
                        Total time: 1767.18s
                               ETA: 1504.4s

################################################################################
                     [1m Learning iteration 1621/3000 [0m                     

                       Computation: 91456 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.5230
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8617
                     Learning rate: 0.0003
                       Mean reward: 132.08
               Mean episode length: 980.30
       Episode_Reward/keep_balance: 0.9833
     Episode_Reward/rew_lin_vel_xy: 6.1452
      Episode_Reward/rew_ang_vel_z: 2.5299
    Episode_Reward/pen_base_height: -0.3144
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1608
   Episode_Reward/pen_joint_torque: -0.2410
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0905
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2542
Episode_Reward/pen_flat_orientation: -0.1027
  Episode_Reward/pen_feet_distance: -0.0276
Episode_Reward/pen_feet_regulation: -0.4871
   Episode_Reward/foot_landing_vel: -0.1375
   Episode_Reward/test_gait_reward: -0.9319
Metrics/base_velocity/error_vel_xy: 0.9860
Metrics/base_velocity/error_vel_yaw: 1.2573
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 159449088
                    Iteration time: 1.07s
                        Total time: 1768.25s
                               ETA: 1503.3s

################################################################################
                     [1m Learning iteration 1622/3000 [0m                     

                       Computation: 88425 steps/s (collection: 0.988s, learning 0.124s)
               Value function loss: 0.5851
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8595
                     Learning rate: 0.0006
                       Mean reward: 136.45
               Mean episode length: 993.61
       Episode_Reward/keep_balance: 0.9869
     Episode_Reward/rew_lin_vel_xy: 6.2926
      Episode_Reward/rew_ang_vel_z: 2.5163
    Episode_Reward/pen_base_height: -0.2883
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1596
   Episode_Reward/pen_joint_torque: -0.2211
    Episode_Reward/pen_joint_accel: -0.1092
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0854
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2543
Episode_Reward/pen_flat_orientation: -0.1015
  Episode_Reward/pen_feet_distance: -0.0282
Episode_Reward/pen_feet_regulation: -0.4687
   Episode_Reward/foot_landing_vel: -0.1355
   Episode_Reward/test_gait_reward: -0.9253
Metrics/base_velocity/error_vel_xy: 0.9403
Metrics/base_velocity/error_vel_yaw: 1.2991
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 159547392
                    Iteration time: 1.11s
                        Total time: 1769.36s
                               ETA: 1502.3s

################################################################################
                     [1m Learning iteration 1623/3000 [0m                     

                       Computation: 89393 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.5225
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8585
                     Learning rate: 0.0003
                       Mean reward: 133.90
               Mean episode length: 981.99
       Episode_Reward/keep_balance: 0.9846
     Episode_Reward/rew_lin_vel_xy: 6.2745
      Episode_Reward/rew_ang_vel_z: 2.5082
    Episode_Reward/pen_base_height: -0.2897
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1598
   Episode_Reward/pen_joint_torque: -0.2332
    Episode_Reward/pen_joint_accel: -0.1123
    Episode_Reward/pen_action_rate: -0.1198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0899
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2573
Episode_Reward/pen_flat_orientation: -0.0985
  Episode_Reward/pen_feet_distance: -0.0250
Episode_Reward/pen_feet_regulation: -0.4702
   Episode_Reward/foot_landing_vel: -0.1439
   Episode_Reward/test_gait_reward: -0.9276
Metrics/base_velocity/error_vel_xy: 0.9244
Metrics/base_velocity/error_vel_yaw: 1.2894
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 159645696
                    Iteration time: 1.10s
                        Total time: 1770.46s
                               ETA: 1501.2s

################################################################################
                     [1m Learning iteration 1624/3000 [0m                     

                       Computation: 89901 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 0.5787
                    Surrogate loss: -0.0051
             Mean action noise std: 0.8578
                     Learning rate: 0.0006
                       Mean reward: 137.81
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4185
      Episode_Reward/rew_ang_vel_z: 2.5628
    Episode_Reward/pen_base_height: -0.3021
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1556
   Episode_Reward/pen_joint_torque: -0.2347
    Episode_Reward/pen_joint_accel: -0.1088
    Episode_Reward/pen_action_rate: -0.1200
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2567
Episode_Reward/pen_flat_orientation: -0.0939
  Episode_Reward/pen_feet_distance: -0.0267
Episode_Reward/pen_feet_regulation: -0.4664
   Episode_Reward/foot_landing_vel: -0.1294
   Episode_Reward/test_gait_reward: -0.9319
Metrics/base_velocity/error_vel_xy: 0.9270
Metrics/base_velocity/error_vel_yaw: 1.2889
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 159744000
                    Iteration time: 1.09s
                        Total time: 1771.56s
                               ETA: 1500.1s

################################################################################
                     [1m Learning iteration 1625/3000 [0m                     

                       Computation: 89352 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.5254
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8581
                     Learning rate: 0.0006
                       Mean reward: 132.49
               Mean episode length: 977.76
       Episode_Reward/keep_balance: 0.9760
     Episode_Reward/rew_lin_vel_xy: 6.1478
      Episode_Reward/rew_ang_vel_z: 2.5367
    Episode_Reward/pen_base_height: -0.3150
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1583
   Episode_Reward/pen_joint_torque: -0.2319
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.1178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2509
Episode_Reward/pen_flat_orientation: -0.1007
  Episode_Reward/pen_feet_distance: -0.0270
Episode_Reward/pen_feet_regulation: -0.4782
   Episode_Reward/foot_landing_vel: -0.1324
   Episode_Reward/test_gait_reward: -0.9228
Metrics/base_velocity/error_vel_xy: 0.9597
Metrics/base_velocity/error_vel_yaw: 1.2358
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 159842304
                    Iteration time: 1.10s
                        Total time: 1772.66s
                               ETA: 1499.0s

################################################################################
                     [1m Learning iteration 1626/3000 [0m                     

                       Computation: 90168 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.5087
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8582
                     Learning rate: 0.0006
                       Mean reward: 130.26
               Mean episode length: 975.39
       Episode_Reward/keep_balance: 0.9598
     Episode_Reward/rew_lin_vel_xy: 5.9571
      Episode_Reward/rew_ang_vel_z: 2.4203
    Episode_Reward/pen_base_height: -0.3128
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1638
   Episode_Reward/pen_joint_torque: -0.2316
    Episode_Reward/pen_joint_accel: -0.1103
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2516
Episode_Reward/pen_flat_orientation: -0.1113
  Episode_Reward/pen_feet_distance: -0.0249
Episode_Reward/pen_feet_regulation: -0.4718
   Episode_Reward/foot_landing_vel: -0.1393
   Episode_Reward/test_gait_reward: -0.9116
Metrics/base_velocity/error_vel_xy: 1.0078
Metrics/base_velocity/error_vel_yaw: 1.3004
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 159940608
                    Iteration time: 1.09s
                        Total time: 1773.75s
                               ETA: 1497.9s

################################################################################
                     [1m Learning iteration 1627/3000 [0m                     

                       Computation: 89699 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 0.5766
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8591
                     Learning rate: 0.0006
                       Mean reward: 131.34
               Mean episode length: 983.10
       Episode_Reward/keep_balance: 0.9954
     Episode_Reward/rew_lin_vel_xy: 6.1951
      Episode_Reward/rew_ang_vel_z: 2.5249
    Episode_Reward/pen_base_height: -0.3083
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.1653
   Episode_Reward/pen_joint_torque: -0.2352
    Episode_Reward/pen_joint_accel: -0.1244
    Episode_Reward/pen_action_rate: -0.1211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0597
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2603
Episode_Reward/pen_flat_orientation: -0.1007
  Episode_Reward/pen_feet_distance: -0.0241
Episode_Reward/pen_feet_regulation: -0.4767
   Episode_Reward/foot_landing_vel: -0.1428
   Episode_Reward/test_gait_reward: -0.9440
Metrics/base_velocity/error_vel_xy: 1.0031
Metrics/base_velocity/error_vel_yaw: 1.3147
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 160038912
                    Iteration time: 1.10s
                        Total time: 1774.84s
                               ETA: 1496.8s

################################################################################
                     [1m Learning iteration 1628/3000 [0m                     

                       Computation: 89775 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 0.4958
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8595
                     Learning rate: 0.0002
                       Mean reward: 133.21
               Mean episode length: 975.42
       Episode_Reward/keep_balance: 0.9645
     Episode_Reward/rew_lin_vel_xy: 6.1038
      Episode_Reward/rew_ang_vel_z: 2.4672
    Episode_Reward/pen_base_height: -0.2940
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1627
   Episode_Reward/pen_joint_torque: -0.2258
    Episode_Reward/pen_joint_accel: -0.1107
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2517
Episode_Reward/pen_flat_orientation: -0.1026
  Episode_Reward/pen_feet_distance: -0.0272
Episode_Reward/pen_feet_regulation: -0.4627
   Episode_Reward/foot_landing_vel: -0.1393
   Episode_Reward/test_gait_reward: -0.9082
Metrics/base_velocity/error_vel_xy: 0.9240
Metrics/base_velocity/error_vel_yaw: 1.2594
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 160137216
                    Iteration time: 1.09s
                        Total time: 1775.94s
                               ETA: 1495.8s

################################################################################
                     [1m Learning iteration 1629/3000 [0m                     

                       Computation: 90480 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.6464
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8591
                     Learning rate: 0.0004
                       Mean reward: 136.63
               Mean episode length: 980.62
       Episode_Reward/keep_balance: 0.9801
     Episode_Reward/rew_lin_vel_xy: 6.3187
      Episode_Reward/rew_ang_vel_z: 2.5300
    Episode_Reward/pen_base_height: -0.2946
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1551
   Episode_Reward/pen_joint_torque: -0.2250
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2522
Episode_Reward/pen_flat_orientation: -0.0909
  Episode_Reward/pen_feet_distance: -0.0206
Episode_Reward/pen_feet_regulation: -0.4533
   Episode_Reward/foot_landing_vel: -0.1346
   Episode_Reward/test_gait_reward: -0.9194
Metrics/base_velocity/error_vel_xy: 0.8902
Metrics/base_velocity/error_vel_yaw: 1.2504
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 160235520
                    Iteration time: 1.09s
                        Total time: 1777.02s
                               ETA: 1494.7s

################################################################################
                     [1m Learning iteration 1630/3000 [0m                     

                       Computation: 90640 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.5636
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8591
                     Learning rate: 0.0006
                       Mean reward: 137.35
               Mean episode length: 984.59
       Episode_Reward/keep_balance: 0.9894
     Episode_Reward/rew_lin_vel_xy: 6.3338
      Episode_Reward/rew_ang_vel_z: 2.5567
    Episode_Reward/pen_base_height: -0.3033
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1589
   Episode_Reward/pen_joint_torque: -0.2358
    Episode_Reward/pen_joint_accel: -0.1087
    Episode_Reward/pen_action_rate: -0.1195
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2557
Episode_Reward/pen_flat_orientation: -0.0987
  Episode_Reward/pen_feet_distance: -0.0286
Episode_Reward/pen_feet_regulation: -0.4658
   Episode_Reward/foot_landing_vel: -0.1267
   Episode_Reward/test_gait_reward: -0.9305
Metrics/base_velocity/error_vel_xy: 0.9202
Metrics/base_velocity/error_vel_yaw: 1.2621
      Episode_Termination/time_out: 5.0833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 160333824
                    Iteration time: 1.08s
                        Total time: 1778.11s
                               ETA: 1493.6s

################################################################################
                     [1m Learning iteration 1631/3000 [0m                     

                       Computation: 90022 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.5229
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8581
                     Learning rate: 0.0004
                       Mean reward: 137.93
               Mean episode length: 995.50
       Episode_Reward/keep_balance: 0.9900
     Episode_Reward/rew_lin_vel_xy: 6.2805
      Episode_Reward/rew_ang_vel_z: 2.5212
    Episode_Reward/pen_base_height: -0.3083
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1602
   Episode_Reward/pen_joint_torque: -0.2322
    Episode_Reward/pen_joint_accel: -0.1092
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2567
Episode_Reward/pen_flat_orientation: -0.1032
  Episode_Reward/pen_feet_distance: -0.0265
Episode_Reward/pen_feet_regulation: -0.4820
   Episode_Reward/foot_landing_vel: -0.1399
   Episode_Reward/test_gait_reward: -0.9386
Metrics/base_velocity/error_vel_xy: 0.9541
Metrics/base_velocity/error_vel_yaw: 1.3018
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 160432128
                    Iteration time: 1.09s
                        Total time: 1779.20s
                               ETA: 1492.5s

################################################################################
                     [1m Learning iteration 1632/3000 [0m                     

                       Computation: 90178 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.5321
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8575
                     Learning rate: 0.0004
                       Mean reward: 132.03
               Mean episode length: 978.26
       Episode_Reward/keep_balance: 0.9590
     Episode_Reward/rew_lin_vel_xy: 6.0528
      Episode_Reward/rew_ang_vel_z: 2.4230
    Episode_Reward/pen_base_height: -0.2946
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1597
   Episode_Reward/pen_joint_torque: -0.2317
    Episode_Reward/pen_joint_accel: -0.1113
    Episode_Reward/pen_action_rate: -0.1174
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2502
Episode_Reward/pen_flat_orientation: -0.1046
  Episode_Reward/pen_feet_distance: -0.0280
Episode_Reward/pen_feet_regulation: -0.4701
   Episode_Reward/foot_landing_vel: -0.1423
   Episode_Reward/test_gait_reward: -0.9052
Metrics/base_velocity/error_vel_xy: 0.9425
Metrics/base_velocity/error_vel_yaw: 1.2816
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 160530432
                    Iteration time: 1.09s
                        Total time: 1780.29s
                               ETA: 1491.4s

################################################################################
                     [1m Learning iteration 1633/3000 [0m                     

                       Computation: 89491 steps/s (collection: 0.973s, learning 0.126s)
               Value function loss: 0.5516
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8575
                     Learning rate: 0.0006
                       Mean reward: 134.17
               Mean episode length: 988.06
       Episode_Reward/keep_balance: 0.9870
     Episode_Reward/rew_lin_vel_xy: 6.2114
      Episode_Reward/rew_ang_vel_z: 2.5491
    Episode_Reward/pen_base_height: -0.3029
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1642
   Episode_Reward/pen_joint_torque: -0.2391
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2551
Episode_Reward/pen_flat_orientation: -0.0973
  Episode_Reward/pen_feet_distance: -0.0286
Episode_Reward/pen_feet_regulation: -0.4728
   Episode_Reward/foot_landing_vel: -0.1482
   Episode_Reward/test_gait_reward: -0.9309
Metrics/base_velocity/error_vel_xy: 0.9705
Metrics/base_velocity/error_vel_yaw: 1.2529
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 160628736
                    Iteration time: 1.10s
                        Total time: 1781.39s
                               ETA: 1490.3s

################################################################################
                     [1m Learning iteration 1634/3000 [0m                     

                       Computation: 89256 steps/s (collection: 0.977s, learning 0.124s)
               Value function loss: 0.6566
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8580
                     Learning rate: 0.0002
                       Mean reward: 134.41
               Mean episode length: 985.48
       Episode_Reward/keep_balance: 0.9879
     Episode_Reward/rew_lin_vel_xy: 6.1778
      Episode_Reward/rew_ang_vel_z: 2.5202
    Episode_Reward/pen_base_height: -0.3115
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1577
   Episode_Reward/pen_joint_torque: -0.2406
    Episode_Reward/pen_joint_accel: -0.1070
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2570
Episode_Reward/pen_flat_orientation: -0.0990
  Episode_Reward/pen_feet_distance: -0.0313
Episode_Reward/pen_feet_regulation: -0.4950
   Episode_Reward/foot_landing_vel: -0.1329
   Episode_Reward/test_gait_reward: -0.9334
Metrics/base_velocity/error_vel_xy: 0.9881
Metrics/base_velocity/error_vel_yaw: 1.2861
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 160727040
                    Iteration time: 1.10s
                        Total time: 1782.49s
                               ETA: 1489.2s

################################################################################
                     [1m Learning iteration 1635/3000 [0m                     

                       Computation: 89915 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.5724
                    Surrogate loss: -0.0051
             Mean action noise std: 0.8583
                     Learning rate: 0.0004
                       Mean reward: 133.68
               Mean episode length: 974.87
       Episode_Reward/keep_balance: 0.9802
     Episode_Reward/rew_lin_vel_xy: 6.2298
      Episode_Reward/rew_ang_vel_z: 2.5206
    Episode_Reward/pen_base_height: -0.3049
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1575
   Episode_Reward/pen_joint_torque: -0.2400
    Episode_Reward/pen_joint_accel: -0.1054
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2513
Episode_Reward/pen_flat_orientation: -0.1007
  Episode_Reward/pen_feet_distance: -0.0282
Episode_Reward/pen_feet_regulation: -0.4842
   Episode_Reward/foot_landing_vel: -0.1332
   Episode_Reward/test_gait_reward: -0.9323
Metrics/base_velocity/error_vel_xy: 0.9393
Metrics/base_velocity/error_vel_yaw: 1.2580
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 160825344
                    Iteration time: 1.09s
                        Total time: 1783.58s
                               ETA: 1488.1s

################################################################################
                     [1m Learning iteration 1636/3000 [0m                     

                       Computation: 84921 steps/s (collection: 1.032s, learning 0.125s)
               Value function loss: 0.5712
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8588
                     Learning rate: 0.0009
                       Mean reward: 136.07
               Mean episode length: 986.73
       Episode_Reward/keep_balance: 0.9848
     Episode_Reward/rew_lin_vel_xy: 6.2523
      Episode_Reward/rew_ang_vel_z: 2.5677
    Episode_Reward/pen_base_height: -0.3024
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1555
   Episode_Reward/pen_joint_torque: -0.2243
    Episode_Reward/pen_joint_accel: -0.1111
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0848
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2508
Episode_Reward/pen_flat_orientation: -0.1006
  Episode_Reward/pen_feet_distance: -0.0243
Episode_Reward/pen_feet_regulation: -0.4574
   Episode_Reward/foot_landing_vel: -0.1301
   Episode_Reward/test_gait_reward: -0.9262
Metrics/base_velocity/error_vel_xy: 0.9573
Metrics/base_velocity/error_vel_yaw: 1.2329
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 160923648
                    Iteration time: 1.16s
                        Total time: 1784.74s
                               ETA: 1487.1s

################################################################################
                     [1m Learning iteration 1637/3000 [0m                     

                       Computation: 91536 steps/s (collection: 0.950s, learning 0.124s)
               Value function loss: 0.5452
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8583
                     Learning rate: 0.0009
                       Mean reward: 132.79
               Mean episode length: 988.43
       Episode_Reward/keep_balance: 0.9864
     Episode_Reward/rew_lin_vel_xy: 6.1642
      Episode_Reward/rew_ang_vel_z: 2.4831
    Episode_Reward/pen_base_height: -0.3148
      Episode_Reward/pen_lin_vel_z: -0.0400
     Episode_Reward/pen_ang_vel_xy: -0.1627
   Episode_Reward/pen_joint_torque: -0.2387
    Episode_Reward/pen_joint_accel: -0.1167
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0602
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2574
Episode_Reward/pen_flat_orientation: -0.1048
  Episode_Reward/pen_feet_distance: -0.0260
Episode_Reward/pen_feet_regulation: -0.5046
   Episode_Reward/foot_landing_vel: -0.1310
   Episode_Reward/test_gait_reward: -0.9482
Metrics/base_velocity/error_vel_xy: 1.0059
Metrics/base_velocity/error_vel_yaw: 1.3185
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 161021952
                    Iteration time: 1.07s
                        Total time: 1785.82s
                               ETA: 1486.0s

################################################################################
                     [1m Learning iteration 1638/3000 [0m                     

                       Computation: 88500 steps/s (collection: 0.988s, learning 0.123s)
               Value function loss: 0.5478
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8595
                     Learning rate: 0.0009
                       Mean reward: 136.00
               Mean episode length: 980.77
       Episode_Reward/keep_balance: 0.9800
     Episode_Reward/rew_lin_vel_xy: 6.2459
      Episode_Reward/rew_ang_vel_z: 2.5761
    Episode_Reward/pen_base_height: -0.3019
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1552
   Episode_Reward/pen_joint_torque: -0.2421
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2532
Episode_Reward/pen_flat_orientation: -0.1028
  Episode_Reward/pen_feet_distance: -0.0257
Episode_Reward/pen_feet_regulation: -0.4613
   Episode_Reward/foot_landing_vel: -0.1323
   Episode_Reward/test_gait_reward: -0.9256
Metrics/base_velocity/error_vel_xy: 0.9303
Metrics/base_velocity/error_vel_yaw: 1.2179
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 161120256
                    Iteration time: 1.11s
                        Total time: 1786.93s
                               ETA: 1484.9s

################################################################################
                     [1m Learning iteration 1639/3000 [0m                     

                       Computation: 89441 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.5096
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8607
                     Learning rate: 0.0006
                       Mean reward: 136.29
               Mean episode length: 983.48
       Episode_Reward/keep_balance: 0.9867
     Episode_Reward/rew_lin_vel_xy: 6.2738
      Episode_Reward/rew_ang_vel_z: 2.5380
    Episode_Reward/pen_base_height: -0.2974
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.1563
   Episode_Reward/pen_joint_torque: -0.2362
    Episode_Reward/pen_joint_accel: -0.1066
    Episode_Reward/pen_action_rate: -0.1190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2554
Episode_Reward/pen_flat_orientation: -0.0952
  Episode_Reward/pen_feet_distance: -0.0256
Episode_Reward/pen_feet_regulation: -0.4639
   Episode_Reward/foot_landing_vel: -0.1332
   Episode_Reward/test_gait_reward: -0.9341
Metrics/base_velocity/error_vel_xy: 0.9410
Metrics/base_velocity/error_vel_yaw: 1.2722
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 161218560
                    Iteration time: 1.10s
                        Total time: 1788.02s
                               ETA: 1483.8s

################################################################################
                     [1m Learning iteration 1640/3000 [0m                     

                       Computation: 90214 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.5361
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8601
                     Learning rate: 0.0009
                       Mean reward: 137.73
               Mean episode length: 984.90
       Episode_Reward/keep_balance: 0.9855
     Episode_Reward/rew_lin_vel_xy: 6.2729
      Episode_Reward/rew_ang_vel_z: 2.5251
    Episode_Reward/pen_base_height: -0.2966
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1573
   Episode_Reward/pen_joint_torque: -0.2274
    Episode_Reward/pen_joint_accel: -0.1022
    Episode_Reward/pen_action_rate: -0.1182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2548
Episode_Reward/pen_flat_orientation: -0.0946
  Episode_Reward/pen_feet_distance: -0.0244
Episode_Reward/pen_feet_regulation: -0.4570
   Episode_Reward/foot_landing_vel: -0.1326
   Episode_Reward/test_gait_reward: -0.9308
Metrics/base_velocity/error_vel_xy: 0.9204
Metrics/base_velocity/error_vel_yaw: 1.2737
      Episode_Termination/time_out: 4.8750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 161316864
                    Iteration time: 1.09s
                        Total time: 1789.11s
                               ETA: 1482.8s

################################################################################
                     [1m Learning iteration 1641/3000 [0m                     

                       Computation: 91415 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.5314
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8606
                     Learning rate: 0.0009
                       Mean reward: 135.52
               Mean episode length: 981.94
       Episode_Reward/keep_balance: 0.9854
     Episode_Reward/rew_lin_vel_xy: 6.2335
      Episode_Reward/rew_ang_vel_z: 2.5254
    Episode_Reward/pen_base_height: -0.2848
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1600
   Episode_Reward/pen_joint_torque: -0.2172
    Episode_Reward/pen_joint_accel: -0.1033
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0856
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2553
Episode_Reward/pen_flat_orientation: -0.0985
  Episode_Reward/pen_feet_distance: -0.0256
Episode_Reward/pen_feet_regulation: -0.4633
   Episode_Reward/foot_landing_vel: -0.1377
   Episode_Reward/test_gait_reward: -0.9312
Metrics/base_velocity/error_vel_xy: 0.9424
Metrics/base_velocity/error_vel_yaw: 1.2881
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 161415168
                    Iteration time: 1.08s
                        Total time: 1790.19s
                               ETA: 1481.6s

################################################################################
                     [1m Learning iteration 1642/3000 [0m                     

                       Computation: 88640 steps/s (collection: 0.985s, learning 0.124s)
               Value function loss: 0.5796
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8618
                     Learning rate: 0.0006
                       Mean reward: 134.68
               Mean episode length: 987.84
       Episode_Reward/keep_balance: 0.9944
     Episode_Reward/rew_lin_vel_xy: 6.2768
      Episode_Reward/rew_ang_vel_z: 2.5322
    Episode_Reward/pen_base_height: -0.2948
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1620
   Episode_Reward/pen_joint_torque: -0.2319
    Episode_Reward/pen_joint_accel: -0.1134
    Episode_Reward/pen_action_rate: -0.1206
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0892
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2606
Episode_Reward/pen_flat_orientation: -0.1043
  Episode_Reward/pen_feet_distance: -0.0239
Episode_Reward/pen_feet_regulation: -0.4948
   Episode_Reward/foot_landing_vel: -0.1279
   Episode_Reward/test_gait_reward: -0.9490
Metrics/base_velocity/error_vel_xy: 0.9728
Metrics/base_velocity/error_vel_yaw: 1.3036
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 161513472
                    Iteration time: 1.11s
                        Total time: 1791.30s
                               ETA: 1480.6s

################################################################################
                     [1m Learning iteration 1643/3000 [0m                     

                       Computation: 90485 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.5676
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8624
                     Learning rate: 0.0006
                       Mean reward: 133.12
               Mean episode length: 975.84
       Episode_Reward/keep_balance: 0.9738
     Episode_Reward/rew_lin_vel_xy: 6.1641
      Episode_Reward/rew_ang_vel_z: 2.4815
    Episode_Reward/pen_base_height: -0.3002
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.1602
   Episode_Reward/pen_joint_torque: -0.2351
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.1192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2545
Episode_Reward/pen_flat_orientation: -0.0996
  Episode_Reward/pen_feet_distance: -0.0323
Episode_Reward/pen_feet_regulation: -0.4824
   Episode_Reward/foot_landing_vel: -0.1444
   Episode_Reward/test_gait_reward: -0.9190
Metrics/base_velocity/error_vel_xy: 0.9265
Metrics/base_velocity/error_vel_yaw: 1.2720
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 161611776
                    Iteration time: 1.09s
                        Total time: 1792.39s
                               ETA: 1479.5s

################################################################################
                     [1m Learning iteration 1644/3000 [0m                     

                       Computation: 90172 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.4925
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8619
                     Learning rate: 0.0009
                       Mean reward: 133.36
               Mean episode length: 979.77
       Episode_Reward/keep_balance: 0.9885
     Episode_Reward/rew_lin_vel_xy: 6.3174
      Episode_Reward/rew_ang_vel_z: 2.5310
    Episode_Reward/pen_base_height: -0.3162
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1581
   Episode_Reward/pen_joint_torque: -0.2385
    Episode_Reward/pen_joint_accel: -0.1114
    Episode_Reward/pen_action_rate: -0.1184
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2550
Episode_Reward/pen_flat_orientation: -0.1001
  Episode_Reward/pen_feet_distance: -0.0266
Episode_Reward/pen_feet_regulation: -0.4676
   Episode_Reward/foot_landing_vel: -0.1390
   Episode_Reward/test_gait_reward: -0.9390
Metrics/base_velocity/error_vel_xy: 0.9210
Metrics/base_velocity/error_vel_yaw: 1.2857
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 161710080
                    Iteration time: 1.09s
                        Total time: 1793.48s
                               ETA: 1478.4s

################################################################################
                     [1m Learning iteration 1645/3000 [0m                     

                       Computation: 89668 steps/s (collection: 0.969s, learning 0.127s)
               Value function loss: 0.5449
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8637
                     Learning rate: 0.0009
                       Mean reward: 135.59
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.3255
      Episode_Reward/rew_ang_vel_z: 2.5648
    Episode_Reward/pen_base_height: -0.2946
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1709
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1275
    Episode_Reward/pen_action_rate: -0.1213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0593
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2633
Episode_Reward/pen_flat_orientation: -0.0982
  Episode_Reward/pen_feet_distance: -0.0241
Episode_Reward/pen_feet_regulation: -0.4927
   Episode_Reward/foot_landing_vel: -0.1426
   Episode_Reward/test_gait_reward: -0.9439
Metrics/base_velocity/error_vel_xy: 0.9658
Metrics/base_velocity/error_vel_yaw: 1.2908
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 161808384
                    Iteration time: 1.10s
                        Total time: 1794.57s
                               ETA: 1477.3s

################################################################################
                     [1m Learning iteration 1646/3000 [0m                     

                       Computation: 89571 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.5305
                    Surrogate loss: 0.0014
             Mean action noise std: 0.8634
                     Learning rate: 0.0002
                       Mean reward: 137.14
               Mean episode length: 990.50
       Episode_Reward/keep_balance: 0.9934
     Episode_Reward/rew_lin_vel_xy: 6.2925
      Episode_Reward/rew_ang_vel_z: 2.5481
    Episode_Reward/pen_base_height: -0.2985
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1607
   Episode_Reward/pen_joint_torque: -0.2395
    Episode_Reward/pen_joint_accel: -0.1128
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0904
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2575
Episode_Reward/pen_flat_orientation: -0.0993
  Episode_Reward/pen_feet_distance: -0.0266
Episode_Reward/pen_feet_regulation: -0.4755
   Episode_Reward/foot_landing_vel: -0.1375
   Episode_Reward/test_gait_reward: -0.9457
Metrics/base_velocity/error_vel_xy: 0.9505
Metrics/base_velocity/error_vel_yaw: 1.2835
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 161906688
                    Iteration time: 1.10s
                        Total time: 1795.67s
                               ETA: 1476.2s

################################################################################
                     [1m Learning iteration 1647/3000 [0m                     

                       Computation: 90027 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.5289
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8626
                     Learning rate: 0.0004
                       Mean reward: 133.25
               Mean episode length: 974.68
       Episode_Reward/keep_balance: 0.9802
     Episode_Reward/rew_lin_vel_xy: 6.1663
      Episode_Reward/rew_ang_vel_z: 2.4955
    Episode_Reward/pen_base_height: -0.3122
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1598
   Episode_Reward/pen_joint_torque: -0.2298
    Episode_Reward/pen_joint_accel: -0.1138
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2553
Episode_Reward/pen_flat_orientation: -0.1023
  Episode_Reward/pen_feet_distance: -0.0300
Episode_Reward/pen_feet_regulation: -0.4839
   Episode_Reward/foot_landing_vel: -0.1397
   Episode_Reward/test_gait_reward: -0.9354
Metrics/base_velocity/error_vel_xy: 0.9715
Metrics/base_velocity/error_vel_yaw: 1.2882
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 162004992
                    Iteration time: 1.09s
                        Total time: 1796.76s
                               ETA: 1475.1s

################################################################################
                     [1m Learning iteration 1648/3000 [0m                     

                       Computation: 89235 steps/s (collection: 0.978s, learning 0.124s)
               Value function loss: 0.4868
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8629
                     Learning rate: 0.0001
                       Mean reward: 137.75
               Mean episode length: 999.61
       Episode_Reward/keep_balance: 0.9997
     Episode_Reward/rew_lin_vel_xy: 6.4237
      Episode_Reward/rew_ang_vel_z: 2.5645
    Episode_Reward/pen_base_height: -0.2991
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1592
   Episode_Reward/pen_joint_torque: -0.2325
    Episode_Reward/pen_joint_accel: -0.0992
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0869
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2605
Episode_Reward/pen_flat_orientation: -0.0975
  Episode_Reward/pen_feet_distance: -0.0244
Episode_Reward/pen_feet_regulation: -0.4651
   Episode_Reward/foot_landing_vel: -0.1307
   Episode_Reward/test_gait_reward: -0.9501
Metrics/base_velocity/error_vel_xy: 0.9183
Metrics/base_velocity/error_vel_yaw: 1.2881
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 162103296
                    Iteration time: 1.10s
                        Total time: 1797.86s
                               ETA: 1474.1s

################################################################################
                     [1m Learning iteration 1649/3000 [0m                     

                       Computation: 89318 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.5769
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8617
                     Learning rate: 0.0002
                       Mean reward: 133.19
               Mean episode length: 981.63
       Episode_Reward/keep_balance: 0.9642
     Episode_Reward/rew_lin_vel_xy: 6.0664
      Episode_Reward/rew_ang_vel_z: 2.4619
    Episode_Reward/pen_base_height: -0.3187
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1540
   Episode_Reward/pen_joint_torque: -0.2403
    Episode_Reward/pen_joint_accel: -0.1101
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0891
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2491
Episode_Reward/pen_flat_orientation: -0.0980
  Episode_Reward/pen_feet_distance: -0.0302
Episode_Reward/pen_feet_regulation: -0.4673
   Episode_Reward/foot_landing_vel: -0.1323
   Episode_Reward/test_gait_reward: -0.9166
Metrics/base_velocity/error_vel_xy: 0.9529
Metrics/base_velocity/error_vel_yaw: 1.2660
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 162201600
                    Iteration time: 1.10s
                        Total time: 1798.96s
                               ETA: 1473.0s

################################################################################
                     [1m Learning iteration 1650/3000 [0m                     

                       Computation: 87117 steps/s (collection: 1.002s, learning 0.127s)
               Value function loss: 0.5962
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8596
                     Learning rate: 0.0004
                       Mean reward: 134.73
               Mean episode length: 984.12
       Episode_Reward/keep_balance: 0.9871
     Episode_Reward/rew_lin_vel_xy: 6.2906
      Episode_Reward/rew_ang_vel_z: 2.5384
    Episode_Reward/pen_base_height: -0.3074
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1633
   Episode_Reward/pen_joint_torque: -0.2375
    Episode_Reward/pen_joint_accel: -0.1145
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2587
Episode_Reward/pen_flat_orientation: -0.0991
  Episode_Reward/pen_feet_distance: -0.0278
Episode_Reward/pen_feet_regulation: -0.4804
   Episode_Reward/foot_landing_vel: -0.1274
   Episode_Reward/test_gait_reward: -0.9443
Metrics/base_velocity/error_vel_xy: 0.9254
Metrics/base_velocity/error_vel_yaw: 1.2705
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 162299904
                    Iteration time: 1.13s
                        Total time: 1800.09s
                               ETA: 1471.9s

################################################################################
                     [1m Learning iteration 1651/3000 [0m                     

                       Computation: 87481 steps/s (collection: 0.998s, learning 0.126s)
               Value function loss: 0.5104
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8590
                     Learning rate: 0.0004
                       Mean reward: 126.45
               Mean episode length: 933.97
       Episode_Reward/keep_balance: 0.9429
     Episode_Reward/rew_lin_vel_xy: 5.9743
      Episode_Reward/rew_ang_vel_z: 2.4306
    Episode_Reward/pen_base_height: -0.2956
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1556
   Episode_Reward/pen_joint_torque: -0.2255
    Episode_Reward/pen_joint_accel: -0.1120
    Episode_Reward/pen_action_rate: -0.1149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2459
Episode_Reward/pen_flat_orientation: -0.1024
  Episode_Reward/pen_feet_distance: -0.0255
Episode_Reward/pen_feet_regulation: -0.4602
   Episode_Reward/foot_landing_vel: -0.1307
   Episode_Reward/test_gait_reward: -0.8983
Metrics/base_velocity/error_vel_xy: 0.9140
Metrics/base_velocity/error_vel_yaw: 1.2257
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 162398208
                    Iteration time: 1.12s
                        Total time: 1801.22s
                               ETA: 1470.8s

################################################################################
                     [1m Learning iteration 1652/3000 [0m                     

                       Computation: 87622 steps/s (collection: 0.999s, learning 0.123s)
               Value function loss: 0.5220
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8573
                     Learning rate: 0.0003
                       Mean reward: 136.58
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.3291
      Episode_Reward/rew_ang_vel_z: 2.5794
    Episode_Reward/pen_base_height: -0.3071
      Episode_Reward/pen_lin_vel_z: -0.0405
     Episode_Reward/pen_ang_vel_xy: -0.1590
   Episode_Reward/pen_joint_torque: -0.2362
    Episode_Reward/pen_joint_accel: -0.1105
    Episode_Reward/pen_action_rate: -0.1224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0591
   Episode_Reward/pen_joint_powers: -0.0900
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2621
Episode_Reward/pen_flat_orientation: -0.0994
  Episode_Reward/pen_feet_distance: -0.0285
Episode_Reward/pen_feet_regulation: -0.5129
   Episode_Reward/foot_landing_vel: -0.1425
   Episode_Reward/test_gait_reward: -0.9605
Metrics/base_velocity/error_vel_xy: 0.9720
Metrics/base_velocity/error_vel_yaw: 1.2784
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 162496512
                    Iteration time: 1.12s
                        Total time: 1802.34s
                               ETA: 1469.8s

################################################################################
                     [1m Learning iteration 1653/3000 [0m                     

                       Computation: 89382 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.4958
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8548
                     Learning rate: 0.0004
                       Mean reward: 134.91
               Mean episode length: 991.59
       Episode_Reward/keep_balance: 0.9940
     Episode_Reward/rew_lin_vel_xy: 6.3000
      Episode_Reward/rew_ang_vel_z: 2.5729
    Episode_Reward/pen_base_height: -0.3180
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.1624
   Episode_Reward/pen_joint_torque: -0.2431
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1226
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0910
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2574
Episode_Reward/pen_flat_orientation: -0.1008
  Episode_Reward/pen_feet_distance: -0.0293
Episode_Reward/pen_feet_regulation: -0.4960
   Episode_Reward/foot_landing_vel: -0.1303
   Episode_Reward/test_gait_reward: -0.9530
Metrics/base_velocity/error_vel_xy: 0.9603
Metrics/base_velocity/error_vel_yaw: 1.2722
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 162594816
                    Iteration time: 1.10s
                        Total time: 1803.44s
                               ETA: 1468.7s

################################################################################
                     [1m Learning iteration 1654/3000 [0m                     

                       Computation: 90911 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.5776
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8540
                     Learning rate: 0.0004
                       Mean reward: 138.13
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.3577
      Episode_Reward/rew_ang_vel_z: 2.5658
    Episode_Reward/pen_base_height: -0.3006
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1633
   Episode_Reward/pen_joint_torque: -0.2362
    Episode_Reward/pen_joint_accel: -0.1133
    Episode_Reward/pen_action_rate: -0.1224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0892
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2627
Episode_Reward/pen_flat_orientation: -0.0985
  Episode_Reward/pen_feet_distance: -0.0247
Episode_Reward/pen_feet_regulation: -0.4777
   Episode_Reward/foot_landing_vel: -0.1322
   Episode_Reward/test_gait_reward: -0.9513
Metrics/base_velocity/error_vel_xy: 0.9599
Metrics/base_velocity/error_vel_yaw: 1.2990
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 162693120
                    Iteration time: 1.08s
                        Total time: 1804.52s
                               ETA: 1467.6s

################################################################################
                     [1m Learning iteration 1655/3000 [0m                     

                       Computation: 90414 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.5704
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8533
                     Learning rate: 0.0004
                       Mean reward: 131.92
               Mean episode length: 967.65
       Episode_Reward/keep_balance: 0.9728
     Episode_Reward/rew_lin_vel_xy: 6.1995
      Episode_Reward/rew_ang_vel_z: 2.5234
    Episode_Reward/pen_base_height: -0.2989
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1567
   Episode_Reward/pen_joint_torque: -0.2402
    Episode_Reward/pen_joint_accel: -0.1123
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2527
Episode_Reward/pen_flat_orientation: -0.0935
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4655
   Episode_Reward/foot_landing_vel: -0.1394
   Episode_Reward/test_gait_reward: -0.9274
Metrics/base_velocity/error_vel_xy: 0.9120
Metrics/base_velocity/error_vel_yaw: 1.2316
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 162791424
                    Iteration time: 1.09s
                        Total time: 1805.61s
                               ETA: 1466.5s

################################################################################
                     [1m Learning iteration 1656/3000 [0m                     

                       Computation: 89362 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 0.5219
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8520
                     Learning rate: 0.0006
                       Mean reward: 135.70
               Mean episode length: 988.25
       Episode_Reward/keep_balance: 0.9581
     Episode_Reward/rew_lin_vel_xy: 6.0466
      Episode_Reward/rew_ang_vel_z: 2.4763
    Episode_Reward/pen_base_height: -0.2834
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1531
   Episode_Reward/pen_joint_torque: -0.2314
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1170
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0556
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2494
Episode_Reward/pen_flat_orientation: -0.0940
  Episode_Reward/pen_feet_distance: -0.0210
Episode_Reward/pen_feet_regulation: -0.4539
   Episode_Reward/foot_landing_vel: -0.1354
   Episode_Reward/test_gait_reward: -0.9142
Metrics/base_velocity/error_vel_xy: 0.9259
Metrics/base_velocity/error_vel_yaw: 1.2194
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 162889728
                    Iteration time: 1.10s
                        Total time: 1806.71s
                               ETA: 1465.4s

################################################################################
                     [1m Learning iteration 1657/3000 [0m                     

                       Computation: 89728 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.5148
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8521
                     Learning rate: 0.0004
                       Mean reward: 140.84
               Mean episode length: 990.31
       Episode_Reward/keep_balance: 0.9933
     Episode_Reward/rew_lin_vel_xy: 6.3879
      Episode_Reward/rew_ang_vel_z: 2.6099
    Episode_Reward/pen_base_height: -0.3055
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1506
   Episode_Reward/pen_joint_torque: -0.2438
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2536
Episode_Reward/pen_flat_orientation: -0.0936
  Episode_Reward/pen_feet_distance: -0.0221
Episode_Reward/pen_feet_regulation: -0.4507
   Episode_Reward/foot_landing_vel: -0.1290
   Episode_Reward/test_gait_reward: -0.9391
Metrics/base_velocity/error_vel_xy: 0.9068
Metrics/base_velocity/error_vel_yaw: 1.2274
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 162988032
                    Iteration time: 1.10s
                        Total time: 1807.80s
                               ETA: 1464.3s

################################################################################
                     [1m Learning iteration 1658/3000 [0m                     

                       Computation: 89887 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.5386
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8526
                     Learning rate: 0.0006
                       Mean reward: 139.36
               Mean episode length: 996.54
       Episode_Reward/keep_balance: 0.9984
     Episode_Reward/rew_lin_vel_xy: 6.4005
      Episode_Reward/rew_ang_vel_z: 2.6156
    Episode_Reward/pen_base_height: -0.2915
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1559
   Episode_Reward/pen_joint_torque: -0.2423
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2571
Episode_Reward/pen_flat_orientation: -0.0930
  Episode_Reward/pen_feet_distance: -0.0202
Episode_Reward/pen_feet_regulation: -0.4621
   Episode_Reward/foot_landing_vel: -0.1378
   Episode_Reward/test_gait_reward: -0.9521
Metrics/base_velocity/error_vel_xy: 0.9280
Metrics/base_velocity/error_vel_yaw: 1.2341
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 163086336
                    Iteration time: 1.09s
                        Total time: 1808.90s
                               ETA: 1463.3s

################################################################################
                     [1m Learning iteration 1659/3000 [0m                     

                       Computation: 90199 steps/s (collection: 0.965s, learning 0.125s)
               Value function loss: 0.5505
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8529
                     Learning rate: 0.0009
                       Mean reward: 131.88
               Mean episode length: 968.83
       Episode_Reward/keep_balance: 0.9762
     Episode_Reward/rew_lin_vel_xy: 6.1956
      Episode_Reward/rew_ang_vel_z: 2.5204
    Episode_Reward/pen_base_height: -0.3010
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1589
   Episode_Reward/pen_joint_torque: -0.2334
    Episode_Reward/pen_joint_accel: -0.1137
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0891
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2540
Episode_Reward/pen_flat_orientation: -0.1033
  Episode_Reward/pen_feet_distance: -0.0221
Episode_Reward/pen_feet_regulation: -0.4788
   Episode_Reward/foot_landing_vel: -0.1365
   Episode_Reward/test_gait_reward: -0.9196
Metrics/base_velocity/error_vel_xy: 0.9336
Metrics/base_velocity/error_vel_yaw: 1.2518
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 163184640
                    Iteration time: 1.09s
                        Total time: 1809.98s
                               ETA: 1462.2s

################################################################################
                     [1m Learning iteration 1660/3000 [0m                     

                       Computation: 90617 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.5249
                    Surrogate loss: -0.0003
             Mean action noise std: 0.8518
                     Learning rate: 0.0001
                       Mean reward: 136.90
               Mean episode length: 982.50
       Episode_Reward/keep_balance: 0.9729
     Episode_Reward/rew_lin_vel_xy: 6.2162
      Episode_Reward/rew_ang_vel_z: 2.5245
    Episode_Reward/pen_base_height: -0.2866
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1572
   Episode_Reward/pen_joint_torque: -0.2245
    Episode_Reward/pen_joint_accel: -0.1028
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0541
   Episode_Reward/pen_joint_powers: -0.0849
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2528
Episode_Reward/pen_flat_orientation: -0.0948
  Episode_Reward/pen_feet_distance: -0.0230
Episode_Reward/pen_feet_regulation: -0.4425
   Episode_Reward/foot_landing_vel: -0.1242
   Episode_Reward/test_gait_reward: -0.9252
Metrics/base_velocity/error_vel_xy: 0.9169
Metrics/base_velocity/error_vel_yaw: 1.2431
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 163282944
                    Iteration time: 1.08s
                        Total time: 1811.07s
                               ETA: 1461.1s

################################################################################
                     [1m Learning iteration 1661/3000 [0m                     

                       Computation: 89711 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.5422
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8521
                     Learning rate: 0.0002
                       Mean reward: 132.47
               Mean episode length: 968.60
       Episode_Reward/keep_balance: 0.9733
     Episode_Reward/rew_lin_vel_xy: 6.2146
      Episode_Reward/rew_ang_vel_z: 2.4939
    Episode_Reward/pen_base_height: -0.3099
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1560
   Episode_Reward/pen_joint_torque: -0.2302
    Episode_Reward/pen_joint_accel: -0.1133
    Episode_Reward/pen_action_rate: -0.1189
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2531
Episode_Reward/pen_flat_orientation: -0.0972
  Episode_Reward/pen_feet_distance: -0.0219
Episode_Reward/pen_feet_regulation: -0.4790
   Episode_Reward/foot_landing_vel: -0.1246
   Episode_Reward/test_gait_reward: -0.9341
Metrics/base_velocity/error_vel_xy: 0.9205
Metrics/base_velocity/error_vel_yaw: 1.2614
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 163381248
                    Iteration time: 1.10s
                        Total time: 1812.17s
                               ETA: 1460.0s

################################################################################
                     [1m Learning iteration 1662/3000 [0m                     

                       Computation: 91280 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.5869
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8511
                     Learning rate: 0.0004
                       Mean reward: 133.27
               Mean episode length: 981.21
       Episode_Reward/keep_balance: 0.9848
     Episode_Reward/rew_lin_vel_xy: 6.2925
      Episode_Reward/rew_ang_vel_z: 2.5071
    Episode_Reward/pen_base_height: -0.3094
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1610
   Episode_Reward/pen_joint_torque: -0.2422
    Episode_Reward/pen_joint_accel: -0.1029
    Episode_Reward/pen_action_rate: -0.1211
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0915
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2596
Episode_Reward/pen_flat_orientation: -0.1027
  Episode_Reward/pen_feet_distance: -0.0190
Episode_Reward/pen_feet_regulation: -0.4875
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.9410
Metrics/base_velocity/error_vel_xy: 0.9447
Metrics/base_velocity/error_vel_yaw: 1.2960
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 163479552
                    Iteration time: 1.08s
                        Total time: 1813.24s
                               ETA: 1458.9s

################################################################################
                     [1m Learning iteration 1663/3000 [0m                     

                       Computation: 89406 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.5306
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8521
                     Learning rate: 0.0009
                       Mean reward: 137.36
               Mean episode length: 993.29
       Episode_Reward/keep_balance: 0.9930
     Episode_Reward/rew_lin_vel_xy: 6.3209
      Episode_Reward/rew_ang_vel_z: 2.5970
    Episode_Reward/pen_base_height: -0.2991
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.1548
   Episode_Reward/pen_joint_torque: -0.2459
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.1214
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2579
Episode_Reward/pen_flat_orientation: -0.0950
  Episode_Reward/pen_feet_distance: -0.0226
Episode_Reward/pen_feet_regulation: -0.4807
   Episode_Reward/foot_landing_vel: -0.1309
   Episode_Reward/test_gait_reward: -0.9448
Metrics/base_velocity/error_vel_xy: 0.9358
Metrics/base_velocity/error_vel_yaw: 1.2420
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 163577856
                    Iteration time: 1.10s
                        Total time: 1814.34s
                               ETA: 1457.8s

################################################################################
                     [1m Learning iteration 1664/3000 [0m                     

                       Computation: 89830 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 0.5595
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8532
                     Learning rate: 0.0001
                       Mean reward: 134.79
               Mean episode length: 983.91
       Episode_Reward/keep_balance: 0.9944
     Episode_Reward/rew_lin_vel_xy: 6.3183
      Episode_Reward/rew_ang_vel_z: 2.5557
    Episode_Reward/pen_base_height: -0.2818
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1613
   Episode_Reward/pen_joint_torque: -0.2222
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2578
Episode_Reward/pen_flat_orientation: -0.0986
  Episode_Reward/pen_feet_distance: -0.0244
Episode_Reward/pen_feet_regulation: -0.4699
   Episode_Reward/foot_landing_vel: -0.1431
   Episode_Reward/test_gait_reward: -0.9374
Metrics/base_velocity/error_vel_xy: 0.9519
Metrics/base_velocity/error_vel_yaw: 1.2806
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 163676160
                    Iteration time: 1.09s
                        Total time: 1815.44s
                               ETA: 1456.7s

################################################################################
                     [1m Learning iteration 1665/3000 [0m                     

                       Computation: 88846 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 0.5833
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8538
                     Learning rate: 0.0004
                       Mean reward: 130.72
               Mean episode length: 972.86
       Episode_Reward/keep_balance: 0.9764
     Episode_Reward/rew_lin_vel_xy: 6.1607
      Episode_Reward/rew_ang_vel_z: 2.5070
    Episode_Reward/pen_base_height: -0.2983
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1606
   Episode_Reward/pen_joint_torque: -0.2377
    Episode_Reward/pen_joint_accel: -0.1116
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0910
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2591
Episode_Reward/pen_flat_orientation: -0.1073
  Episode_Reward/pen_feet_distance: -0.0248
Episode_Reward/pen_feet_regulation: -0.4858
   Episode_Reward/foot_landing_vel: -0.1337
   Episode_Reward/test_gait_reward: -0.9340
Metrics/base_velocity/error_vel_xy: 0.9545
Metrics/base_velocity/error_vel_yaw: 1.2658
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 163774464
                    Iteration time: 1.11s
                        Total time: 1816.54s
                               ETA: 1455.6s

################################################################################
                     [1m Learning iteration 1666/3000 [0m                     

                       Computation: 89804 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.5339
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8542
                     Learning rate: 0.0009
                       Mean reward: 136.05
               Mean episode length: 983.44
       Episode_Reward/keep_balance: 0.9833
     Episode_Reward/rew_lin_vel_xy: 6.3060
      Episode_Reward/rew_ang_vel_z: 2.5512
    Episode_Reward/pen_base_height: -0.3015
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1533
   Episode_Reward/pen_joint_torque: -0.2380
    Episode_Reward/pen_joint_accel: -0.1028
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2559
Episode_Reward/pen_flat_orientation: -0.0981
  Episode_Reward/pen_feet_distance: -0.0224
Episode_Reward/pen_feet_regulation: -0.4615
   Episode_Reward/foot_landing_vel: -0.1239
   Episode_Reward/test_gait_reward: -0.9319
Metrics/base_velocity/error_vel_xy: 0.9164
Metrics/base_velocity/error_vel_yaw: 1.2569
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 163872768
                    Iteration time: 1.09s
                        Total time: 1817.64s
                               ETA: 1454.5s

################################################################################
                     [1m Learning iteration 1667/3000 [0m                     

                       Computation: 88801 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 0.5721
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8539
                     Learning rate: 0.0006
                       Mean reward: 136.66
               Mean episode length: 983.62
       Episode_Reward/keep_balance: 0.9842
     Episode_Reward/rew_lin_vel_xy: 6.3125
      Episode_Reward/rew_ang_vel_z: 2.5906
    Episode_Reward/pen_base_height: -0.3072
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1555
   Episode_Reward/pen_joint_torque: -0.2351
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.1190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2536
Episode_Reward/pen_flat_orientation: -0.0938
  Episode_Reward/pen_feet_distance: -0.0211
Episode_Reward/pen_feet_regulation: -0.4644
   Episode_Reward/foot_landing_vel: -0.1301
   Episode_Reward/test_gait_reward: -0.9390
Metrics/base_velocity/error_vel_xy: 0.9167
Metrics/base_velocity/error_vel_yaw: 1.2160
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 163971072
                    Iteration time: 1.11s
                        Total time: 1818.74s
                               ETA: 1453.5s

################################################################################
                     [1m Learning iteration 1668/3000 [0m                     

                       Computation: 90900 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 0.5371
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8524
                     Learning rate: 0.0006
                       Mean reward: 133.26
               Mean episode length: 982.15
       Episode_Reward/keep_balance: 0.9831
     Episode_Reward/rew_lin_vel_xy: 6.1489
      Episode_Reward/rew_ang_vel_z: 2.5007
    Episode_Reward/pen_base_height: -0.2989
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1649
   Episode_Reward/pen_joint_torque: -0.2298
    Episode_Reward/pen_joint_accel: -0.1132
    Episode_Reward/pen_action_rate: -0.1208
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2580
Episode_Reward/pen_flat_orientation: -0.1004
  Episode_Reward/pen_feet_distance: -0.0209
Episode_Reward/pen_feet_regulation: -0.4652
   Episode_Reward/foot_landing_vel: -0.1350
   Episode_Reward/test_gait_reward: -0.9399
Metrics/base_velocity/error_vel_xy: 0.9820
Metrics/base_velocity/error_vel_yaw: 1.2966
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 164069376
                    Iteration time: 1.08s
                        Total time: 1819.83s
                               ETA: 1452.4s

################################################################################
                     [1m Learning iteration 1669/3000 [0m                     

                       Computation: 88786 steps/s (collection: 0.985s, learning 0.122s)
               Value function loss: 0.5919
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8510
                     Learning rate: 0.0006
                       Mean reward: 135.19
               Mean episode length: 990.02
       Episode_Reward/keep_balance: 0.9862
     Episode_Reward/rew_lin_vel_xy: 6.2956
      Episode_Reward/rew_ang_vel_z: 2.5278
    Episode_Reward/pen_base_height: -0.2944
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1602
   Episode_Reward/pen_joint_torque: -0.2373
    Episode_Reward/pen_joint_accel: -0.1282
    Episode_Reward/pen_action_rate: -0.1218
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2617
Episode_Reward/pen_flat_orientation: -0.0945
  Episode_Reward/pen_feet_distance: -0.0237
Episode_Reward/pen_feet_regulation: -0.4953
   Episode_Reward/foot_landing_vel: -0.1418
   Episode_Reward/test_gait_reward: -0.9451
Metrics/base_velocity/error_vel_xy: 0.9235
Metrics/base_velocity/error_vel_yaw: 1.2778
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 164167680
                    Iteration time: 1.11s
                        Total time: 1820.93s
                               ETA: 1451.3s

################################################################################
                     [1m Learning iteration 1670/3000 [0m                     

                       Computation: 88521 steps/s (collection: 0.988s, learning 0.123s)
               Value function loss: 0.5200
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8499
                     Learning rate: 0.0003
                       Mean reward: 133.07
               Mean episode length: 969.46
       Episode_Reward/keep_balance: 0.9723
     Episode_Reward/rew_lin_vel_xy: 6.2002
      Episode_Reward/rew_ang_vel_z: 2.5128
    Episode_Reward/pen_base_height: -0.2911
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1634
   Episode_Reward/pen_joint_torque: -0.2315
    Episode_Reward/pen_joint_accel: -0.1111
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2540
Episode_Reward/pen_flat_orientation: -0.0999
  Episode_Reward/pen_feet_distance: -0.0229
Episode_Reward/pen_feet_regulation: -0.4561
   Episode_Reward/foot_landing_vel: -0.1375
   Episode_Reward/test_gait_reward: -0.9216
Metrics/base_velocity/error_vel_xy: 0.9167
Metrics/base_velocity/error_vel_yaw: 1.2552
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 164265984
                    Iteration time: 1.11s
                        Total time: 1822.04s
                               ETA: 1450.2s

################################################################################
                     [1m Learning iteration 1671/3000 [0m                     

                       Computation: 90131 steps/s (collection: 0.966s, learning 0.125s)
               Value function loss: 0.5046
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8499
                     Learning rate: 0.0004
                       Mean reward: 138.61
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4097
      Episode_Reward/rew_ang_vel_z: 2.5612
    Episode_Reward/pen_base_height: -0.3051
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1549
   Episode_Reward/pen_joint_torque: -0.2395
    Episode_Reward/pen_joint_accel: -0.1077
    Episode_Reward/pen_action_rate: -0.1213
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2590
Episode_Reward/pen_flat_orientation: -0.0911
  Episode_Reward/pen_feet_distance: -0.0235
Episode_Reward/pen_feet_regulation: -0.4839
   Episode_Reward/foot_landing_vel: -0.1296
   Episode_Reward/test_gait_reward: -0.9499
Metrics/base_velocity/error_vel_xy: 0.9302
Metrics/base_velocity/error_vel_yaw: 1.2988
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 164364288
                    Iteration time: 1.09s
                        Total time: 1823.13s
                               ETA: 1449.1s

################################################################################
                     [1m Learning iteration 1672/3000 [0m                     

                       Computation: 89314 steps/s (collection: 0.977s, learning 0.124s)
               Value function loss: 0.5257
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8497
                     Learning rate: 0.0004
                       Mean reward: 137.84
               Mean episode length: 995.70
       Episode_Reward/keep_balance: 0.9868
     Episode_Reward/rew_lin_vel_xy: 6.2945
      Episode_Reward/rew_ang_vel_z: 2.5666
    Episode_Reward/pen_base_height: -0.2908
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1576
   Episode_Reward/pen_joint_torque: -0.2278
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0556
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2562
Episode_Reward/pen_flat_orientation: -0.0923
  Episode_Reward/pen_feet_distance: -0.0201
Episode_Reward/pen_feet_regulation: -0.4490
   Episode_Reward/foot_landing_vel: -0.1312
   Episode_Reward/test_gait_reward: -0.9295
Metrics/base_velocity/error_vel_xy: 0.9319
Metrics/base_velocity/error_vel_yaw: 1.2428
      Episode_Termination/time_out: 5.3750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 164462592
                    Iteration time: 1.10s
                        Total time: 1824.23s
                               ETA: 1448.0s

################################################################################
                     [1m Learning iteration 1673/3000 [0m                     

                       Computation: 89958 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.5540
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8490
                     Learning rate: 0.0006
                       Mean reward: 135.95
               Mean episode length: 991.50
       Episode_Reward/keep_balance: 0.9978
     Episode_Reward/rew_lin_vel_xy: 6.3718
      Episode_Reward/rew_ang_vel_z: 2.5685
    Episode_Reward/pen_base_height: -0.3020
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1595
   Episode_Reward/pen_joint_torque: -0.2437
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.1236
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2613
Episode_Reward/pen_flat_orientation: -0.0951
  Episode_Reward/pen_feet_distance: -0.0258
Episode_Reward/pen_feet_regulation: -0.4878
   Episode_Reward/foot_landing_vel: -0.1369
   Episode_Reward/test_gait_reward: -0.9522
Metrics/base_velocity/error_vel_xy: 0.9466
Metrics/base_velocity/error_vel_yaw: 1.2738
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 164560896
                    Iteration time: 1.09s
                        Total time: 1825.33s
                               ETA: 1447.0s

################################################################################
                     [1m Learning iteration 1674/3000 [0m                     

                       Computation: 89112 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.5394
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8481
                     Learning rate: 0.0006
                       Mean reward: 137.37
               Mean episode length: 984.50
       Episode_Reward/keep_balance: 0.9890
     Episode_Reward/rew_lin_vel_xy: 6.3237
      Episode_Reward/rew_ang_vel_z: 2.5792
    Episode_Reward/pen_base_height: -0.2801
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1527
   Episode_Reward/pen_joint_torque: -0.2417
    Episode_Reward/pen_joint_accel: -0.1114
    Episode_Reward/pen_action_rate: -0.1195
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2568
Episode_Reward/pen_flat_orientation: -0.0901
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.4342
   Episode_Reward/foot_landing_vel: -0.1436
   Episode_Reward/test_gait_reward: -0.9282
Metrics/base_velocity/error_vel_xy: 0.9103
Metrics/base_velocity/error_vel_yaw: 1.2429
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 164659200
                    Iteration time: 1.10s
                        Total time: 1826.43s
                               ETA: 1445.9s

################################################################################
                     [1m Learning iteration 1675/3000 [0m                     

                       Computation: 89908 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.5741
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8469
                     Learning rate: 0.0004
                       Mean reward: 134.60
               Mean episode length: 981.93
       Episode_Reward/keep_balance: 0.9875
     Episode_Reward/rew_lin_vel_xy: 6.2990
      Episode_Reward/rew_ang_vel_z: 2.5322
    Episode_Reward/pen_base_height: -0.3017
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1630
   Episode_Reward/pen_joint_torque: -0.2381
    Episode_Reward/pen_joint_accel: -0.1057
    Episode_Reward/pen_action_rate: -0.1212
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2564
Episode_Reward/pen_flat_orientation: -0.0961
  Episode_Reward/pen_feet_distance: -0.0243
Episode_Reward/pen_feet_regulation: -0.4948
   Episode_Reward/foot_landing_vel: -0.1414
   Episode_Reward/test_gait_reward: -0.9392
Metrics/base_velocity/error_vel_xy: 0.9288
Metrics/base_velocity/error_vel_yaw: 1.2848
      Episode_Termination/time_out: 4.9583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 164757504
                    Iteration time: 1.09s
                        Total time: 1827.52s
                               ETA: 1444.8s

################################################################################
                     [1m Learning iteration 1676/3000 [0m                     

                       Computation: 89986 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.5025
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8472
                     Learning rate: 0.0006
                       Mean reward: 135.70
               Mean episode length: 989.55
       Episode_Reward/keep_balance: 0.9911
     Episode_Reward/rew_lin_vel_xy: 6.2316
      Episode_Reward/rew_ang_vel_z: 2.5568
    Episode_Reward/pen_base_height: -0.3027
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1577
   Episode_Reward/pen_joint_torque: -0.2523
    Episode_Reward/pen_joint_accel: -0.1061
    Episode_Reward/pen_action_rate: -0.1236
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0930
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2598
Episode_Reward/pen_flat_orientation: -0.0954
  Episode_Reward/pen_feet_distance: -0.0247
Episode_Reward/pen_feet_regulation: -0.5053
   Episode_Reward/foot_landing_vel: -0.1312
   Episode_Reward/test_gait_reward: -0.9499
Metrics/base_velocity/error_vel_xy: 0.9663
Metrics/base_velocity/error_vel_yaw: 1.2702
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 164855808
                    Iteration time: 1.09s
                        Total time: 1828.62s
                               ETA: 1443.7s

################################################################################
                     [1m Learning iteration 1677/3000 [0m                     

                       Computation: 89676 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.5487
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8467
                     Learning rate: 0.0006
                       Mean reward: 134.90
               Mean episode length: 974.82
       Episode_Reward/keep_balance: 0.9679
     Episode_Reward/rew_lin_vel_xy: 6.1701
      Episode_Reward/rew_ang_vel_z: 2.5271
    Episode_Reward/pen_base_height: -0.2887
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1519
   Episode_Reward/pen_joint_torque: -0.2253
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1154
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0853
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2465
Episode_Reward/pen_flat_orientation: -0.0931
  Episode_Reward/pen_feet_distance: -0.0217
Episode_Reward/pen_feet_regulation: -0.4564
   Episode_Reward/foot_landing_vel: -0.1249
   Episode_Reward/test_gait_reward: -0.9167
Metrics/base_velocity/error_vel_xy: 0.9188
Metrics/base_velocity/error_vel_yaw: 1.2169
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 164954112
                    Iteration time: 1.10s
                        Total time: 1829.71s
                               ETA: 1442.6s

################################################################################
                     [1m Learning iteration 1678/3000 [0m                     

                       Computation: 91325 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.5145
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8470
                     Learning rate: 0.0006
                       Mean reward: 133.79
               Mean episode length: 974.06
       Episode_Reward/keep_balance: 0.9726
     Episode_Reward/rew_lin_vel_xy: 6.1635
      Episode_Reward/rew_ang_vel_z: 2.5333
    Episode_Reward/pen_base_height: -0.2934
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1528
   Episode_Reward/pen_joint_torque: -0.2245
    Episode_Reward/pen_joint_accel: -0.1053
    Episode_Reward/pen_action_rate: -0.1168
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2481
Episode_Reward/pen_flat_orientation: -0.0978
  Episode_Reward/pen_feet_distance: -0.0216
Episode_Reward/pen_feet_regulation: -0.4737
   Episode_Reward/foot_landing_vel: -0.1274
   Episode_Reward/test_gait_reward: -0.9216
Metrics/base_velocity/error_vel_xy: 0.9381
Metrics/base_velocity/error_vel_yaw: 1.2385
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 165052416
                    Iteration time: 1.08s
                        Total time: 1830.79s
                               ETA: 1441.5s

################################################################################
                     [1m Learning iteration 1679/3000 [0m                     

                       Computation: 89866 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 0.5057
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8460
                     Learning rate: 0.0006
                       Mean reward: 135.89
               Mean episode length: 983.12
       Episode_Reward/keep_balance: 0.9699
     Episode_Reward/rew_lin_vel_xy: 6.1748
      Episode_Reward/rew_ang_vel_z: 2.5046
    Episode_Reward/pen_base_height: -0.2908
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1530
   Episode_Reward/pen_joint_torque: -0.2386
    Episode_Reward/pen_joint_accel: -0.1106
    Episode_Reward/pen_action_rate: -0.1184
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2527
Episode_Reward/pen_flat_orientation: -0.0993
  Episode_Reward/pen_feet_distance: -0.0251
Episode_Reward/pen_feet_regulation: -0.4716
   Episode_Reward/foot_landing_vel: -0.1244
   Episode_Reward/test_gait_reward: -0.9257
Metrics/base_velocity/error_vel_xy: 0.9192
Metrics/base_velocity/error_vel_yaw: 1.2444
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 165150720
                    Iteration time: 1.09s
                        Total time: 1831.88s
                               ETA: 1440.4s

################################################################################
                     [1m Learning iteration 1680/3000 [0m                     

                       Computation: 89395 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.4757
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8466
                     Learning rate: 0.0006
                       Mean reward: 140.83
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4563
      Episode_Reward/rew_ang_vel_z: 2.6329
    Episode_Reward/pen_base_height: -0.2927
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1577
   Episode_Reward/pen_joint_torque: -0.2439
    Episode_Reward/pen_joint_accel: -0.1112
    Episode_Reward/pen_action_rate: -0.1223
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0911
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2578
Episode_Reward/pen_flat_orientation: -0.0921
  Episode_Reward/pen_feet_distance: -0.0297
Episode_Reward/pen_feet_regulation: -0.4925
   Episode_Reward/foot_landing_vel: -0.1287
   Episode_Reward/test_gait_reward: -0.9554
Metrics/base_velocity/error_vel_xy: 0.9139
Metrics/base_velocity/error_vel_yaw: 1.2323
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 165249024
                    Iteration time: 1.10s
                        Total time: 1832.98s
                               ETA: 1439.3s

################################################################################
                     [1m Learning iteration 1681/3000 [0m                     

                       Computation: 91241 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.5144
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8463
                     Learning rate: 0.0006
                       Mean reward: 141.47
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4521
      Episode_Reward/rew_ang_vel_z: 2.6054
    Episode_Reward/pen_base_height: -0.2818
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1597
   Episode_Reward/pen_joint_torque: -0.2322
    Episode_Reward/pen_joint_accel: -0.1006
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0892
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2589
Episode_Reward/pen_flat_orientation: -0.0904
  Episode_Reward/pen_feet_distance: -0.0232
Episode_Reward/pen_feet_regulation: -0.4722
   Episode_Reward/foot_landing_vel: -0.1325
   Episode_Reward/test_gait_reward: -0.9421
Metrics/base_velocity/error_vel_xy: 0.9067
Metrics/base_velocity/error_vel_yaw: 1.2620
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 165347328
                    Iteration time: 1.08s
                        Total time: 1834.06s
                               ETA: 1438.2s

################################################################################
                     [1m Learning iteration 1682/3000 [0m                     

                       Computation: 91295 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.5779
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8464
                     Learning rate: 0.0006
                       Mean reward: 138.21
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.2786
      Episode_Reward/rew_ang_vel_z: 2.5580
    Episode_Reward/pen_base_height: -0.2983
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.1602
   Episode_Reward/pen_joint_torque: -0.2364
    Episode_Reward/pen_joint_accel: -0.1190
    Episode_Reward/pen_action_rate: -0.1225
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2591
Episode_Reward/pen_flat_orientation: -0.0996
  Episode_Reward/pen_feet_distance: -0.0250
Episode_Reward/pen_feet_regulation: -0.5036
   Episode_Reward/foot_landing_vel: -0.1410
   Episode_Reward/test_gait_reward: -0.9507
Metrics/base_velocity/error_vel_xy: 0.9902
Metrics/base_velocity/error_vel_yaw: 1.3270
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 165445632
                    Iteration time: 1.08s
                        Total time: 1835.14s
                               ETA: 1437.1s

################################################################################
                     [1m Learning iteration 1683/3000 [0m                     

                       Computation: 91636 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.5275
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8453
                     Learning rate: 0.0009
                       Mean reward: 134.15
               Mean episode length: 977.09
       Episode_Reward/keep_balance: 0.9719
     Episode_Reward/rew_lin_vel_xy: 6.1710
      Episode_Reward/rew_ang_vel_z: 2.5066
    Episode_Reward/pen_base_height: -0.2870
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1610
   Episode_Reward/pen_joint_torque: -0.2226
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.1187
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2548
Episode_Reward/pen_flat_orientation: -0.0981
  Episode_Reward/pen_feet_distance: -0.0231
Episode_Reward/pen_feet_regulation: -0.4777
   Episode_Reward/foot_landing_vel: -0.1318
   Episode_Reward/test_gait_reward: -0.9176
Metrics/base_velocity/error_vel_xy: 0.9336
Metrics/base_velocity/error_vel_yaw: 1.2649
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 165543936
                    Iteration time: 1.07s
                        Total time: 1836.21s
                               ETA: 1436.0s

################################################################################
                     [1m Learning iteration 1684/3000 [0m                     

                       Computation: 89721 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 0.5146
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8459
                     Learning rate: 0.0006
                       Mean reward: 136.75
               Mean episode length: 986.43
       Episode_Reward/keep_balance: 0.9795
     Episode_Reward/rew_lin_vel_xy: 6.2689
      Episode_Reward/rew_ang_vel_z: 2.5535
    Episode_Reward/pen_base_height: -0.2885
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1566
   Episode_Reward/pen_joint_torque: -0.2334
    Episode_Reward/pen_joint_accel: -0.1051
    Episode_Reward/pen_action_rate: -0.1172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2500
Episode_Reward/pen_flat_orientation: -0.0962
  Episode_Reward/pen_feet_distance: -0.0237
Episode_Reward/pen_feet_regulation: -0.4729
   Episode_Reward/foot_landing_vel: -0.1222
   Episode_Reward/test_gait_reward: -0.9228
Metrics/base_velocity/error_vel_xy: 0.9255
Metrics/base_velocity/error_vel_yaw: 1.2386
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 165642240
                    Iteration time: 1.10s
                        Total time: 1837.31s
                               ETA: 1435.0s

################################################################################
                     [1m Learning iteration 1685/3000 [0m                     

                       Computation: 91111 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.5186
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8450
                     Learning rate: 0.0004
                       Mean reward: 135.95
               Mean episode length: 996.14
       Episode_Reward/keep_balance: 0.9964
     Episode_Reward/rew_lin_vel_xy: 6.3322
      Episode_Reward/rew_ang_vel_z: 2.5927
    Episode_Reward/pen_base_height: -0.3048
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1613
   Episode_Reward/pen_joint_torque: -0.2465
    Episode_Reward/pen_joint_accel: -0.1158
    Episode_Reward/pen_action_rate: -0.1226
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2587
Episode_Reward/pen_flat_orientation: -0.0980
  Episode_Reward/pen_feet_distance: -0.0325
Episode_Reward/pen_feet_regulation: -0.4855
   Episode_Reward/foot_landing_vel: -0.1457
   Episode_Reward/test_gait_reward: -0.9515
Metrics/base_velocity/error_vel_xy: 0.9444
Metrics/base_velocity/error_vel_yaw: 1.2629
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 165740544
                    Iteration time: 1.08s
                        Total time: 1838.38s
                               ETA: 1433.9s

################################################################################
                     [1m Learning iteration 1686/3000 [0m                     

                       Computation: 89179 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.5357
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8446
                     Learning rate: 0.0003
                       Mean reward: 135.03
               Mean episode length: 977.35
       Episode_Reward/keep_balance: 0.9815
     Episode_Reward/rew_lin_vel_xy: 6.2488
      Episode_Reward/rew_ang_vel_z: 2.5513
    Episode_Reward/pen_base_height: -0.2882
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1593
   Episode_Reward/pen_joint_torque: -0.2303
    Episode_Reward/pen_joint_accel: -0.1196
    Episode_Reward/pen_action_rate: -0.1176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2544
Episode_Reward/pen_flat_orientation: -0.0937
  Episode_Reward/pen_feet_distance: -0.0249
Episode_Reward/pen_feet_regulation: -0.4684
   Episode_Reward/foot_landing_vel: -0.1466
   Episode_Reward/test_gait_reward: -0.9200
Metrics/base_velocity/error_vel_xy: 0.9353
Metrics/base_velocity/error_vel_yaw: 1.2386
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 165838848
                    Iteration time: 1.10s
                        Total time: 1839.49s
                               ETA: 1432.8s

################################################################################
                     [1m Learning iteration 1687/3000 [0m                     

                       Computation: 90535 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.5174
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8431
                     Learning rate: 0.0003
                       Mean reward: 139.44
               Mean episode length: 991.94
       Episode_Reward/keep_balance: 0.9952
     Episode_Reward/rew_lin_vel_xy: 6.3144
      Episode_Reward/rew_ang_vel_z: 2.6076
    Episode_Reward/pen_base_height: -0.2856
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1602
   Episode_Reward/pen_joint_torque: -0.2309
    Episode_Reward/pen_joint_accel: -0.1102
    Episode_Reward/pen_action_rate: -0.1195
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2555
Episode_Reward/pen_flat_orientation: -0.0961
  Episode_Reward/pen_feet_distance: -0.0250
Episode_Reward/pen_feet_regulation: -0.4691
   Episode_Reward/foot_landing_vel: -0.1309
   Episode_Reward/test_gait_reward: -0.9394
Metrics/base_velocity/error_vel_xy: 0.9336
Metrics/base_velocity/error_vel_yaw: 1.2447
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 165937152
                    Iteration time: 1.09s
                        Total time: 1840.57s
                               ETA: 1431.7s

################################################################################
                     [1m Learning iteration 1688/3000 [0m                     

                       Computation: 89990 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.5891
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8426
                     Learning rate: 0.0006
                       Mean reward: 134.33
               Mean episode length: 961.51
       Episode_Reward/keep_balance: 0.9612
     Episode_Reward/rew_lin_vel_xy: 6.1409
      Episode_Reward/rew_ang_vel_z: 2.5202
    Episode_Reward/pen_base_height: -0.2854
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1512
   Episode_Reward/pen_joint_torque: -0.2351
    Episode_Reward/pen_joint_accel: -0.1101
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2459
Episode_Reward/pen_flat_orientation: -0.0999
  Episode_Reward/pen_feet_distance: -0.0245
Episode_Reward/pen_feet_regulation: -0.4638
   Episode_Reward/foot_landing_vel: -0.1341
   Episode_Reward/test_gait_reward: -0.9073
Metrics/base_velocity/error_vel_xy: 0.9038
Metrics/base_velocity/error_vel_yaw: 1.2015
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 166035456
                    Iteration time: 1.09s
                        Total time: 1841.66s
                               ETA: 1430.6s

################################################################################
                     [1m Learning iteration 1689/3000 [0m                     

                       Computation: 89801 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.4991
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8431
                     Learning rate: 0.0003
                       Mean reward: 133.94
               Mean episode length: 959.52
       Episode_Reward/keep_balance: 0.9734
     Episode_Reward/rew_lin_vel_xy: 6.1952
      Episode_Reward/rew_ang_vel_z: 2.5357
    Episode_Reward/pen_base_height: -0.2845
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1561
   Episode_Reward/pen_joint_torque: -0.2213
    Episode_Reward/pen_joint_accel: -0.1029
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0842
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2507
Episode_Reward/pen_flat_orientation: -0.0964
  Episode_Reward/pen_feet_distance: -0.0258
Episode_Reward/pen_feet_regulation: -0.4549
   Episode_Reward/foot_landing_vel: -0.1274
   Episode_Reward/test_gait_reward: -0.9143
Metrics/base_velocity/error_vel_xy: 0.9235
Metrics/base_velocity/error_vel_yaw: 1.2362
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 166133760
                    Iteration time: 1.09s
                        Total time: 1842.76s
                               ETA: 1429.5s

################################################################################
                     [1m Learning iteration 1690/3000 [0m                     

                       Computation: 87608 steps/s (collection: 0.999s, learning 0.124s)
               Value function loss: 0.5170
                    Surrogate loss: -0.0055
             Mean action noise std: 0.8419
                     Learning rate: 0.0004
                       Mean reward: 140.22
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4412
      Episode_Reward/rew_ang_vel_z: 2.5723
    Episode_Reward/pen_base_height: -0.2875
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1537
   Episode_Reward/pen_joint_torque: -0.2379
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2550
Episode_Reward/pen_flat_orientation: -0.0950
  Episode_Reward/pen_feet_distance: -0.0305
Episode_Reward/pen_feet_regulation: -0.4732
   Episode_Reward/foot_landing_vel: -0.1317
   Episode_Reward/test_gait_reward: -0.9375
Metrics/base_velocity/error_vel_xy: 0.9111
Metrics/base_velocity/error_vel_yaw: 1.2854
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 166232064
                    Iteration time: 1.12s
                        Total time: 1843.88s
                               ETA: 1428.4s

################################################################################
                     [1m Learning iteration 1691/3000 [0m                     

                       Computation: 88517 steps/s (collection: 0.986s, learning 0.124s)
               Value function loss: 0.6500
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8414
                     Learning rate: 0.0009
                       Mean reward: 133.46
               Mean episode length: 966.04
       Episode_Reward/keep_balance: 0.9628
     Episode_Reward/rew_lin_vel_xy: 6.1287
      Episode_Reward/rew_ang_vel_z: 2.5012
    Episode_Reward/pen_base_height: -0.3009
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1540
   Episode_Reward/pen_joint_torque: -0.2397
    Episode_Reward/pen_joint_accel: -0.1103
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2464
Episode_Reward/pen_flat_orientation: -0.0965
  Episode_Reward/pen_feet_distance: -0.0283
Episode_Reward/pen_feet_regulation: -0.4791
   Episode_Reward/foot_landing_vel: -0.1286
   Episode_Reward/test_gait_reward: -0.9088
Metrics/base_velocity/error_vel_xy: 0.9052
Metrics/base_velocity/error_vel_yaw: 1.2232
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 166330368
                    Iteration time: 1.11s
                        Total time: 1844.99s
                               ETA: 1427.4s

################################################################################
                     [1m Learning iteration 1692/3000 [0m                     

                       Computation: 91369 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.5860
                    Surrogate loss: -0.0016
             Mean action noise std: 0.8414
                     Learning rate: 0.0003
                       Mean reward: 131.74
               Mean episode length: 979.98
       Episode_Reward/keep_balance: 0.9789
     Episode_Reward/rew_lin_vel_xy: 6.1572
      Episode_Reward/rew_ang_vel_z: 2.4864
    Episode_Reward/pen_base_height: -0.3017
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1685
   Episode_Reward/pen_joint_torque: -0.2409
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.1232
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0602
   Episode_Reward/pen_joint_powers: -0.0925
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2601
Episode_Reward/pen_flat_orientation: -0.1062
  Episode_Reward/pen_feet_distance: -0.0274
Episode_Reward/pen_feet_regulation: -0.5104
   Episode_Reward/foot_landing_vel: -0.1322
   Episode_Reward/test_gait_reward: -0.9362
Metrics/base_velocity/error_vel_xy: 0.9635
Metrics/base_velocity/error_vel_yaw: 1.3079
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 166428672
                    Iteration time: 1.08s
                        Total time: 1846.07s
                               ETA: 1426.3s

################################################################################
                     [1m Learning iteration 1693/3000 [0m                     

                       Computation: 89956 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.4582
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8401
                     Learning rate: 0.0006
                       Mean reward: 138.81
               Mean episode length: 985.61
       Episode_Reward/keep_balance: 0.9861
     Episode_Reward/rew_lin_vel_xy: 6.2743
      Episode_Reward/rew_ang_vel_z: 2.6071
    Episode_Reward/pen_base_height: -0.2892
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1561
   Episode_Reward/pen_joint_torque: -0.2288
    Episode_Reward/pen_joint_accel: -0.1147
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2510
Episode_Reward/pen_flat_orientation: -0.0950
  Episode_Reward/pen_feet_distance: -0.0279
Episode_Reward/pen_feet_regulation: -0.4656
   Episode_Reward/foot_landing_vel: -0.1359
   Episode_Reward/test_gait_reward: -0.9204
Metrics/base_velocity/error_vel_xy: 0.9393
Metrics/base_velocity/error_vel_yaw: 1.2193
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 166526976
                    Iteration time: 1.09s
                        Total time: 1847.16s
                               ETA: 1425.2s

################################################################################
                     [1m Learning iteration 1694/3000 [0m                     

                       Computation: 89899 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.5435
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8402
                     Learning rate: 0.0006
                       Mean reward: 138.03
               Mean episode length: 990.62
       Episode_Reward/keep_balance: 0.9902
     Episode_Reward/rew_lin_vel_xy: 6.2859
      Episode_Reward/rew_ang_vel_z: 2.6092
    Episode_Reward/pen_base_height: -0.2918
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1560
   Episode_Reward/pen_joint_torque: -0.2343
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.1195
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0882
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2519
Episode_Reward/pen_flat_orientation: -0.0979
  Episode_Reward/pen_feet_distance: -0.0276
Episode_Reward/pen_feet_regulation: -0.4929
   Episode_Reward/foot_landing_vel: -0.1286
   Episode_Reward/test_gait_reward: -0.9343
Metrics/base_velocity/error_vel_xy: 0.9508
Metrics/base_velocity/error_vel_yaw: 1.2285
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 166625280
                    Iteration time: 1.09s
                        Total time: 1848.25s
                               ETA: 1424.1s

################################################################################
                     [1m Learning iteration 1695/3000 [0m                     

                       Computation: 89741 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.5878
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8400
                     Learning rate: 0.0004
                       Mean reward: 138.71
               Mean episode length: 988.41
       Episode_Reward/keep_balance: 0.9813
     Episode_Reward/rew_lin_vel_xy: 6.3158
      Episode_Reward/rew_ang_vel_z: 2.5695
    Episode_Reward/pen_base_height: -0.2942
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.1593
   Episode_Reward/pen_joint_torque: -0.2317
    Episode_Reward/pen_joint_accel: -0.1048
    Episode_Reward/pen_action_rate: -0.1176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2484
Episode_Reward/pen_flat_orientation: -0.0971
  Episode_Reward/pen_feet_distance: -0.0223
Episode_Reward/pen_feet_regulation: -0.4538
   Episode_Reward/foot_landing_vel: -0.1185
   Episode_Reward/test_gait_reward: -0.9182
Metrics/base_velocity/error_vel_xy: 0.8968
Metrics/base_velocity/error_vel_yaw: 1.2436
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 166723584
                    Iteration time: 1.10s
                        Total time: 1849.35s
                               ETA: 1423.0s

################################################################################
                     [1m Learning iteration 1696/3000 [0m                     

                       Computation: 89808 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.5191
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8390
                     Learning rate: 0.0004
                       Mean reward: 136.39
               Mean episode length: 990.39
       Episode_Reward/keep_balance: 0.9950
     Episode_Reward/rew_lin_vel_xy: 6.3227
      Episode_Reward/rew_ang_vel_z: 2.5881
    Episode_Reward/pen_base_height: -0.2941
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1612
   Episode_Reward/pen_joint_torque: -0.2497
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1236
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0610
   Episode_Reward/pen_joint_powers: -0.0941
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2593
Episode_Reward/pen_flat_orientation: -0.0979
  Episode_Reward/pen_feet_distance: -0.0332
Episode_Reward/pen_feet_regulation: -0.5145
   Episode_Reward/foot_landing_vel: -0.1391
   Episode_Reward/test_gait_reward: -0.9403
Metrics/base_velocity/error_vel_xy: 0.9516
Metrics/base_velocity/error_vel_yaw: 1.2579
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 166821888
                    Iteration time: 1.09s
                        Total time: 1850.44s
                               ETA: 1421.9s

################################################################################
                     [1m Learning iteration 1697/3000 [0m                     

                       Computation: 90994 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.4674
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8389
                     Learning rate: 0.0002
                       Mean reward: 139.88
               Mean episode length: 992.71
       Episode_Reward/keep_balance: 0.9921
     Episode_Reward/rew_lin_vel_xy: 6.3066
      Episode_Reward/rew_ang_vel_z: 2.6168
    Episode_Reward/pen_base_height: -0.2897
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1588
   Episode_Reward/pen_joint_torque: -0.2348
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.1192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2515
Episode_Reward/pen_flat_orientation: -0.1003
  Episode_Reward/pen_feet_distance: -0.0247
Episode_Reward/pen_feet_regulation: -0.4793
   Episode_Reward/foot_landing_vel: -0.1352
   Episode_Reward/test_gait_reward: -0.9306
Metrics/base_velocity/error_vel_xy: 0.9470
Metrics/base_velocity/error_vel_yaw: 1.2276
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 166920192
                    Iteration time: 1.08s
                        Total time: 1851.52s
                               ETA: 1420.8s

################################################################################
                     [1m Learning iteration 1698/3000 [0m                     

                       Computation: 90134 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.5148
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8385
                     Learning rate: 0.0004
                       Mean reward: 139.66
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4025
      Episode_Reward/rew_ang_vel_z: 2.6347
    Episode_Reward/pen_base_height: -0.2877
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1545
   Episode_Reward/pen_joint_torque: -0.2507
    Episode_Reward/pen_joint_accel: -0.1174
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0927
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2529
Episode_Reward/pen_flat_orientation: -0.0978
  Episode_Reward/pen_feet_distance: -0.0244
Episode_Reward/pen_feet_regulation: -0.4769
   Episode_Reward/foot_landing_vel: -0.1392
   Episode_Reward/test_gait_reward: -0.9424
Metrics/base_velocity/error_vel_xy: 0.9184
Metrics/base_velocity/error_vel_yaw: 1.2330
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 167018496
                    Iteration time: 1.09s
                        Total time: 1852.62s
                               ETA: 1419.7s

################################################################################
                     [1m Learning iteration 1699/3000 [0m                     

                       Computation: 90105 steps/s (collection: 0.966s, learning 0.125s)
               Value function loss: 0.5131
                    Surrogate loss: -0.0051
             Mean action noise std: 0.8373
                     Learning rate: 0.0004
                       Mean reward: 139.14
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 0.9980
     Episode_Reward/rew_lin_vel_xy: 6.3504
      Episode_Reward/rew_ang_vel_z: 2.5987
    Episode_Reward/pen_base_height: -0.2922
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1549
   Episode_Reward/pen_joint_torque: -0.2432
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1214
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0581
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2530
Episode_Reward/pen_flat_orientation: -0.0972
  Episode_Reward/pen_feet_distance: -0.0294
Episode_Reward/pen_feet_regulation: -0.4932
   Episode_Reward/foot_landing_vel: -0.1328
   Episode_Reward/test_gait_reward: -0.9347
Metrics/base_velocity/error_vel_xy: 0.9488
Metrics/base_velocity/error_vel_yaw: 1.2872
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 167116800
                    Iteration time: 1.09s
                        Total time: 1853.71s
                               ETA: 1418.6s

################################################################################
                     [1m Learning iteration 1700/3000 [0m                     

                       Computation: 90068 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.5134
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8391
                     Learning rate: 0.0006
                       Mean reward: 138.56
               Mean episode length: 988.57
       Episode_Reward/keep_balance: 0.9925
     Episode_Reward/rew_lin_vel_xy: 6.3243
      Episode_Reward/rew_ang_vel_z: 2.6126
    Episode_Reward/pen_base_height: -0.2724
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1543
   Episode_Reward/pen_joint_torque: -0.2389
    Episode_Reward/pen_joint_accel: -0.1103
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0558
   Episode_Reward/pen_joint_powers: -0.0882
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2510
Episode_Reward/pen_flat_orientation: -0.0913
  Episode_Reward/pen_feet_distance: -0.0308
Episode_Reward/pen_feet_regulation: -0.4556
   Episode_Reward/foot_landing_vel: -0.1219
   Episode_Reward/test_gait_reward: -0.9299
Metrics/base_velocity/error_vel_xy: 0.9287
Metrics/base_velocity/error_vel_yaw: 1.2256
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 167215104
                    Iteration time: 1.09s
                        Total time: 1854.80s
                               ETA: 1417.5s

################################################################################
                     [1m Learning iteration 1701/3000 [0m                     

                       Computation: 89669 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.5240
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8401
                     Learning rate: 0.0004
                       Mean reward: 138.58
               Mean episode length: 979.96
       Episode_Reward/keep_balance: 0.9801
     Episode_Reward/rew_lin_vel_xy: 6.2634
      Episode_Reward/rew_ang_vel_z: 2.5986
    Episode_Reward/pen_base_height: -0.2771
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1533
   Episode_Reward/pen_joint_torque: -0.2222
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.1149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0845
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2463
Episode_Reward/pen_flat_orientation: -0.0966
  Episode_Reward/pen_feet_distance: -0.0248
Episode_Reward/pen_feet_regulation: -0.4477
   Episode_Reward/foot_landing_vel: -0.1345
   Episode_Reward/test_gait_reward: -0.9124
Metrics/base_velocity/error_vel_xy: 0.9088
Metrics/base_velocity/error_vel_yaw: 1.2014
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 167313408
                    Iteration time: 1.10s
                        Total time: 1855.89s
                               ETA: 1416.5s

################################################################################
                     [1m Learning iteration 1702/3000 [0m                     

                       Computation: 88904 steps/s (collection: 0.979s, learning 0.126s)
               Value function loss: 0.5244
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8401
                     Learning rate: 0.0003
                       Mean reward: 139.85
               Mean episode length: 984.37
       Episode_Reward/keep_balance: 0.9837
     Episode_Reward/rew_lin_vel_xy: 6.3238
      Episode_Reward/rew_ang_vel_z: 2.6015
    Episode_Reward/pen_base_height: -0.2794
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1602
   Episode_Reward/pen_joint_torque: -0.2321
    Episode_Reward/pen_joint_accel: -0.1098
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2489
Episode_Reward/pen_flat_orientation: -0.0980
  Episode_Reward/pen_feet_distance: -0.0293
Episode_Reward/pen_feet_regulation: -0.4670
   Episode_Reward/foot_landing_vel: -0.1154
   Episode_Reward/test_gait_reward: -0.9299
Metrics/base_velocity/error_vel_xy: 0.9047
Metrics/base_velocity/error_vel_yaw: 1.2075
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 167411712
                    Iteration time: 1.11s
                        Total time: 1857.00s
                               ETA: 1415.4s

################################################################################
                     [1m Learning iteration 1703/3000 [0m                     

                       Computation: 90691 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.4829
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8398
                     Learning rate: 0.0004
                       Mean reward: 137.01
               Mean episode length: 991.76
       Episode_Reward/keep_balance: 0.9943
     Episode_Reward/rew_lin_vel_xy: 6.3519
      Episode_Reward/rew_ang_vel_z: 2.5844
    Episode_Reward/pen_base_height: -0.2958
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1557
   Episode_Reward/pen_joint_torque: -0.2355
    Episode_Reward/pen_joint_accel: -0.1149
    Episode_Reward/pen_action_rate: -0.1205
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2539
Episode_Reward/pen_flat_orientation: -0.0949
  Episode_Reward/pen_feet_distance: -0.0323
Episode_Reward/pen_feet_regulation: -0.4869
   Episode_Reward/foot_landing_vel: -0.1314
   Episode_Reward/test_gait_reward: -0.9428
Metrics/base_velocity/error_vel_xy: 0.9321
Metrics/base_velocity/error_vel_yaw: 1.2767
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 167510016
                    Iteration time: 1.08s
                        Total time: 1858.08s
                               ETA: 1414.3s

################################################################################
                     [1m Learning iteration 1704/3000 [0m                     

                       Computation: 90041 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.4958
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8408
                     Learning rate: 0.0006
                       Mean reward: 139.87
               Mean episode length: 991.29
       Episode_Reward/keep_balance: 0.9775
     Episode_Reward/rew_lin_vel_xy: 6.2752
      Episode_Reward/rew_ang_vel_z: 2.5353
    Episode_Reward/pen_base_height: -0.2788
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1577
   Episode_Reward/pen_joint_torque: -0.2356
    Episode_Reward/pen_joint_accel: -0.1004
    Episode_Reward/pen_action_rate: -0.1163
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0882
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2488
Episode_Reward/pen_flat_orientation: -0.0960
  Episode_Reward/pen_feet_distance: -0.0223
Episode_Reward/pen_feet_regulation: -0.4719
   Episode_Reward/foot_landing_vel: -0.1290
   Episode_Reward/test_gait_reward: -0.9130
Metrics/base_velocity/error_vel_xy: 0.9051
Metrics/base_velocity/error_vel_yaw: 1.2413
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 167608320
                    Iteration time: 1.09s
                        Total time: 1859.18s
                               ETA: 1413.2s

################################################################################
                     [1m Learning iteration 1705/3000 [0m                     

                       Computation: 89803 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.5643
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8405
                     Learning rate: 0.0009
                       Mean reward: 130.37
               Mean episode length: 965.08
       Episode_Reward/keep_balance: 0.9290
     Episode_Reward/rew_lin_vel_xy: 5.8456
      Episode_Reward/rew_ang_vel_z: 2.4447
    Episode_Reward/pen_base_height: -0.2930
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1517
   Episode_Reward/pen_joint_torque: -0.2350
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.1143
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2372
Episode_Reward/pen_flat_orientation: -0.1020
  Episode_Reward/pen_feet_distance: -0.0274
Episode_Reward/pen_feet_regulation: -0.4783
   Episode_Reward/foot_landing_vel: -0.1252
   Episode_Reward/test_gait_reward: -0.8841
Metrics/base_velocity/error_vel_xy: 0.9396
Metrics/base_velocity/error_vel_yaw: 1.1575
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 167706624
                    Iteration time: 1.09s
                        Total time: 1860.27s
                               ETA: 1412.1s

################################################################################
                     [1m Learning iteration 1706/3000 [0m                     

                       Computation: 89732 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.5171
                    Surrogate loss: -0.0014
             Mean action noise std: 0.8395
                     Learning rate: 0.0004
                       Mean reward: 135.82
               Mean episode length: 983.40
       Episode_Reward/keep_balance: 0.9719
     Episode_Reward/rew_lin_vel_xy: 6.1389
      Episode_Reward/rew_ang_vel_z: 2.5772
    Episode_Reward/pen_base_height: -0.2796
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1531
   Episode_Reward/pen_joint_torque: -0.2243
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0558
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2450
Episode_Reward/pen_flat_orientation: -0.1004
  Episode_Reward/pen_feet_distance: -0.0222
Episode_Reward/pen_feet_regulation: -0.4514
   Episode_Reward/foot_landing_vel: -0.1407
   Episode_Reward/test_gait_reward: -0.8995
Metrics/base_velocity/error_vel_xy: 0.9471
Metrics/base_velocity/error_vel_yaw: 1.1892
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 167804928
                    Iteration time: 1.10s
                        Total time: 1861.37s
                               ETA: 1411.0s

################################################################################
                     [1m Learning iteration 1707/3000 [0m                     

                       Computation: 90314 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 0.4958
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8379
                     Learning rate: 0.0006
                       Mean reward: 136.18
               Mean episode length: 983.27
       Episode_Reward/keep_balance: 0.9859
     Episode_Reward/rew_lin_vel_xy: 6.2769
      Episode_Reward/rew_ang_vel_z: 2.5545
    Episode_Reward/pen_base_height: -0.2825
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1532
   Episode_Reward/pen_joint_torque: -0.2408
    Episode_Reward/pen_joint_accel: -0.1100
    Episode_Reward/pen_action_rate: -0.1202
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0908
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2529
Episode_Reward/pen_flat_orientation: -0.0965
  Episode_Reward/pen_feet_distance: -0.0288
Episode_Reward/pen_feet_regulation: -0.5041
   Episode_Reward/foot_landing_vel: -0.1295
   Episode_Reward/test_gait_reward: -0.9380
Metrics/base_velocity/error_vel_xy: 0.9341
Metrics/base_velocity/error_vel_yaw: 1.2478
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 167903232
                    Iteration time: 1.09s
                        Total time: 1862.45s
                               ETA: 1409.9s

################################################################################
                     [1m Learning iteration 1708/3000 [0m                     

                       Computation: 89710 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 0.5828
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8379
                     Learning rate: 0.0006
                       Mean reward: 141.00
               Mean episode length: 995.97
       Episode_Reward/keep_balance: 0.9979
     Episode_Reward/rew_lin_vel_xy: 6.4129
      Episode_Reward/rew_ang_vel_z: 2.6607
    Episode_Reward/pen_base_height: -0.2888
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1563
   Episode_Reward/pen_joint_torque: -0.2360
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0879
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2522
Episode_Reward/pen_flat_orientation: -0.0946
  Episode_Reward/pen_feet_distance: -0.0280
Episode_Reward/pen_feet_regulation: -0.4743
   Episode_Reward/foot_landing_vel: -0.1210
   Episode_Reward/test_gait_reward: -0.9338
Metrics/base_velocity/error_vel_xy: 0.9175
Metrics/base_velocity/error_vel_yaw: 1.2046
      Episode_Termination/time_out: 4.9583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 168001536
                    Iteration time: 1.10s
                        Total time: 1863.55s
                               ETA: 1408.8s

################################################################################
                     [1m Learning iteration 1709/3000 [0m                     

                       Computation: 90136 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.6015
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8380
                     Learning rate: 0.0004
                       Mean reward: 137.73
               Mean episode length: 990.22
       Episode_Reward/keep_balance: 0.9900
     Episode_Reward/rew_lin_vel_xy: 6.3233
      Episode_Reward/rew_ang_vel_z: 2.6064
    Episode_Reward/pen_base_height: -0.2776
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1584
   Episode_Reward/pen_joint_torque: -0.2290
    Episode_Reward/pen_joint_accel: -0.1076
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2490
Episode_Reward/pen_flat_orientation: -0.0970
  Episode_Reward/pen_feet_distance: -0.0276
Episode_Reward/pen_feet_regulation: -0.4722
   Episode_Reward/foot_landing_vel: -0.1298
   Episode_Reward/test_gait_reward: -0.9310
Metrics/base_velocity/error_vel_xy: 0.9230
Metrics/base_velocity/error_vel_yaw: 1.2340
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 168099840
                    Iteration time: 1.09s
                        Total time: 1864.64s
                               ETA: 1407.7s

################################################################################
                     [1m Learning iteration 1710/3000 [0m                     

                       Computation: 88610 steps/s (collection: 0.986s, learning 0.124s)
               Value function loss: 0.5254
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8382
                     Learning rate: 0.0006
                       Mean reward: 134.06
               Mean episode length: 967.87
       Episode_Reward/keep_balance: 0.9675
     Episode_Reward/rew_lin_vel_xy: 6.0662
      Episode_Reward/rew_ang_vel_z: 2.5117
    Episode_Reward/pen_base_height: -0.2932
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.1609
   Episode_Reward/pen_joint_torque: -0.2275
    Episode_Reward/pen_joint_accel: -0.1100
    Episode_Reward/pen_action_rate: -0.1167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2478
Episode_Reward/pen_flat_orientation: -0.1045
  Episode_Reward/pen_feet_distance: -0.0262
Episode_Reward/pen_feet_regulation: -0.4789
   Episode_Reward/foot_landing_vel: -0.1342
   Episode_Reward/test_gait_reward: -0.9048
Metrics/base_velocity/error_vel_xy: 0.9569
Metrics/base_velocity/error_vel_yaw: 1.2369
      Episode_Termination/time_out: 3.2500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 168198144
                    Iteration time: 1.11s
                        Total time: 1865.75s
                               ETA: 1406.7s

################################################################################
                     [1m Learning iteration 1711/3000 [0m                     

                       Computation: 90716 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.5267
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8390
                     Learning rate: 0.0003
                       Mean reward: 142.32
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4287
      Episode_Reward/rew_ang_vel_z: 2.6224
    Episode_Reward/pen_base_height: -0.2797
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1557
   Episode_Reward/pen_joint_torque: -0.2312
    Episode_Reward/pen_joint_accel: -0.1138
    Episode_Reward/pen_action_rate: -0.1189
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2531
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0218
Episode_Reward/pen_feet_regulation: -0.4694
   Episode_Reward/foot_landing_vel: -0.1298
   Episode_Reward/test_gait_reward: -0.9399
Metrics/base_velocity/error_vel_xy: 0.9280
Metrics/base_velocity/error_vel_yaw: 1.2497
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 168296448
                    Iteration time: 1.08s
                        Total time: 1866.83s
                               ETA: 1405.6s

################################################################################
                     [1m Learning iteration 1712/3000 [0m                     

                       Computation: 91106 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.5429
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8386
                     Learning rate: 0.0003
                       Mean reward: 139.38
               Mean episode length: 988.18
       Episode_Reward/keep_balance: 0.9877
     Episode_Reward/rew_lin_vel_xy: 6.3361
      Episode_Reward/rew_ang_vel_z: 2.6016
    Episode_Reward/pen_base_height: -0.2836
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1561
   Episode_Reward/pen_joint_torque: -0.2302
    Episode_Reward/pen_joint_accel: -0.0976
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0869
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2478
Episode_Reward/pen_flat_orientation: -0.0928
  Episode_Reward/pen_feet_distance: -0.0239
Episode_Reward/pen_feet_regulation: -0.4564
   Episode_Reward/foot_landing_vel: -0.1228
   Episode_Reward/test_gait_reward: -0.9328
Metrics/base_velocity/error_vel_xy: 0.9150
Metrics/base_velocity/error_vel_yaw: 1.2286
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 168394752
                    Iteration time: 1.08s
                        Total time: 1867.91s
                               ETA: 1404.5s

################################################################################
                     [1m Learning iteration 1713/3000 [0m                     

                       Computation: 89049 steps/s (collection: 0.980s, learning 0.124s)
               Value function loss: 0.5323
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8370
                     Learning rate: 0.0006
                       Mean reward: 138.40
               Mean episode length: 991.46
       Episode_Reward/keep_balance: 0.9952
     Episode_Reward/rew_lin_vel_xy: 6.3893
      Episode_Reward/rew_ang_vel_z: 2.6306
    Episode_Reward/pen_base_height: -0.2912
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1524
   Episode_Reward/pen_joint_torque: -0.2383
    Episode_Reward/pen_joint_accel: -0.1127
    Episode_Reward/pen_action_rate: -0.1179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0882
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2503
Episode_Reward/pen_flat_orientation: -0.0913
  Episode_Reward/pen_feet_distance: -0.0232
Episode_Reward/pen_feet_regulation: -0.4747
   Episode_Reward/foot_landing_vel: -0.1221
   Episode_Reward/test_gait_reward: -0.9324
Metrics/base_velocity/error_vel_xy: 0.9130
Metrics/base_velocity/error_vel_yaw: 1.2238
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 168493056
                    Iteration time: 1.10s
                        Total time: 1869.02s
                               ETA: 1403.4s

################################################################################
                     [1m Learning iteration 1714/3000 [0m                     

                       Computation: 88255 steps/s (collection: 0.990s, learning 0.123s)
               Value function loss: 0.5487
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8376
                     Learning rate: 0.0004
                       Mean reward: 138.80
               Mean episode length: 986.42
       Episode_Reward/keep_balance: 0.9891
     Episode_Reward/rew_lin_vel_xy: 6.3466
      Episode_Reward/rew_ang_vel_z: 2.6305
    Episode_Reward/pen_base_height: -0.2740
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1581
   Episode_Reward/pen_joint_torque: -0.2271
    Episode_Reward/pen_joint_accel: -0.1086
    Episode_Reward/pen_action_rate: -0.1164
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0858
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2489
Episode_Reward/pen_flat_orientation: -0.0919
  Episode_Reward/pen_feet_distance: -0.0220
Episode_Reward/pen_feet_regulation: -0.4586
   Episode_Reward/foot_landing_vel: -0.1276
   Episode_Reward/test_gait_reward: -0.9210
Metrics/base_velocity/error_vel_xy: 0.8986
Metrics/base_velocity/error_vel_yaw: 1.1963
      Episode_Termination/time_out: 5.0417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 168591360
                    Iteration time: 1.11s
                        Total time: 1870.13s
                               ETA: 1402.3s

################################################################################
                     [1m Learning iteration 1715/3000 [0m                     

                       Computation: 89823 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: 0.5480
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8387
                     Learning rate: 0.0003
                       Mean reward: 139.75
               Mean episode length: 990.63
       Episode_Reward/keep_balance: 0.9912
     Episode_Reward/rew_lin_vel_xy: 6.4084
      Episode_Reward/rew_ang_vel_z: 2.6036
    Episode_Reward/pen_base_height: -0.2800
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1534
   Episode_Reward/pen_joint_torque: -0.2437
    Episode_Reward/pen_joint_accel: -0.1072
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2493
Episode_Reward/pen_flat_orientation: -0.0972
  Episode_Reward/pen_feet_distance: -0.0272
Episode_Reward/pen_feet_regulation: -0.4792
   Episode_Reward/foot_landing_vel: -0.1352
   Episode_Reward/test_gait_reward: -0.9191
Metrics/base_velocity/error_vel_xy: 0.8823
Metrics/base_velocity/error_vel_yaw: 1.2290
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 168689664
                    Iteration time: 1.09s
                        Total time: 1871.22s
                               ETA: 1401.2s

################################################################################
                     [1m Learning iteration 1716/3000 [0m                     

                       Computation: 89290 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.5354
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8388
                     Learning rate: 0.0004
                       Mean reward: 138.90
               Mean episode length: 989.02
       Episode_Reward/keep_balance: 0.9874
     Episode_Reward/rew_lin_vel_xy: 6.2966
      Episode_Reward/rew_ang_vel_z: 2.6132
    Episode_Reward/pen_base_height: -0.2799
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.1546
   Episode_Reward/pen_joint_torque: -0.2370
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2502
Episode_Reward/pen_flat_orientation: -0.0945
  Episode_Reward/pen_feet_distance: -0.0254
Episode_Reward/pen_feet_regulation: -0.4642
   Episode_Reward/foot_landing_vel: -0.1402
   Episode_Reward/test_gait_reward: -0.9214
Metrics/base_velocity/error_vel_xy: 0.9234
Metrics/base_velocity/error_vel_yaw: 1.2061
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 168787968
                    Iteration time: 1.10s
                        Total time: 1872.33s
                               ETA: 1400.2s

################################################################################
                     [1m Learning iteration 1717/3000 [0m                     

                       Computation: 90962 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.4946
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8378
                     Learning rate: 0.0002
                       Mean reward: 134.99
               Mean episode length: 976.15
       Episode_Reward/keep_balance: 0.9699
     Episode_Reward/rew_lin_vel_xy: 6.0788
      Episode_Reward/rew_ang_vel_z: 2.5273
    Episode_Reward/pen_base_height: -0.3001
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1574
   Episode_Reward/pen_joint_torque: -0.2370
    Episode_Reward/pen_joint_accel: -0.1014
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0897
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2450
Episode_Reward/pen_flat_orientation: -0.1044
  Episode_Reward/pen_feet_distance: -0.0244
Episode_Reward/pen_feet_regulation: -0.4953
   Episode_Reward/foot_landing_vel: -0.1220
   Episode_Reward/test_gait_reward: -0.9188
Metrics/base_velocity/error_vel_xy: 0.9731
Metrics/base_velocity/error_vel_yaw: 1.2400
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 168886272
                    Iteration time: 1.08s
                        Total time: 1873.41s
                               ETA: 1399.1s

################################################################################
                     [1m Learning iteration 1718/3000 [0m                     

                       Computation: 91651 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.4840
                    Surrogate loss: -0.0057
             Mean action noise std: 0.8369
                     Learning rate: 0.0004
                       Mean reward: 138.04
               Mean episode length: 978.68
       Episode_Reward/keep_balance: 0.9815
     Episode_Reward/rew_lin_vel_xy: 6.3318
      Episode_Reward/rew_ang_vel_z: 2.5907
    Episode_Reward/pen_base_height: -0.2789
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1579
   Episode_Reward/pen_joint_torque: -0.2356
    Episode_Reward/pen_joint_accel: -0.1061
    Episode_Reward/pen_action_rate: -0.1182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2506
Episode_Reward/pen_flat_orientation: -0.0934
  Episode_Reward/pen_feet_distance: -0.0265
Episode_Reward/pen_feet_regulation: -0.4787
   Episode_Reward/foot_landing_vel: -0.1286
   Episode_Reward/test_gait_reward: -0.9200
Metrics/base_velocity/error_vel_xy: 0.8927
Metrics/base_velocity/error_vel_yaw: 1.2138
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 168984576
                    Iteration time: 1.07s
                        Total time: 1874.48s
                               ETA: 1398.0s

################################################################################
                     [1m Learning iteration 1719/3000 [0m                     

                       Computation: 90366 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.5783
                    Surrogate loss: -0.0016
             Mean action noise std: 0.8371
                     Learning rate: 0.0004
                       Mean reward: 140.36
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.3249
      Episode_Reward/rew_ang_vel_z: 2.6512
    Episode_Reward/pen_base_height: -0.2869
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.1529
   Episode_Reward/pen_joint_torque: -0.2379
    Episode_Reward/pen_joint_accel: -0.1068
    Episode_Reward/pen_action_rate: -0.1182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2488
Episode_Reward/pen_flat_orientation: -0.0930
  Episode_Reward/pen_feet_distance: -0.0306
Episode_Reward/pen_feet_regulation: -0.4840
   Episode_Reward/foot_landing_vel: -0.1272
   Episode_Reward/test_gait_reward: -0.9352
Metrics/base_velocity/error_vel_xy: 0.9710
Metrics/base_velocity/error_vel_yaw: 1.2268
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 169082880
                    Iteration time: 1.09s
                        Total time: 1875.57s
                               ETA: 1396.9s

################################################################################
                     [1m Learning iteration 1720/3000 [0m                     

                       Computation: 90970 steps/s (collection: 0.957s, learning 0.124s)
               Value function loss: 0.5358
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8375
                     Learning rate: 0.0006
                       Mean reward: 136.69
               Mean episode length: 981.39
       Episode_Reward/keep_balance: 0.9832
     Episode_Reward/rew_lin_vel_xy: 6.2088
      Episode_Reward/rew_ang_vel_z: 2.5705
    Episode_Reward/pen_base_height: -0.2783
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1525
   Episode_Reward/pen_joint_torque: -0.2220
    Episode_Reward/pen_joint_accel: -0.1027
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0847
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2480
Episode_Reward/pen_flat_orientation: -0.0991
  Episode_Reward/pen_feet_distance: -0.0267
Episode_Reward/pen_feet_regulation: -0.4772
   Episode_Reward/foot_landing_vel: -0.1229
   Episode_Reward/test_gait_reward: -0.9211
Metrics/base_velocity/error_vel_xy: 0.9523
Metrics/base_velocity/error_vel_yaw: 1.2415
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 169181184
                    Iteration time: 1.08s
                        Total time: 1876.65s
                               ETA: 1395.8s

################################################################################
                     [1m Learning iteration 1721/3000 [0m                     

                       Computation: 90481 steps/s (collection: 0.961s, learning 0.126s)
               Value function loss: 0.5390
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8381
                     Learning rate: 0.0009
                       Mean reward: 134.25
               Mean episode length: 976.63
       Episode_Reward/keep_balance: 0.9868
     Episode_Reward/rew_lin_vel_xy: 6.2982
      Episode_Reward/rew_ang_vel_z: 2.6034
    Episode_Reward/pen_base_height: -0.2961
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1499
   Episode_Reward/pen_joint_torque: -0.2397
    Episode_Reward/pen_joint_accel: -0.1088
    Episode_Reward/pen_action_rate: -0.1167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2468
Episode_Reward/pen_flat_orientation: -0.1006
  Episode_Reward/pen_feet_distance: -0.0243
Episode_Reward/pen_feet_regulation: -0.4601
   Episode_Reward/foot_landing_vel: -0.1204
   Episode_Reward/test_gait_reward: -0.9315
Metrics/base_velocity/error_vel_xy: 0.9476
Metrics/base_velocity/error_vel_yaw: 1.2275
      Episode_Termination/time_out: 3.1250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 169279488
                    Iteration time: 1.09s
                        Total time: 1877.73s
                               ETA: 1394.7s

################################################################################
                     [1m Learning iteration 1722/3000 [0m                     

                       Computation: 88622 steps/s (collection: 0.984s, learning 0.125s)
               Value function loss: 0.5770
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8379
                     Learning rate: 0.0006
                       Mean reward: 135.16
               Mean episode length: 965.46
       Episode_Reward/keep_balance: 0.9725
     Episode_Reward/rew_lin_vel_xy: 6.2109
      Episode_Reward/rew_ang_vel_z: 2.5826
    Episode_Reward/pen_base_height: -0.2832
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1539
   Episode_Reward/pen_joint_torque: -0.2408
    Episode_Reward/pen_joint_accel: -0.1076
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0899
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2457
Episode_Reward/pen_flat_orientation: -0.0984
  Episode_Reward/pen_feet_distance: -0.0261
Episode_Reward/pen_feet_regulation: -0.4659
   Episode_Reward/foot_landing_vel: -0.1215
   Episode_Reward/test_gait_reward: -0.9172
Metrics/base_velocity/error_vel_xy: 0.9160
Metrics/base_velocity/error_vel_yaw: 1.1827
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 169377792
                    Iteration time: 1.11s
                        Total time: 1878.84s
                               ETA: 1393.6s

################################################################################
                     [1m Learning iteration 1723/3000 [0m                     

                       Computation: 91396 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.5379
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8374
                     Learning rate: 0.0006
                       Mean reward: 136.35
               Mean episode length: 979.16
       Episode_Reward/keep_balance: 0.9854
     Episode_Reward/rew_lin_vel_xy: 6.2476
      Episode_Reward/rew_ang_vel_z: 2.5660
    Episode_Reward/pen_base_height: -0.2784
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1583
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2504
Episode_Reward/pen_flat_orientation: -0.0971
  Episode_Reward/pen_feet_distance: -0.0270
Episode_Reward/pen_feet_regulation: -0.4802
   Episode_Reward/foot_landing_vel: -0.1300
   Episode_Reward/test_gait_reward: -0.9209
Metrics/base_velocity/error_vel_xy: 0.9489
Metrics/base_velocity/error_vel_yaw: 1.2591
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 169476096
                    Iteration time: 1.08s
                        Total time: 1879.92s
                               ETA: 1392.5s

################################################################################
                     [1m Learning iteration 1724/3000 [0m                     

                       Computation: 91068 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.5630
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8384
                     Learning rate: 0.0009
                       Mean reward: 141.19
               Mean episode length: 983.40
       Episode_Reward/keep_balance: 0.9871
     Episode_Reward/rew_lin_vel_xy: 6.4038
      Episode_Reward/rew_ang_vel_z: 2.6541
    Episode_Reward/pen_base_height: -0.2679
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1482
   Episode_Reward/pen_joint_torque: -0.2239
    Episode_Reward/pen_joint_accel: -0.1078
    Episode_Reward/pen_action_rate: -0.1137
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0522
   Episode_Reward/pen_joint_powers: -0.0817
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2429
Episode_Reward/pen_flat_orientation: -0.0867
  Episode_Reward/pen_feet_distance: -0.0228
Episode_Reward/pen_feet_regulation: -0.4341
   Episode_Reward/foot_landing_vel: -0.1212
   Episode_Reward/test_gait_reward: -0.9173
Metrics/base_velocity/error_vel_xy: 0.8729
Metrics/base_velocity/error_vel_yaw: 1.1756
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 169574400
                    Iteration time: 1.08s
                        Total time: 1881.00s
                               ETA: 1391.4s

################################################################################
                     [1m Learning iteration 1725/3000 [0m                     

                       Computation: 91489 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.6392
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8391
                     Learning rate: 0.0006
                       Mean reward: 138.93
               Mean episode length: 990.23
       Episode_Reward/keep_balance: 0.9924
     Episode_Reward/rew_lin_vel_xy: 6.3219
      Episode_Reward/rew_ang_vel_z: 2.6078
    Episode_Reward/pen_base_height: -0.2733
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1598
   Episode_Reward/pen_joint_torque: -0.2262
    Episode_Reward/pen_joint_accel: -0.1081
    Episode_Reward/pen_action_rate: -0.1179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2527
Episode_Reward/pen_flat_orientation: -0.0930
  Episode_Reward/pen_feet_distance: -0.0237
Episode_Reward/pen_feet_regulation: -0.4859
   Episode_Reward/foot_landing_vel: -0.1207
   Episode_Reward/test_gait_reward: -0.9269
Metrics/base_velocity/error_vel_xy: 0.9370
Metrics/base_velocity/error_vel_yaw: 1.2286
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 169672704
                    Iteration time: 1.07s
                        Total time: 1882.07s
                               ETA: 1390.3s

################################################################################
                     [1m Learning iteration 1726/3000 [0m                     

                       Computation: 88696 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 0.5562
                    Surrogate loss: -0.0012
             Mean action noise std: 0.8381
                     Learning rate: 0.0004
                       Mean reward: 138.41
               Mean episode length: 982.14
       Episode_Reward/keep_balance: 0.9873
     Episode_Reward/rew_lin_vel_xy: 6.3475
      Episode_Reward/rew_ang_vel_z: 2.6431
    Episode_Reward/pen_base_height: -0.2799
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1533
   Episode_Reward/pen_joint_torque: -0.2383
    Episode_Reward/pen_joint_accel: -0.0969
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0541
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2445
Episode_Reward/pen_flat_orientation: -0.0910
  Episode_Reward/pen_feet_distance: -0.0277
Episode_Reward/pen_feet_regulation: -0.4689
   Episode_Reward/foot_landing_vel: -0.1247
   Episode_Reward/test_gait_reward: -0.9182
Metrics/base_velocity/error_vel_xy: 0.9113
Metrics/base_velocity/error_vel_yaw: 1.1788
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 169771008
                    Iteration time: 1.11s
                        Total time: 1883.18s
                               ETA: 1389.2s

################################################################################
                     [1m Learning iteration 1727/3000 [0m                     

                       Computation: 90195 steps/s (collection: 0.965s, learning 0.125s)
               Value function loss: 0.4816
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8376
                     Learning rate: 0.0006
                       Mean reward: 138.29
               Mean episode length: 996.78
       Episode_Reward/keep_balance: 0.9974
     Episode_Reward/rew_lin_vel_xy: 6.3336
      Episode_Reward/rew_ang_vel_z: 2.6415
    Episode_Reward/pen_base_height: -0.2944
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1533
   Episode_Reward/pen_joint_torque: -0.2436
    Episode_Reward/pen_joint_accel: -0.1110
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2475
Episode_Reward/pen_flat_orientation: -0.0992
  Episode_Reward/pen_feet_distance: -0.0212
Episode_Reward/pen_feet_regulation: -0.4703
   Episode_Reward/foot_landing_vel: -0.1289
   Episode_Reward/test_gait_reward: -0.9379
Metrics/base_velocity/error_vel_xy: 0.9523
Metrics/base_velocity/error_vel_yaw: 1.2300
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 169869312
                    Iteration time: 1.09s
                        Total time: 1884.27s
                               ETA: 1388.1s

################################################################################
                     [1m Learning iteration 1728/3000 [0m                     

                       Computation: 88559 steps/s (collection: 0.986s, learning 0.124s)
               Value function loss: 0.5770
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8375
                     Learning rate: 0.0006
                       Mean reward: 135.19
               Mean episode length: 972.75
       Episode_Reward/keep_balance: 0.9796
     Episode_Reward/rew_lin_vel_xy: 6.2460
      Episode_Reward/rew_ang_vel_z: 2.5562
    Episode_Reward/pen_base_height: -0.2737
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.1605
   Episode_Reward/pen_joint_torque: -0.2229
    Episode_Reward/pen_joint_accel: -0.1157
    Episode_Reward/pen_action_rate: -0.1154
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0856
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2479
Episode_Reward/pen_flat_orientation: -0.0934
  Episode_Reward/pen_feet_distance: -0.0222
Episode_Reward/pen_feet_regulation: -0.4866
   Episode_Reward/foot_landing_vel: -0.1377
   Episode_Reward/test_gait_reward: -0.9141
Metrics/base_velocity/error_vel_xy: 0.9177
Metrics/base_velocity/error_vel_yaw: 1.2294
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 169967616
                    Iteration time: 1.11s
                        Total time: 1885.38s
                               ETA: 1387.0s

################################################################################
                     [1m Learning iteration 1729/3000 [0m                     

                       Computation: 89891 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.5931
                    Surrogate loss: 0.0034
             Mean action noise std: 0.8372
                     Learning rate: 0.0000
                       Mean reward: 133.71
               Mean episode length: 966.35
       Episode_Reward/keep_balance: 0.9749
     Episode_Reward/rew_lin_vel_xy: 6.1809
      Episode_Reward/rew_ang_vel_z: 2.5728
    Episode_Reward/pen_base_height: -0.2799
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1566
   Episode_Reward/pen_joint_torque: -0.2317
    Episode_Reward/pen_joint_accel: -0.1091
    Episode_Reward/pen_action_rate: -0.1168
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2476
Episode_Reward/pen_flat_orientation: -0.0999
  Episode_Reward/pen_feet_distance: -0.0235
Episode_Reward/pen_feet_regulation: -0.4750
   Episode_Reward/foot_landing_vel: -0.1266
   Episode_Reward/test_gait_reward: -0.9147
Metrics/base_velocity/error_vel_xy: 0.9400
Metrics/base_velocity/error_vel_yaw: 1.2057
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 170065920
                    Iteration time: 1.09s
                        Total time: 1886.47s
                               ETA: 1386.0s

################################################################################
                     [1m Learning iteration 1730/3000 [0m                     

                       Computation: 89855 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.5454
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8367
                     Learning rate: 0.0002
                       Mean reward: 136.93
               Mean episode length: 968.84
       Episode_Reward/keep_balance: 0.9716
     Episode_Reward/rew_lin_vel_xy: 6.1922
      Episode_Reward/rew_ang_vel_z: 2.5843
    Episode_Reward/pen_base_height: -0.2895
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.1518
   Episode_Reward/pen_joint_torque: -0.2271
    Episode_Reward/pen_joint_accel: -0.1017
    Episode_Reward/pen_action_rate: -0.1145
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0846
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2424
Episode_Reward/pen_flat_orientation: -0.0961
  Episode_Reward/pen_feet_distance: -0.0232
Episode_Reward/pen_feet_regulation: -0.4643
   Episode_Reward/foot_landing_vel: -0.1251
   Episode_Reward/test_gait_reward: -0.9102
Metrics/base_velocity/error_vel_xy: 0.9142
Metrics/base_velocity/error_vel_yaw: 1.1848
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 170164224
                    Iteration time: 1.09s
                        Total time: 1887.57s
                               ETA: 1384.9s

################################################################################
                     [1m Learning iteration 1731/3000 [0m                     

                       Computation: 90339 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.5178
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8347
                     Learning rate: 0.0006
                       Mean reward: 137.29
               Mean episode length: 980.21
       Episode_Reward/keep_balance: 0.9856
     Episode_Reward/rew_lin_vel_xy: 6.3187
      Episode_Reward/rew_ang_vel_z: 2.5441
    Episode_Reward/pen_base_height: -0.2738
      Episode_Reward/pen_lin_vel_z: -0.0341
     Episode_Reward/pen_ang_vel_xy: -0.1574
   Episode_Reward/pen_joint_torque: -0.2226
    Episode_Reward/pen_joint_accel: -0.0997
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0856
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2513
Episode_Reward/pen_flat_orientation: -0.0929
  Episode_Reward/pen_feet_distance: -0.0277
Episode_Reward/pen_feet_regulation: -0.4822
   Episode_Reward/foot_landing_vel: -0.1228
   Episode_Reward/test_gait_reward: -0.9234
Metrics/base_velocity/error_vel_xy: 0.9166
Metrics/base_velocity/error_vel_yaw: 1.2730
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 170262528
                    Iteration time: 1.09s
                        Total time: 1888.66s
                               ETA: 1383.8s

################################################################################
                     [1m Learning iteration 1732/3000 [0m                     

                       Computation: 90132 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.5191
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8339
                     Learning rate: 0.0009
                       Mean reward: 139.41
               Mean episode length: 990.27
       Episode_Reward/keep_balance: 0.9919
     Episode_Reward/rew_lin_vel_xy: 6.3758
      Episode_Reward/rew_ang_vel_z: 2.5876
    Episode_Reward/pen_base_height: -0.2904
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1490
   Episode_Reward/pen_joint_torque: -0.2427
    Episode_Reward/pen_joint_accel: -0.1082
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2480
Episode_Reward/pen_flat_orientation: -0.0913
  Episode_Reward/pen_feet_distance: -0.0248
Episode_Reward/pen_feet_regulation: -0.4847
   Episode_Reward/foot_landing_vel: -0.1202
   Episode_Reward/test_gait_reward: -0.9332
Metrics/base_velocity/error_vel_xy: 0.8992
Metrics/base_velocity/error_vel_yaw: 1.2519
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 170360832
                    Iteration time: 1.09s
                        Total time: 1889.75s
                               ETA: 1382.7s

################################################################################
                     [1m Learning iteration 1733/3000 [0m                     

                       Computation: 89846 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.6055
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8341
                     Learning rate: 0.0009
                       Mean reward: 139.69
               Mean episode length: 984.21
       Episode_Reward/keep_balance: 0.9869
     Episode_Reward/rew_lin_vel_xy: 6.3449
      Episode_Reward/rew_ang_vel_z: 2.6500
    Episode_Reward/pen_base_height: -0.2908
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1544
   Episode_Reward/pen_joint_torque: -0.2405
    Episode_Reward/pen_joint_accel: -0.1114
    Episode_Reward/pen_action_rate: -0.1174
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2479
Episode_Reward/pen_flat_orientation: -0.0910
  Episode_Reward/pen_feet_distance: -0.0236
Episode_Reward/pen_feet_regulation: -0.4657
   Episode_Reward/foot_landing_vel: -0.1242
   Episode_Reward/test_gait_reward: -0.9243
Metrics/base_velocity/error_vel_xy: 0.8970
Metrics/base_velocity/error_vel_yaw: 1.1755
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 170459136
                    Iteration time: 1.09s
                        Total time: 1890.84s
                               ETA: 1381.6s

################################################################################
                     [1m Learning iteration 1734/3000 [0m                     

                       Computation: 90002 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 0.5974
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8331
                     Learning rate: 0.0006
                       Mean reward: 137.36
               Mean episode length: 972.73
       Episode_Reward/keep_balance: 0.9740
     Episode_Reward/rew_lin_vel_xy: 6.2645
      Episode_Reward/rew_ang_vel_z: 2.5671
    Episode_Reward/pen_base_height: -0.2737
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.1520
   Episode_Reward/pen_joint_torque: -0.2276
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1150
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0852
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2441
Episode_Reward/pen_flat_orientation: -0.0933
  Episode_Reward/pen_feet_distance: -0.0261
Episode_Reward/pen_feet_regulation: -0.4654
   Episode_Reward/foot_landing_vel: -0.1192
   Episode_Reward/test_gait_reward: -0.9184
Metrics/base_velocity/error_vel_xy: 0.8980
Metrics/base_velocity/error_vel_yaw: 1.2147
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 170557440
                    Iteration time: 1.09s
                        Total time: 1891.93s
                               ETA: 1380.5s

################################################################################
                     [1m Learning iteration 1735/3000 [0m                     

                       Computation: 90465 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.5529
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8338
                     Learning rate: 0.0004
                       Mean reward: 139.60
               Mean episode length: 982.97
       Episode_Reward/keep_balance: 0.9855
     Episode_Reward/rew_lin_vel_xy: 6.2946
      Episode_Reward/rew_ang_vel_z: 2.6290
    Episode_Reward/pen_base_height: -0.2850
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1537
   Episode_Reward/pen_joint_torque: -0.2289
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0558
   Episode_Reward/pen_joint_powers: -0.0863
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2459
Episode_Reward/pen_flat_orientation: -0.0944
  Episode_Reward/pen_feet_distance: -0.0238
Episode_Reward/pen_feet_regulation: -0.4910
   Episode_Reward/foot_landing_vel: -0.1275
   Episode_Reward/test_gait_reward: -0.9305
Metrics/base_velocity/error_vel_xy: 0.9357
Metrics/base_velocity/error_vel_yaw: 1.1851
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 170655744
                    Iteration time: 1.09s
                        Total time: 1893.02s
                               ETA: 1379.4s

################################################################################
                     [1m Learning iteration 1736/3000 [0m                     

                       Computation: 89128 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 0.5306
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8356
                     Learning rate: 0.0006
                       Mean reward: 139.00
               Mean episode length: 991.21
       Episode_Reward/keep_balance: 0.9878
     Episode_Reward/rew_lin_vel_xy: 6.3466
      Episode_Reward/rew_ang_vel_z: 2.6377
    Episode_Reward/pen_base_height: -0.2853
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1548
   Episode_Reward/pen_joint_torque: -0.2295
    Episode_Reward/pen_joint_accel: -0.1013
    Episode_Reward/pen_action_rate: -0.1163
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0858
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2445
Episode_Reward/pen_flat_orientation: -0.0932
  Episode_Reward/pen_feet_distance: -0.0246
Episode_Reward/pen_feet_regulation: -0.4736
   Episode_Reward/foot_landing_vel: -0.1204
   Episode_Reward/test_gait_reward: -0.9238
Metrics/base_velocity/error_vel_xy: 0.9170
Metrics/base_velocity/error_vel_yaw: 1.1993
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 170754048
                    Iteration time: 1.10s
                        Total time: 1894.12s
                               ETA: 1378.3s

################################################################################
                     [1m Learning iteration 1737/3000 [0m                     

                       Computation: 88966 steps/s (collection: 0.983s, learning 0.122s)
               Value function loss: 0.5330
                    Surrogate loss: 0.0028
             Mean action noise std: 0.8358
                     Learning rate: 0.0001
                       Mean reward: 138.99
               Mean episode length: 988.87
       Episode_Reward/keep_balance: 0.9933
     Episode_Reward/rew_lin_vel_xy: 6.3966
      Episode_Reward/rew_ang_vel_z: 2.6346
    Episode_Reward/pen_base_height: -0.2789
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1529
   Episode_Reward/pen_joint_torque: -0.2406
    Episode_Reward/pen_joint_accel: -0.1095
    Episode_Reward/pen_action_rate: -0.1182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2490
Episode_Reward/pen_flat_orientation: -0.0903
  Episode_Reward/pen_feet_distance: -0.0254
Episode_Reward/pen_feet_regulation: -0.4783
   Episode_Reward/foot_landing_vel: -0.1239
   Episode_Reward/test_gait_reward: -0.9310
Metrics/base_velocity/error_vel_xy: 0.9130
Metrics/base_velocity/error_vel_yaw: 1.2193
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 170852352
                    Iteration time: 1.10s
                        Total time: 1895.23s
                               ETA: 1377.3s

################################################################################
                     [1m Learning iteration 1738/3000 [0m                     

                       Computation: 90381 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.5754
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8349
                     Learning rate: 0.0003
                       Mean reward: 141.74
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.3834
      Episode_Reward/rew_ang_vel_z: 2.6554
    Episode_Reward/pen_base_height: -0.2762
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1565
   Episode_Reward/pen_joint_torque: -0.2411
    Episode_Reward/pen_joint_accel: -0.1084
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0891
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2518
Episode_Reward/pen_flat_orientation: -0.0891
  Episode_Reward/pen_feet_distance: -0.0276
Episode_Reward/pen_feet_regulation: -0.4645
   Episode_Reward/foot_landing_vel: -0.1298
   Episode_Reward/test_gait_reward: -0.9331
Metrics/base_velocity/error_vel_xy: 0.9277
Metrics/base_velocity/error_vel_yaw: 1.2234
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 170950656
                    Iteration time: 1.09s
                        Total time: 1896.32s
                               ETA: 1376.2s

################################################################################
                     [1m Learning iteration 1739/3000 [0m                     

                       Computation: 88278 steps/s (collection: 0.992s, learning 0.122s)
               Value function loss: 0.5411
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8356
                     Learning rate: 0.0003
                       Mean reward: 141.02
               Mean episode length: 971.20
       Episode_Reward/keep_balance: 0.9733
     Episode_Reward/rew_lin_vel_xy: 6.3127
      Episode_Reward/rew_ang_vel_z: 2.6315
    Episode_Reward/pen_base_height: -0.2617
      Episode_Reward/pen_lin_vel_z: -0.0348
     Episode_Reward/pen_ang_vel_xy: -0.1453
   Episode_Reward/pen_joint_torque: -0.2288
    Episode_Reward/pen_joint_accel: -0.1012
    Episode_Reward/pen_action_rate: -0.1129
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0520
   Episode_Reward/pen_joint_powers: -0.0840
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2384
Episode_Reward/pen_flat_orientation: -0.0920
  Episode_Reward/pen_feet_distance: -0.0210
Episode_Reward/pen_feet_regulation: -0.4345
   Episode_Reward/foot_landing_vel: -0.1200
   Episode_Reward/test_gait_reward: -0.9056
Metrics/base_velocity/error_vel_xy: 0.8505
Metrics/base_velocity/error_vel_yaw: 1.1553
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 171048960
                    Iteration time: 1.11s
                        Total time: 1897.43s
                               ETA: 1375.1s

################################################################################
                     [1m Learning iteration 1740/3000 [0m                     

                       Computation: 86876 steps/s (collection: 1.009s, learning 0.123s)
               Value function loss: 0.6295
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8356
                     Learning rate: 0.0004
                       Mean reward: 136.47
               Mean episode length: 970.25
       Episode_Reward/keep_balance: 0.9798
     Episode_Reward/rew_lin_vel_xy: 6.2906
      Episode_Reward/rew_ang_vel_z: 2.6235
    Episode_Reward/pen_base_height: -0.2843
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.1479
   Episode_Reward/pen_joint_torque: -0.2435
    Episode_Reward/pen_joint_accel: -0.1061
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2419
Episode_Reward/pen_flat_orientation: -0.0942
  Episode_Reward/pen_feet_distance: -0.0282
Episode_Reward/pen_feet_regulation: -0.4798
   Episode_Reward/foot_landing_vel: -0.1247
   Episode_Reward/test_gait_reward: -0.9245
Metrics/base_velocity/error_vel_xy: 0.9008
Metrics/base_velocity/error_vel_yaw: 1.1796
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 171147264
                    Iteration time: 1.13s
                        Total time: 1898.56s
                               ETA: 1374.0s

################################################################################
                     [1m Learning iteration 1741/3000 [0m                     

                       Computation: 88277 steps/s (collection: 0.989s, learning 0.125s)
               Value function loss: 0.5637
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8350
                     Learning rate: 0.0004
                       Mean reward: 133.35
               Mean episode length: 979.74
       Episode_Reward/keep_balance: 0.9780
     Episode_Reward/rew_lin_vel_xy: 6.1319
      Episode_Reward/rew_ang_vel_z: 2.5593
    Episode_Reward/pen_base_height: -0.2999
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1516
   Episode_Reward/pen_joint_torque: -0.2420
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1189
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2464
Episode_Reward/pen_flat_orientation: -0.1058
  Episode_Reward/pen_feet_distance: -0.0263
Episode_Reward/pen_feet_regulation: -0.5006
   Episode_Reward/foot_landing_vel: -0.1351
   Episode_Reward/test_gait_reward: -0.9302
Metrics/base_velocity/error_vel_xy: 0.9875
Metrics/base_velocity/error_vel_yaw: 1.2393
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 171245568
                    Iteration time: 1.11s
                        Total time: 1899.67s
                               ETA: 1373.0s

################################################################################
                     [1m Learning iteration 1742/3000 [0m                     

                       Computation: 88137 steps/s (collection: 0.990s, learning 0.125s)
               Value function loss: 0.5157
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8353
                     Learning rate: 0.0006
                       Mean reward: 139.49
               Mean episode length: 990.31
       Episode_Reward/keep_balance: 0.9885
     Episode_Reward/rew_lin_vel_xy: 6.3547
      Episode_Reward/rew_ang_vel_z: 2.6221
    Episode_Reward/pen_base_height: -0.2674
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.1533
   Episode_Reward/pen_joint_torque: -0.2369
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0556
   Episode_Reward/pen_joint_powers: -0.0879
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2465
Episode_Reward/pen_flat_orientation: -0.0906
  Episode_Reward/pen_feet_distance: -0.0259
Episode_Reward/pen_feet_regulation: -0.4750
   Episode_Reward/foot_landing_vel: -0.1272
   Episode_Reward/test_gait_reward: -0.9267
Metrics/base_velocity/error_vel_xy: 0.9035
Metrics/base_velocity/error_vel_yaw: 1.2183
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 171343872
                    Iteration time: 1.12s
                        Total time: 1900.79s
                               ETA: 1371.9s

################################################################################
                     [1m Learning iteration 1743/3000 [0m                     

                       Computation: 89140 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 0.5522
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8363
                     Learning rate: 0.0004
                       Mean reward: 135.35
               Mean episode length: 980.08
       Episode_Reward/keep_balance: 0.9891
     Episode_Reward/rew_lin_vel_xy: 6.2788
      Episode_Reward/rew_ang_vel_z: 2.6037
    Episode_Reward/pen_base_height: -0.2803
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1594
   Episode_Reward/pen_joint_torque: -0.2211
    Episode_Reward/pen_joint_accel: -0.1118
    Episode_Reward/pen_action_rate: -0.1168
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2495
Episode_Reward/pen_flat_orientation: -0.0970
  Episode_Reward/pen_feet_distance: -0.0266
Episode_Reward/pen_feet_regulation: -0.4976
   Episode_Reward/foot_landing_vel: -0.1280
   Episode_Reward/test_gait_reward: -0.9341
Metrics/base_velocity/error_vel_xy: 0.9681
Metrics/base_velocity/error_vel_yaw: 1.2332
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 171442176
                    Iteration time: 1.10s
                        Total time: 1901.89s
                               ETA: 1370.8s

################################################################################
                     [1m Learning iteration 1744/3000 [0m                     

                       Computation: 89200 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.5255
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8363
                     Learning rate: 0.0006
                       Mean reward: 134.87
               Mean episode length: 964.37
       Episode_Reward/keep_balance: 0.9783
     Episode_Reward/rew_lin_vel_xy: 6.2623
      Episode_Reward/rew_ang_vel_z: 2.5928
    Episode_Reward/pen_base_height: -0.2953
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1521
   Episode_Reward/pen_joint_torque: -0.2319
    Episode_Reward/pen_joint_accel: -0.1033
    Episode_Reward/pen_action_rate: -0.1155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0534
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2431
Episode_Reward/pen_flat_orientation: -0.0952
  Episode_Reward/pen_feet_distance: -0.0244
Episode_Reward/pen_feet_regulation: -0.4625
   Episode_Reward/foot_landing_vel: -0.1118
   Episode_Reward/test_gait_reward: -0.9234
Metrics/base_velocity/error_vel_xy: 0.9181
Metrics/base_velocity/error_vel_yaw: 1.2129
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 171540480
                    Iteration time: 1.10s
                        Total time: 1902.99s
                               ETA: 1369.7s

################################################################################
                     [1m Learning iteration 1745/3000 [0m                     

                       Computation: 89958 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.5295
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8368
                     Learning rate: 0.0003
                       Mean reward: 138.52
               Mean episode length: 988.51
       Episode_Reward/keep_balance: 0.9902
     Episode_Reward/rew_lin_vel_xy: 6.3270
      Episode_Reward/rew_ang_vel_z: 2.5928
    Episode_Reward/pen_base_height: -0.2891
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1471
   Episode_Reward/pen_joint_torque: -0.2424
    Episode_Reward/pen_joint_accel: -0.1093
    Episode_Reward/pen_action_rate: -0.1174
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2473
Episode_Reward/pen_flat_orientation: -0.0931
  Episode_Reward/pen_feet_distance: -0.0245
Episode_Reward/pen_feet_regulation: -0.4838
   Episode_Reward/foot_landing_vel: -0.1248
   Episode_Reward/test_gait_reward: -0.9382
Metrics/base_velocity/error_vel_xy: 0.9352
Metrics/base_velocity/error_vel_yaw: 1.2474
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 171638784
                    Iteration time: 1.09s
                        Total time: 1904.09s
                               ETA: 1368.6s

################################################################################
                     [1m Learning iteration 1746/3000 [0m                     

                       Computation: 89844 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.4995
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8361
                     Learning rate: 0.0006
                       Mean reward: 139.49
               Mean episode length: 993.67
       Episode_Reward/keep_balance: 0.9912
     Episode_Reward/rew_lin_vel_xy: 6.2875
      Episode_Reward/rew_ang_vel_z: 2.6370
    Episode_Reward/pen_base_height: -0.2874
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.1538
   Episode_Reward/pen_joint_torque: -0.2411
    Episode_Reward/pen_joint_accel: -0.0979
    Episode_Reward/pen_action_rate: -0.1167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0540
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2475
Episode_Reward/pen_flat_orientation: -0.0915
  Episode_Reward/pen_feet_distance: -0.0277
Episode_Reward/pen_feet_regulation: -0.4619
   Episode_Reward/foot_landing_vel: -0.1237
   Episode_Reward/test_gait_reward: -0.9225
Metrics/base_velocity/error_vel_xy: 0.9414
Metrics/base_velocity/error_vel_yaw: 1.2025
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 171737088
                    Iteration time: 1.09s
                        Total time: 1905.18s
                               ETA: 1367.5s

################################################################################
                     [1m Learning iteration 1747/3000 [0m                     

                       Computation: 88614 steps/s (collection: 0.985s, learning 0.125s)
               Value function loss: 0.6056
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8366
                     Learning rate: 0.0009
                       Mean reward: 141.79
               Mean episode length: 997.51
       Episode_Reward/keep_balance: 0.9972
     Episode_Reward/rew_lin_vel_xy: 6.4234
      Episode_Reward/rew_ang_vel_z: 2.6681
    Episode_Reward/pen_base_height: -0.2797
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1522
   Episode_Reward/pen_joint_torque: -0.2273
    Episode_Reward/pen_joint_accel: -0.1015
    Episode_Reward/pen_action_rate: -0.1156
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0537
   Episode_Reward/pen_joint_powers: -0.0844
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2465
Episode_Reward/pen_flat_orientation: -0.0923
  Episode_Reward/pen_feet_distance: -0.0238
Episode_Reward/pen_feet_regulation: -0.4769
   Episode_Reward/foot_landing_vel: -0.1227
   Episode_Reward/test_gait_reward: -0.9325
Metrics/base_velocity/error_vel_xy: 0.9212
Metrics/base_velocity/error_vel_yaw: 1.1939
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 171835392
                    Iteration time: 1.11s
                        Total time: 1906.29s
                               ETA: 1366.5s

################################################################################
                     [1m Learning iteration 1748/3000 [0m                     

                       Computation: 88828 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 0.5267
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8362
                     Learning rate: 0.0013
                       Mean reward: 140.64
               Mean episode length: 983.39
       Episode_Reward/keep_balance: 0.9854
     Episode_Reward/rew_lin_vel_xy: 6.3354
      Episode_Reward/rew_ang_vel_z: 2.6424
    Episode_Reward/pen_base_height: -0.2700
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.1460
   Episode_Reward/pen_joint_torque: -0.2296
    Episode_Reward/pen_joint_accel: -0.1047
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0858
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2449
Episode_Reward/pen_flat_orientation: -0.0915
  Episode_Reward/pen_feet_distance: -0.0270
Episode_Reward/pen_feet_regulation: -0.4569
   Episode_Reward/foot_landing_vel: -0.1297
   Episode_Reward/test_gait_reward: -0.9206
Metrics/base_velocity/error_vel_xy: 0.8959
Metrics/base_velocity/error_vel_yaw: 1.1772
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 171933696
                    Iteration time: 1.11s
                        Total time: 1907.40s
                               ETA: 1365.4s

################################################################################
                     [1m Learning iteration 1749/3000 [0m                     

                       Computation: 84892 steps/s (collection: 1.027s, learning 0.131s)
               Value function loss: 0.5792
                    Surrogate loss: 0.0025
             Mean action noise std: 0.8364
                     Learning rate: 0.0001
                       Mean reward: 139.96
               Mean episode length: 992.14
       Episode_Reward/keep_balance: 0.9946
     Episode_Reward/rew_lin_vel_xy: 6.3813
      Episode_Reward/rew_ang_vel_z: 2.6309
    Episode_Reward/pen_base_height: -0.2870
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1506
   Episode_Reward/pen_joint_torque: -0.2389
    Episode_Reward/pen_joint_accel: -0.1030
    Episode_Reward/pen_action_rate: -0.1182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0897
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2484
Episode_Reward/pen_flat_orientation: -0.0936
  Episode_Reward/pen_feet_distance: -0.0266
Episode_Reward/pen_feet_regulation: -0.4960
   Episode_Reward/foot_landing_vel: -0.1212
   Episode_Reward/test_gait_reward: -0.9330
Metrics/base_velocity/error_vel_xy: 0.9227
Metrics/base_velocity/error_vel_yaw: 1.2224
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 172032000
                    Iteration time: 1.16s
                        Total time: 1908.56s
                               ETA: 1364.3s

################################################################################
                     [1m Learning iteration 1750/3000 [0m                     

                       Computation: 89459 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.6177
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8362
                     Learning rate: 0.0003
                       Mean reward: 140.04
               Mean episode length: 981.55
       Episode_Reward/keep_balance: 0.9898
     Episode_Reward/rew_lin_vel_xy: 6.3777
      Episode_Reward/rew_ang_vel_z: 2.6474
    Episode_Reward/pen_base_height: -0.2931
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1539
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.0968
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0541
   Episode_Reward/pen_joint_powers: -0.0854
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2434
Episode_Reward/pen_flat_orientation: -0.0884
  Episode_Reward/pen_feet_distance: -0.0260
Episode_Reward/pen_feet_regulation: -0.4659
   Episode_Reward/foot_landing_vel: -0.1177
   Episode_Reward/test_gait_reward: -0.9316
Metrics/base_velocity/error_vel_xy: 0.9002
Metrics/base_velocity/error_vel_yaw: 1.1932
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 172130304
                    Iteration time: 1.10s
                        Total time: 1909.65s
                               ETA: 1363.3s

################################################################################
                     [1m Learning iteration 1751/3000 [0m                     

                       Computation: 90494 steps/s (collection: 0.962s, learning 0.125s)
               Value function loss: 0.4684
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8350
                     Learning rate: 0.0004
                       Mean reward: 133.26
               Mean episode length: 959.20
       Episode_Reward/keep_balance: 0.9682
     Episode_Reward/rew_lin_vel_xy: 6.0905
      Episode_Reward/rew_ang_vel_z: 2.5460
    Episode_Reward/pen_base_height: -0.2801
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1519
   Episode_Reward/pen_joint_torque: -0.2231
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0846
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2388
Episode_Reward/pen_flat_orientation: -0.0968
  Episode_Reward/pen_feet_distance: -0.0253
Episode_Reward/pen_feet_regulation: -0.4656
   Episode_Reward/foot_landing_vel: -0.1253
   Episode_Reward/test_gait_reward: -0.9136
Metrics/base_velocity/error_vel_xy: 0.9520
Metrics/base_velocity/error_vel_yaw: 1.2169
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 172228608
                    Iteration time: 1.09s
                        Total time: 1910.74s
                               ETA: 1362.2s

################################################################################
                     [1m Learning iteration 1752/3000 [0m                     

                       Computation: 87511 steps/s (collection: 0.999s, learning 0.124s)
               Value function loss: 0.5276
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8354
                     Learning rate: 0.0004
                       Mean reward: 137.16
               Mean episode length: 989.68
       Episode_Reward/keep_balance: 0.9987
     Episode_Reward/rew_lin_vel_xy: 6.3424
      Episode_Reward/rew_ang_vel_z: 2.6215
    Episode_Reward/pen_base_height: -0.2886
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1552
   Episode_Reward/pen_joint_torque: -0.2353
    Episode_Reward/pen_joint_accel: -0.1250
    Episode_Reward/pen_action_rate: -0.1195
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2530
Episode_Reward/pen_flat_orientation: -0.0929
  Episode_Reward/pen_feet_distance: -0.0327
Episode_Reward/pen_feet_regulation: -0.4990
   Episode_Reward/foot_landing_vel: -0.1352
   Episode_Reward/test_gait_reward: -0.9367
Metrics/base_velocity/error_vel_xy: 0.9471
Metrics/base_velocity/error_vel_yaw: 1.2652
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 172326912
                    Iteration time: 1.12s
                        Total time: 1911.86s
                               ETA: 1361.1s

################################################################################
                     [1m Learning iteration 1753/3000 [0m                     

                       Computation: 88276 steps/s (collection: 0.990s, learning 0.124s)
               Value function loss: 0.5167
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8356
                     Learning rate: 0.0003
                       Mean reward: 139.85
               Mean episode length: 984.58
       Episode_Reward/keep_balance: 0.9882
     Episode_Reward/rew_lin_vel_xy: 6.3412
      Episode_Reward/rew_ang_vel_z: 2.6252
    Episode_Reward/pen_base_height: -0.2722
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1571
   Episode_Reward/pen_joint_torque: -0.2275
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0558
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2468
Episode_Reward/pen_flat_orientation: -0.0921
  Episode_Reward/pen_feet_distance: -0.0289
Episode_Reward/pen_feet_regulation: -0.4722
   Episode_Reward/foot_landing_vel: -0.1302
   Episode_Reward/test_gait_reward: -0.9241
Metrics/base_velocity/error_vel_xy: 0.9001
Metrics/base_velocity/error_vel_yaw: 1.2083
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 172425216
                    Iteration time: 1.11s
                        Total time: 1912.98s
                               ETA: 1360.0s

################################################################################
                     [1m Learning iteration 1754/3000 [0m                     

                       Computation: 88497 steps/s (collection: 0.987s, learning 0.124s)
               Value function loss: 0.5055
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8343
                     Learning rate: 0.0004
                       Mean reward: 139.16
               Mean episode length: 980.93
       Episode_Reward/keep_balance: 0.9835
     Episode_Reward/rew_lin_vel_xy: 6.3613
      Episode_Reward/rew_ang_vel_z: 2.6078
    Episode_Reward/pen_base_height: -0.2827
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1516
   Episode_Reward/pen_joint_torque: -0.2280
    Episode_Reward/pen_joint_accel: -0.1019
    Episode_Reward/pen_action_rate: -0.1149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2434
Episode_Reward/pen_flat_orientation: -0.0896
  Episode_Reward/pen_feet_distance: -0.0289
Episode_Reward/pen_feet_regulation: -0.4729
   Episode_Reward/foot_landing_vel: -0.1207
   Episode_Reward/test_gait_reward: -0.9216
Metrics/base_velocity/error_vel_xy: 0.8943
Metrics/base_velocity/error_vel_yaw: 1.2106
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 172523520
                    Iteration time: 1.11s
                        Total time: 1914.09s
                               ETA: 1358.9s

################################################################################
                     [1m Learning iteration 1755/3000 [0m                     

                       Computation: 87509 steps/s (collection: 0.997s, learning 0.127s)
               Value function loss: 0.5656
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8347
                     Learning rate: 0.0004
                       Mean reward: 137.93
               Mean episode length: 971.68
       Episode_Reward/keep_balance: 0.9810
     Episode_Reward/rew_lin_vel_xy: 6.2973
      Episode_Reward/rew_ang_vel_z: 2.6161
    Episode_Reward/pen_base_height: -0.2893
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1489
   Episode_Reward/pen_joint_torque: -0.2357
    Episode_Reward/pen_joint_accel: -0.1049
    Episode_Reward/pen_action_rate: -0.1147
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0538
   Episode_Reward/pen_joint_powers: -0.0855
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2425
Episode_Reward/pen_flat_orientation: -0.0927
  Episode_Reward/pen_feet_distance: -0.0268
Episode_Reward/pen_feet_regulation: -0.4745
   Episode_Reward/foot_landing_vel: -0.1181
   Episode_Reward/test_gait_reward: -0.9202
Metrics/base_velocity/error_vel_xy: 0.9047
Metrics/base_velocity/error_vel_yaw: 1.1912
      Episode_Termination/time_out: 5.0833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 172621824
                    Iteration time: 1.12s
                        Total time: 1915.21s
                               ETA: 1357.9s

################################################################################
                     [1m Learning iteration 1756/3000 [0m                     

                       Computation: 88920 steps/s (collection: 0.981s, learning 0.124s)
               Value function loss: 0.5455
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8342
                     Learning rate: 0.0001
                       Mean reward: 136.96
               Mean episode length: 962.87
       Episode_Reward/keep_balance: 0.9670
     Episode_Reward/rew_lin_vel_xy: 6.2536
      Episode_Reward/rew_ang_vel_z: 2.5802
    Episode_Reward/pen_base_height: -0.2780
      Episode_Reward/pen_lin_vel_z: -0.0353
     Episode_Reward/pen_ang_vel_xy: -0.1490
   Episode_Reward/pen_joint_torque: -0.2255
    Episode_Reward/pen_joint_accel: -0.1039
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0532
   Episode_Reward/pen_joint_powers: -0.0831
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2380
Episode_Reward/pen_flat_orientation: -0.0912
  Episode_Reward/pen_feet_distance: -0.0272
Episode_Reward/pen_feet_regulation: -0.4510
   Episode_Reward/foot_landing_vel: -0.1233
   Episode_Reward/test_gait_reward: -0.8994
Metrics/base_velocity/error_vel_xy: 0.8726
Metrics/base_velocity/error_vel_yaw: 1.1701
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 172720128
                    Iteration time: 1.11s
                        Total time: 1916.32s
                               ETA: 1356.8s

################################################################################
                     [1m Learning iteration 1757/3000 [0m                     

                       Computation: 89336 steps/s (collection: 0.975s, learning 0.125s)
               Value function loss: 0.5391
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8344
                     Learning rate: 0.0003
                       Mean reward: 142.30
               Mean episode length: 992.32
       Episode_Reward/keep_balance: 0.9840
     Episode_Reward/rew_lin_vel_xy: 6.3413
      Episode_Reward/rew_ang_vel_z: 2.6159
    Episode_Reward/pen_base_height: -0.2786
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1478
   Episode_Reward/pen_joint_torque: -0.2357
    Episode_Reward/pen_joint_accel: -0.1019
    Episode_Reward/pen_action_rate: -0.1145
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0863
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2425
Episode_Reward/pen_flat_orientation: -0.0928
  Episode_Reward/pen_feet_distance: -0.0289
Episode_Reward/pen_feet_regulation: -0.4650
   Episode_Reward/foot_landing_vel: -0.1252
   Episode_Reward/test_gait_reward: -0.9186
Metrics/base_velocity/error_vel_xy: 0.8861
Metrics/base_velocity/error_vel_yaw: 1.1902
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 172818432
                    Iteration time: 1.10s
                        Total time: 1917.42s
                               ETA: 1355.7s

################################################################################
                     [1m Learning iteration 1758/3000 [0m                     

                       Computation: 88684 steps/s (collection: 0.983s, learning 0.125s)
               Value function loss: 0.5470
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8343
                     Learning rate: 0.0004
                       Mean reward: 135.90
               Mean episode length: 969.25
       Episode_Reward/keep_balance: 0.9754
     Episode_Reward/rew_lin_vel_xy: 6.2030
      Episode_Reward/rew_ang_vel_z: 2.5807
    Episode_Reward/pen_base_height: -0.2900
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1547
   Episode_Reward/pen_joint_torque: -0.2345
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.1150
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2427
Episode_Reward/pen_flat_orientation: -0.0964
  Episode_Reward/pen_feet_distance: -0.0311
Episode_Reward/pen_feet_regulation: -0.4735
   Episode_Reward/foot_landing_vel: -0.1292
   Episode_Reward/test_gait_reward: -0.9133
Metrics/base_velocity/error_vel_xy: 0.9282
Metrics/base_velocity/error_vel_yaw: 1.2017
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 172916736
                    Iteration time: 1.11s
                        Total time: 1918.53s
                               ETA: 1354.6s

################################################################################
                     [1m Learning iteration 1759/3000 [0m                     

                       Computation: 89580 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.5159
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8344
                     Learning rate: 0.0006
                       Mean reward: 139.37
               Mean episode length: 995.80
       Episode_Reward/keep_balance: 0.9961
     Episode_Reward/rew_lin_vel_xy: 6.3274
      Episode_Reward/rew_ang_vel_z: 2.6255
    Episode_Reward/pen_base_height: -0.2949
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1552
   Episode_Reward/pen_joint_torque: -0.2360
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.1168
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2459
Episode_Reward/pen_flat_orientation: -0.0939
  Episode_Reward/pen_feet_distance: -0.0270
Episode_Reward/pen_feet_regulation: -0.4778
   Episode_Reward/foot_landing_vel: -0.1213
   Episode_Reward/test_gait_reward: -0.9381
Metrics/base_velocity/error_vel_xy: 0.9439
Metrics/base_velocity/error_vel_yaw: 1.2379
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 173015040
                    Iteration time: 1.10s
                        Total time: 1919.62s
                               ETA: 1353.6s

################################################################################
                     [1m Learning iteration 1760/3000 [0m                     

                       Computation: 87210 steps/s (collection: 1.003s, learning 0.124s)
               Value function loss: 0.6083
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8357
                     Learning rate: 0.0003
                       Mean reward: 141.43
               Mean episode length: 995.39
       Episode_Reward/keep_balance: 0.9808
     Episode_Reward/rew_lin_vel_xy: 6.3040
      Episode_Reward/rew_ang_vel_z: 2.6167
    Episode_Reward/pen_base_height: -0.2858
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.1493
   Episode_Reward/pen_joint_torque: -0.2324
    Episode_Reward/pen_joint_accel: -0.0995
    Episode_Reward/pen_action_rate: -0.1143
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0541
   Episode_Reward/pen_joint_powers: -0.0856
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2401
Episode_Reward/pen_flat_orientation: -0.0912
  Episode_Reward/pen_feet_distance: -0.0314
Episode_Reward/pen_feet_regulation: -0.4677
   Episode_Reward/foot_landing_vel: -0.1184
   Episode_Reward/test_gait_reward: -0.9237
Metrics/base_velocity/error_vel_xy: 0.9068
Metrics/base_velocity/error_vel_yaw: 1.1891
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 173113344
                    Iteration time: 1.13s
                        Total time: 1920.75s
                               ETA: 1352.5s

################################################################################
                     [1m Learning iteration 1761/3000 [0m                     

                       Computation: 89047 steps/s (collection: 0.978s, learning 0.126s)
               Value function loss: 0.5298
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8364
                     Learning rate: 0.0006
                       Mean reward: 140.92
               Mean episode length: 990.79
       Episode_Reward/keep_balance: 0.9925
     Episode_Reward/rew_lin_vel_xy: 6.3912
      Episode_Reward/rew_ang_vel_z: 2.6777
    Episode_Reward/pen_base_height: -0.2833
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.1523
   Episode_Reward/pen_joint_torque: -0.2199
    Episode_Reward/pen_joint_accel: -0.1069
    Episode_Reward/pen_action_rate: -0.1136
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0537
   Episode_Reward/pen_joint_powers: -0.0832
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2417
Episode_Reward/pen_flat_orientation: -0.0947
  Episode_Reward/pen_feet_distance: -0.0286
Episode_Reward/pen_feet_regulation: -0.4611
   Episode_Reward/foot_landing_vel: -0.1212
   Episode_Reward/test_gait_reward: -0.9241
Metrics/base_velocity/error_vel_xy: 0.9089
Metrics/base_velocity/error_vel_yaw: 1.1777
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 173211648
                    Iteration time: 1.10s
                        Total time: 1921.85s
                               ETA: 1351.4s

################################################################################
                     [1m Learning iteration 1762/3000 [0m                     

                       Computation: 92247 steps/s (collection: 0.942s, learning 0.124s)
               Value function loss: 0.5064
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8375
                     Learning rate: 0.0006
                       Mean reward: 135.65
               Mean episode length: 972.36
       Episode_Reward/keep_balance: 0.9494
     Episode_Reward/rew_lin_vel_xy: 5.9884
      Episode_Reward/rew_ang_vel_z: 2.4645
    Episode_Reward/pen_base_height: -0.2969
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1463
   Episode_Reward/pen_joint_torque: -0.2209
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.1117
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0833
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2364
Episode_Reward/pen_flat_orientation: -0.0993
  Episode_Reward/pen_feet_distance: -0.0279
Episode_Reward/pen_feet_regulation: -0.4579
   Episode_Reward/foot_landing_vel: -0.1134
   Episode_Reward/test_gait_reward: -0.8974
Metrics/base_velocity/error_vel_xy: 0.9256
Metrics/base_velocity/error_vel_yaw: 1.2214
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 173309952
                    Iteration time: 1.07s
                        Total time: 1922.92s
                               ETA: 1350.3s

################################################################################
                     [1m Learning iteration 1763/3000 [0m                     

                       Computation: 90610 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.5567
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8395
                     Learning rate: 0.0006
                       Mean reward: 138.45
               Mean episode length: 976.55
       Episode_Reward/keep_balance: 0.9890
     Episode_Reward/rew_lin_vel_xy: 6.4115
      Episode_Reward/rew_ang_vel_z: 2.6492
    Episode_Reward/pen_base_height: -0.2845
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.1451
   Episode_Reward/pen_joint_torque: -0.2373
    Episode_Reward/pen_joint_accel: -0.1013
    Episode_Reward/pen_action_rate: -0.1139
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2415
Episode_Reward/pen_flat_orientation: -0.0928
  Episode_Reward/pen_feet_distance: -0.0292
Episode_Reward/pen_feet_regulation: -0.4786
   Episode_Reward/foot_landing_vel: -0.1211
   Episode_Reward/test_gait_reward: -0.9336
Metrics/base_velocity/error_vel_xy: 0.8801
Metrics/base_velocity/error_vel_yaw: 1.1856
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 173408256
                    Iteration time: 1.08s
                        Total time: 1924.01s
                               ETA: 1349.2s

################################################################################
                     [1m Learning iteration 1764/3000 [0m                     

                       Computation: 90567 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.5086
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8377
                     Learning rate: 0.0009
                       Mean reward: 134.32
               Mean episode length: 975.52
       Episode_Reward/keep_balance: 0.9771
     Episode_Reward/rew_lin_vel_xy: 6.1983
      Episode_Reward/rew_ang_vel_z: 2.5744
    Episode_Reward/pen_base_height: -0.3049
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1558
   Episode_Reward/pen_joint_torque: -0.2366
    Episode_Reward/pen_joint_accel: -0.1044
    Episode_Reward/pen_action_rate: -0.1159
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0897
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2437
Episode_Reward/pen_flat_orientation: -0.1008
  Episode_Reward/pen_feet_distance: -0.0323
Episode_Reward/pen_feet_regulation: -0.5011
   Episode_Reward/foot_landing_vel: -0.1231
   Episode_Reward/test_gait_reward: -0.9227
Metrics/base_velocity/error_vel_xy: 0.9541
Metrics/base_velocity/error_vel_yaw: 1.2203
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 173506560
                    Iteration time: 1.09s
                        Total time: 1925.09s
                               ETA: 1348.1s

################################################################################
                     [1m Learning iteration 1765/3000 [0m                     

                       Computation: 89258 steps/s (collection: 0.974s, learning 0.128s)
               Value function loss: 0.5546
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8369
                     Learning rate: 0.0004
                       Mean reward: 139.43
               Mean episode length: 990.55
       Episode_Reward/keep_balance: 0.9921
     Episode_Reward/rew_lin_vel_xy: 6.3581
      Episode_Reward/rew_ang_vel_z: 2.6110
    Episode_Reward/pen_base_height: -0.2977
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1533
   Episode_Reward/pen_joint_torque: -0.2319
    Episode_Reward/pen_joint_accel: -0.1021
    Episode_Reward/pen_action_rate: -0.1162
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2458
Episode_Reward/pen_flat_orientation: -0.0891
  Episode_Reward/pen_feet_distance: -0.0339
Episode_Reward/pen_feet_regulation: -0.4913
   Episode_Reward/foot_landing_vel: -0.1242
   Episode_Reward/test_gait_reward: -0.9341
Metrics/base_velocity/error_vel_xy: 0.9286
Metrics/base_velocity/error_vel_yaw: 1.2336
      Episode_Termination/time_out: 4.8333
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 173604864
                    Iteration time: 1.10s
                        Total time: 1926.19s
                               ETA: 1347.0s

################################################################################
                     [1m Learning iteration 1766/3000 [0m                     

                       Computation: 89615 steps/s (collection: 0.971s, learning 0.126s)
               Value function loss: 0.5565
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8378
                     Learning rate: 0.0006
                       Mean reward: 138.88
               Mean episode length: 991.54
       Episode_Reward/keep_balance: 0.9888
     Episode_Reward/rew_lin_vel_xy: 6.2593
      Episode_Reward/rew_ang_vel_z: 2.6106
    Episode_Reward/pen_base_height: -0.2839
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.1534
   Episode_Reward/pen_joint_torque: -0.2175
    Episode_Reward/pen_joint_accel: -0.1006
    Episode_Reward/pen_action_rate: -0.1137
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0842
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2423
Episode_Reward/pen_flat_orientation: -0.0941
  Episode_Reward/pen_feet_distance: -0.0260
Episode_Reward/pen_feet_regulation: -0.4717
   Episode_Reward/foot_landing_vel: -0.1231
   Episode_Reward/test_gait_reward: -0.9305
Metrics/base_velocity/error_vel_xy: 0.9538
Metrics/base_velocity/error_vel_yaw: 1.2355
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 173703168
                    Iteration time: 1.10s
                        Total time: 1927.29s
                               ETA: 1345.9s

################################################################################
                     [1m Learning iteration 1767/3000 [0m                     

                       Computation: 87953 steps/s (collection: 0.994s, learning 0.124s)
               Value function loss: 0.6046
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8383
                     Learning rate: 0.0003
                       Mean reward: 138.72
               Mean episode length: 972.83
       Episode_Reward/keep_balance: 0.9695
     Episode_Reward/rew_lin_vel_xy: 6.2797
      Episode_Reward/rew_ang_vel_z: 2.5611
    Episode_Reward/pen_base_height: -0.2687
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.1518
   Episode_Reward/pen_joint_torque: -0.2234
    Episode_Reward/pen_joint_accel: -0.1044
    Episode_Reward/pen_action_rate: -0.1136
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0845
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2425
Episode_Reward/pen_flat_orientation: -0.0913
  Episode_Reward/pen_feet_distance: -0.0270
Episode_Reward/pen_feet_regulation: -0.4769
   Episode_Reward/foot_landing_vel: -0.1152
   Episode_Reward/test_gait_reward: -0.9110
Metrics/base_velocity/error_vel_xy: 0.8532
Metrics/base_velocity/error_vel_yaw: 1.2032
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 173801472
                    Iteration time: 1.12s
                        Total time: 1928.41s
                               ETA: 1344.9s

################################################################################
                     [1m Learning iteration 1768/3000 [0m                     

                       Computation: 90523 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.5231
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8378
                     Learning rate: 0.0004
                       Mean reward: 135.08
               Mean episode length: 965.41
       Episode_Reward/keep_balance: 0.9659
     Episode_Reward/rew_lin_vel_xy: 6.1743
      Episode_Reward/rew_ang_vel_z: 2.5638
    Episode_Reward/pen_base_height: -0.2914
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.1515
   Episode_Reward/pen_joint_torque: -0.2273
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0857
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2370
Episode_Reward/pen_flat_orientation: -0.0937
  Episode_Reward/pen_feet_distance: -0.0259
Episode_Reward/pen_feet_regulation: -0.4689
   Episode_Reward/foot_landing_vel: -0.1242
   Episode_Reward/test_gait_reward: -0.9081
Metrics/base_velocity/error_vel_xy: 0.8982
Metrics/base_velocity/error_vel_yaw: 1.1820
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 173899776
                    Iteration time: 1.09s
                        Total time: 1929.49s
                               ETA: 1343.8s

################################################################################
                     [1m Learning iteration 1769/3000 [0m                     

                       Computation: 89367 steps/s (collection: 0.975s, learning 0.125s)
               Value function loss: 0.5253
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8375
                     Learning rate: 0.0003
                       Mean reward: 138.41
               Mean episode length: 986.85
       Episode_Reward/keep_balance: 0.9821
     Episode_Reward/rew_lin_vel_xy: 6.3002
      Episode_Reward/rew_ang_vel_z: 2.6181
    Episode_Reward/pen_base_height: -0.3014
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1515
   Episode_Reward/pen_joint_torque: -0.2355
    Episode_Reward/pen_joint_accel: -0.1039
    Episode_Reward/pen_action_rate: -0.1126
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0859
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2392
Episode_Reward/pen_flat_orientation: -0.0958
  Episode_Reward/pen_feet_distance: -0.0270
Episode_Reward/pen_feet_regulation: -0.4684
   Episode_Reward/foot_landing_vel: -0.1264
   Episode_Reward/test_gait_reward: -0.9229
Metrics/base_velocity/error_vel_xy: 0.9076
Metrics/base_velocity/error_vel_yaw: 1.1883
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 173998080
                    Iteration time: 1.10s
                        Total time: 1930.59s
                               ETA: 1342.7s

################################################################################
                     [1m Learning iteration 1770/3000 [0m                     

                       Computation: 89841 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.5727
                    Surrogate loss: -0.0057
             Mean action noise std: 0.8384
                     Learning rate: 0.0006
                       Mean reward: 138.96
               Mean episode length: 988.96
       Episode_Reward/keep_balance: 0.9941
     Episode_Reward/rew_lin_vel_xy: 6.3457
      Episode_Reward/rew_ang_vel_z: 2.6353
    Episode_Reward/pen_base_height: -0.2820
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1616
   Episode_Reward/pen_joint_torque: -0.2226
    Episode_Reward/pen_joint_accel: -0.1174
    Episode_Reward/pen_action_rate: -0.1150
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2468
Episode_Reward/pen_flat_orientation: -0.0932
  Episode_Reward/pen_feet_distance: -0.0265
Episode_Reward/pen_feet_regulation: -0.4914
   Episode_Reward/foot_landing_vel: -0.1335
   Episode_Reward/test_gait_reward: -0.9268
Metrics/base_velocity/error_vel_xy: 0.9274
Metrics/base_velocity/error_vel_yaw: 1.2142
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 174096384
                    Iteration time: 1.09s
                        Total time: 1931.69s
                               ETA: 1341.6s

################################################################################
                     [1m Learning iteration 1771/3000 [0m                     

                       Computation: 87550 steps/s (collection: 0.998s, learning 0.125s)
               Value function loss: 0.4996
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8386
                     Learning rate: 0.0006
                       Mean reward: 137.33
               Mean episode length: 978.86
       Episode_Reward/keep_balance: 0.9839
     Episode_Reward/rew_lin_vel_xy: 6.3061
      Episode_Reward/rew_ang_vel_z: 2.6101
    Episode_Reward/pen_base_height: -0.2848
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1508
   Episode_Reward/pen_joint_torque: -0.2281
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.1126
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0853
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2405
Episode_Reward/pen_flat_orientation: -0.0920
  Episode_Reward/pen_feet_distance: -0.0229
Episode_Reward/pen_feet_regulation: -0.4573
   Episode_Reward/foot_landing_vel: -0.1229
   Episode_Reward/test_gait_reward: -0.9242
Metrics/base_velocity/error_vel_xy: 0.9096
Metrics/base_velocity/error_vel_yaw: 1.1996
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 174194688
                    Iteration time: 1.12s
                        Total time: 1932.81s
                               ETA: 1340.5s

################################################################################
                     [1m Learning iteration 1772/3000 [0m                     

                       Computation: 89286 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.5112
                    Surrogate loss: -0.0008
             Mean action noise std: 0.8374
                     Learning rate: 0.0003
                       Mean reward: 137.50
               Mean episode length: 982.53
       Episode_Reward/keep_balance: 0.9834
     Episode_Reward/rew_lin_vel_xy: 6.2616
      Episode_Reward/rew_ang_vel_z: 2.5769
    Episode_Reward/pen_base_height: -0.3040
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1525
   Episode_Reward/pen_joint_torque: -0.2236
    Episode_Reward/pen_joint_accel: -0.1117
    Episode_Reward/pen_action_rate: -0.1141
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2424
Episode_Reward/pen_flat_orientation: -0.0975
  Episode_Reward/pen_feet_distance: -0.0228
Episode_Reward/pen_feet_regulation: -0.4885
   Episode_Reward/foot_landing_vel: -0.1253
   Episode_Reward/test_gait_reward: -0.9278
Metrics/base_velocity/error_vel_xy: 0.9282
Metrics/base_velocity/error_vel_yaw: 1.2363
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 174292992
                    Iteration time: 1.10s
                        Total time: 1933.91s
                               ETA: 1339.4s

################################################################################
                     [1m Learning iteration 1773/3000 [0m                     

                       Computation: 88088 steps/s (collection: 0.991s, learning 0.125s)
               Value function loss: 0.5298
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8369
                     Learning rate: 0.0004
                       Mean reward: 137.88
               Mean episode length: 979.48
       Episode_Reward/keep_balance: 0.9841
     Episode_Reward/rew_lin_vel_xy: 6.3733
      Episode_Reward/rew_ang_vel_z: 2.5951
    Episode_Reward/pen_base_height: -0.2824
      Episode_Reward/pen_lin_vel_z: -0.0337
     Episode_Reward/pen_ang_vel_xy: -0.1526
   Episode_Reward/pen_joint_torque: -0.2177
    Episode_Reward/pen_joint_accel: -0.0978
    Episode_Reward/pen_action_rate: -0.1125
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0539
   Episode_Reward/pen_joint_powers: -0.0838
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2428
Episode_Reward/pen_flat_orientation: -0.0903
  Episode_Reward/pen_feet_distance: -0.0248
Episode_Reward/pen_feet_regulation: -0.4686
   Episode_Reward/foot_landing_vel: -0.1180
   Episode_Reward/test_gait_reward: -0.9271
Metrics/base_velocity/error_vel_xy: 0.8840
Metrics/base_velocity/error_vel_yaw: 1.2179
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 174391296
                    Iteration time: 1.12s
                        Total time: 1935.03s
                               ETA: 1338.4s

################################################################################
                     [1m Learning iteration 1774/3000 [0m                     

                       Computation: 88362 steps/s (collection: 0.988s, learning 0.125s)
               Value function loss: 0.5745
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8370
                     Learning rate: 0.0006
                       Mean reward: 134.79
               Mean episode length: 962.05
       Episode_Reward/keep_balance: 0.9697
     Episode_Reward/rew_lin_vel_xy: 6.1949
      Episode_Reward/rew_ang_vel_z: 2.5762
    Episode_Reward/pen_base_height: -0.3123
      Episode_Reward/pen_lin_vel_z: -0.0348
     Episode_Reward/pen_ang_vel_xy: -0.1454
   Episode_Reward/pen_joint_torque: -0.2364
    Episode_Reward/pen_joint_accel: -0.1019
    Episode_Reward/pen_action_rate: -0.1128
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0535
   Episode_Reward/pen_joint_powers: -0.0869
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2356
Episode_Reward/pen_flat_orientation: -0.0978
  Episode_Reward/pen_feet_distance: -0.0356
Episode_Reward/pen_feet_regulation: -0.4641
   Episode_Reward/foot_landing_vel: -0.1128
   Episode_Reward/test_gait_reward: -0.9183
Metrics/base_velocity/error_vel_xy: 0.9000
Metrics/base_velocity/error_vel_yaw: 1.1918
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 174489600
                    Iteration time: 1.11s
                        Total time: 1936.14s
                               ETA: 1337.3s

################################################################################
                     [1m Learning iteration 1775/3000 [0m                     

                       Computation: 89846 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.4997
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8359
                     Learning rate: 0.0003
                       Mean reward: 138.86
               Mean episode length: 979.71
       Episode_Reward/keep_balance: 0.9807
     Episode_Reward/rew_lin_vel_xy: 6.3156
      Episode_Reward/rew_ang_vel_z: 2.6159
    Episode_Reward/pen_base_height: -0.2989
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.1528
   Episode_Reward/pen_joint_torque: -0.2290
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.1136
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2407
Episode_Reward/pen_flat_orientation: -0.0920
  Episode_Reward/pen_feet_distance: -0.0265
Episode_Reward/pen_feet_regulation: -0.4799
   Episode_Reward/foot_landing_vel: -0.1171
   Episode_Reward/test_gait_reward: -0.9305
Metrics/base_velocity/error_vel_xy: 0.8980
Metrics/base_velocity/error_vel_yaw: 1.1900
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 174587904
                    Iteration time: 1.09s
                        Total time: 1937.23s
                               ETA: 1336.2s

################################################################################
                     [1m Learning iteration 1776/3000 [0m                     

                       Computation: 88591 steps/s (collection: 0.984s, learning 0.125s)
               Value function loss: 0.5147
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8344
                     Learning rate: 0.0006
                       Mean reward: 140.04
               Mean episode length: 986.67
       Episode_Reward/keep_balance: 0.9921
     Episode_Reward/rew_lin_vel_xy: 6.3844
      Episode_Reward/rew_ang_vel_z: 2.6250
    Episode_Reward/pen_base_height: -0.2873
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.1563
   Episode_Reward/pen_joint_torque: -0.2284
    Episode_Reward/pen_joint_accel: -0.1127
    Episode_Reward/pen_action_rate: -0.1154
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2446
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0256
Episode_Reward/pen_feet_regulation: -0.4771
   Episode_Reward/foot_landing_vel: -0.1233
   Episode_Reward/test_gait_reward: -0.9395
Metrics/base_velocity/error_vel_xy: 0.9033
Metrics/base_velocity/error_vel_yaw: 1.2209
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 174686208
                    Iteration time: 1.11s
                        Total time: 1938.34s
                               ETA: 1335.1s

################################################################################
                     [1m Learning iteration 1777/3000 [0m                     

                       Computation: 89964 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.5757
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8332
                     Learning rate: 0.0004
                       Mean reward: 139.26
               Mean episode length: 983.51
       Episode_Reward/keep_balance: 0.9841
     Episode_Reward/rew_lin_vel_xy: 6.2732
      Episode_Reward/rew_ang_vel_z: 2.6294
    Episode_Reward/pen_base_height: -0.2949
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.1525
   Episode_Reward/pen_joint_torque: -0.2260
    Episode_Reward/pen_joint_accel: -0.1052
    Episode_Reward/pen_action_rate: -0.1143
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0852
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2421
Episode_Reward/pen_flat_orientation: -0.0981
  Episode_Reward/pen_feet_distance: -0.0240
Episode_Reward/pen_feet_regulation: -0.4908
   Episode_Reward/foot_landing_vel: -0.1259
   Episode_Reward/test_gait_reward: -0.9270
Metrics/base_velocity/error_vel_xy: 0.9255
Metrics/base_velocity/error_vel_yaw: 1.1961
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 174784512
                    Iteration time: 1.09s
                        Total time: 1939.44s
                               ETA: 1334.0s

################################################################################
                     [1m Learning iteration 1778/3000 [0m                     

                       Computation: 88868 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 0.4561
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8339
                     Learning rate: 0.0003
                       Mean reward: 139.90
               Mean episode length: 992.38
       Episode_Reward/keep_balance: 0.9894
     Episode_Reward/rew_lin_vel_xy: 6.3446
      Episode_Reward/rew_ang_vel_z: 2.6495
    Episode_Reward/pen_base_height: -0.3107
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1534
   Episode_Reward/pen_joint_torque: -0.2356
    Episode_Reward/pen_joint_accel: -0.1002
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2404
Episode_Reward/pen_flat_orientation: -0.0951
  Episode_Reward/pen_feet_distance: -0.0242
Episode_Reward/pen_feet_regulation: -0.4770
   Episode_Reward/foot_landing_vel: -0.1188
   Episode_Reward/test_gait_reward: -0.9350
Metrics/base_velocity/error_vel_xy: 0.9231
Metrics/base_velocity/error_vel_yaw: 1.1977
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 174882816
                    Iteration time: 1.11s
                        Total time: 1940.54s
                               ETA: 1333.0s

################################################################################
                     [1m Learning iteration 1779/3000 [0m                     

                       Computation: 90717 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.5383
                    Surrogate loss: -0.0056
             Mean action noise std: 0.8344
                     Learning rate: 0.0006
                       Mean reward: 136.40
               Mean episode length: 982.39
       Episode_Reward/keep_balance: 0.9800
     Episode_Reward/rew_lin_vel_xy: 6.2462
      Episode_Reward/rew_ang_vel_z: 2.6065
    Episode_Reward/pen_base_height: -0.2978
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1570
   Episode_Reward/pen_joint_torque: -0.2294
    Episode_Reward/pen_joint_accel: -0.1096
    Episode_Reward/pen_action_rate: -0.1142
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0869
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2416
Episode_Reward/pen_flat_orientation: -0.0953
  Episode_Reward/pen_feet_distance: -0.0265
Episode_Reward/pen_feet_regulation: -0.4789
   Episode_Reward/foot_landing_vel: -0.1273
   Episode_Reward/test_gait_reward: -0.9252
Metrics/base_velocity/error_vel_xy: 0.9334
Metrics/base_velocity/error_vel_yaw: 1.2011
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 174981120
                    Iteration time: 1.08s
                        Total time: 1941.63s
                               ETA: 1331.9s

################################################################################
                     [1m Learning iteration 1780/3000 [0m                     

                       Computation: 87208 steps/s (collection: 1.004s, learning 0.123s)
               Value function loss: 0.5784
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8359
                     Learning rate: 0.0003
                       Mean reward: 139.44
               Mean episode length: 987.70
       Episode_Reward/keep_balance: 0.9784
     Episode_Reward/rew_lin_vel_xy: 6.2745
      Episode_Reward/rew_ang_vel_z: 2.6162
    Episode_Reward/pen_base_height: -0.2877
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1528
   Episode_Reward/pen_joint_torque: -0.2403
    Episode_Reward/pen_joint_accel: -0.0984
    Episode_Reward/pen_action_rate: -0.1140
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2409
Episode_Reward/pen_flat_orientation: -0.0916
  Episode_Reward/pen_feet_distance: -0.0282
Episode_Reward/pen_feet_regulation: -0.4714
   Episode_Reward/foot_landing_vel: -0.1273
   Episode_Reward/test_gait_reward: -0.9160
Metrics/base_velocity/error_vel_xy: 0.9050
Metrics/base_velocity/error_vel_yaw: 1.1762
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 175079424
                    Iteration time: 1.13s
                        Total time: 1942.75s
                               ETA: 1330.8s

################################################################################
                     [1m Learning iteration 1781/3000 [0m                     

                       Computation: 87312 steps/s (collection: 1.002s, learning 0.124s)
               Value function loss: 0.5737
                    Surrogate loss: -0.0004
             Mean action noise std: 0.8358
                     Learning rate: 0.0002
                       Mean reward: 136.45
               Mean episode length: 978.32
       Episode_Reward/keep_balance: 0.9727
     Episode_Reward/rew_lin_vel_xy: 6.1989
      Episode_Reward/rew_ang_vel_z: 2.6017
    Episode_Reward/pen_base_height: -0.2898
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1492
   Episode_Reward/pen_joint_torque: -0.2303
    Episode_Reward/pen_joint_accel: -0.1033
    Episode_Reward/pen_action_rate: -0.1115
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2356
Episode_Reward/pen_flat_orientation: -0.0957
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4712
   Episode_Reward/foot_landing_vel: -0.1287
   Episode_Reward/test_gait_reward: -0.9133
Metrics/base_velocity/error_vel_xy: 0.9213
Metrics/base_velocity/error_vel_yaw: 1.1812
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 175177728
                    Iteration time: 1.13s
                        Total time: 1943.88s
                               ETA: 1329.7s

################################################################################
                     [1m Learning iteration 1782/3000 [0m                     

                       Computation: 88460 steps/s (collection: 0.988s, learning 0.123s)
               Value function loss: 0.5411
                    Surrogate loss: -0.0061
             Mean action noise std: 0.8347
                     Learning rate: 0.0004
                       Mean reward: 142.58
               Mean episode length: 995.06
       Episode_Reward/keep_balance: 0.9966
     Episode_Reward/rew_lin_vel_xy: 6.4292
      Episode_Reward/rew_ang_vel_z: 2.6972
    Episode_Reward/pen_base_height: -0.3025
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1446
   Episode_Reward/pen_joint_torque: -0.2390
    Episode_Reward/pen_joint_accel: -0.1020
    Episode_Reward/pen_action_rate: -0.1126
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2373
Episode_Reward/pen_flat_orientation: -0.0901
  Episode_Reward/pen_feet_distance: -0.0290
Episode_Reward/pen_feet_regulation: -0.4648
   Episode_Reward/foot_landing_vel: -0.1194
   Episode_Reward/test_gait_reward: -0.9366
Metrics/base_velocity/error_vel_xy: 0.9117
Metrics/base_velocity/error_vel_yaw: 1.1720
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 175276032
                    Iteration time: 1.11s
                        Total time: 1944.99s
                               ETA: 1328.7s

################################################################################
                     [1m Learning iteration 1783/3000 [0m                     

                       Computation: 90074 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.6002
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8352
                     Learning rate: 0.0006
                       Mean reward: 139.93
               Mean episode length: 987.67
       Episode_Reward/keep_balance: 0.9945
     Episode_Reward/rew_lin_vel_xy: 6.3618
      Episode_Reward/rew_ang_vel_z: 2.6750
    Episode_Reward/pen_base_height: -0.2972
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1540
   Episode_Reward/pen_joint_torque: -0.2359
    Episode_Reward/pen_joint_accel: -0.1079
    Episode_Reward/pen_action_rate: -0.1145
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2406
Episode_Reward/pen_flat_orientation: -0.0957
  Episode_Reward/pen_feet_distance: -0.0259
Episode_Reward/pen_feet_regulation: -0.4817
   Episode_Reward/foot_landing_vel: -0.1296
   Episode_Reward/test_gait_reward: -0.9406
Metrics/base_velocity/error_vel_xy: 0.9316
Metrics/base_velocity/error_vel_yaw: 1.1772
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 175374336
                    Iteration time: 1.09s
                        Total time: 1946.08s
                               ETA: 1327.6s

################################################################################
                     [1m Learning iteration 1784/3000 [0m                     

                       Computation: 88407 steps/s (collection: 0.988s, learning 0.123s)
               Value function loss: 0.5652
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8356
                     Learning rate: 0.0009
                       Mean reward: 136.50
               Mean episode length: 964.64
       Episode_Reward/keep_balance: 0.9590
     Episode_Reward/rew_lin_vel_xy: 6.1465
      Episode_Reward/rew_ang_vel_z: 2.5756
    Episode_Reward/pen_base_height: -0.2849
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1471
   Episode_Reward/pen_joint_torque: -0.2224
    Episode_Reward/pen_joint_accel: -0.1036
    Episode_Reward/pen_action_rate: -0.1087
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0532
   Episode_Reward/pen_joint_powers: -0.0839
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2300
Episode_Reward/pen_flat_orientation: -0.0939
  Episode_Reward/pen_feet_distance: -0.0223
Episode_Reward/pen_feet_regulation: -0.4537
   Episode_Reward/foot_landing_vel: -0.1196
   Episode_Reward/test_gait_reward: -0.8947
Metrics/base_velocity/error_vel_xy: 0.8951
Metrics/base_velocity/error_vel_yaw: 1.1461
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 175472640
                    Iteration time: 1.11s
                        Total time: 1947.19s
                               ETA: 1326.5s

################################################################################
                     [1m Learning iteration 1785/3000 [0m                     

                       Computation: 87339 steps/s (collection: 0.998s, learning 0.127s)
               Value function loss: 0.5577
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8362
                     Learning rate: 0.0003
                       Mean reward: 137.98
               Mean episode length: 973.68
       Episode_Reward/keep_balance: 0.9771
     Episode_Reward/rew_lin_vel_xy: 6.2786
      Episode_Reward/rew_ang_vel_z: 2.6290
    Episode_Reward/pen_base_height: -0.2902
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.1584
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1048
    Episode_Reward/pen_action_rate: -0.1125
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0855
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2404
Episode_Reward/pen_flat_orientation: -0.0937
  Episode_Reward/pen_feet_distance: -0.0286
Episode_Reward/pen_feet_regulation: -0.4645
   Episode_Reward/foot_landing_vel: -0.1233
   Episode_Reward/test_gait_reward: -0.9185
Metrics/base_velocity/error_vel_xy: 0.8953
Metrics/base_velocity/error_vel_yaw: 1.1573
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 175570944
                    Iteration time: 1.13s
                        Total time: 1948.32s
                               ETA: 1325.4s

################################################################################
                     [1m Learning iteration 1786/3000 [0m                     

                       Computation: 83103 steps/s (collection: 1.055s, learning 0.128s)
               Value function loss: 0.5904
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8349
                     Learning rate: 0.0006
                       Mean reward: 140.92
               Mean episode length: 989.25
       Episode_Reward/keep_balance: 0.9896
     Episode_Reward/rew_lin_vel_xy: 6.3925
      Episode_Reward/rew_ang_vel_z: 2.6465
    Episode_Reward/pen_base_height: -0.2952
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.1551
   Episode_Reward/pen_joint_torque: -0.2266
    Episode_Reward/pen_joint_accel: -0.1143
    Episode_Reward/pen_action_rate: -0.1138
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0558
   Episode_Reward/pen_joint_powers: -0.0854
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2430
Episode_Reward/pen_flat_orientation: -0.0923
  Episode_Reward/pen_feet_distance: -0.0237
Episode_Reward/pen_feet_regulation: -0.4707
   Episode_Reward/foot_landing_vel: -0.1210
   Episode_Reward/test_gait_reward: -0.9241
Metrics/base_velocity/error_vel_xy: 0.9056
Metrics/base_velocity/error_vel_yaw: 1.1886
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 175669248
                    Iteration time: 1.18s
                        Total time: 1949.50s
                               ETA: 1324.4s

################################################################################
                     [1m Learning iteration 1787/3000 [0m                     

                       Computation: 87471 steps/s (collection: 0.994s, learning 0.129s)
               Value function loss: 0.4977
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8350
                     Learning rate: 0.0004
                       Mean reward: 135.44
               Mean episode length: 965.91
       Episode_Reward/keep_balance: 0.9720
     Episode_Reward/rew_lin_vel_xy: 6.2471
      Episode_Reward/rew_ang_vel_z: 2.5716
    Episode_Reward/pen_base_height: -0.2868
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1480
   Episode_Reward/pen_joint_torque: -0.2331
    Episode_Reward/pen_joint_accel: -0.1017
    Episode_Reward/pen_action_rate: -0.1119
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0541
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2373
Episode_Reward/pen_flat_orientation: -0.0871
  Episode_Reward/pen_feet_distance: -0.0260
Episode_Reward/pen_feet_regulation: -0.4605
   Episode_Reward/foot_landing_vel: -0.1179
   Episode_Reward/test_gait_reward: -0.9142
Metrics/base_velocity/error_vel_xy: 0.8939
Metrics/base_velocity/error_vel_yaw: 1.1951
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 175767552
                    Iteration time: 1.12s
                        Total time: 1950.63s
                               ETA: 1323.3s

################################################################################
                     [1m Learning iteration 1788/3000 [0m                     

                       Computation: 87561 steps/s (collection: 0.996s, learning 0.127s)
               Value function loss: 0.5664
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8348
                     Learning rate: 0.0003
                       Mean reward: 139.68
               Mean episode length: 990.25
       Episode_Reward/keep_balance: 0.9865
     Episode_Reward/rew_lin_vel_xy: 6.2701
      Episode_Reward/rew_ang_vel_z: 2.6661
    Episode_Reward/pen_base_height: -0.3023
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1516
   Episode_Reward/pen_joint_torque: -0.2466
    Episode_Reward/pen_joint_accel: -0.1049
    Episode_Reward/pen_action_rate: -0.1139
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2405
Episode_Reward/pen_flat_orientation: -0.0950
  Episode_Reward/pen_feet_distance: -0.0270
Episode_Reward/pen_feet_regulation: -0.4727
   Episode_Reward/foot_landing_vel: -0.1277
   Episode_Reward/test_gait_reward: -0.9306
Metrics/base_velocity/error_vel_xy: 0.9372
Metrics/base_velocity/error_vel_yaw: 1.1598
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 175865856
                    Iteration time: 1.12s
                        Total time: 1951.75s
                               ETA: 1322.3s

################################################################################
                     [1m Learning iteration 1789/3000 [0m                     

                       Computation: 86481 steps/s (collection: 1.007s, learning 0.130s)
               Value function loss: 0.5567
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8361
                     Learning rate: 0.0006
                       Mean reward: 136.83
               Mean episode length: 969.78
       Episode_Reward/keep_balance: 0.9664
     Episode_Reward/rew_lin_vel_xy: 6.1643
      Episode_Reward/rew_ang_vel_z: 2.5500
    Episode_Reward/pen_base_height: -0.2816
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1512
   Episode_Reward/pen_joint_torque: -0.2131
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1109
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0827
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2370
Episode_Reward/pen_flat_orientation: -0.0945
  Episode_Reward/pen_feet_distance: -0.0221
Episode_Reward/pen_feet_regulation: -0.4750
   Episode_Reward/foot_landing_vel: -0.1341
   Episode_Reward/test_gait_reward: -0.9074
Metrics/base_velocity/error_vel_xy: 0.9216
Metrics/base_velocity/error_vel_yaw: 1.1946
      Episode_Termination/time_out: 3.2500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 175964160
                    Iteration time: 1.14s
                        Total time: 1952.88s
                               ETA: 1321.2s

################################################################################
                     [1m Learning iteration 1790/3000 [0m                     

                       Computation: 82609 steps/s (collection: 1.057s, learning 0.133s)
               Value function loss: 0.5358
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8367
                     Learning rate: 0.0006
                       Mean reward: 136.56
               Mean episode length: 968.28
       Episode_Reward/keep_balance: 0.9733
     Episode_Reward/rew_lin_vel_xy: 6.2389
      Episode_Reward/rew_ang_vel_z: 2.6111
    Episode_Reward/pen_base_height: -0.2864
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1525
   Episode_Reward/pen_joint_torque: -0.2275
    Episode_Reward/pen_joint_accel: -0.1047
    Episode_Reward/pen_action_rate: -0.1120
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2389
Episode_Reward/pen_flat_orientation: -0.0948
  Episode_Reward/pen_feet_distance: -0.0245
Episode_Reward/pen_feet_regulation: -0.4473
   Episode_Reward/foot_landing_vel: -0.1197
   Episode_Reward/test_gait_reward: -0.9012
Metrics/base_velocity/error_vel_xy: 0.8977
Metrics/base_velocity/error_vel_yaw: 1.1702
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 176062464
                    Iteration time: 1.19s
                        Total time: 1954.07s
                               ETA: 1320.2s

################################################################################
                     [1m Learning iteration 1791/3000 [0m                     

                       Computation: 86492 steps/s (collection: 1.008s, learning 0.129s)
               Value function loss: 0.4979
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8361
                     Learning rate: 0.0004
                       Mean reward: 136.92
               Mean episode length: 982.98
       Episode_Reward/keep_balance: 0.9886
     Episode_Reward/rew_lin_vel_xy: 6.3135
      Episode_Reward/rew_ang_vel_z: 2.6057
    Episode_Reward/pen_base_height: -0.2976
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1495
   Episode_Reward/pen_joint_torque: -0.2361
    Episode_Reward/pen_joint_accel: -0.0997
    Episode_Reward/pen_action_rate: -0.1152
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2441
Episode_Reward/pen_flat_orientation: -0.0931
  Episode_Reward/pen_feet_distance: -0.0213
Episode_Reward/pen_feet_regulation: -0.4877
   Episode_Reward/foot_landing_vel: -0.1268
   Episode_Reward/test_gait_reward: -0.9269
Metrics/base_velocity/error_vel_xy: 0.9403
Metrics/base_velocity/error_vel_yaw: 1.2179
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 176160768
                    Iteration time: 1.14s
                        Total time: 1955.21s
                               ETA: 1319.1s

################################################################################
                     [1m Learning iteration 1792/3000 [0m                     

                       Computation: 84819 steps/s (collection: 1.028s, learning 0.131s)
               Value function loss: 0.6292
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8359
                     Learning rate: 0.0009
                       Mean reward: 139.05
               Mean episode length: 976.52
       Episode_Reward/keep_balance: 0.9723
     Episode_Reward/rew_lin_vel_xy: 6.2608
      Episode_Reward/rew_ang_vel_z: 2.6076
    Episode_Reward/pen_base_height: -0.2901
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1523
   Episode_Reward/pen_joint_torque: -0.2218
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.1115
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0838
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2369
Episode_Reward/pen_flat_orientation: -0.0922
  Episode_Reward/pen_feet_distance: -0.0241
Episode_Reward/pen_feet_regulation: -0.4529
   Episode_Reward/foot_landing_vel: -0.1195
   Episode_Reward/test_gait_reward: -0.9135
Metrics/base_velocity/error_vel_xy: 0.8920
Metrics/base_velocity/error_vel_yaw: 1.1650
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 176259072
                    Iteration time: 1.16s
                        Total time: 1956.37s
                               ETA: 1318.1s

################################################################################
                     [1m Learning iteration 1793/3000 [0m                     

                       Computation: 86391 steps/s (collection: 1.010s, learning 0.127s)
               Value function loss: 0.5894
                    Surrogate loss: -0.0012
             Mean action noise std: 0.8366
                     Learning rate: 0.0003
                       Mean reward: 138.39
               Mean episode length: 986.30
       Episode_Reward/keep_balance: 0.9858
     Episode_Reward/rew_lin_vel_xy: 6.2808
      Episode_Reward/rew_ang_vel_z: 2.6072
    Episode_Reward/pen_base_height: -0.2849
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1586
   Episode_Reward/pen_joint_torque: -0.2255
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.1145
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2429
Episode_Reward/pen_flat_orientation: -0.0971
  Episode_Reward/pen_feet_distance: -0.0233
Episode_Reward/pen_feet_regulation: -0.4723
   Episode_Reward/foot_landing_vel: -0.1279
   Episode_Reward/test_gait_reward: -0.9296
Metrics/base_velocity/error_vel_xy: 0.9209
Metrics/base_velocity/error_vel_yaw: 1.2120
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 176357376
                    Iteration time: 1.14s
                        Total time: 1957.51s
                               ETA: 1317.0s

################################################################################
                     [1m Learning iteration 1794/3000 [0m                     

                       Computation: 88138 steps/s (collection: 0.990s, learning 0.126s)
               Value function loss: 0.5312
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8355
                     Learning rate: 0.0006
                       Mean reward: 136.27
               Mean episode length: 976.15
       Episode_Reward/keep_balance: 0.9752
     Episode_Reward/rew_lin_vel_xy: 6.2484
      Episode_Reward/rew_ang_vel_z: 2.6211
    Episode_Reward/pen_base_height: -0.2865
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1505
   Episode_Reward/pen_joint_torque: -0.2290
    Episode_Reward/pen_joint_accel: -0.1215
    Episode_Reward/pen_action_rate: -0.1127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0859
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2405
Episode_Reward/pen_flat_orientation: -0.0940
  Episode_Reward/pen_feet_distance: -0.0234
Episode_Reward/pen_feet_regulation: -0.4715
   Episode_Reward/foot_landing_vel: -0.1273
   Episode_Reward/test_gait_reward: -0.9079
Metrics/base_velocity/error_vel_xy: 0.9178
Metrics/base_velocity/error_vel_yaw: 1.1626
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 176455680
                    Iteration time: 1.12s
                        Total time: 1958.62s
                               ETA: 1315.9s

################################################################################
                     [1m Learning iteration 1795/3000 [0m                     

                       Computation: 88280 steps/s (collection: 0.988s, learning 0.126s)
               Value function loss: 0.5774
                    Surrogate loss: 0.0010
             Mean action noise std: 0.8352
                     Learning rate: 0.0001
                       Mean reward: 140.82
               Mean episode length: 985.32
       Episode_Reward/keep_balance: 0.9876
     Episode_Reward/rew_lin_vel_xy: 6.3628
      Episode_Reward/rew_ang_vel_z: 2.6550
    Episode_Reward/pen_base_height: -0.2876
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1574
   Episode_Reward/pen_joint_torque: -0.2299
    Episode_Reward/pen_joint_accel: -0.1090
    Episode_Reward/pen_action_rate: -0.1132
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2404
Episode_Reward/pen_flat_orientation: -0.0924
  Episode_Reward/pen_feet_distance: -0.0260
Episode_Reward/pen_feet_regulation: -0.4509
   Episode_Reward/foot_landing_vel: -0.1282
   Episode_Reward/test_gait_reward: -0.9188
Metrics/base_velocity/error_vel_xy: 0.9028
Metrics/base_velocity/error_vel_yaw: 1.1807
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 176553984
                    Iteration time: 1.11s
                        Total time: 1959.74s
                               ETA: 1314.9s

################################################################################
                     [1m Learning iteration 1796/3000 [0m                     

                       Computation: 89036 steps/s (collection: 0.980s, learning 0.124s)
               Value function loss: 0.5116
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8333
                     Learning rate: 0.0004
                       Mean reward: 138.31
               Mean episode length: 986.58
       Episode_Reward/keep_balance: 0.9878
     Episode_Reward/rew_lin_vel_xy: 6.3410
      Episode_Reward/rew_ang_vel_z: 2.6174
    Episode_Reward/pen_base_height: -0.3018
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1515
   Episode_Reward/pen_joint_torque: -0.2336
    Episode_Reward/pen_joint_accel: -0.1069
    Episode_Reward/pen_action_rate: -0.1143
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0879
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2419
Episode_Reward/pen_flat_orientation: -0.0903
  Episode_Reward/pen_feet_distance: -0.0237
Episode_Reward/pen_feet_regulation: -0.4801
   Episode_Reward/foot_landing_vel: -0.1272
   Episode_Reward/test_gait_reward: -0.9266
Metrics/base_velocity/error_vel_xy: 0.9137
Metrics/base_velocity/error_vel_yaw: 1.2133
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 176652288
                    Iteration time: 1.10s
                        Total time: 1960.84s
                               ETA: 1313.8s

################################################################################
                     [1m Learning iteration 1797/3000 [0m                     

                       Computation: 87390 steps/s (collection: 0.999s, learning 0.126s)
               Value function loss: 0.5323
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8329
                     Learning rate: 0.0004
                       Mean reward: 140.74
               Mean episode length: 999.22
       Episode_Reward/keep_balance: 0.9996
     Episode_Reward/rew_lin_vel_xy: 6.4060
      Episode_Reward/rew_ang_vel_z: 2.6363
    Episode_Reward/pen_base_height: -0.2845
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1628
   Episode_Reward/pen_joint_torque: -0.2271
    Episode_Reward/pen_joint_accel: -0.1118
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2477
Episode_Reward/pen_flat_orientation: -0.0921
  Episode_Reward/pen_feet_distance: -0.0218
Episode_Reward/pen_feet_regulation: -0.4966
   Episode_Reward/foot_landing_vel: -0.1329
   Episode_Reward/test_gait_reward: -0.9391
Metrics/base_velocity/error_vel_xy: 0.9299
Metrics/base_velocity/error_vel_yaw: 1.2380
      Episode_Termination/time_out: 5.0833
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 176750592
                    Iteration time: 1.12s
                        Total time: 1961.97s
                               ETA: 1312.7s

################################################################################
                     [1m Learning iteration 1798/3000 [0m                     

                       Computation: 89736 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.5266
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8336
                     Learning rate: 0.0004
                       Mean reward: 141.92
               Mean episode length: 998.69
       Episode_Reward/keep_balance: 0.9993
     Episode_Reward/rew_lin_vel_xy: 6.4621
      Episode_Reward/rew_ang_vel_z: 2.6692
    Episode_Reward/pen_base_height: -0.2994
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1539
   Episode_Reward/pen_joint_torque: -0.2374
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2467
Episode_Reward/pen_flat_orientation: -0.0882
  Episode_Reward/pen_feet_distance: -0.0344
Episode_Reward/pen_feet_regulation: -0.4754
   Episode_Reward/foot_landing_vel: -0.1321
   Episode_Reward/test_gait_reward: -0.9313
Metrics/base_velocity/error_vel_xy: 0.8953
Metrics/base_velocity/error_vel_yaw: 1.1975
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 176848896
                    Iteration time: 1.10s
                        Total time: 1963.06s
                               ETA: 1311.6s

################################################################################
                     [1m Learning iteration 1799/3000 [0m                     

                       Computation: 86617 steps/s (collection: 1.010s, learning 0.125s)
               Value function loss: 0.4701
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8353
                     Learning rate: 0.0004
                       Mean reward: 135.60
               Mean episode length: 975.47
       Episode_Reward/keep_balance: 0.9813
     Episode_Reward/rew_lin_vel_xy: 6.2217
      Episode_Reward/rew_ang_vel_z: 2.5874
    Episode_Reward/pen_base_height: -0.2907
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.1525
   Episode_Reward/pen_joint_torque: -0.2387
    Episode_Reward/pen_joint_accel: -0.1091
    Episode_Reward/pen_action_rate: -0.1152
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0588
   Episode_Reward/pen_joint_powers: -0.0897
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2430
Episode_Reward/pen_flat_orientation: -0.0951
  Episode_Reward/pen_feet_distance: -0.0256
Episode_Reward/pen_feet_regulation: -0.4896
   Episode_Reward/foot_landing_vel: -0.1400
   Episode_Reward/test_gait_reward: -0.9212
Metrics/base_velocity/error_vel_xy: 0.9450
Metrics/base_velocity/error_vel_yaw: 1.2213
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 176947200
                    Iteration time: 1.13s
                        Total time: 1964.20s
                               ETA: 1310.6s

################################################################################
                     [1m Learning iteration 1800/3000 [0m                     

                       Computation: 88633 steps/s (collection: 0.986s, learning 0.123s)
               Value function loss: 0.5116
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8363
                     Learning rate: 0.0006
                       Mean reward: 140.18
               Mean episode length: 990.24
       Episode_Reward/keep_balance: 0.9919
     Episode_Reward/rew_lin_vel_xy: 6.3751
      Episode_Reward/rew_ang_vel_z: 2.6035
    Episode_Reward/pen_base_height: -0.2927
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1579
   Episode_Reward/pen_joint_torque: -0.2311
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1153
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0879
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2430
Episode_Reward/pen_flat_orientation: -0.0914
  Episode_Reward/pen_feet_distance: -0.0274
Episode_Reward/pen_feet_regulation: -0.4842
   Episode_Reward/foot_landing_vel: -0.1324
   Episode_Reward/test_gait_reward: -0.9284
Metrics/base_velocity/error_vel_xy: 0.9100
Metrics/base_velocity/error_vel_yaw: 1.2395
      Episode_Termination/time_out: 5.1667
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 177045504
                    Iteration time: 1.11s
                        Total time: 1965.31s
                               ETA: 1309.5s

################################################################################
                     [1m Learning iteration 1801/3000 [0m                     

                       Computation: 90945 steps/s (collection: 0.956s, learning 0.125s)
               Value function loss: 0.5143
                    Surrogate loss: 0.0011
             Mean action noise std: 0.8367
                     Learning rate: 0.0001
                       Mean reward: 142.45
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4263
      Episode_Reward/rew_ang_vel_z: 2.6836
    Episode_Reward/pen_base_height: -0.2846
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1543
   Episode_Reward/pen_joint_torque: -0.2424
    Episode_Reward/pen_joint_accel: -0.1028
    Episode_Reward/pen_action_rate: -0.1160
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2452
Episode_Reward/pen_flat_orientation: -0.0873
  Episode_Reward/pen_feet_distance: -0.0239
Episode_Reward/pen_feet_regulation: -0.4720
   Episode_Reward/foot_landing_vel: -0.1278
   Episode_Reward/test_gait_reward: -0.9316
Metrics/base_velocity/error_vel_xy: 0.9043
Metrics/base_velocity/error_vel_yaw: 1.1882
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 177143808
                    Iteration time: 1.08s
                        Total time: 1966.39s
                               ETA: 1308.4s

################################################################################
                     [1m Learning iteration 1802/3000 [0m                     

                       Computation: 90263 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.5711
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8357
                     Learning rate: 0.0003
                       Mean reward: 139.39
               Mean episode length: 978.04
       Episode_Reward/keep_balance: 0.9665
     Episode_Reward/rew_lin_vel_xy: 6.2041
      Episode_Reward/rew_ang_vel_z: 2.5852
    Episode_Reward/pen_base_height: -0.2842
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1497
   Episode_Reward/pen_joint_torque: -0.2257
    Episode_Reward/pen_joint_accel: -0.1003
    Episode_Reward/pen_action_rate: -0.1107
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0540
   Episode_Reward/pen_joint_powers: -0.0844
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2336
Episode_Reward/pen_flat_orientation: -0.0904
  Episode_Reward/pen_feet_distance: -0.0268
Episode_Reward/pen_feet_regulation: -0.4587
   Episode_Reward/foot_landing_vel: -0.1191
   Episode_Reward/test_gait_reward: -0.9024
Metrics/base_velocity/error_vel_xy: 0.8909
Metrics/base_velocity/error_vel_yaw: 1.1671
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 177242112
                    Iteration time: 1.09s
                        Total time: 1967.48s
                               ETA: 1307.3s

################################################################################
                     [1m Learning iteration 1803/3000 [0m                     

                       Computation: 88896 steps/s (collection: 0.982s, learning 0.124s)
               Value function loss: 0.5670
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8355
                     Learning rate: 0.0001
                       Mean reward: 139.35
               Mean episode length: 977.16
       Episode_Reward/keep_balance: 0.9736
     Episode_Reward/rew_lin_vel_xy: 6.2523
      Episode_Reward/rew_ang_vel_z: 2.6271
    Episode_Reward/pen_base_height: -0.2786
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1507
   Episode_Reward/pen_joint_torque: -0.2210
    Episode_Reward/pen_joint_accel: -0.1061
    Episode_Reward/pen_action_rate: -0.1115
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0844
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2368
Episode_Reward/pen_flat_orientation: -0.0923
  Episode_Reward/pen_feet_distance: -0.0268
Episode_Reward/pen_feet_regulation: -0.4655
   Episode_Reward/foot_landing_vel: -0.1244
   Episode_Reward/test_gait_reward: -0.9002
Metrics/base_velocity/error_vel_xy: 0.8990
Metrics/base_velocity/error_vel_yaw: 1.1505
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 177340416
                    Iteration time: 1.11s
                        Total time: 1968.58s
                               ETA: 1306.2s

################################################################################
                     [1m Learning iteration 1804/3000 [0m                     

                       Computation: 88469 steps/s (collection: 0.986s, learning 0.125s)
               Value function loss: 0.5600
                    Surrogate loss: -0.0016
             Mean action noise std: 0.8355
                     Learning rate: 0.0002
                       Mean reward: 136.16
               Mean episode length: 962.83
       Episode_Reward/keep_balance: 0.9393
     Episode_Reward/rew_lin_vel_xy: 6.0281
      Episode_Reward/rew_ang_vel_z: 2.4925
    Episode_Reward/pen_base_height: -0.2691
      Episode_Reward/pen_lin_vel_z: -0.0347
     Episode_Reward/pen_ang_vel_xy: -0.1448
   Episode_Reward/pen_joint_torque: -0.2180
    Episode_Reward/pen_joint_accel: -0.1059
    Episode_Reward/pen_action_rate: -0.1080
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0536
   Episode_Reward/pen_joint_powers: -0.0826
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2317
Episode_Reward/pen_flat_orientation: -0.0942
  Episode_Reward/pen_feet_distance: -0.0275
Episode_Reward/pen_feet_regulation: -0.4434
   Episode_Reward/foot_landing_vel: -0.1237
   Episode_Reward/test_gait_reward: -0.8759
Metrics/base_velocity/error_vel_xy: 0.8628
Metrics/base_velocity/error_vel_yaw: 1.1475
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 177438720
                    Iteration time: 1.11s
                        Total time: 1969.69s
                               ETA: 1305.1s

################################################################################
                     [1m Learning iteration 1805/3000 [0m                     

                       Computation: 88756 steps/s (collection: 0.983s, learning 0.125s)
               Value function loss: 0.5380
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8340
                     Learning rate: 0.0004
                       Mean reward: 141.48
               Mean episode length: 992.21
       Episode_Reward/keep_balance: 0.9938
     Episode_Reward/rew_lin_vel_xy: 6.4083
      Episode_Reward/rew_ang_vel_z: 2.6841
    Episode_Reward/pen_base_height: -0.2953
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1494
   Episode_Reward/pen_joint_torque: -0.2383
    Episode_Reward/pen_joint_accel: -0.1028
    Episode_Reward/pen_action_rate: -0.1141
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2417
Episode_Reward/pen_flat_orientation: -0.0924
  Episode_Reward/pen_feet_distance: -0.0294
Episode_Reward/pen_feet_regulation: -0.4466
   Episode_Reward/foot_landing_vel: -0.1195
   Episode_Reward/test_gait_reward: -0.9278
Metrics/base_velocity/error_vel_xy: 0.9057
Metrics/base_velocity/error_vel_yaw: 1.1773
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 177537024
                    Iteration time: 1.11s
                        Total time: 1970.80s
                               ETA: 1304.0s

################################################################################
                     [1m Learning iteration 1806/3000 [0m                     

                       Computation: 89843 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.5255
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8339
                     Learning rate: 0.0004
                       Mean reward: 139.67
               Mean episode length: 992.59
       Episode_Reward/keep_balance: 0.9969
     Episode_Reward/rew_lin_vel_xy: 6.4006
      Episode_Reward/rew_ang_vel_z: 2.6204
    Episode_Reward/pen_base_height: -0.2848
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1587
   Episode_Reward/pen_joint_torque: -0.2269
    Episode_Reward/pen_joint_accel: -0.0974
    Episode_Reward/pen_action_rate: -0.1167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2482
Episode_Reward/pen_flat_orientation: -0.0940
  Episode_Reward/pen_feet_distance: -0.0272
Episode_Reward/pen_feet_regulation: -0.4798
   Episode_Reward/foot_landing_vel: -0.1295
   Episode_Reward/test_gait_reward: -0.9281
Metrics/base_velocity/error_vel_xy: 0.9170
Metrics/base_velocity/error_vel_yaw: 1.2460
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 177635328
                    Iteration time: 1.09s
                        Total time: 1971.89s
                               ETA: 1303.0s

################################################################################
                     [1m Learning iteration 1807/3000 [0m                     

                       Computation: 90128 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.5551
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8360
                     Learning rate: 0.0006
                       Mean reward: 137.58
               Mean episode length: 970.20
       Episode_Reward/keep_balance: 0.9476
     Episode_Reward/rew_lin_vel_xy: 6.0401
      Episode_Reward/rew_ang_vel_z: 2.5171
    Episode_Reward/pen_base_height: -0.2742
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.1481
   Episode_Reward/pen_joint_torque: -0.2223
    Episode_Reward/pen_joint_accel: -0.1017
    Episode_Reward/pen_action_rate: -0.1098
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0537
   Episode_Reward/pen_joint_powers: -0.0831
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2334
Episode_Reward/pen_flat_orientation: -0.0915
  Episode_Reward/pen_feet_distance: -0.0295
Episode_Reward/pen_feet_regulation: -0.4487
   Episode_Reward/foot_landing_vel: -0.1235
   Episode_Reward/test_gait_reward: -0.8786
Metrics/base_velocity/error_vel_xy: 0.8963
Metrics/base_velocity/error_vel_yaw: 1.1613
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 177733632
                    Iteration time: 1.09s
                        Total time: 1972.99s
                               ETA: 1301.9s

################################################################################
                     [1m Learning iteration 1808/3000 [0m                     

                       Computation: 91113 steps/s (collection: 0.955s, learning 0.124s)
               Value function loss: 0.5600
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8379
                     Learning rate: 0.0003
                       Mean reward: 138.86
               Mean episode length: 972.53
       Episode_Reward/keep_balance: 0.9702
     Episode_Reward/rew_lin_vel_xy: 6.2554
      Episode_Reward/rew_ang_vel_z: 2.5787
    Episode_Reward/pen_base_height: -0.2721
      Episode_Reward/pen_lin_vel_z: -0.0346
     Episode_Reward/pen_ang_vel_xy: -0.1540
   Episode_Reward/pen_joint_torque: -0.2119
    Episode_Reward/pen_joint_accel: -0.0981
    Episode_Reward/pen_action_rate: -0.1098
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0537
   Episode_Reward/pen_joint_powers: -0.0820
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2361
Episode_Reward/pen_flat_orientation: -0.0902
  Episode_Reward/pen_feet_distance: -0.0258
Episode_Reward/pen_feet_regulation: -0.4522
   Episode_Reward/foot_landing_vel: -0.1220
   Episode_Reward/test_gait_reward: -0.8969
Metrics/base_velocity/error_vel_xy: 0.8737
Metrics/base_velocity/error_vel_yaw: 1.1816
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 177831936
                    Iteration time: 1.08s
                        Total time: 1974.06s
                               ETA: 1300.8s

################################################################################
                     [1m Learning iteration 1809/3000 [0m                     

                       Computation: 91141 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.5559
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8374
                     Learning rate: 0.0006
                       Mean reward: 140.00
               Mean episode length: 987.23
       Episode_Reward/keep_balance: 0.9918
     Episode_Reward/rew_lin_vel_xy: 6.3824
      Episode_Reward/rew_ang_vel_z: 2.6184
    Episode_Reward/pen_base_height: -0.2889
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1537
   Episode_Reward/pen_joint_torque: -0.2318
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.1148
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0869
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2429
Episode_Reward/pen_flat_orientation: -0.0903
  Episode_Reward/pen_feet_distance: -0.0310
Episode_Reward/pen_feet_regulation: -0.4822
   Episode_Reward/foot_landing_vel: -0.1200
   Episode_Reward/test_gait_reward: -0.9284
Metrics/base_velocity/error_vel_xy: 0.9087
Metrics/base_velocity/error_vel_yaw: 1.2247
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 177930240
                    Iteration time: 1.08s
                        Total time: 1975.14s
                               ETA: 1299.7s

################################################################################
                     [1m Learning iteration 1810/3000 [0m                     

                       Computation: 91984 steps/s (collection: 0.947s, learning 0.122s)
               Value function loss: 0.4954
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8365
                     Learning rate: 0.0004
                       Mean reward: 137.91
               Mean episode length: 980.68
       Episode_Reward/keep_balance: 0.9844
     Episode_Reward/rew_lin_vel_xy: 6.3481
      Episode_Reward/rew_ang_vel_z: 2.6095
    Episode_Reward/pen_base_height: -0.2870
      Episode_Reward/pen_lin_vel_z: -0.0347
     Episode_Reward/pen_ang_vel_xy: -0.1550
   Episode_Reward/pen_joint_torque: -0.2342
    Episode_Reward/pen_joint_accel: -0.1127
    Episode_Reward/pen_action_rate: -0.1143
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2413
Episode_Reward/pen_flat_orientation: -0.0952
  Episode_Reward/pen_feet_distance: -0.0249
Episode_Reward/pen_feet_regulation: -0.4672
   Episode_Reward/foot_landing_vel: -0.1367
   Episode_Reward/test_gait_reward: -0.9267
Metrics/base_velocity/error_vel_xy: 0.8932
Metrics/base_velocity/error_vel_yaw: 1.2119
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 178028544
                    Iteration time: 1.07s
                        Total time: 1976.21s
                               ETA: 1298.6s

################################################################################
                     [1m Learning iteration 1811/3000 [0m                     

                       Computation: 88781 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 0.5171
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8355
                     Learning rate: 0.0009
                       Mean reward: 137.34
               Mean episode length: 982.10
       Episode_Reward/keep_balance: 0.9793
     Episode_Reward/rew_lin_vel_xy: 6.3052
      Episode_Reward/rew_ang_vel_z: 2.5959
    Episode_Reward/pen_base_height: -0.2824
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1568
   Episode_Reward/pen_joint_torque: -0.2273
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.1127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0859
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2409
Episode_Reward/pen_flat_orientation: -0.0945
  Episode_Reward/pen_feet_distance: -0.0288
Episode_Reward/pen_feet_regulation: -0.4764
   Episode_Reward/foot_landing_vel: -0.1390
   Episode_Reward/test_gait_reward: -0.9097
Metrics/base_velocity/error_vel_xy: 0.9002
Metrics/base_velocity/error_vel_yaw: 1.1930
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 178126848
                    Iteration time: 1.11s
                        Total time: 1977.32s
                               ETA: 1297.5s

################################################################################
                     [1m Learning iteration 1812/3000 [0m                     

                       Computation: 90730 steps/s (collection: 0.959s, learning 0.125s)
               Value function loss: 0.5513
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8343
                     Learning rate: 0.0004
                       Mean reward: 143.41
               Mean episode length: 999.07
       Episode_Reward/keep_balance: 0.9995
     Episode_Reward/rew_lin_vel_xy: 6.4660
      Episode_Reward/rew_ang_vel_z: 2.6623
    Episode_Reward/pen_base_height: -0.2743
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1579
   Episode_Reward/pen_joint_torque: -0.2242
    Episode_Reward/pen_joint_accel: -0.1175
    Episode_Reward/pen_action_rate: -0.1148
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2456
Episode_Reward/pen_flat_orientation: -0.0906
  Episode_Reward/pen_feet_distance: -0.0304
Episode_Reward/pen_feet_regulation: -0.4762
   Episode_Reward/foot_landing_vel: -0.1318
   Episode_Reward/test_gait_reward: -0.9263
Metrics/base_velocity/error_vel_xy: 0.8976
Metrics/base_velocity/error_vel_yaw: 1.2130
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 178225152
                    Iteration time: 1.08s
                        Total time: 1978.40s
                               ETA: 1296.4s

################################################################################
                     [1m Learning iteration 1813/3000 [0m                     

                       Computation: 87853 steps/s (collection: 0.996s, learning 0.123s)
               Value function loss: 0.6591
                    Surrogate loss: -0.0051
             Mean action noise std: 0.8348
                     Learning rate: 0.0006
                       Mean reward: 135.49
               Mean episode length: 977.89
       Episode_Reward/keep_balance: 0.9822
     Episode_Reward/rew_lin_vel_xy: 6.2824
      Episode_Reward/rew_ang_vel_z: 2.5666
    Episode_Reward/pen_base_height: -0.2973
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1595
   Episode_Reward/pen_joint_torque: -0.2305
    Episode_Reward/pen_joint_accel: -0.1119
    Episode_Reward/pen_action_rate: -0.1164
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0596
   Episode_Reward/pen_joint_powers: -0.0900
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2459
Episode_Reward/pen_flat_orientation: -0.0981
  Episode_Reward/pen_feet_distance: -0.0310
Episode_Reward/pen_feet_regulation: -0.5105
   Episode_Reward/foot_landing_vel: -0.1331
   Episode_Reward/test_gait_reward: -0.9240
Metrics/base_velocity/error_vel_xy: 0.9231
Metrics/base_velocity/error_vel_yaw: 1.2387
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 178323456
                    Iteration time: 1.12s
                        Total time: 1979.52s
                               ETA: 1295.3s

################################################################################
                     [1m Learning iteration 1814/3000 [0m                     

                       Computation: 89758 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 0.5375
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8350
                     Learning rate: 0.0004
                       Mean reward: 138.46
               Mean episode length: 976.18
       Episode_Reward/keep_balance: 0.9732
     Episode_Reward/rew_lin_vel_xy: 6.2614
      Episode_Reward/rew_ang_vel_z: 2.5889
    Episode_Reward/pen_base_height: -0.2877
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1532
   Episode_Reward/pen_joint_torque: -0.2231
    Episode_Reward/pen_joint_accel: -0.1042
    Episode_Reward/pen_action_rate: -0.1121
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0852
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2395
Episode_Reward/pen_flat_orientation: -0.0979
  Episode_Reward/pen_feet_distance: -0.0245
Episode_Reward/pen_feet_regulation: -0.4609
   Episode_Reward/foot_landing_vel: -0.1294
   Episode_Reward/test_gait_reward: -0.9046
Metrics/base_velocity/error_vel_xy: 0.9015
Metrics/base_velocity/error_vel_yaw: 1.1807
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 178421760
                    Iteration time: 1.10s
                        Total time: 1980.62s
                               ETA: 1294.2s

################################################################################
                     [1m Learning iteration 1815/3000 [0m                     

                       Computation: 89601 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.4999
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8335
                     Learning rate: 0.0006
                       Mean reward: 137.68
               Mean episode length: 974.13
       Episode_Reward/keep_balance: 0.9794
     Episode_Reward/rew_lin_vel_xy: 6.3003
      Episode_Reward/rew_ang_vel_z: 2.5630
    Episode_Reward/pen_base_height: -0.2750
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1497
   Episode_Reward/pen_joint_torque: -0.2247
    Episode_Reward/pen_joint_accel: -0.1126
    Episode_Reward/pen_action_rate: -0.1137
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2419
Episode_Reward/pen_flat_orientation: -0.0933
  Episode_Reward/pen_feet_distance: -0.0296
Episode_Reward/pen_feet_regulation: -0.4837
   Episode_Reward/foot_landing_vel: -0.1326
   Episode_Reward/test_gait_reward: -0.9112
Metrics/base_velocity/error_vel_xy: 0.9029
Metrics/base_velocity/error_vel_yaw: 1.2291
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 178520064
                    Iteration time: 1.10s
                        Total time: 1981.71s
                               ETA: 1293.1s

################################################################################
                     [1m Learning iteration 1816/3000 [0m                     

                       Computation: 84419 steps/s (collection: 1.041s, learning 0.124s)
               Value function loss: 0.5396
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8333
                     Learning rate: 0.0003
                       Mean reward: 141.75
               Mean episode length: 996.50
       Episode_Reward/keep_balance: 0.9979
     Episode_Reward/rew_lin_vel_xy: 6.4412
      Episode_Reward/rew_ang_vel_z: 2.6855
    Episode_Reward/pen_base_height: -0.2954
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1512
   Episode_Reward/pen_joint_torque: -0.2400
    Episode_Reward/pen_joint_accel: -0.1154
    Episode_Reward/pen_action_rate: -0.1162
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2441
Episode_Reward/pen_flat_orientation: -0.0916
  Episode_Reward/pen_feet_distance: -0.0341
Episode_Reward/pen_feet_regulation: -0.4712
   Episode_Reward/foot_landing_vel: -0.1268
   Episode_Reward/test_gait_reward: -0.9213
Metrics/base_velocity/error_vel_xy: 0.9024
Metrics/base_velocity/error_vel_yaw: 1.1823
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 178618368
                    Iteration time: 1.16s
                        Total time: 1982.88s
                               ETA: 1292.1s

################################################################################
                     [1m Learning iteration 1817/3000 [0m                     

                       Computation: 91015 steps/s (collection: 0.957s, learning 0.123s)
               Value function loss: 0.5917
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8338
                     Learning rate: 0.0002
                       Mean reward: 140.94
               Mean episode length: 989.25
       Episode_Reward/keep_balance: 0.9936
     Episode_Reward/rew_lin_vel_xy: 6.4272
      Episode_Reward/rew_ang_vel_z: 2.6597
    Episode_Reward/pen_base_height: -0.2902
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1580
   Episode_Reward/pen_joint_torque: -0.2333
    Episode_Reward/pen_joint_accel: -0.1117
    Episode_Reward/pen_action_rate: -0.1159
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2462
Episode_Reward/pen_flat_orientation: -0.0919
  Episode_Reward/pen_feet_distance: -0.0256
Episode_Reward/pen_feet_regulation: -0.4648
   Episode_Reward/foot_landing_vel: -0.1214
   Episode_Reward/test_gait_reward: -0.9296
Metrics/base_velocity/error_vel_xy: 0.8893
Metrics/base_velocity/error_vel_yaw: 1.1889
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 178716672
                    Iteration time: 1.08s
                        Total time: 1983.96s
                               ETA: 1291.0s

################################################################################
                     [1m Learning iteration 1818/3000 [0m                     

                       Computation: 88983 steps/s (collection: 0.980s, learning 0.124s)
               Value function loss: 0.5007
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8344
                     Learning rate: 0.0004
                       Mean reward: 136.99
               Mean episode length: 964.16
       Episode_Reward/keep_balance: 0.9625
     Episode_Reward/rew_lin_vel_xy: 6.1718
      Episode_Reward/rew_ang_vel_z: 2.5800
    Episode_Reward/pen_base_height: -0.2826
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1481
   Episode_Reward/pen_joint_torque: -0.2206
    Episode_Reward/pen_joint_accel: -0.1102
    Episode_Reward/pen_action_rate: -0.1113
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0848
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2352
Episode_Reward/pen_flat_orientation: -0.0925
  Episode_Reward/pen_feet_distance: -0.0268
Episode_Reward/pen_feet_regulation: -0.4696
   Episode_Reward/foot_landing_vel: -0.1286
   Episode_Reward/test_gait_reward: -0.8905
Metrics/base_velocity/error_vel_xy: 0.9060
Metrics/base_velocity/error_vel_yaw: 1.1639
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 178814976
                    Iteration time: 1.10s
                        Total time: 1985.06s
                               ETA: 1289.9s

################################################################################
                     [1m Learning iteration 1819/3000 [0m                     

                       Computation: 89547 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 0.5464
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8341
                     Learning rate: 0.0006
                       Mean reward: 140.00
               Mean episode length: 990.30
       Episode_Reward/keep_balance: 0.9798
     Episode_Reward/rew_lin_vel_xy: 6.2674
      Episode_Reward/rew_ang_vel_z: 2.6153
    Episode_Reward/pen_base_height: -0.2842
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1508
   Episode_Reward/pen_joint_torque: -0.2301
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.1141
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0558
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2392
Episode_Reward/pen_flat_orientation: -0.0933
  Episode_Reward/pen_feet_distance: -0.0245
Episode_Reward/pen_feet_regulation: -0.4834
   Episode_Reward/foot_landing_vel: -0.1260
   Episode_Reward/test_gait_reward: -0.9038
Metrics/base_velocity/error_vel_xy: 0.9184
Metrics/base_velocity/error_vel_yaw: 1.1819
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 178913280
                    Iteration time: 1.10s
                        Total time: 1986.16s
                               ETA: 1288.8s

################################################################################
                     [1m Learning iteration 1820/3000 [0m                     

                       Computation: 89319 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.5353
                    Surrogate loss: -0.0011
             Mean action noise std: 0.8339
                     Learning rate: 0.0003
                       Mean reward: 141.63
               Mean episode length: 991.16
       Episode_Reward/keep_balance: 0.9934
     Episode_Reward/rew_lin_vel_xy: 6.3913
      Episode_Reward/rew_ang_vel_z: 2.6692
    Episode_Reward/pen_base_height: -0.2886
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1557
   Episode_Reward/pen_joint_torque: -0.2354
    Episode_Reward/pen_joint_accel: -0.1103
    Episode_Reward/pen_action_rate: -0.1159
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2429
Episode_Reward/pen_flat_orientation: -0.0909
  Episode_Reward/pen_feet_distance: -0.0269
Episode_Reward/pen_feet_regulation: -0.4721
   Episode_Reward/foot_landing_vel: -0.1253
   Episode_Reward/test_gait_reward: -0.9208
Metrics/base_velocity/error_vel_xy: 0.9104
Metrics/base_velocity/error_vel_yaw: 1.1930
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 179011584
                    Iteration time: 1.10s
                        Total time: 1987.26s
                               ETA: 1287.7s

################################################################################
                     [1m Learning iteration 1821/3000 [0m                     

                       Computation: 89561 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.5858
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8337
                     Learning rate: 0.0006
                       Mean reward: 140.23
               Mean episode length: 988.68
       Episode_Reward/keep_balance: 0.9906
     Episode_Reward/rew_lin_vel_xy: 6.3600
      Episode_Reward/rew_ang_vel_z: 2.6500
    Episode_Reward/pen_base_height: -0.2838
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1526
   Episode_Reward/pen_joint_torque: -0.2372
    Episode_Reward/pen_joint_accel: -0.1103
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2442
Episode_Reward/pen_flat_orientation: -0.0943
  Episode_Reward/pen_feet_distance: -0.0286
Episode_Reward/pen_feet_regulation: -0.4671
   Episode_Reward/foot_landing_vel: -0.1326
   Episode_Reward/test_gait_reward: -0.9163
Metrics/base_velocity/error_vel_xy: 0.9191
Metrics/base_velocity/error_vel_yaw: 1.1958
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 179109888
                    Iteration time: 1.10s
                        Total time: 1988.36s
                               ETA: 1286.6s

################################################################################
                     [1m Learning iteration 1822/3000 [0m                     

                       Computation: 87744 steps/s (collection: 0.995s, learning 0.125s)
               Value function loss: 0.5382
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8355
                     Learning rate: 0.0006
                       Mean reward: 139.09
               Mean episode length: 965.76
       Episode_Reward/keep_balance: 0.9398
     Episode_Reward/rew_lin_vel_xy: 6.0500
      Episode_Reward/rew_ang_vel_z: 2.5352
    Episode_Reward/pen_base_height: -0.2705
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.1473
   Episode_Reward/pen_joint_torque: -0.2164
    Episode_Reward/pen_joint_accel: -0.0983
    Episode_Reward/pen_action_rate: -0.1089
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0532
   Episode_Reward/pen_joint_powers: -0.0823
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2303
Episode_Reward/pen_flat_orientation: -0.0945
  Episode_Reward/pen_feet_distance: -0.0302
Episode_Reward/pen_feet_regulation: -0.4342
   Episode_Reward/foot_landing_vel: -0.1299
   Episode_Reward/test_gait_reward: -0.8664
Metrics/base_velocity/error_vel_xy: 0.8548
Metrics/base_velocity/error_vel_yaw: 1.1108
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 179208192
                    Iteration time: 1.12s
                        Total time: 1989.48s
                               ETA: 1285.6s

################################################################################
                     [1m Learning iteration 1823/3000 [0m                     

                       Computation: 88460 steps/s (collection: 0.987s, learning 0.125s)
               Value function loss: 0.4825
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8352
                     Learning rate: 0.0004
                       Mean reward: 136.29
               Mean episode length: 977.07
       Episode_Reward/keep_balance: 0.9871
     Episode_Reward/rew_lin_vel_xy: 6.2727
      Episode_Reward/rew_ang_vel_z: 2.6191
    Episode_Reward/pen_base_height: -0.2896
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1497
   Episode_Reward/pen_joint_torque: -0.2470
    Episode_Reward/pen_joint_accel: -0.1138
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0923
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2450
Episode_Reward/pen_flat_orientation: -0.0925
  Episode_Reward/pen_feet_distance: -0.0291
Episode_Reward/pen_feet_regulation: -0.4966
   Episode_Reward/foot_landing_vel: -0.1432
   Episode_Reward/test_gait_reward: -0.9190
Metrics/base_velocity/error_vel_xy: 0.9387
Metrics/base_velocity/error_vel_yaw: 1.2089
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 179306496
                    Iteration time: 1.11s
                        Total time: 1990.59s
                               ETA: 1284.5s

################################################################################
                     [1m Learning iteration 1824/3000 [0m                     

                       Computation: 88625 steps/s (collection: 0.985s, learning 0.124s)
               Value function loss: 0.5626
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8345
                     Learning rate: 0.0004
                       Mean reward: 141.09
               Mean episode length: 985.24
       Episode_Reward/keep_balance: 0.9895
     Episode_Reward/rew_lin_vel_xy: 6.3966
      Episode_Reward/rew_ang_vel_z: 2.6622
    Episode_Reward/pen_base_height: -0.2935
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1468
   Episode_Reward/pen_joint_torque: -0.2378
    Episode_Reward/pen_joint_accel: -0.1053
    Episode_Reward/pen_action_rate: -0.1145
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0558
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2399
Episode_Reward/pen_flat_orientation: -0.0916
  Episode_Reward/pen_feet_distance: -0.0325
Episode_Reward/pen_feet_regulation: -0.4747
   Episode_Reward/foot_landing_vel: -0.1315
   Episode_Reward/test_gait_reward: -0.9165
Metrics/base_velocity/error_vel_xy: 0.8948
Metrics/base_velocity/error_vel_yaw: 1.1789
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 179404800
                    Iteration time: 1.11s
                        Total time: 1991.70s
                               ETA: 1283.4s

################################################################################
                     [1m Learning iteration 1825/3000 [0m                     

                       Computation: 89239 steps/s (collection: 0.978s, learning 0.124s)
               Value function loss: 0.5425
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8336
                     Learning rate: 0.0004
                       Mean reward: 142.19
               Mean episode length: 988.34
       Episode_Reward/keep_balance: 0.9919
     Episode_Reward/rew_lin_vel_xy: 6.4221
      Episode_Reward/rew_ang_vel_z: 2.6883
    Episode_Reward/pen_base_height: -0.2712
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.1522
   Episode_Reward/pen_joint_torque: -0.2350
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.1137
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0859
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2407
Episode_Reward/pen_flat_orientation: -0.0909
  Episode_Reward/pen_feet_distance: -0.0268
Episode_Reward/pen_feet_regulation: -0.4588
   Episode_Reward/foot_landing_vel: -0.1272
   Episode_Reward/test_gait_reward: -0.9043
Metrics/base_velocity/error_vel_xy: 0.8880
Metrics/base_velocity/error_vel_yaw: 1.1571
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 179503104
                    Iteration time: 1.10s
                        Total time: 1992.80s
                               ETA: 1282.3s

################################################################################
                     [1m Learning iteration 1826/3000 [0m                     

                       Computation: 89510 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.5154
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8334
                     Learning rate: 0.0003
                       Mean reward: 140.33
               Mean episode length: 985.28
       Episode_Reward/keep_balance: 0.9803
     Episode_Reward/rew_lin_vel_xy: 6.3073
      Episode_Reward/rew_ang_vel_z: 2.6158
    Episode_Reward/pen_base_height: -0.2656
      Episode_Reward/pen_lin_vel_z: -0.0353
     Episode_Reward/pen_ang_vel_xy: -0.1522
   Episode_Reward/pen_joint_torque: -0.2230
    Episode_Reward/pen_joint_accel: -0.1132
    Episode_Reward/pen_action_rate: -0.1126
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0846
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2410
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0252
Episode_Reward/pen_feet_regulation: -0.4576
   Episode_Reward/foot_landing_vel: -0.1319
   Episode_Reward/test_gait_reward: -0.9003
Metrics/base_velocity/error_vel_xy: 0.8888
Metrics/base_velocity/error_vel_yaw: 1.1883
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 179601408
                    Iteration time: 1.10s
                        Total time: 1993.90s
                               ETA: 1281.2s

################################################################################
                     [1m Learning iteration 1827/3000 [0m                     

                       Computation: 89930 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.6025
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8343
                     Learning rate: 0.0006
                       Mean reward: 140.55
               Mean episode length: 988.99
       Episode_Reward/keep_balance: 0.9856
     Episode_Reward/rew_lin_vel_xy: 6.3753
      Episode_Reward/rew_ang_vel_z: 2.6513
    Episode_Reward/pen_base_height: -0.2797
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1585
   Episode_Reward/pen_joint_torque: -0.2306
    Episode_Reward/pen_joint_accel: -0.1167
    Episode_Reward/pen_action_rate: -0.1156
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2452
Episode_Reward/pen_flat_orientation: -0.0951
  Episode_Reward/pen_feet_distance: -0.0282
Episode_Reward/pen_feet_regulation: -0.4754
   Episode_Reward/foot_landing_vel: -0.1282
   Episode_Reward/test_gait_reward: -0.9101
Metrics/base_velocity/error_vel_xy: 0.8845
Metrics/base_velocity/error_vel_yaw: 1.1754
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 179699712
                    Iteration time: 1.09s
                        Total time: 1994.99s
                               ETA: 1280.2s

################################################################################
                     [1m Learning iteration 1828/3000 [0m                     

                       Computation: 88907 steps/s (collection: 0.982s, learning 0.123s)
               Value function loss: 0.4694
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8348
                     Learning rate: 0.0009
                       Mean reward: 135.41
               Mean episode length: 974.86
       Episode_Reward/keep_balance: 0.9793
     Episode_Reward/rew_lin_vel_xy: 6.2747
      Episode_Reward/rew_ang_vel_z: 2.5775
    Episode_Reward/pen_base_height: -0.2912
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1512
   Episode_Reward/pen_joint_torque: -0.2315
    Episode_Reward/pen_joint_accel: -0.1206
    Episode_Reward/pen_action_rate: -0.1164
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2445
Episode_Reward/pen_flat_orientation: -0.0988
  Episode_Reward/pen_feet_distance: -0.0256
Episode_Reward/pen_feet_regulation: -0.4968
   Episode_Reward/foot_landing_vel: -0.1389
   Episode_Reward/test_gait_reward: -0.9107
Metrics/base_velocity/error_vel_xy: 0.9193
Metrics/base_velocity/error_vel_yaw: 1.2363
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 179798016
                    Iteration time: 1.11s
                        Total time: 1996.10s
                               ETA: 1279.1s

################################################################################
                     [1m Learning iteration 1829/3000 [0m                     

                       Computation: 90499 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.5429
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8358
                     Learning rate: 0.0009
                       Mean reward: 139.49
               Mean episode length: 986.95
       Episode_Reward/keep_balance: 0.9907
     Episode_Reward/rew_lin_vel_xy: 6.3634
      Episode_Reward/rew_ang_vel_z: 2.6125
    Episode_Reward/pen_base_height: -0.2709
      Episode_Reward/pen_lin_vel_z: -0.0346
     Episode_Reward/pen_ang_vel_xy: -0.1536
   Episode_Reward/pen_joint_torque: -0.2300
    Episode_Reward/pen_joint_accel: -0.1066
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2455
Episode_Reward/pen_flat_orientation: -0.0913
  Episode_Reward/pen_feet_distance: -0.0251
Episode_Reward/pen_feet_regulation: -0.4557
   Episode_Reward/foot_landing_vel: -0.1282
   Episode_Reward/test_gait_reward: -0.9083
Metrics/base_velocity/error_vel_xy: 0.9044
Metrics/base_velocity/error_vel_yaw: 1.2250
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 179896320
                    Iteration time: 1.09s
                        Total time: 1997.18s
                               ETA: 1278.0s

################################################################################
                     [1m Learning iteration 1830/3000 [0m                     

                       Computation: 90185 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.5362
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8376
                     Learning rate: 0.0003
                       Mean reward: 139.85
               Mean episode length: 986.50
       Episode_Reward/keep_balance: 0.9855
     Episode_Reward/rew_lin_vel_xy: 6.2821
      Episode_Reward/rew_ang_vel_z: 2.6515
    Episode_Reward/pen_base_height: -0.2786
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1479
   Episode_Reward/pen_joint_torque: -0.2390
    Episode_Reward/pen_joint_accel: -0.1009
    Episode_Reward/pen_action_rate: -0.1141
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2427
Episode_Reward/pen_flat_orientation: -0.0914
  Episode_Reward/pen_feet_distance: -0.0228
Episode_Reward/pen_feet_regulation: -0.4563
   Episode_Reward/foot_landing_vel: -0.1338
   Episode_Reward/test_gait_reward: -0.9002
Metrics/base_velocity/error_vel_xy: 0.9165
Metrics/base_velocity/error_vel_yaw: 1.1644
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 179994624
                    Iteration time: 1.09s
                        Total time: 1998.27s
                               ETA: 1276.9s

################################################################################
                     [1m Learning iteration 1831/3000 [0m                     

                       Computation: 89323 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.5140
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8355
                     Learning rate: 0.0004
                       Mean reward: 140.62
               Mean episode length: 978.11
       Episode_Reward/keep_balance: 0.9844
     Episode_Reward/rew_lin_vel_xy: 6.3066
      Episode_Reward/rew_ang_vel_z: 2.6205
    Episode_Reward/pen_base_height: -0.2683
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1549
   Episode_Reward/pen_joint_torque: -0.2236
    Episode_Reward/pen_joint_accel: -0.1113
    Episode_Reward/pen_action_rate: -0.1149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2443
Episode_Reward/pen_flat_orientation: -0.0956
  Episode_Reward/pen_feet_distance: -0.0240
Episode_Reward/pen_feet_regulation: -0.4784
   Episode_Reward/foot_landing_vel: -0.1452
   Episode_Reward/test_gait_reward: -0.8973
Metrics/base_velocity/error_vel_xy: 0.9193
Metrics/base_velocity/error_vel_yaw: 1.1897
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 180092928
                    Iteration time: 1.10s
                        Total time: 1999.37s
                               ETA: 1275.8s

################################################################################
                     [1m Learning iteration 1832/3000 [0m                     

                       Computation: 88123 steps/s (collection: 0.993s, learning 0.123s)
               Value function loss: 0.5359
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8341
                     Learning rate: 0.0004
                       Mean reward: 141.09
               Mean episode length: 991.69
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4643
      Episode_Reward/rew_ang_vel_z: 2.6500
    Episode_Reward/pen_base_height: -0.2701
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1494
   Episode_Reward/pen_joint_torque: -0.2388
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2487
Episode_Reward/pen_flat_orientation: -0.0892
  Episode_Reward/pen_feet_distance: -0.0269
Episode_Reward/pen_feet_regulation: -0.4779
   Episode_Reward/foot_landing_vel: -0.1328
   Episode_Reward/test_gait_reward: -0.9238
Metrics/base_velocity/error_vel_xy: 0.8993
Metrics/base_velocity/error_vel_yaw: 1.2111
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 180191232
                    Iteration time: 1.12s
                        Total time: 2000.49s
                               ETA: 1274.7s

################################################################################
                     [1m Learning iteration 1833/3000 [0m                     

                       Computation: 90159 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.5154
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8345
                     Learning rate: 0.0006
                       Mean reward: 142.78
               Mean episode length: 988.88
       Episode_Reward/keep_balance: 0.9938
     Episode_Reward/rew_lin_vel_xy: 6.4345
      Episode_Reward/rew_ang_vel_z: 2.6688
    Episode_Reward/pen_base_height: -0.2797
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.1472
   Episode_Reward/pen_joint_torque: -0.2317
    Episode_Reward/pen_joint_accel: -0.1041
    Episode_Reward/pen_action_rate: -0.1145
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0859
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2434
Episode_Reward/pen_flat_orientation: -0.0908
  Episode_Reward/pen_feet_distance: -0.0311
Episode_Reward/pen_feet_regulation: -0.4644
   Episode_Reward/foot_landing_vel: -0.1205
   Episode_Reward/test_gait_reward: -0.9105
Metrics/base_velocity/error_vel_xy: 0.8804
Metrics/base_velocity/error_vel_yaw: 1.1860
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 180289536
                    Iteration time: 1.09s
                        Total time: 2001.58s
                               ETA: 1273.6s

################################################################################
                     [1m Learning iteration 1834/3000 [0m                     

                       Computation: 88176 steps/s (collection: 0.991s, learning 0.123s)
               Value function loss: 0.5319
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8345
                     Learning rate: 0.0004
                       Mean reward: 137.65
               Mean episode length: 983.04
       Episode_Reward/keep_balance: 0.9944
     Episode_Reward/rew_lin_vel_xy: 6.3655
      Episode_Reward/rew_ang_vel_z: 2.6395
    Episode_Reward/pen_base_height: -0.2873
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1591
   Episode_Reward/pen_joint_torque: -0.2299
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.1164
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2451
Episode_Reward/pen_flat_orientation: -0.0970
  Episode_Reward/pen_feet_distance: -0.0255
Episode_Reward/pen_feet_regulation: -0.4776
   Episode_Reward/foot_landing_vel: -0.1344
   Episode_Reward/test_gait_reward: -0.9188
Metrics/base_velocity/error_vel_xy: 0.9330
Metrics/base_velocity/error_vel_yaw: 1.2285
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 180387840
                    Iteration time: 1.11s
                        Total time: 2002.70s
                               ETA: 1272.6s

################################################################################
                     [1m Learning iteration 1835/3000 [0m                     

                       Computation: 88929 steps/s (collection: 0.983s, learning 0.122s)
               Value function loss: 0.5124
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8353
                     Learning rate: 0.0004
                       Mean reward: 138.62
               Mean episode length: 983.46
       Episode_Reward/keep_balance: 0.9847
     Episode_Reward/rew_lin_vel_xy: 6.2626
      Episode_Reward/rew_ang_vel_z: 2.5944
    Episode_Reward/pen_base_height: -0.2785
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1490
   Episode_Reward/pen_joint_torque: -0.2334
    Episode_Reward/pen_joint_accel: -0.1148
    Episode_Reward/pen_action_rate: -0.1144
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2421
Episode_Reward/pen_flat_orientation: -0.0971
  Episode_Reward/pen_feet_distance: -0.0235
Episode_Reward/pen_feet_regulation: -0.4680
   Episode_Reward/foot_landing_vel: -0.1390
   Episode_Reward/test_gait_reward: -0.8989
Metrics/base_velocity/error_vel_xy: 0.9313
Metrics/base_velocity/error_vel_yaw: 1.2214
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 180486144
                    Iteration time: 1.11s
                        Total time: 2003.80s
                               ETA: 1271.5s

################################################################################
                     [1m Learning iteration 1836/3000 [0m                     

                       Computation: 89789 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.5302
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8365
                     Learning rate: 0.0003
                       Mean reward: 142.52
               Mean episode length: 994.15
       Episode_Reward/keep_balance: 0.9929
     Episode_Reward/rew_lin_vel_xy: 6.4248
      Episode_Reward/rew_ang_vel_z: 2.6287
    Episode_Reward/pen_base_height: -0.2787
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1527
   Episode_Reward/pen_joint_torque: -0.2280
    Episode_Reward/pen_joint_accel: -0.1138
    Episode_Reward/pen_action_rate: -0.1157
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2458
Episode_Reward/pen_flat_orientation: -0.0951
  Episode_Reward/pen_feet_distance: -0.0256
Episode_Reward/pen_feet_regulation: -0.4713
   Episode_Reward/foot_landing_vel: -0.1314
   Episode_Reward/test_gait_reward: -0.9127
Metrics/base_velocity/error_vel_xy: 0.8887
Metrics/base_velocity/error_vel_yaw: 1.2258
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 180584448
                    Iteration time: 1.09s
                        Total time: 2004.90s
                               ETA: 1270.4s

################################################################################
                     [1m Learning iteration 1837/3000 [0m                     

                       Computation: 90392 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 0.5843
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8365
                     Learning rate: 0.0006
                       Mean reward: 140.72
               Mean episode length: 992.94
       Episode_Reward/keep_balance: 0.9951
     Episode_Reward/rew_lin_vel_xy: 6.3639
      Episode_Reward/rew_ang_vel_z: 2.6582
    Episode_Reward/pen_base_height: -0.2884
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1553
   Episode_Reward/pen_joint_torque: -0.2324
    Episode_Reward/pen_joint_accel: -0.1008
    Episode_Reward/pen_action_rate: -0.1155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0882
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2432
Episode_Reward/pen_flat_orientation: -0.0891
  Episode_Reward/pen_feet_distance: -0.0216
Episode_Reward/pen_feet_regulation: -0.4787
   Episode_Reward/foot_landing_vel: -0.1326
   Episode_Reward/test_gait_reward: -0.9208
Metrics/base_velocity/error_vel_xy: 0.9368
Metrics/base_velocity/error_vel_yaw: 1.2004
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 180682752
                    Iteration time: 1.09s
                        Total time: 2005.98s
                               ETA: 1269.3s

################################################################################
                     [1m Learning iteration 1838/3000 [0m                     

                       Computation: 89779 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.5849
                    Surrogate loss: -0.0057
             Mean action noise std: 0.8372
                     Learning rate: 0.0013
                       Mean reward: 139.11
               Mean episode length: 992.96
       Episode_Reward/keep_balance: 0.9819
     Episode_Reward/rew_lin_vel_xy: 6.3030
      Episode_Reward/rew_ang_vel_z: 2.5745
    Episode_Reward/pen_base_height: -0.2852
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1502
   Episode_Reward/pen_joint_torque: -0.2364
    Episode_Reward/pen_joint_accel: -0.1158
    Episode_Reward/pen_action_rate: -0.1147
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2424
Episode_Reward/pen_flat_orientation: -0.0906
  Episode_Reward/pen_feet_distance: -0.0275
Episode_Reward/pen_feet_regulation: -0.4824
   Episode_Reward/foot_landing_vel: -0.1308
   Episode_Reward/test_gait_reward: -0.9011
Metrics/base_velocity/error_vel_xy: 0.9073
Metrics/base_velocity/error_vel_yaw: 1.2267
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 180781056
                    Iteration time: 1.09s
                        Total time: 2007.08s
                               ETA: 1268.2s

################################################################################
                     [1m Learning iteration 1839/3000 [0m                     

                       Computation: 88699 steps/s (collection: 0.985s, learning 0.123s)
               Value function loss: 0.5079
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8385
                     Learning rate: 0.0009
                       Mean reward: 143.64
               Mean episode length: 999.82
       Episode_Reward/keep_balance: 0.9999
     Episode_Reward/rew_lin_vel_xy: 6.4469
      Episode_Reward/rew_ang_vel_z: 2.6731
    Episode_Reward/pen_base_height: -0.2751
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1537
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1175
    Episode_Reward/pen_action_rate: -0.1145
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0859
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2448
Episode_Reward/pen_flat_orientation: -0.0908
  Episode_Reward/pen_feet_distance: -0.0254
Episode_Reward/pen_feet_regulation: -0.4701
   Episode_Reward/foot_landing_vel: -0.1372
   Episode_Reward/test_gait_reward: -0.9103
Metrics/base_velocity/error_vel_xy: 0.9047
Metrics/base_velocity/error_vel_yaw: 1.1970
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 180879360
                    Iteration time: 1.11s
                        Total time: 2008.19s
                               ETA: 1267.1s

################################################################################
                     [1m Learning iteration 1840/3000 [0m                     

                       Computation: 88318 steps/s (collection: 0.988s, learning 0.125s)
               Value function loss: 0.5449
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8393
                     Learning rate: 0.0004
                       Mean reward: 136.33
               Mean episode length: 974.22
       Episode_Reward/keep_balance: 0.9795
     Episode_Reward/rew_lin_vel_xy: 6.3270
      Episode_Reward/rew_ang_vel_z: 2.5604
    Episode_Reward/pen_base_height: -0.2840
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1502
   Episode_Reward/pen_joint_torque: -0.2377
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1156
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2442
Episode_Reward/pen_flat_orientation: -0.0948
  Episode_Reward/pen_feet_distance: -0.0261
Episode_Reward/pen_feet_regulation: -0.4876
   Episode_Reward/foot_landing_vel: -0.1367
   Episode_Reward/test_gait_reward: -0.8953
Metrics/base_velocity/error_vel_xy: 0.8940
Metrics/base_velocity/error_vel_yaw: 1.2360
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 180977664
                    Iteration time: 1.11s
                        Total time: 2009.30s
                               ETA: 1266.0s

################################################################################
                     [1m Learning iteration 1841/3000 [0m                     

                       Computation: 87975 steps/s (collection: 0.994s, learning 0.123s)
               Value function loss: 0.5474
                    Surrogate loss: -0.0059
             Mean action noise std: 0.8406
                     Learning rate: 0.0006
                       Mean reward: 136.77
               Mean episode length: 993.00
       Episode_Reward/keep_balance: 0.9947
     Episode_Reward/rew_lin_vel_xy: 6.2701
      Episode_Reward/rew_ang_vel_z: 2.6085
    Episode_Reward/pen_base_height: -0.2858
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1561
   Episode_Reward/pen_joint_torque: -0.2398
    Episode_Reward/pen_joint_accel: -0.1165
    Episode_Reward/pen_action_rate: -0.1184
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0598
   Episode_Reward/pen_joint_powers: -0.0917
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2489
Episode_Reward/pen_flat_orientation: -0.0957
  Episode_Reward/pen_feet_distance: -0.0299
Episode_Reward/pen_feet_regulation: -0.4971
   Episode_Reward/foot_landing_vel: -0.1488
   Episode_Reward/test_gait_reward: -0.9122
Metrics/base_velocity/error_vel_xy: 0.9685
Metrics/base_velocity/error_vel_yaw: 1.2462
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 181075968
                    Iteration time: 1.12s
                        Total time: 2010.42s
                               ETA: 1265.0s

################################################################################
                     [1m Learning iteration 1842/3000 [0m                     

                       Computation: 90169 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.5529
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8417
                     Learning rate: 0.0009
                       Mean reward: 139.60
               Mean episode length: 990.54
       Episode_Reward/keep_balance: 0.9904
     Episode_Reward/rew_lin_vel_xy: 6.2730
      Episode_Reward/rew_ang_vel_z: 2.6111
    Episode_Reward/pen_base_height: -0.2868
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1502
   Episode_Reward/pen_joint_torque: -0.2338
    Episode_Reward/pen_joint_accel: -0.1066
    Episode_Reward/pen_action_rate: -0.1155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2412
Episode_Reward/pen_flat_orientation: -0.0904
  Episode_Reward/pen_feet_distance: -0.0295
Episode_Reward/pen_feet_regulation: -0.4918
   Episode_Reward/foot_landing_vel: -0.1327
   Episode_Reward/test_gait_reward: -0.9092
Metrics/base_velocity/error_vel_xy: 0.9532
Metrics/base_velocity/error_vel_yaw: 1.2229
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 181174272
                    Iteration time: 1.09s
                        Total time: 2011.51s
                               ETA: 1263.9s

################################################################################
                     [1m Learning iteration 1843/3000 [0m                     

                       Computation: 90070 steps/s (collection: 0.970s, learning 0.121s)
               Value function loss: 0.5474
                    Surrogate loss: 0.0016
             Mean action noise std: 0.8415
                     Learning rate: 0.0001
                       Mean reward: 136.40
               Mean episode length: 972.75
       Episode_Reward/keep_balance: 0.9678
     Episode_Reward/rew_lin_vel_xy: 6.1672
      Episode_Reward/rew_ang_vel_z: 2.5470
    Episode_Reward/pen_base_height: -0.2822
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1543
   Episode_Reward/pen_joint_torque: -0.2337
    Episode_Reward/pen_joint_accel: -0.1096
    Episode_Reward/pen_action_rate: -0.1149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2419
Episode_Reward/pen_flat_orientation: -0.0974
  Episode_Reward/pen_feet_distance: -0.0315
Episode_Reward/pen_feet_regulation: -0.4893
   Episode_Reward/foot_landing_vel: -0.1340
   Episode_Reward/test_gait_reward: -0.8833
Metrics/base_velocity/error_vel_xy: 0.9269
Metrics/base_velocity/error_vel_yaw: 1.2092
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 181272576
                    Iteration time: 1.09s
                        Total time: 2012.60s
                               ETA: 1262.8s

################################################################################
                     [1m Learning iteration 1844/3000 [0m                     

                       Computation: 91092 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.4531
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8410
                     Learning rate: 0.0003
                       Mean reward: 137.68
               Mean episode length: 977.89
       Episode_Reward/keep_balance: 0.9763
     Episode_Reward/rew_lin_vel_xy: 6.2383
      Episode_Reward/rew_ang_vel_z: 2.5847
    Episode_Reward/pen_base_height: -0.2764
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1479
   Episode_Reward/pen_joint_torque: -0.2336
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1144
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2405
Episode_Reward/pen_flat_orientation: -0.0921
  Episode_Reward/pen_feet_distance: -0.0311
Episode_Reward/pen_feet_regulation: -0.4966
   Episode_Reward/foot_landing_vel: -0.1298
   Episode_Reward/test_gait_reward: -0.8903
Metrics/base_velocity/error_vel_xy: 0.9279
Metrics/base_velocity/error_vel_yaw: 1.1983
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 181370880
                    Iteration time: 1.08s
                        Total time: 2013.68s
                               ETA: 1261.7s

################################################################################
                     [1m Learning iteration 1845/3000 [0m                     

                       Computation: 91133 steps/s (collection: 0.957s, learning 0.121s)
               Value function loss: 0.4509
                    Surrogate loss: -0.0062
             Mean action noise std: 0.8414
                     Learning rate: 0.0006
                       Mean reward: 139.83
               Mean episode length: 982.95
       Episode_Reward/keep_balance: 0.9843
     Episode_Reward/rew_lin_vel_xy: 6.3219
      Episode_Reward/rew_ang_vel_z: 2.6554
    Episode_Reward/pen_base_height: -0.2733
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1479
   Episode_Reward/pen_joint_torque: -0.2217
    Episode_Reward/pen_joint_accel: -0.1060
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0840
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2387
Episode_Reward/pen_flat_orientation: -0.0907
  Episode_Reward/pen_feet_distance: -0.0276
Episode_Reward/pen_feet_regulation: -0.4581
   Episode_Reward/foot_landing_vel: -0.1339
   Episode_Reward/test_gait_reward: -0.8941
Metrics/base_velocity/error_vel_xy: 0.9065
Metrics/base_velocity/error_vel_yaw: 1.1598
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 181469184
                    Iteration time: 1.08s
                        Total time: 2014.76s
                               ETA: 1260.6s

################################################################################
                     [1m Learning iteration 1846/3000 [0m                     

                       Computation: 90233 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.5264
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8423
                     Learning rate: 0.0004
                       Mean reward: 140.81
               Mean episode length: 989.72
       Episode_Reward/keep_balance: 0.9956
     Episode_Reward/rew_lin_vel_xy: 6.4611
      Episode_Reward/rew_ang_vel_z: 2.6459
    Episode_Reward/pen_base_height: -0.2743
      Episode_Reward/pen_lin_vel_z: -0.0348
     Episode_Reward/pen_ang_vel_xy: -0.1456
   Episode_Reward/pen_joint_torque: -0.2358
    Episode_Reward/pen_joint_accel: -0.1167
    Episode_Reward/pen_action_rate: -0.1152
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2464
Episode_Reward/pen_flat_orientation: -0.0921
  Episode_Reward/pen_feet_distance: -0.0274
Episode_Reward/pen_feet_regulation: -0.4694
   Episode_Reward/foot_landing_vel: -0.1362
   Episode_Reward/test_gait_reward: -0.9113
Metrics/base_velocity/error_vel_xy: 0.8768
Metrics/base_velocity/error_vel_yaw: 1.2158
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 181567488
                    Iteration time: 1.09s
                        Total time: 2015.85s
                               ETA: 1259.5s

################################################################################
                     [1m Learning iteration 1847/3000 [0m                     

                       Computation: 88883 steps/s (collection: 0.982s, learning 0.124s)
               Value function loss: 0.5194
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8432
                     Learning rate: 0.0006
                       Mean reward: 143.63
               Mean episode length: 996.86
       Episode_Reward/keep_balance: 0.9989
     Episode_Reward/rew_lin_vel_xy: 6.4628
      Episode_Reward/rew_ang_vel_z: 2.6842
    Episode_Reward/pen_base_height: -0.2790
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.1494
   Episode_Reward/pen_joint_torque: -0.2426
    Episode_Reward/pen_joint_accel: -0.1022
    Episode_Reward/pen_action_rate: -0.1156
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0896
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2440
Episode_Reward/pen_flat_orientation: -0.0885
  Episode_Reward/pen_feet_distance: -0.0303
Episode_Reward/pen_feet_regulation: -0.4669
   Episode_Reward/foot_landing_vel: -0.1289
   Episode_Reward/test_gait_reward: -0.9132
Metrics/base_velocity/error_vel_xy: 0.8948
Metrics/base_velocity/error_vel_yaw: 1.1809
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 181665792
                    Iteration time: 1.11s
                        Total time: 2016.95s
                               ETA: 1258.4s

################################################################################
                     [1m Learning iteration 1848/3000 [0m                     

                       Computation: 89717 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.5189
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8440
                     Learning rate: 0.0002
                       Mean reward: 136.27
               Mean episode length: 975.76
       Episode_Reward/keep_balance: 0.9663
     Episode_Reward/rew_lin_vel_xy: 6.1311
      Episode_Reward/rew_ang_vel_z: 2.5234
    Episode_Reward/pen_base_height: -0.2732
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1537
   Episode_Reward/pen_joint_torque: -0.2201
    Episode_Reward/pen_joint_accel: -0.0992
    Episode_Reward/pen_action_rate: -0.1132
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2408
Episode_Reward/pen_flat_orientation: -0.0923
  Episode_Reward/pen_feet_distance: -0.0315
Episode_Reward/pen_feet_regulation: -0.4926
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.8776
Metrics/base_velocity/error_vel_xy: 0.9250
Metrics/base_velocity/error_vel_yaw: 1.2184
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 181764096
                    Iteration time: 1.10s
                        Total time: 2018.05s
                               ETA: 1257.3s

################################################################################
                     [1m Learning iteration 1849/3000 [0m                     

                       Computation: 89935 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.5294
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8439
                     Learning rate: 0.0003
                       Mean reward: 142.35
               Mean episode length: 979.27
       Episode_Reward/keep_balance: 0.9892
     Episode_Reward/rew_lin_vel_xy: 6.4052
      Episode_Reward/rew_ang_vel_z: 2.6325
    Episode_Reward/pen_base_height: -0.2715
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.1509
   Episode_Reward/pen_joint_torque: -0.2241
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.1138
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0843
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2435
Episode_Reward/pen_flat_orientation: -0.0897
  Episode_Reward/pen_feet_distance: -0.0280
Episode_Reward/pen_feet_regulation: -0.4508
   Episode_Reward/foot_landing_vel: -0.1268
   Episode_Reward/test_gait_reward: -0.8933
Metrics/base_velocity/error_vel_xy: 0.8919
Metrics/base_velocity/error_vel_yaw: 1.1945
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 181862400
                    Iteration time: 1.09s
                        Total time: 2019.14s
                               ETA: 1256.2s

################################################################################
                     [1m Learning iteration 1850/3000 [0m                     

                       Computation: 91413 steps/s (collection: 0.953s, learning 0.122s)
               Value function loss: 0.5265
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8451
                     Learning rate: 0.0006
                       Mean reward: 138.99
               Mean episode length: 976.14
       Episode_Reward/keep_balance: 0.9834
     Episode_Reward/rew_lin_vel_xy: 6.2603
      Episode_Reward/rew_ang_vel_z: 2.5756
    Episode_Reward/pen_base_height: -0.2703
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.1532
   Episode_Reward/pen_joint_torque: -0.2207
    Episode_Reward/pen_joint_accel: -0.1135
    Episode_Reward/pen_action_rate: -0.1142
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0858
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2447
Episode_Reward/pen_flat_orientation: -0.0906
  Episode_Reward/pen_feet_distance: -0.0260
Episode_Reward/pen_feet_regulation: -0.4847
   Episode_Reward/foot_landing_vel: -0.1288
   Episode_Reward/test_gait_reward: -0.8977
Metrics/base_velocity/error_vel_xy: 0.9314
Metrics/base_velocity/error_vel_yaw: 1.2332
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 181960704
                    Iteration time: 1.08s
                        Total time: 2020.22s
                               ETA: 1255.1s

################################################################################
                     [1m Learning iteration 1851/3000 [0m                     

                       Computation: 90573 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.5363
                    Surrogate loss: 0.0002
             Mean action noise std: 0.8452
                     Learning rate: 0.0002
                       Mean reward: 141.39
               Mean episode length: 984.28
       Episode_Reward/keep_balance: 0.9727
     Episode_Reward/rew_lin_vel_xy: 6.3187
      Episode_Reward/rew_ang_vel_z: 2.6251
    Episode_Reward/pen_base_height: -0.2726
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1482
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.1021
    Episode_Reward/pen_action_rate: -0.1118
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0843
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2383
Episode_Reward/pen_flat_orientation: -0.0901
  Episode_Reward/pen_feet_distance: -0.0297
Episode_Reward/pen_feet_regulation: -0.4489
   Episode_Reward/foot_landing_vel: -0.1327
   Episode_Reward/test_gait_reward: -0.8786
Metrics/base_velocity/error_vel_xy: 0.8536
Metrics/base_velocity/error_vel_yaw: 1.1517
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 182059008
                    Iteration time: 1.09s
                        Total time: 2021.30s
                               ETA: 1254.0s

################################################################################
                     [1m Learning iteration 1852/3000 [0m                     

                       Computation: 91943 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.4162
                    Surrogate loss: -0.0057
             Mean action noise std: 0.8448
                     Learning rate: 0.0004
                       Mean reward: 140.86
               Mean episode length: 992.54
       Episode_Reward/keep_balance: 0.9897
     Episode_Reward/rew_lin_vel_xy: 6.3898
      Episode_Reward/rew_ang_vel_z: 2.6299
    Episode_Reward/pen_base_height: -0.2842
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1482
   Episode_Reward/pen_joint_torque: -0.2397
    Episode_Reward/pen_joint_accel: -0.1077
    Episode_Reward/pen_action_rate: -0.1146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2426
Episode_Reward/pen_flat_orientation: -0.0946
  Episode_Reward/pen_feet_distance: -0.0284
Episode_Reward/pen_feet_regulation: -0.4835
   Episode_Reward/foot_landing_vel: -0.1429
   Episode_Reward/test_gait_reward: -0.8968
Metrics/base_velocity/error_vel_xy: 0.9033
Metrics/base_velocity/error_vel_yaw: 1.2116
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 182157312
                    Iteration time: 1.07s
                        Total time: 2022.37s
                               ETA: 1252.9s

################################################################################
                     [1m Learning iteration 1853/3000 [0m                     

                       Computation: 90749 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.4705
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8449
                     Learning rate: 0.0006
                       Mean reward: 144.01
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4453
      Episode_Reward/rew_ang_vel_z: 2.6784
    Episode_Reward/pen_base_height: -0.2734
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.1548
   Episode_Reward/pen_joint_torque: -0.2219
    Episode_Reward/pen_joint_accel: -0.1144
    Episode_Reward/pen_action_rate: -0.1136
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0847
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2453
Episode_Reward/pen_flat_orientation: -0.0868
  Episode_Reward/pen_feet_distance: -0.0329
Episode_Reward/pen_feet_regulation: -0.4639
   Episode_Reward/foot_landing_vel: -0.1432
   Episode_Reward/test_gait_reward: -0.8943
Metrics/base_velocity/error_vel_xy: 0.8965
Metrics/base_velocity/error_vel_yaw: 1.1988
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 182255616
                    Iteration time: 1.08s
                        Total time: 2023.45s
                               ETA: 1251.8s

################################################################################
                     [1m Learning iteration 1854/3000 [0m                     

                       Computation: 89807 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.5084
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8447
                     Learning rate: 0.0009
                       Mean reward: 140.38
               Mean episode length: 993.47
       Episode_Reward/keep_balance: 0.9946
     Episode_Reward/rew_lin_vel_xy: 6.3688
      Episode_Reward/rew_ang_vel_z: 2.6017
    Episode_Reward/pen_base_height: -0.2808
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.1569
   Episode_Reward/pen_joint_torque: -0.2305
    Episode_Reward/pen_joint_accel: -0.1117
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0590
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2483
Episode_Reward/pen_flat_orientation: -0.0953
  Episode_Reward/pen_feet_distance: -0.0349
Episode_Reward/pen_feet_regulation: -0.4953
   Episode_Reward/foot_landing_vel: -0.1333
   Episode_Reward/test_gait_reward: -0.9068
Metrics/base_velocity/error_vel_xy: 0.9302
Metrics/base_velocity/error_vel_yaw: 1.2506
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 182353920
                    Iteration time: 1.09s
                        Total time: 2024.55s
                               ETA: 1250.7s

################################################################################
                     [1m Learning iteration 1855/3000 [0m                     

                       Computation: 90077 steps/s (collection: 0.966s, learning 0.125s)
               Value function loss: 0.5373
                    Surrogate loss: -0.0016
             Mean action noise std: 0.8434
                     Learning rate: 0.0002
                       Mean reward: 141.23
               Mean episode length: 988.96
       Episode_Reward/keep_balance: 0.9902
     Episode_Reward/rew_lin_vel_xy: 6.3285
      Episode_Reward/rew_ang_vel_z: 2.6351
    Episode_Reward/pen_base_height: -0.2893
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.1499
   Episode_Reward/pen_joint_torque: -0.2362
    Episode_Reward/pen_joint_accel: -0.1114
    Episode_Reward/pen_action_rate: -0.1149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0879
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2424
Episode_Reward/pen_flat_orientation: -0.0956
  Episode_Reward/pen_feet_distance: -0.0309
Episode_Reward/pen_feet_regulation: -0.4690
   Episode_Reward/foot_landing_vel: -0.1341
   Episode_Reward/test_gait_reward: -0.8969
Metrics/base_velocity/error_vel_xy: 0.9124
Metrics/base_velocity/error_vel_yaw: 1.2168
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 182452224
                    Iteration time: 1.09s
                        Total time: 2025.64s
                               ETA: 1249.7s

################################################################################
                     [1m Learning iteration 1856/3000 [0m                     

                       Computation: 90783 steps/s (collection: 0.959s, learning 0.124s)
               Value function loss: 0.4854
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8437
                     Learning rate: 0.0004
                       Mean reward: 137.80
               Mean episode length: 982.32
       Episode_Reward/keep_balance: 0.9714
     Episode_Reward/rew_lin_vel_xy: 6.2133
      Episode_Reward/rew_ang_vel_z: 2.5212
    Episode_Reward/pen_base_height: -0.2761
      Episode_Reward/pen_lin_vel_z: -0.0347
     Episode_Reward/pen_ang_vel_xy: -0.1491
   Episode_Reward/pen_joint_torque: -0.2216
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.1134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0859
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2418
Episode_Reward/pen_flat_orientation: -0.0924
  Episode_Reward/pen_feet_distance: -0.0372
Episode_Reward/pen_feet_regulation: -0.4825
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.8845
Metrics/base_velocity/error_vel_xy: 0.9202
Metrics/base_velocity/error_vel_yaw: 1.2397
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 182550528
                    Iteration time: 1.08s
                        Total time: 2026.72s
                               ETA: 1248.6s

################################################################################
                     [1m Learning iteration 1857/3000 [0m                     

                       Computation: 90043 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 0.4654
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8441
                     Learning rate: 0.0003
                       Mean reward: 143.57
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4619
      Episode_Reward/rew_ang_vel_z: 2.6787
    Episode_Reward/pen_base_height: -0.2815
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.1404
   Episode_Reward/pen_joint_torque: -0.2403
    Episode_Reward/pen_joint_accel: -0.1069
    Episode_Reward/pen_action_rate: -0.1141
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2395
Episode_Reward/pen_flat_orientation: -0.0879
  Episode_Reward/pen_feet_distance: -0.0299
Episode_Reward/pen_feet_regulation: -0.4678
   Episode_Reward/foot_landing_vel: -0.1318
   Episode_Reward/test_gait_reward: -0.9000
Metrics/base_velocity/error_vel_xy: 0.8962
Metrics/base_velocity/error_vel_yaw: 1.1999
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 182648832
                    Iteration time: 1.09s
                        Total time: 2027.81s
                               ETA: 1247.5s

################################################################################
                     [1m Learning iteration 1858/3000 [0m                     

                       Computation: 90888 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.5160
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8445
                     Learning rate: 0.0006
                       Mean reward: 142.96
               Mean episode length: 991.83
       Episode_Reward/keep_balance: 0.9915
     Episode_Reward/rew_lin_vel_xy: 6.3876
      Episode_Reward/rew_ang_vel_z: 2.6268
    Episode_Reward/pen_base_height: -0.2881
      Episode_Reward/pen_lin_vel_z: -0.0347
     Episode_Reward/pen_ang_vel_xy: -0.1480
   Episode_Reward/pen_joint_torque: -0.2366
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1150
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2413
Episode_Reward/pen_flat_orientation: -0.0885
  Episode_Reward/pen_feet_distance: -0.0319
Episode_Reward/pen_feet_regulation: -0.4677
   Episode_Reward/foot_landing_vel: -0.1308
   Episode_Reward/test_gait_reward: -0.9087
Metrics/base_velocity/error_vel_xy: 0.9041
Metrics/base_velocity/error_vel_yaw: 1.2114
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 182747136
                    Iteration time: 1.08s
                        Total time: 2028.90s
                               ETA: 1246.4s

################################################################################
                     [1m Learning iteration 1859/3000 [0m                     

                       Computation: 88584 steps/s (collection: 0.986s, learning 0.124s)
               Value function loss: 0.5148
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8446
                     Learning rate: 0.0009
                       Mean reward: 140.01
               Mean episode length: 990.61
       Episode_Reward/keep_balance: 0.9940
     Episode_Reward/rew_lin_vel_xy: 6.4162
      Episode_Reward/rew_ang_vel_z: 2.6319
    Episode_Reward/pen_base_height: -0.2853
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1500
   Episode_Reward/pen_joint_torque: -0.2319
    Episode_Reward/pen_joint_accel: -0.1139
    Episode_Reward/pen_action_rate: -0.1156
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2458
Episode_Reward/pen_flat_orientation: -0.0898
  Episode_Reward/pen_feet_distance: -0.0349
Episode_Reward/pen_feet_regulation: -0.4696
   Episode_Reward/foot_landing_vel: -0.1301
   Episode_Reward/test_gait_reward: -0.9012
Metrics/base_velocity/error_vel_xy: 0.9137
Metrics/base_velocity/error_vel_yaw: 1.2306
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 182845440
                    Iteration time: 1.11s
                        Total time: 2030.01s
                               ETA: 1245.3s

################################################################################
                     [1m Learning iteration 1860/3000 [0m                     

                       Computation: 89972 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 0.4978
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8461
                     Learning rate: 0.0006
                       Mean reward: 139.50
               Mean episode length: 973.58
       Episode_Reward/keep_balance: 0.9697
     Episode_Reward/rew_lin_vel_xy: 6.2151
      Episode_Reward/rew_ang_vel_z: 2.5905
    Episode_Reward/pen_base_height: -0.2830
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.1466
   Episode_Reward/pen_joint_torque: -0.2246
    Episode_Reward/pen_joint_accel: -0.1054
    Episode_Reward/pen_action_rate: -0.1127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0841
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2376
Episode_Reward/pen_flat_orientation: -0.0939
  Episode_Reward/pen_feet_distance: -0.0287
Episode_Reward/pen_feet_regulation: -0.4640
   Episode_Reward/foot_landing_vel: -0.1310
   Episode_Reward/test_gait_reward: -0.8880
Metrics/base_velocity/error_vel_xy: 0.8999
Metrics/base_velocity/error_vel_yaw: 1.1657
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 182943744
                    Iteration time: 1.09s
                        Total time: 2031.10s
                               ETA: 1244.2s

################################################################################
                     [1m Learning iteration 1861/3000 [0m                     

                       Computation: 90004 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.4780
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8472
                     Learning rate: 0.0003
                       Mean reward: 139.70
               Mean episode length: 985.40
       Episode_Reward/keep_balance: 0.9950
     Episode_Reward/rew_lin_vel_xy: 6.3657
      Episode_Reward/rew_ang_vel_z: 2.6283
    Episode_Reward/pen_base_height: -0.2830
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1518
   Episode_Reward/pen_joint_torque: -0.2291
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1157
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2432
Episode_Reward/pen_flat_orientation: -0.0914
  Episode_Reward/pen_feet_distance: -0.0273
Episode_Reward/pen_feet_regulation: -0.4883
   Episode_Reward/foot_landing_vel: -0.1365
   Episode_Reward/test_gait_reward: -0.9050
Metrics/base_velocity/error_vel_xy: 0.9384
Metrics/base_velocity/error_vel_yaw: 1.2314
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 183042048
                    Iteration time: 1.09s
                        Total time: 2032.19s
                               ETA: 1243.1s

################################################################################
                     [1m Learning iteration 1862/3000 [0m                     

                       Computation: 92173 steps/s (collection: 0.943s, learning 0.124s)
               Value function loss: 0.4873
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8479
                     Learning rate: 0.0006
                       Mean reward: 139.45
               Mean episode length: 990.22
       Episode_Reward/keep_balance: 0.9932
     Episode_Reward/rew_lin_vel_xy: 6.3621
      Episode_Reward/rew_ang_vel_z: 2.6607
    Episode_Reward/pen_base_height: -0.2853
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1538
   Episode_Reward/pen_joint_torque: -0.2385
    Episode_Reward/pen_joint_accel: -0.1107
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2462
Episode_Reward/pen_flat_orientation: -0.0907
  Episode_Reward/pen_feet_distance: -0.0332
Episode_Reward/pen_feet_regulation: -0.4810
   Episode_Reward/foot_landing_vel: -0.1399
   Episode_Reward/test_gait_reward: -0.8999
Metrics/base_velocity/error_vel_xy: 0.9286
Metrics/base_velocity/error_vel_yaw: 1.1952
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 183140352
                    Iteration time: 1.07s
                        Total time: 2033.26s
                               ETA: 1242.0s

################################################################################
                     [1m Learning iteration 1863/3000 [0m                     

                       Computation: 90472 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: 0.5292
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8485
                     Learning rate: 0.0004
                       Mean reward: 138.02
               Mean episode length: 984.64
       Episode_Reward/keep_balance: 0.9913
     Episode_Reward/rew_lin_vel_xy: 6.3040
      Episode_Reward/rew_ang_vel_z: 2.6120
    Episode_Reward/pen_base_height: -0.2779
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1554
   Episode_Reward/pen_joint_torque: -0.2406
    Episode_Reward/pen_joint_accel: -0.1136
    Episode_Reward/pen_action_rate: -0.1176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0899
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2485
Episode_Reward/pen_flat_orientation: -0.0891
  Episode_Reward/pen_feet_distance: -0.0329
Episode_Reward/pen_feet_regulation: -0.4774
   Episode_Reward/foot_landing_vel: -0.1394
   Episode_Reward/test_gait_reward: -0.9013
Metrics/base_velocity/error_vel_xy: 0.9388
Metrics/base_velocity/error_vel_yaw: 1.2261
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 183238656
                    Iteration time: 1.09s
                        Total time: 2034.34s
                               ETA: 1240.9s

################################################################################
                     [1m Learning iteration 1864/3000 [0m                     

                       Computation: 90361 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.5258
                    Surrogate loss: -0.0055
             Mean action noise std: 0.8490
                     Learning rate: 0.0006
                       Mean reward: 144.26
               Mean episode length: 998.36
       Episode_Reward/keep_balance: 0.9925
     Episode_Reward/rew_lin_vel_xy: 6.4011
      Episode_Reward/rew_ang_vel_z: 2.6758
    Episode_Reward/pen_base_height: -0.2743
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1462
   Episode_Reward/pen_joint_torque: -0.2295
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.1134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0854
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2405
Episode_Reward/pen_flat_orientation: -0.0907
  Episode_Reward/pen_feet_distance: -0.0341
Episode_Reward/pen_feet_regulation: -0.4615
   Episode_Reward/foot_landing_vel: -0.1376
   Episode_Reward/test_gait_reward: -0.8903
Metrics/base_velocity/error_vel_xy: 0.9032
Metrics/base_velocity/error_vel_yaw: 1.1689
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 183336960
                    Iteration time: 1.09s
                        Total time: 2035.43s
                               ETA: 1239.8s

################################################################################
                     [1m Learning iteration 1865/3000 [0m                     

                       Computation: 90859 steps/s (collection: 0.961s, learning 0.121s)
               Value function loss: 0.4952
                    Surrogate loss: -0.0002
             Mean action noise std: 0.8488
                     Learning rate: 0.0002
                       Mean reward: 143.47
               Mean episode length: 987.16
       Episode_Reward/keep_balance: 0.9897
     Episode_Reward/rew_lin_vel_xy: 6.4041
      Episode_Reward/rew_ang_vel_z: 2.6711
    Episode_Reward/pen_base_height: -0.2869
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.1423
   Episode_Reward/pen_joint_torque: -0.2452
    Episode_Reward/pen_joint_accel: -0.1009
    Episode_Reward/pen_action_rate: -0.1134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2381
Episode_Reward/pen_flat_orientation: -0.0885
  Episode_Reward/pen_feet_distance: -0.0374
Episode_Reward/pen_feet_regulation: -0.4606
   Episode_Reward/foot_landing_vel: -0.1305
   Episode_Reward/test_gait_reward: -0.8898
Metrics/base_velocity/error_vel_xy: 0.8829
Metrics/base_velocity/error_vel_yaw: 1.1679
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 183435264
                    Iteration time: 1.08s
                        Total time: 2036.51s
                               ETA: 1238.7s

################################################################################
                     [1m Learning iteration 1866/3000 [0m                     

                       Computation: 91232 steps/s (collection: 0.954s, learning 0.124s)
               Value function loss: 0.5356
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8492
                     Learning rate: 0.0004
                       Mean reward: 141.93
               Mean episode length: 998.80
       Episode_Reward/keep_balance: 0.9983
     Episode_Reward/rew_lin_vel_xy: 6.3807
      Episode_Reward/rew_ang_vel_z: 2.6732
    Episode_Reward/pen_base_height: -0.2911
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1422
   Episode_Reward/pen_joint_torque: -0.2393
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.1150
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2415
Episode_Reward/pen_flat_orientation: -0.0918
  Episode_Reward/pen_feet_distance: -0.0329
Episode_Reward/pen_feet_regulation: -0.4757
   Episode_Reward/foot_landing_vel: -0.1401
   Episode_Reward/test_gait_reward: -0.9074
Metrics/base_velocity/error_vel_xy: 0.9395
Metrics/base_velocity/error_vel_yaw: 1.1973
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 183533568
                    Iteration time: 1.08s
                        Total time: 2037.59s
                               ETA: 1237.6s

################################################################################
                     [1m Learning iteration 1867/3000 [0m                     

                       Computation: 89126 steps/s (collection: 0.979s, learning 0.124s)
               Value function loss: 0.4636
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8485
                     Learning rate: 0.0002
                       Mean reward: 139.39
               Mean episode length: 985.66
       Episode_Reward/keep_balance: 0.9920
     Episode_Reward/rew_lin_vel_xy: 6.3657
      Episode_Reward/rew_ang_vel_z: 2.6140
    Episode_Reward/pen_base_height: -0.2719
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1500
   Episode_Reward/pen_joint_torque: -0.2445
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1162
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0896
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2437
Episode_Reward/pen_flat_orientation: -0.0930
  Episode_Reward/pen_feet_distance: -0.0319
Episode_Reward/pen_feet_regulation: -0.4910
   Episode_Reward/foot_landing_vel: -0.1387
   Episode_Reward/test_gait_reward: -0.9026
Metrics/base_velocity/error_vel_xy: 0.9164
Metrics/base_velocity/error_vel_yaw: 1.2350
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 183631872
                    Iteration time: 1.10s
                        Total time: 2038.69s
                               ETA: 1236.5s

################################################################################
                     [1m Learning iteration 1868/3000 [0m                     

                       Computation: 90808 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.5102
                    Surrogate loss: -0.0062
             Mean action noise std: 0.8475
                     Learning rate: 0.0004
                       Mean reward: 142.41
               Mean episode length: 995.61
       Episode_Reward/keep_balance: 0.9939
     Episode_Reward/rew_lin_vel_xy: 6.3882
      Episode_Reward/rew_ang_vel_z: 2.6578
    Episode_Reward/pen_base_height: -0.2742
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1535
   Episode_Reward/pen_joint_torque: -0.2264
    Episode_Reward/pen_joint_accel: -0.1145
    Episode_Reward/pen_action_rate: -0.1146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0857
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2458
Episode_Reward/pen_flat_orientation: -0.0916
  Episode_Reward/pen_feet_distance: -0.0411
Episode_Reward/pen_feet_regulation: -0.4804
   Episode_Reward/foot_landing_vel: -0.1367
   Episode_Reward/test_gait_reward: -0.8962
Metrics/base_velocity/error_vel_xy: 0.9092
Metrics/base_velocity/error_vel_yaw: 1.1976
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 183730176
                    Iteration time: 1.08s
                        Total time: 2039.78s
                               ETA: 1235.4s

################################################################################
                     [1m Learning iteration 1869/3000 [0m                     

                       Computation: 90869 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.5488
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8476
                     Learning rate: 0.0009
                       Mean reward: 140.44
               Mean episode length: 983.22
       Episode_Reward/keep_balance: 0.9911
     Episode_Reward/rew_lin_vel_xy: 6.3698
      Episode_Reward/rew_ang_vel_z: 2.6248
    Episode_Reward/pen_base_height: -0.2825
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1508
   Episode_Reward/pen_joint_torque: -0.2329
    Episode_Reward/pen_joint_accel: -0.1208
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2473
Episode_Reward/pen_flat_orientation: -0.0903
  Episode_Reward/pen_feet_distance: -0.0359
Episode_Reward/pen_feet_regulation: -0.4749
   Episode_Reward/foot_landing_vel: -0.1331
   Episode_Reward/test_gait_reward: -0.9005
Metrics/base_velocity/error_vel_xy: 0.9133
Metrics/base_velocity/error_vel_yaw: 1.2258
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 183828480
                    Iteration time: 1.08s
                        Total time: 2040.86s
                               ETA: 1234.3s

################################################################################
                     [1m Learning iteration 1870/3000 [0m                     

                       Computation: 90333 steps/s (collection: 0.961s, learning 0.127s)
               Value function loss: 0.5768
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8489
                     Learning rate: 0.0013
                       Mean reward: 142.12
               Mean episode length: 984.51
       Episode_Reward/keep_balance: 0.9905
     Episode_Reward/rew_lin_vel_xy: 6.4495
      Episode_Reward/rew_ang_vel_z: 2.6325
    Episode_Reward/pen_base_height: -0.2752
      Episode_Reward/pen_lin_vel_z: -0.0345
     Episode_Reward/pen_ang_vel_xy: -0.1397
   Episode_Reward/pen_joint_torque: -0.2400
    Episode_Reward/pen_joint_accel: -0.1088
    Episode_Reward/pen_action_rate: -0.1138
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2411
Episode_Reward/pen_flat_orientation: -0.0897
  Episode_Reward/pen_feet_distance: -0.0312
Episode_Reward/pen_feet_regulation: -0.4432
   Episode_Reward/foot_landing_vel: -0.1339
   Episode_Reward/test_gait_reward: -0.8904
Metrics/base_velocity/error_vel_xy: 0.8778
Metrics/base_velocity/error_vel_yaw: 1.2099
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 183926784
                    Iteration time: 1.09s
                        Total time: 2041.95s
                               ETA: 1233.2s

################################################################################
                     [1m Learning iteration 1871/3000 [0m                     

                       Computation: 90137 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.5412
                    Surrogate loss: -0.0015
             Mean action noise std: 0.8481
                     Learning rate: 0.0003
                       Mean reward: 139.10
               Mean episode length: 990.78
       Episode_Reward/keep_balance: 0.9973
     Episode_Reward/rew_lin_vel_xy: 6.3336
      Episode_Reward/rew_ang_vel_z: 2.6535
    Episode_Reward/pen_base_height: -0.2905
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1537
   Episode_Reward/pen_joint_torque: -0.2396
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2497
Episode_Reward/pen_flat_orientation: -0.0924
  Episode_Reward/pen_feet_distance: -0.0375
Episode_Reward/pen_feet_regulation: -0.4822
   Episode_Reward/foot_landing_vel: -0.1443
   Episode_Reward/test_gait_reward: -0.8964
Metrics/base_velocity/error_vel_xy: 0.9493
Metrics/base_velocity/error_vel_yaw: 1.2145
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 184025088
                    Iteration time: 1.09s
                        Total time: 2043.04s
                               ETA: 1232.2s

################################################################################
                     [1m Learning iteration 1872/3000 [0m                     

                       Computation: 89154 steps/s (collection: 0.978s, learning 0.125s)
               Value function loss: 0.5157
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8463
                     Learning rate: 0.0006
                       Mean reward: 140.37
               Mean episode length: 983.35
       Episode_Reward/keep_balance: 0.9785
     Episode_Reward/rew_lin_vel_xy: 6.2742
      Episode_Reward/rew_ang_vel_z: 2.5992
    Episode_Reward/pen_base_height: -0.2674
      Episode_Reward/pen_lin_vel_z: -0.0347
     Episode_Reward/pen_ang_vel_xy: -0.1442
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.1130
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0535
   Episode_Reward/pen_joint_powers: -0.0832
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2411
Episode_Reward/pen_flat_orientation: -0.0929
  Episode_Reward/pen_feet_distance: -0.0279
Episode_Reward/pen_feet_regulation: -0.4511
   Episode_Reward/foot_landing_vel: -0.1287
   Episode_Reward/test_gait_reward: -0.8820
Metrics/base_velocity/error_vel_xy: 0.8939
Metrics/base_velocity/error_vel_yaw: 1.1881
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 184123392
                    Iteration time: 1.10s
                        Total time: 2044.14s
                               ETA: 1231.1s

################################################################################
                     [1m Learning iteration 1873/3000 [0m                     

                       Computation: 90300 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 0.4686
                    Surrogate loss: -0.0012
             Mean action noise std: 0.8452
                     Learning rate: 0.0003
                       Mean reward: 141.23
               Mean episode length: 990.32
       Episode_Reward/keep_balance: 0.9919
     Episode_Reward/rew_lin_vel_xy: 6.3559
      Episode_Reward/rew_ang_vel_z: 2.6395
    Episode_Reward/pen_base_height: -0.2705
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.1464
   Episode_Reward/pen_joint_torque: -0.2282
    Episode_Reward/pen_joint_accel: -0.1128
    Episode_Reward/pen_action_rate: -0.1146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2459
Episode_Reward/pen_flat_orientation: -0.0903
  Episode_Reward/pen_feet_distance: -0.0351
Episode_Reward/pen_feet_regulation: -0.4577
   Episode_Reward/foot_landing_vel: -0.1364
   Episode_Reward/test_gait_reward: -0.8996
Metrics/base_velocity/error_vel_xy: 0.9067
Metrics/base_velocity/error_vel_yaw: 1.1979
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 184221696
                    Iteration time: 1.09s
                        Total time: 2045.23s
                               ETA: 1230.0s

################################################################################
                     [1m Learning iteration 1874/3000 [0m                     

                       Computation: 89944 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 0.5730
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8440
                     Learning rate: 0.0003
                       Mean reward: 145.47
               Mean episode length: 999.43
       Episode_Reward/keep_balance: 0.9994
     Episode_Reward/rew_lin_vel_xy: 6.4496
      Episode_Reward/rew_ang_vel_z: 2.6727
    Episode_Reward/pen_base_height: -0.2752
      Episode_Reward/pen_lin_vel_z: -0.0349
     Episode_Reward/pen_ang_vel_xy: -0.1427
   Episode_Reward/pen_joint_torque: -0.2301
    Episode_Reward/pen_joint_accel: -0.1016
    Episode_Reward/pen_action_rate: -0.1133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0857
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2414
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0371
Episode_Reward/pen_feet_regulation: -0.4578
   Episode_Reward/foot_landing_vel: -0.1262
   Episode_Reward/test_gait_reward: -0.8930
Metrics/base_velocity/error_vel_xy: 0.9106
Metrics/base_velocity/error_vel_yaw: 1.2058
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 184320000
                    Iteration time: 1.09s
                        Total time: 2046.32s
                               ETA: 1228.9s

################################################################################
                     [1m Learning iteration 1875/3000 [0m                     

                       Computation: 90405 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.4743
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8442
                     Learning rate: 0.0004
                       Mean reward: 138.60
               Mean episode length: 973.83
       Episode_Reward/keep_balance: 0.9852
     Episode_Reward/rew_lin_vel_xy: 6.3459
      Episode_Reward/rew_ang_vel_z: 2.6100
    Episode_Reward/pen_base_height: -0.2841
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1503
   Episode_Reward/pen_joint_torque: -0.2330
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1150
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0556
   Episode_Reward/pen_joint_powers: -0.0869
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2436
Episode_Reward/pen_flat_orientation: -0.0934
  Episode_Reward/pen_feet_distance: -0.0335
Episode_Reward/pen_feet_regulation: -0.4786
   Episode_Reward/foot_landing_vel: -0.1261
   Episode_Reward/test_gait_reward: -0.8994
Metrics/base_velocity/error_vel_xy: 0.9035
Metrics/base_velocity/error_vel_yaw: 1.2122
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 184418304
                    Iteration time: 1.09s
                        Total time: 2047.41s
                               ETA: 1227.8s

################################################################################
                     [1m Learning iteration 1876/3000 [0m                     

                       Computation: 88444 steps/s (collection: 0.988s, learning 0.124s)
               Value function loss: 0.5243
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8447
                     Learning rate: 0.0003
                       Mean reward: 139.87
               Mean episode length: 989.20
       Episode_Reward/keep_balance: 0.9936
     Episode_Reward/rew_lin_vel_xy: 6.3532
      Episode_Reward/rew_ang_vel_z: 2.6339
    Episode_Reward/pen_base_height: -0.2750
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1483
   Episode_Reward/pen_joint_torque: -0.2302
    Episode_Reward/pen_joint_accel: -0.1090
    Episode_Reward/pen_action_rate: -0.1152
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0856
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2437
Episode_Reward/pen_flat_orientation: -0.0927
  Episode_Reward/pen_feet_distance: -0.0297
Episode_Reward/pen_feet_regulation: -0.4679
   Episode_Reward/foot_landing_vel: -0.1325
   Episode_Reward/test_gait_reward: -0.8950
Metrics/base_velocity/error_vel_xy: 0.9348
Metrics/base_velocity/error_vel_yaw: 1.2272
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 184516608
                    Iteration time: 1.11s
                        Total time: 2048.52s
                               ETA: 1226.7s

################################################################################
                     [1m Learning iteration 1877/3000 [0m                     

                       Computation: 89752 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.6003
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8449
                     Learning rate: 0.0006
                       Mean reward: 135.65
               Mean episode length: 966.48
       Episode_Reward/keep_balance: 0.9661
     Episode_Reward/rew_lin_vel_xy: 6.1348
      Episode_Reward/rew_ang_vel_z: 2.5139
    Episode_Reward/pen_base_height: -0.2821
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1519
   Episode_Reward/pen_joint_torque: -0.2347
    Episode_Reward/pen_joint_accel: -0.1141
    Episode_Reward/pen_action_rate: -0.1159
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2435
Episode_Reward/pen_flat_orientation: -0.0923
  Episode_Reward/pen_feet_distance: -0.0295
Episode_Reward/pen_feet_regulation: -0.4975
   Episode_Reward/foot_landing_vel: -0.1345
   Episode_Reward/test_gait_reward: -0.8782
Metrics/base_velocity/error_vel_xy: 0.9300
Metrics/base_velocity/error_vel_yaw: 1.2367
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 184614912
                    Iteration time: 1.10s
                        Total time: 2049.62s
                               ETA: 1225.6s

################################################################################
                     [1m Learning iteration 1878/3000 [0m                     

                       Computation: 89249 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.5203
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8440
                     Learning rate: 0.0006
                       Mean reward: 137.83
               Mean episode length: 985.08
       Episode_Reward/keep_balance: 0.9871
     Episode_Reward/rew_lin_vel_xy: 6.2642
      Episode_Reward/rew_ang_vel_z: 2.5986
    Episode_Reward/pen_base_height: -0.2816
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1546
   Episode_Reward/pen_joint_torque: -0.2269
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1154
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2471
Episode_Reward/pen_flat_orientation: -0.0958
  Episode_Reward/pen_feet_distance: -0.0326
Episode_Reward/pen_feet_regulation: -0.4680
   Episode_Reward/foot_landing_vel: -0.1351
   Episode_Reward/test_gait_reward: -0.8916
Metrics/base_velocity/error_vel_xy: 0.9519
Metrics/base_velocity/error_vel_yaw: 1.2356
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 184713216
                    Iteration time: 1.10s
                        Total time: 2050.72s
                               ETA: 1224.5s

################################################################################
                     [1m Learning iteration 1879/3000 [0m                     

                       Computation: 90368 steps/s (collection: 0.965s, learning 0.122s)
               Value function loss: 0.5125
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8453
                     Learning rate: 0.0009
                       Mean reward: 142.66
               Mean episode length: 992.31
       Episode_Reward/keep_balance: 0.9924
     Episode_Reward/rew_lin_vel_xy: 6.4241
      Episode_Reward/rew_ang_vel_z: 2.6402
    Episode_Reward/pen_base_height: -0.2852
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1461
   Episode_Reward/pen_joint_torque: -0.2323
    Episode_Reward/pen_joint_accel: -0.1011
    Episode_Reward/pen_action_rate: -0.1147
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0558
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2437
Episode_Reward/pen_flat_orientation: -0.0901
  Episode_Reward/pen_feet_distance: -0.0288
Episode_Reward/pen_feet_regulation: -0.4671
   Episode_Reward/foot_landing_vel: -0.1370
   Episode_Reward/test_gait_reward: -0.8933
Metrics/base_velocity/error_vel_xy: 0.9014
Metrics/base_velocity/error_vel_yaw: 1.2116
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 184811520
                    Iteration time: 1.09s
                        Total time: 2051.80s
                               ETA: 1223.4s

################################################################################
                     [1m Learning iteration 1880/3000 [0m                     

                       Computation: 90900 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.4856
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8464
                     Learning rate: 0.0013
                       Mean reward: 137.99
               Mean episode length: 990.00
       Episode_Reward/keep_balance: 0.9918
     Episode_Reward/rew_lin_vel_xy: 6.3264
      Episode_Reward/rew_ang_vel_z: 2.5802
    Episode_Reward/pen_base_height: -0.2809
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1510
   Episode_Reward/pen_joint_torque: -0.2405
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.1170
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0896
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2479
Episode_Reward/pen_flat_orientation: -0.0919
  Episode_Reward/pen_feet_distance: -0.0276
Episode_Reward/pen_feet_regulation: -0.4931
   Episode_Reward/foot_landing_vel: -0.1282
   Episode_Reward/test_gait_reward: -0.9004
Metrics/base_velocity/error_vel_xy: 0.9291
Metrics/base_velocity/error_vel_yaw: 1.2627
      Episode_Termination/time_out: 4.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 184909824
                    Iteration time: 1.08s
                        Total time: 2052.89s
                               ETA: 1222.3s

################################################################################
                     [1m Learning iteration 1881/3000 [0m                     

                       Computation: 87973 steps/s (collection: 0.993s, learning 0.124s)
               Value function loss: 0.5315
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8479
                     Learning rate: 0.0006
                       Mean reward: 141.14
               Mean episode length: 996.82
       Episode_Reward/keep_balance: 0.9974
     Episode_Reward/rew_lin_vel_xy: 6.4010
      Episode_Reward/rew_ang_vel_z: 2.6058
    Episode_Reward/pen_base_height: -0.2830
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1534
   Episode_Reward/pen_joint_torque: -0.2337
    Episode_Reward/pen_joint_accel: -0.1155
    Episode_Reward/pen_action_rate: -0.1176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2512
Episode_Reward/pen_flat_orientation: -0.0941
  Episode_Reward/pen_feet_distance: -0.0299
Episode_Reward/pen_feet_regulation: -0.4972
   Episode_Reward/foot_landing_vel: -0.1380
   Episode_Reward/test_gait_reward: -0.9020
Metrics/base_velocity/error_vel_xy: 0.9269
Metrics/base_velocity/error_vel_yaw: 1.2637
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 185008128
                    Iteration time: 1.12s
                        Total time: 2054.00s
                               ETA: 1221.3s

################################################################################
                     [1m Learning iteration 1882/3000 [0m                     

                       Computation: 89161 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.4714
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8487
                     Learning rate: 0.0006
                       Mean reward: 139.52
               Mean episode length: 985.89
       Episode_Reward/keep_balance: 0.9766
     Episode_Reward/rew_lin_vel_xy: 6.3019
      Episode_Reward/rew_ang_vel_z: 2.5794
    Episode_Reward/pen_base_height: -0.2761
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1440
   Episode_Reward/pen_joint_torque: -0.2324
    Episode_Reward/pen_joint_accel: -0.1072
    Episode_Reward/pen_action_rate: -0.1142
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2430
Episode_Reward/pen_flat_orientation: -0.0930
  Episode_Reward/pen_feet_distance: -0.0342
Episode_Reward/pen_feet_regulation: -0.4680
   Episode_Reward/foot_landing_vel: -0.1355
   Episode_Reward/test_gait_reward: -0.8760
Metrics/base_velocity/error_vel_xy: 0.8826
Metrics/base_velocity/error_vel_yaw: 1.2073
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 185106432
                    Iteration time: 1.10s
                        Total time: 2055.11s
                               ETA: 1220.2s

################################################################################
                     [1m Learning iteration 1883/3000 [0m                     

                       Computation: 89387 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.5194
                    Surrogate loss: -0.0013
             Mean action noise std: 0.8487
                     Learning rate: 0.0003
                       Mean reward: 138.68
               Mean episode length: 989.76
       Episode_Reward/keep_balance: 0.9893
     Episode_Reward/rew_lin_vel_xy: 6.3451
      Episode_Reward/rew_ang_vel_z: 2.6193
    Episode_Reward/pen_base_height: -0.2765
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1545
   Episode_Reward/pen_joint_torque: -0.2330
    Episode_Reward/pen_joint_accel: -0.1069
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2471
Episode_Reward/pen_flat_orientation: -0.0963
  Episode_Reward/pen_feet_distance: -0.0320
Episode_Reward/pen_feet_regulation: -0.4755
   Episode_Reward/foot_landing_vel: -0.1422
   Episode_Reward/test_gait_reward: -0.8909
Metrics/base_velocity/error_vel_xy: 0.9144
Metrics/base_velocity/error_vel_yaw: 1.2154
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 185204736
                    Iteration time: 1.10s
                        Total time: 2056.21s
                               ETA: 1219.1s

################################################################################
                     [1m Learning iteration 1884/3000 [0m                     

                       Computation: 90616 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.4954
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8485
                     Learning rate: 0.0006
                       Mean reward: 141.47
               Mean episode length: 993.44
       Episode_Reward/keep_balance: 0.9932
     Episode_Reward/rew_lin_vel_xy: 6.3310
      Episode_Reward/rew_ang_vel_z: 2.6019
    Episode_Reward/pen_base_height: -0.2750
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.1464
   Episode_Reward/pen_joint_torque: -0.2306
    Episode_Reward/pen_joint_accel: -0.1053
    Episode_Reward/pen_action_rate: -0.1156
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2467
Episode_Reward/pen_flat_orientation: -0.0885
  Episode_Reward/pen_feet_distance: -0.0353
Episode_Reward/pen_feet_regulation: -0.4647
   Episode_Reward/foot_landing_vel: -0.1287
   Episode_Reward/test_gait_reward: -0.8972
Metrics/base_velocity/error_vel_xy: 0.9283
Metrics/base_velocity/error_vel_yaw: 1.2440
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 185303040
                    Iteration time: 1.08s
                        Total time: 2057.29s
                               ETA: 1218.0s

################################################################################
                     [1m Learning iteration 1885/3000 [0m                     

                       Computation: 87747 steps/s (collection: 0.995s, learning 0.125s)
               Value function loss: 0.4837
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8491
                     Learning rate: 0.0006
                       Mean reward: 139.85
               Mean episode length: 988.66
       Episode_Reward/keep_balance: 0.9921
     Episode_Reward/rew_lin_vel_xy: 6.3563
      Episode_Reward/rew_ang_vel_z: 2.6079
    Episode_Reward/pen_base_height: -0.2792
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1471
   Episode_Reward/pen_joint_torque: -0.2386
    Episode_Reward/pen_joint_accel: -0.1053
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2473
Episode_Reward/pen_flat_orientation: -0.0882
  Episode_Reward/pen_feet_distance: -0.0335
Episode_Reward/pen_feet_regulation: -0.4767
   Episode_Reward/foot_landing_vel: -0.1324
   Episode_Reward/test_gait_reward: -0.9040
Metrics/base_velocity/error_vel_xy: 0.9186
Metrics/base_velocity/error_vel_yaw: 1.2461
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 185401344
                    Iteration time: 1.12s
                        Total time: 2058.41s
                               ETA: 1216.9s

################################################################################
                     [1m Learning iteration 1886/3000 [0m                     

                       Computation: 89401 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.5456
                    Surrogate loss: -0.0009
             Mean action noise std: 0.8492
                     Learning rate: 0.0003
                       Mean reward: 140.44
               Mean episode length: 993.63
       Episode_Reward/keep_balance: 0.9912
     Episode_Reward/rew_lin_vel_xy: 6.3487
      Episode_Reward/rew_ang_vel_z: 2.6207
    Episode_Reward/pen_base_height: -0.2730
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1452
   Episode_Reward/pen_joint_torque: -0.2237
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.1143
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2446
Episode_Reward/pen_flat_orientation: -0.0924
  Episode_Reward/pen_feet_distance: -0.0292
Episode_Reward/pen_feet_regulation: -0.4772
   Episode_Reward/foot_landing_vel: -0.1321
   Episode_Reward/test_gait_reward: -0.8899
Metrics/base_velocity/error_vel_xy: 0.9238
Metrics/base_velocity/error_vel_yaw: 1.2214
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 185499648
                    Iteration time: 1.10s
                        Total time: 2059.51s
                               ETA: 1215.8s

################################################################################
                     [1m Learning iteration 1887/3000 [0m                     

                       Computation: 90431 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.4694
                    Surrogate loss: -0.0058
             Mean action noise std: 0.8479
                     Learning rate: 0.0006
                       Mean reward: 138.46
               Mean episode length: 995.39
       Episode_Reward/keep_balance: 0.9961
     Episode_Reward/rew_lin_vel_xy: 6.3356
      Episode_Reward/rew_ang_vel_z: 2.6072
    Episode_Reward/pen_base_height: -0.2797
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1493
   Episode_Reward/pen_joint_torque: -0.2280
    Episode_Reward/pen_joint_accel: -0.1245
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0574
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2499
Episode_Reward/pen_flat_orientation: -0.0930
  Episode_Reward/pen_feet_distance: -0.0294
Episode_Reward/pen_feet_regulation: -0.4792
   Episode_Reward/foot_landing_vel: -0.1329
   Episode_Reward/test_gait_reward: -0.9008
Metrics/base_velocity/error_vel_xy: 0.9449
Metrics/base_velocity/error_vel_yaw: 1.2506
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 185597952
                    Iteration time: 1.09s
                        Total time: 2060.60s
                               ETA: 1214.7s

################################################################################
                     [1m Learning iteration 1888/3000 [0m                     

                       Computation: 91017 steps/s (collection: 0.956s, learning 0.124s)
               Value function loss: 0.5395
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8481
                     Learning rate: 0.0003
                       Mean reward: 139.34
               Mean episode length: 984.21
       Episode_Reward/keep_balance: 0.9850
     Episode_Reward/rew_lin_vel_xy: 6.3682
      Episode_Reward/rew_ang_vel_z: 2.6016
    Episode_Reward/pen_base_height: -0.2719
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1434
   Episode_Reward/pen_joint_torque: -0.2391
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2474
Episode_Reward/pen_flat_orientation: -0.0946
  Episode_Reward/pen_feet_distance: -0.0362
Episode_Reward/pen_feet_regulation: -0.4838
   Episode_Reward/foot_landing_vel: -0.1289
   Episode_Reward/test_gait_reward: -0.9004
Metrics/base_velocity/error_vel_xy: 0.8885
Metrics/base_velocity/error_vel_yaw: 1.2258
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 185696256
                    Iteration time: 1.08s
                        Total time: 2061.68s
                               ETA: 1213.7s

################################################################################
                     [1m Learning iteration 1889/3000 [0m                     

                       Computation: 89207 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.4757
                    Surrogate loss: -0.0057
             Mean action noise std: 0.8494
                     Learning rate: 0.0006
                       Mean reward: 140.13
               Mean episode length: 987.52
       Episode_Reward/keep_balance: 0.9811
     Episode_Reward/rew_lin_vel_xy: 6.3084
      Episode_Reward/rew_ang_vel_z: 2.5849
    Episode_Reward/pen_base_height: -0.2825
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1509
   Episode_Reward/pen_joint_torque: -0.2413
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.1172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0901
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2471
Episode_Reward/pen_flat_orientation: -0.0945
  Episode_Reward/pen_feet_distance: -0.0319
Episode_Reward/pen_feet_regulation: -0.4929
   Episode_Reward/foot_landing_vel: -0.1332
   Episode_Reward/test_gait_reward: -0.8935
Metrics/base_velocity/error_vel_xy: 0.9042
Metrics/base_velocity/error_vel_yaw: 1.2173
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 185794560
                    Iteration time: 1.10s
                        Total time: 2062.78s
                               ETA: 1212.6s

################################################################################
                     [1m Learning iteration 1890/3000 [0m                     

                       Computation: 90381 steps/s (collection: 0.961s, learning 0.127s)
               Value function loss: 0.5286
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8491
                     Learning rate: 0.0003
                       Mean reward: 142.82
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4059
      Episode_Reward/rew_ang_vel_z: 2.6037
    Episode_Reward/pen_base_height: -0.2682
      Episode_Reward/pen_lin_vel_z: -0.0347
     Episode_Reward/pen_ang_vel_xy: -0.1477
   Episode_Reward/pen_joint_torque: -0.2289
    Episode_Reward/pen_joint_accel: -0.0943
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2496
Episode_Reward/pen_flat_orientation: -0.0885
  Episode_Reward/pen_feet_distance: -0.0405
Episode_Reward/pen_feet_regulation: -0.4835
   Episode_Reward/foot_landing_vel: -0.1271
   Episode_Reward/test_gait_reward: -0.9035
Metrics/base_velocity/error_vel_xy: 0.9308
Metrics/base_velocity/error_vel_yaw: 1.2690
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 185892864
                    Iteration time: 1.09s
                        Total time: 2063.87s
                               ETA: 1211.5s

################################################################################
                     [1m Learning iteration 1891/3000 [0m                     

                       Computation: 90595 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.5306
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8478
                     Learning rate: 0.0004
                       Mean reward: 139.44
               Mean episode length: 979.04
       Episode_Reward/keep_balance: 0.9685
     Episode_Reward/rew_lin_vel_xy: 6.2313
      Episode_Reward/rew_ang_vel_z: 2.5209
    Episode_Reward/pen_base_height: -0.2611
      Episode_Reward/pen_lin_vel_z: -0.0341
     Episode_Reward/pen_ang_vel_xy: -0.1471
   Episode_Reward/pen_joint_torque: -0.2122
    Episode_Reward/pen_joint_accel: -0.1016
    Episode_Reward/pen_action_rate: -0.1127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0538
   Episode_Reward/pen_joint_powers: -0.0831
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2419
Episode_Reward/pen_flat_orientation: -0.0923
  Episode_Reward/pen_feet_distance: -0.0297
Episode_Reward/pen_feet_regulation: -0.4657
   Episode_Reward/foot_landing_vel: -0.1215
   Episode_Reward/test_gait_reward: -0.8750
Metrics/base_velocity/error_vel_xy: 0.8898
Metrics/base_velocity/error_vel_yaw: 1.2338
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 185991168
                    Iteration time: 1.09s
                        Total time: 2064.95s
                               ETA: 1210.4s

################################################################################
                     [1m Learning iteration 1892/3000 [0m                     

                       Computation: 89050 steps/s (collection: 0.981s, learning 0.122s)
               Value function loss: 0.5433
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8482
                     Learning rate: 0.0006
                       Mean reward: 136.59
               Mean episode length: 955.43
       Episode_Reward/keep_balance: 0.9438
     Episode_Reward/rew_lin_vel_xy: 6.1241
      Episode_Reward/rew_ang_vel_z: 2.4567
    Episode_Reward/pen_base_height: -0.2542
      Episode_Reward/pen_lin_vel_z: -0.0331
     Episode_Reward/pen_ang_vel_xy: -0.1450
   Episode_Reward/pen_joint_torque: -0.2115
    Episode_Reward/pen_joint_accel: -0.1008
    Episode_Reward/pen_action_rate: -0.1100
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0525
   Episode_Reward/pen_joint_powers: -0.0811
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2372
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0255
Episode_Reward/pen_feet_regulation: -0.4421
   Episode_Reward/foot_landing_vel: -0.1180
   Episode_Reward/test_gait_reward: -0.8502
Metrics/base_velocity/error_vel_xy: 0.8406
Metrics/base_velocity/error_vel_yaw: 1.2119
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 186089472
                    Iteration time: 1.10s
                        Total time: 2066.06s
                               ETA: 1209.3s

################################################################################
                     [1m Learning iteration 1893/3000 [0m                     

                       Computation: 90298 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.5082
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8482
                     Learning rate: 0.0003
                       Mean reward: 137.61
               Mean episode length: 979.50
       Episode_Reward/keep_balance: 0.9821
     Episode_Reward/rew_lin_vel_xy: 6.2935
      Episode_Reward/rew_ang_vel_z: 2.5821
    Episode_Reward/pen_base_height: -0.2804
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1537
   Episode_Reward/pen_joint_torque: -0.2318
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0879
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2503
Episode_Reward/pen_flat_orientation: -0.0977
  Episode_Reward/pen_feet_distance: -0.0290
Episode_Reward/pen_feet_regulation: -0.4738
   Episode_Reward/foot_landing_vel: -0.1380
   Episode_Reward/test_gait_reward: -0.8950
Metrics/base_velocity/error_vel_xy: 0.9093
Metrics/base_velocity/error_vel_yaw: 1.2303
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 186187776
                    Iteration time: 1.09s
                        Total time: 2067.14s
                               ETA: 1208.2s

################################################################################
                     [1m Learning iteration 1894/3000 [0m                     

                       Computation: 89683 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.4444
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8509
                     Learning rate: 0.0004
                       Mean reward: 141.18
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4439
      Episode_Reward/rew_ang_vel_z: 2.6267
    Episode_Reward/pen_base_height: -0.2846
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1479
   Episode_Reward/pen_joint_torque: -0.2393
    Episode_Reward/pen_joint_accel: -0.1089
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2495
Episode_Reward/pen_flat_orientation: -0.0938
  Episode_Reward/pen_feet_distance: -0.0308
Episode_Reward/pen_feet_regulation: -0.4791
   Episode_Reward/foot_landing_vel: -0.1374
   Episode_Reward/test_gait_reward: -0.9102
Metrics/base_velocity/error_vel_xy: 0.9077
Metrics/base_velocity/error_vel_yaw: 1.2500
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 186286080
                    Iteration time: 1.10s
                        Total time: 2068.24s
                               ETA: 1207.1s

################################################################################
                     [1m Learning iteration 1895/3000 [0m                     

                       Computation: 89910 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.5325
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8515
                     Learning rate: 0.0006
                       Mean reward: 139.87
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.3737
      Episode_Reward/rew_ang_vel_z: 2.6100
    Episode_Reward/pen_base_height: -0.2762
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1581
   Episode_Reward/pen_joint_torque: -0.2253
    Episode_Reward/pen_joint_accel: -0.1200
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2559
Episode_Reward/pen_flat_orientation: -0.0903
  Episode_Reward/pen_feet_distance: -0.0345
Episode_Reward/pen_feet_regulation: -0.4989
   Episode_Reward/foot_landing_vel: -0.1409
   Episode_Reward/test_gait_reward: -0.9035
Metrics/base_velocity/error_vel_xy: 0.9293
Metrics/base_velocity/error_vel_yaw: 1.2532
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 186384384
                    Iteration time: 1.09s
                        Total time: 2069.33s
                               ETA: 1206.0s

################################################################################
                     [1m Learning iteration 1896/3000 [0m                     

                       Computation: 88138 steps/s (collection: 0.987s, learning 0.128s)
               Value function loss: 0.5700
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8510
                     Learning rate: 0.0006
                       Mean reward: 141.99
               Mean episode length: 988.42
       Episode_Reward/keep_balance: 0.9891
     Episode_Reward/rew_lin_vel_xy: 6.3940
      Episode_Reward/rew_ang_vel_z: 2.6145
    Episode_Reward/pen_base_height: -0.2716
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1465
   Episode_Reward/pen_joint_torque: -0.2264
    Episode_Reward/pen_joint_accel: -0.1030
    Episode_Reward/pen_action_rate: -0.1146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0858
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2472
Episode_Reward/pen_flat_orientation: -0.0898
  Episode_Reward/pen_feet_distance: -0.0337
Episode_Reward/pen_feet_regulation: -0.4502
   Episode_Reward/foot_landing_vel: -0.1253
   Episode_Reward/test_gait_reward: -0.8956
Metrics/base_velocity/error_vel_xy: 0.8849
Metrics/base_velocity/error_vel_yaw: 1.2167
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 186482688
                    Iteration time: 1.12s
                        Total time: 2070.45s
                               ETA: 1204.9s

################################################################################
                     [1m Learning iteration 1897/3000 [0m                     

                       Computation: 88827 steps/s (collection: 0.977s, learning 0.130s)
               Value function loss: 0.5394
                    Surrogate loss: 0.0003
             Mean action noise std: 0.8514
                     Learning rate: 0.0002
                       Mean reward: 139.16
               Mean episode length: 986.81
       Episode_Reward/keep_balance: 0.9863
     Episode_Reward/rew_lin_vel_xy: 6.3485
      Episode_Reward/rew_ang_vel_z: 2.5916
    Episode_Reward/pen_base_height: -0.2768
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1458
   Episode_Reward/pen_joint_torque: -0.2308
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2506
Episode_Reward/pen_flat_orientation: -0.0916
  Episode_Reward/pen_feet_distance: -0.0319
Episode_Reward/pen_feet_regulation: -0.4835
   Episode_Reward/foot_landing_vel: -0.1335
   Episode_Reward/test_gait_reward: -0.8978
Metrics/base_velocity/error_vel_xy: 0.9057
Metrics/base_velocity/error_vel_yaw: 1.2433
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 186580992
                    Iteration time: 1.11s
                        Total time: 2071.56s
                               ETA: 1203.9s

################################################################################
                     [1m Learning iteration 1898/3000 [0m                     

                       Computation: 88872 steps/s (collection: 0.978s, learning 0.128s)
               Value function loss: 0.5337
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8502
                     Learning rate: 0.0004
                       Mean reward: 140.76
               Mean episode length: 992.42
       Episode_Reward/keep_balance: 0.9895
     Episode_Reward/rew_lin_vel_xy: 6.3970
      Episode_Reward/rew_ang_vel_z: 2.6053
    Episode_Reward/pen_base_height: -0.2652
      Episode_Reward/pen_lin_vel_z: -0.0348
     Episode_Reward/pen_ang_vel_xy: -0.1464
   Episode_Reward/pen_joint_torque: -0.2239
    Episode_Reward/pen_joint_accel: -0.0993
    Episode_Reward/pen_action_rate: -0.1150
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0844
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2491
Episode_Reward/pen_flat_orientation: -0.0870
  Episode_Reward/pen_feet_distance: -0.0384
Episode_Reward/pen_feet_regulation: -0.4574
   Episode_Reward/foot_landing_vel: -0.1284
   Episode_Reward/test_gait_reward: -0.8909
Metrics/base_velocity/error_vel_xy: 0.8824
Metrics/base_velocity/error_vel_yaw: 1.2148
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 186679296
                    Iteration time: 1.11s
                        Total time: 2072.66s
                               ETA: 1202.8s

################################################################################
                     [1m Learning iteration 1899/3000 [0m                     

                       Computation: 89459 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.4976
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8483
                     Learning rate: 0.0006
                       Mean reward: 139.10
               Mean episode length: 992.44
       Episode_Reward/keep_balance: 0.9937
     Episode_Reward/rew_lin_vel_xy: 6.3150
      Episode_Reward/rew_ang_vel_z: 2.6238
    Episode_Reward/pen_base_height: -0.2850
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1480
   Episode_Reward/pen_joint_torque: -0.2433
    Episode_Reward/pen_joint_accel: -0.1120
    Episode_Reward/pen_action_rate: -0.1195
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2513
Episode_Reward/pen_flat_orientation: -0.0935
  Episode_Reward/pen_feet_distance: -0.0373
Episode_Reward/pen_feet_regulation: -0.4908
   Episode_Reward/foot_landing_vel: -0.1251
   Episode_Reward/test_gait_reward: -0.9084
Metrics/base_velocity/error_vel_xy: 0.9421
Metrics/base_velocity/error_vel_yaw: 1.2290
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 186777600
                    Iteration time: 1.10s
                        Total time: 2073.76s
                               ETA: 1201.7s

################################################################################
                     [1m Learning iteration 1900/3000 [0m                     

                       Computation: 89634 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 0.5434
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8483
                     Learning rate: 0.0006
                       Mean reward: 138.97
               Mean episode length: 981.92
       Episode_Reward/keep_balance: 0.9840
     Episode_Reward/rew_lin_vel_xy: 6.3236
      Episode_Reward/rew_ang_vel_z: 2.5905
    Episode_Reward/pen_base_height: -0.2773
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1503
   Episode_Reward/pen_joint_torque: -0.2346
    Episode_Reward/pen_joint_accel: -0.1180
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0882
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2509
Episode_Reward/pen_flat_orientation: -0.0928
  Episode_Reward/pen_feet_distance: -0.0354
Episode_Reward/pen_feet_regulation: -0.4874
   Episode_Reward/foot_landing_vel: -0.1254
   Episode_Reward/test_gait_reward: -0.9012
Metrics/base_velocity/error_vel_xy: 0.9122
Metrics/base_velocity/error_vel_yaw: 1.2166
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 186875904
                    Iteration time: 1.10s
                        Total time: 2074.86s
                               ETA: 1200.6s

################################################################################
                     [1m Learning iteration 1901/3000 [0m                     

                       Computation: 89742 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.5281
                    Surrogate loss: -0.0014
             Mean action noise std: 0.8482
                     Learning rate: 0.0002
                       Mean reward: 139.03
               Mean episode length: 970.86
       Episode_Reward/keep_balance: 0.9668
     Episode_Reward/rew_lin_vel_xy: 6.2107
      Episode_Reward/rew_ang_vel_z: 2.5588
    Episode_Reward/pen_base_height: -0.2674
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1458
   Episode_Reward/pen_joint_torque: -0.2241
    Episode_Reward/pen_joint_accel: -0.1082
    Episode_Reward/pen_action_rate: -0.1137
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0846
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2439
Episode_Reward/pen_flat_orientation: -0.0909
  Episode_Reward/pen_feet_distance: -0.0317
Episode_Reward/pen_feet_regulation: -0.4510
   Episode_Reward/foot_landing_vel: -0.1243
   Episode_Reward/test_gait_reward: -0.8829
Metrics/base_velocity/error_vel_xy: 0.8957
Metrics/base_velocity/error_vel_yaw: 1.1929
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 186974208
                    Iteration time: 1.10s
                        Total time: 2075.95s
                               ETA: 1199.5s

################################################################################
                     [1m Learning iteration 1902/3000 [0m                     

                       Computation: 90222 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.5527
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8502
                     Learning rate: 0.0006
                       Mean reward: 137.44
               Mean episode length: 970.51
       Episode_Reward/keep_balance: 0.9736
     Episode_Reward/rew_lin_vel_xy: 6.2438
      Episode_Reward/rew_ang_vel_z: 2.5756
    Episode_Reward/pen_base_height: -0.2809
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1475
   Episode_Reward/pen_joint_torque: -0.2235
    Episode_Reward/pen_joint_accel: -0.0997
    Episode_Reward/pen_action_rate: -0.1157
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2466
Episode_Reward/pen_flat_orientation: -0.0959
  Episode_Reward/pen_feet_distance: -0.0282
Episode_Reward/pen_feet_regulation: -0.4786
   Episode_Reward/foot_landing_vel: -0.1306
   Episode_Reward/test_gait_reward: -0.8919
Metrics/base_velocity/error_vel_xy: 0.9027
Metrics/base_velocity/error_vel_yaw: 1.2134
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 187072512
                    Iteration time: 1.09s
                        Total time: 2077.04s
                               ETA: 1198.4s

################################################################################
                     [1m Learning iteration 1903/3000 [0m                     

                       Computation: 90621 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.5351
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8517
                     Learning rate: 0.0006
                       Mean reward: 138.14
               Mean episode length: 986.57
       Episode_Reward/keep_balance: 0.9877
     Episode_Reward/rew_lin_vel_xy: 6.2988
      Episode_Reward/rew_ang_vel_z: 2.6149
    Episode_Reward/pen_base_height: -0.2750
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1511
   Episode_Reward/pen_joint_torque: -0.2355
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.1184
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2492
Episode_Reward/pen_flat_orientation: -0.0962
  Episode_Reward/pen_feet_distance: -0.0324
Episode_Reward/pen_feet_regulation: -0.4815
   Episode_Reward/foot_landing_vel: -0.1306
   Episode_Reward/test_gait_reward: -0.9031
Metrics/base_velocity/error_vel_xy: 0.9363
Metrics/base_velocity/error_vel_yaw: 1.2248
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 187170816
                    Iteration time: 1.08s
                        Total time: 2078.13s
                               ETA: 1197.3s

################################################################################
                     [1m Learning iteration 1904/3000 [0m                     

                       Computation: 91242 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.5882
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8524
                     Learning rate: 0.0003
                       Mean reward: 139.36
               Mean episode length: 979.25
       Episode_Reward/keep_balance: 0.9768
     Episode_Reward/rew_lin_vel_xy: 6.3022
      Episode_Reward/rew_ang_vel_z: 2.5977
    Episode_Reward/pen_base_height: -0.2743
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1507
   Episode_Reward/pen_joint_torque: -0.2258
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2475
Episode_Reward/pen_flat_orientation: -0.0930
  Episode_Reward/pen_feet_distance: -0.0267
Episode_Reward/pen_feet_regulation: -0.4526
   Episode_Reward/foot_landing_vel: -0.1288
   Episode_Reward/test_gait_reward: -0.8848
Metrics/base_velocity/error_vel_xy: 0.8913
Metrics/base_velocity/error_vel_yaw: 1.2004
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 187269120
                    Iteration time: 1.08s
                        Total time: 2079.21s
                               ETA: 1196.2s

################################################################################
                     [1m Learning iteration 1905/3000 [0m                     

                       Computation: 83837 steps/s (collection: 1.040s, learning 0.133s)
               Value function loss: 0.5220
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8519
                     Learning rate: 0.0006
                       Mean reward: 135.84
               Mean episode length: 969.78
       Episode_Reward/keep_balance: 0.9664
     Episode_Reward/rew_lin_vel_xy: 6.1749
      Episode_Reward/rew_ang_vel_z: 2.5287
    Episode_Reward/pen_base_height: -0.2676
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1515
   Episode_Reward/pen_joint_torque: -0.2340
    Episode_Reward/pen_joint_accel: -0.1026
    Episode_Reward/pen_action_rate: -0.1162
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2486
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0352
Episode_Reward/pen_feet_regulation: -0.4627
   Episode_Reward/foot_landing_vel: -0.1261
   Episode_Reward/test_gait_reward: -0.8812
Metrics/base_velocity/error_vel_xy: 0.9019
Metrics/base_velocity/error_vel_yaw: 1.2085
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 187367424
                    Iteration time: 1.17s
                        Total time: 2080.38s
                               ETA: 1195.2s

################################################################################
                     [1m Learning iteration 1906/3000 [0m                     

                       Computation: 87081 steps/s (collection: 1.004s, learning 0.124s)
               Value function loss: 0.5304
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8513
                     Learning rate: 0.0006
                       Mean reward: 138.22
               Mean episode length: 979.71
       Episode_Reward/keep_balance: 0.9875
     Episode_Reward/rew_lin_vel_xy: 6.3233
      Episode_Reward/rew_ang_vel_z: 2.6409
    Episode_Reward/pen_base_height: -0.2727
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1445
   Episode_Reward/pen_joint_torque: -0.2361
    Episode_Reward/pen_joint_accel: -0.1088
    Episode_Reward/pen_action_rate: -0.1157
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2471
Episode_Reward/pen_flat_orientation: -0.0911
  Episode_Reward/pen_feet_distance: -0.0307
Episode_Reward/pen_feet_regulation: -0.4596
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.8878
Metrics/base_velocity/error_vel_xy: 0.9121
Metrics/base_velocity/error_vel_yaw: 1.1861
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 187465728
                    Iteration time: 1.13s
                        Total time: 2081.51s
                               ETA: 1194.1s

################################################################################
                     [1m Learning iteration 1907/3000 [0m                     

                       Computation: 90245 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.4869
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8502
                     Learning rate: 0.0002
                       Mean reward: 139.08
               Mean episode length: 976.05
       Episode_Reward/keep_balance: 0.9749
     Episode_Reward/rew_lin_vel_xy: 6.2729
      Episode_Reward/rew_ang_vel_z: 2.6162
    Episode_Reward/pen_base_height: -0.2719
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.1406
   Episode_Reward/pen_joint_torque: -0.2373
    Episode_Reward/pen_joint_accel: -0.0975
    Episode_Reward/pen_action_rate: -0.1140
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0532
   Episode_Reward/pen_joint_powers: -0.0857
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2423
Episode_Reward/pen_flat_orientation: -0.0871
  Episode_Reward/pen_feet_distance: -0.0348
Episode_Reward/pen_feet_regulation: -0.4554
   Episode_Reward/foot_landing_vel: -0.1207
   Episode_Reward/test_gait_reward: -0.8850
Metrics/base_velocity/error_vel_xy: 0.8904
Metrics/base_velocity/error_vel_yaw: 1.1646
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 187564032
                    Iteration time: 1.09s
                        Total time: 2082.60s
                               ETA: 1193.0s

################################################################################
                     [1m Learning iteration 1908/3000 [0m                     

                       Computation: 88976 steps/s (collection: 0.983s, learning 0.122s)
               Value function loss: 0.4812
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8499
                     Learning rate: 0.0004
                       Mean reward: 138.24
               Mean episode length: 998.30
       Episode_Reward/keep_balance: 0.9994
     Episode_Reward/rew_lin_vel_xy: 6.3156
      Episode_Reward/rew_ang_vel_z: 2.6167
    Episode_Reward/pen_base_height: -0.2848
      Episode_Reward/pen_lin_vel_z: -0.0394
     Episode_Reward/pen_ang_vel_xy: -0.1503
   Episode_Reward/pen_joint_torque: -0.2441
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1223
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0918
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2590
Episode_Reward/pen_flat_orientation: -0.0946
  Episode_Reward/pen_feet_distance: -0.0346
Episode_Reward/pen_feet_regulation: -0.5159
   Episode_Reward/foot_landing_vel: -0.1366
   Episode_Reward/test_gait_reward: -0.9257
Metrics/base_velocity/error_vel_xy: 0.9722
Metrics/base_velocity/error_vel_yaw: 1.2480
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 187662336
                    Iteration time: 1.10s
                        Total time: 2083.70s
                               ETA: 1191.9s

################################################################################
                     [1m Learning iteration 1909/3000 [0m                     

                       Computation: 89570 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.5596
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8500
                     Learning rate: 0.0006
                       Mean reward: 136.93
               Mean episode length: 968.80
       Episode_Reward/keep_balance: 0.9696
     Episode_Reward/rew_lin_vel_xy: 6.2161
      Episode_Reward/rew_ang_vel_z: 2.5498
    Episode_Reward/pen_base_height: -0.2621
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.1477
   Episode_Reward/pen_joint_torque: -0.2306
    Episode_Reward/pen_joint_accel: -0.1053
    Episode_Reward/pen_action_rate: -0.1164
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2469
Episode_Reward/pen_flat_orientation: -0.0910
  Episode_Reward/pen_feet_distance: -0.0269
Episode_Reward/pen_feet_regulation: -0.4829
   Episode_Reward/foot_landing_vel: -0.1226
   Episode_Reward/test_gait_reward: -0.8835
Metrics/base_velocity/error_vel_xy: 0.9006
Metrics/base_velocity/error_vel_yaw: 1.2059
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 187760640
                    Iteration time: 1.10s
                        Total time: 2084.80s
                               ETA: 1190.8s

################################################################################
                     [1m Learning iteration 1910/3000 [0m                     

                       Computation: 91730 steps/s (collection: 0.949s, learning 0.123s)
               Value function loss: 0.5410
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8512
                     Learning rate: 0.0009
                       Mean reward: 140.75
               Mean episode length: 984.33
       Episode_Reward/keep_balance: 0.9917
     Episode_Reward/rew_lin_vel_xy: 6.3270
      Episode_Reward/rew_ang_vel_z: 2.6558
    Episode_Reward/pen_base_height: -0.2682
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.1470
   Episode_Reward/pen_joint_torque: -0.2241
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1145
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0535
   Episode_Reward/pen_joint_powers: -0.0841
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2486
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0300
Episode_Reward/pen_feet_regulation: -0.4504
   Episode_Reward/foot_landing_vel: -0.1237
   Episode_Reward/test_gait_reward: -0.8987
Metrics/base_velocity/error_vel_xy: 0.9393
Metrics/base_velocity/error_vel_yaw: 1.1921
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 187858944
                    Iteration time: 1.07s
                        Total time: 2085.87s
                               ETA: 1189.7s

################################################################################
                     [1m Learning iteration 1911/3000 [0m                     

                       Computation: 90925 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.5744
                    Surrogate loss: -0.0007
             Mean action noise std: 0.8508
                     Learning rate: 0.0004
                       Mean reward: 141.07
               Mean episode length: 986.91
       Episode_Reward/keep_balance: 0.9855
     Episode_Reward/rew_lin_vel_xy: 6.3872
      Episode_Reward/rew_ang_vel_z: 2.5952
    Episode_Reward/pen_base_height: -0.2754
      Episode_Reward/pen_lin_vel_z: -0.0352
     Episode_Reward/pen_ang_vel_xy: -0.1474
   Episode_Reward/pen_joint_torque: -0.2287
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1184
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2552
Episode_Reward/pen_flat_orientation: -0.0884
  Episode_Reward/pen_feet_distance: -0.0323
Episode_Reward/pen_feet_regulation: -0.4623
   Episode_Reward/foot_landing_vel: -0.1235
   Episode_Reward/test_gait_reward: -0.9034
Metrics/base_velocity/error_vel_xy: 0.8823
Metrics/base_velocity/error_vel_yaw: 1.2276
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 187957248
                    Iteration time: 1.08s
                        Total time: 2086.95s
                               ETA: 1188.6s

################################################################################
                     [1m Learning iteration 1912/3000 [0m                     

                       Computation: 92518 steps/s (collection: 0.941s, learning 0.122s)
               Value function loss: 0.5302
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8490
                     Learning rate: 0.0003
                       Mean reward: 140.66
               Mean episode length: 987.13
       Episode_Reward/keep_balance: 0.9854
     Episode_Reward/rew_lin_vel_xy: 6.4007
      Episode_Reward/rew_ang_vel_z: 2.5551
    Episode_Reward/pen_base_height: -0.2696
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.1485
   Episode_Reward/pen_joint_torque: -0.2356
    Episode_Reward/pen_joint_accel: -0.0993
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2536
Episode_Reward/pen_flat_orientation: -0.0893
  Episode_Reward/pen_feet_distance: -0.0328
Episode_Reward/pen_feet_regulation: -0.4718
   Episode_Reward/foot_landing_vel: -0.1211
   Episode_Reward/test_gait_reward: -0.8995
Metrics/base_velocity/error_vel_xy: 0.8848
Metrics/base_velocity/error_vel_yaw: 1.2611
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 188055552
                    Iteration time: 1.06s
                        Total time: 2088.01s
                               ETA: 1187.5s

################################################################################
                     [1m Learning iteration 1913/3000 [0m                     

                       Computation: 91150 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.5181
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8484
                     Learning rate: 0.0006
                       Mean reward: 139.64
               Mean episode length: 985.07
       Episode_Reward/keep_balance: 0.9856
     Episode_Reward/rew_lin_vel_xy: 6.2949
      Episode_Reward/rew_ang_vel_z: 2.6383
    Episode_Reward/pen_base_height: -0.2768
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1496
   Episode_Reward/pen_joint_torque: -0.2413
    Episode_Reward/pen_joint_accel: -0.0988
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0879
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2512
Episode_Reward/pen_flat_orientation: -0.0939
  Episode_Reward/pen_feet_distance: -0.0356
Episode_Reward/pen_feet_regulation: -0.4634
   Episode_Reward/foot_landing_vel: -0.1287
   Episode_Reward/test_gait_reward: -0.8936
Metrics/base_velocity/error_vel_xy: 0.9163
Metrics/base_velocity/error_vel_yaw: 1.1840
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 188153856
                    Iteration time: 1.08s
                        Total time: 2089.09s
                               ETA: 1186.4s

################################################################################
                     [1m Learning iteration 1914/3000 [0m                     

                       Computation: 90996 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.4928
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8489
                     Learning rate: 0.0006
                       Mean reward: 138.60
               Mean episode length: 984.73
       Episode_Reward/keep_balance: 0.9868
     Episode_Reward/rew_lin_vel_xy: 6.3267
      Episode_Reward/rew_ang_vel_z: 2.6114
    Episode_Reward/pen_base_height: -0.2645
      Episode_Reward/pen_lin_vel_z: -0.0350
     Episode_Reward/pen_ang_vel_xy: -0.1483
   Episode_Reward/pen_joint_torque: -0.2185
    Episode_Reward/pen_joint_accel: -0.1012
    Episode_Reward/pen_action_rate: -0.1160
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0846
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2512
Episode_Reward/pen_flat_orientation: -0.0885
  Episode_Reward/pen_feet_distance: -0.0315
Episode_Reward/pen_feet_regulation: -0.4647
   Episode_Reward/foot_landing_vel: -0.1299
   Episode_Reward/test_gait_reward: -0.8977
Metrics/base_velocity/error_vel_xy: 0.9163
Metrics/base_velocity/error_vel_yaw: 1.2118
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 188252160
                    Iteration time: 1.08s
                        Total time: 2090.17s
                               ETA: 1185.3s

################################################################################
                     [1m Learning iteration 1915/3000 [0m                     

                       Computation: 90582 steps/s (collection: 0.963s, learning 0.122s)
               Value function loss: 0.6206
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8505
                     Learning rate: 0.0003
                       Mean reward: 139.49
               Mean episode length: 987.55
       Episode_Reward/keep_balance: 0.9930
     Episode_Reward/rew_lin_vel_xy: 6.3639
      Episode_Reward/rew_ang_vel_z: 2.6053
    Episode_Reward/pen_base_height: -0.2676
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1528
   Episode_Reward/pen_joint_torque: -0.2317
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2572
Episode_Reward/pen_flat_orientation: -0.0897
  Episode_Reward/pen_feet_distance: -0.0317
Episode_Reward/pen_feet_regulation: -0.4784
   Episode_Reward/foot_landing_vel: -0.1225
   Episode_Reward/test_gait_reward: -0.9098
Metrics/base_velocity/error_vel_xy: 0.9178
Metrics/base_velocity/error_vel_yaw: 1.2308
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 188350464
                    Iteration time: 1.09s
                        Total time: 2091.26s
                               ETA: 1184.2s

################################################################################
                     [1m Learning iteration 1916/3000 [0m                     

                       Computation: 91238 steps/s (collection: 0.955s, learning 0.122s)
               Value function loss: 0.5386
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8511
                     Learning rate: 0.0003
                       Mean reward: 138.76
               Mean episode length: 978.63
       Episode_Reward/keep_balance: 0.9736
     Episode_Reward/rew_lin_vel_xy: 6.2921
      Episode_Reward/rew_ang_vel_z: 2.5858
    Episode_Reward/pen_base_height: -0.2714
      Episode_Reward/pen_lin_vel_z: -0.0350
     Episode_Reward/pen_ang_vel_xy: -0.1420
   Episode_Reward/pen_joint_torque: -0.2346
    Episode_Reward/pen_joint_accel: -0.0961
    Episode_Reward/pen_action_rate: -0.1167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2484
Episode_Reward/pen_flat_orientation: -0.0897
  Episode_Reward/pen_feet_distance: -0.0351
Episode_Reward/pen_feet_regulation: -0.4594
   Episode_Reward/foot_landing_vel: -0.1209
   Episode_Reward/test_gait_reward: -0.8832
Metrics/base_velocity/error_vel_xy: 0.8816
Metrics/base_velocity/error_vel_yaw: 1.1840
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 188448768
                    Iteration time: 1.08s
                        Total time: 2092.33s
                               ETA: 1183.1s

################################################################################
                     [1m Learning iteration 1917/3000 [0m                     

                       Computation: 85991 steps/s (collection: 1.021s, learning 0.122s)
               Value function loss: 0.5199
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8514
                     Learning rate: 0.0003
                       Mean reward: 140.74
               Mean episode length: 989.08
       Episode_Reward/keep_balance: 0.9951
     Episode_Reward/rew_lin_vel_xy: 6.4141
      Episode_Reward/rew_ang_vel_z: 2.6397
    Episode_Reward/pen_base_height: -0.2769
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1480
   Episode_Reward/pen_joint_torque: -0.2266
    Episode_Reward/pen_joint_accel: -0.1010
    Episode_Reward/pen_action_rate: -0.1172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0856
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2527
Episode_Reward/pen_flat_orientation: -0.0873
  Episode_Reward/pen_feet_distance: -0.0304
Episode_Reward/pen_feet_regulation: -0.4686
   Episode_Reward/foot_landing_vel: -0.1187
   Episode_Reward/test_gait_reward: -0.9021
Metrics/base_velocity/error_vel_xy: 0.9067
Metrics/base_velocity/error_vel_yaw: 1.2187
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 188547072
                    Iteration time: 1.14s
                        Total time: 2093.48s
                               ETA: 1182.1s

################################################################################
                     [1m Learning iteration 1918/3000 [0m                     

                       Computation: 90858 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.4967
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8517
                     Learning rate: 0.0006
                       Mean reward: 136.76
               Mean episode length: 972.28
       Episode_Reward/keep_balance: 0.9525
     Episode_Reward/rew_lin_vel_xy: 6.0550
      Episode_Reward/rew_ang_vel_z: 2.4883
    Episode_Reward/pen_base_height: -0.2749
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1475
   Episode_Reward/pen_joint_torque: -0.2264
    Episode_Reward/pen_joint_accel: -0.0950
    Episode_Reward/pen_action_rate: -0.1149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0853
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2453
Episode_Reward/pen_flat_orientation: -0.0925
  Episode_Reward/pen_feet_distance: -0.0293
Episode_Reward/pen_feet_regulation: -0.4732
   Episode_Reward/foot_landing_vel: -0.1254
   Episode_Reward/test_gait_reward: -0.8735
Metrics/base_velocity/error_vel_xy: 0.9038
Metrics/base_velocity/error_vel_yaw: 1.1950
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 188645376
                    Iteration time: 1.08s
                        Total time: 2094.56s
                               ETA: 1181.0s

################################################################################
                     [1m Learning iteration 1919/3000 [0m                     

                       Computation: 90233 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.5196
                    Surrogate loss: -0.0006
             Mean action noise std: 0.8516
                     Learning rate: 0.0001
                       Mean reward: 136.81
               Mean episode length: 973.23
       Episode_Reward/keep_balance: 0.9777
     Episode_Reward/rew_lin_vel_xy: 6.2874
      Episode_Reward/rew_ang_vel_z: 2.5732
    Episode_Reward/pen_base_height: -0.2803
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1523
   Episode_Reward/pen_joint_torque: -0.2325
    Episode_Reward/pen_joint_accel: -0.1185
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2550
Episode_Reward/pen_flat_orientation: -0.0957
  Episode_Reward/pen_feet_distance: -0.0349
Episode_Reward/pen_feet_regulation: -0.4892
   Episode_Reward/foot_landing_vel: -0.1286
   Episode_Reward/test_gait_reward: -0.8906
Metrics/base_velocity/error_vel_xy: 0.8995
Metrics/base_velocity/error_vel_yaw: 1.2148
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 188743680
                    Iteration time: 1.09s
                        Total time: 2095.65s
                               ETA: 1179.9s

################################################################################
                     [1m Learning iteration 1920/3000 [0m                     

                       Computation: 91023 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.4928
                    Surrogate loss: -0.0057
             Mean action noise std: 0.8486
                     Learning rate: 0.0003
                       Mean reward: 141.59
               Mean episode length: 989.40
       Episode_Reward/keep_balance: 0.9931
     Episode_Reward/rew_lin_vel_xy: 6.4088
      Episode_Reward/rew_ang_vel_z: 2.6637
    Episode_Reward/pen_base_height: -0.2759
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1543
   Episode_Reward/pen_joint_torque: -0.2318
    Episode_Reward/pen_joint_accel: -0.0996
    Episode_Reward/pen_action_rate: -0.1179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2543
Episode_Reward/pen_flat_orientation: -0.0890
  Episode_Reward/pen_feet_distance: -0.0321
Episode_Reward/pen_feet_regulation: -0.4550
   Episode_Reward/foot_landing_vel: -0.1269
   Episode_Reward/test_gait_reward: -0.9001
Metrics/base_velocity/error_vel_xy: 0.8965
Metrics/base_velocity/error_vel_yaw: 1.1861
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 188841984
                    Iteration time: 1.08s
                        Total time: 2096.73s
                               ETA: 1178.8s

################################################################################
                     [1m Learning iteration 1921/3000 [0m                     

                       Computation: 91699 steps/s (collection: 0.950s, learning 0.122s)
               Value function loss: 0.4953
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8478
                     Learning rate: 0.0003
                       Mean reward: 139.50
               Mean episode length: 990.33
       Episode_Reward/keep_balance: 0.9920
     Episode_Reward/rew_lin_vel_xy: 6.3871
      Episode_Reward/rew_ang_vel_z: 2.5848
    Episode_Reward/pen_base_height: -0.2831
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1491
   Episode_Reward/pen_joint_torque: -0.2420
    Episode_Reward/pen_joint_accel: -0.1006
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0898
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2551
Episode_Reward/pen_flat_orientation: -0.0867
  Episode_Reward/pen_feet_distance: -0.0309
Episode_Reward/pen_feet_regulation: -0.4735
   Episode_Reward/foot_landing_vel: -0.1220
   Episode_Reward/test_gait_reward: -0.9006
Metrics/base_velocity/error_vel_xy: 0.8970
Metrics/base_velocity/error_vel_yaw: 1.2600
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 188940288
                    Iteration time: 1.07s
                        Total time: 2097.80s
                               ETA: 1177.7s

################################################################################
                     [1m Learning iteration 1922/3000 [0m                     

                       Computation: 89489 steps/s (collection: 0.976s, learning 0.122s)
               Value function loss: 0.4678
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8483
                     Learning rate: 0.0006
                       Mean reward: 139.91
               Mean episode length: 996.50
       Episode_Reward/keep_balance: 0.9982
     Episode_Reward/rew_lin_vel_xy: 6.4033
      Episode_Reward/rew_ang_vel_z: 2.6135
    Episode_Reward/pen_base_height: -0.2693
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1537
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1084
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2585
Episode_Reward/pen_flat_orientation: -0.0857
  Episode_Reward/pen_feet_distance: -0.0269
Episode_Reward/pen_feet_regulation: -0.4820
   Episode_Reward/foot_landing_vel: -0.1289
   Episode_Reward/test_gait_reward: -0.9091
Metrics/base_velocity/error_vel_xy: 0.9220
Metrics/base_velocity/error_vel_yaw: 1.2476
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 189038592
                    Iteration time: 1.10s
                        Total time: 2098.90s
                               ETA: 1176.6s

################################################################################
                     [1m Learning iteration 1923/3000 [0m                     

                       Computation: 90727 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.5089
                    Surrogate loss: -0.0014
             Mean action noise std: 0.8475
                     Learning rate: 0.0003
                       Mean reward: 142.57
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.3948
      Episode_Reward/rew_ang_vel_z: 2.5817
    Episode_Reward/pen_base_height: -0.2895
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1535
   Episode_Reward/pen_joint_torque: -0.2353
    Episode_Reward/pen_joint_accel: -0.1037
    Episode_Reward/pen_action_rate: -0.1226
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0902
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2631
Episode_Reward/pen_flat_orientation: -0.0921
  Episode_Reward/pen_feet_distance: -0.0417
Episode_Reward/pen_feet_regulation: -0.5030
   Episode_Reward/foot_landing_vel: -0.1266
   Episode_Reward/test_gait_reward: -0.9134
Metrics/base_velocity/error_vel_xy: 0.9564
Metrics/base_velocity/error_vel_yaw: 1.2895
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 189136896
                    Iteration time: 1.08s
                        Total time: 2099.98s
                               ETA: 1175.5s

################################################################################
                     [1m Learning iteration 1924/3000 [0m                     

                       Computation: 89833 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.4934
                    Surrogate loss: -0.0056
             Mean action noise std: 0.8482
                     Learning rate: 0.0006
                       Mean reward: 138.57
               Mean episode length: 986.62
       Episode_Reward/keep_balance: 0.9882
     Episode_Reward/rew_lin_vel_xy: 6.2875
      Episode_Reward/rew_ang_vel_z: 2.5953
    Episode_Reward/pen_base_height: -0.2752
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1498
   Episode_Reward/pen_joint_torque: -0.2369
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1193
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2585
Episode_Reward/pen_flat_orientation: -0.0901
  Episode_Reward/pen_feet_distance: -0.0315
Episode_Reward/pen_feet_regulation: -0.4585
   Episode_Reward/foot_landing_vel: -0.1371
   Episode_Reward/test_gait_reward: -0.8886
Metrics/base_velocity/error_vel_xy: 0.9282
Metrics/base_velocity/error_vel_yaw: 1.2343
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 189235200
                    Iteration time: 1.09s
                        Total time: 2101.08s
                               ETA: 1174.4s

################################################################################
                     [1m Learning iteration 1925/3000 [0m                     

                       Computation: 89888 steps/s (collection: 0.968s, learning 0.126s)
               Value function loss: 0.5788
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8497
                     Learning rate: 0.0004
                       Mean reward: 140.47
               Mean episode length: 993.60
       Episode_Reward/keep_balance: 0.9933
     Episode_Reward/rew_lin_vel_xy: 6.4120
      Episode_Reward/rew_ang_vel_z: 2.6201
    Episode_Reward/pen_base_height: -0.2833
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1497
   Episode_Reward/pen_joint_torque: -0.2288
    Episode_Reward/pen_joint_accel: -0.1041
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2551
Episode_Reward/pen_flat_orientation: -0.0868
  Episode_Reward/pen_feet_distance: -0.0368
Episode_Reward/pen_feet_regulation: -0.4800
   Episode_Reward/foot_landing_vel: -0.1312
   Episode_Reward/test_gait_reward: -0.9080
Metrics/base_velocity/error_vel_xy: 0.9054
Metrics/base_velocity/error_vel_yaw: 1.2216
      Episode_Termination/time_out: 5.0417
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 189333504
                    Iteration time: 1.09s
                        Total time: 2102.17s
                               ETA: 1173.3s

################################################################################
                     [1m Learning iteration 1926/3000 [0m                     

                       Computation: 89845 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.6076
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8499
                     Learning rate: 0.0006
                       Mean reward: 138.30
               Mean episode length: 985.10
       Episode_Reward/keep_balance: 0.9880
     Episode_Reward/rew_lin_vel_xy: 6.3228
      Episode_Reward/rew_ang_vel_z: 2.5751
    Episode_Reward/pen_base_height: -0.2720
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1507
   Episode_Reward/pen_joint_torque: -0.2407
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.1210
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2584
Episode_Reward/pen_flat_orientation: -0.0854
  Episode_Reward/pen_feet_distance: -0.0315
Episode_Reward/pen_feet_regulation: -0.4778
   Episode_Reward/foot_landing_vel: -0.1226
   Episode_Reward/test_gait_reward: -0.8987
Metrics/base_velocity/error_vel_xy: 0.9166
Metrics/base_velocity/error_vel_yaw: 1.2451
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 189431808
                    Iteration time: 1.09s
                        Total time: 2103.27s
                               ETA: 1172.2s

################################################################################
                     [1m Learning iteration 1927/3000 [0m                     

                       Computation: 89784 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.4907
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8488
                     Learning rate: 0.0004
                       Mean reward: 135.39
               Mean episode length: 959.37
       Episode_Reward/keep_balance: 0.9612
     Episode_Reward/rew_lin_vel_xy: 6.1855
      Episode_Reward/rew_ang_vel_z: 2.5209
    Episode_Reward/pen_base_height: -0.2690
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1471
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1010
    Episode_Reward/pen_action_rate: -0.1162
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2480
Episode_Reward/pen_flat_orientation: -0.0902
  Episode_Reward/pen_feet_distance: -0.0340
Episode_Reward/pen_feet_regulation: -0.4746
   Episode_Reward/foot_landing_vel: -0.1142
   Episode_Reward/test_gait_reward: -0.8815
Metrics/base_velocity/error_vel_xy: 0.8867
Metrics/base_velocity/error_vel_yaw: 1.2104
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 189530112
                    Iteration time: 1.09s
                        Total time: 2104.36s
                               ETA: 1171.2s

################################################################################
                     [1m Learning iteration 1928/3000 [0m                     

                       Computation: 91145 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.4872
                    Surrogate loss: -0.0006
             Mean action noise std: 0.8488
                     Learning rate: 0.0001
                       Mean reward: 138.09
               Mean episode length: 981.15
       Episode_Reward/keep_balance: 0.9857
     Episode_Reward/rew_lin_vel_xy: 6.3351
      Episode_Reward/rew_ang_vel_z: 2.5997
    Episode_Reward/pen_base_height: -0.2670
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.1451
   Episode_Reward/pen_joint_torque: -0.2210
    Episode_Reward/pen_joint_accel: -0.1037
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2536
Episode_Reward/pen_flat_orientation: -0.0877
  Episode_Reward/pen_feet_distance: -0.0308
Episode_Reward/pen_feet_regulation: -0.4835
   Episode_Reward/foot_landing_vel: -0.1241
   Episode_Reward/test_gait_reward: -0.8915
Metrics/base_velocity/error_vel_xy: 0.9244
Metrics/base_velocity/error_vel_yaw: 1.2243
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 189628416
                    Iteration time: 1.08s
                        Total time: 2105.44s
                               ETA: 1170.1s

################################################################################
                     [1m Learning iteration 1929/3000 [0m                     

                       Computation: 87914 steps/s (collection: 0.993s, learning 0.125s)
               Value function loss: 0.5456
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8490
                     Learning rate: 0.0003
                       Mean reward: 141.16
               Mean episode length: 998.73
       Episode_Reward/keep_balance: 0.9987
     Episode_Reward/rew_lin_vel_xy: 6.3437
      Episode_Reward/rew_ang_vel_z: 2.6203
    Episode_Reward/pen_base_height: -0.2770
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1494
   Episode_Reward/pen_joint_torque: -0.2320
    Episode_Reward/pen_joint_accel: -0.1136
    Episode_Reward/pen_action_rate: -0.1196
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0885
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2602
Episode_Reward/pen_flat_orientation: -0.0882
  Episode_Reward/pen_feet_distance: -0.0282
Episode_Reward/pen_feet_regulation: -0.4691
   Episode_Reward/foot_landing_vel: -0.1269
   Episode_Reward/test_gait_reward: -0.9085
Metrics/base_velocity/error_vel_xy: 0.9409
Metrics/base_velocity/error_vel_yaw: 1.2404
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 189726720
                    Iteration time: 1.12s
                        Total time: 2106.56s
                               ETA: 1169.0s

################################################################################
                     [1m Learning iteration 1930/3000 [0m                     

                       Computation: 90360 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.5431
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8486
                     Learning rate: 0.0006
                       Mean reward: 142.66
               Mean episode length: 996.02
       Episode_Reward/keep_balance: 0.9959
     Episode_Reward/rew_lin_vel_xy: 6.4642
      Episode_Reward/rew_ang_vel_z: 2.6326
    Episode_Reward/pen_base_height: -0.2722
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1444
   Episode_Reward/pen_joint_torque: -0.2403
    Episode_Reward/pen_joint_accel: -0.1051
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2547
Episode_Reward/pen_flat_orientation: -0.0865
  Episode_Reward/pen_feet_distance: -0.0356
Episode_Reward/pen_feet_regulation: -0.4610
   Episode_Reward/foot_landing_vel: -0.1206
   Episode_Reward/test_gait_reward: -0.9036
Metrics/base_velocity/error_vel_xy: 0.8800
Metrics/base_velocity/error_vel_yaw: 1.2266
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 189825024
                    Iteration time: 1.09s
                        Total time: 2107.65s
                               ETA: 1167.9s

################################################################################
                     [1m Learning iteration 1931/3000 [0m                     

                       Computation: 90805 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.5837
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8495
                     Learning rate: 0.0004
                       Mean reward: 142.00
               Mean episode length: 990.83
       Episode_Reward/keep_balance: 0.9912
     Episode_Reward/rew_lin_vel_xy: 6.3954
      Episode_Reward/rew_ang_vel_z: 2.6010
    Episode_Reward/pen_base_height: -0.2666
      Episode_Reward/pen_lin_vel_z: -0.0348
     Episode_Reward/pen_ang_vel_xy: -0.1501
   Episode_Reward/pen_joint_torque: -0.2270
    Episode_Reward/pen_joint_accel: -0.0965
    Episode_Reward/pen_action_rate: -0.1191
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2582
Episode_Reward/pen_flat_orientation: -0.0861
  Episode_Reward/pen_feet_distance: -0.0320
Episode_Reward/pen_feet_regulation: -0.4574
   Episode_Reward/foot_landing_vel: -0.1179
   Episode_Reward/test_gait_reward: -0.8967
Metrics/base_velocity/error_vel_xy: 0.8867
Metrics/base_velocity/error_vel_yaw: 1.2394
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 189923328
                    Iteration time: 1.08s
                        Total time: 2108.73s
                               ETA: 1166.8s

################################################################################
                     [1m Learning iteration 1932/3000 [0m                     

                       Computation: 89934 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.5364
                    Surrogate loss: -0.0056
             Mean action noise std: 0.8486
                     Learning rate: 0.0009
                       Mean reward: 136.73
               Mean episode length: 975.24
       Episode_Reward/keep_balance: 0.9797
     Episode_Reward/rew_lin_vel_xy: 6.2577
      Episode_Reward/rew_ang_vel_z: 2.5466
    Episode_Reward/pen_base_height: -0.2658
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1487
   Episode_Reward/pen_joint_torque: -0.2287
    Episode_Reward/pen_joint_accel: -0.1022
    Episode_Reward/pen_action_rate: -0.1187
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0556
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2563
Episode_Reward/pen_flat_orientation: -0.0861
  Episode_Reward/pen_feet_distance: -0.0351
Episode_Reward/pen_feet_regulation: -0.4701
   Episode_Reward/foot_landing_vel: -0.1233
   Episode_Reward/test_gait_reward: -0.8935
Metrics/base_velocity/error_vel_xy: 0.9180
Metrics/base_velocity/error_vel_yaw: 1.2626
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 190021632
                    Iteration time: 1.09s
                        Total time: 2109.82s
                               ETA: 1165.7s

################################################################################
                     [1m Learning iteration 1933/3000 [0m                     

                       Computation: 91599 steps/s (collection: 0.950s, learning 0.123s)
               Value function loss: 0.5604
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8481
                     Learning rate: 0.0003
                       Mean reward: 140.44
               Mean episode length: 979.83
       Episode_Reward/keep_balance: 0.9831
     Episode_Reward/rew_lin_vel_xy: 6.3016
      Episode_Reward/rew_ang_vel_z: 2.6030
    Episode_Reward/pen_base_height: -0.2624
      Episode_Reward/pen_lin_vel_z: -0.0343
     Episode_Reward/pen_ang_vel_xy: -0.1496
   Episode_Reward/pen_joint_torque: -0.2113
    Episode_Reward/pen_joint_accel: -0.0903
    Episode_Reward/pen_action_rate: -0.1146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0523
   Episode_Reward/pen_joint_powers: -0.0819
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2511
Episode_Reward/pen_flat_orientation: -0.0843
  Episode_Reward/pen_feet_distance: -0.0304
Episode_Reward/pen_feet_regulation: -0.4496
   Episode_Reward/foot_landing_vel: -0.1132
   Episode_Reward/test_gait_reward: -0.8878
Metrics/base_velocity/error_vel_xy: 0.8989
Metrics/base_velocity/error_vel_yaw: 1.2084
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 190119936
                    Iteration time: 1.07s
                        Total time: 2110.89s
                               ETA: 1164.6s

################################################################################
                     [1m Learning iteration 1934/3000 [0m                     

                       Computation: 89484 steps/s (collection: 0.969s, learning 0.129s)
               Value function loss: 0.4708
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8480
                     Learning rate: 0.0006
                       Mean reward: 138.38
               Mean episode length: 988.41
       Episode_Reward/keep_balance: 0.9896
     Episode_Reward/rew_lin_vel_xy: 6.3388
      Episode_Reward/rew_ang_vel_z: 2.5967
    Episode_Reward/pen_base_height: -0.2768
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1526
   Episode_Reward/pen_joint_torque: -0.2317
    Episode_Reward/pen_joint_accel: -0.1026
    Episode_Reward/pen_action_rate: -0.1195
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0879
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2579
Episode_Reward/pen_flat_orientation: -0.0881
  Episode_Reward/pen_feet_distance: -0.0309
Episode_Reward/pen_feet_regulation: -0.4761
   Episode_Reward/foot_landing_vel: -0.1185
   Episode_Reward/test_gait_reward: -0.8993
Metrics/base_velocity/error_vel_xy: 0.9260
Metrics/base_velocity/error_vel_yaw: 1.2400
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 190218240
                    Iteration time: 1.10s
                        Total time: 2111.99s
                               ETA: 1163.5s

################################################################################
                     [1m Learning iteration 1935/3000 [0m                     

                       Computation: 90075 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.4878
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8473
                     Learning rate: 0.0004
                       Mean reward: 141.24
               Mean episode length: 995.90
       Episode_Reward/keep_balance: 0.9834
     Episode_Reward/rew_lin_vel_xy: 6.2683
      Episode_Reward/rew_ang_vel_z: 2.5761
    Episode_Reward/pen_base_height: -0.2841
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1545
   Episode_Reward/pen_joint_torque: -0.2312
    Episode_Reward/pen_joint_accel: -0.1052
    Episode_Reward/pen_action_rate: -0.1188
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2572
Episode_Reward/pen_flat_orientation: -0.0925
  Episode_Reward/pen_feet_distance: -0.0310
Episode_Reward/pen_feet_regulation: -0.4698
   Episode_Reward/foot_landing_vel: -0.1353
   Episode_Reward/test_gait_reward: -0.8952
Metrics/base_velocity/error_vel_xy: 0.9206
Metrics/base_velocity/error_vel_yaw: 1.2368
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 190316544
                    Iteration time: 1.09s
                        Total time: 2113.08s
                               ETA: 1162.4s

################################################################################
                     [1m Learning iteration 1936/3000 [0m                     

                       Computation: 90131 steps/s (collection: 0.965s, learning 0.126s)
               Value function loss: 0.5541
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8473
                     Learning rate: 0.0006
                       Mean reward: 138.61
               Mean episode length: 998.45
       Episode_Reward/keep_balance: 0.9987
     Episode_Reward/rew_lin_vel_xy: 6.3834
      Episode_Reward/rew_ang_vel_z: 2.6083
    Episode_Reward/pen_base_height: -0.2851
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1564
   Episode_Reward/pen_joint_torque: -0.2352
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1203
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0573
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2604
Episode_Reward/pen_flat_orientation: -0.0887
  Episode_Reward/pen_feet_distance: -0.0376
Episode_Reward/pen_feet_regulation: -0.5046
   Episode_Reward/foot_landing_vel: -0.1326
   Episode_Reward/test_gait_reward: -0.9123
Metrics/base_velocity/error_vel_xy: 0.9415
Metrics/base_velocity/error_vel_yaw: 1.2519
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 190414848
                    Iteration time: 1.09s
                        Total time: 2114.17s
                               ETA: 1161.3s

################################################################################
                     [1m Learning iteration 1937/3000 [0m                     

                       Computation: 89286 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.5068
                    Surrogate loss: -0.0006
             Mean action noise std: 0.8480
                     Learning rate: 0.0002
                       Mean reward: 137.65
               Mean episode length: 980.09
       Episode_Reward/keep_balance: 0.9876
     Episode_Reward/rew_lin_vel_xy: 6.3021
      Episode_Reward/rew_ang_vel_z: 2.6025
    Episode_Reward/pen_base_height: -0.2757
      Episode_Reward/pen_lin_vel_z: -0.0356
     Episode_Reward/pen_ang_vel_xy: -0.1548
   Episode_Reward/pen_joint_torque: -0.2226
    Episode_Reward/pen_joint_accel: -0.1127
    Episode_Reward/pen_action_rate: -0.1190
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2579
Episode_Reward/pen_flat_orientation: -0.0870
  Episode_Reward/pen_feet_distance: -0.0315
Episode_Reward/pen_feet_regulation: -0.4766
   Episode_Reward/foot_landing_vel: -0.1267
   Episode_Reward/test_gait_reward: -0.8972
Metrics/base_velocity/error_vel_xy: 0.9281
Metrics/base_velocity/error_vel_yaw: 1.2348
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 190513152
                    Iteration time: 1.10s
                        Total time: 2115.28s
                               ETA: 1160.2s

################################################################################
                     [1m Learning iteration 1938/3000 [0m                     

                       Computation: 90187 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 0.5388
                    Surrogate loss: -0.0058
             Mean action noise std: 0.8475
                     Learning rate: 0.0004
                       Mean reward: 138.59
               Mean episode length: 984.32
       Episode_Reward/keep_balance: 0.9909
     Episode_Reward/rew_lin_vel_xy: 6.3225
      Episode_Reward/rew_ang_vel_z: 2.5766
    Episode_Reward/pen_base_height: -0.2792
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1532
   Episode_Reward/pen_joint_torque: -0.2340
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2592
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0304
Episode_Reward/pen_feet_regulation: -0.5009
   Episode_Reward/foot_landing_vel: -0.1270
   Episode_Reward/test_gait_reward: -0.9107
Metrics/base_velocity/error_vel_xy: 0.9357
Metrics/base_velocity/error_vel_yaw: 1.2575
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 190611456
                    Iteration time: 1.09s
                        Total time: 2116.37s
                               ETA: 1159.1s

################################################################################
                     [1m Learning iteration 1939/3000 [0m                     

                       Computation: 89061 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.5073
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8473
                     Learning rate: 0.0009
                       Mean reward: 142.20
               Mean episode length: 983.03
       Episode_Reward/keep_balance: 0.9764
     Episode_Reward/rew_lin_vel_xy: 6.3082
      Episode_Reward/rew_ang_vel_z: 2.5793
    Episode_Reward/pen_base_height: -0.2692
      Episode_Reward/pen_lin_vel_z: -0.0338
     Episode_Reward/pen_ang_vel_xy: -0.1473
   Episode_Reward/pen_joint_torque: -0.2255
    Episode_Reward/pen_joint_accel: -0.1016
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0539
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2512
Episode_Reward/pen_flat_orientation: -0.0852
  Episode_Reward/pen_feet_distance: -0.0385
Episode_Reward/pen_feet_regulation: -0.4447
   Episode_Reward/foot_landing_vel: -0.1197
   Episode_Reward/test_gait_reward: -0.8904
Metrics/base_velocity/error_vel_xy: 0.8849
Metrics/base_velocity/error_vel_yaw: 1.1982
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 190709760
                    Iteration time: 1.10s
                        Total time: 2117.47s
                               ETA: 1158.1s

################################################################################
                     [1m Learning iteration 1940/3000 [0m                     

                       Computation: 90685 steps/s (collection: 0.961s, learning 0.123s)
               Value function loss: 0.5593
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8463
                     Learning rate: 0.0006
                       Mean reward: 142.61
               Mean episode length: 995.42
       Episode_Reward/keep_balance: 0.9979
     Episode_Reward/rew_lin_vel_xy: 6.4427
      Episode_Reward/rew_ang_vel_z: 2.6307
    Episode_Reward/pen_base_height: -0.2689
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1485
   Episode_Reward/pen_joint_torque: -0.2343
    Episode_Reward/pen_joint_accel: -0.1071
    Episode_Reward/pen_action_rate: -0.1195
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2576
Episode_Reward/pen_flat_orientation: -0.0881
  Episode_Reward/pen_feet_distance: -0.0389
Episode_Reward/pen_feet_regulation: -0.4758
   Episode_Reward/foot_landing_vel: -0.1283
   Episode_Reward/test_gait_reward: -0.9064
Metrics/base_velocity/error_vel_xy: 0.8987
Metrics/base_velocity/error_vel_yaw: 1.2316
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 190808064
                    Iteration time: 1.08s
                        Total time: 2118.55s
                               ETA: 1157.0s

################################################################################
                     [1m Learning iteration 1941/3000 [0m                     

                       Computation: 90063 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.5757
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8449
                     Learning rate: 0.0003
                       Mean reward: 140.02
               Mean episode length: 988.41
       Episode_Reward/keep_balance: 0.9848
     Episode_Reward/rew_lin_vel_xy: 6.3532
      Episode_Reward/rew_ang_vel_z: 2.6192
    Episode_Reward/pen_base_height: -0.2946
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1481
   Episode_Reward/pen_joint_torque: -0.2452
    Episode_Reward/pen_joint_accel: -0.1052
    Episode_Reward/pen_action_rate: -0.1198
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0899
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2547
Episode_Reward/pen_flat_orientation: -0.0891
  Episode_Reward/pen_feet_distance: -0.0357
Episode_Reward/pen_feet_regulation: -0.4768
   Episode_Reward/foot_landing_vel: -0.1195
   Episode_Reward/test_gait_reward: -0.9045
Metrics/base_velocity/error_vel_xy: 0.8999
Metrics/base_velocity/error_vel_yaw: 1.1903
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 190906368
                    Iteration time: 1.09s
                        Total time: 2119.64s
                               ETA: 1155.9s

################################################################################
                     [1m Learning iteration 1942/3000 [0m                     

                       Computation: 91246 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.4930
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8443
                     Learning rate: 0.0006
                       Mean reward: 137.14
               Mean episode length: 981.49
       Episode_Reward/keep_balance: 0.9741
     Episode_Reward/rew_lin_vel_xy: 6.2066
      Episode_Reward/rew_ang_vel_z: 2.5136
    Episode_Reward/pen_base_height: -0.2871
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1553
   Episode_Reward/pen_joint_torque: -0.2353
    Episode_Reward/pen_joint_accel: -0.1065
    Episode_Reward/pen_action_rate: -0.1207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0899
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2587
Episode_Reward/pen_flat_orientation: -0.0930
  Episode_Reward/pen_feet_distance: -0.0386
Episode_Reward/pen_feet_regulation: -0.4854
   Episode_Reward/foot_landing_vel: -0.1169
   Episode_Reward/test_gait_reward: -0.9021
Metrics/base_velocity/error_vel_xy: 0.9166
Metrics/base_velocity/error_vel_yaw: 1.2624
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 191004672
                    Iteration time: 1.08s
                        Total time: 2120.72s
                               ETA: 1154.8s

################################################################################
                     [1m Learning iteration 1943/3000 [0m                     

                       Computation: 87534 steps/s (collection: 0.999s, learning 0.124s)
               Value function loss: 0.5334
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8451
                     Learning rate: 0.0004
                       Mean reward: 140.43
               Mean episode length: 981.56
       Episode_Reward/keep_balance: 0.9880
     Episode_Reward/rew_lin_vel_xy: 6.3392
      Episode_Reward/rew_ang_vel_z: 2.6437
    Episode_Reward/pen_base_height: -0.2866
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1478
   Episode_Reward/pen_joint_torque: -0.2280
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0856
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2525
Episode_Reward/pen_flat_orientation: -0.0867
  Episode_Reward/pen_feet_distance: -0.0340
Episode_Reward/pen_feet_regulation: -0.4655
   Episode_Reward/foot_landing_vel: -0.1258
   Episode_Reward/test_gait_reward: -0.8974
Metrics/base_velocity/error_vel_xy: 0.9150
Metrics/base_velocity/error_vel_yaw: 1.1885
      Episode_Termination/time_out: 4.9583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 191102976
                    Iteration time: 1.12s
                        Total time: 2121.85s
                               ETA: 1153.7s

################################################################################
                     [1m Learning iteration 1944/3000 [0m                     

                       Computation: 88535 steps/s (collection: 0.987s, learning 0.124s)
               Value function loss: 0.5032
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8439
                     Learning rate: 0.0006
                       Mean reward: 139.65
               Mean episode length: 977.23
       Episode_Reward/keep_balance: 0.9908
     Episode_Reward/rew_lin_vel_xy: 6.3637
      Episode_Reward/rew_ang_vel_z: 2.6351
    Episode_Reward/pen_base_height: -0.2800
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1490
   Episode_Reward/pen_joint_torque: -0.2274
    Episode_Reward/pen_joint_accel: -0.0988
    Episode_Reward/pen_action_rate: -0.1187
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0539
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2552
Episode_Reward/pen_flat_orientation: -0.0856
  Episode_Reward/pen_feet_distance: -0.0273
Episode_Reward/pen_feet_regulation: -0.4680
   Episode_Reward/foot_landing_vel: -0.1216
   Episode_Reward/test_gait_reward: -0.9046
Metrics/base_velocity/error_vel_xy: 0.9117
Metrics/base_velocity/error_vel_yaw: 1.2162
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 191201280
                    Iteration time: 1.11s
                        Total time: 2122.96s
                               ETA: 1152.6s

################################################################################
                     [1m Learning iteration 1945/3000 [0m                     

                       Computation: 90884 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.5302
                    Surrogate loss: -0.0009
             Mean action noise std: 0.8440
                     Learning rate: 0.0002
                       Mean reward: 140.28
               Mean episode length: 991.09
       Episode_Reward/keep_balance: 0.9926
     Episode_Reward/rew_lin_vel_xy: 6.3879
      Episode_Reward/rew_ang_vel_z: 2.6288
    Episode_Reward/pen_base_height: -0.2790
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1554
   Episode_Reward/pen_joint_torque: -0.2341
    Episode_Reward/pen_joint_accel: -0.1024
    Episode_Reward/pen_action_rate: -0.1201
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0557
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2548
Episode_Reward/pen_flat_orientation: -0.0882
  Episode_Reward/pen_feet_distance: -0.0342
Episode_Reward/pen_feet_regulation: -0.4609
   Episode_Reward/foot_landing_vel: -0.1227
   Episode_Reward/test_gait_reward: -0.9098
Metrics/base_velocity/error_vel_xy: 0.8994
Metrics/base_velocity/error_vel_yaw: 1.2305
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 191299584
                    Iteration time: 1.08s
                        Total time: 2124.04s
                               ETA: 1151.5s

################################################################################
                     [1m Learning iteration 1946/3000 [0m                     

                       Computation: 91362 steps/s (collection: 0.953s, learning 0.123s)
               Value function loss: 0.4782
                    Surrogate loss: -0.0062
             Mean action noise std: 0.8432
                     Learning rate: 0.0004
                       Mean reward: 140.04
               Mean episode length: 986.98
       Episode_Reward/keep_balance: 0.9916
     Episode_Reward/rew_lin_vel_xy: 6.3593
      Episode_Reward/rew_ang_vel_z: 2.6200
    Episode_Reward/pen_base_height: -0.2754
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1505
   Episode_Reward/pen_joint_torque: -0.2398
    Episode_Reward/pen_joint_accel: -0.1074
    Episode_Reward/pen_action_rate: -0.1202
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0896
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2571
Episode_Reward/pen_flat_orientation: -0.0867
  Episode_Reward/pen_feet_distance: -0.0337
Episode_Reward/pen_feet_regulation: -0.4743
   Episode_Reward/foot_landing_vel: -0.1260
   Episode_Reward/test_gait_reward: -0.9036
Metrics/base_velocity/error_vel_xy: 0.9145
Metrics/base_velocity/error_vel_yaw: 1.2198
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 191397888
                    Iteration time: 1.08s
                        Total time: 2125.11s
                               ETA: 1150.4s

################################################################################
                     [1m Learning iteration 1947/3000 [0m                     

                       Computation: 90011 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.5472
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8445
                     Learning rate: 0.0006
                       Mean reward: 138.52
               Mean episode length: 981.51
       Episode_Reward/keep_balance: 0.9855
     Episode_Reward/rew_lin_vel_xy: 6.2921
      Episode_Reward/rew_ang_vel_z: 2.5980
    Episode_Reward/pen_base_height: -0.2771
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1521
   Episode_Reward/pen_joint_torque: -0.2275
    Episode_Reward/pen_joint_accel: -0.1060
    Episode_Reward/pen_action_rate: -0.1184
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2553
Episode_Reward/pen_flat_orientation: -0.0870
  Episode_Reward/pen_feet_distance: -0.0331
Episode_Reward/pen_feet_regulation: -0.4677
   Episode_Reward/foot_landing_vel: -0.1223
   Episode_Reward/test_gait_reward: -0.8940
Metrics/base_velocity/error_vel_xy: 0.9251
Metrics/base_velocity/error_vel_yaw: 1.2176
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 191496192
                    Iteration time: 1.09s
                        Total time: 2126.21s
                               ETA: 1149.3s

################################################################################
                     [1m Learning iteration 1948/3000 [0m                     

                       Computation: 89027 steps/s (collection: 0.982s, learning 0.123s)
               Value function loss: 0.5293
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8445
                     Learning rate: 0.0004
                       Mean reward: 136.95
               Mean episode length: 966.53
       Episode_Reward/keep_balance: 0.9634
     Episode_Reward/rew_lin_vel_xy: 6.1284
      Episode_Reward/rew_ang_vel_z: 2.5505
    Episode_Reward/pen_base_height: -0.2794
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1428
   Episode_Reward/pen_joint_torque: -0.2436
    Episode_Reward/pen_joint_accel: -0.1061
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2483
Episode_Reward/pen_flat_orientation: -0.0906
  Episode_Reward/pen_feet_distance: -0.0343
Episode_Reward/pen_feet_regulation: -0.4596
   Episode_Reward/foot_landing_vel: -0.1243
   Episode_Reward/test_gait_reward: -0.8749
Metrics/base_velocity/error_vel_xy: 0.9105
Metrics/base_velocity/error_vel_yaw: 1.1791
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 191594496
                    Iteration time: 1.10s
                        Total time: 2127.31s
                               ETA: 1148.2s

################################################################################
                     [1m Learning iteration 1949/3000 [0m                     

                       Computation: 90543 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.5280
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8436
                     Learning rate: 0.0009
                       Mean reward: 140.20
               Mean episode length: 982.67
       Episode_Reward/keep_balance: 0.9829
     Episode_Reward/rew_lin_vel_xy: 6.3600
      Episode_Reward/rew_ang_vel_z: 2.6186
    Episode_Reward/pen_base_height: -0.2851
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.1432
   Episode_Reward/pen_joint_torque: -0.2344
    Episode_Reward/pen_joint_accel: -0.0987
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0538
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2504
Episode_Reward/pen_flat_orientation: -0.0862
  Episode_Reward/pen_feet_distance: -0.0313
Episode_Reward/pen_feet_regulation: -0.4645
   Episode_Reward/foot_landing_vel: -0.1180
   Episode_Reward/test_gait_reward: -0.8871
Metrics/base_velocity/error_vel_xy: 0.8800
Metrics/base_velocity/error_vel_yaw: 1.1954
      Episode_Termination/time_out: 4.9583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 191692800
                    Iteration time: 1.09s
                        Total time: 2128.40s
                               ETA: 1147.2s

################################################################################
                     [1m Learning iteration 1950/3000 [0m                     

                       Computation: 90039 steps/s (collection: 0.966s, learning 0.125s)
               Value function loss: 0.5598
                    Surrogate loss: -0.0007
             Mean action noise std: 0.8436
                     Learning rate: 0.0004
                       Mean reward: 138.50
               Mean episode length: 982.46
       Episode_Reward/keep_balance: 0.9778
     Episode_Reward/rew_lin_vel_xy: 6.2883
      Episode_Reward/rew_ang_vel_z: 2.5731
    Episode_Reward/pen_base_height: -0.2777
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1512
   Episode_Reward/pen_joint_torque: -0.2433
    Episode_Reward/pen_joint_accel: -0.0941
    Episode_Reward/pen_action_rate: -0.1195
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0558
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2536
Episode_Reward/pen_flat_orientation: -0.0949
  Episode_Reward/pen_feet_distance: -0.0358
Episode_Reward/pen_feet_regulation: -0.4762
   Episode_Reward/foot_landing_vel: -0.1125
   Episode_Reward/test_gait_reward: -0.9053
Metrics/base_velocity/error_vel_xy: 0.8994
Metrics/base_velocity/error_vel_yaw: 1.2132
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 191791104
                    Iteration time: 1.09s
                        Total time: 2129.49s
                               ETA: 1146.1s

################################################################################
                     [1m Learning iteration 1951/3000 [0m                     

                       Computation: 89894 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.4736
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8443
                     Learning rate: 0.0006
                       Mean reward: 141.09
               Mean episode length: 992.00
       Episode_Reward/keep_balance: 0.9933
     Episode_Reward/rew_lin_vel_xy: 6.4288
      Episode_Reward/rew_ang_vel_z: 2.6153
    Episode_Reward/pen_base_height: -0.2728
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1523
   Episode_Reward/pen_joint_torque: -0.2331
    Episode_Reward/pen_joint_accel: -0.1133
    Episode_Reward/pen_action_rate: -0.1194
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2571
Episode_Reward/pen_flat_orientation: -0.0866
  Episode_Reward/pen_feet_distance: -0.0310
Episode_Reward/pen_feet_regulation: -0.4844
   Episode_Reward/foot_landing_vel: -0.1291
   Episode_Reward/test_gait_reward: -0.9101
Metrics/base_velocity/error_vel_xy: 0.8770
Metrics/base_velocity/error_vel_yaw: 1.2368
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 191889408
                    Iteration time: 1.09s
                        Total time: 2130.58s
                               ETA: 1145.0s

################################################################################
                     [1m Learning iteration 1952/3000 [0m                     

                       Computation: 91475 steps/s (collection: 0.952s, learning 0.123s)
               Value function loss: 0.4524
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8436
                     Learning rate: 0.0006
                       Mean reward: 143.68
               Mean episode length: 993.65
       Episode_Reward/keep_balance: 0.9956
     Episode_Reward/rew_lin_vel_xy: 6.4375
      Episode_Reward/rew_ang_vel_z: 2.6973
    Episode_Reward/pen_base_height: -0.2753
      Episode_Reward/pen_lin_vel_z: -0.0351
     Episode_Reward/pen_ang_vel_xy: -0.1490
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.1122
    Episode_Reward/pen_action_rate: -0.1160
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0538
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2507
Episode_Reward/pen_flat_orientation: -0.0845
  Episode_Reward/pen_feet_distance: -0.0270
Episode_Reward/pen_feet_regulation: -0.4439
   Episode_Reward/foot_landing_vel: -0.1185
   Episode_Reward/test_gait_reward: -0.9063
Metrics/base_velocity/error_vel_xy: 0.8926
Metrics/base_velocity/error_vel_yaw: 1.1727
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 191987712
                    Iteration time: 1.07s
                        Total time: 2131.66s
                               ETA: 1143.9s

################################################################################
                     [1m Learning iteration 1953/3000 [0m                     

                       Computation: 89650 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.5137
                    Surrogate loss: 0.0008
             Mean action noise std: 0.8440
                     Learning rate: 0.0002
                       Mean reward: 142.95
               Mean episode length: 993.69
       Episode_Reward/keep_balance: 0.9869
     Episode_Reward/rew_lin_vel_xy: 6.4263
      Episode_Reward/rew_ang_vel_z: 2.6350
    Episode_Reward/pen_base_height: -0.2806
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1457
   Episode_Reward/pen_joint_torque: -0.2365
    Episode_Reward/pen_joint_accel: -0.1092
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2508
Episode_Reward/pen_flat_orientation: -0.0877
  Episode_Reward/pen_feet_distance: -0.0311
Episode_Reward/pen_feet_regulation: -0.4656
   Episode_Reward/foot_landing_vel: -0.1265
   Episode_Reward/test_gait_reward: -0.8980
Metrics/base_velocity/error_vel_xy: 0.8751
Metrics/base_velocity/error_vel_yaw: 1.2072
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 192086016
                    Iteration time: 1.10s
                        Total time: 2132.75s
                               ETA: 1142.8s

################################################################################
                     [1m Learning iteration 1954/3000 [0m                     

                       Computation: 91805 steps/s (collection: 0.949s, learning 0.122s)
               Value function loss: 0.5066
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8438
                     Learning rate: 0.0004
                       Mean reward: 140.85
               Mean episode length: 995.72
       Episode_Reward/keep_balance: 0.9928
     Episode_Reward/rew_lin_vel_xy: 6.3781
      Episode_Reward/rew_ang_vel_z: 2.5919
    Episode_Reward/pen_base_height: -0.2866
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1578
   Episode_Reward/pen_joint_torque: -0.2370
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2591
Episode_Reward/pen_flat_orientation: -0.0906
  Episode_Reward/pen_feet_distance: -0.0319
Episode_Reward/pen_feet_regulation: -0.4863
   Episode_Reward/foot_landing_vel: -0.1279
   Episode_Reward/test_gait_reward: -0.9085
Metrics/base_velocity/error_vel_xy: 0.9203
Metrics/base_velocity/error_vel_yaw: 1.2622
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 192184320
                    Iteration time: 1.07s
                        Total time: 2133.82s
                               ETA: 1141.7s

################################################################################
                     [1m Learning iteration 1955/3000 [0m                     

                       Computation: 90498 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.5032
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8431
                     Learning rate: 0.0002
                       Mean reward: 138.59
               Mean episode length: 978.91
       Episode_Reward/keep_balance: 0.9864
     Episode_Reward/rew_lin_vel_xy: 6.3007
      Episode_Reward/rew_ang_vel_z: 2.6491
    Episode_Reward/pen_base_height: -0.2772
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1494
   Episode_Reward/pen_joint_torque: -0.2356
    Episode_Reward/pen_joint_accel: -0.0972
    Episode_Reward/pen_action_rate: -0.1170
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2511
Episode_Reward/pen_flat_orientation: -0.0847
  Episode_Reward/pen_feet_distance: -0.0308
Episode_Reward/pen_feet_regulation: -0.4627
   Episode_Reward/foot_landing_vel: -0.1216
   Episode_Reward/test_gait_reward: -0.9017
Metrics/base_velocity/error_vel_xy: 0.9225
Metrics/base_velocity/error_vel_yaw: 1.1749
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 192282624
                    Iteration time: 1.09s
                        Total time: 2134.91s
                               ETA: 1140.6s

################################################################################
                     [1m Learning iteration 1956/3000 [0m                     

                       Computation: 89960 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.5343
                    Surrogate loss: -0.0059
             Mean action noise std: 0.8420
                     Learning rate: 0.0004
                       Mean reward: 141.05
               Mean episode length: 991.69
       Episode_Reward/keep_balance: 0.9999
     Episode_Reward/rew_lin_vel_xy: 6.3648
      Episode_Reward/rew_ang_vel_z: 2.6389
    Episode_Reward/pen_base_height: -0.2758
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1594
   Episode_Reward/pen_joint_torque: -0.2272
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1207
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2597
Episode_Reward/pen_flat_orientation: -0.0904
  Episode_Reward/pen_feet_distance: -0.0284
Episode_Reward/pen_feet_regulation: -0.4776
   Episode_Reward/foot_landing_vel: -0.1293
   Episode_Reward/test_gait_reward: -0.9123
Metrics/base_velocity/error_vel_xy: 0.9360
Metrics/base_velocity/error_vel_yaw: 1.2367
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 192380928
                    Iteration time: 1.09s
                        Total time: 2136.00s
                               ETA: 1139.5s

################################################################################
                     [1m Learning iteration 1957/3000 [0m                     

                       Computation: 90543 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.5357
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8414
                     Learning rate: 0.0004
                       Mean reward: 140.12
               Mean episode length: 976.29
       Episode_Reward/keep_balance: 0.9717
     Episode_Reward/rew_lin_vel_xy: 6.2539
      Episode_Reward/rew_ang_vel_z: 2.5637
    Episode_Reward/pen_base_height: -0.2744
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1438
   Episode_Reward/pen_joint_torque: -0.2334
    Episode_Reward/pen_joint_accel: -0.0991
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0531
   Episode_Reward/pen_joint_powers: -0.0858
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2491
Episode_Reward/pen_flat_orientation: -0.0894
  Episode_Reward/pen_feet_distance: -0.0310
Episode_Reward/pen_feet_regulation: -0.4528
   Episode_Reward/foot_landing_vel: -0.1165
   Episode_Reward/test_gait_reward: -0.8822
Metrics/base_velocity/error_vel_xy: 0.8897
Metrics/base_velocity/error_vel_yaw: 1.2032
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 192479232
                    Iteration time: 1.09s
                        Total time: 2137.09s
                               ETA: 1138.4s

################################################################################
                     [1m Learning iteration 1958/3000 [0m                     

                       Computation: 90022 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.5460
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8403
                     Learning rate: 0.0004
                       Mean reward: 138.41
               Mean episode length: 989.69
       Episode_Reward/keep_balance: 0.9927
     Episode_Reward/rew_lin_vel_xy: 6.3882
      Episode_Reward/rew_ang_vel_z: 2.6423
    Episode_Reward/pen_base_height: -0.2914
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1492
   Episode_Reward/pen_joint_torque: -0.2397
    Episode_Reward/pen_joint_accel: -0.0999
    Episode_Reward/pen_action_rate: -0.1197
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0896
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2543
Episode_Reward/pen_flat_orientation: -0.0909
  Episode_Reward/pen_feet_distance: -0.0356
Episode_Reward/pen_feet_regulation: -0.4947
   Episode_Reward/foot_landing_vel: -0.1186
   Episode_Reward/test_gait_reward: -0.9113
Metrics/base_velocity/error_vel_xy: 0.9146
Metrics/base_velocity/error_vel_yaw: 1.2051
      Episode_Termination/time_out: 4.8333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 192577536
                    Iteration time: 1.09s
                        Total time: 2138.18s
                               ETA: 1137.3s

################################################################################
                     [1m Learning iteration 1959/3000 [0m                     

                       Computation: 90424 steps/s (collection: 0.963s, learning 0.124s)
               Value function loss: 0.5077
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8394
                     Learning rate: 0.0004
                       Mean reward: 138.72
               Mean episode length: 983.56
       Episode_Reward/keep_balance: 0.9883
     Episode_Reward/rew_lin_vel_xy: 6.3341
      Episode_Reward/rew_ang_vel_z: 2.6176
    Episode_Reward/pen_base_height: -0.2826
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1534
   Episode_Reward/pen_joint_torque: -0.2292
    Episode_Reward/pen_joint_accel: -0.1013
    Episode_Reward/pen_action_rate: -0.1184
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2530
Episode_Reward/pen_flat_orientation: -0.0872
  Episode_Reward/pen_feet_distance: -0.0298
Episode_Reward/pen_feet_regulation: -0.4675
   Episode_Reward/foot_landing_vel: -0.1224
   Episode_Reward/test_gait_reward: -0.9033
Metrics/base_velocity/error_vel_xy: 0.9169
Metrics/base_velocity/error_vel_yaw: 1.2087
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 192675840
                    Iteration time: 1.09s
                        Total time: 2139.27s
                               ETA: 1136.2s

################################################################################
                     [1m Learning iteration 1960/3000 [0m                     

                       Computation: 88700 steps/s (collection: 0.986s, learning 0.123s)
               Value function loss: 0.5432
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8396
                     Learning rate: 0.0009
                       Mean reward: 142.17
               Mean episode length: 988.84
       Episode_Reward/keep_balance: 0.9828
     Episode_Reward/rew_lin_vel_xy: 6.3169
      Episode_Reward/rew_ang_vel_z: 2.6052
    Episode_Reward/pen_base_height: -0.2841
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1463
   Episode_Reward/pen_joint_torque: -0.2381
    Episode_Reward/pen_joint_accel: -0.1032
    Episode_Reward/pen_action_rate: -0.1173
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0869
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2499
Episode_Reward/pen_flat_orientation: -0.0892
  Episode_Reward/pen_feet_distance: -0.0317
Episode_Reward/pen_feet_regulation: -0.4814
   Episode_Reward/foot_landing_vel: -0.1273
   Episode_Reward/test_gait_reward: -0.8971
Metrics/base_velocity/error_vel_xy: 0.8958
Metrics/base_velocity/error_vel_yaw: 1.2059
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 192774144
                    Iteration time: 1.11s
                        Total time: 2140.37s
                               ETA: 1135.1s

################################################################################
                     [1m Learning iteration 1961/3000 [0m                     

                       Computation: 89003 steps/s (collection: 0.982s, learning 0.123s)
               Value function loss: 0.5749
                    Surrogate loss: 0.0022
             Mean action noise std: 0.8398
                     Learning rate: 0.0001
                       Mean reward: 140.72
               Mean episode length: 986.80
       Episode_Reward/keep_balance: 0.9849
     Episode_Reward/rew_lin_vel_xy: 6.3599
      Episode_Reward/rew_ang_vel_z: 2.6012
    Episode_Reward/pen_base_height: -0.2778
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1540
   Episode_Reward/pen_joint_torque: -0.2287
    Episode_Reward/pen_joint_accel: -0.1117
    Episode_Reward/pen_action_rate: -0.1179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0853
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2547
Episode_Reward/pen_flat_orientation: -0.0866
  Episode_Reward/pen_feet_distance: -0.0298
Episode_Reward/pen_feet_regulation: -0.4598
   Episode_Reward/foot_landing_vel: -0.1190
   Episode_Reward/test_gait_reward: -0.8948
Metrics/base_velocity/error_vel_xy: 0.8865
Metrics/base_velocity/error_vel_yaw: 1.2099
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 192872448
                    Iteration time: 1.10s
                        Total time: 2141.48s
                               ETA: 1134.0s

################################################################################
                     [1m Learning iteration 1962/3000 [0m                     

                       Computation: 89111 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.5151
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8395
                     Learning rate: 0.0004
                       Mean reward: 138.96
               Mean episode length: 977.65
       Episode_Reward/keep_balance: 0.9867
     Episode_Reward/rew_lin_vel_xy: 6.3646
      Episode_Reward/rew_ang_vel_z: 2.6335
    Episode_Reward/pen_base_height: -0.2911
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1529
   Episode_Reward/pen_joint_torque: -0.2331
    Episode_Reward/pen_joint_accel: -0.0914
    Episode_Reward/pen_action_rate: -0.1182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2507
Episode_Reward/pen_flat_orientation: -0.0921
  Episode_Reward/pen_feet_distance: -0.0354
Episode_Reward/pen_feet_regulation: -0.4660
   Episode_Reward/foot_landing_vel: -0.1181
   Episode_Reward/test_gait_reward: -0.9056
Metrics/base_velocity/error_vel_xy: 0.9036
Metrics/base_velocity/error_vel_yaw: 1.1958
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 192970752
                    Iteration time: 1.10s
                        Total time: 2142.58s
                               ETA: 1133.0s

################################################################################
                     [1m Learning iteration 1963/3000 [0m                     

                       Computation: 91264 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.5962
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8405
                     Learning rate: 0.0006
                       Mean reward: 140.12
               Mean episode length: 990.12
       Episode_Reward/keep_balance: 0.9888
     Episode_Reward/rew_lin_vel_xy: 6.3907
      Episode_Reward/rew_ang_vel_z: 2.5868
    Episode_Reward/pen_base_height: -0.2824
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1504
   Episode_Reward/pen_joint_torque: -0.2425
    Episode_Reward/pen_joint_accel: -0.1057
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0891
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2515
Episode_Reward/pen_flat_orientation: -0.0860
  Episode_Reward/pen_feet_distance: -0.0319
Episode_Reward/pen_feet_regulation: -0.4668
   Episode_Reward/foot_landing_vel: -0.1179
   Episode_Reward/test_gait_reward: -0.9037
Metrics/base_velocity/error_vel_xy: 0.8955
Metrics/base_velocity/error_vel_yaw: 1.2411
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 193069056
                    Iteration time: 1.08s
                        Total time: 2143.66s
                               ETA: 1131.9s

################################################################################
                     [1m Learning iteration 1964/3000 [0m                     

                       Computation: 90265 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.5055
                    Surrogate loss: -0.0004
             Mean action noise std: 0.8406
                     Learning rate: 0.0001
                       Mean reward: 138.34
               Mean episode length: 972.66
       Episode_Reward/keep_balance: 0.9716
     Episode_Reward/rew_lin_vel_xy: 6.2485
      Episode_Reward/rew_ang_vel_z: 2.5789
    Episode_Reward/pen_base_height: -0.2847
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1529
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1096
    Episode_Reward/pen_action_rate: -0.1152
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0852
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2478
Episode_Reward/pen_flat_orientation: -0.0906
  Episode_Reward/pen_feet_distance: -0.0260
Episode_Reward/pen_feet_regulation: -0.4660
   Episode_Reward/foot_landing_vel: -0.1209
   Episode_Reward/test_gait_reward: -0.8844
Metrics/base_velocity/error_vel_xy: 0.9032
Metrics/base_velocity/error_vel_yaw: 1.1874
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 193167360
                    Iteration time: 1.09s
                        Total time: 2144.75s
                               ETA: 1130.8s

################################################################################
                     [1m Learning iteration 1965/3000 [0m                     

                       Computation: 89150 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.5942
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8403
                     Learning rate: 0.0003
                       Mean reward: 139.20
               Mean episode length: 973.47
       Episode_Reward/keep_balance: 0.9783
     Episode_Reward/rew_lin_vel_xy: 6.3210
      Episode_Reward/rew_ang_vel_z: 2.5501
    Episode_Reward/pen_base_height: -0.2867
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1473
   Episode_Reward/pen_joint_torque: -0.2377
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.1176
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2508
Episode_Reward/pen_flat_orientation: -0.0884
  Episode_Reward/pen_feet_distance: -0.0389
Episode_Reward/pen_feet_regulation: -0.4609
   Episode_Reward/foot_landing_vel: -0.1214
   Episode_Reward/test_gait_reward: -0.8872
Metrics/base_velocity/error_vel_xy: 0.8897
Metrics/base_velocity/error_vel_yaw: 1.2359
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 193265664
                    Iteration time: 1.10s
                        Total time: 2145.85s
                               ETA: 1129.7s

################################################################################
                     [1m Learning iteration 1966/3000 [0m                     

                       Computation: 87735 steps/s (collection: 0.991s, learning 0.129s)
               Value function loss: 0.5142
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8389
                     Learning rate: 0.0006
                       Mean reward: 138.42
               Mean episode length: 991.08
       Episode_Reward/keep_balance: 0.9947
     Episode_Reward/rew_lin_vel_xy: 6.3225
      Episode_Reward/rew_ang_vel_z: 2.6136
    Episode_Reward/pen_base_height: -0.2886
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1547
   Episode_Reward/pen_joint_torque: -0.2379
    Episode_Reward/pen_joint_accel: -0.1093
    Episode_Reward/pen_action_rate: -0.1195
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2553
Episode_Reward/pen_flat_orientation: -0.0897
  Episode_Reward/pen_feet_distance: -0.0300
Episode_Reward/pen_feet_regulation: -0.4806
   Episode_Reward/foot_landing_vel: -0.1357
   Episode_Reward/test_gait_reward: -0.9113
Metrics/base_velocity/error_vel_xy: 0.9571
Metrics/base_velocity/error_vel_yaw: 1.2339
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 193363968
                    Iteration time: 1.12s
                        Total time: 2146.97s
                               ETA: 1128.6s

################################################################################
                     [1m Learning iteration 1967/3000 [0m                     

                       Computation: 88844 steps/s (collection: 0.981s, learning 0.125s)
               Value function loss: 0.9030
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8402
                     Learning rate: 0.0006
                       Mean reward: 141.47
               Mean episode length: 987.21
       Episode_Reward/keep_balance: 0.9639
     Episode_Reward/rew_lin_vel_xy: 6.1513
      Episode_Reward/rew_ang_vel_z: 2.5847
    Episode_Reward/pen_base_height: -0.2951
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1483
   Episode_Reward/pen_joint_torque: -0.2274
    Episode_Reward/pen_joint_accel: -0.0962
    Episode_Reward/pen_action_rate: -0.1139
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0539
   Episode_Reward/pen_joint_powers: -0.0855
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2413
Episode_Reward/pen_flat_orientation: -0.0985
  Episode_Reward/pen_feet_distance: -0.0284
Episode_Reward/pen_feet_regulation: -0.4593
   Episode_Reward/foot_landing_vel: -0.1175
   Episode_Reward/test_gait_reward: -0.8713
Metrics/base_velocity/error_vel_xy: 0.9140
Metrics/base_velocity/error_vel_yaw: 1.1679
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 193462272
                    Iteration time: 1.11s
                        Total time: 2148.08s
                               ETA: 1127.5s

################################################################################
                     [1m Learning iteration 1968/3000 [0m                     

                       Computation: 89329 steps/s (collection: 0.974s, learning 0.127s)
               Value function loss: 0.5669
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8418
                     Learning rate: 0.0004
                       Mean reward: 141.22
               Mean episode length: 987.36
       Episode_Reward/keep_balance: 0.9862
     Episode_Reward/rew_lin_vel_xy: 6.3646
      Episode_Reward/rew_ang_vel_z: 2.5931
    Episode_Reward/pen_base_height: -0.2826
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1526
   Episode_Reward/pen_joint_torque: -0.2384
    Episode_Reward/pen_joint_accel: -0.1025
    Episode_Reward/pen_action_rate: -0.1185
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0879
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2524
Episode_Reward/pen_flat_orientation: -0.0864
  Episode_Reward/pen_feet_distance: -0.0261
Episode_Reward/pen_feet_regulation: -0.4843
   Episode_Reward/foot_landing_vel: -0.1231
   Episode_Reward/test_gait_reward: -0.9073
Metrics/base_velocity/error_vel_xy: 0.9019
Metrics/base_velocity/error_vel_yaw: 1.2352
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 193560576
                    Iteration time: 1.10s
                        Total time: 2149.18s
                               ETA: 1126.4s

################################################################################
                     [1m Learning iteration 1969/3000 [0m                     

                       Computation: 89591 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.5019
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8422
                     Learning rate: 0.0004
                       Mean reward: 140.75
               Mean episode length: 991.00
       Episode_Reward/keep_balance: 0.9906
     Episode_Reward/rew_lin_vel_xy: 6.3511
      Episode_Reward/rew_ang_vel_z: 2.6300
    Episode_Reward/pen_base_height: -0.2822
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1494
   Episode_Reward/pen_joint_torque: -0.2373
    Episode_Reward/pen_joint_accel: -0.0995
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2490
Episode_Reward/pen_flat_orientation: -0.0871
  Episode_Reward/pen_feet_distance: -0.0278
Episode_Reward/pen_feet_regulation: -0.4868
   Episode_Reward/foot_landing_vel: -0.1174
   Episode_Reward/test_gait_reward: -0.9052
Metrics/base_velocity/error_vel_xy: 0.9226
Metrics/base_velocity/error_vel_yaw: 1.2128
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 193658880
                    Iteration time: 1.10s
                        Total time: 2150.28s
                               ETA: 1125.3s

################################################################################
                     [1m Learning iteration 1970/3000 [0m                     

                       Computation: 88617 steps/s (collection: 0.985s, learning 0.125s)
               Value function loss: 0.4829
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8434
                     Learning rate: 0.0009
                       Mean reward: 139.12
               Mean episode length: 990.58
       Episode_Reward/keep_balance: 0.9616
     Episode_Reward/rew_lin_vel_xy: 6.1418
      Episode_Reward/rew_ang_vel_z: 2.5435
    Episode_Reward/pen_base_height: -0.2754
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.1467
   Episode_Reward/pen_joint_torque: -0.2240
    Episode_Reward/pen_joint_accel: -0.1070
    Episode_Reward/pen_action_rate: -0.1132
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0841
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2413
Episode_Reward/pen_flat_orientation: -0.0922
  Episode_Reward/pen_feet_distance: -0.0246
Episode_Reward/pen_feet_regulation: -0.4719
   Episode_Reward/foot_landing_vel: -0.1250
   Episode_Reward/test_gait_reward: -0.8754
Metrics/base_velocity/error_vel_xy: 0.9081
Metrics/base_velocity/error_vel_yaw: 1.1853
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 193757184
                    Iteration time: 1.11s
                        Total time: 2151.39s
                               ETA: 1124.3s

################################################################################
                     [1m Learning iteration 1971/3000 [0m                     

                       Computation: 90958 steps/s (collection: 0.958s, learning 0.123s)
               Value function loss: 0.4895
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8442
                     Learning rate: 0.0006
                       Mean reward: 139.83
               Mean episode length: 987.02
       Episode_Reward/keep_balance: 0.9772
     Episode_Reward/rew_lin_vel_xy: 6.3772
      Episode_Reward/rew_ang_vel_z: 2.6035
    Episode_Reward/pen_base_height: -0.2745
      Episode_Reward/pen_lin_vel_z: -0.0357
     Episode_Reward/pen_ang_vel_xy: -0.1441
   Episode_Reward/pen_joint_torque: -0.2317
    Episode_Reward/pen_joint_accel: -0.1103
    Episode_Reward/pen_action_rate: -0.1147
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0536
   Episode_Reward/pen_joint_powers: -0.0849
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2467
Episode_Reward/pen_flat_orientation: -0.0850
  Episode_Reward/pen_feet_distance: -0.0280
Episode_Reward/pen_feet_regulation: -0.4496
   Episode_Reward/foot_landing_vel: -0.1191
   Episode_Reward/test_gait_reward: -0.8935
Metrics/base_velocity/error_vel_xy: 0.8368
Metrics/base_velocity/error_vel_yaw: 1.1835
      Episode_Termination/time_out: 3.2083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 193855488
                    Iteration time: 1.08s
                        Total time: 2152.47s
                               ETA: 1123.2s

################################################################################
                     [1m Learning iteration 1972/3000 [0m                     

                       Computation: 88902 steps/s (collection: 0.982s, learning 0.124s)
               Value function loss: 0.4975
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8464
                     Learning rate: 0.0009
                       Mean reward: 141.86
               Mean episode length: 990.37
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4361
      Episode_Reward/rew_ang_vel_z: 2.6593
    Episode_Reward/pen_base_height: -0.2935
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1496
   Episode_Reward/pen_joint_torque: -0.2442
    Episode_Reward/pen_joint_accel: -0.1000
    Episode_Reward/pen_action_rate: -0.1183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2517
Episode_Reward/pen_flat_orientation: -0.0894
  Episode_Reward/pen_feet_distance: -0.0353
Episode_Reward/pen_feet_regulation: -0.4851
   Episode_Reward/foot_landing_vel: -0.1195
   Episode_Reward/test_gait_reward: -0.9217
Metrics/base_velocity/error_vel_xy: 0.9221
Metrics/base_velocity/error_vel_yaw: 1.2124
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 193953792
                    Iteration time: 1.11s
                        Total time: 2153.57s
                               ETA: 1122.1s

################################################################################
                     [1m Learning iteration 1973/3000 [0m                     

                       Computation: 90904 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.4757
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8480
                     Learning rate: 0.0004
                       Mean reward: 142.44
               Mean episode length: 992.34
       Episode_Reward/keep_balance: 0.9907
     Episode_Reward/rew_lin_vel_xy: 6.3601
      Episode_Reward/rew_ang_vel_z: 2.6085
    Episode_Reward/pen_base_height: -0.2862
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1522
   Episode_Reward/pen_joint_torque: -0.2278
    Episode_Reward/pen_joint_accel: -0.0955
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0869
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2495
Episode_Reward/pen_flat_orientation: -0.0897
  Episode_Reward/pen_feet_distance: -0.0248
Episode_Reward/pen_feet_regulation: -0.4837
   Episode_Reward/foot_landing_vel: -0.1216
   Episode_Reward/test_gait_reward: -0.9084
Metrics/base_velocity/error_vel_xy: 0.9186
Metrics/base_velocity/error_vel_yaw: 1.2307
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 194052096
                    Iteration time: 1.08s
                        Total time: 2154.65s
                               ETA: 1121.0s

################################################################################
                     [1m Learning iteration 1974/3000 [0m                     

                       Computation: 90336 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.5133
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8499
                     Learning rate: 0.0006
                       Mean reward: 143.16
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4885
      Episode_Reward/rew_ang_vel_z: 2.6338
    Episode_Reward/pen_base_height: -0.2788
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1532
   Episode_Reward/pen_joint_torque: -0.2295
    Episode_Reward/pen_joint_accel: -0.0997
    Episode_Reward/pen_action_rate: -0.1179
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2528
Episode_Reward/pen_flat_orientation: -0.0845
  Episode_Reward/pen_feet_distance: -0.0307
Episode_Reward/pen_feet_regulation: -0.4765
   Episode_Reward/foot_landing_vel: -0.1158
   Episode_Reward/test_gait_reward: -0.9202
Metrics/base_velocity/error_vel_xy: 0.8854
Metrics/base_velocity/error_vel_yaw: 1.2388
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 194150400
                    Iteration time: 1.09s
                        Total time: 2155.74s
                               ETA: 1119.9s

################################################################################
                     [1m Learning iteration 1975/3000 [0m                     

                       Computation: 89933 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.5312
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8510
                     Learning rate: 0.0006
                       Mean reward: 141.72
               Mean episode length: 996.09
       Episode_Reward/keep_balance: 0.9968
     Episode_Reward/rew_lin_vel_xy: 6.3841
      Episode_Reward/rew_ang_vel_z: 2.6328
    Episode_Reward/pen_base_height: -0.2777
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1546
   Episode_Reward/pen_joint_torque: -0.2245
    Episode_Reward/pen_joint_accel: -0.1029
    Episode_Reward/pen_action_rate: -0.1169
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2515
Episode_Reward/pen_flat_orientation: -0.0844
  Episode_Reward/pen_feet_distance: -0.0331
Episode_Reward/pen_feet_regulation: -0.4914
   Episode_Reward/foot_landing_vel: -0.1179
   Episode_Reward/test_gait_reward: -0.9176
Metrics/base_velocity/error_vel_xy: 0.9235
Metrics/base_velocity/error_vel_yaw: 1.2253
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 194248704
                    Iteration time: 1.09s
                        Total time: 2156.83s
                               ETA: 1118.8s

################################################################################
                     [1m Learning iteration 1976/3000 [0m                     

                       Computation: 89262 steps/s (collection: 0.978s, learning 0.124s)
               Value function loss: 0.5041
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8515
                     Learning rate: 0.0004
                       Mean reward: 139.64
               Mean episode length: 991.35
       Episode_Reward/keep_balance: 0.9930
     Episode_Reward/rew_lin_vel_xy: 6.3808
      Episode_Reward/rew_ang_vel_z: 2.6090
    Episode_Reward/pen_base_height: -0.2887
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1549
   Episode_Reward/pen_joint_torque: -0.2343
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1172
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0882
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2514
Episode_Reward/pen_flat_orientation: -0.0875
  Episode_Reward/pen_feet_distance: -0.0299
Episode_Reward/pen_feet_regulation: -0.4854
   Episode_Reward/foot_landing_vel: -0.1277
   Episode_Reward/test_gait_reward: -0.9093
Metrics/base_velocity/error_vel_xy: 0.9121
Metrics/base_velocity/error_vel_yaw: 1.2308
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 194347008
                    Iteration time: 1.10s
                        Total time: 2157.94s
                               ETA: 1117.7s

################################################################################
                     [1m Learning iteration 1977/3000 [0m                     

                       Computation: 89684 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.4981
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8510
                     Learning rate: 0.0006
                       Mean reward: 138.18
               Mean episode length: 980.41
       Episode_Reward/keep_balance: 0.9609
     Episode_Reward/rew_lin_vel_xy: 6.1934
      Episode_Reward/rew_ang_vel_z: 2.5068
    Episode_Reward/pen_base_height: -0.2826
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1461
   Episode_Reward/pen_joint_torque: -0.2315
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1140
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2435
Episode_Reward/pen_flat_orientation: -0.0906
  Episode_Reward/pen_feet_distance: -0.0304
Episode_Reward/pen_feet_regulation: -0.4794
   Episode_Reward/foot_landing_vel: -0.1227
   Episode_Reward/test_gait_reward: -0.8956
Metrics/base_velocity/error_vel_xy: 0.8748
Metrics/base_velocity/error_vel_yaw: 1.2184
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 194445312
                    Iteration time: 1.10s
                        Total time: 2159.03s
                               ETA: 1116.6s

################################################################################
                     [1m Learning iteration 1978/3000 [0m                     

                       Computation: 89337 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 0.4962
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8495
                     Learning rate: 0.0002
                       Mean reward: 141.70
               Mean episode length: 998.80
       Episode_Reward/keep_balance: 0.9975
     Episode_Reward/rew_lin_vel_xy: 6.4312
      Episode_Reward/rew_ang_vel_z: 2.6146
    Episode_Reward/pen_base_height: -0.2841
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1542
   Episode_Reward/pen_joint_torque: -0.2292
    Episode_Reward/pen_joint_accel: -0.1135
    Episode_Reward/pen_action_rate: -0.1170
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2527
Episode_Reward/pen_flat_orientation: -0.0876
  Episode_Reward/pen_feet_distance: -0.0281
Episode_Reward/pen_feet_regulation: -0.4927
   Episode_Reward/foot_landing_vel: -0.1348
   Episode_Reward/test_gait_reward: -0.9103
Metrics/base_velocity/error_vel_xy: 0.9085
Metrics/base_velocity/error_vel_yaw: 1.2430
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 194543616
                    Iteration time: 1.10s
                        Total time: 2160.13s
                               ETA: 1115.5s

################################################################################
                     [1m Learning iteration 1979/3000 [0m                     

                       Computation: 90345 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.5184
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8493
                     Learning rate: 0.0002
                       Mean reward: 141.32
               Mean episode length: 995.41
       Episode_Reward/keep_balance: 0.9936
     Episode_Reward/rew_lin_vel_xy: 6.3739
      Episode_Reward/rew_ang_vel_z: 2.6114
    Episode_Reward/pen_base_height: -0.2881
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1579
   Episode_Reward/pen_joint_torque: -0.2323
    Episode_Reward/pen_joint_accel: -0.1084
    Episode_Reward/pen_action_rate: -0.1186
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0586
   Episode_Reward/pen_joint_powers: -0.0908
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2535
Episode_Reward/pen_flat_orientation: -0.0875
  Episode_Reward/pen_feet_distance: -0.0317
Episode_Reward/pen_feet_regulation: -0.5122
   Episode_Reward/foot_landing_vel: -0.1275
   Episode_Reward/test_gait_reward: -0.9203
Metrics/base_velocity/error_vel_xy: 0.9298
Metrics/base_velocity/error_vel_yaw: 1.2299
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 194641920
                    Iteration time: 1.09s
                        Total time: 2161.22s
                               ETA: 1114.4s

################################################################################
                     [1m Learning iteration 1980/3000 [0m                     

                       Computation: 88673 steps/s (collection: 0.980s, learning 0.129s)
               Value function loss: 0.5794
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8487
                     Learning rate: 0.0003
                       Mean reward: 143.48
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 0.9908
     Episode_Reward/rew_lin_vel_xy: 6.3914
      Episode_Reward/rew_ang_vel_z: 2.6298
    Episode_Reward/pen_base_height: -0.2915
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1474
   Episode_Reward/pen_joint_torque: -0.2416
    Episode_Reward/pen_joint_accel: -0.1048
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2467
Episode_Reward/pen_flat_orientation: -0.0882
  Episode_Reward/pen_feet_distance: -0.0322
Episode_Reward/pen_feet_regulation: -0.4782
   Episode_Reward/foot_landing_vel: -0.1264
   Episode_Reward/test_gait_reward: -0.9170
Metrics/base_velocity/error_vel_xy: 0.9058
Metrics/base_velocity/error_vel_yaw: 1.2066
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 194740224
                    Iteration time: 1.11s
                        Total time: 2162.33s
                               ETA: 1113.4s

################################################################################
                     [1m Learning iteration 1981/3000 [0m                     

                       Computation: 89687 steps/s (collection: 0.974s, learning 0.122s)
               Value function loss: 0.5152
                    Surrogate loss: -0.0058
             Mean action noise std: 0.8494
                     Learning rate: 0.0006
                       Mean reward: 136.13
               Mean episode length: 969.86
       Episode_Reward/keep_balance: 0.9667
     Episode_Reward/rew_lin_vel_xy: 6.2235
      Episode_Reward/rew_ang_vel_z: 2.4977
    Episode_Reward/pen_base_height: -0.2964
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1523
   Episode_Reward/pen_joint_torque: -0.2313
    Episode_Reward/pen_joint_accel: -0.0933
    Episode_Reward/pen_action_rate: -0.1163
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2488
Episode_Reward/pen_flat_orientation: -0.0927
  Episode_Reward/pen_feet_distance: -0.0326
Episode_Reward/pen_feet_regulation: -0.4987
   Episode_Reward/foot_landing_vel: -0.1268
   Episode_Reward/test_gait_reward: -0.8995
Metrics/base_velocity/error_vel_xy: 0.8890
Metrics/base_velocity/error_vel_yaw: 1.2432
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 194838528
                    Iteration time: 1.10s
                        Total time: 2163.42s
                               ETA: 1112.3s

################################################################################
                     [1m Learning iteration 1982/3000 [0m                     

                       Computation: 90450 steps/s (collection: 0.959s, learning 0.128s)
               Value function loss: 0.5266
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8505
                     Learning rate: 0.0004
                       Mean reward: 136.86
               Mean episode length: 974.53
       Episode_Reward/keep_balance: 0.9772
     Episode_Reward/rew_lin_vel_xy: 6.2386
      Episode_Reward/rew_ang_vel_z: 2.5527
    Episode_Reward/pen_base_height: -0.3026
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1449
   Episode_Reward/pen_joint_torque: -0.2389
    Episode_Reward/pen_joint_accel: -0.0997
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0556
   Episode_Reward/pen_joint_powers: -0.0891
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2470
Episode_Reward/pen_flat_orientation: -0.0908
  Episode_Reward/pen_feet_distance: -0.0285
Episode_Reward/pen_feet_regulation: -0.4833
   Episode_Reward/foot_landing_vel: -0.1179
   Episode_Reward/test_gait_reward: -0.9175
Metrics/base_velocity/error_vel_xy: 0.9196
Metrics/base_velocity/error_vel_yaw: 1.2253
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 194936832
                    Iteration time: 1.09s
                        Total time: 2164.51s
                               ETA: 1111.2s

################################################################################
                     [1m Learning iteration 1983/3000 [0m                     

                       Computation: 89529 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.5395
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8516
                     Learning rate: 0.0006
                       Mean reward: 141.66
               Mean episode length: 990.58
       Episode_Reward/keep_balance: 0.9881
     Episode_Reward/rew_lin_vel_xy: 6.4013
      Episode_Reward/rew_ang_vel_z: 2.6395
    Episode_Reward/pen_base_height: -0.2940
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1499
   Episode_Reward/pen_joint_torque: -0.2411
    Episode_Reward/pen_joint_accel: -0.1027
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0535
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2465
Episode_Reward/pen_flat_orientation: -0.0892
  Episode_Reward/pen_feet_distance: -0.0281
Episode_Reward/pen_feet_regulation: -0.4629
   Episode_Reward/foot_landing_vel: -0.1189
   Episode_Reward/test_gait_reward: -0.9091
Metrics/base_velocity/error_vel_xy: 0.8788
Metrics/base_velocity/error_vel_yaw: 1.1895
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 195035136
                    Iteration time: 1.10s
                        Total time: 2165.61s
                               ETA: 1110.1s

################################################################################
                     [1m Learning iteration 1984/3000 [0m                     

                       Computation: 88804 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 0.4905
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8523
                     Learning rate: 0.0004
                       Mean reward: 143.48
               Mean episode length: 993.84
       Episode_Reward/keep_balance: 0.9976
     Episode_Reward/rew_lin_vel_xy: 6.4622
      Episode_Reward/rew_ang_vel_z: 2.6589
    Episode_Reward/pen_base_height: -0.2918
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1536
   Episode_Reward/pen_joint_torque: -0.2335
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1161
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0879
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2488
Episode_Reward/pen_flat_orientation: -0.0886
  Episode_Reward/pen_feet_distance: -0.0300
Episode_Reward/pen_feet_regulation: -0.4744
   Episode_Reward/foot_landing_vel: -0.1224
   Episode_Reward/test_gait_reward: -0.9215
Metrics/base_velocity/error_vel_xy: 0.8959
Metrics/base_velocity/error_vel_yaw: 1.2115
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 195133440
                    Iteration time: 1.11s
                        Total time: 2166.72s
                               ETA: 1109.0s

################################################################################
                     [1m Learning iteration 1985/3000 [0m                     

                       Computation: 89374 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 0.5480
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8529
                     Learning rate: 0.0006
                       Mean reward: 145.72
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4902
      Episode_Reward/rew_ang_vel_z: 2.7113
    Episode_Reward/pen_base_height: -0.2892
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1435
   Episode_Reward/pen_joint_torque: -0.2317
    Episode_Reward/pen_joint_accel: -0.0998
    Episode_Reward/pen_action_rate: -0.1142
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0533
   Episode_Reward/pen_joint_powers: -0.0844
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2428
Episode_Reward/pen_flat_orientation: -0.0808
  Episode_Reward/pen_feet_distance: -0.0302
Episode_Reward/pen_feet_regulation: -0.4583
   Episode_Reward/foot_landing_vel: -0.1235
   Episode_Reward/test_gait_reward: -0.9152
Metrics/base_velocity/error_vel_xy: 0.8928
Metrics/base_velocity/error_vel_yaw: 1.1587
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 195231744
                    Iteration time: 1.10s
                        Total time: 2167.82s
                               ETA: 1107.9s

################################################################################
                     [1m Learning iteration 1986/3000 [0m                     

                       Computation: 89176 steps/s (collection: 0.978s, learning 0.125s)
               Value function loss: 0.5345
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8531
                     Learning rate: 0.0009
                       Mean reward: 140.63
               Mean episode length: 982.49
       Episode_Reward/keep_balance: 0.9826
     Episode_Reward/rew_lin_vel_xy: 6.3570
      Episode_Reward/rew_ang_vel_z: 2.6116
    Episode_Reward/pen_base_height: -0.2924
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1486
   Episode_Reward/pen_joint_torque: -0.2250
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.1136
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0540
   Episode_Reward/pen_joint_powers: -0.0847
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2414
Episode_Reward/pen_flat_orientation: -0.0929
  Episode_Reward/pen_feet_distance: -0.0235
Episode_Reward/pen_feet_regulation: -0.4636
   Episode_Reward/foot_landing_vel: -0.1204
   Episode_Reward/test_gait_reward: -0.8996
Metrics/base_velocity/error_vel_xy: 0.8814
Metrics/base_velocity/error_vel_yaw: 1.2145
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 195330048
                    Iteration time: 1.10s
                        Total time: 2168.92s
                               ETA: 1106.8s

################################################################################
                     [1m Learning iteration 1987/3000 [0m                     

                       Computation: 88828 steps/s (collection: 0.983s, learning 0.123s)
               Value function loss: 0.6575
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8527
                     Learning rate: 0.0004
                       Mean reward: 137.22
               Mean episode length: 983.36
       Episode_Reward/keep_balance: 0.9773
     Episode_Reward/rew_lin_vel_xy: 6.2201
      Episode_Reward/rew_ang_vel_z: 2.5715
    Episode_Reward/pen_base_height: -0.3068
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1504
   Episode_Reward/pen_joint_torque: -0.2431
    Episode_Reward/pen_joint_accel: -0.1039
    Episode_Reward/pen_action_rate: -0.1162
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0909
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2440
Episode_Reward/pen_flat_orientation: -0.0971
  Episode_Reward/pen_feet_distance: -0.0275
Episode_Reward/pen_feet_regulation: -0.5120
   Episode_Reward/foot_landing_vel: -0.1266
   Episode_Reward/test_gait_reward: -0.9156
Metrics/base_velocity/error_vel_xy: 0.9405
Metrics/base_velocity/error_vel_yaw: 1.2221
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 195428352
                    Iteration time: 1.11s
                        Total time: 2170.03s
                               ETA: 1105.8s

################################################################################
                     [1m Learning iteration 1988/3000 [0m                     

                       Computation: 88829 steps/s (collection: 0.980s, learning 0.126s)
               Value function loss: 0.5402
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8527
                     Learning rate: 0.0006
                       Mean reward: 139.27
               Mean episode length: 984.87
       Episode_Reward/keep_balance: 0.9913
     Episode_Reward/rew_lin_vel_xy: 6.4022
      Episode_Reward/rew_ang_vel_z: 2.6276
    Episode_Reward/pen_base_height: -0.2898
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1529
   Episode_Reward/pen_joint_torque: -0.2407
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1170
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2492
Episode_Reward/pen_flat_orientation: -0.0869
  Episode_Reward/pen_feet_distance: -0.0264
Episode_Reward/pen_feet_regulation: -0.4716
   Episode_Reward/foot_landing_vel: -0.1249
   Episode_Reward/test_gait_reward: -0.9133
Metrics/base_velocity/error_vel_xy: 0.9012
Metrics/base_velocity/error_vel_yaw: 1.2165
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 195526656
                    Iteration time: 1.11s
                        Total time: 2171.13s
                               ETA: 1104.7s

################################################################################
                     [1m Learning iteration 1989/3000 [0m                     

                       Computation: 89219 steps/s (collection: 0.979s, learning 0.123s)
               Value function loss: 0.4343
                    Surrogate loss: -0.0014
             Mean action noise std: 0.8528
                     Learning rate: 0.0001
                       Mean reward: 137.39
               Mean episode length: 962.77
       Episode_Reward/keep_balance: 0.9634
     Episode_Reward/rew_lin_vel_xy: 6.2356
      Episode_Reward/rew_ang_vel_z: 2.5592
    Episode_Reward/pen_base_height: -0.2818
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1482
   Episode_Reward/pen_joint_torque: -0.2278
    Episode_Reward/pen_joint_accel: -0.1011
    Episode_Reward/pen_action_rate: -0.1127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0859
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2410
Episode_Reward/pen_flat_orientation: -0.0925
  Episode_Reward/pen_feet_distance: -0.0253
Episode_Reward/pen_feet_regulation: -0.4642
   Episode_Reward/foot_landing_vel: -0.1273
   Episode_Reward/test_gait_reward: -0.8835
Metrics/base_velocity/error_vel_xy: 0.8829
Metrics/base_velocity/error_vel_yaw: 1.1807
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 195624960
                    Iteration time: 1.10s
                        Total time: 2172.23s
                               ETA: 1103.6s

################################################################################
                     [1m Learning iteration 1990/3000 [0m                     

                       Computation: 89416 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.4782
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8524
                     Learning rate: 0.0003
                       Mean reward: 144.07
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 0.9980
     Episode_Reward/rew_lin_vel_xy: 6.4556
      Episode_Reward/rew_ang_vel_z: 2.6714
    Episode_Reward/pen_base_height: -0.3135
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1455
   Episode_Reward/pen_joint_torque: -0.2499
    Episode_Reward/pen_joint_accel: -0.0974
    Episode_Reward/pen_action_rate: -0.1159
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2440
Episode_Reward/pen_flat_orientation: -0.0898
  Episode_Reward/pen_feet_distance: -0.0269
Episode_Reward/pen_feet_regulation: -0.4808
   Episode_Reward/foot_landing_vel: -0.1212
   Episode_Reward/test_gait_reward: -0.9158
Metrics/base_velocity/error_vel_xy: 0.9041
Metrics/base_velocity/error_vel_yaw: 1.1956
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 195723264
                    Iteration time: 1.10s
                        Total time: 2173.33s
                               ETA: 1102.5s

################################################################################
                     [1m Learning iteration 1991/3000 [0m                     

                       Computation: 88796 steps/s (collection: 0.982s, learning 0.125s)
               Value function loss: 0.5343
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8528
                     Learning rate: 0.0004
                       Mean reward: 143.49
               Mean episode length: 991.56
       Episode_Reward/keep_balance: 0.9854
     Episode_Reward/rew_lin_vel_xy: 6.3992
      Episode_Reward/rew_ang_vel_z: 2.6366
    Episode_Reward/pen_base_height: -0.2879
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1394
   Episode_Reward/pen_joint_torque: -0.2352
    Episode_Reward/pen_joint_accel: -0.0934
    Episode_Reward/pen_action_rate: -0.1130
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0528
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2409
Episode_Reward/pen_flat_orientation: -0.0855
  Episode_Reward/pen_feet_distance: -0.0255
Episode_Reward/pen_feet_regulation: -0.4422
   Episode_Reward/foot_landing_vel: -0.1192
   Episode_Reward/test_gait_reward: -0.9043
Metrics/base_velocity/error_vel_xy: 0.8627
Metrics/base_velocity/error_vel_yaw: 1.1801
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 195821568
                    Iteration time: 1.11s
                        Total time: 2174.44s
                               ETA: 1101.4s

################################################################################
                     [1m Learning iteration 1992/3000 [0m                     

                       Computation: 88364 steps/s (collection: 0.989s, learning 0.124s)
               Value function loss: 0.5617
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8516
                     Learning rate: 0.0009
                       Mean reward: 140.95
               Mean episode length: 982.13
       Episode_Reward/keep_balance: 0.9811
     Episode_Reward/rew_lin_vel_xy: 6.4377
      Episode_Reward/rew_ang_vel_z: 2.6204
    Episode_Reward/pen_base_height: -0.2876
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1417
   Episode_Reward/pen_joint_torque: -0.2443
    Episode_Reward/pen_joint_accel: -0.0971
    Episode_Reward/pen_action_rate: -0.1131
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0531
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2398
Episode_Reward/pen_flat_orientation: -0.0866
  Episode_Reward/pen_feet_distance: -0.0254
Episode_Reward/pen_feet_regulation: -0.4506
   Episode_Reward/foot_landing_vel: -0.1164
   Episode_Reward/test_gait_reward: -0.9021
Metrics/base_velocity/error_vel_xy: 0.8517
Metrics/base_velocity/error_vel_yaw: 1.1861
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 195919872
                    Iteration time: 1.11s
                        Total time: 2175.55s
                               ETA: 1100.3s

################################################################################
                     [1m Learning iteration 1993/3000 [0m                     

                       Computation: 89148 steps/s (collection: 0.974s, learning 0.128s)
               Value function loss: 0.5850
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8504
                     Learning rate: 0.0013
                       Mean reward: 141.35
               Mean episode length: 989.86
       Episode_Reward/keep_balance: 0.9882
     Episode_Reward/rew_lin_vel_xy: 6.4051
      Episode_Reward/rew_ang_vel_z: 2.6524
    Episode_Reward/pen_base_height: -0.2809
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1474
   Episode_Reward/pen_joint_torque: -0.2263
    Episode_Reward/pen_joint_accel: -0.1125
    Episode_Reward/pen_action_rate: -0.1136
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0849
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2449
Episode_Reward/pen_flat_orientation: -0.0829
  Episode_Reward/pen_feet_distance: -0.0291
Episode_Reward/pen_feet_regulation: -0.4696
   Episode_Reward/foot_landing_vel: -0.1282
   Episode_Reward/test_gait_reward: -0.9079
Metrics/base_velocity/error_vel_xy: 0.8821
Metrics/base_velocity/error_vel_yaw: 1.1771
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 196018176
                    Iteration time: 1.10s
                        Total time: 2176.66s
                               ETA: 1099.2s

################################################################################
                     [1m Learning iteration 1994/3000 [0m                     

                       Computation: 87403 steps/s (collection: 1.002s, learning 0.123s)
               Value function loss: 0.4687
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8494
                     Learning rate: 0.0009
                       Mean reward: 137.28
               Mean episode length: 976.23
       Episode_Reward/keep_balance: 0.9822
     Episode_Reward/rew_lin_vel_xy: 6.3104
      Episode_Reward/rew_ang_vel_z: 2.5977
    Episode_Reward/pen_base_height: -0.3041
      Episode_Reward/pen_lin_vel_z: -0.0396
     Episode_Reward/pen_ang_vel_xy: -0.1518
   Episode_Reward/pen_joint_torque: -0.2358
    Episode_Reward/pen_joint_accel: -0.1155
    Episode_Reward/pen_action_rate: -0.1164
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2474
Episode_Reward/pen_flat_orientation: -0.0966
  Episode_Reward/pen_feet_distance: -0.0264
Episode_Reward/pen_feet_regulation: -0.4824
   Episode_Reward/foot_landing_vel: -0.1246
   Episode_Reward/test_gait_reward: -0.9053
Metrics/base_velocity/error_vel_xy: 0.9170
Metrics/base_velocity/error_vel_yaw: 1.2128
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 196116480
                    Iteration time: 1.12s
                        Total time: 2177.78s
                               ETA: 1098.2s

################################################################################
                     [1m Learning iteration 1995/3000 [0m                     

                       Computation: 90380 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.4818
                    Surrogate loss: 0.0043
             Mean action noise std: 0.8498
                     Learning rate: 0.0000
                       Mean reward: 136.39
               Mean episode length: 970.12
       Episode_Reward/keep_balance: 0.9659
     Episode_Reward/rew_lin_vel_xy: 6.2766
      Episode_Reward/rew_ang_vel_z: 2.5418
    Episode_Reward/pen_base_height: -0.2861
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1425
   Episode_Reward/pen_joint_torque: -0.2374
    Episode_Reward/pen_joint_accel: -0.1057
    Episode_Reward/pen_action_rate: -0.1139
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2432
Episode_Reward/pen_flat_orientation: -0.0920
  Episode_Reward/pen_feet_distance: -0.0285
Episode_Reward/pen_feet_regulation: -0.4625
   Episode_Reward/foot_landing_vel: -0.1261
   Episode_Reward/test_gait_reward: -0.8954
Metrics/base_velocity/error_vel_xy: 0.8653
Metrics/base_velocity/error_vel_yaw: 1.2035
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 196214784
                    Iteration time: 1.09s
                        Total time: 2178.87s
                               ETA: 1097.1s

################################################################################
                     [1m Learning iteration 1996/3000 [0m                     

                       Computation: 88571 steps/s (collection: 0.986s, learning 0.123s)
               Value function loss: 0.4927
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8497
                     Learning rate: 0.0001
                       Mean reward: 139.38
               Mean episode length: 981.94
       Episode_Reward/keep_balance: 0.9886
     Episode_Reward/rew_lin_vel_xy: 6.3495
      Episode_Reward/rew_ang_vel_z: 2.6295
    Episode_Reward/pen_base_height: -0.2996
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1514
   Episode_Reward/pen_joint_torque: -0.2396
    Episode_Reward/pen_joint_accel: -0.1028
    Episode_Reward/pen_action_rate: -0.1141
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2461
Episode_Reward/pen_flat_orientation: -0.0872
  Episode_Reward/pen_feet_distance: -0.0278
Episode_Reward/pen_feet_regulation: -0.4675
   Episode_Reward/foot_landing_vel: -0.1263
   Episode_Reward/test_gait_reward: -0.9169
Metrics/base_velocity/error_vel_xy: 0.9028
Metrics/base_velocity/error_vel_yaw: 1.1991
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 196313088
                    Iteration time: 1.11s
                        Total time: 2179.98s
                               ETA: 1096.0s

################################################################################
                     [1m Learning iteration 1997/3000 [0m                     

                       Computation: 89077 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.6003
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8503
                     Learning rate: 0.0004
                       Mean reward: 141.91
               Mean episode length: 994.01
       Episode_Reward/keep_balance: 0.9955
     Episode_Reward/rew_lin_vel_xy: 6.4555
      Episode_Reward/rew_ang_vel_z: 2.6523
    Episode_Reward/pen_base_height: -0.2824
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1460
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.1130
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0529
   Episode_Reward/pen_joint_powers: -0.0834
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2444
Episode_Reward/pen_flat_orientation: -0.0867
  Episode_Reward/pen_feet_distance: -0.0254
Episode_Reward/pen_feet_regulation: -0.4623
   Episode_Reward/foot_landing_vel: -0.1213
   Episode_Reward/test_gait_reward: -0.9080
Metrics/base_velocity/error_vel_xy: 0.8893
Metrics/base_velocity/error_vel_yaw: 1.2053
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 196411392
                    Iteration time: 1.10s
                        Total time: 2181.08s
                               ETA: 1094.9s

################################################################################
                     [1m Learning iteration 1998/3000 [0m                     

                       Computation: 90610 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.5328
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8512
                     Learning rate: 0.0003
                       Mean reward: 135.21
               Mean episode length: 954.88
       Episode_Reward/keep_balance: 0.9496
     Episode_Reward/rew_lin_vel_xy: 6.1362
      Episode_Reward/rew_ang_vel_z: 2.5192
    Episode_Reward/pen_base_height: -0.2786
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1444
   Episode_Reward/pen_joint_torque: -0.2257
    Episode_Reward/pen_joint_accel: -0.1014
    Episode_Reward/pen_action_rate: -0.1111
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0538
   Episode_Reward/pen_joint_powers: -0.0852
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2385
Episode_Reward/pen_flat_orientation: -0.0913
  Episode_Reward/pen_feet_distance: -0.0268
Episode_Reward/pen_feet_regulation: -0.4515
   Episode_Reward/foot_landing_vel: -0.1230
   Episode_Reward/test_gait_reward: -0.8732
Metrics/base_velocity/error_vel_xy: 0.8687
Metrics/base_velocity/error_vel_yaw: 1.1558
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 196509696
                    Iteration time: 1.08s
                        Total time: 2182.17s
                               ETA: 1093.8s

################################################################################
                     [1m Learning iteration 1999/3000 [0m                     

                       Computation: 90197 steps/s (collection: 0.968s, learning 0.122s)
               Value function loss: 0.4967
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8499
                     Learning rate: 0.0006
                       Mean reward: 140.95
               Mean episode length: 994.16
       Episode_Reward/keep_balance: 0.9920
     Episode_Reward/rew_lin_vel_xy: 6.4342
      Episode_Reward/rew_ang_vel_z: 2.5990
    Episode_Reward/pen_base_height: -0.3032
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1418
   Episode_Reward/pen_joint_torque: -0.2418
    Episode_Reward/pen_joint_accel: -0.1047
    Episode_Reward/pen_action_rate: -0.1174
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0896
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2482
Episode_Reward/pen_flat_orientation: -0.0910
  Episode_Reward/pen_feet_distance: -0.0266
Episode_Reward/pen_feet_regulation: -0.4978
   Episode_Reward/foot_landing_vel: -0.1267
   Episode_Reward/test_gait_reward: -0.9162
Metrics/base_velocity/error_vel_xy: 0.8955
Metrics/base_velocity/error_vel_yaw: 1.2340
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 196608000
                    Iteration time: 1.09s
                        Total time: 2183.26s
                               ETA: 1092.7s

################################################################################
                     [1m Learning iteration 2000/3000 [0m                     

                       Computation: 90382 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.4457
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8497
                     Learning rate: 0.0006
                       Mean reward: 140.32
               Mean episode length: 983.98
       Episode_Reward/keep_balance: 0.9738
     Episode_Reward/rew_lin_vel_xy: 6.3400
      Episode_Reward/rew_ang_vel_z: 2.5848
    Episode_Reward/pen_base_height: -0.2977
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1492
   Episode_Reward/pen_joint_torque: -0.2311
    Episode_Reward/pen_joint_accel: -0.0962
    Episode_Reward/pen_action_rate: -0.1135
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2419
Episode_Reward/pen_flat_orientation: -0.0884
  Episode_Reward/pen_feet_distance: -0.0285
Episode_Reward/pen_feet_regulation: -0.4866
   Episode_Reward/foot_landing_vel: -0.1196
   Episode_Reward/test_gait_reward: -0.9018
Metrics/base_velocity/error_vel_xy: 0.8641
Metrics/base_velocity/error_vel_yaw: 1.1860
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 196706304
                    Iteration time: 1.09s
                        Total time: 2184.34s
                               ETA: 1091.6s

################################################################################
                     [1m Learning iteration 2001/3000 [0m                     

                       Computation: 90665 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 0.5379
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8499
                     Learning rate: 0.0004
                       Mean reward: 140.17
               Mean episode length: 987.42
       Episode_Reward/keep_balance: 0.9905
     Episode_Reward/rew_lin_vel_xy: 6.3710
      Episode_Reward/rew_ang_vel_z: 2.5998
    Episode_Reward/pen_base_height: -0.2825
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1499
   Episode_Reward/pen_joint_torque: -0.2300
    Episode_Reward/pen_joint_accel: -0.1035
    Episode_Reward/pen_action_rate: -0.1150
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2468
Episode_Reward/pen_flat_orientation: -0.0883
  Episode_Reward/pen_feet_distance: -0.0262
Episode_Reward/pen_feet_regulation: -0.4790
   Episode_Reward/foot_landing_vel: -0.1233
   Episode_Reward/test_gait_reward: -0.9118
Metrics/base_velocity/error_vel_xy: 0.9151
Metrics/base_velocity/error_vel_yaw: 1.2423
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 196804608
                    Iteration time: 1.08s
                        Total time: 2185.43s
                               ETA: 1090.5s

################################################################################
                     [1m Learning iteration 2002/3000 [0m                     

                       Computation: 90875 steps/s (collection: 0.961s, learning 0.121s)
               Value function loss: 0.5417
                    Surrogate loss: -0.0057
             Mean action noise std: 0.8486
                     Learning rate: 0.0009
                       Mean reward: 137.80
               Mean episode length: 970.52
       Episode_Reward/keep_balance: 0.9711
     Episode_Reward/rew_lin_vel_xy: 6.2648
      Episode_Reward/rew_ang_vel_z: 2.5507
    Episode_Reward/pen_base_height: -0.2807
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1452
   Episode_Reward/pen_joint_torque: -0.2300
    Episode_Reward/pen_joint_accel: -0.1024
    Episode_Reward/pen_action_rate: -0.1137
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2446
Episode_Reward/pen_flat_orientation: -0.0847
  Episode_Reward/pen_feet_distance: -0.0267
Episode_Reward/pen_feet_regulation: -0.4670
   Episode_Reward/foot_landing_vel: -0.1193
   Episode_Reward/test_gait_reward: -0.8935
Metrics/base_velocity/error_vel_xy: 0.8868
Metrics/base_velocity/error_vel_yaw: 1.2174
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 196902912
                    Iteration time: 1.08s
                        Total time: 2186.51s
                               ETA: 1089.4s

################################################################################
                     [1m Learning iteration 2003/3000 [0m                     

                       Computation: 90892 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.5417
                    Surrogate loss: -0.0004
             Mean action noise std: 0.8486
                     Learning rate: 0.0003
                       Mean reward: 136.75
               Mean episode length: 974.11
       Episode_Reward/keep_balance: 0.9809
     Episode_Reward/rew_lin_vel_xy: 6.3473
      Episode_Reward/rew_ang_vel_z: 2.5688
    Episode_Reward/pen_base_height: -0.2889
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1529
   Episode_Reward/pen_joint_torque: -0.2261
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1144
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2475
Episode_Reward/pen_flat_orientation: -0.0912
  Episode_Reward/pen_feet_distance: -0.0261
Episode_Reward/pen_feet_regulation: -0.4718
   Episode_Reward/foot_landing_vel: -0.1307
   Episode_Reward/test_gait_reward: -0.9050
Metrics/base_velocity/error_vel_xy: 0.8811
Metrics/base_velocity/error_vel_yaw: 1.2303
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 197001216
                    Iteration time: 1.08s
                        Total time: 2187.59s
                               ETA: 1088.3s

################################################################################
                     [1m Learning iteration 2004/3000 [0m                     

                       Computation: 90202 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.5261
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8480
                     Learning rate: 0.0004
                       Mean reward: 141.40
               Mean episode length: 995.80
       Episode_Reward/keep_balance: 0.9942
     Episode_Reward/rew_lin_vel_xy: 6.4427
      Episode_Reward/rew_ang_vel_z: 2.6372
    Episode_Reward/pen_base_height: -0.3069
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1472
   Episode_Reward/pen_joint_torque: -0.2391
    Episode_Reward/pen_joint_accel: -0.0962
    Episode_Reward/pen_action_rate: -0.1156
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0891
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2464
Episode_Reward/pen_flat_orientation: -0.0890
  Episode_Reward/pen_feet_distance: -0.0238
Episode_Reward/pen_feet_regulation: -0.4763
   Episode_Reward/foot_landing_vel: -0.1308
   Episode_Reward/test_gait_reward: -0.9130
Metrics/base_velocity/error_vel_xy: 0.9000
Metrics/base_velocity/error_vel_yaw: 1.2182
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 197099520
                    Iteration time: 1.09s
                        Total time: 2188.68s
                               ETA: 1087.2s

################################################################################
                     [1m Learning iteration 2005/3000 [0m                     

                       Computation: 91552 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.5159
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8457
                     Learning rate: 0.0006
                       Mean reward: 139.18
               Mean episode length: 987.53
       Episode_Reward/keep_balance: 0.9937
     Episode_Reward/rew_lin_vel_xy: 6.3772
      Episode_Reward/rew_ang_vel_z: 2.5990
    Episode_Reward/pen_base_height: -0.3048
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1531
   Episode_Reward/pen_joint_torque: -0.2448
    Episode_Reward/pen_joint_accel: -0.1080
    Episode_Reward/pen_action_rate: -0.1178
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2524
Episode_Reward/pen_flat_orientation: -0.0919
  Episode_Reward/pen_feet_distance: -0.0263
Episode_Reward/pen_feet_regulation: -0.5090
   Episode_Reward/foot_landing_vel: -0.1273
   Episode_Reward/test_gait_reward: -0.9112
Metrics/base_velocity/error_vel_xy: 0.9311
Metrics/base_velocity/error_vel_yaw: 1.2455
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 197197824
                    Iteration time: 1.07s
                        Total time: 2189.75s
                               ETA: 1086.1s

################################################################################
                     [1m Learning iteration 2006/3000 [0m                     

                       Computation: 90310 steps/s (collection: 0.965s, learning 0.124s)
               Value function loss: 0.5418
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8453
                     Learning rate: 0.0009
                       Mean reward: 137.43
               Mean episode length: 970.79
       Episode_Reward/keep_balance: 0.9743
     Episode_Reward/rew_lin_vel_xy: 6.2426
      Episode_Reward/rew_ang_vel_z: 2.5286
    Episode_Reward/pen_base_height: -0.3031
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1492
   Episode_Reward/pen_joint_torque: -0.2299
    Episode_Reward/pen_joint_accel: -0.1041
    Episode_Reward/pen_action_rate: -0.1148
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0555
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2467
Episode_Reward/pen_flat_orientation: -0.0940
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4853
   Episode_Reward/foot_landing_vel: -0.1299
   Episode_Reward/test_gait_reward: -0.8963
Metrics/base_velocity/error_vel_xy: 0.9192
Metrics/base_velocity/error_vel_yaw: 1.2440
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 197296128
                    Iteration time: 1.09s
                        Total time: 2190.84s
                               ETA: 1085.1s

################################################################################
                     [1m Learning iteration 2007/3000 [0m                     

                       Computation: 90525 steps/s (collection: 0.964s, learning 0.122s)
               Value function loss: 0.5534
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8443
                     Learning rate: 0.0004
                       Mean reward: 139.89
               Mean episode length: 987.58
       Episode_Reward/keep_balance: 0.9669
     Episode_Reward/rew_lin_vel_xy: 6.1835
      Episode_Reward/rew_ang_vel_z: 2.5443
    Episode_Reward/pen_base_height: -0.2965
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1437
   Episode_Reward/pen_joint_torque: -0.2328
    Episode_Reward/pen_joint_accel: -0.1072
    Episode_Reward/pen_action_rate: -0.1132
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2426
Episode_Reward/pen_flat_orientation: -0.0937
  Episode_Reward/pen_feet_distance: -0.0265
Episode_Reward/pen_feet_regulation: -0.4561
   Episode_Reward/foot_landing_vel: -0.1303
   Episode_Reward/test_gait_reward: -0.8919
Metrics/base_velocity/error_vel_xy: 0.8967
Metrics/base_velocity/error_vel_yaw: 1.2014
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 197394432
                    Iteration time: 1.09s
                        Total time: 2191.93s
                               ETA: 1084.0s

################################################################################
                     [1m Learning iteration 2008/3000 [0m                     

                       Computation: 90439 steps/s (collection: 0.966s, learning 0.121s)
               Value function loss: 0.5483
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8439
                     Learning rate: 0.0004
                       Mean reward: 138.99
               Mean episode length: 980.23
       Episode_Reward/keep_balance: 0.9838
     Episode_Reward/rew_lin_vel_xy: 6.3728
      Episode_Reward/rew_ang_vel_z: 2.5988
    Episode_Reward/pen_base_height: -0.2924
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1542
   Episode_Reward/pen_joint_torque: -0.2341
    Episode_Reward/pen_joint_accel: -0.1048
    Episode_Reward/pen_action_rate: -0.1157
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2492
Episode_Reward/pen_flat_orientation: -0.0923
  Episode_Reward/pen_feet_distance: -0.0279
Episode_Reward/pen_feet_regulation: -0.4818
   Episode_Reward/foot_landing_vel: -0.1367
   Episode_Reward/test_gait_reward: -0.9037
Metrics/base_velocity/error_vel_xy: 0.8894
Metrics/base_velocity/error_vel_yaw: 1.2127
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 197492736
                    Iteration time: 1.09s
                        Total time: 2193.02s
                               ETA: 1082.9s

################################################################################
                     [1m Learning iteration 2009/3000 [0m                     

                       Computation: 90927 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.5259
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8433
                     Learning rate: 0.0006
                       Mean reward: 140.98
               Mean episode length: 983.46
       Episode_Reward/keep_balance: 0.9868
     Episode_Reward/rew_lin_vel_xy: 6.3965
      Episode_Reward/rew_ang_vel_z: 2.5966
    Episode_Reward/pen_base_height: -0.2998
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1443
   Episode_Reward/pen_joint_torque: -0.2338
    Episode_Reward/pen_joint_accel: -0.0997
    Episode_Reward/pen_action_rate: -0.1148
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2459
Episode_Reward/pen_flat_orientation: -0.0864
  Episode_Reward/pen_feet_distance: -0.0292
Episode_Reward/pen_feet_regulation: -0.4851
   Episode_Reward/foot_landing_vel: -0.1263
   Episode_Reward/test_gait_reward: -0.9073
Metrics/base_velocity/error_vel_xy: 0.8909
Metrics/base_velocity/error_vel_yaw: 1.2255
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 197591040
                    Iteration time: 1.08s
                        Total time: 2194.10s
                               ETA: 1081.8s

################################################################################
                     [1m Learning iteration 2010/3000 [0m                     

                       Computation: 89315 steps/s (collection: 0.975s, learning 0.126s)
               Value function loss: 0.4926
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8443
                     Learning rate: 0.0006
                       Mean reward: 137.50
               Mean episode length: 987.92
       Episode_Reward/keep_balance: 0.9933
     Episode_Reward/rew_lin_vel_xy: 6.3692
      Episode_Reward/rew_ang_vel_z: 2.5884
    Episode_Reward/pen_base_height: -0.3070
      Episode_Reward/pen_lin_vel_z: -0.0389
     Episode_Reward/pen_ang_vel_xy: -0.1504
   Episode_Reward/pen_joint_torque: -0.2448
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0914
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2509
Episode_Reward/pen_flat_orientation: -0.0926
  Episode_Reward/pen_feet_distance: -0.0278
Episode_Reward/pen_feet_regulation: -0.5101
   Episode_Reward/foot_landing_vel: -0.1316
   Episode_Reward/test_gait_reward: -0.9223
Metrics/base_velocity/error_vel_xy: 0.9294
Metrics/base_velocity/error_vel_yaw: 1.2632
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 197689344
                    Iteration time: 1.10s
                        Total time: 2195.20s
                               ETA: 1080.7s

################################################################################
                     [1m Learning iteration 2011/3000 [0m                     

                       Computation: 89566 steps/s (collection: 0.976s, learning 0.122s)
               Value function loss: 0.5196
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8436
                     Learning rate: 0.0004
                       Mean reward: 139.98
               Mean episode length: 995.82
       Episode_Reward/keep_balance: 0.9985
     Episode_Reward/rew_lin_vel_xy: 6.4546
      Episode_Reward/rew_ang_vel_z: 2.6467
    Episode_Reward/pen_base_height: -0.2928
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1444
   Episode_Reward/pen_joint_torque: -0.2289
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.1148
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2474
Episode_Reward/pen_flat_orientation: -0.0864
  Episode_Reward/pen_feet_distance: -0.0229
Episode_Reward/pen_feet_regulation: -0.4851
   Episode_Reward/foot_landing_vel: -0.1227
   Episode_Reward/test_gait_reward: -0.9100
Metrics/base_velocity/error_vel_xy: 0.9123
Metrics/base_velocity/error_vel_yaw: 1.2149
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 197787648
                    Iteration time: 1.10s
                        Total time: 2196.30s
                               ETA: 1079.6s

################################################################################
                     [1m Learning iteration 2012/3000 [0m                     

                       Computation: 89523 steps/s (collection: 0.975s, learning 0.123s)
               Value function loss: 0.6389
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8432
                     Learning rate: 0.0004
                       Mean reward: 140.50
               Mean episode length: 994.00
       Episode_Reward/keep_balance: 0.9875
     Episode_Reward/rew_lin_vel_xy: 6.2836
      Episode_Reward/rew_ang_vel_z: 2.5604
    Episode_Reward/pen_base_height: -0.2854
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1493
   Episode_Reward/pen_joint_torque: -0.2330
    Episode_Reward/pen_joint_accel: -0.1207
    Episode_Reward/pen_action_rate: -0.1164
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2510
Episode_Reward/pen_flat_orientation: -0.0909
  Episode_Reward/pen_feet_distance: -0.0306
Episode_Reward/pen_feet_regulation: -0.4957
   Episode_Reward/foot_landing_vel: -0.1288
   Episode_Reward/test_gait_reward: -0.9111
Metrics/base_velocity/error_vel_xy: 0.9367
Metrics/base_velocity/error_vel_yaw: 1.2540
      Episode_Termination/time_out: 3.2917
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 197885952
                    Iteration time: 1.10s
                        Total time: 2197.39s
                               ETA: 1078.5s

################################################################################
                     [1m Learning iteration 2013/3000 [0m                     

                       Computation: 91531 steps/s (collection: 0.952s, learning 0.122s)
               Value function loss: 0.5332
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8443
                     Learning rate: 0.0009
                       Mean reward: 138.98
               Mean episode length: 961.84
       Episode_Reward/keep_balance: 0.9637
     Episode_Reward/rew_lin_vel_xy: 6.3439
      Episode_Reward/rew_ang_vel_z: 2.5924
    Episode_Reward/pen_base_height: -0.2872
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1357
   Episode_Reward/pen_joint_torque: -0.2376
    Episode_Reward/pen_joint_accel: -0.0979
    Episode_Reward/pen_action_rate: -0.1108
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0530
   Episode_Reward/pen_joint_powers: -0.0852
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2376
Episode_Reward/pen_flat_orientation: -0.0888
  Episode_Reward/pen_feet_distance: -0.0284
Episode_Reward/pen_feet_regulation: -0.4492
   Episode_Reward/foot_landing_vel: -0.1249
   Episode_Reward/test_gait_reward: -0.8814
Metrics/base_velocity/error_vel_xy: 0.8243
Metrics/base_velocity/error_vel_yaw: 1.1454
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 197984256
                    Iteration time: 1.07s
                        Total time: 2198.47s
                               ETA: 1077.4s

################################################################################
                     [1m Learning iteration 2014/3000 [0m                     

                       Computation: 91993 steps/s (collection: 0.947s, learning 0.121s)
               Value function loss: 0.5580
                    Surrogate loss: 0.0006
             Mean action noise std: 0.8449
                     Learning rate: 0.0002
                       Mean reward: 141.37
               Mean episode length: 979.44
       Episode_Reward/keep_balance: 0.9931
     Episode_Reward/rew_lin_vel_xy: 6.4465
      Episode_Reward/rew_ang_vel_z: 2.6243
    Episode_Reward/pen_base_height: -0.2933
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1484
   Episode_Reward/pen_joint_torque: -0.2376
    Episode_Reward/pen_joint_accel: -0.0949
    Episode_Reward/pen_action_rate: -0.1153
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0887
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2487
Episode_Reward/pen_flat_orientation: -0.0887
  Episode_Reward/pen_feet_distance: -0.0301
Episode_Reward/pen_feet_regulation: -0.4726
   Episode_Reward/foot_landing_vel: -0.1186
   Episode_Reward/test_gait_reward: -0.9095
Metrics/base_velocity/error_vel_xy: 0.8864
Metrics/base_velocity/error_vel_yaw: 1.2278
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 198082560
                    Iteration time: 1.07s
                        Total time: 2199.54s
                               ETA: 1076.3s

################################################################################
                     [1m Learning iteration 2015/3000 [0m                     

                       Computation: 90756 steps/s (collection: 0.960s, learning 0.123s)
               Value function loss: 0.4772
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8451
                     Learning rate: 0.0004
                       Mean reward: 140.56
               Mean episode length: 979.63
       Episode_Reward/keep_balance: 0.9844
     Episode_Reward/rew_lin_vel_xy: 6.4153
      Episode_Reward/rew_ang_vel_z: 2.5736
    Episode_Reward/pen_base_height: -0.2831
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1467
   Episode_Reward/pen_joint_torque: -0.2298
    Episode_Reward/pen_joint_accel: -0.0971
    Episode_Reward/pen_action_rate: -0.1149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2486
Episode_Reward/pen_flat_orientation: -0.0844
  Episode_Reward/pen_feet_distance: -0.0291
Episode_Reward/pen_feet_regulation: -0.4738
   Episode_Reward/foot_landing_vel: -0.1195
   Episode_Reward/test_gait_reward: -0.8961
Metrics/base_velocity/error_vel_xy: 0.8609
Metrics/base_velocity/error_vel_yaw: 1.2324
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 198180864
                    Iteration time: 1.08s
                        Total time: 2200.62s
                               ETA: 1075.2s

################################################################################
                     [1m Learning iteration 2016/3000 [0m                     

                       Computation: 90955 steps/s (collection: 0.958s, learning 0.122s)
               Value function loss: 0.5304
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8462
                     Learning rate: 0.0006
                       Mean reward: 139.48
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.3610
      Episode_Reward/rew_ang_vel_z: 2.6054
    Episode_Reward/pen_base_height: -0.2933
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1551
   Episode_Reward/pen_joint_torque: -0.2245
    Episode_Reward/pen_joint_accel: -0.1008
    Episode_Reward/pen_action_rate: -0.1167
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2529
Episode_Reward/pen_flat_orientation: -0.0902
  Episode_Reward/pen_feet_distance: -0.0243
Episode_Reward/pen_feet_regulation: -0.5006
   Episode_Reward/foot_landing_vel: -0.1300
   Episode_Reward/test_gait_reward: -0.9203
Metrics/base_velocity/error_vel_xy: 0.9631
Metrics/base_velocity/error_vel_yaw: 1.2664
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 198279168
                    Iteration time: 1.08s
                        Total time: 2201.70s
                               ETA: 1074.1s

################################################################################
                     [1m Learning iteration 2017/3000 [0m                     

                       Computation: 87949 steps/s (collection: 0.995s, learning 0.123s)
               Value function loss: 0.5719
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8471
                     Learning rate: 0.0003
                       Mean reward: 140.26
               Mean episode length: 988.43
       Episode_Reward/keep_balance: 0.9941
     Episode_Reward/rew_lin_vel_xy: 6.4031
      Episode_Reward/rew_ang_vel_z: 2.5955
    Episode_Reward/pen_base_height: -0.2751
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1489
   Episode_Reward/pen_joint_torque: -0.2276
    Episode_Reward/pen_joint_accel: -0.1083
    Episode_Reward/pen_action_rate: -0.1155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0558
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2517
Episode_Reward/pen_flat_orientation: -0.0895
  Episode_Reward/pen_feet_distance: -0.0216
Episode_Reward/pen_feet_regulation: -0.4850
   Episode_Reward/foot_landing_vel: -0.1233
   Episode_Reward/test_gait_reward: -0.9156
Metrics/base_velocity/error_vel_xy: 0.9017
Metrics/base_velocity/error_vel_yaw: 1.2526
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 198377472
                    Iteration time: 1.12s
                        Total time: 2202.82s
                               ETA: 1073.0s

################################################################################
                     [1m Learning iteration 2018/3000 [0m                     

                       Computation: 89327 steps/s (collection: 0.975s, learning 0.125s)
               Value function loss: 0.5297
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8480
                     Learning rate: 0.0006
                       Mean reward: 140.81
               Mean episode length: 982.47
       Episode_Reward/keep_balance: 0.9898
     Episode_Reward/rew_lin_vel_xy: 6.3629
      Episode_Reward/rew_ang_vel_z: 2.6168
    Episode_Reward/pen_base_height: -0.2995
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1542
   Episode_Reward/pen_joint_torque: -0.2317
    Episode_Reward/pen_joint_accel: -0.1103
    Episode_Reward/pen_action_rate: -0.1149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2496
Episode_Reward/pen_flat_orientation: -0.0958
  Episode_Reward/pen_feet_distance: -0.0294
Episode_Reward/pen_feet_regulation: -0.4865
   Episode_Reward/foot_landing_vel: -0.1379
   Episode_Reward/test_gait_reward: -0.9062
Metrics/base_velocity/error_vel_xy: 0.9116
Metrics/base_velocity/error_vel_yaw: 1.2154
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 198475776
                    Iteration time: 1.10s
                        Total time: 2203.92s
                               ETA: 1071.9s

################################################################################
                     [1m Learning iteration 2019/3000 [0m                     

                       Computation: 88860 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 0.4567
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8465
                     Learning rate: 0.0006
                       Mean reward: 141.39
               Mean episode length: 982.85
       Episode_Reward/keep_balance: 0.9942
     Episode_Reward/rew_lin_vel_xy: 6.4830
      Episode_Reward/rew_ang_vel_z: 2.6487
    Episode_Reward/pen_base_height: -0.2961
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1479
   Episode_Reward/pen_joint_torque: -0.2385
    Episode_Reward/pen_joint_accel: -0.0984
    Episode_Reward/pen_action_rate: -0.1136
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2462
Episode_Reward/pen_flat_orientation: -0.0885
  Episode_Reward/pen_feet_distance: -0.0292
Episode_Reward/pen_feet_regulation: -0.4738
   Episode_Reward/foot_landing_vel: -0.1300
   Episode_Reward/test_gait_reward: -0.9145
Metrics/base_velocity/error_vel_xy: 0.8681
Metrics/base_velocity/error_vel_yaw: 1.1952
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 198574080
                    Iteration time: 1.11s
                        Total time: 2205.02s
                               ETA: 1070.9s

################################################################################
                     [1m Learning iteration 2020/3000 [0m                     

                       Computation: 88642 steps/s (collection: 0.984s, learning 0.125s)
               Value function loss: 0.4928
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8464
                     Learning rate: 0.0006
                       Mean reward: 141.88
               Mean episode length: 990.32
       Episode_Reward/keep_balance: 0.9919
     Episode_Reward/rew_lin_vel_xy: 6.4104
      Episode_Reward/rew_ang_vel_z: 2.6329
    Episode_Reward/pen_base_height: -0.2809
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1549
   Episode_Reward/pen_joint_torque: -0.2234
    Episode_Reward/pen_joint_accel: -0.1159
    Episode_Reward/pen_action_rate: -0.1138
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2489
Episode_Reward/pen_flat_orientation: -0.0878
  Episode_Reward/pen_feet_distance: -0.0288
Episode_Reward/pen_feet_regulation: -0.4584
   Episode_Reward/foot_landing_vel: -0.1361
   Episode_Reward/test_gait_reward: -0.8931
Metrics/base_velocity/error_vel_xy: 0.8913
Metrics/base_velocity/error_vel_yaw: 1.2115
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 198672384
                    Iteration time: 1.11s
                        Total time: 2206.13s
                               ETA: 1069.8s

################################################################################
                     [1m Learning iteration 2021/3000 [0m                     

                       Computation: 87687 steps/s (collection: 1.000s, learning 0.121s)
               Value function loss: 0.6091
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8476
                     Learning rate: 0.0009
                       Mean reward: 142.23
               Mean episode length: 988.56
       Episode_Reward/keep_balance: 0.9903
     Episode_Reward/rew_lin_vel_xy: 6.4307
      Episode_Reward/rew_ang_vel_z: 2.6092
    Episode_Reward/pen_base_height: -0.2884
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1474
   Episode_Reward/pen_joint_torque: -0.2319
    Episode_Reward/pen_joint_accel: -0.0968
    Episode_Reward/pen_action_rate: -0.1147
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2490
Episode_Reward/pen_flat_orientation: -0.0902
  Episode_Reward/pen_feet_distance: -0.0291
Episode_Reward/pen_feet_regulation: -0.4747
   Episode_Reward/foot_landing_vel: -0.1239
   Episode_Reward/test_gait_reward: -0.9192
Metrics/base_velocity/error_vel_xy: 0.8946
Metrics/base_velocity/error_vel_yaw: 1.2177
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 198770688
                    Iteration time: 1.12s
                        Total time: 2207.25s
                               ETA: 1068.7s

################################################################################
                     [1m Learning iteration 2022/3000 [0m                     

                       Computation: 90291 steps/s (collection: 0.967s, learning 0.122s)
               Value function loss: 0.5171
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8486
                     Learning rate: 0.0004
                       Mean reward: 138.17
               Mean episode length: 988.08
       Episode_Reward/keep_balance: 0.9920
     Episode_Reward/rew_lin_vel_xy: 6.3405
      Episode_Reward/rew_ang_vel_z: 2.5823
    Episode_Reward/pen_base_height: -0.3077
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1495
   Episode_Reward/pen_joint_torque: -0.2404
    Episode_Reward/pen_joint_accel: -0.1140
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2509
Episode_Reward/pen_flat_orientation: -0.0964
  Episode_Reward/pen_feet_distance: -0.0292
Episode_Reward/pen_feet_regulation: -0.4936
   Episode_Reward/foot_landing_vel: -0.1303
   Episode_Reward/test_gait_reward: -0.9155
Metrics/base_velocity/error_vel_xy: 0.9448
Metrics/base_velocity/error_vel_yaw: 1.2622
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 198868992
                    Iteration time: 1.09s
                        Total time: 2208.34s
                               ETA: 1067.6s

################################################################################
                     [1m Learning iteration 2023/3000 [0m                     

                       Computation: 89603 steps/s (collection: 0.975s, learning 0.122s)
               Value function loss: 0.4943
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8489
                     Learning rate: 0.0003
                       Mean reward: 140.25
               Mean episode length: 980.27
       Episode_Reward/keep_balance: 0.9864
     Episode_Reward/rew_lin_vel_xy: 6.4330
      Episode_Reward/rew_ang_vel_z: 2.5934
    Episode_Reward/pen_base_height: -0.2856
      Episode_Reward/pen_lin_vel_z: -0.0355
     Episode_Reward/pen_ang_vel_xy: -0.1489
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.0947
    Episode_Reward/pen_action_rate: -0.1139
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0531
   Episode_Reward/pen_joint_powers: -0.0848
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2481
Episode_Reward/pen_flat_orientation: -0.0891
  Episode_Reward/pen_feet_distance: -0.0292
Episode_Reward/pen_feet_regulation: -0.4549
   Episode_Reward/foot_landing_vel: -0.1245
   Episode_Reward/test_gait_reward: -0.9023
Metrics/base_velocity/error_vel_xy: 0.8669
Metrics/base_velocity/error_vel_yaw: 1.2208
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 198967296
                    Iteration time: 1.10s
                        Total time: 2209.44s
                               ETA: 1066.5s

################################################################################
                     [1m Learning iteration 2024/3000 [0m                     

                       Computation: 90265 steps/s (collection: 0.964s, learning 0.125s)
               Value function loss: 0.4888
                    Surrogate loss: -0.0058
             Mean action noise std: 0.8488
                     Learning rate: 0.0006
                       Mean reward: 141.86
               Mean episode length: 991.16
       Episode_Reward/keep_balance: 0.9882
     Episode_Reward/rew_lin_vel_xy: 6.3846
      Episode_Reward/rew_ang_vel_z: 2.6143
    Episode_Reward/pen_base_height: -0.3095
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1441
   Episode_Reward/pen_joint_torque: -0.2437
    Episode_Reward/pen_joint_accel: -0.1047
    Episode_Reward/pen_action_rate: -0.1155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0535
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2471
Episode_Reward/pen_flat_orientation: -0.0921
  Episode_Reward/pen_feet_distance: -0.0285
Episode_Reward/pen_feet_regulation: -0.4671
   Episode_Reward/foot_landing_vel: -0.1216
   Episode_Reward/test_gait_reward: -0.9031
Metrics/base_velocity/error_vel_xy: 0.8835
Metrics/base_velocity/error_vel_yaw: 1.2043
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 199065600
                    Iteration time: 1.09s
                        Total time: 2210.53s
                               ETA: 1065.4s

################################################################################
                     [1m Learning iteration 2025/3000 [0m                     

                       Computation: 90085 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.4965
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8481
                     Learning rate: 0.0006
                       Mean reward: 139.92
               Mean episode length: 974.57
       Episode_Reward/keep_balance: 0.9487
     Episode_Reward/rew_lin_vel_xy: 6.1689
      Episode_Reward/rew_ang_vel_z: 2.5054
    Episode_Reward/pen_base_height: -0.2837
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.1445
   Episode_Reward/pen_joint_torque: -0.2329
    Episode_Reward/pen_joint_accel: -0.1022
    Episode_Reward/pen_action_rate: -0.1115
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0530
   Episode_Reward/pen_joint_powers: -0.0854
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2392
Episode_Reward/pen_flat_orientation: -0.0889
  Episode_Reward/pen_feet_distance: -0.0303
Episode_Reward/pen_feet_regulation: -0.4671
   Episode_Reward/foot_landing_vel: -0.1234
   Episode_Reward/test_gait_reward: -0.8697
Metrics/base_velocity/error_vel_xy: 0.8426
Metrics/base_velocity/error_vel_yaw: 1.1609
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 199163904
                    Iteration time: 1.09s
                        Total time: 2211.62s
                               ETA: 1064.3s

################################################################################
                     [1m Learning iteration 2026/3000 [0m                     

                       Computation: 90860 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.5071
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8480
                     Learning rate: 0.0004
                       Mean reward: 142.35
               Mean episode length: 990.67
       Episode_Reward/keep_balance: 0.9871
     Episode_Reward/rew_lin_vel_xy: 6.3916
      Episode_Reward/rew_ang_vel_z: 2.6341
    Episode_Reward/pen_base_height: -0.2933
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1477
   Episode_Reward/pen_joint_torque: -0.2305
    Episode_Reward/pen_joint_accel: -0.1074
    Episode_Reward/pen_action_rate: -0.1131
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0855
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2448
Episode_Reward/pen_flat_orientation: -0.0877
  Episode_Reward/pen_feet_distance: -0.0260
Episode_Reward/pen_feet_regulation: -0.4588
   Episode_Reward/foot_landing_vel: -0.1240
   Episode_Reward/test_gait_reward: -0.9066
Metrics/base_velocity/error_vel_xy: 0.8906
Metrics/base_velocity/error_vel_yaw: 1.1917
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 199262208
                    Iteration time: 1.08s
                        Total time: 2212.70s
                               ETA: 1063.2s

################################################################################
                     [1m Learning iteration 2027/3000 [0m                     

                       Computation: 90963 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.5020
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8469
                     Learning rate: 0.0004
                       Mean reward: 139.92
               Mean episode length: 976.36
       Episode_Reward/keep_balance: 0.9733
     Episode_Reward/rew_lin_vel_xy: 6.2799
      Episode_Reward/rew_ang_vel_z: 2.6012
    Episode_Reward/pen_base_height: -0.2957
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1452
   Episode_Reward/pen_joint_torque: -0.2229
    Episode_Reward/pen_joint_accel: -0.0970
    Episode_Reward/pen_action_rate: -0.1131
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0534
   Episode_Reward/pen_joint_powers: -0.0834
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2438
Episode_Reward/pen_flat_orientation: -0.0906
  Episode_Reward/pen_feet_distance: -0.0236
Episode_Reward/pen_feet_regulation: -0.4573
   Episode_Reward/foot_landing_vel: -0.1247
   Episode_Reward/test_gait_reward: -0.8904
Metrics/base_velocity/error_vel_xy: 0.8849
Metrics/base_velocity/error_vel_yaw: 1.1663
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 199360512
                    Iteration time: 1.08s
                        Total time: 2213.78s
                               ETA: 1062.1s

################################################################################
                     [1m Learning iteration 2028/3000 [0m                     

                       Computation: 92129 steps/s (collection: 0.945s, learning 0.122s)
               Value function loss: 0.5311
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8458
                     Learning rate: 0.0004
                       Mean reward: 141.52
               Mean episode length: 993.98
       Episode_Reward/keep_balance: 0.9917
     Episode_Reward/rew_lin_vel_xy: 6.4046
      Episode_Reward/rew_ang_vel_z: 2.6269
    Episode_Reward/pen_base_height: -0.2940
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1501
   Episode_Reward/pen_joint_torque: -0.2391
    Episode_Reward/pen_joint_accel: -0.0995
    Episode_Reward/pen_action_rate: -0.1166
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2484
Episode_Reward/pen_flat_orientation: -0.0915
  Episode_Reward/pen_feet_distance: -0.0271
Episode_Reward/pen_feet_regulation: -0.4735
   Episode_Reward/foot_landing_vel: -0.1255
   Episode_Reward/test_gait_reward: -0.9128
Metrics/base_velocity/error_vel_xy: 0.9035
Metrics/base_velocity/error_vel_yaw: 1.2179
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 199458816
                    Iteration time: 1.07s
                        Total time: 2214.85s
                               ETA: 1061.0s

################################################################################
                     [1m Learning iteration 2029/3000 [0m                     

                       Computation: 90233 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.5016
                    Surrogate loss: -0.0059
             Mean action noise std: 0.8462
                     Learning rate: 0.0006
                       Mean reward: 144.08
               Mean episode length: 987.91
       Episode_Reward/keep_balance: 0.9917
     Episode_Reward/rew_lin_vel_xy: 6.4788
      Episode_Reward/rew_ang_vel_z: 2.6754
    Episode_Reward/pen_base_height: -0.2855
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1489
   Episode_Reward/pen_joint_torque: -0.2311
    Episode_Reward/pen_joint_accel: -0.1063
    Episode_Reward/pen_action_rate: -0.1141
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0541
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2463
Episode_Reward/pen_flat_orientation: -0.0857
  Episode_Reward/pen_feet_distance: -0.0264
Episode_Reward/pen_feet_regulation: -0.4652
   Episode_Reward/foot_landing_vel: -0.1265
   Episode_Reward/test_gait_reward: -0.9059
Metrics/base_velocity/error_vel_xy: 0.8690
Metrics/base_velocity/error_vel_yaw: 1.1713
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 199557120
                    Iteration time: 1.09s
                        Total time: 2215.94s
                               ETA: 1059.9s

################################################################################
                     [1m Learning iteration 2030/3000 [0m                     

                       Computation: 89893 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 0.5571
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8469
                     Learning rate: 0.0004
                       Mean reward: 138.27
               Mean episode length: 986.36
       Episode_Reward/keep_balance: 0.9886
     Episode_Reward/rew_lin_vel_xy: 6.3300
      Episode_Reward/rew_ang_vel_z: 2.5881
    Episode_Reward/pen_base_height: -0.2914
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1574
   Episode_Reward/pen_joint_torque: -0.2434
    Episode_Reward/pen_joint_accel: -0.1048
    Episode_Reward/pen_action_rate: -0.1181
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0907
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2551
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0300
Episode_Reward/pen_feet_regulation: -0.4837
   Episode_Reward/foot_landing_vel: -0.1301
   Episode_Reward/test_gait_reward: -0.9078
Metrics/base_velocity/error_vel_xy: 0.9292
Metrics/base_velocity/error_vel_yaw: 1.2406
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 199655424
                    Iteration time: 1.09s
                        Total time: 2217.03s
                               ETA: 1058.8s

################################################################################
                     [1m Learning iteration 2031/3000 [0m                     

                       Computation: 89579 steps/s (collection: 0.971s, learning 0.127s)
               Value function loss: 0.5346
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8464
                     Learning rate: 0.0003
                       Mean reward: 138.30
               Mean episode length: 980.20
       Episode_Reward/keep_balance: 0.9861
     Episode_Reward/rew_lin_vel_xy: 6.3078
      Episode_Reward/rew_ang_vel_z: 2.5783
    Episode_Reward/pen_base_height: -0.3024
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.1472
   Episode_Reward/pen_joint_torque: -0.2446
    Episode_Reward/pen_joint_accel: -0.1049
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0913
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2486
Episode_Reward/pen_flat_orientation: -0.0988
  Episode_Reward/pen_feet_distance: -0.0281
Episode_Reward/pen_feet_regulation: -0.4922
   Episode_Reward/foot_landing_vel: -0.1322
   Episode_Reward/test_gait_reward: -0.9080
Metrics/base_velocity/error_vel_xy: 0.9305
Metrics/base_velocity/error_vel_yaw: 1.2366
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 199753728
                    Iteration time: 1.10s
                        Total time: 2218.13s
                               ETA: 1057.8s

################################################################################
                     [1m Learning iteration 2032/3000 [0m                     

                       Computation: 90657 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.5417
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8466
                     Learning rate: 0.0003
                       Mean reward: 141.75
               Mean episode length: 995.53
       Episode_Reward/keep_balance: 0.9963
     Episode_Reward/rew_lin_vel_xy: 6.4547
      Episode_Reward/rew_ang_vel_z: 2.6330
    Episode_Reward/pen_base_height: -0.3086
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1436
   Episode_Reward/pen_joint_torque: -0.2445
    Episode_Reward/pen_joint_accel: -0.0996
    Episode_Reward/pen_action_rate: -0.1157
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2473
Episode_Reward/pen_flat_orientation: -0.0892
  Episode_Reward/pen_feet_distance: -0.0285
Episode_Reward/pen_feet_regulation: -0.4838
   Episode_Reward/foot_landing_vel: -0.1245
   Episode_Reward/test_gait_reward: -0.9134
Metrics/base_velocity/error_vel_xy: 0.9018
Metrics/base_velocity/error_vel_yaw: 1.2203
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 199852032
                    Iteration time: 1.08s
                        Total time: 2219.22s
                               ETA: 1056.7s

################################################################################
                     [1m Learning iteration 2033/3000 [0m                     

                       Computation: 90625 steps/s (collection: 0.962s, learning 0.123s)
               Value function loss: 0.5056
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8480
                     Learning rate: 0.0006
                       Mean reward: 138.95
               Mean episode length: 978.17
       Episode_Reward/keep_balance: 0.9825
     Episode_Reward/rew_lin_vel_xy: 6.3653
      Episode_Reward/rew_ang_vel_z: 2.6181
    Episode_Reward/pen_base_height: -0.2924
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1438
   Episode_Reward/pen_joint_torque: -0.2432
    Episode_Reward/pen_joint_accel: -0.0947
    Episode_Reward/pen_action_rate: -0.1142
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0537
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2447
Episode_Reward/pen_flat_orientation: -0.0909
  Episode_Reward/pen_feet_distance: -0.0268
Episode_Reward/pen_feet_regulation: -0.4650
   Episode_Reward/foot_landing_vel: -0.1240
   Episode_Reward/test_gait_reward: -0.9028
Metrics/base_velocity/error_vel_xy: 0.8868
Metrics/base_velocity/error_vel_yaw: 1.1834
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 199950336
                    Iteration time: 1.08s
                        Total time: 2220.30s
                               ETA: 1055.6s

################################################################################
                     [1m Learning iteration 2034/3000 [0m                     

                       Computation: 90890 steps/s (collection: 0.960s, learning 0.122s)
               Value function loss: 0.5180
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8482
                     Learning rate: 0.0006
                       Mean reward: 138.52
               Mean episode length: 987.81
       Episode_Reward/keep_balance: 0.9893
     Episode_Reward/rew_lin_vel_xy: 6.3458
      Episode_Reward/rew_ang_vel_z: 2.6093
    Episode_Reward/pen_base_height: -0.3007
      Episode_Reward/pen_lin_vel_z: -0.0389
     Episode_Reward/pen_ang_vel_xy: -0.1505
   Episode_Reward/pen_joint_torque: -0.2436
    Episode_Reward/pen_joint_accel: -0.1068
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0558
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2474
Episode_Reward/pen_flat_orientation: -0.0955
  Episode_Reward/pen_feet_distance: -0.0272
Episode_Reward/pen_feet_regulation: -0.4918
   Episode_Reward/foot_landing_vel: -0.1220
   Episode_Reward/test_gait_reward: -0.9025
Metrics/base_velocity/error_vel_xy: 0.9281
Metrics/base_velocity/error_vel_yaw: 1.2270
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 200048640
                    Iteration time: 1.08s
                        Total time: 2221.38s
                               ETA: 1054.5s

################################################################################
                     [1m Learning iteration 2035/3000 [0m                     

                       Computation: 91585 steps/s (collection: 0.950s, learning 0.124s)
               Value function loss: 0.4966
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8485
                     Learning rate: 0.0004
                       Mean reward: 140.04
               Mean episode length: 982.30
       Episode_Reward/keep_balance: 0.9820
     Episode_Reward/rew_lin_vel_xy: 6.3659
      Episode_Reward/rew_ang_vel_z: 2.6220
    Episode_Reward/pen_base_height: -0.2832
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1474
   Episode_Reward/pen_joint_torque: -0.2337
    Episode_Reward/pen_joint_accel: -0.1009
    Episode_Reward/pen_action_rate: -0.1140
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0539
   Episode_Reward/pen_joint_powers: -0.0859
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2464
Episode_Reward/pen_flat_orientation: -0.0876
  Episode_Reward/pen_feet_distance: -0.0331
Episode_Reward/pen_feet_regulation: -0.4686
   Episode_Reward/foot_landing_vel: -0.1260
   Episode_Reward/test_gait_reward: -0.9059
Metrics/base_velocity/error_vel_xy: 0.8925
Metrics/base_velocity/error_vel_yaw: 1.1906
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 200146944
                    Iteration time: 1.07s
                        Total time: 2222.46s
                               ETA: 1053.4s

################################################################################
                     [1m Learning iteration 2036/3000 [0m                     

                       Computation: 89112 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.5116
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8480
                     Learning rate: 0.0004
                       Mean reward: 137.24
               Mean episode length: 990.53
       Episode_Reward/keep_balance: 0.9951
     Episode_Reward/rew_lin_vel_xy: 6.3679
      Episode_Reward/rew_ang_vel_z: 2.6143
    Episode_Reward/pen_base_height: -0.3049
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.1530
   Episode_Reward/pen_joint_torque: -0.2382
    Episode_Reward/pen_joint_accel: -0.1174
    Episode_Reward/pen_action_rate: -0.1192
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0591
   Episode_Reward/pen_joint_powers: -0.0911
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2561
Episode_Reward/pen_flat_orientation: -0.0946
  Episode_Reward/pen_feet_distance: -0.0268
Episode_Reward/pen_feet_regulation: -0.5261
   Episode_Reward/foot_landing_vel: -0.1308
   Episode_Reward/test_gait_reward: -0.9248
Metrics/base_velocity/error_vel_xy: 0.9356
Metrics/base_velocity/error_vel_yaw: 1.2338
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 200245248
                    Iteration time: 1.10s
                        Total time: 2223.56s
                               ETA: 1052.3s

################################################################################
                     [1m Learning iteration 2037/3000 [0m                     

                       Computation: 90936 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.5080
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8461
                     Learning rate: 0.0004
                       Mean reward: 137.26
               Mean episode length: 988.47
       Episode_Reward/keep_balance: 0.9889
     Episode_Reward/rew_lin_vel_xy: 6.3923
      Episode_Reward/rew_ang_vel_z: 2.5508
    Episode_Reward/pen_base_height: -0.2916
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1513
   Episode_Reward/pen_joint_torque: -0.2390
    Episode_Reward/pen_joint_accel: -0.1051
    Episode_Reward/pen_action_rate: -0.1182
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0568
   Episode_Reward/pen_joint_powers: -0.0897
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2529
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0275
Episode_Reward/pen_feet_regulation: -0.4978
   Episode_Reward/foot_landing_vel: -0.1291
   Episode_Reward/test_gait_reward: -0.9154
Metrics/base_velocity/error_vel_xy: 0.8952
Metrics/base_velocity/error_vel_yaw: 1.2667
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 200343552
                    Iteration time: 1.08s
                        Total time: 2224.64s
                               ETA: 1051.2s

################################################################################
                     [1m Learning iteration 2038/3000 [0m                     

                       Computation: 87989 steps/s (collection: 0.988s, learning 0.129s)
               Value function loss: 0.4900
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8449
                     Learning rate: 0.0004
                       Mean reward: 133.87
               Mean episode length: 961.84
       Episode_Reward/keep_balance: 0.9738
     Episode_Reward/rew_lin_vel_xy: 6.2461
      Episode_Reward/rew_ang_vel_z: 2.5952
    Episode_Reward/pen_base_height: -0.2920
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1477
   Episode_Reward/pen_joint_torque: -0.2402
    Episode_Reward/pen_joint_accel: -0.0995
    Episode_Reward/pen_action_rate: -0.1131
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2435
Episode_Reward/pen_flat_orientation: -0.0930
  Episode_Reward/pen_feet_distance: -0.0284
Episode_Reward/pen_feet_regulation: -0.4678
   Episode_Reward/foot_landing_vel: -0.1270
   Episode_Reward/test_gait_reward: -0.8927
Metrics/base_velocity/error_vel_xy: 0.9051
Metrics/base_velocity/error_vel_yaw: 1.1777
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 200441856
                    Iteration time: 1.12s
                        Total time: 2225.76s
                               ETA: 1050.1s

################################################################################
                     [1m Learning iteration 2039/3000 [0m                     

                       Computation: 88608 steps/s (collection: 0.987s, learning 0.123s)
               Value function loss: 0.5150
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8442
                     Learning rate: 0.0004
                       Mean reward: 138.88
               Mean episode length: 981.50
       Episode_Reward/keep_balance: 0.9762
     Episode_Reward/rew_lin_vel_xy: 6.2823
      Episode_Reward/rew_ang_vel_z: 2.5982
    Episode_Reward/pen_base_height: -0.2746
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1459
   Episode_Reward/pen_joint_torque: -0.2189
    Episode_Reward/pen_joint_accel: -0.0999
    Episode_Reward/pen_action_rate: -0.1125
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0530
   Episode_Reward/pen_joint_powers: -0.0825
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2443
Episode_Reward/pen_flat_orientation: -0.0902
  Episode_Reward/pen_feet_distance: -0.0364
Episode_Reward/pen_feet_regulation: -0.4687
   Episode_Reward/foot_landing_vel: -0.1293
   Episode_Reward/test_gait_reward: -0.8928
Metrics/base_velocity/error_vel_xy: 0.8907
Metrics/base_velocity/error_vel_yaw: 1.1829
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 200540160
                    Iteration time: 1.11s
                        Total time: 2226.87s
                               ETA: 1049.0s

################################################################################
                     [1m Learning iteration 2040/3000 [0m                     

                       Computation: 88701 steps/s (collection: 0.985s, learning 0.124s)
               Value function loss: 0.5338
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8425
                     Learning rate: 0.0003
                       Mean reward: 140.07
               Mean episode length: 973.80
       Episode_Reward/keep_balance: 0.9748
     Episode_Reward/rew_lin_vel_xy: 6.3829
      Episode_Reward/rew_ang_vel_z: 2.5805
    Episode_Reward/pen_base_height: -0.2743
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1481
   Episode_Reward/pen_joint_torque: -0.2329
    Episode_Reward/pen_joint_accel: -0.1059
    Episode_Reward/pen_action_rate: -0.1143
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2461
Episode_Reward/pen_flat_orientation: -0.0893
  Episode_Reward/pen_feet_distance: -0.0335
Episode_Reward/pen_feet_regulation: -0.4688
   Episode_Reward/foot_landing_vel: -0.1224
   Episode_Reward/test_gait_reward: -0.8885
Metrics/base_velocity/error_vel_xy: 0.8391
Metrics/base_velocity/error_vel_yaw: 1.1914
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 200638464
                    Iteration time: 1.11s
                        Total time: 2227.97s
                               ETA: 1047.9s

################################################################################
                     [1m Learning iteration 2041/3000 [0m                     

                       Computation: 89328 steps/s (collection: 0.978s, learning 0.122s)
               Value function loss: 0.4563
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8400
                     Learning rate: 0.0004
                       Mean reward: 144.02
               Mean episode length: 998.62
       Episode_Reward/keep_balance: 0.9981
     Episode_Reward/rew_lin_vel_xy: 6.5292
      Episode_Reward/rew_ang_vel_z: 2.6395
    Episode_Reward/pen_base_height: -0.2758
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1441
   Episode_Reward/pen_joint_torque: -0.2336
    Episode_Reward/pen_joint_accel: -0.0989
    Episode_Reward/pen_action_rate: -0.1158
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2477
Episode_Reward/pen_flat_orientation: -0.0868
  Episode_Reward/pen_feet_distance: -0.0269
Episode_Reward/pen_feet_regulation: -0.4897
   Episode_Reward/foot_landing_vel: -0.1214
   Episode_Reward/test_gait_reward: -0.9200
Metrics/base_velocity/error_vel_xy: 0.8542
Metrics/base_velocity/error_vel_yaw: 1.2160
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 200736768
                    Iteration time: 1.10s
                        Total time: 2229.07s
                               ETA: 1046.9s

################################################################################
                     [1m Learning iteration 2042/3000 [0m                     

                       Computation: 90096 steps/s (collection: 0.969s, learning 0.122s)
               Value function loss: 0.4546
                    Surrogate loss: -0.0051
             Mean action noise std: 0.8389
                     Learning rate: 0.0009
                       Mean reward: 143.68
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.5016
      Episode_Reward/rew_ang_vel_z: 2.6615
    Episode_Reward/pen_base_height: -0.2820
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1490
   Episode_Reward/pen_joint_torque: -0.2270
    Episode_Reward/pen_joint_accel: -0.0994
    Episode_Reward/pen_action_rate: -0.1148
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0529
   Episode_Reward/pen_joint_powers: -0.0842
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2479
Episode_Reward/pen_flat_orientation: -0.0868
  Episode_Reward/pen_feet_distance: -0.0316
Episode_Reward/pen_feet_regulation: -0.4636
   Episode_Reward/foot_landing_vel: -0.1172
   Episode_Reward/test_gait_reward: -0.9188
Metrics/base_velocity/error_vel_xy: 0.8765
Metrics/base_velocity/error_vel_yaw: 1.2021
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 200835072
                    Iteration time: 1.09s
                        Total time: 2230.17s
                               ETA: 1045.8s

################################################################################
                     [1m Learning iteration 2043/3000 [0m                     

                       Computation: 89905 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.4612
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8382
                     Learning rate: 0.0004
                       Mean reward: 139.63
               Mean episode length: 989.53
       Episode_Reward/keep_balance: 0.9769
     Episode_Reward/rew_lin_vel_xy: 6.2349
      Episode_Reward/rew_ang_vel_z: 2.5681
    Episode_Reward/pen_base_height: -0.2880
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1501
   Episode_Reward/pen_joint_torque: -0.2317
    Episode_Reward/pen_joint_accel: -0.0983
    Episode_Reward/pen_action_rate: -0.1143
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2449
Episode_Reward/pen_flat_orientation: -0.0967
  Episode_Reward/pen_feet_distance: -0.0297
Episode_Reward/pen_feet_regulation: -0.4747
   Episode_Reward/foot_landing_vel: -0.1216
   Episode_Reward/test_gait_reward: -0.8999
Metrics/base_velocity/error_vel_xy: 0.9229
Metrics/base_velocity/error_vel_yaw: 1.2166
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 200933376
                    Iteration time: 1.09s
                        Total time: 2231.26s
                               ETA: 1044.7s

################################################################################
                     [1m Learning iteration 2044/3000 [0m                     

                       Computation: 90277 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.4871
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8381
                     Learning rate: 0.0002
                       Mean reward: 140.81
               Mean episode length: 990.67
       Episode_Reward/keep_balance: 0.9903
     Episode_Reward/rew_lin_vel_xy: 6.4172
      Episode_Reward/rew_ang_vel_z: 2.6197
    Episode_Reward/pen_base_height: -0.2809
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1514
   Episode_Reward/pen_joint_torque: -0.2284
    Episode_Reward/pen_joint_accel: -0.1076
    Episode_Reward/pen_action_rate: -0.1150
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2504
Episode_Reward/pen_flat_orientation: -0.0910
  Episode_Reward/pen_feet_distance: -0.0312
Episode_Reward/pen_feet_regulation: -0.4879
   Episode_Reward/foot_landing_vel: -0.1235
   Episode_Reward/test_gait_reward: -0.9002
Metrics/base_velocity/error_vel_xy: 0.8976
Metrics/base_velocity/error_vel_yaw: 1.2044
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 201031680
                    Iteration time: 1.09s
                        Total time: 2232.35s
                               ETA: 1043.6s

################################################################################
                     [1m Learning iteration 2045/3000 [0m                     

                       Computation: 87669 steps/s (collection: 0.992s, learning 0.129s)
               Value function loss: 0.5154
                    Surrogate loss: -0.0055
             Mean action noise std: 0.8374
                     Learning rate: 0.0004
                       Mean reward: 142.12
               Mean episode length: 988.04
       Episode_Reward/keep_balance: 0.9838
     Episode_Reward/rew_lin_vel_xy: 6.3815
      Episode_Reward/rew_ang_vel_z: 2.6183
    Episode_Reward/pen_base_height: -0.2801
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1541
   Episode_Reward/pen_joint_torque: -0.2338
    Episode_Reward/pen_joint_accel: -0.1014
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2478
Episode_Reward/pen_flat_orientation: -0.0915
  Episode_Reward/pen_feet_distance: -0.0321
Episode_Reward/pen_feet_regulation: -0.4707
   Episode_Reward/foot_landing_vel: -0.1259
   Episode_Reward/test_gait_reward: -0.8972
Metrics/base_velocity/error_vel_xy: 0.8773
Metrics/base_velocity/error_vel_yaw: 1.1869
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 201129984
                    Iteration time: 1.12s
                        Total time: 2233.47s
                               ETA: 1042.5s

################################################################################
                     [1m Learning iteration 2046/3000 [0m                     

                       Computation: 89381 steps/s (collection: 0.971s, learning 0.129s)
               Value function loss: 0.5064
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8367
                     Learning rate: 0.0004
                       Mean reward: 139.77
               Mean episode length: 996.91
       Episode_Reward/keep_balance: 0.9986
     Episode_Reward/rew_lin_vel_xy: 6.4150
      Episode_Reward/rew_ang_vel_z: 2.6111
    Episode_Reward/pen_base_height: -0.3044
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1520
   Episode_Reward/pen_joint_torque: -0.2448
    Episode_Reward/pen_joint_accel: -0.1058
    Episode_Reward/pen_action_rate: -0.1175
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2513
Episode_Reward/pen_flat_orientation: -0.0883
  Episode_Reward/pen_feet_distance: -0.0301
Episode_Reward/pen_feet_regulation: -0.4818
   Episode_Reward/foot_landing_vel: -0.1247
   Episode_Reward/test_gait_reward: -0.9146
Metrics/base_velocity/error_vel_xy: 0.9302
Metrics/base_velocity/error_vel_yaw: 1.2481
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 201228288
                    Iteration time: 1.10s
                        Total time: 2234.57s
                               ETA: 1041.4s

################################################################################
                     [1m Learning iteration 2047/3000 [0m                     

                       Computation: 89773 steps/s (collection: 0.971s, learning 0.124s)
               Value function loss: 0.5361
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8372
                     Learning rate: 0.0004
                       Mean reward: 141.82
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 0.9930
     Episode_Reward/rew_lin_vel_xy: 6.3906
      Episode_Reward/rew_ang_vel_z: 2.6230
    Episode_Reward/pen_base_height: -0.2763
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1539
   Episode_Reward/pen_joint_torque: -0.2306
    Episode_Reward/pen_joint_accel: -0.1078
    Episode_Reward/pen_action_rate: -0.1155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0873
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2499
Episode_Reward/pen_flat_orientation: -0.0892
  Episode_Reward/pen_feet_distance: -0.0273
Episode_Reward/pen_feet_regulation: -0.4883
   Episode_Reward/foot_landing_vel: -0.1292
   Episode_Reward/test_gait_reward: -0.9049
Metrics/base_velocity/error_vel_xy: 0.9187
Metrics/base_velocity/error_vel_yaw: 1.2180
      Episode_Termination/time_out: 5.0417
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 201326592
                    Iteration time: 1.10s
                        Total time: 2235.66s
                               ETA: 1040.3s

################################################################################
                     [1m Learning iteration 2048/3000 [0m                     

                       Computation: 88509 steps/s (collection: 0.988s, learning 0.123s)
               Value function loss: 0.4701
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8363
                     Learning rate: 0.0006
                       Mean reward: 139.79
               Mean episode length: 983.37
       Episode_Reward/keep_balance: 0.9853
     Episode_Reward/rew_lin_vel_xy: 6.3846
      Episode_Reward/rew_ang_vel_z: 2.5737
    Episode_Reward/pen_base_height: -0.2899
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1487
   Episode_Reward/pen_joint_torque: -0.2323
    Episode_Reward/pen_joint_accel: -0.1027
    Episode_Reward/pen_action_rate: -0.1171
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0869
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2505
Episode_Reward/pen_flat_orientation: -0.0939
  Episode_Reward/pen_feet_distance: -0.0348
Episode_Reward/pen_feet_regulation: -0.5003
   Episode_Reward/foot_landing_vel: -0.1253
   Episode_Reward/test_gait_reward: -0.9071
Metrics/base_velocity/error_vel_xy: 0.8866
Metrics/base_velocity/error_vel_yaw: 1.2397
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 201424896
                    Iteration time: 1.11s
                        Total time: 2236.77s
                               ETA: 1039.2s

################################################################################
                     [1m Learning iteration 2049/3000 [0m                     

                       Computation: 89952 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 0.4705
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8354
                     Learning rate: 0.0003
                       Mean reward: 138.28
               Mean episode length: 991.14
       Episode_Reward/keep_balance: 0.9939
     Episode_Reward/rew_lin_vel_xy: 6.3538
      Episode_Reward/rew_ang_vel_z: 2.6114
    Episode_Reward/pen_base_height: -0.2808
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1547
   Episode_Reward/pen_joint_torque: -0.2354
    Episode_Reward/pen_joint_accel: -0.1081
    Episode_Reward/pen_action_rate: -0.1170
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0571
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2518
Episode_Reward/pen_flat_orientation: -0.0955
  Episode_Reward/pen_feet_distance: -0.0296
Episode_Reward/pen_feet_regulation: -0.4841
   Episode_Reward/foot_landing_vel: -0.1348
   Episode_Reward/test_gait_reward: -0.9075
Metrics/base_velocity/error_vel_xy: 0.9323
Metrics/base_velocity/error_vel_yaw: 1.2449
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 201523200
                    Iteration time: 1.09s
                        Total time: 2237.87s
                               ETA: 1038.2s

################################################################################
                     [1m Learning iteration 2050/3000 [0m                     

                       Computation: 89725 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.5077
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8346
                     Learning rate: 0.0004
                       Mean reward: 142.15
               Mean episode length: 992.14
       Episode_Reward/keep_balance: 0.9918
     Episode_Reward/rew_lin_vel_xy: 6.4146
      Episode_Reward/rew_ang_vel_z: 2.6241
    Episode_Reward/pen_base_height: -0.2915
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1485
   Episode_Reward/pen_joint_torque: -0.2315
    Episode_Reward/pen_joint_accel: -0.0985
    Episode_Reward/pen_action_rate: -0.1146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2457
Episode_Reward/pen_flat_orientation: -0.0895
  Episode_Reward/pen_feet_distance: -0.0358
Episode_Reward/pen_feet_regulation: -0.4715
   Episode_Reward/foot_landing_vel: -0.1239
   Episode_Reward/test_gait_reward: -0.9065
Metrics/base_velocity/error_vel_xy: 0.9084
Metrics/base_velocity/error_vel_yaw: 1.2120
      Episode_Termination/time_out: 4.9583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 201621504
                    Iteration time: 1.10s
                        Total time: 2238.96s
                               ETA: 1037.1s

################################################################################
                     [1m Learning iteration 2051/3000 [0m                     

                       Computation: 89346 steps/s (collection: 0.974s, learning 0.127s)
               Value function loss: 0.5178
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8348
                     Learning rate: 0.0004
                       Mean reward: 143.45
               Mean episode length: 996.79
       Episode_Reward/keep_balance: 0.9956
     Episode_Reward/rew_lin_vel_xy: 6.4455
      Episode_Reward/rew_ang_vel_z: 2.6321
    Episode_Reward/pen_base_height: -0.2845
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1524
   Episode_Reward/pen_joint_torque: -0.2394
    Episode_Reward/pen_joint_accel: -0.1022
    Episode_Reward/pen_action_rate: -0.1155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0541
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2477
Episode_Reward/pen_flat_orientation: -0.0892
  Episode_Reward/pen_feet_distance: -0.0279
Episode_Reward/pen_feet_regulation: -0.4815
   Episode_Reward/foot_landing_vel: -0.1193
   Episode_Reward/test_gait_reward: -0.9006
Metrics/base_velocity/error_vel_xy: 0.9014
Metrics/base_velocity/error_vel_yaw: 1.2237
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 201719808
                    Iteration time: 1.10s
                        Total time: 2240.06s
                               ETA: 1036.0s

################################################################################
                     [1m Learning iteration 2052/3000 [0m                     

                       Computation: 89940 steps/s (collection: 0.963s, learning 0.130s)
               Value function loss: 0.5290
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8355
                     Learning rate: 0.0006
                       Mean reward: 137.21
               Mean episode length: 974.14
       Episode_Reward/keep_balance: 0.9818
     Episode_Reward/rew_lin_vel_xy: 6.3088
      Episode_Reward/rew_ang_vel_z: 2.5849
    Episode_Reward/pen_base_height: -0.2815
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1485
   Episode_Reward/pen_joint_torque: -0.2316
    Episode_Reward/pen_joint_accel: -0.1000
    Episode_Reward/pen_action_rate: -0.1139
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2441
Episode_Reward/pen_flat_orientation: -0.0931
  Episode_Reward/pen_feet_distance: -0.0307
Episode_Reward/pen_feet_regulation: -0.4852
   Episode_Reward/foot_landing_vel: -0.1173
   Episode_Reward/test_gait_reward: -0.9036
Metrics/base_velocity/error_vel_xy: 0.9038
Metrics/base_velocity/error_vel_yaw: 1.2169
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 201818112
                    Iteration time: 1.09s
                        Total time: 2241.16s
                               ETA: 1034.9s

################################################################################
                     [1m Learning iteration 2053/3000 [0m                     

                       Computation: 88474 steps/s (collection: 0.982s, learning 0.129s)
               Value function loss: 0.4946
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8345
                     Learning rate: 0.0002
                       Mean reward: 140.64
               Mean episode length: 986.83
       Episode_Reward/keep_balance: 0.9964
     Episode_Reward/rew_lin_vel_xy: 6.3927
      Episode_Reward/rew_ang_vel_z: 2.6666
    Episode_Reward/pen_base_height: -0.2770
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1458
   Episode_Reward/pen_joint_torque: -0.2308
    Episode_Reward/pen_joint_accel: -0.1041
    Episode_Reward/pen_action_rate: -0.1149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0852
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2472
Episode_Reward/pen_flat_orientation: -0.0897
  Episode_Reward/pen_feet_distance: -0.0297
Episode_Reward/pen_feet_regulation: -0.4771
   Episode_Reward/foot_landing_vel: -0.1250
   Episode_Reward/test_gait_reward: -0.9069
Metrics/base_velocity/error_vel_xy: 0.9351
Metrics/base_velocity/error_vel_yaw: 1.1911
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 201916416
                    Iteration time: 1.11s
                        Total time: 2242.27s
                               ETA: 1033.8s

################################################################################
                     [1m Learning iteration 2054/3000 [0m                     

                       Computation: 89299 steps/s (collection: 0.971s, learning 0.130s)
               Value function loss: 0.5223
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8331
                     Learning rate: 0.0004
                       Mean reward: 141.62
               Mean episode length: 994.17
       Episode_Reward/keep_balance: 0.9941
     Episode_Reward/rew_lin_vel_xy: 6.3984
      Episode_Reward/rew_ang_vel_z: 2.5952
    Episode_Reward/pen_base_height: -0.2838
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1512
   Episode_Reward/pen_joint_torque: -0.2315
    Episode_Reward/pen_joint_accel: -0.1106
    Episode_Reward/pen_action_rate: -0.1163
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0563
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2530
Episode_Reward/pen_flat_orientation: -0.0989
  Episode_Reward/pen_feet_distance: -0.0384
Episode_Reward/pen_feet_regulation: -0.4815
   Episode_Reward/foot_landing_vel: -0.1244
   Episode_Reward/test_gait_reward: -0.9204
Metrics/base_velocity/error_vel_xy: 0.9059
Metrics/base_velocity/error_vel_yaw: 1.2406
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 202014720
                    Iteration time: 1.10s
                        Total time: 2243.37s
                               ETA: 1032.7s

################################################################################
                     [1m Learning iteration 2055/3000 [0m                     

                       Computation: 89410 steps/s (collection: 0.970s, learning 0.129s)
               Value function loss: 0.5321
                    Surrogate loss: -0.0055
             Mean action noise std: 0.8331
                     Learning rate: 0.0009
                       Mean reward: 141.43
               Mean episode length: 989.98
       Episode_Reward/keep_balance: 0.9915
     Episode_Reward/rew_lin_vel_xy: 6.4234
      Episode_Reward/rew_ang_vel_z: 2.6369
    Episode_Reward/pen_base_height: -0.2882
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1439
   Episode_Reward/pen_joint_torque: -0.2435
    Episode_Reward/pen_joint_accel: -0.0993
    Episode_Reward/pen_action_rate: -0.1153
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2458
Episode_Reward/pen_flat_orientation: -0.0914
  Episode_Reward/pen_feet_distance: -0.0402
Episode_Reward/pen_feet_regulation: -0.4713
   Episode_Reward/foot_landing_vel: -0.1208
   Episode_Reward/test_gait_reward: -0.9064
Metrics/base_velocity/error_vel_xy: 0.8905
Metrics/base_velocity/error_vel_yaw: 1.2081
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 202113024
                    Iteration time: 1.10s
                        Total time: 2244.47s
                               ETA: 1031.6s

################################################################################
                     [1m Learning iteration 2056/3000 [0m                     

                       Computation: 91929 steps/s (collection: 0.946s, learning 0.123s)
               Value function loss: 0.5985
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8335
                     Learning rate: 0.0004
                       Mean reward: 140.34
               Mean episode length: 982.20
       Episode_Reward/keep_balance: 0.9745
     Episode_Reward/rew_lin_vel_xy: 6.3002
      Episode_Reward/rew_ang_vel_z: 2.5608
    Episode_Reward/pen_base_height: -0.2767
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1500
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.0953
    Episode_Reward/pen_action_rate: -0.1134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2438
Episode_Reward/pen_flat_orientation: -0.0958
  Episode_Reward/pen_feet_distance: -0.0344
Episode_Reward/pen_feet_regulation: -0.4794
   Episode_Reward/foot_landing_vel: -0.1218
   Episode_Reward/test_gait_reward: -0.8927
Metrics/base_velocity/error_vel_xy: 0.8833
Metrics/base_velocity/error_vel_yaw: 1.2189
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 202211328
                    Iteration time: 1.07s
                        Total time: 2245.54s
                               ETA: 1030.5s

################################################################################
                     [1m Learning iteration 2057/3000 [0m                     

                       Computation: 88180 steps/s (collection: 0.985s, learning 0.129s)
               Value function loss: 0.5567
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8335
                     Learning rate: 0.0004
                       Mean reward: 140.09
               Mean episode length: 966.86
       Episode_Reward/keep_balance: 0.9608
     Episode_Reward/rew_lin_vel_xy: 6.2261
      Episode_Reward/rew_ang_vel_z: 2.5448
    Episode_Reward/pen_base_height: -0.2756
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1452
   Episode_Reward/pen_joint_torque: -0.2282
    Episode_Reward/pen_joint_accel: -0.1012
    Episode_Reward/pen_action_rate: -0.1118
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0535
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2400
Episode_Reward/pen_flat_orientation: -0.0902
  Episode_Reward/pen_feet_distance: -0.0361
Episode_Reward/pen_feet_regulation: -0.4693
   Episode_Reward/foot_landing_vel: -0.1223
   Episode_Reward/test_gait_reward: -0.8716
Metrics/base_velocity/error_vel_xy: 0.8697
Metrics/base_velocity/error_vel_yaw: 1.1887
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 202309632
                    Iteration time: 1.11s
                        Total time: 2246.65s
                               ETA: 1029.4s

################################################################################
                     [1m Learning iteration 2058/3000 [0m                     

                       Computation: 88986 steps/s (collection: 0.976s, learning 0.129s)
               Value function loss: 0.5498
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8342
                     Learning rate: 0.0003
                       Mean reward: 137.58
               Mean episode length: 975.80
       Episode_Reward/keep_balance: 0.9850
     Episode_Reward/rew_lin_vel_xy: 6.2957
      Episode_Reward/rew_ang_vel_z: 2.6142
    Episode_Reward/pen_base_height: -0.2899
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1571
   Episode_Reward/pen_joint_torque: -0.2215
    Episode_Reward/pen_joint_accel: -0.0979
    Episode_Reward/pen_action_rate: -0.1142
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2467
Episode_Reward/pen_flat_orientation: -0.0962
  Episode_Reward/pen_feet_distance: -0.0330
Episode_Reward/pen_feet_regulation: -0.4883
   Episode_Reward/foot_landing_vel: -0.1252
   Episode_Reward/test_gait_reward: -0.8959
Metrics/base_velocity/error_vel_xy: 0.9258
Metrics/base_velocity/error_vel_yaw: 1.2026
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 202407936
                    Iteration time: 1.10s
                        Total time: 2247.76s
                               ETA: 1028.4s

################################################################################
                     [1m Learning iteration 2059/3000 [0m                     

                       Computation: 88853 steps/s (collection: 0.977s, learning 0.129s)
               Value function loss: 0.6385
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8332
                     Learning rate: 0.0004
                       Mean reward: 140.81
               Mean episode length: 983.90
       Episode_Reward/keep_balance: 0.9874
     Episode_Reward/rew_lin_vel_xy: 6.4168
      Episode_Reward/rew_ang_vel_z: 2.6218
    Episode_Reward/pen_base_height: -0.2801
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.1484
   Episode_Reward/pen_joint_torque: -0.2302
    Episode_Reward/pen_joint_accel: -0.1081
    Episode_Reward/pen_action_rate: -0.1135
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0857
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2453
Episode_Reward/pen_flat_orientation: -0.0906
  Episode_Reward/pen_feet_distance: -0.0337
Episode_Reward/pen_feet_regulation: -0.4837
   Episode_Reward/foot_landing_vel: -0.1251
   Episode_Reward/test_gait_reward: -0.9037
Metrics/base_velocity/error_vel_xy: 0.8773
Metrics/base_velocity/error_vel_yaw: 1.2009
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 202506240
                    Iteration time: 1.11s
                        Total time: 2248.86s
                               ETA: 1027.3s

################################################################################
                     [1m Learning iteration 2060/3000 [0m                     

                       Computation: 87486 steps/s (collection: 0.994s, learning 0.130s)
               Value function loss: 0.5786
                    Surrogate loss: -0.0008
             Mean action noise std: 0.8324
                     Learning rate: 0.0001
                       Mean reward: 136.06
               Mean episode length: 959.96
       Episode_Reward/keep_balance: 0.9627
     Episode_Reward/rew_lin_vel_xy: 6.2106
      Episode_Reward/rew_ang_vel_z: 2.5383
    Episode_Reward/pen_base_height: -0.2786
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1478
   Episode_Reward/pen_joint_torque: -0.2253
    Episode_Reward/pen_joint_accel: -0.1074
    Episode_Reward/pen_action_rate: -0.1109
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0534
   Episode_Reward/pen_joint_powers: -0.0848
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2393
Episode_Reward/pen_flat_orientation: -0.0963
  Episode_Reward/pen_feet_distance: -0.0272
Episode_Reward/pen_feet_regulation: -0.4617
   Episode_Reward/foot_landing_vel: -0.1252
   Episode_Reward/test_gait_reward: -0.8839
Metrics/base_velocity/error_vel_xy: 0.8718
Metrics/base_velocity/error_vel_yaw: 1.1983
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 202604544
                    Iteration time: 1.12s
                        Total time: 2249.99s
                               ETA: 1026.2s

################################################################################
                     [1m Learning iteration 2061/3000 [0m                     

                       Computation: 87634 steps/s (collection: 0.995s, learning 0.127s)
               Value function loss: 0.4912
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8327
                     Learning rate: 0.0003
                       Mean reward: 138.06
               Mean episode length: 968.92
       Episode_Reward/keep_balance: 0.9680
     Episode_Reward/rew_lin_vel_xy: 6.2718
      Episode_Reward/rew_ang_vel_z: 2.5668
    Episode_Reward/pen_base_height: -0.2867
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1513
   Episode_Reward/pen_joint_torque: -0.2269
    Episode_Reward/pen_joint_accel: -0.0989
    Episode_Reward/pen_action_rate: -0.1118
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0534
   Episode_Reward/pen_joint_powers: -0.0844
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2414
Episode_Reward/pen_flat_orientation: -0.0996
  Episode_Reward/pen_feet_distance: -0.0323
Episode_Reward/pen_feet_regulation: -0.4607
   Episode_Reward/foot_landing_vel: -0.1285
   Episode_Reward/test_gait_reward: -0.8772
Metrics/base_velocity/error_vel_xy: 0.8629
Metrics/base_velocity/error_vel_yaw: 1.1901
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 202702848
                    Iteration time: 1.12s
                        Total time: 2251.11s
                               ETA: 1025.1s

################################################################################
                     [1m Learning iteration 2062/3000 [0m                     

                       Computation: 87928 steps/s (collection: 0.995s, learning 0.123s)
               Value function loss: 0.5150
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8331
                     Learning rate: 0.0003
                       Mean reward: 145.13
               Mean episode length: 996.01
       Episode_Reward/keep_balance: 0.9930
     Episode_Reward/rew_lin_vel_xy: 6.4124
      Episode_Reward/rew_ang_vel_z: 2.6565
    Episode_Reward/pen_base_height: -0.2833
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1507
   Episode_Reward/pen_joint_torque: -0.2277
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.1133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0533
   Episode_Reward/pen_joint_powers: -0.0849
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2438
Episode_Reward/pen_flat_orientation: -0.0931
  Episode_Reward/pen_feet_distance: -0.0359
Episode_Reward/pen_feet_regulation: -0.4504
   Episode_Reward/foot_landing_vel: -0.1250
   Episode_Reward/test_gait_reward: -0.9017
Metrics/base_velocity/error_vel_xy: 0.8887
Metrics/base_velocity/error_vel_yaw: 1.1928
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 202801152
                    Iteration time: 1.12s
                        Total time: 2252.23s
                               ETA: 1024.0s

################################################################################
                     [1m Learning iteration 2063/3000 [0m                     

                       Computation: 87544 steps/s (collection: 1.000s, learning 0.123s)
               Value function loss: 0.5392
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8332
                     Learning rate: 0.0006
                       Mean reward: 141.80
               Mean episode length: 991.00
       Episode_Reward/keep_balance: 0.9920
     Episode_Reward/rew_lin_vel_xy: 6.3984
      Episode_Reward/rew_ang_vel_z: 2.6144
    Episode_Reward/pen_base_height: -0.2830
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1451
   Episode_Reward/pen_joint_torque: -0.2323
    Episode_Reward/pen_joint_accel: -0.1014
    Episode_Reward/pen_action_rate: -0.1140
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0863
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2461
Episode_Reward/pen_flat_orientation: -0.0945
  Episode_Reward/pen_feet_distance: -0.0320
Episode_Reward/pen_feet_regulation: -0.4819
   Episode_Reward/foot_landing_vel: -0.1281
   Episode_Reward/test_gait_reward: -0.9083
Metrics/base_velocity/error_vel_xy: 0.9125
Metrics/base_velocity/error_vel_yaw: 1.2274
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 202899456
                    Iteration time: 1.12s
                        Total time: 2253.35s
                               ETA: 1023.0s

################################################################################
                     [1m Learning iteration 2064/3000 [0m                     

                       Computation: 89407 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.5523
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8326
                     Learning rate: 0.0004
                       Mean reward: 141.53
               Mean episode length: 986.84
       Episode_Reward/keep_balance: 0.9882
     Episode_Reward/rew_lin_vel_xy: 6.4349
      Episode_Reward/rew_ang_vel_z: 2.6394
    Episode_Reward/pen_base_height: -0.2898
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1489
   Episode_Reward/pen_joint_torque: -0.2363
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.1137
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2429
Episode_Reward/pen_flat_orientation: -0.0940
  Episode_Reward/pen_feet_distance: -0.0384
Episode_Reward/pen_feet_regulation: -0.4814
   Episode_Reward/foot_landing_vel: -0.1272
   Episode_Reward/test_gait_reward: -0.8977
Metrics/base_velocity/error_vel_xy: 0.8796
Metrics/base_velocity/error_vel_yaw: 1.1873
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 202997760
                    Iteration time: 1.10s
                        Total time: 2254.45s
                               ETA: 1021.9s

################################################################################
                     [1m Learning iteration 2065/3000 [0m                     

                       Computation: 90150 steps/s (collection: 0.968s, learning 0.123s)
               Value function loss: 0.5248
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8319
                     Learning rate: 0.0003
                       Mean reward: 138.41
               Mean episode length: 980.69
       Episode_Reward/keep_balance: 0.9769
     Episode_Reward/rew_lin_vel_xy: 6.3318
      Episode_Reward/rew_ang_vel_z: 2.5635
    Episode_Reward/pen_base_height: -0.2848
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1440
   Episode_Reward/pen_joint_torque: -0.2313
    Episode_Reward/pen_joint_accel: -0.1061
    Episode_Reward/pen_action_rate: -0.1129
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2418
Episode_Reward/pen_flat_orientation: -0.0946
  Episode_Reward/pen_feet_distance: -0.0314
Episode_Reward/pen_feet_regulation: -0.4828
   Episode_Reward/foot_landing_vel: -0.1249
   Episode_Reward/test_gait_reward: -0.9017
Metrics/base_velocity/error_vel_xy: 0.8777
Metrics/base_velocity/error_vel_yaw: 1.2202
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 203096064
                    Iteration time: 1.09s
                        Total time: 2255.54s
                               ETA: 1020.8s

################################################################################
                     [1m Learning iteration 2066/3000 [0m                     

                       Computation: 88503 steps/s (collection: 0.987s, learning 0.124s)
               Value function loss: 0.4600
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8321
                     Learning rate: 0.0006
                       Mean reward: 143.45
               Mean episode length: 999.68
       Episode_Reward/keep_balance: 0.9997
     Episode_Reward/rew_lin_vel_xy: 6.5037
      Episode_Reward/rew_ang_vel_z: 2.6910
    Episode_Reward/pen_base_height: -0.3007
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1468
   Episode_Reward/pen_joint_torque: -0.2451
    Episode_Reward/pen_joint_accel: -0.1070
    Episode_Reward/pen_action_rate: -0.1146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0540
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2436
Episode_Reward/pen_flat_orientation: -0.0921
  Episode_Reward/pen_feet_distance: -0.0355
Episode_Reward/pen_feet_regulation: -0.4903
   Episode_Reward/foot_landing_vel: -0.1222
   Episode_Reward/test_gait_reward: -0.9167
Metrics/base_velocity/error_vel_xy: 0.8843
Metrics/base_velocity/error_vel_yaw: 1.1730
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 203194368
                    Iteration time: 1.11s
                        Total time: 2256.65s
                               ETA: 1019.7s

################################################################################
                     [1m Learning iteration 2067/3000 [0m                     

                       Computation: 84135 steps/s (collection: 1.046s, learning 0.123s)
               Value function loss: 0.5861
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8321
                     Learning rate: 0.0004
                       Mean reward: 139.99
               Mean episode length: 982.27
       Episode_Reward/keep_balance: 0.9843
     Episode_Reward/rew_lin_vel_xy: 6.3413
      Episode_Reward/rew_ang_vel_z: 2.5735
    Episode_Reward/pen_base_height: -0.2845
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1496
   Episode_Reward/pen_joint_torque: -0.2316
    Episode_Reward/pen_joint_accel: -0.1081
    Episode_Reward/pen_action_rate: -0.1142
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2442
Episode_Reward/pen_flat_orientation: -0.0918
  Episode_Reward/pen_feet_distance: -0.0362
Episode_Reward/pen_feet_regulation: -0.4750
   Episode_Reward/foot_landing_vel: -0.1226
   Episode_Reward/test_gait_reward: -0.9040
Metrics/base_velocity/error_vel_xy: 0.8971
Metrics/base_velocity/error_vel_yaw: 1.2401
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 203292672
                    Iteration time: 1.17s
                        Total time: 2257.82s
                               ETA: 1018.6s

################################################################################
                     [1m Learning iteration 2068/3000 [0m                     

                       Computation: 88898 steps/s (collection: 0.982s, learning 0.124s)
               Value function loss: 0.4909
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8316
                     Learning rate: 0.0006
                       Mean reward: 140.64
               Mean episode length: 982.65
       Episode_Reward/keep_balance: 0.9883
     Episode_Reward/rew_lin_vel_xy: 6.4189
      Episode_Reward/rew_ang_vel_z: 2.6401
    Episode_Reward/pen_base_height: -0.2843
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1464
   Episode_Reward/pen_joint_torque: -0.2247
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.1127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0537
   Episode_Reward/pen_joint_powers: -0.0846
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2421
Episode_Reward/pen_flat_orientation: -0.0887
  Episode_Reward/pen_feet_distance: -0.0376
Episode_Reward/pen_feet_regulation: -0.4679
   Episode_Reward/foot_landing_vel: -0.1275
   Episode_Reward/test_gait_reward: -0.9030
Metrics/base_velocity/error_vel_xy: 0.8842
Metrics/base_velocity/error_vel_yaw: 1.1912
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 203390976
                    Iteration time: 1.11s
                        Total time: 2258.92s
                               ETA: 1017.6s

################################################################################
                     [1m Learning iteration 2069/3000 [0m                     

                       Computation: 91174 steps/s (collection: 0.956s, learning 0.122s)
               Value function loss: 0.5083
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8328
                     Learning rate: 0.0003
                       Mean reward: 143.33
               Mean episode length: 991.53
       Episode_Reward/keep_balance: 0.9913
     Episode_Reward/rew_lin_vel_xy: 6.4048
      Episode_Reward/rew_ang_vel_z: 2.6389
    Episode_Reward/pen_base_height: -0.2762
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1463
   Episode_Reward/pen_joint_torque: -0.2259
    Episode_Reward/pen_joint_accel: -0.0948
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0533
   Episode_Reward/pen_joint_powers: -0.0835
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2402
Episode_Reward/pen_flat_orientation: -0.0918
  Episode_Reward/pen_feet_distance: -0.0317
Episode_Reward/pen_feet_regulation: -0.4671
   Episode_Reward/foot_landing_vel: -0.1241
   Episode_Reward/test_gait_reward: -0.9078
Metrics/base_velocity/error_vel_xy: 0.8898
Metrics/base_velocity/error_vel_yaw: 1.2043
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 203489280
                    Iteration time: 1.08s
                        Total time: 2260.00s
                               ETA: 1016.5s

################################################################################
                     [1m Learning iteration 2070/3000 [0m                     

                       Computation: 88978 steps/s (collection: 0.983s, learning 0.122s)
               Value function loss: 0.5387
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8335
                     Learning rate: 0.0006
                       Mean reward: 141.90
               Mean episode length: 992.95
       Episode_Reward/keep_balance: 0.9837
     Episode_Reward/rew_lin_vel_xy: 6.3443
      Episode_Reward/rew_ang_vel_z: 2.6557
    Episode_Reward/pen_base_height: -0.3066
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.1531
   Episode_Reward/pen_joint_torque: -0.2346
    Episode_Reward/pen_joint_accel: -0.1047
    Episode_Reward/pen_action_rate: -0.1122
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0533
   Episode_Reward/pen_joint_powers: -0.0849
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.2372
Episode_Reward/pen_flat_orientation: -0.0993
  Episode_Reward/pen_feet_distance: -0.0339
Episode_Reward/pen_feet_regulation: -0.4619
   Episode_Reward/foot_landing_vel: -0.1212
   Episode_Reward/test_gait_reward: -0.8969
Metrics/base_velocity/error_vel_xy: 0.9041
Metrics/base_velocity/error_vel_yaw: 1.1755
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 203587584
                    Iteration time: 1.10s
                        Total time: 2261.11s
                               ETA: 1015.4s

################################################################################
                     [1m Learning iteration 2071/3000 [0m                     

                       Computation: 90409 steps/s (collection: 0.966s, learning 0.122s)
               Value function loss: 0.5475
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8331
                     Learning rate: 0.0004
                       Mean reward: 144.59
               Mean episode length: 994.04
       Episode_Reward/keep_balance: 0.9970
     Episode_Reward/rew_lin_vel_xy: 6.4728
      Episode_Reward/rew_ang_vel_z: 2.6809
    Episode_Reward/pen_base_height: -0.2857
      Episode_Reward/pen_lin_vel_z: -0.0360
     Episode_Reward/pen_ang_vel_xy: -0.1479
   Episode_Reward/pen_joint_torque: -0.2348
    Episode_Reward/pen_joint_accel: -0.1016
    Episode_Reward/pen_action_rate: -0.1123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0531
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2401
Episode_Reward/pen_flat_orientation: -0.0886
  Episode_Reward/pen_feet_distance: -0.0379
Episode_Reward/pen_feet_regulation: -0.4523
   Episode_Reward/foot_landing_vel: -0.1195
   Episode_Reward/test_gait_reward: -0.9061
Metrics/base_velocity/error_vel_xy: 0.8869
Metrics/base_velocity/error_vel_yaw: 1.1857
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 203685888
                    Iteration time: 1.09s
                        Total time: 2262.19s
                               ETA: 1014.3s

################################################################################
                     [1m Learning iteration 2072/3000 [0m                     

                       Computation: 91103 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.4735
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8331
                     Learning rate: 0.0006
                       Mean reward: 145.29
               Mean episode length: 990.48
       Episode_Reward/keep_balance: 0.9922
     Episode_Reward/rew_lin_vel_xy: 6.4828
      Episode_Reward/rew_ang_vel_z: 2.6917
    Episode_Reward/pen_base_height: -0.2741
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1493
   Episode_Reward/pen_joint_torque: -0.2257
    Episode_Reward/pen_joint_accel: -0.1054
    Episode_Reward/pen_action_rate: -0.1112
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0530
   Episode_Reward/pen_joint_powers: -0.0839
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2392
Episode_Reward/pen_flat_orientation: -0.0898
  Episode_Reward/pen_feet_distance: -0.0367
Episode_Reward/pen_feet_regulation: -0.4550
   Episode_Reward/foot_landing_vel: -0.1284
   Episode_Reward/test_gait_reward: -0.8963
Metrics/base_velocity/error_vel_xy: 0.8578
Metrics/base_velocity/error_vel_yaw: 1.1535
      Episode_Termination/time_out: 4.6667
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 203784192
                    Iteration time: 1.08s
                        Total time: 2263.27s
                               ETA: 1013.2s

################################################################################
                     [1m Learning iteration 2073/3000 [0m                     

                       Computation: 86233 steps/s (collection: 1.011s, learning 0.129s)
               Value function loss: 0.5200
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8351
                     Learning rate: 0.0006
                       Mean reward: 145.33
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4712
      Episode_Reward/rew_ang_vel_z: 2.7007
    Episode_Reward/pen_base_height: -0.2920
      Episode_Reward/pen_lin_vel_z: -0.0391
     Episode_Reward/pen_ang_vel_xy: -0.1413
   Episode_Reward/pen_joint_torque: -0.2450
    Episode_Reward/pen_joint_accel: -0.1060
    Episode_Reward/pen_action_rate: -0.1131
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0877
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2414
Episode_Reward/pen_flat_orientation: -0.0892
  Episode_Reward/pen_feet_distance: -0.0374
Episode_Reward/pen_feet_regulation: -0.4739
   Episode_Reward/foot_landing_vel: -0.1307
   Episode_Reward/test_gait_reward: -0.9071
Metrics/base_velocity/error_vel_xy: 0.8930
Metrics/base_velocity/error_vel_yaw: 1.1714
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 203882496
                    Iteration time: 1.14s
                        Total time: 2264.41s
                               ETA: 1012.1s

################################################################################
                     [1m Learning iteration 2074/3000 [0m                     

                       Computation: 90615 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.4894
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8351
                     Learning rate: 0.0003
                       Mean reward: 139.70
               Mean episode length: 978.08
       Episode_Reward/keep_balance: 0.9845
     Episode_Reward/rew_lin_vel_xy: 6.3624
      Episode_Reward/rew_ang_vel_z: 2.6412
    Episode_Reward/pen_base_height: -0.2963
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1436
   Episode_Reward/pen_joint_torque: -0.2328
    Episode_Reward/pen_joint_accel: -0.0973
    Episode_Reward/pen_action_rate: -0.1119
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0526
   Episode_Reward/pen_joint_powers: -0.0847
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2373
Episode_Reward/pen_flat_orientation: -0.0896
  Episode_Reward/pen_feet_distance: -0.0342
Episode_Reward/pen_feet_regulation: -0.4686
   Episode_Reward/foot_landing_vel: -0.1213
   Episode_Reward/test_gait_reward: -0.8964
Metrics/base_velocity/error_vel_xy: 0.8976
Metrics/base_velocity/error_vel_yaw: 1.1749
      Episode_Termination/time_out: 4.9167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 203980800
                    Iteration time: 1.08s
                        Total time: 2265.50s
                               ETA: 1011.0s

################################################################################
                     [1m Learning iteration 2075/3000 [0m                     

                       Computation: 90919 steps/s (collection: 0.959s, learning 0.122s)
               Value function loss: 0.5559
                    Surrogate loss: -0.0057
             Mean action noise std: 0.8352
                     Learning rate: 0.0006
                       Mean reward: 141.60
               Mean episode length: 992.68
       Episode_Reward/keep_balance: 0.9939
     Episode_Reward/rew_lin_vel_xy: 6.4313
      Episode_Reward/rew_ang_vel_z: 2.6458
    Episode_Reward/pen_base_height: -0.2861
      Episode_Reward/pen_lin_vel_z: -0.0370
     Episode_Reward/pen_ang_vel_xy: -0.1423
   Episode_Reward/pen_joint_torque: -0.2431
    Episode_Reward/pen_joint_accel: -0.0986
    Episode_Reward/pen_action_rate: -0.1138
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0540
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2419
Episode_Reward/pen_flat_orientation: -0.0933
  Episode_Reward/pen_feet_distance: -0.0363
Episode_Reward/pen_feet_regulation: -0.4786
   Episode_Reward/foot_landing_vel: -0.1135
   Episode_Reward/test_gait_reward: -0.9128
Metrics/base_velocity/error_vel_xy: 0.8834
Metrics/base_velocity/error_vel_yaw: 1.2038
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 204079104
                    Iteration time: 1.08s
                        Total time: 2266.58s
                               ETA: 1009.9s

################################################################################
                     [1m Learning iteration 2076/3000 [0m                     

                       Computation: 90060 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 0.5005
                    Surrogate loss: -0.0050
             Mean action noise std: 0.8354
                     Learning rate: 0.0006
                       Mean reward: 141.69
               Mean episode length: 976.55
       Episode_Reward/keep_balance: 0.9655
     Episode_Reward/rew_lin_vel_xy: 6.2441
      Episode_Reward/rew_ang_vel_z: 2.6047
    Episode_Reward/pen_base_height: -0.2781
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1416
   Episode_Reward/pen_joint_torque: -0.2257
    Episode_Reward/pen_joint_accel: -0.1033
    Episode_Reward/pen_action_rate: -0.1087
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0509
   Episode_Reward/pen_joint_powers: -0.0816
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2342
Episode_Reward/pen_flat_orientation: -0.0896
  Episode_Reward/pen_feet_distance: -0.0326
Episode_Reward/pen_feet_regulation: -0.4414
   Episode_Reward/foot_landing_vel: -0.1179
   Episode_Reward/test_gait_reward: -0.8775
Metrics/base_velocity/error_vel_xy: 0.8677
Metrics/base_velocity/error_vel_yaw: 1.1380
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 204177408
                    Iteration time: 1.09s
                        Total time: 2267.67s
                               ETA: 1008.8s

################################################################################
                     [1m Learning iteration 2077/3000 [0m                     

                       Computation: 89479 steps/s (collection: 0.976s, learning 0.123s)
               Value function loss: 0.5271
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8345
                     Learning rate: 0.0004
                       Mean reward: 139.69
               Mean episode length: 979.04
       Episode_Reward/keep_balance: 0.9731
     Episode_Reward/rew_lin_vel_xy: 6.2424
      Episode_Reward/rew_ang_vel_z: 2.6061
    Episode_Reward/pen_base_height: -0.2863
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1472
   Episode_Reward/pen_joint_torque: -0.2284
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1114
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0855
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2377
Episode_Reward/pen_flat_orientation: -0.0928
  Episode_Reward/pen_feet_distance: -0.0382
Episode_Reward/pen_feet_regulation: -0.4726
   Episode_Reward/foot_landing_vel: -0.1236
   Episode_Reward/test_gait_reward: -0.8901
Metrics/base_velocity/error_vel_xy: 0.8963
Metrics/base_velocity/error_vel_yaw: 1.1651
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 204275712
                    Iteration time: 1.10s
                        Total time: 2268.77s
                               ETA: 1007.7s

################################################################################
                     [1m Learning iteration 2078/3000 [0m                     

                       Computation: 89007 steps/s (collection: 0.975s, learning 0.129s)
               Value function loss: 0.5169
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8349
                     Learning rate: 0.0004
                       Mean reward: 143.50
               Mean episode length: 991.74
       Episode_Reward/keep_balance: 0.9981
     Episode_Reward/rew_lin_vel_xy: 6.5311
      Episode_Reward/rew_ang_vel_z: 2.6805
    Episode_Reward/pen_base_height: -0.2867
      Episode_Reward/pen_lin_vel_z: -0.0353
     Episode_Reward/pen_ang_vel_xy: -0.1426
   Episode_Reward/pen_joint_torque: -0.2304
    Episode_Reward/pen_joint_accel: -0.1034
    Episode_Reward/pen_action_rate: -0.1142
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0539
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2449
Episode_Reward/pen_flat_orientation: -0.0888
  Episode_Reward/pen_feet_distance: -0.0344
Episode_Reward/pen_feet_regulation: -0.4670
   Episode_Reward/foot_landing_vel: -0.1260
   Episode_Reward/test_gait_reward: -0.9120
Metrics/base_velocity/error_vel_xy: 0.8537
Metrics/base_velocity/error_vel_yaw: 1.1943
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 204374016
                    Iteration time: 1.10s
                        Total time: 2269.87s
                               ETA: 1006.6s

################################################################################
                     [1m Learning iteration 2079/3000 [0m                     

                       Computation: 88357 steps/s (collection: 0.987s, learning 0.126s)
               Value function loss: 0.4990
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8356
                     Learning rate: 0.0006
                       Mean reward: 143.02
               Mean episode length: 996.45
       Episode_Reward/keep_balance: 0.9852
     Episode_Reward/rew_lin_vel_xy: 6.3803
      Episode_Reward/rew_ang_vel_z: 2.5813
    Episode_Reward/pen_base_height: -0.2888
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1465
   Episode_Reward/pen_joint_torque: -0.2294
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1120
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0533
   Episode_Reward/pen_joint_powers: -0.0854
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2412
Episode_Reward/pen_flat_orientation: -0.0907
  Episode_Reward/pen_feet_distance: -0.0348
Episode_Reward/pen_feet_regulation: -0.4707
   Episode_Reward/foot_landing_vel: -0.1229
   Episode_Reward/test_gait_reward: -0.9036
Metrics/base_velocity/error_vel_xy: 0.8774
Metrics/base_velocity/error_vel_yaw: 1.2313
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 204472320
                    Iteration time: 1.11s
                        Total time: 2270.99s
                               ETA: 1005.6s

################################################################################
                     [1m Learning iteration 2080/3000 [0m                     

                       Computation: 87364 steps/s (collection: 0.996s, learning 0.129s)
               Value function loss: 0.4590
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8359
                     Learning rate: 0.0004
                       Mean reward: 143.33
               Mean episode length: 996.70
       Episode_Reward/keep_balance: 0.9971
     Episode_Reward/rew_lin_vel_xy: 6.4291
      Episode_Reward/rew_ang_vel_z: 2.7188
    Episode_Reward/pen_base_height: -0.2886
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1441
   Episode_Reward/pen_joint_torque: -0.2375
    Episode_Reward/pen_joint_accel: -0.0966
    Episode_Reward/pen_action_rate: -0.1109
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0520
   Episode_Reward/pen_joint_powers: -0.0839
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2378
Episode_Reward/pen_flat_orientation: -0.0922
  Episode_Reward/pen_feet_distance: -0.0358
Episode_Reward/pen_feet_regulation: -0.4536
   Episode_Reward/foot_landing_vel: -0.1199
   Episode_Reward/test_gait_reward: -0.8975
Metrics/base_velocity/error_vel_xy: 0.9128
Metrics/base_velocity/error_vel_yaw: 1.1546
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 204570624
                    Iteration time: 1.13s
                        Total time: 2272.11s
                               ETA: 1004.5s

################################################################################
                     [1m Learning iteration 2081/3000 [0m                     

                       Computation: 88342 steps/s (collection: 0.983s, learning 0.129s)
               Value function loss: 0.4835
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8348
                     Learning rate: 0.0006
                       Mean reward: 143.70
               Mean episode length: 993.87
       Episode_Reward/keep_balance: 0.9968
     Episode_Reward/rew_lin_vel_xy: 6.4516
      Episode_Reward/rew_ang_vel_z: 2.6908
    Episode_Reward/pen_base_height: -0.2832
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1457
   Episode_Reward/pen_joint_torque: -0.2276
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1120
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0857
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2402
Episode_Reward/pen_flat_orientation: -0.0923
  Episode_Reward/pen_feet_distance: -0.0391
Episode_Reward/pen_feet_regulation: -0.4704
   Episode_Reward/foot_landing_vel: -0.1295
   Episode_Reward/test_gait_reward: -0.9050
Metrics/base_velocity/error_vel_xy: 0.8905
Metrics/base_velocity/error_vel_yaw: 1.1695
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 204668928
                    Iteration time: 1.11s
                        Total time: 2273.22s
                               ETA: 1003.4s

################################################################################
                     [1m Learning iteration 2082/3000 [0m                     

                       Computation: 86465 steps/s (collection: 1.008s, learning 0.129s)
               Value function loss: 0.5433
                    Surrogate loss: -0.0014
             Mean action noise std: 0.8355
                     Learning rate: 0.0003
                       Mean reward: 141.50
               Mean episode length: 972.62
       Episode_Reward/keep_balance: 0.9765
     Episode_Reward/rew_lin_vel_xy: 6.3543
      Episode_Reward/rew_ang_vel_z: 2.6229
    Episode_Reward/pen_base_height: -0.2814
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1405
   Episode_Reward/pen_joint_torque: -0.2313
    Episode_Reward/pen_joint_accel: -0.1031
    Episode_Reward/pen_action_rate: -0.1107
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0519
   Episode_Reward/pen_joint_powers: -0.0840
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2369
Episode_Reward/pen_flat_orientation: -0.0912
  Episode_Reward/pen_feet_distance: -0.0323
Episode_Reward/pen_feet_regulation: -0.4463
   Episode_Reward/foot_landing_vel: -0.1214
   Episode_Reward/test_gait_reward: -0.8826
Metrics/base_velocity/error_vel_xy: 0.8586
Metrics/base_velocity/error_vel_yaw: 1.1530
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 204767232
                    Iteration time: 1.14s
                        Total time: 2274.36s
                               ETA: 1002.3s

################################################################################
                     [1m Learning iteration 2083/3000 [0m                     

                       Computation: 89088 steps/s (collection: 0.974s, learning 0.129s)
               Value function loss: 0.4878
                    Surrogate loss: -0.0016
             Mean action noise std: 0.8352
                     Learning rate: 0.0002
                       Mean reward: 140.24
               Mean episode length: 986.41
       Episode_Reward/keep_balance: 0.9906
     Episode_Reward/rew_lin_vel_xy: 6.3772
      Episode_Reward/rew_ang_vel_z: 2.6554
    Episode_Reward/pen_base_height: -0.2991
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1453
   Episode_Reward/pen_joint_torque: -0.2326
    Episode_Reward/pen_joint_accel: -0.1049
    Episode_Reward/pen_action_rate: -0.1129
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2410
Episode_Reward/pen_flat_orientation: -0.0934
  Episode_Reward/pen_feet_distance: -0.0380
Episode_Reward/pen_feet_regulation: -0.4985
   Episode_Reward/foot_landing_vel: -0.1208
   Episode_Reward/test_gait_reward: -0.9078
Metrics/base_velocity/error_vel_xy: 0.9192
Metrics/base_velocity/error_vel_yaw: 1.1813
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 204865536
                    Iteration time: 1.10s
                        Total time: 2275.47s
                               ETA: 1001.2s

################################################################################
                     [1m Learning iteration 2084/3000 [0m                     

                       Computation: 87288 steps/s (collection: 0.997s, learning 0.129s)
               Value function loss: 0.5223
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8353
                     Learning rate: 0.0003
                       Mean reward: 140.83
               Mean episode length: 995.25
       Episode_Reward/keep_balance: 0.9954
     Episode_Reward/rew_lin_vel_xy: 6.4189
      Episode_Reward/rew_ang_vel_z: 2.6420
    Episode_Reward/pen_base_height: -0.2967
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1534
   Episode_Reward/pen_joint_torque: -0.2282
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.1134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0859
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2430
Episode_Reward/pen_flat_orientation: -0.0917
  Episode_Reward/pen_feet_distance: -0.0364
Episode_Reward/pen_feet_regulation: -0.4766
   Episode_Reward/foot_landing_vel: -0.1230
   Episode_Reward/test_gait_reward: -0.9165
Metrics/base_velocity/error_vel_xy: 0.9214
Metrics/base_velocity/error_vel_yaw: 1.2159
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 204963840
                    Iteration time: 1.13s
                        Total time: 2276.59s
                               ETA: 1000.2s

################################################################################
                     [1m Learning iteration 2085/3000 [0m                     

                       Computation: 88645 steps/s (collection: 0.984s, learning 0.125s)
               Value function loss: 0.4788
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8365
                     Learning rate: 0.0004
                       Mean reward: 142.11
               Mean episode length: 995.29
       Episode_Reward/keep_balance: 0.9947
     Episode_Reward/rew_lin_vel_xy: 6.4050
      Episode_Reward/rew_ang_vel_z: 2.6447
    Episode_Reward/pen_base_height: -0.2920
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1460
   Episode_Reward/pen_joint_torque: -0.2318
    Episode_Reward/pen_joint_accel: -0.1051
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0545
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2403
Episode_Reward/pen_flat_orientation: -0.0904
  Episode_Reward/pen_feet_distance: -0.0373
Episode_Reward/pen_feet_regulation: -0.4851
   Episode_Reward/foot_landing_vel: -0.1233
   Episode_Reward/test_gait_reward: -0.9097
Metrics/base_velocity/error_vel_xy: 0.9132
Metrics/base_velocity/error_vel_yaw: 1.2042
      Episode_Termination/time_out: 3.3333
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 205062144
                    Iteration time: 1.11s
                        Total time: 2277.70s
                               ETA: 999.1s

################################################################################
                     [1m Learning iteration 2086/3000 [0m                     

                       Computation: 88934 steps/s (collection: 0.983s, learning 0.123s)
               Value function loss: 0.5512
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8369
                     Learning rate: 0.0004
                       Mean reward: 142.67
               Mean episode length: 980.16
       Episode_Reward/keep_balance: 0.9886
     Episode_Reward/rew_lin_vel_xy: 6.4231
      Episode_Reward/rew_ang_vel_z: 2.6545
    Episode_Reward/pen_base_height: -0.2884
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1463
   Episode_Reward/pen_joint_torque: -0.2266
    Episode_Reward/pen_joint_accel: -0.1092
    Episode_Reward/pen_action_rate: -0.1115
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0539
   Episode_Reward/pen_joint_powers: -0.0844
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2411
Episode_Reward/pen_flat_orientation: -0.0933
  Episode_Reward/pen_feet_distance: -0.0285
Episode_Reward/pen_feet_regulation: -0.4625
   Episode_Reward/foot_landing_vel: -0.1236
   Episode_Reward/test_gait_reward: -0.9056
Metrics/base_velocity/error_vel_xy: 0.8855
Metrics/base_velocity/error_vel_yaw: 1.1745
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 205160448
                    Iteration time: 1.11s
                        Total time: 2278.81s
                               ETA: 998.0s

################################################################################
                     [1m Learning iteration 2087/3000 [0m                     

                       Computation: 90334 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.5560
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8360
                     Learning rate: 0.0006
                       Mean reward: 141.38
               Mean episode length: 991.67
       Episode_Reward/keep_balance: 0.9911
     Episode_Reward/rew_lin_vel_xy: 6.3813
      Episode_Reward/rew_ang_vel_z: 2.6607
    Episode_Reward/pen_base_height: -0.2987
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1473
   Episode_Reward/pen_joint_torque: -0.2323
    Episode_Reward/pen_joint_accel: -0.0974
    Episode_Reward/pen_action_rate: -0.1123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0540
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2383
Episode_Reward/pen_flat_orientation: -0.0970
  Episode_Reward/pen_feet_distance: -0.0375
Episode_Reward/pen_feet_regulation: -0.4738
   Episode_Reward/foot_landing_vel: -0.1202
   Episode_Reward/test_gait_reward: -0.9127
Metrics/base_velocity/error_vel_xy: 0.9181
Metrics/base_velocity/error_vel_yaw: 1.1953
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 205258752
                    Iteration time: 1.09s
                        Total time: 2279.89s
                               ETA: 996.9s

################################################################################
                     [1m Learning iteration 2088/3000 [0m                     

                       Computation: 89334 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.5232
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8354
                     Learning rate: 0.0004
                       Mean reward: 141.53
               Mean episode length: 982.78
       Episode_Reward/keep_balance: 0.9718
     Episode_Reward/rew_lin_vel_xy: 6.3264
      Episode_Reward/rew_ang_vel_z: 2.5785
    Episode_Reward/pen_base_height: -0.2872
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1419
   Episode_Reward/pen_joint_torque: -0.2294
    Episode_Reward/pen_joint_accel: -0.1069
    Episode_Reward/pen_action_rate: -0.1091
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0519
   Episode_Reward/pen_joint_powers: -0.0843
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2348
Episode_Reward/pen_flat_orientation: -0.0900
  Episode_Reward/pen_feet_distance: -0.0376
Episode_Reward/pen_feet_regulation: -0.4526
   Episode_Reward/foot_landing_vel: -0.1129
   Episode_Reward/test_gait_reward: -0.8824
Metrics/base_velocity/error_vel_xy: 0.8526
Metrics/base_velocity/error_vel_yaw: 1.1857
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 205357056
                    Iteration time: 1.10s
                        Total time: 2280.99s
                               ETA: 995.8s

################################################################################
                     [1m Learning iteration 2089/3000 [0m                     

                       Computation: 90501 steps/s (collection: 0.963s, learning 0.123s)
               Value function loss: 0.4934
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8352
                     Learning rate: 0.0009
                       Mean reward: 143.79
               Mean episode length: 998.13
       Episode_Reward/keep_balance: 0.9945
     Episode_Reward/rew_lin_vel_xy: 6.4358
      Episode_Reward/rew_ang_vel_z: 2.6526
    Episode_Reward/pen_base_height: -0.2927
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1494
   Episode_Reward/pen_joint_torque: -0.2307
    Episode_Reward/pen_joint_accel: -0.1035
    Episode_Reward/pen_action_rate: -0.1130
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2426
Episode_Reward/pen_flat_orientation: -0.0955
  Episode_Reward/pen_feet_distance: -0.0296
Episode_Reward/pen_feet_regulation: -0.4948
   Episode_Reward/foot_landing_vel: -0.1235
   Episode_Reward/test_gait_reward: -0.9120
Metrics/base_velocity/error_vel_xy: 0.9063
Metrics/base_velocity/error_vel_yaw: 1.1968
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 205455360
                    Iteration time: 1.09s
                        Total time: 2282.08s
                               ETA: 994.7s

################################################################################
                     [1m Learning iteration 2090/3000 [0m                     

                       Computation: 88779 steps/s (collection: 0.984s, learning 0.123s)
               Value function loss: 0.4956
                    Surrogate loss: -0.0046
             Mean action noise std: 0.8351
                     Learning rate: 0.0006
                       Mean reward: 139.59
               Mean episode length: 989.96
       Episode_Reward/keep_balance: 0.9953
     Episode_Reward/rew_lin_vel_xy: 6.4872
      Episode_Reward/rew_ang_vel_z: 2.6161
    Episode_Reward/pen_base_height: -0.2938
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1457
   Episode_Reward/pen_joint_torque: -0.2307
    Episode_Reward/pen_joint_accel: -0.1057
    Episode_Reward/pen_action_rate: -0.1141
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0533
   Episode_Reward/pen_joint_powers: -0.0855
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2443
Episode_Reward/pen_flat_orientation: -0.0993
  Episode_Reward/pen_feet_distance: -0.0318
Episode_Reward/pen_feet_regulation: -0.4684
   Episode_Reward/foot_landing_vel: -0.1239
   Episode_Reward/test_gait_reward: -0.9066
Metrics/base_velocity/error_vel_xy: 0.8627
Metrics/base_velocity/error_vel_yaw: 1.2371
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 205553664
                    Iteration time: 1.11s
                        Total time: 2283.19s
                               ETA: 993.6s

################################################################################
                     [1m Learning iteration 2091/3000 [0m                     

                       Computation: 89996 steps/s (collection: 0.967s, learning 0.125s)
               Value function loss: 0.4904
                    Surrogate loss: -0.0023
             Mean action noise std: 0.8351
                     Learning rate: 0.0004
                       Mean reward: 142.28
               Mean episode length: 986.07
       Episode_Reward/keep_balance: 0.9867
     Episode_Reward/rew_lin_vel_xy: 6.3633
      Episode_Reward/rew_ang_vel_z: 2.6612
    Episode_Reward/pen_base_height: -0.2902
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1447
   Episode_Reward/pen_joint_torque: -0.2285
    Episode_Reward/pen_joint_accel: -0.0986
    Episode_Reward/pen_action_rate: -0.1118
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0531
   Episode_Reward/pen_joint_powers: -0.0848
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2410
Episode_Reward/pen_flat_orientation: -0.0918
  Episode_Reward/pen_feet_distance: -0.0329
Episode_Reward/pen_feet_regulation: -0.4628
   Episode_Reward/foot_landing_vel: -0.1311
   Episode_Reward/test_gait_reward: -0.8951
Metrics/base_velocity/error_vel_xy: 0.8939
Metrics/base_velocity/error_vel_yaw: 1.1638
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 205651968
                    Iteration time: 1.09s
                        Total time: 2284.28s
                               ETA: 992.5s

################################################################################
                     [1m Learning iteration 2092/3000 [0m                     

                       Computation: 89920 steps/s (collection: 0.968s, learning 0.125s)
               Value function loss: 0.4899
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8348
                     Learning rate: 0.0009
                       Mean reward: 142.36
               Mean episode length: 984.15
       Episode_Reward/keep_balance: 0.9670
     Episode_Reward/rew_lin_vel_xy: 6.2422
      Episode_Reward/rew_ang_vel_z: 2.5955
    Episode_Reward/pen_base_height: -0.3066
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1424
   Episode_Reward/pen_joint_torque: -0.2227
    Episode_Reward/pen_joint_accel: -0.0940
    Episode_Reward/pen_action_rate: -0.1095
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0530
   Episode_Reward/pen_joint_powers: -0.0837
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2339
Episode_Reward/pen_flat_orientation: -0.0913
  Episode_Reward/pen_feet_distance: -0.0333
Episode_Reward/pen_feet_regulation: -0.4715
   Episode_Reward/foot_landing_vel: -0.1188
   Episode_Reward/test_gait_reward: -0.8790
Metrics/base_velocity/error_vel_xy: 0.8861
Metrics/base_velocity/error_vel_yaw: 1.1553
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 205750272
                    Iteration time: 1.09s
                        Total time: 2285.37s
                               ETA: 991.5s

################################################################################
                     [1m Learning iteration 2093/3000 [0m                     

                       Computation: 89504 steps/s (collection: 0.973s, learning 0.125s)
               Value function loss: 0.5720
                    Surrogate loss: -0.0024
             Mean action noise std: 0.8352
                     Learning rate: 0.0006
                       Mean reward: 142.80
               Mean episode length: 982.18
       Episode_Reward/keep_balance: 0.9746
     Episode_Reward/rew_lin_vel_xy: 6.3418
      Episode_Reward/rew_ang_vel_z: 2.6029
    Episode_Reward/pen_base_height: -0.2867
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1436
   Episode_Reward/pen_joint_torque: -0.2323
    Episode_Reward/pen_joint_accel: -0.1071
    Episode_Reward/pen_action_rate: -0.1113
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0525
   Episode_Reward/pen_joint_powers: -0.0843
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2377
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0297
Episode_Reward/pen_feet_regulation: -0.4771
   Episode_Reward/foot_landing_vel: -0.1232
   Episode_Reward/test_gait_reward: -0.9002
Metrics/base_velocity/error_vel_xy: 0.8648
Metrics/base_velocity/error_vel_yaw: 1.1699
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 205848576
                    Iteration time: 1.10s
                        Total time: 2286.47s
                               ETA: 990.4s

################################################################################
                     [1m Learning iteration 2094/3000 [0m                     

                       Computation: 89464 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.5661
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8359
                     Learning rate: 0.0004
                       Mean reward: 141.04
               Mean episode length: 979.92
       Episode_Reward/keep_balance: 0.9706
     Episode_Reward/rew_lin_vel_xy: 6.3141
      Episode_Reward/rew_ang_vel_z: 2.6083
    Episode_Reward/pen_base_height: -0.2943
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1398
   Episode_Reward/pen_joint_torque: -0.2257
    Episode_Reward/pen_joint_accel: -0.1003
    Episode_Reward/pen_action_rate: -0.1088
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0514
   Episode_Reward/pen_joint_powers: -0.0833
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2329
Episode_Reward/pen_flat_orientation: -0.0935
  Episode_Reward/pen_feet_distance: -0.0311
Episode_Reward/pen_feet_regulation: -0.4581
   Episode_Reward/foot_landing_vel: -0.1136
   Episode_Reward/test_gait_reward: -0.8881
Metrics/base_velocity/error_vel_xy: 0.8670
Metrics/base_velocity/error_vel_yaw: 1.1556
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 205946880
                    Iteration time: 1.10s
                        Total time: 2287.57s
                               ETA: 989.3s

################################################################################
                     [1m Learning iteration 2095/3000 [0m                     

                       Computation: 89591 steps/s (collection: 0.973s, learning 0.124s)
               Value function loss: 0.4471
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8360
                     Learning rate: 0.0003
                       Mean reward: 139.62
               Mean episode length: 980.68
       Episode_Reward/keep_balance: 0.9813
     Episode_Reward/rew_lin_vel_xy: 6.3269
      Episode_Reward/rew_ang_vel_z: 2.6079
    Episode_Reward/pen_base_height: -0.2924
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1418
   Episode_Reward/pen_joint_torque: -0.2230
    Episode_Reward/pen_joint_accel: -0.1051
    Episode_Reward/pen_action_rate: -0.1112
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0540
   Episode_Reward/pen_joint_powers: -0.0840
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2393
Episode_Reward/pen_flat_orientation: -0.0961
  Episode_Reward/pen_feet_distance: -0.0326
Episode_Reward/pen_feet_regulation: -0.4825
   Episode_Reward/foot_landing_vel: -0.1200
   Episode_Reward/test_gait_reward: -0.9056
Metrics/base_velocity/error_vel_xy: 0.8949
Metrics/base_velocity/error_vel_yaw: 1.1935
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 206045184
                    Iteration time: 1.10s
                        Total time: 2288.67s
                               ETA: 988.2s

################################################################################
                     [1m Learning iteration 2096/3000 [0m                     

                       Computation: 90850 steps/s (collection: 0.959s, learning 0.123s)
               Value function loss: 0.5068
                    Surrogate loss: -0.0051
             Mean action noise std: 0.8356
                     Learning rate: 0.0006
                       Mean reward: 140.49
               Mean episode length: 988.14
       Episode_Reward/keep_balance: 0.9924
     Episode_Reward/rew_lin_vel_xy: 6.4158
      Episode_Reward/rew_ang_vel_z: 2.5986
    Episode_Reward/pen_base_height: -0.2892
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1441
   Episode_Reward/pen_joint_torque: -0.2323
    Episode_Reward/pen_joint_accel: -0.1151
    Episode_Reward/pen_action_rate: -0.1125
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0879
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2423
Episode_Reward/pen_flat_orientation: -0.0943
  Episode_Reward/pen_feet_distance: -0.0347
Episode_Reward/pen_feet_regulation: -0.4853
   Episode_Reward/foot_landing_vel: -0.1309
   Episode_Reward/test_gait_reward: -0.9180
Metrics/base_velocity/error_vel_xy: 0.9019
Metrics/base_velocity/error_vel_yaw: 1.2421
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 206143488
                    Iteration time: 1.08s
                        Total time: 2289.75s
                               ETA: 987.1s

################################################################################
                     [1m Learning iteration 2097/3000 [0m                     

                       Computation: 89387 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.5286
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8358
                     Learning rate: 0.0004
                       Mean reward: 141.41
               Mean episode length: 982.76
       Episode_Reward/keep_balance: 0.9882
     Episode_Reward/rew_lin_vel_xy: 6.4240
      Episode_Reward/rew_ang_vel_z: 2.6677
    Episode_Reward/pen_base_height: -0.3001
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1428
   Episode_Reward/pen_joint_torque: -0.2389
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.1121
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0541
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2401
Episode_Reward/pen_flat_orientation: -0.0926
  Episode_Reward/pen_feet_distance: -0.0339
Episode_Reward/pen_feet_regulation: -0.4746
   Episode_Reward/foot_landing_vel: -0.1230
   Episode_Reward/test_gait_reward: -0.9035
Metrics/base_velocity/error_vel_xy: 0.8743
Metrics/base_velocity/error_vel_yaw: 1.1615
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 206241792
                    Iteration time: 1.10s
                        Total time: 2290.85s
                               ETA: 986.0s

################################################################################
                     [1m Learning iteration 2098/3000 [0m                     

                       Computation: 91308 steps/s (collection: 0.950s, learning 0.126s)
               Value function loss: 0.5261
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8363
                     Learning rate: 0.0009
                       Mean reward: 141.84
               Mean episode length: 988.30
       Episode_Reward/keep_balance: 0.9916
     Episode_Reward/rew_lin_vel_xy: 6.3683
      Episode_Reward/rew_ang_vel_z: 2.6518
    Episode_Reward/pen_base_height: -0.2942
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.1418
   Episode_Reward/pen_joint_torque: -0.2283
    Episode_Reward/pen_joint_accel: -0.1005
    Episode_Reward/pen_action_rate: -0.1112
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0529
   Episode_Reward/pen_joint_powers: -0.0841
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2394
Episode_Reward/pen_flat_orientation: -0.0889
  Episode_Reward/pen_feet_distance: -0.0300
Episode_Reward/pen_feet_regulation: -0.4621
   Episode_Reward/foot_landing_vel: -0.1225
   Episode_Reward/test_gait_reward: -0.9049
Metrics/base_velocity/error_vel_xy: 0.9115
Metrics/base_velocity/error_vel_yaw: 1.1938
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 206340096
                    Iteration time: 1.08s
                        Total time: 2291.93s
                               ETA: 984.9s

################################################################################
                     [1m Learning iteration 2099/3000 [0m                     

                       Computation: 89471 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.6779
                    Surrogate loss: -0.0005
             Mean action noise std: 0.8369
                     Learning rate: 0.0003
                       Mean reward: 142.50
               Mean episode length: 992.45
       Episode_Reward/keep_balance: 0.9921
     Episode_Reward/rew_lin_vel_xy: 6.4506
      Episode_Reward/rew_ang_vel_z: 2.6462
    Episode_Reward/pen_base_height: -0.2903
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1455
   Episode_Reward/pen_joint_torque: -0.2244
    Episode_Reward/pen_joint_accel: -0.1012
    Episode_Reward/pen_action_rate: -0.1120
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0530
   Episode_Reward/pen_joint_powers: -0.0843
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2429
Episode_Reward/pen_flat_orientation: -0.0929
  Episode_Reward/pen_feet_distance: -0.0321
Episode_Reward/pen_feet_regulation: -0.4667
   Episode_Reward/foot_landing_vel: -0.1199
   Episode_Reward/test_gait_reward: -0.9072
Metrics/base_velocity/error_vel_xy: 0.8858
Metrics/base_velocity/error_vel_yaw: 1.2023
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 206438400
                    Iteration time: 1.10s
                        Total time: 2293.02s
                               ETA: 983.8s

################################################################################
                     [1m Learning iteration 2100/3000 [0m                     

                       Computation: 90321 steps/s (collection: 0.961s, learning 0.127s)
               Value function loss: 0.5565
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8368
                     Learning rate: 0.0006
                       Mean reward: 136.31
               Mean episode length: 954.75
       Episode_Reward/keep_balance: 0.9455
     Episode_Reward/rew_lin_vel_xy: 6.0956
      Episode_Reward/rew_ang_vel_z: 2.4972
    Episode_Reward/pen_base_height: -0.2815
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1439
   Episode_Reward/pen_joint_torque: -0.2121
    Episode_Reward/pen_joint_accel: -0.1068
    Episode_Reward/pen_action_rate: -0.1074
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0525
   Episode_Reward/pen_joint_powers: -0.0817
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2325
Episode_Reward/pen_flat_orientation: -0.0964
  Episode_Reward/pen_feet_distance: -0.0280
Episode_Reward/pen_feet_regulation: -0.4661
   Episode_Reward/foot_landing_vel: -0.1192
   Episode_Reward/test_gait_reward: -0.8615
Metrics/base_velocity/error_vel_xy: 0.8668
Metrics/base_velocity/error_vel_yaw: 1.1684
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 206536704
                    Iteration time: 1.09s
                        Total time: 2294.11s
                               ETA: 982.7s

################################################################################
                     [1m Learning iteration 2101/3000 [0m                     

                       Computation: 90405 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.5636
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8376
                     Learning rate: 0.0013
                       Mean reward: 144.76
               Mean episode length: 995.07
       Episode_Reward/keep_balance: 0.9930
     Episode_Reward/rew_lin_vel_xy: 6.4762
      Episode_Reward/rew_ang_vel_z: 2.6625
    Episode_Reward/pen_base_height: -0.2945
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1477
   Episode_Reward/pen_joint_torque: -0.2319
    Episode_Reward/pen_joint_accel: -0.1075
    Episode_Reward/pen_action_rate: -0.1130
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0533
   Episode_Reward/pen_joint_powers: -0.0852
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2435
Episode_Reward/pen_flat_orientation: -0.0941
  Episode_Reward/pen_feet_distance: -0.0353
Episode_Reward/pen_feet_regulation: -0.4636
   Episode_Reward/foot_landing_vel: -0.1279
   Episode_Reward/test_gait_reward: -0.8961
Metrics/base_velocity/error_vel_xy: 0.8688
Metrics/base_velocity/error_vel_yaw: 1.1876
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 206635008
                    Iteration time: 1.09s
                        Total time: 2295.20s
                               ETA: 981.6s

################################################################################
                     [1m Learning iteration 2102/3000 [0m                     

                       Computation: 90387 steps/s (collection: 0.964s, learning 0.123s)
               Value function loss: 0.5679
                    Surrogate loss: 0.0051
             Mean action noise std: 0.8380
                     Learning rate: 0.0000
                       Mean reward: 138.31
               Mean episode length: 985.57
       Episode_Reward/keep_balance: 0.9816
     Episode_Reward/rew_lin_vel_xy: 6.2646
      Episode_Reward/rew_ang_vel_z: 2.5855
    Episode_Reward/pen_base_height: -0.3056
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1442
   Episode_Reward/pen_joint_torque: -0.2351
    Episode_Reward/pen_joint_accel: -0.1083
    Episode_Reward/pen_action_rate: -0.1126
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2420
Episode_Reward/pen_flat_orientation: -0.0949
  Episode_Reward/pen_feet_distance: -0.0321
Episode_Reward/pen_feet_regulation: -0.4827
   Episode_Reward/foot_landing_vel: -0.1274
   Episode_Reward/test_gait_reward: -0.9120
Metrics/base_velocity/error_vel_xy: 0.9256
Metrics/base_velocity/error_vel_yaw: 1.2147
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 206733312
                    Iteration time: 1.09s
                        Total time: 2296.29s
                               ETA: 980.5s

################################################################################
                     [1m Learning iteration 2103/3000 [0m                     

                       Computation: 89661 steps/s (collection: 0.970s, learning 0.126s)
               Value function loss: 0.5125
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8373
                     Learning rate: 0.0001
                       Mean reward: 140.09
               Mean episode length: 985.97
       Episode_Reward/keep_balance: 0.9889
     Episode_Reward/rew_lin_vel_xy: 6.4451
      Episode_Reward/rew_ang_vel_z: 2.6218
    Episode_Reward/pen_base_height: -0.2903
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1492
   Episode_Reward/pen_joint_torque: -0.2254
    Episode_Reward/pen_joint_accel: -0.1165
    Episode_Reward/pen_action_rate: -0.1119
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0537
   Episode_Reward/pen_joint_powers: -0.0847
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2430
Episode_Reward/pen_flat_orientation: -0.0936
  Episode_Reward/pen_feet_distance: -0.0370
Episode_Reward/pen_feet_regulation: -0.4789
   Episode_Reward/foot_landing_vel: -0.1311
   Episode_Reward/test_gait_reward: -0.8990
Metrics/base_velocity/error_vel_xy: 0.8574
Metrics/base_velocity/error_vel_yaw: 1.2039
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 206831616
                    Iteration time: 1.10s
                        Total time: 2297.38s
                               ETA: 979.4s

################################################################################
                     [1m Learning iteration 2104/3000 [0m                     

                       Computation: 88523 steps/s (collection: 0.983s, learning 0.128s)
               Value function loss: 0.5855
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8368
                     Learning rate: 0.0003
                       Mean reward: 138.91
               Mean episode length: 957.73
       Episode_Reward/keep_balance: 0.9780
     Episode_Reward/rew_lin_vel_xy: 6.3966
      Episode_Reward/rew_ang_vel_z: 2.6331
    Episode_Reward/pen_base_height: -0.2910
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1424
   Episode_Reward/pen_joint_torque: -0.2271
    Episode_Reward/pen_joint_accel: -0.1070
    Episode_Reward/pen_action_rate: -0.1107
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0529
   Episode_Reward/pen_joint_powers: -0.0843
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2386
Episode_Reward/pen_flat_orientation: -0.0906
  Episode_Reward/pen_feet_distance: -0.0384
Episode_Reward/pen_feet_regulation: -0.4655
   Episode_Reward/foot_landing_vel: -0.1257
   Episode_Reward/test_gait_reward: -0.8893
Metrics/base_velocity/error_vel_xy: 0.8470
Metrics/base_velocity/error_vel_yaw: 1.1643
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 206929920
                    Iteration time: 1.11s
                        Total time: 2298.50s
                               ETA: 978.4s

################################################################################
                     [1m Learning iteration 2105/3000 [0m                     

                       Computation: 89555 steps/s (collection: 0.971s, learning 0.127s)
               Value function loss: 0.4541
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8369
                     Learning rate: 0.0006
                       Mean reward: 140.16
               Mean episode length: 969.70
       Episode_Reward/keep_balance: 0.9724
     Episode_Reward/rew_lin_vel_xy: 6.3192
      Episode_Reward/rew_ang_vel_z: 2.6065
    Episode_Reward/pen_base_height: -0.2961
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1416
   Episode_Reward/pen_joint_torque: -0.2286
    Episode_Reward/pen_joint_accel: -0.1029
    Episode_Reward/pen_action_rate: -0.1090
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0521
   Episode_Reward/pen_joint_powers: -0.0838
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2342
Episode_Reward/pen_flat_orientation: -0.0909
  Episode_Reward/pen_feet_distance: -0.0328
Episode_Reward/pen_feet_regulation: -0.4666
   Episode_Reward/foot_landing_vel: -0.1130
   Episode_Reward/test_gait_reward: -0.8874
Metrics/base_velocity/error_vel_xy: 0.8721
Metrics/base_velocity/error_vel_yaw: 1.1627
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 207028224
                    Iteration time: 1.10s
                        Total time: 2299.59s
                               ETA: 977.3s

################################################################################
                     [1m Learning iteration 2106/3000 [0m                     

                       Computation: 89285 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 0.4921
                    Surrogate loss: -0.0051
             Mean action noise std: 0.8374
                     Learning rate: 0.0009
                       Mean reward: 142.76
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4800
      Episode_Reward/rew_ang_vel_z: 2.6149
    Episode_Reward/pen_base_height: -0.2960
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1468
   Episode_Reward/pen_joint_torque: -0.2293
    Episode_Reward/pen_joint_accel: -0.1042
    Episode_Reward/pen_action_rate: -0.1149
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0537
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2487
Episode_Reward/pen_flat_orientation: -0.0915
  Episode_Reward/pen_feet_distance: -0.0335
Episode_Reward/pen_feet_regulation: -0.4877
   Episode_Reward/foot_landing_vel: -0.1234
   Episode_Reward/test_gait_reward: -0.9197
Metrics/base_velocity/error_vel_xy: 0.8871
Metrics/base_velocity/error_vel_yaw: 1.2522
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 207126528
                    Iteration time: 1.10s
                        Total time: 2300.69s
                               ETA: 976.2s

################################################################################
                     [1m Learning iteration 2107/3000 [0m                     

                       Computation: 90062 steps/s (collection: 0.967s, learning 0.124s)
               Value function loss: 0.5427
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8371
                     Learning rate: 0.0009
                       Mean reward: 141.28
               Mean episode length: 997.31
       Episode_Reward/keep_balance: 0.9972
     Episode_Reward/rew_lin_vel_xy: 6.4299
      Episode_Reward/rew_ang_vel_z: 2.6442
    Episode_Reward/pen_base_height: -0.3166
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1420
   Episode_Reward/pen_joint_torque: -0.2425
    Episode_Reward/pen_joint_accel: -0.1106
    Episode_Reward/pen_action_rate: -0.1148
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0541
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2446
Episode_Reward/pen_flat_orientation: -0.0933
  Episode_Reward/pen_feet_distance: -0.0281
Episode_Reward/pen_feet_regulation: -0.4836
   Episode_Reward/foot_landing_vel: -0.1192
   Episode_Reward/test_gait_reward: -0.9310
Metrics/base_velocity/error_vel_xy: 0.9055
Metrics/base_velocity/error_vel_yaw: 1.2087
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 207224832
                    Iteration time: 1.09s
                        Total time: 2301.79s
                               ETA: 975.1s

################################################################################
                     [1m Learning iteration 2108/3000 [0m                     

                       Computation: 90032 steps/s (collection: 0.970s, learning 0.122s)
               Value function loss: 0.5664
                    Surrogate loss: -0.0007
             Mean action noise std: 0.8367
                     Learning rate: 0.0002
                       Mean reward: 135.92
               Mean episode length: 966.58
       Episode_Reward/keep_balance: 0.9748
     Episode_Reward/rew_lin_vel_xy: 6.2641
      Episode_Reward/rew_ang_vel_z: 2.5639
    Episode_Reward/pen_base_height: -0.2969
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1422
   Episode_Reward/pen_joint_torque: -0.2355
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1122
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0541
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2390
Episode_Reward/pen_flat_orientation: -0.0958
  Episode_Reward/pen_feet_distance: -0.0353
Episode_Reward/pen_feet_regulation: -0.4813
   Episode_Reward/foot_landing_vel: -0.1316
   Episode_Reward/test_gait_reward: -0.9045
Metrics/base_velocity/error_vel_xy: 0.8934
Metrics/base_velocity/error_vel_yaw: 1.2094
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 207323136
                    Iteration time: 1.09s
                        Total time: 2302.88s
                               ETA: 974.0s

################################################################################
                     [1m Learning iteration 2109/3000 [0m                     

                       Computation: 88991 steps/s (collection: 0.981s, learning 0.123s)
               Value function loss: 0.5055
                    Surrogate loss: -0.0051
             Mean action noise std: 0.8371
                     Learning rate: 0.0004
                       Mean reward: 142.34
               Mean episode length: 987.09
       Episode_Reward/keep_balance: 0.9882
     Episode_Reward/rew_lin_vel_xy: 6.4323
      Episode_Reward/rew_ang_vel_z: 2.6379
    Episode_Reward/pen_base_height: -0.2860
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1503
   Episode_Reward/pen_joint_torque: -0.2263
    Episode_Reward/pen_joint_accel: -0.1114
    Episode_Reward/pen_action_rate: -0.1119
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0534
   Episode_Reward/pen_joint_powers: -0.0844
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2425
Episode_Reward/pen_flat_orientation: -0.0893
  Episode_Reward/pen_feet_distance: -0.0310
Episode_Reward/pen_feet_regulation: -0.4662
   Episode_Reward/foot_landing_vel: -0.1260
   Episode_Reward/test_gait_reward: -0.9012
Metrics/base_velocity/error_vel_xy: 0.8624
Metrics/base_velocity/error_vel_yaw: 1.1888
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 207421440
                    Iteration time: 1.10s
                        Total time: 2303.98s
                               ETA: 972.9s

################################################################################
                     [1m Learning iteration 2110/3000 [0m                     

                       Computation: 89419 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.5114
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8369
                     Learning rate: 0.0009
                       Mean reward: 143.84
               Mean episode length: 991.57
       Episode_Reward/keep_balance: 0.9915
     Episode_Reward/rew_lin_vel_xy: 6.4343
      Episode_Reward/rew_ang_vel_z: 2.6817
    Episode_Reward/pen_base_height: -0.3055
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1415
   Episode_Reward/pen_joint_torque: -0.2267
    Episode_Reward/pen_joint_accel: -0.1001
    Episode_Reward/pen_action_rate: -0.1113
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0513
   Episode_Reward/pen_joint_powers: -0.0824
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2384
Episode_Reward/pen_flat_orientation: -0.0944
  Episode_Reward/pen_feet_distance: -0.0330
Episode_Reward/pen_feet_regulation: -0.4462
   Episode_Reward/foot_landing_vel: -0.1199
   Episode_Reward/test_gait_reward: -0.9082
Metrics/base_velocity/error_vel_xy: 0.8866
Metrics/base_velocity/error_vel_yaw: 1.1711
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 207519744
                    Iteration time: 1.10s
                        Total time: 2305.08s
                               ETA: 971.8s

################################################################################
                     [1m Learning iteration 2111/3000 [0m                     

                       Computation: 91096 steps/s (collection: 0.957s, learning 0.122s)
               Value function loss: 0.5528
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8371
                     Learning rate: 0.0006
                       Mean reward: 143.31
               Mean episode length: 990.68
       Episode_Reward/keep_balance: 0.9922
     Episode_Reward/rew_lin_vel_xy: 6.4157
      Episode_Reward/rew_ang_vel_z: 2.6193
    Episode_Reward/pen_base_height: -0.2943
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1482
   Episode_Reward/pen_joint_torque: -0.2268
    Episode_Reward/pen_joint_accel: -0.1022
    Episode_Reward/pen_action_rate: -0.1133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0540
   Episode_Reward/pen_joint_powers: -0.0853
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2423
Episode_Reward/pen_flat_orientation: -0.0931
  Episode_Reward/pen_feet_distance: -0.0332
Episode_Reward/pen_feet_regulation: -0.4972
   Episode_Reward/foot_landing_vel: -0.1233
   Episode_Reward/test_gait_reward: -0.9126
Metrics/base_velocity/error_vel_xy: 0.8972
Metrics/base_velocity/error_vel_yaw: 1.2235
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 207618048
                    Iteration time: 1.08s
                        Total time: 2306.16s
                               ETA: 970.7s

################################################################################
                     [1m Learning iteration 2112/3000 [0m                     

                       Computation: 89888 steps/s (collection: 0.971s, learning 0.123s)
               Value function loss: 0.5340
                    Surrogate loss: -0.0051
             Mean action noise std: 0.8369
                     Learning rate: 0.0006
                       Mean reward: 142.13
               Mean episode length: 984.74
       Episode_Reward/keep_balance: 0.9816
     Episode_Reward/rew_lin_vel_xy: 6.3441
      Episode_Reward/rew_ang_vel_z: 2.6425
    Episode_Reward/pen_base_height: -0.2944
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1389
   Episode_Reward/pen_joint_torque: -0.2303
    Episode_Reward/pen_joint_accel: -0.0979
    Episode_Reward/pen_action_rate: -0.1100
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0519
   Episode_Reward/pen_joint_powers: -0.0841
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2344
Episode_Reward/pen_flat_orientation: -0.0921
  Episode_Reward/pen_feet_distance: -0.0344
Episode_Reward/pen_feet_regulation: -0.4556
   Episode_Reward/foot_landing_vel: -0.1187
   Episode_Reward/test_gait_reward: -0.8946
Metrics/base_velocity/error_vel_xy: 0.8874
Metrics/base_velocity/error_vel_yaw: 1.1745
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 207716352
                    Iteration time: 1.09s
                        Total time: 2307.25s
                               ETA: 969.6s

################################################################################
                     [1m Learning iteration 2113/3000 [0m                     

                       Computation: 90618 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.5210
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8375
                     Learning rate: 0.0006
                       Mean reward: 142.53
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4796
      Episode_Reward/rew_ang_vel_z: 2.6843
    Episode_Reward/pen_base_height: -0.2953
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1477
   Episode_Reward/pen_joint_torque: -0.2412
    Episode_Reward/pen_joint_accel: -0.1104
    Episode_Reward/pen_action_rate: -0.1139
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2437
Episode_Reward/pen_flat_orientation: -0.0913
  Episode_Reward/pen_feet_distance: -0.0368
Episode_Reward/pen_feet_regulation: -0.4747
   Episode_Reward/foot_landing_vel: -0.1285
   Episode_Reward/test_gait_reward: -0.9156
Metrics/base_velocity/error_vel_xy: 0.9016
Metrics/base_velocity/error_vel_yaw: 1.1909
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 207814656
                    Iteration time: 1.08s
                        Total time: 2308.34s
                               ETA: 968.5s

################################################################################
                     [1m Learning iteration 2114/3000 [0m                     

                       Computation: 89612 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.5284
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8380
                     Learning rate: 0.0006
                       Mean reward: 138.69
               Mean episode length: 972.61
       Episode_Reward/keep_balance: 0.9772
     Episode_Reward/rew_lin_vel_xy: 6.3099
      Episode_Reward/rew_ang_vel_z: 2.5992
    Episode_Reward/pen_base_height: -0.2889
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1471
   Episode_Reward/pen_joint_torque: -0.2304
    Episode_Reward/pen_joint_accel: -0.1120
    Episode_Reward/pen_action_rate: -0.1121
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0543
   Episode_Reward/pen_joint_powers: -0.0863
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2388
Episode_Reward/pen_flat_orientation: -0.0966
  Episode_Reward/pen_feet_distance: -0.0345
Episode_Reward/pen_feet_regulation: -0.4802
   Episode_Reward/foot_landing_vel: -0.1273
   Episode_Reward/test_gait_reward: -0.9003
Metrics/base_velocity/error_vel_xy: 0.8965
Metrics/base_velocity/error_vel_yaw: 1.1950
      Episode_Termination/time_out: 4.6250
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 207912960
                    Iteration time: 1.10s
                        Total time: 2309.44s
                               ETA: 967.5s

################################################################################
                     [1m Learning iteration 2115/3000 [0m                     

                       Computation: 89926 steps/s (collection: 0.970s, learning 0.123s)
               Value function loss: 0.5129
                    Surrogate loss: -0.0035
             Mean action noise std: 0.8381
                     Learning rate: 0.0004
                       Mean reward: 136.07
               Mean episode length: 971.63
       Episode_Reward/keep_balance: 0.9698
     Episode_Reward/rew_lin_vel_xy: 6.2306
      Episode_Reward/rew_ang_vel_z: 2.5386
    Episode_Reward/pen_base_height: -0.3137
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1446
   Episode_Reward/pen_joint_torque: -0.2374
    Episode_Reward/pen_joint_accel: -0.1010
    Episode_Reward/pen_action_rate: -0.1134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2395
Episode_Reward/pen_flat_orientation: -0.0994
  Episode_Reward/pen_feet_distance: -0.0398
Episode_Reward/pen_feet_regulation: -0.4990
   Episode_Reward/foot_landing_vel: -0.1239
   Episode_Reward/test_gait_reward: -0.9035
Metrics/base_velocity/error_vel_xy: 0.9152
Metrics/base_velocity/error_vel_yaw: 1.2264
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 208011264
                    Iteration time: 1.09s
                        Total time: 2310.53s
                               ETA: 966.4s

################################################################################
                     [1m Learning iteration 2116/3000 [0m                     

                       Computation: 89402 steps/s (collection: 0.978s, learning 0.122s)
               Value function loss: 0.5307
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8404
                     Learning rate: 0.0006
                       Mean reward: 139.06
               Mean episode length: 984.97
       Episode_Reward/keep_balance: 0.9642
     Episode_Reward/rew_lin_vel_xy: 6.1646
      Episode_Reward/rew_ang_vel_z: 2.5445
    Episode_Reward/pen_base_height: -0.3096
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1401
   Episode_Reward/pen_joint_torque: -0.2352
    Episode_Reward/pen_joint_accel: -0.0943
    Episode_Reward/pen_action_rate: -0.1114
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0536
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2354
Episode_Reward/pen_flat_orientation: -0.0964
  Episode_Reward/pen_feet_distance: -0.0285
Episode_Reward/pen_feet_regulation: -0.4849
   Episode_Reward/foot_landing_vel: -0.1206
   Episode_Reward/test_gait_reward: -0.8969
Metrics/base_velocity/error_vel_xy: 0.9159
Metrics/base_velocity/error_vel_yaw: 1.1955
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 208109568
                    Iteration time: 1.10s
                        Total time: 2311.63s
                               ETA: 965.3s

################################################################################
                     [1m Learning iteration 2117/3000 [0m                     

                       Computation: 89839 steps/s (collection: 0.968s, learning 0.126s)
               Value function loss: 0.5047
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8410
                     Learning rate: 0.0004
                       Mean reward: 138.46
               Mean episode length: 971.46
       Episode_Reward/keep_balance: 0.9548
     Episode_Reward/rew_lin_vel_xy: 6.1466
      Episode_Reward/rew_ang_vel_z: 2.5554
    Episode_Reward/pen_base_height: -0.2879
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1373
   Episode_Reward/pen_joint_torque: -0.2339
    Episode_Reward/pen_joint_accel: -0.0995
    Episode_Reward/pen_action_rate: -0.1078
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0511
   Episode_Reward/pen_joint_powers: -0.0833
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2284
Episode_Reward/pen_flat_orientation: -0.0921
  Episode_Reward/pen_feet_distance: -0.0345
Episode_Reward/pen_feet_regulation: -0.4592
   Episode_Reward/foot_landing_vel: -0.1144
   Episode_Reward/test_gait_reward: -0.8755
Metrics/base_velocity/error_vel_xy: 0.8730
Metrics/base_velocity/error_vel_yaw: 1.1421
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 208207872
                    Iteration time: 1.09s
                        Total time: 2312.72s
                               ETA: 964.2s

################################################################################
                     [1m Learning iteration 2118/3000 [0m                     

                       Computation: 90594 steps/s (collection: 0.961s, learning 0.125s)
               Value function loss: 0.5364
                    Surrogate loss: -0.0048
             Mean action noise std: 0.8407
                     Learning rate: 0.0009
                       Mean reward: 138.49
               Mean episode length: 968.02
       Episode_Reward/keep_balance: 0.9652
     Episode_Reward/rew_lin_vel_xy: 6.2622
      Episode_Reward/rew_ang_vel_z: 2.5867
    Episode_Reward/pen_base_height: -0.2913
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1430
   Episode_Reward/pen_joint_torque: -0.2226
    Episode_Reward/pen_joint_accel: -0.1054
    Episode_Reward/pen_action_rate: -0.1092
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0520
   Episode_Reward/pen_joint_powers: -0.0824
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2364
Episode_Reward/pen_flat_orientation: -0.0957
  Episode_Reward/pen_feet_distance: -0.0337
Episode_Reward/pen_feet_regulation: -0.4555
   Episode_Reward/foot_landing_vel: -0.1196
   Episode_Reward/test_gait_reward: -0.8895
Metrics/base_velocity/error_vel_xy: 0.8576
Metrics/base_velocity/error_vel_yaw: 1.1573
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 208306176
                    Iteration time: 1.09s
                        Total time: 2313.81s
                               ETA: 963.1s

################################################################################
                     [1m Learning iteration 2119/3000 [0m                     

                       Computation: 88496 steps/s (collection: 0.985s, learning 0.126s)
               Value function loss: 0.4610
                    Surrogate loss: -0.0056
             Mean action noise std: 0.8416
                     Learning rate: 0.0009
                       Mean reward: 141.34
               Mean episode length: 989.45
       Episode_Reward/keep_balance: 0.9862
     Episode_Reward/rew_lin_vel_xy: 6.3565
      Episode_Reward/rew_ang_vel_z: 2.6177
    Episode_Reward/pen_base_height: -0.2991
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1447
   Episode_Reward/pen_joint_torque: -0.2288
    Episode_Reward/pen_joint_accel: -0.1109
    Episode_Reward/pen_action_rate: -0.1134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0531
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2423
Episode_Reward/pen_flat_orientation: -0.0940
  Episode_Reward/pen_feet_distance: -0.0313
Episode_Reward/pen_feet_regulation: -0.4632
   Episode_Reward/foot_landing_vel: -0.1149
   Episode_Reward/test_gait_reward: -0.9114
Metrics/base_velocity/error_vel_xy: 0.9019
Metrics/base_velocity/error_vel_yaw: 1.2110
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 208404480
                    Iteration time: 1.11s
                        Total time: 2314.92s
                               ETA: 962.0s

################################################################################
                     [1m Learning iteration 2120/3000 [0m                     

                       Computation: 91313 steps/s (collection: 0.951s, learning 0.125s)
               Value function loss: 0.5396
                    Surrogate loss: 0.0013
             Mean action noise std: 0.8422
                     Learning rate: 0.0001
                       Mean reward: 143.47
               Mean episode length: 998.26
       Episode_Reward/keep_balance: 0.9986
     Episode_Reward/rew_lin_vel_xy: 6.5311
      Episode_Reward/rew_ang_vel_z: 2.6649
    Episode_Reward/pen_base_height: -0.2883
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1398
   Episode_Reward/pen_joint_torque: -0.2361
    Episode_Reward/pen_joint_accel: -0.1101
    Episode_Reward/pen_action_rate: -0.1130
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0531
   Episode_Reward/pen_joint_powers: -0.0855
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2439
Episode_Reward/pen_flat_orientation: -0.0903
  Episode_Reward/pen_feet_distance: -0.0261
Episode_Reward/pen_feet_regulation: -0.4585
   Episode_Reward/foot_landing_vel: -0.1275
   Episode_Reward/test_gait_reward: -0.9196
Metrics/base_velocity/error_vel_xy: 0.8621
Metrics/base_velocity/error_vel_yaw: 1.2017
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 208502784
                    Iteration time: 1.08s
                        Total time: 2316.00s
                               ETA: 960.9s

################################################################################
                     [1m Learning iteration 2121/3000 [0m                     

                       Computation: 89410 steps/s (collection: 0.973s, learning 0.127s)
               Value function loss: 0.4940
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8422
                     Learning rate: 0.0002
                       Mean reward: 140.71
               Mean episode length: 990.85
       Episode_Reward/keep_balance: 0.9949
     Episode_Reward/rew_lin_vel_xy: 6.3877
      Episode_Reward/rew_ang_vel_z: 2.6438
    Episode_Reward/pen_base_height: -0.2890
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1479
   Episode_Reward/pen_joint_torque: -0.2363
    Episode_Reward/pen_joint_accel: -0.1040
    Episode_Reward/pen_action_rate: -0.1134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0533
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2450
Episode_Reward/pen_flat_orientation: -0.0925
  Episode_Reward/pen_feet_distance: -0.0293
Episode_Reward/pen_feet_regulation: -0.4745
   Episode_Reward/foot_landing_vel: -0.1204
   Episode_Reward/test_gait_reward: -0.9130
Metrics/base_velocity/error_vel_xy: 0.9061
Metrics/base_velocity/error_vel_yaw: 1.2070
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 208601088
                    Iteration time: 1.10s
                        Total time: 2317.09s
                               ETA: 959.8s

################################################################################
                     [1m Learning iteration 2122/3000 [0m                     

                       Computation: 88615 steps/s (collection: 0.985s, learning 0.124s)
               Value function loss: 0.4721
                    Surrogate loss: -0.0056
             Mean action noise std: 0.8407
                     Learning rate: 0.0004
                       Mean reward: 144.95
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.5023
      Episode_Reward/rew_ang_vel_z: 2.6804
    Episode_Reward/pen_base_height: -0.2774
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1451
   Episode_Reward/pen_joint_torque: -0.2202
    Episode_Reward/pen_joint_accel: -0.1001
    Episode_Reward/pen_action_rate: -0.1110
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0515
   Episode_Reward/pen_joint_powers: -0.0815
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2398
Episode_Reward/pen_flat_orientation: -0.0895
  Episode_Reward/pen_feet_distance: -0.0306
Episode_Reward/pen_feet_regulation: -0.4678
   Episode_Reward/foot_landing_vel: -0.1173
   Episode_Reward/test_gait_reward: -0.9069
Metrics/base_velocity/error_vel_xy: 0.8794
Metrics/base_velocity/error_vel_yaw: 1.1989
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 208699392
                    Iteration time: 1.11s
                        Total time: 2318.20s
                               ETA: 958.7s

################################################################################
                     [1m Learning iteration 2123/3000 [0m                     

                       Computation: 90381 steps/s (collection: 0.965s, learning 0.123s)
               Value function loss: 0.5964
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8398
                     Learning rate: 0.0009
                       Mean reward: 140.73
               Mean episode length: 985.64
       Episode_Reward/keep_balance: 0.9875
     Episode_Reward/rew_lin_vel_xy: 6.3876
      Episode_Reward/rew_ang_vel_z: 2.6524
    Episode_Reward/pen_base_height: -0.2879
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1447
   Episode_Reward/pen_joint_torque: -0.2363
    Episode_Reward/pen_joint_accel: -0.1025
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0537
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2410
Episode_Reward/pen_flat_orientation: -0.0953
  Episode_Reward/pen_feet_distance: -0.0350
Episode_Reward/pen_feet_regulation: -0.4643
   Episode_Reward/foot_landing_vel: -0.1267
   Episode_Reward/test_gait_reward: -0.9031
Metrics/base_velocity/error_vel_xy: 0.8920
Metrics/base_velocity/error_vel_yaw: 1.1773
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 208797696
                    Iteration time: 1.09s
                        Total time: 2319.29s
                               ETA: 957.6s

################################################################################
                     [1m Learning iteration 2124/3000 [0m                     

                       Computation: 86850 steps/s (collection: 1.008s, learning 0.124s)
               Value function loss: 0.5519
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8404
                     Learning rate: 0.0006
                       Mean reward: 137.68
               Mean episode length: 982.12
       Episode_Reward/keep_balance: 0.9865
     Episode_Reward/rew_lin_vel_xy: 6.2923
      Episode_Reward/rew_ang_vel_z: 2.5894
    Episode_Reward/pen_base_height: -0.2986
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1417
   Episode_Reward/pen_joint_torque: -0.2338
    Episode_Reward/pen_joint_accel: -0.1060
    Episode_Reward/pen_action_rate: -0.1129
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2410
Episode_Reward/pen_flat_orientation: -0.0952
  Episode_Reward/pen_feet_distance: -0.0323
Episode_Reward/pen_feet_regulation: -0.4896
   Episode_Reward/foot_landing_vel: -0.1238
   Episode_Reward/test_gait_reward: -0.9133
Metrics/base_velocity/error_vel_xy: 0.9447
Metrics/base_velocity/error_vel_yaw: 1.2324
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 208896000
                    Iteration time: 1.13s
                        Total time: 2320.42s
                               ETA: 956.6s

################################################################################
                     [1m Learning iteration 2125/3000 [0m                     

                       Computation: 90057 steps/s (collection: 0.965s, learning 0.127s)
               Value function loss: 0.4621
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8404
                     Learning rate: 0.0004
                       Mean reward: 140.67
               Mean episode length: 983.87
       Episode_Reward/keep_balance: 0.9891
     Episode_Reward/rew_lin_vel_xy: 6.4081
      Episode_Reward/rew_ang_vel_z: 2.6587
    Episode_Reward/pen_base_height: -0.2959
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1488
   Episode_Reward/pen_joint_torque: -0.2284
    Episode_Reward/pen_joint_accel: -0.0955
    Episode_Reward/pen_action_rate: -0.1120
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0518
   Episode_Reward/pen_joint_powers: -0.0842
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2403
Episode_Reward/pen_flat_orientation: -0.0942
  Episode_Reward/pen_feet_distance: -0.0358
Episode_Reward/pen_feet_regulation: -0.4635
   Episode_Reward/foot_landing_vel: -0.1142
   Episode_Reward/test_gait_reward: -0.9039
Metrics/base_velocity/error_vel_xy: 0.9045
Metrics/base_velocity/error_vel_yaw: 1.1810
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 208994304
                    Iteration time: 1.09s
                        Total time: 2321.51s
                               ETA: 955.5s

################################################################################
                     [1m Learning iteration 2126/3000 [0m                     

                       Computation: 89995 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.5136
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8396
                     Learning rate: 0.0003
                       Mean reward: 142.33
               Mean episode length: 994.66
       Episode_Reward/keep_balance: 0.9964
     Episode_Reward/rew_lin_vel_xy: 6.4460
      Episode_Reward/rew_ang_vel_z: 2.6482
    Episode_Reward/pen_base_height: -0.2884
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.1506
   Episode_Reward/pen_joint_torque: -0.2275
    Episode_Reward/pen_joint_accel: -0.1094
    Episode_Reward/pen_action_rate: -0.1126
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0528
   Episode_Reward/pen_joint_powers: -0.0839
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2419
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0301
Episode_Reward/pen_feet_regulation: -0.4625
   Episode_Reward/foot_landing_vel: -0.1211
   Episode_Reward/test_gait_reward: -0.9061
Metrics/base_velocity/error_vel_xy: 0.9027
Metrics/base_velocity/error_vel_yaw: 1.2184
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 209092608
                    Iteration time: 1.09s
                        Total time: 2322.61s
                               ETA: 954.4s

################################################################################
                     [1m Learning iteration 2127/3000 [0m                     

                       Computation: 90589 steps/s (collection: 0.961s, learning 0.124s)
               Value function loss: 0.4952
                    Surrogate loss: -0.0057
             Mean action noise std: 0.8389
                     Learning rate: 0.0006
                       Mean reward: 142.12
               Mean episode length: 994.22
       Episode_Reward/keep_balance: 0.9943
     Episode_Reward/rew_lin_vel_xy: 6.3705
      Episode_Reward/rew_ang_vel_z: 2.6448
    Episode_Reward/pen_base_height: -0.2937
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1457
   Episode_Reward/pen_joint_torque: -0.2340
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1135
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0535
   Episode_Reward/pen_joint_powers: -0.0858
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2445
Episode_Reward/pen_flat_orientation: -0.0914
  Episode_Reward/pen_feet_distance: -0.0300
Episode_Reward/pen_feet_regulation: -0.4771
   Episode_Reward/foot_landing_vel: -0.1185
   Episode_Reward/test_gait_reward: -0.9035
Metrics/base_velocity/error_vel_xy: 0.9304
Metrics/base_velocity/error_vel_yaw: 1.2102
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 209190912
                    Iteration time: 1.09s
                        Total time: 2323.69s
                               ETA: 953.3s

################################################################################
                     [1m Learning iteration 2128/3000 [0m                     

                       Computation: 89898 steps/s (collection: 0.971s, learning 0.122s)
               Value function loss: 0.4737
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8387
                     Learning rate: 0.0006
                       Mean reward: 141.03
               Mean episode length: 990.18
       Episode_Reward/keep_balance: 0.9888
     Episode_Reward/rew_lin_vel_xy: 6.3589
      Episode_Reward/rew_ang_vel_z: 2.5799
    Episode_Reward/pen_base_height: -0.2844
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1523
   Episode_Reward/pen_joint_torque: -0.2288
    Episode_Reward/pen_joint_accel: -0.1032
    Episode_Reward/pen_action_rate: -0.1135
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2447
Episode_Reward/pen_flat_orientation: -0.0951
  Episode_Reward/pen_feet_distance: -0.0316
Episode_Reward/pen_feet_regulation: -0.4820
   Episode_Reward/foot_landing_vel: -0.1207
   Episode_Reward/test_gait_reward: -0.9083
Metrics/base_velocity/error_vel_xy: 0.9181
Metrics/base_velocity/error_vel_yaw: 1.2540
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 209289216
                    Iteration time: 1.09s
                        Total time: 2324.79s
                               ETA: 952.2s

################################################################################
                     [1m Learning iteration 2129/3000 [0m                     

                       Computation: 89753 steps/s (collection: 0.970s, learning 0.125s)
               Value function loss: 0.4990
                    Surrogate loss: 0.0013
             Mean action noise std: 0.8392
                     Learning rate: 0.0001
                       Mean reward: 145.01
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.5014
      Episode_Reward/rew_ang_vel_z: 2.6675
    Episode_Reward/pen_base_height: -0.3020
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.1464
   Episode_Reward/pen_joint_torque: -0.2351
    Episode_Reward/pen_joint_accel: -0.0965
    Episode_Reward/pen_action_rate: -0.1129
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0533
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2409
Episode_Reward/pen_flat_orientation: -0.0894
  Episode_Reward/pen_feet_distance: -0.0342
Episode_Reward/pen_feet_regulation: -0.4611
   Episode_Reward/foot_landing_vel: -0.1211
   Episode_Reward/test_gait_reward: -0.9054
Metrics/base_velocity/error_vel_xy: 0.8954
Metrics/base_velocity/error_vel_yaw: 1.2050
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 209387520
                    Iteration time: 1.10s
                        Total time: 2325.88s
                               ETA: 951.1s

################################################################################
                     [1m Learning iteration 2130/3000 [0m                     

                       Computation: 89126 steps/s (collection: 0.980s, learning 0.123s)
               Value function loss: 0.5268
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8394
                     Learning rate: 0.0003
                       Mean reward: 143.37
               Mean episode length: 996.28
       Episode_Reward/keep_balance: 0.9978
     Episode_Reward/rew_lin_vel_xy: 6.4510
      Episode_Reward/rew_ang_vel_z: 2.6369
    Episode_Reward/pen_base_height: -0.2971
      Episode_Reward/pen_lin_vel_z: -0.0378
     Episode_Reward/pen_ang_vel_xy: -0.1472
   Episode_Reward/pen_joint_torque: -0.2386
    Episode_Reward/pen_joint_accel: -0.1050
    Episode_Reward/pen_action_rate: -0.1123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0536
   Episode_Reward/pen_joint_powers: -0.0863
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2409
Episode_Reward/pen_flat_orientation: -0.0939
  Episode_Reward/pen_feet_distance: -0.0287
Episode_Reward/pen_feet_regulation: -0.4837
   Episode_Reward/foot_landing_vel: -0.1153
   Episode_Reward/test_gait_reward: -0.9082
Metrics/base_velocity/error_vel_xy: 0.9035
Metrics/base_velocity/error_vel_yaw: 1.2304
      Episode_Termination/time_out: 5.0000
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 209485824
                    Iteration time: 1.10s
                        Total time: 2326.98s
                               ETA: 950.0s

################################################################################
                     [1m Learning iteration 2131/3000 [0m                     

                       Computation: 91291 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 0.4929
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8411
                     Learning rate: 0.0006
                       Mean reward: 141.77
               Mean episode length: 983.74
       Episode_Reward/keep_balance: 0.9812
     Episode_Reward/rew_lin_vel_xy: 6.3708
      Episode_Reward/rew_ang_vel_z: 2.6085
    Episode_Reward/pen_base_height: -0.2911
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1444
   Episode_Reward/pen_joint_torque: -0.2320
    Episode_Reward/pen_joint_accel: -0.1005
    Episode_Reward/pen_action_rate: -0.1103
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0529
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2370
Episode_Reward/pen_flat_orientation: -0.0913
  Episode_Reward/pen_feet_distance: -0.0304
Episode_Reward/pen_feet_regulation: -0.4835
   Episode_Reward/foot_landing_vel: -0.1207
   Episode_Reward/test_gait_reward: -0.8940
Metrics/base_velocity/error_vel_xy: 0.8756
Metrics/base_velocity/error_vel_yaw: 1.1907
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 209584128
                    Iteration time: 1.08s
                        Total time: 2328.06s
                               ETA: 948.9s

################################################################################
                     [1m Learning iteration 2132/3000 [0m                     

                       Computation: 90613 steps/s (collection: 0.960s, learning 0.125s)
               Value function loss: 0.4876
                    Surrogate loss: -0.0008
             Mean action noise std: 0.8413
                     Learning rate: 0.0001
                       Mean reward: 141.56
               Mean episode length: 998.99
       Episode_Reward/keep_balance: 0.9995
     Episode_Reward/rew_lin_vel_xy: 6.4349
      Episode_Reward/rew_ang_vel_z: 2.6310
    Episode_Reward/pen_base_height: -0.2943
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1480
   Episode_Reward/pen_joint_torque: -0.2305
    Episode_Reward/pen_joint_accel: -0.0975
    Episode_Reward/pen_action_rate: -0.1144
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0529
   Episode_Reward/pen_joint_powers: -0.0855
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2462
Episode_Reward/pen_flat_orientation: -0.0951
  Episode_Reward/pen_feet_distance: -0.0344
Episode_Reward/pen_feet_regulation: -0.4754
   Episode_Reward/foot_landing_vel: -0.1219
   Episode_Reward/test_gait_reward: -0.9096
Metrics/base_velocity/error_vel_xy: 0.9114
Metrics/base_velocity/error_vel_yaw: 1.2434
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 209682432
                    Iteration time: 1.08s
                        Total time: 2329.15s
                               ETA: 947.8s

################################################################################
                     [1m Learning iteration 2133/3000 [0m                     

                       Computation: 89137 steps/s (collection: 0.978s, learning 0.124s)
               Value function loss: 0.4975
                    Surrogate loss: -0.0047
             Mean action noise std: 0.8411
                     Learning rate: 0.0003
                       Mean reward: 144.08
               Mean episode length: 996.62
       Episode_Reward/keep_balance: 0.9972
     Episode_Reward/rew_lin_vel_xy: 6.4280
      Episode_Reward/rew_ang_vel_z: 2.6668
    Episode_Reward/pen_base_height: -0.2889
      Episode_Reward/pen_lin_vel_z: -0.0387
     Episode_Reward/pen_ang_vel_xy: -0.1521
   Episode_Reward/pen_joint_torque: -0.2342
    Episode_Reward/pen_joint_accel: -0.0991
    Episode_Reward/pen_action_rate: -0.1133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0540
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2439
Episode_Reward/pen_flat_orientation: -0.0921
  Episode_Reward/pen_feet_distance: -0.0359
Episode_Reward/pen_feet_regulation: -0.4723
   Episode_Reward/foot_landing_vel: -0.1272
   Episode_Reward/test_gait_reward: -0.8979
Metrics/base_velocity/error_vel_xy: 0.9097
Metrics/base_velocity/error_vel_yaw: 1.2012
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 209780736
                    Iteration time: 1.10s
                        Total time: 2330.25s
                               ETA: 946.7s

################################################################################
                     [1m Learning iteration 2134/3000 [0m                     

                       Computation: 88782 steps/s (collection: 0.984s, learning 0.123s)
               Value function loss: 0.4584
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8419
                     Learning rate: 0.0006
                       Mean reward: 141.73
               Mean episode length: 988.92
       Episode_Reward/keep_balance: 0.9938
     Episode_Reward/rew_lin_vel_xy: 6.4648
      Episode_Reward/rew_ang_vel_z: 2.6118
    Episode_Reward/pen_base_height: -0.2918
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1504
   Episode_Reward/pen_joint_torque: -0.2345
    Episode_Reward/pen_joint_accel: -0.1048
    Episode_Reward/pen_action_rate: -0.1144
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0867
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2446
Episode_Reward/pen_flat_orientation: -0.0944
  Episode_Reward/pen_feet_distance: -0.0335
Episode_Reward/pen_feet_regulation: -0.4795
   Episode_Reward/foot_landing_vel: -0.1237
   Episode_Reward/test_gait_reward: -0.9056
Metrics/base_velocity/error_vel_xy: 0.8859
Metrics/base_velocity/error_vel_yaw: 1.2307
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 209879040
                    Iteration time: 1.11s
                        Total time: 2331.36s
                               ETA: 945.6s

################################################################################
                     [1m Learning iteration 2135/3000 [0m                     

                       Computation: 88971 steps/s (collection: 0.981s, learning 0.124s)
               Value function loss: 0.4842
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8435
                     Learning rate: 0.0006
                       Mean reward: 142.93
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4809
      Episode_Reward/rew_ang_vel_z: 2.6547
    Episode_Reward/pen_base_height: -0.2901
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1445
   Episode_Reward/pen_joint_torque: -0.2368
    Episode_Reward/pen_joint_accel: -0.0967
    Episode_Reward/pen_action_rate: -0.1128
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0529
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2407
Episode_Reward/pen_flat_orientation: -0.0907
  Episode_Reward/pen_feet_distance: -0.0301
Episode_Reward/pen_feet_regulation: -0.4777
   Episode_Reward/foot_landing_vel: -0.1179
   Episode_Reward/test_gait_reward: -0.9104
Metrics/base_velocity/error_vel_xy: 0.9006
Metrics/base_velocity/error_vel_yaw: 1.2183
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 209977344
                    Iteration time: 1.10s
                        Total time: 2332.46s
                               ETA: 944.6s

################################################################################
                     [1m Learning iteration 2136/3000 [0m                     

                       Computation: 89276 steps/s (collection: 0.978s, learning 0.123s)
               Value function loss: 0.5319
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8437
                     Learning rate: 0.0013
                       Mean reward: 140.08
               Mean episode length: 982.42
       Episode_Reward/keep_balance: 0.9790
     Episode_Reward/rew_lin_vel_xy: 6.3029
      Episode_Reward/rew_ang_vel_z: 2.5814
    Episode_Reward/pen_base_height: -0.2824
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1434
   Episode_Reward/pen_joint_torque: -0.2205
    Episode_Reward/pen_joint_accel: -0.0951
    Episode_Reward/pen_action_rate: -0.1109
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0530
   Episode_Reward/pen_joint_powers: -0.0843
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2400
Episode_Reward/pen_flat_orientation: -0.0960
  Episode_Reward/pen_feet_distance: -0.0299
Episode_Reward/pen_feet_regulation: -0.4832
   Episode_Reward/foot_landing_vel: -0.1168
   Episode_Reward/test_gait_reward: -0.8892
Metrics/base_velocity/error_vel_xy: 0.8986
Metrics/base_velocity/error_vel_yaw: 1.2127
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 210075648
                    Iteration time: 1.10s
                        Total time: 2333.56s
                               ETA: 943.5s

################################################################################
                     [1m Learning iteration 2137/3000 [0m                     

                       Computation: 90362 steps/s (collection: 0.964s, learning 0.124s)
               Value function loss: 0.6444
                    Surrogate loss: -0.0011
             Mean action noise std: 0.8439
                     Learning rate: 0.0003
                       Mean reward: 139.69
               Mean episode length: 983.97
       Episode_Reward/keep_balance: 0.9935
     Episode_Reward/rew_lin_vel_xy: 6.3511
      Episode_Reward/rew_ang_vel_z: 2.6112
    Episode_Reward/pen_base_height: -0.2796
      Episode_Reward/pen_lin_vel_z: -0.0362
     Episode_Reward/pen_ang_vel_xy: -0.1454
   Episode_Reward/pen_joint_torque: -0.2237
    Episode_Reward/pen_joint_accel: -0.1166
    Episode_Reward/pen_action_rate: -0.1110
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0540
   Episode_Reward/pen_joint_powers: -0.0846
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2410
Episode_Reward/pen_flat_orientation: -0.0923
  Episode_Reward/pen_feet_distance: -0.0290
Episode_Reward/pen_feet_regulation: -0.4652
   Episode_Reward/foot_landing_vel: -0.1093
   Episode_Reward/test_gait_reward: -0.9052
Metrics/base_velocity/error_vel_xy: 0.9127
Metrics/base_velocity/error_vel_yaw: 1.2334
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 210173952
                    Iteration time: 1.09s
                        Total time: 2334.65s
                               ETA: 942.4s

################################################################################
                     [1m Learning iteration 2138/3000 [0m                     

                       Computation: 90033 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.5681
                    Surrogate loss: -0.0057
             Mean action noise std: 0.8440
                     Learning rate: 0.0006
                       Mean reward: 143.71
               Mean episode length: 991.50
       Episode_Reward/keep_balance: 0.9932
     Episode_Reward/rew_lin_vel_xy: 6.4249
      Episode_Reward/rew_ang_vel_z: 2.6606
    Episode_Reward/pen_base_height: -0.2898
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1409
   Episode_Reward/pen_joint_torque: -0.2403
    Episode_Reward/pen_joint_accel: -0.0998
    Episode_Reward/pen_action_rate: -0.1123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0538
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2408
Episode_Reward/pen_flat_orientation: -0.0928
  Episode_Reward/pen_feet_distance: -0.0293
Episode_Reward/pen_feet_regulation: -0.4660
   Episode_Reward/foot_landing_vel: -0.1223
   Episode_Reward/test_gait_reward: -0.9087
Metrics/base_velocity/error_vel_xy: 0.9038
Metrics/base_velocity/error_vel_yaw: 1.1963
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 210272256
                    Iteration time: 1.09s
                        Total time: 2335.74s
                               ETA: 941.3s

################################################################################
                     [1m Learning iteration 2139/3000 [0m                     

                       Computation: 89356 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.5438
                    Surrogate loss: -0.0026
             Mean action noise std: 0.8433
                     Learning rate: 0.0006
                       Mean reward: 136.79
               Mean episode length: 964.67
       Episode_Reward/keep_balance: 0.9698
     Episode_Reward/rew_lin_vel_xy: 6.2534
      Episode_Reward/rew_ang_vel_z: 2.5378
    Episode_Reward/pen_base_height: -0.2790
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1483
   Episode_Reward/pen_joint_torque: -0.2276
    Episode_Reward/pen_joint_accel: -0.0970
    Episode_Reward/pen_action_rate: -0.1103
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0534
   Episode_Reward/pen_joint_powers: -0.0858
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2376
Episode_Reward/pen_flat_orientation: -0.0942
  Episode_Reward/pen_feet_distance: -0.0363
Episode_Reward/pen_feet_regulation: -0.4661
   Episode_Reward/foot_landing_vel: -0.1123
   Episode_Reward/test_gait_reward: -0.8917
Metrics/base_velocity/error_vel_xy: 0.8741
Metrics/base_velocity/error_vel_yaw: 1.2225
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 210370560
                    Iteration time: 1.10s
                        Total time: 2336.84s
                               ETA: 940.2s

################################################################################
                     [1m Learning iteration 2140/3000 [0m                     

                       Computation: 85194 steps/s (collection: 1.028s, learning 0.125s)
               Value function loss: 0.5389
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8418
                     Learning rate: 0.0006
                       Mean reward: 137.50
               Mean episode length: 979.83
       Episode_Reward/keep_balance: 0.9808
     Episode_Reward/rew_lin_vel_xy: 6.2624
      Episode_Reward/rew_ang_vel_z: 2.5762
    Episode_Reward/pen_base_height: -0.2965
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.1483
   Episode_Reward/pen_joint_torque: -0.2352
    Episode_Reward/pen_joint_accel: -0.1006
    Episode_Reward/pen_action_rate: -0.1132
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2427
Episode_Reward/pen_flat_orientation: -0.1017
  Episode_Reward/pen_feet_distance: -0.0318
Episode_Reward/pen_feet_regulation: -0.4948
   Episode_Reward/foot_landing_vel: -0.1207
   Episode_Reward/test_gait_reward: -0.8918
Metrics/base_velocity/error_vel_xy: 0.9308
Metrics/base_velocity/error_vel_yaw: 1.2278
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 210468864
                    Iteration time: 1.15s
                        Total time: 2338.00s
                               ETA: 939.1s

################################################################################
                     [1m Learning iteration 2141/3000 [0m                     

                       Computation: 90354 steps/s (collection: 0.963s, learning 0.125s)
               Value function loss: 0.4977
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8417
                     Learning rate: 0.0004
                       Mean reward: 143.95
               Mean episode length: 997.62
       Episode_Reward/keep_balance: 0.9974
     Episode_Reward/rew_lin_vel_xy: 6.4544
      Episode_Reward/rew_ang_vel_z: 2.6361
    Episode_Reward/pen_base_height: -0.2785
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1513
   Episode_Reward/pen_joint_torque: -0.2219
    Episode_Reward/pen_joint_accel: -0.0971
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0535
   Episode_Reward/pen_joint_powers: -0.0844
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2428
Episode_Reward/pen_flat_orientation: -0.0930
  Episode_Reward/pen_feet_distance: -0.0331
Episode_Reward/pen_feet_regulation: -0.4744
   Episode_Reward/foot_landing_vel: -0.1196
   Episode_Reward/test_gait_reward: -0.9064
Metrics/base_velocity/error_vel_xy: 0.9039
Metrics/base_velocity/error_vel_yaw: 1.2272
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 210567168
                    Iteration time: 1.09s
                        Total time: 2339.08s
                               ETA: 938.0s

################################################################################
                     [1m Learning iteration 2142/3000 [0m                     

                       Computation: 89896 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.5640
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8415
                     Learning rate: 0.0009
                       Mean reward: 141.97
               Mean episode length: 999.22
       Episode_Reward/keep_balance: 0.9997
     Episode_Reward/rew_lin_vel_xy: 6.3983
      Episode_Reward/rew_ang_vel_z: 2.6137
    Episode_Reward/pen_base_height: -0.2816
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1534
   Episode_Reward/pen_joint_torque: -0.2272
    Episode_Reward/pen_joint_accel: -0.1123
    Episode_Reward/pen_action_rate: -0.1133
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2471
Episode_Reward/pen_flat_orientation: -0.0908
  Episode_Reward/pen_feet_distance: -0.0301
Episode_Reward/pen_feet_regulation: -0.4842
   Episode_Reward/foot_landing_vel: -0.1191
   Episode_Reward/test_gait_reward: -0.9069
Metrics/base_velocity/error_vel_xy: 0.9302
Metrics/base_velocity/error_vel_yaw: 1.2598
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 210665472
                    Iteration time: 1.09s
                        Total time: 2340.18s
                               ETA: 936.9s

################################################################################
                     [1m Learning iteration 2143/3000 [0m                     

                       Computation: 89296 steps/s (collection: 0.977s, learning 0.124s)
               Value function loss: 0.5076
                    Surrogate loss: -0.0005
             Mean action noise std: 0.8419
                     Learning rate: 0.0001
                       Mean reward: 139.57
               Mean episode length: 984.97
       Episode_Reward/keep_balance: 0.9851
     Episode_Reward/rew_lin_vel_xy: 6.3378
      Episode_Reward/rew_ang_vel_z: 2.5806
    Episode_Reward/pen_base_height: -0.2894
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1499
   Episode_Reward/pen_joint_torque: -0.2259
    Episode_Reward/pen_joint_accel: -0.1009
    Episode_Reward/pen_action_rate: -0.1112
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2405
Episode_Reward/pen_flat_orientation: -0.0940
  Episode_Reward/pen_feet_distance: -0.0345
Episode_Reward/pen_feet_regulation: -0.4816
   Episode_Reward/foot_landing_vel: -0.1233
   Episode_Reward/test_gait_reward: -0.8959
Metrics/base_velocity/error_vel_xy: 0.9154
Metrics/base_velocity/error_vel_yaw: 1.2381
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 210763776
                    Iteration time: 1.10s
                        Total time: 2341.28s
                               ETA: 935.9s

################################################################################
                     [1m Learning iteration 2144/3000 [0m                     

                       Computation: 91874 steps/s (collection: 0.948s, learning 0.122s)
               Value function loss: 0.4583
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8405
                     Learning rate: 0.0004
                       Mean reward: 138.37
               Mean episode length: 974.57
       Episode_Reward/keep_balance: 0.9853
     Episode_Reward/rew_lin_vel_xy: 6.3620
      Episode_Reward/rew_ang_vel_z: 2.5829
    Episode_Reward/pen_base_height: -0.2880
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1476
   Episode_Reward/pen_joint_torque: -0.2432
    Episode_Reward/pen_joint_accel: -0.1019
    Episode_Reward/pen_action_rate: -0.1129
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0539
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2422
Episode_Reward/pen_flat_orientation: -0.0951
  Episode_Reward/pen_feet_distance: -0.0330
Episode_Reward/pen_feet_regulation: -0.4887
   Episode_Reward/foot_landing_vel: -0.1212
   Episode_Reward/test_gait_reward: -0.8950
Metrics/base_velocity/error_vel_xy: 0.8877
Metrics/base_velocity/error_vel_yaw: 1.2300
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 210862080
                    Iteration time: 1.07s
                        Total time: 2342.35s
                               ETA: 934.8s

################################################################################
                     [1m Learning iteration 2145/3000 [0m                     

                       Computation: 89539 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 0.4496
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8419
                     Learning rate: 0.0004
                       Mean reward: 141.25
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.3836
      Episode_Reward/rew_ang_vel_z: 2.6167
    Episode_Reward/pen_base_height: -0.2930
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1577
   Episode_Reward/pen_joint_torque: -0.2289
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.1134
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0549
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2454
Episode_Reward/pen_flat_orientation: -0.0902
  Episode_Reward/pen_feet_distance: -0.0339
Episode_Reward/pen_feet_regulation: -0.4818
   Episode_Reward/foot_landing_vel: -0.1231
   Episode_Reward/test_gait_reward: -0.9048
Metrics/base_velocity/error_vel_xy: 0.9438
Metrics/base_velocity/error_vel_yaw: 1.2602
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 210960384
                    Iteration time: 1.10s
                        Total time: 2343.45s
                               ETA: 933.7s

################################################################################
                     [1m Learning iteration 2146/3000 [0m                     

                       Computation: 89611 steps/s (collection: 0.975s, learning 0.122s)
               Value function loss: 0.5018
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8422
                     Learning rate: 0.0004
                       Mean reward: 140.08
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4031
      Episode_Reward/rew_ang_vel_z: 2.6038
    Episode_Reward/pen_base_height: -0.2933
      Episode_Reward/pen_lin_vel_z: -0.0389
     Episode_Reward/pen_ang_vel_xy: -0.1533
   Episode_Reward/pen_joint_torque: -0.2354
    Episode_Reward/pen_joint_accel: -0.0995
    Episode_Reward/pen_action_rate: -0.1148
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2487
Episode_Reward/pen_flat_orientation: -0.0918
  Episode_Reward/pen_feet_distance: -0.0336
Episode_Reward/pen_feet_regulation: -0.5018
   Episode_Reward/foot_landing_vel: -0.1241
   Episode_Reward/test_gait_reward: -0.9129
Metrics/base_velocity/error_vel_xy: 0.9506
Metrics/base_velocity/error_vel_yaw: 1.2729
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 211058688
                    Iteration time: 1.10s
                        Total time: 2344.54s
                               ETA: 932.6s

################################################################################
                     [1m Learning iteration 2147/3000 [0m                     

                       Computation: 88635 steps/s (collection: 0.986s, learning 0.123s)
               Value function loss: 0.4305
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8417
                     Learning rate: 0.0004
                       Mean reward: 144.03
               Mean episode length: 999.54
       Episode_Reward/keep_balance: 0.9995
     Episode_Reward/rew_lin_vel_xy: 6.4382
      Episode_Reward/rew_ang_vel_z: 2.6465
    Episode_Reward/pen_base_height: -0.2798
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1500
   Episode_Reward/pen_joint_torque: -0.2300
    Episode_Reward/pen_joint_accel: -0.1096
    Episode_Reward/pen_action_rate: -0.1127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0538
   Episode_Reward/pen_joint_powers: -0.0849
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2423
Episode_Reward/pen_flat_orientation: -0.0929
  Episode_Reward/pen_feet_distance: -0.0338
Episode_Reward/pen_feet_regulation: -0.4701
   Episode_Reward/foot_landing_vel: -0.1184
   Episode_Reward/test_gait_reward: -0.9005
Metrics/base_velocity/error_vel_xy: 0.9042
Metrics/base_velocity/error_vel_yaw: 1.2239
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 211156992
                    Iteration time: 1.11s
                        Total time: 2345.65s
                               ETA: 931.5s

################################################################################
                     [1m Learning iteration 2148/3000 [0m                     

                       Computation: 89767 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.4857
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8417
                     Learning rate: 0.0009
                       Mean reward: 141.26
               Mean episode length: 982.83
       Episode_Reward/keep_balance: 0.9826
     Episode_Reward/rew_lin_vel_xy: 6.3771
      Episode_Reward/rew_ang_vel_z: 2.5574
    Episode_Reward/pen_base_height: -0.2693
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1471
   Episode_Reward/pen_joint_torque: -0.2225
    Episode_Reward/pen_joint_accel: -0.0928
    Episode_Reward/pen_action_rate: -0.1110
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0525
   Episode_Reward/pen_joint_powers: -0.0838
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2419
Episode_Reward/pen_flat_orientation: -0.0900
  Episode_Reward/pen_feet_distance: -0.0330
Episode_Reward/pen_feet_regulation: -0.4620
   Episode_Reward/foot_landing_vel: -0.1206
   Episode_Reward/test_gait_reward: -0.8863
Metrics/base_velocity/error_vel_xy: 0.8697
Metrics/base_velocity/error_vel_yaw: 1.2392
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 211255296
                    Iteration time: 1.10s
                        Total time: 2346.75s
                               ETA: 930.4s

################################################################################
                     [1m Learning iteration 2149/3000 [0m                     

                       Computation: 90110 steps/s (collection: 0.966s, learning 0.125s)
               Value function loss: 0.6014
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8435
                     Learning rate: 0.0006
                       Mean reward: 140.33
               Mean episode length: 991.39
       Episode_Reward/keep_balance: 0.9940
     Episode_Reward/rew_lin_vel_xy: 6.3369
      Episode_Reward/rew_ang_vel_z: 2.6076
    Episode_Reward/pen_base_height: -0.2901
      Episode_Reward/pen_lin_vel_z: -0.0392
     Episode_Reward/pen_ang_vel_xy: -0.1467
   Episode_Reward/pen_joint_torque: -0.2405
    Episode_Reward/pen_joint_accel: -0.1101
    Episode_Reward/pen_action_rate: -0.1146
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0883
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2430
Episode_Reward/pen_flat_orientation: -0.0949
  Episode_Reward/pen_feet_distance: -0.0326
Episode_Reward/pen_feet_regulation: -0.4936
   Episode_Reward/foot_landing_vel: -0.1160
   Episode_Reward/test_gait_reward: -0.9059
Metrics/base_velocity/error_vel_xy: 0.9396
Metrics/base_velocity/error_vel_yaw: 1.2410
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 211353600
                    Iteration time: 1.09s
                        Total time: 2347.84s
                               ETA: 929.3s

################################################################################
                     [1m Learning iteration 2150/3000 [0m                     

                       Computation: 89255 steps/s (collection: 0.977s, learning 0.124s)
               Value function loss: 0.5121
                    Surrogate loss: -0.0044
             Mean action noise std: 0.8430
                     Learning rate: 0.0006
                       Mean reward: 140.41
               Mean episode length: 984.67
       Episode_Reward/keep_balance: 0.9886
     Episode_Reward/rew_lin_vel_xy: 6.3488
      Episode_Reward/rew_ang_vel_z: 2.5933
    Episode_Reward/pen_base_height: -0.2833
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1497
   Episode_Reward/pen_joint_torque: -0.2357
    Episode_Reward/pen_joint_accel: -0.1245
    Episode_Reward/pen_action_rate: -0.1136
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0870
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2431
Episode_Reward/pen_flat_orientation: -0.0931
  Episode_Reward/pen_feet_distance: -0.0278
Episode_Reward/pen_feet_regulation: -0.4658
   Episode_Reward/foot_landing_vel: -0.1277
   Episode_Reward/test_gait_reward: -0.8941
Metrics/base_velocity/error_vel_xy: 0.9051
Metrics/base_velocity/error_vel_yaw: 1.2301
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 211451904
                    Iteration time: 1.10s
                        Total time: 2348.94s
                               ETA: 928.2s

################################################################################
                     [1m Learning iteration 2151/3000 [0m                     

                       Computation: 89264 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 0.5141
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8433
                     Learning rate: 0.0004
                       Mean reward: 140.17
               Mean episode length: 984.04
       Episode_Reward/keep_balance: 0.9831
     Episode_Reward/rew_lin_vel_xy: 6.3092
      Episode_Reward/rew_ang_vel_z: 2.5827
    Episode_Reward/pen_base_height: -0.2862
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.1520
   Episode_Reward/pen_joint_torque: -0.2235
    Episode_Reward/pen_joint_accel: -0.1051
    Episode_Reward/pen_action_rate: -0.1118
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0547
   Episode_Reward/pen_joint_powers: -0.0856
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2415
Episode_Reward/pen_flat_orientation: -0.0948
  Episode_Reward/pen_feet_distance: -0.0366
Episode_Reward/pen_feet_regulation: -0.4741
   Episode_Reward/foot_landing_vel: -0.1261
   Episode_Reward/test_gait_reward: -0.8861
Metrics/base_velocity/error_vel_xy: 0.9230
Metrics/base_velocity/error_vel_yaw: 1.2268
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 211550208
                    Iteration time: 1.10s
                        Total time: 2350.04s
                               ETA: 927.1s

################################################################################
                     [1m Learning iteration 2152/3000 [0m                     

                       Computation: 90760 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 0.4839
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8438
                     Learning rate: 0.0003
                       Mean reward: 143.70
               Mean episode length: 988.24
       Episode_Reward/keep_balance: 0.9836
     Episode_Reward/rew_lin_vel_xy: 6.3537
      Episode_Reward/rew_ang_vel_z: 2.6068
    Episode_Reward/pen_base_height: -0.2831
      Episode_Reward/pen_lin_vel_z: -0.0377
     Episode_Reward/pen_ang_vel_xy: -0.1453
   Episode_Reward/pen_joint_torque: -0.2211
    Episode_Reward/pen_joint_accel: -0.0930
    Episode_Reward/pen_action_rate: -0.1104
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0526
   Episode_Reward/pen_joint_powers: -0.0832
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2373
Episode_Reward/pen_flat_orientation: -0.0920
  Episode_Reward/pen_feet_distance: -0.0323
Episode_Reward/pen_feet_regulation: -0.4740
   Episode_Reward/foot_landing_vel: -0.1152
   Episode_Reward/test_gait_reward: -0.8833
Metrics/base_velocity/error_vel_xy: 0.8945
Metrics/base_velocity/error_vel_yaw: 1.2070
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 211648512
                    Iteration time: 1.08s
                        Total time: 2351.12s
                               ETA: 926.0s

################################################################################
                     [1m Learning iteration 2153/3000 [0m                     

                       Computation: 87724 steps/s (collection: 0.992s, learning 0.128s)
               Value function loss: 0.5211
                    Surrogate loss: -0.0038
             Mean action noise std: 0.8440
                     Learning rate: 0.0006
                       Mean reward: 140.86
               Mean episode length: 994.18
       Episode_Reward/keep_balance: 0.9960
     Episode_Reward/rew_lin_vel_xy: 6.3715
      Episode_Reward/rew_ang_vel_z: 2.6185
    Episode_Reward/pen_base_height: -0.2828
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.1526
   Episode_Reward/pen_joint_torque: -0.2348
    Episode_Reward/pen_joint_accel: -0.1018
    Episode_Reward/pen_action_rate: -0.1141
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0559
   Episode_Reward/pen_joint_powers: -0.0889
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2434
Episode_Reward/pen_flat_orientation: -0.0939
  Episode_Reward/pen_feet_distance: -0.0319
Episode_Reward/pen_feet_regulation: -0.4945
   Episode_Reward/foot_landing_vel: -0.1198
   Episode_Reward/test_gait_reward: -0.9078
Metrics/base_velocity/error_vel_xy: 0.9232
Metrics/base_velocity/error_vel_yaw: 1.2449
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 211746816
                    Iteration time: 1.12s
                        Total time: 2352.24s
                               ETA: 925.0s

################################################################################
                     [1m Learning iteration 2154/3000 [0m                     

                       Computation: 90115 steps/s (collection: 0.967s, learning 0.123s)
               Value function loss: 0.5256
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8437
                     Learning rate: 0.0004
                       Mean reward: 140.94
               Mean episode length: 992.52
       Episode_Reward/keep_balance: 0.9896
     Episode_Reward/rew_lin_vel_xy: 6.3288
      Episode_Reward/rew_ang_vel_z: 2.6258
    Episode_Reward/pen_base_height: -0.2782
      Episode_Reward/pen_lin_vel_z: -0.0375
     Episode_Reward/pen_ang_vel_xy: -0.1470
   Episode_Reward/pen_joint_torque: -0.2265
    Episode_Reward/pen_joint_accel: -0.1025
    Episode_Reward/pen_action_rate: -0.1125
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0541
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2412
Episode_Reward/pen_flat_orientation: -0.0930
  Episode_Reward/pen_feet_distance: -0.0327
Episode_Reward/pen_feet_regulation: -0.4689
   Episode_Reward/foot_landing_vel: -0.1228
   Episode_Reward/test_gait_reward: -0.8873
Metrics/base_velocity/error_vel_xy: 0.9305
Metrics/base_velocity/error_vel_yaw: 1.2147
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 211845120
                    Iteration time: 1.09s
                        Total time: 2353.34s
                               ETA: 923.9s

################################################################################
                     [1m Learning iteration 2155/3000 [0m                     

                       Computation: 89775 steps/s (collection: 0.973s, learning 0.122s)
               Value function loss: 0.4831
                    Surrogate loss: -0.0053
             Mean action noise std: 0.8429
                     Learning rate: 0.0006
                       Mean reward: 139.26
               Mean episode length: 985.34
       Episode_Reward/keep_balance: 0.9913
     Episode_Reward/rew_lin_vel_xy: 6.3862
      Episode_Reward/rew_ang_vel_z: 2.6124
    Episode_Reward/pen_base_height: -0.2799
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1553
   Episode_Reward/pen_joint_torque: -0.2399
    Episode_Reward/pen_joint_accel: -0.1052
    Episode_Reward/pen_action_rate: -0.1145
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0566
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2454
Episode_Reward/pen_flat_orientation: -0.0922
  Episode_Reward/pen_feet_distance: -0.0341
Episode_Reward/pen_feet_regulation: -0.4848
   Episode_Reward/foot_landing_vel: -0.1244
   Episode_Reward/test_gait_reward: -0.8935
Metrics/base_velocity/error_vel_xy: 0.9065
Metrics/base_velocity/error_vel_yaw: 1.2338
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 211943424
                    Iteration time: 1.10s
                        Total time: 2354.43s
                               ETA: 922.8s

################################################################################
                     [1m Learning iteration 2156/3000 [0m                     

                       Computation: 91285 steps/s (collection: 0.954s, learning 0.123s)
               Value function loss: 0.5803
                    Surrogate loss: -0.0052
             Mean action noise std: 0.8425
                     Learning rate: 0.0009
                       Mean reward: 136.85
               Mean episode length: 972.97
       Episode_Reward/keep_balance: 0.9677
     Episode_Reward/rew_lin_vel_xy: 6.2109
      Episode_Reward/rew_ang_vel_z: 2.5351
    Episode_Reward/pen_base_height: -0.2774
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1458
   Episode_Reward/pen_joint_torque: -0.2359
    Episode_Reward/pen_joint_accel: -0.1029
    Episode_Reward/pen_action_rate: -0.1117
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0539
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2371
Episode_Reward/pen_flat_orientation: -0.0932
  Episode_Reward/pen_feet_distance: -0.0275
Episode_Reward/pen_feet_regulation: -0.4669
   Episode_Reward/foot_landing_vel: -0.1261
   Episode_Reward/test_gait_reward: -0.8756
Metrics/base_velocity/error_vel_xy: 0.8989
Metrics/base_velocity/error_vel_yaw: 1.2111
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 212041728
                    Iteration time: 1.08s
                        Total time: 2355.51s
                               ETA: 921.7s

################################################################################
                     [1m Learning iteration 2157/3000 [0m                     

                       Computation: 89154 steps/s (collection: 0.980s, learning 0.122s)
               Value function loss: 0.5220
                    Surrogate loss: -0.0033
             Mean action noise std: 0.8433
                     Learning rate: 0.0001
                       Mean reward: 142.30
               Mean episode length: 977.23
       Episode_Reward/keep_balance: 0.9856
     Episode_Reward/rew_lin_vel_xy: 6.4432
      Episode_Reward/rew_ang_vel_z: 2.6506
    Episode_Reward/pen_base_height: -0.2752
      Episode_Reward/pen_lin_vel_z: -0.0365
     Episode_Reward/pen_ang_vel_xy: -0.1381
   Episode_Reward/pen_joint_torque: -0.2266
    Episode_Reward/pen_joint_accel: -0.0975
    Episode_Reward/pen_action_rate: -0.1089
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0509
   Episode_Reward/pen_joint_powers: -0.0815
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2350
Episode_Reward/pen_flat_orientation: -0.0875
  Episode_Reward/pen_feet_distance: -0.0309
Episode_Reward/pen_feet_regulation: -0.4339
   Episode_Reward/foot_landing_vel: -0.1154
   Episode_Reward/test_gait_reward: -0.8738
Metrics/base_velocity/error_vel_xy: 0.8520
Metrics/base_velocity/error_vel_yaw: 1.1741
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 212140032
                    Iteration time: 1.10s
                        Total time: 2356.61s
                               ETA: 920.6s

################################################################################
                     [1m Learning iteration 2158/3000 [0m                     

                       Computation: 89316 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 0.4721
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8438
                     Learning rate: 0.0003
                       Mean reward: 137.53
               Mean episode length: 986.57
       Episode_Reward/keep_balance: 0.9792
     Episode_Reward/rew_lin_vel_xy: 6.2664
      Episode_Reward/rew_ang_vel_z: 2.5626
    Episode_Reward/pen_base_height: -0.2872
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1493
   Episode_Reward/pen_joint_torque: -0.2447
    Episode_Reward/pen_joint_accel: -0.1061
    Episode_Reward/pen_action_rate: -0.1136
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2410
Episode_Reward/pen_flat_orientation: -0.1018
  Episode_Reward/pen_feet_distance: -0.0327
Episode_Reward/pen_feet_regulation: -0.4984
   Episode_Reward/foot_landing_vel: -0.1277
   Episode_Reward/test_gait_reward: -0.8905
Metrics/base_velocity/error_vel_xy: 0.9209
Metrics/base_velocity/error_vel_yaw: 1.2321
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 212238336
                    Iteration time: 1.10s
                        Total time: 2357.71s
                               ETA: 919.5s

################################################################################
                     [1m Learning iteration 2159/3000 [0m                     

                       Computation: 88774 steps/s (collection: 0.983s, learning 0.124s)
               Value function loss: 0.4861
                    Surrogate loss: -0.0060
             Mean action noise std: 0.8450
                     Learning rate: 0.0006
                       Mean reward: 144.59
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4663
      Episode_Reward/rew_ang_vel_z: 2.6650
    Episode_Reward/pen_base_height: -0.2750
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1465
   Episode_Reward/pen_joint_torque: -0.2402
    Episode_Reward/pen_joint_accel: -0.0995
    Episode_Reward/pen_action_rate: -0.1130
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0533
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2415
Episode_Reward/pen_flat_orientation: -0.0913
  Episode_Reward/pen_feet_distance: -0.0323
Episode_Reward/pen_feet_regulation: -0.4625
   Episode_Reward/foot_landing_vel: -0.1109
   Episode_Reward/test_gait_reward: -0.8960
Metrics/base_velocity/error_vel_xy: 0.9037
Metrics/base_velocity/error_vel_yaw: 1.2086
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 212336640
                    Iteration time: 1.11s
                        Total time: 2358.82s
                               ETA: 918.4s

################################################################################
                     [1m Learning iteration 2160/3000 [0m                     

                       Computation: 91587 steps/s (collection: 0.951s, learning 0.122s)
               Value function loss: 0.5169
                    Surrogate loss: -0.0040
             Mean action noise std: 0.8463
                     Learning rate: 0.0006
                       Mean reward: 141.22
               Mean episode length: 983.74
       Episode_Reward/keep_balance: 0.9779
     Episode_Reward/rew_lin_vel_xy: 6.3088
      Episode_Reward/rew_ang_vel_z: 2.5979
    Episode_Reward/pen_base_height: -0.2800
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1450
   Episode_Reward/pen_joint_torque: -0.2258
    Episode_Reward/pen_joint_accel: -0.1039
    Episode_Reward/pen_action_rate: -0.1101
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0534
   Episode_Reward/pen_joint_powers: -0.0837
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2377
Episode_Reward/pen_flat_orientation: -0.0921
  Episode_Reward/pen_feet_distance: -0.0330
Episode_Reward/pen_feet_regulation: -0.4583
   Episode_Reward/foot_landing_vel: -0.1251
   Episode_Reward/test_gait_reward: -0.8733
Metrics/base_velocity/error_vel_xy: 0.8817
Metrics/base_velocity/error_vel_yaw: 1.1971
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 212434944
                    Iteration time: 1.07s
                        Total time: 2359.89s
                               ETA: 917.3s

################################################################################
                     [1m Learning iteration 2161/3000 [0m                     

                       Computation: 88456 steps/s (collection: 0.983s, learning 0.128s)
               Value function loss: 0.6145
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8464
                     Learning rate: 0.0003
                       Mean reward: 140.78
               Mean episode length: 989.56
       Episode_Reward/keep_balance: 0.9741
     Episode_Reward/rew_lin_vel_xy: 6.2709
      Episode_Reward/rew_ang_vel_z: 2.5873
    Episode_Reward/pen_base_height: -0.2825
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1468
   Episode_Reward/pen_joint_torque: -0.2225
    Episode_Reward/pen_joint_accel: -0.1125
    Episode_Reward/pen_action_rate: -0.1105
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2387
Episode_Reward/pen_flat_orientation: -0.0921
  Episode_Reward/pen_feet_distance: -0.0301
Episode_Reward/pen_feet_regulation: -0.4665
   Episode_Reward/foot_landing_vel: -0.1237
   Episode_Reward/test_gait_reward: -0.8801
Metrics/base_velocity/error_vel_xy: 0.8899
Metrics/base_velocity/error_vel_yaw: 1.2039
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 212533248
                    Iteration time: 1.11s
                        Total time: 2361.00s
                               ETA: 916.2s

################################################################################
                     [1m Learning iteration 2162/3000 [0m                     

                       Computation: 91141 steps/s (collection: 0.956s, learning 0.123s)
               Value function loss: 0.4655
                    Surrogate loss: -0.0021
             Mean action noise std: 0.8459
                     Learning rate: 0.0000
                       Mean reward: 138.80
               Mean episode length: 975.30
       Episode_Reward/keep_balance: 0.9762
     Episode_Reward/rew_lin_vel_xy: 6.3576
      Episode_Reward/rew_ang_vel_z: 2.5146
    Episode_Reward/pen_base_height: -0.2830
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1488
   Episode_Reward/pen_joint_torque: -0.2345
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1128
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2432
Episode_Reward/pen_flat_orientation: -0.0921
  Episode_Reward/pen_feet_distance: -0.0271
Episode_Reward/pen_feet_regulation: -0.4880
   Episode_Reward/foot_landing_vel: -0.1254
   Episode_Reward/test_gait_reward: -0.8792
Metrics/base_velocity/error_vel_xy: 0.8665
Metrics/base_velocity/error_vel_yaw: 1.2748
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 212631552
                    Iteration time: 1.08s
                        Total time: 2362.08s
                               ETA: 915.1s

################################################################################
                     [1m Learning iteration 2163/3000 [0m                     

                       Computation: 90318 steps/s (collection: 0.966s, learning 0.123s)
               Value function loss: 0.5340
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8450
                     Learning rate: 0.0001
                       Mean reward: 142.39
               Mean episode length: 996.04
       Episode_Reward/keep_balance: 0.9959
     Episode_Reward/rew_lin_vel_xy: 6.4357
      Episode_Reward/rew_ang_vel_z: 2.6785
    Episode_Reward/pen_base_height: -0.2736
      Episode_Reward/pen_lin_vel_z: -0.0385
     Episode_Reward/pen_ang_vel_xy: -0.1436
   Episode_Reward/pen_joint_torque: -0.2387
    Episode_Reward/pen_joint_accel: -0.0996
    Episode_Reward/pen_action_rate: -0.1114
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0524
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2389
Episode_Reward/pen_flat_orientation: -0.0918
  Episode_Reward/pen_feet_distance: -0.0269
Episode_Reward/pen_feet_regulation: -0.4476
   Episode_Reward/foot_landing_vel: -0.1199
   Episode_Reward/test_gait_reward: -0.8885
Metrics/base_velocity/error_vel_xy: 0.8872
Metrics/base_velocity/error_vel_yaw: 1.1881
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 212729856
                    Iteration time: 1.09s
                        Total time: 2363.17s
                               ETA: 914.0s

################################################################################
                     [1m Learning iteration 2164/3000 [0m                     

                       Computation: 90409 steps/s (collection: 0.956s, learning 0.132s)
               Value function loss: 0.5130
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8451
                     Learning rate: 0.0004
                       Mean reward: 139.45
               Mean episode length: 984.44
       Episode_Reward/keep_balance: 0.9863
     Episode_Reward/rew_lin_vel_xy: 6.2980
      Episode_Reward/rew_ang_vel_z: 2.6121
    Episode_Reward/pen_base_height: -0.2805
      Episode_Reward/pen_lin_vel_z: -0.0368
     Episode_Reward/pen_ang_vel_xy: -0.1453
   Episode_Reward/pen_joint_torque: -0.2246
    Episode_Reward/pen_joint_accel: -0.1013
    Episode_Reward/pen_action_rate: -0.1113
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0539
   Episode_Reward/pen_joint_powers: -0.0836
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2414
Episode_Reward/pen_flat_orientation: -0.0966
  Episode_Reward/pen_feet_distance: -0.0305
Episode_Reward/pen_feet_regulation: -0.4752
   Episode_Reward/foot_landing_vel: -0.1252
   Episode_Reward/test_gait_reward: -0.8844
Metrics/base_velocity/error_vel_xy: 0.9210
Metrics/base_velocity/error_vel_yaw: 1.2224
      Episode_Termination/time_out: 3.5417
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 212828160
                    Iteration time: 1.09s
                        Total time: 2364.26s
                               ETA: 912.9s

################################################################################
                     [1m Learning iteration 2165/3000 [0m                     

                       Computation: 86876 steps/s (collection: 1.007s, learning 0.125s)
               Value function loss: 0.5412
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8463
                     Learning rate: 0.0003
                       Mean reward: 139.99
               Mean episode length: 978.75
       Episode_Reward/keep_balance: 0.9773
     Episode_Reward/rew_lin_vel_xy: 6.2908
      Episode_Reward/rew_ang_vel_z: 2.5716
    Episode_Reward/pen_base_height: -0.2748
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1476
   Episode_Reward/pen_joint_torque: -0.2371
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.1120
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0541
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2413
Episode_Reward/pen_flat_orientation: -0.0942
  Episode_Reward/pen_feet_distance: -0.0256
Episode_Reward/pen_feet_regulation: -0.4509
   Episode_Reward/foot_landing_vel: -0.1206
   Episode_Reward/test_gait_reward: -0.8714
Metrics/base_velocity/error_vel_xy: 0.8962
Metrics/base_velocity/error_vel_yaw: 1.2222
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 212926464
                    Iteration time: 1.13s
                        Total time: 2365.39s
                               ETA: 911.9s

################################################################################
                     [1m Learning iteration 2166/3000 [0m                     

                       Computation: 89407 steps/s (collection: 0.975s, learning 0.124s)
               Value function loss: 0.4927
                    Surrogate loss: -0.0054
             Mean action noise std: 0.8468
                     Learning rate: 0.0006
                       Mean reward: 144.27
               Mean episode length: 990.98
       Episode_Reward/keep_balance: 0.9963
     Episode_Reward/rew_lin_vel_xy: 6.4515
      Episode_Reward/rew_ang_vel_z: 2.6599
    Episode_Reward/pen_base_height: -0.2657
      Episode_Reward/pen_lin_vel_z: -0.0359
     Episode_Reward/pen_ang_vel_xy: -0.1410
   Episode_Reward/pen_joint_torque: -0.2288
    Episode_Reward/pen_joint_accel: -0.1010
    Episode_Reward/pen_action_rate: -0.1113
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0539
   Episode_Reward/pen_joint_powers: -0.0853
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2402
Episode_Reward/pen_flat_orientation: -0.0879
  Episode_Reward/pen_feet_distance: -0.0282
Episode_Reward/pen_feet_regulation: -0.4590
   Episode_Reward/foot_landing_vel: -0.1233
   Episode_Reward/test_gait_reward: -0.8878
Metrics/base_velocity/error_vel_xy: 0.8815
Metrics/base_velocity/error_vel_yaw: 1.2032
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 213024768
                    Iteration time: 1.10s
                        Total time: 2366.49s
                               ETA: 910.8s

################################################################################
                     [1m Learning iteration 2167/3000 [0m                     

                       Computation: 88610 steps/s (collection: 0.985s, learning 0.124s)
               Value function loss: 1.4326
                    Surrogate loss: -0.0009
             Mean action noise std: 0.8474
                     Learning rate: 0.0004
                       Mean reward: 145.45
               Mean episode length: 989.61
       Episode_Reward/keep_balance: 0.9931
     Episode_Reward/rew_lin_vel_xy: 6.5225
      Episode_Reward/rew_ang_vel_z: 2.6533
    Episode_Reward/pen_base_height: -0.2735
      Episode_Reward/pen_lin_vel_z: -0.0354
     Episode_Reward/pen_ang_vel_xy: -0.1486
   Episode_Reward/pen_joint_torque: -0.2206
    Episode_Reward/pen_joint_accel: -0.1010
    Episode_Reward/pen_action_rate: -0.1113
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0526
   Episode_Reward/pen_joint_powers: -0.0825
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2394
Episode_Reward/pen_flat_orientation: -0.0861
  Episode_Reward/pen_feet_distance: -0.0315
Episode_Reward/pen_feet_regulation: -0.4466
   Episode_Reward/foot_landing_vel: -0.1120
   Episode_Reward/test_gait_reward: -0.8845
Metrics/base_velocity/error_vel_xy: 0.8362
Metrics/base_velocity/error_vel_yaw: 1.2036
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 213123072
                    Iteration time: 1.11s
                        Total time: 2367.60s
                               ETA: 909.7s

################################################################################
                     [1m Learning iteration 2168/3000 [0m                     

                       Computation: 87814 steps/s (collection: 0.994s, learning 0.126s)
               Value function loss: 0.6758
                    Surrogate loss: -0.0068
             Mean action noise std: 0.8476
                     Learning rate: 0.0009
                       Mean reward: 138.96
               Mean episode length: 988.09
       Episode_Reward/keep_balance: 0.9931
     Episode_Reward/rew_lin_vel_xy: 6.3191
      Episode_Reward/rew_ang_vel_z: 2.5647
    Episode_Reward/pen_base_height: -0.2853
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1567
   Episode_Reward/pen_joint_torque: -0.2303
    Episode_Reward/pen_joint_accel: -0.1115
    Episode_Reward/pen_action_rate: -0.1163
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0576
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2498
Episode_Reward/pen_flat_orientation: -0.0963
  Episode_Reward/pen_feet_distance: -0.0324
Episode_Reward/pen_feet_regulation: -0.5023
   Episode_Reward/foot_landing_vel: -0.1237
   Episode_Reward/test_gait_reward: -0.9000
Metrics/base_velocity/error_vel_xy: 0.9488
Metrics/base_velocity/error_vel_yaw: 1.2912
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 213221376
                    Iteration time: 1.12s
                        Total time: 2368.72s
                               ETA: 908.6s

################################################################################
                     [1m Learning iteration 2169/3000 [0m                     

                       Computation: 89846 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.5134
                    Surrogate loss: -0.0017
             Mean action noise std: 0.8473
                     Learning rate: 0.0000
                       Mean reward: 136.67
               Mean episode length: 974.37
       Episode_Reward/keep_balance: 0.9677
     Episode_Reward/rew_lin_vel_xy: 6.1893
      Episode_Reward/rew_ang_vel_z: 2.5349
    Episode_Reward/pen_base_height: -0.2886
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1485
   Episode_Reward/pen_joint_torque: -0.2303
    Episode_Reward/pen_joint_accel: -0.1118
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2411
Episode_Reward/pen_flat_orientation: -0.0956
  Episode_Reward/pen_feet_distance: -0.0309
Episode_Reward/pen_feet_regulation: -0.4869
   Episode_Reward/foot_landing_vel: -0.1197
   Episode_Reward/test_gait_reward: -0.8646
Metrics/base_velocity/error_vel_xy: 0.9144
Metrics/base_velocity/error_vel_yaw: 1.2312
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 213319680
                    Iteration time: 1.09s
                        Total time: 2369.81s
                               ETA: 907.5s

################################################################################
                     [1m Learning iteration 2170/3000 [0m                     

                       Computation: 88906 steps/s (collection: 0.982s, learning 0.124s)
               Value function loss: 0.4873
                    Surrogate loss: -0.0045
             Mean action noise std: 0.8463
                     Learning rate: 0.0001
                       Mean reward: 142.69
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 0.9803
     Episode_Reward/rew_lin_vel_xy: 6.3240
      Episode_Reward/rew_ang_vel_z: 2.5773
    Episode_Reward/pen_base_height: -0.2817
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1525
   Episode_Reward/pen_joint_torque: -0.2342
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1121
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0855
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2410
Episode_Reward/pen_flat_orientation: -0.0956
  Episode_Reward/pen_feet_distance: -0.0303
Episode_Reward/pen_feet_regulation: -0.4599
   Episode_Reward/foot_landing_vel: -0.1238
   Episode_Reward/test_gait_reward: -0.8779
Metrics/base_velocity/error_vel_xy: 0.8971
Metrics/base_velocity/error_vel_yaw: 1.2254
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 213417984
                    Iteration time: 1.11s
                        Total time: 2370.92s
                               ETA: 906.4s

################################################################################
                     [1m Learning iteration 2171/3000 [0m                     

                       Computation: 88030 steps/s (collection: 0.990s, learning 0.127s)
               Value function loss: 0.6116
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8470
                     Learning rate: 0.0003
                       Mean reward: 139.10
               Mean episode length: 984.78
       Episode_Reward/keep_balance: 0.9916
     Episode_Reward/rew_lin_vel_xy: 6.3979
      Episode_Reward/rew_ang_vel_z: 2.5729
    Episode_Reward/pen_base_height: -0.2899
      Episode_Reward/pen_lin_vel_z: -0.0390
     Episode_Reward/pen_ang_vel_xy: -0.1490
   Episode_Reward/pen_joint_torque: -0.2416
    Episode_Reward/pen_joint_accel: -0.1015
    Episode_Reward/pen_action_rate: -0.1156
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0572
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2452
Episode_Reward/pen_flat_orientation: -0.0943
  Episode_Reward/pen_feet_distance: -0.0344
Episode_Reward/pen_feet_regulation: -0.5003
   Episode_Reward/foot_landing_vel: -0.1227
   Episode_Reward/test_gait_reward: -0.8917
Metrics/base_velocity/error_vel_xy: 0.9073
Metrics/base_velocity/error_vel_yaw: 1.2795
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 213516288
                    Iteration time: 1.12s
                        Total time: 2372.03s
                               ETA: 905.3s

################################################################################
                     [1m Learning iteration 2172/3000 [0m                     

                       Computation: 87602 steps/s (collection: 0.995s, learning 0.127s)
               Value function loss: 0.5479
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8476
                     Learning rate: 0.0000
                       Mean reward: 144.82
               Mean episode length: 998.73
       Episode_Reward/keep_balance: 0.9947
     Episode_Reward/rew_lin_vel_xy: 6.4242
      Episode_Reward/rew_ang_vel_z: 2.6025
    Episode_Reward/pen_base_height: -0.2856
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1478
   Episode_Reward/pen_joint_torque: -0.2239
    Episode_Reward/pen_joint_accel: -0.1098
    Episode_Reward/pen_action_rate: -0.1127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2449
Episode_Reward/pen_flat_orientation: -0.0932
  Episode_Reward/pen_feet_distance: -0.0249
Episode_Reward/pen_feet_regulation: -0.4820
   Episode_Reward/foot_landing_vel: -0.1273
   Episode_Reward/test_gait_reward: -0.8859
Metrics/base_velocity/error_vel_xy: 0.9081
Metrics/base_velocity/error_vel_yaw: 1.2598
      Episode_Termination/time_out: 4.9167
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 213614592
                    Iteration time: 1.12s
                        Total time: 2373.16s
                               ETA: 904.3s

################################################################################
                     [1m Learning iteration 2173/3000 [0m                     

                       Computation: 90667 steps/s (collection: 0.960s, learning 0.124s)
               Value function loss: 0.5075
                    Surrogate loss: -0.0018
             Mean action noise std: 0.8475
                     Learning rate: 0.0000
                       Mean reward: 138.08
               Mean episode length: 972.83
       Episode_Reward/keep_balance: 0.9775
     Episode_Reward/rew_lin_vel_xy: 6.2667
      Episode_Reward/rew_ang_vel_z: 2.5550
    Episode_Reward/pen_base_height: -0.2826
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1445
   Episode_Reward/pen_joint_torque: -0.2383
    Episode_Reward/pen_joint_accel: -0.0998
    Episode_Reward/pen_action_rate: -0.1131
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0866
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2416
Episode_Reward/pen_flat_orientation: -0.0935
  Episode_Reward/pen_feet_distance: -0.0301
Episode_Reward/pen_feet_regulation: -0.4809
   Episode_Reward/foot_landing_vel: -0.1175
   Episode_Reward/test_gait_reward: -0.8799
Metrics/base_velocity/error_vel_xy: 0.9127
Metrics/base_velocity/error_vel_yaw: 1.2357
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 213712896
                    Iteration time: 1.08s
                        Total time: 2374.24s
                               ETA: 903.2s

################################################################################
                     [1m Learning iteration 2174/3000 [0m                     

                       Computation: 90799 steps/s (collection: 0.958s, learning 0.124s)
               Value function loss: 0.4741
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8469
                     Learning rate: 0.0001
                       Mean reward: 138.82
               Mean episode length: 981.87
       Episode_Reward/keep_balance: 0.9844
     Episode_Reward/rew_lin_vel_xy: 6.2825
      Episode_Reward/rew_ang_vel_z: 2.5405
    Episode_Reward/pen_base_height: -0.2817
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1477
   Episode_Reward/pen_joint_torque: -0.2306
    Episode_Reward/pen_joint_accel: -0.1033
    Episode_Reward/pen_action_rate: -0.1139
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2452
Episode_Reward/pen_flat_orientation: -0.0884
  Episode_Reward/pen_feet_distance: -0.0271
Episode_Reward/pen_feet_regulation: -0.4993
   Episode_Reward/foot_landing_vel: -0.1268
   Episode_Reward/test_gait_reward: -0.8839
Metrics/base_velocity/error_vel_xy: 0.9154
Metrics/base_velocity/error_vel_yaw: 1.2769
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 213811200
                    Iteration time: 1.08s
                        Total time: 2375.32s
                               ETA: 902.1s

################################################################################
                     [1m Learning iteration 2175/3000 [0m                     

                       Computation: 89688 steps/s (collection: 0.972s, learning 0.124s)
               Value function loss: 0.5848
                    Surrogate loss: -0.0032
             Mean action noise std: 0.8457
                     Learning rate: 0.0004
                       Mean reward: 145.59
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4656
      Episode_Reward/rew_ang_vel_z: 2.6508
    Episode_Reward/pen_base_height: -0.2831
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1455
   Episode_Reward/pen_joint_torque: -0.2267
    Episode_Reward/pen_joint_accel: -0.1011
    Episode_Reward/pen_action_rate: -0.1126
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0548
   Episode_Reward/pen_joint_powers: -0.0856
Episode_Reward/pen_undesired_contacts: 0.0000
Episode_Reward/pen_action_smoothness: -0.2426
Episode_Reward/pen_flat_orientation: -0.0874
  Episode_Reward/pen_feet_distance: -0.0299
Episode_Reward/pen_feet_regulation: -0.4691
   Episode_Reward/foot_landing_vel: -0.1272
   Episode_Reward/test_gait_reward: -0.8927
Metrics/base_velocity/error_vel_xy: 0.9073
Metrics/base_velocity/error_vel_yaw: 1.2192
      Episode_Termination/time_out: 4.7917
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 213909504
                    Iteration time: 1.10s
                        Total time: 2376.42s
                               ETA: 901.0s

################################################################################
                     [1m Learning iteration 2176/3000 [0m                     

                       Computation: 88078 steps/s (collection: 0.989s, learning 0.127s)
               Value function loss: 0.5111
                    Surrogate loss: -0.0008
             Mean action noise std: 0.8452
                     Learning rate: 0.0000
                       Mean reward: 143.01
               Mean episode length: 981.27
       Episode_Reward/keep_balance: 0.9683
     Episode_Reward/rew_lin_vel_xy: 6.2637
      Episode_Reward/rew_ang_vel_z: 2.5607
    Episode_Reward/pen_base_height: -0.2684
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1467
   Episode_Reward/pen_joint_torque: -0.2462
    Episode_Reward/pen_joint_accel: -0.0988
    Episode_Reward/pen_action_rate: -0.1109
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0527
   Episode_Reward/pen_joint_powers: -0.0843
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2387
Episode_Reward/pen_flat_orientation: -0.0911
  Episode_Reward/pen_feet_distance: -0.0284
Episode_Reward/pen_feet_regulation: -0.4525
   Episode_Reward/foot_landing_vel: -0.1176
   Episode_Reward/test_gait_reward: -0.8586
Metrics/base_velocity/error_vel_xy: 0.8697
Metrics/base_velocity/error_vel_yaw: 1.1975
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 214007808
                    Iteration time: 1.12s
                        Total time: 2377.53s
                               ETA: 899.9s

################################################################################
                     [1m Learning iteration 2177/3000 [0m                     

                       Computation: 89895 steps/s (collection: 0.970s, learning 0.124s)
               Value function loss: 0.5618
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8443
                     Learning rate: 0.0002
                       Mean reward: 139.37
               Mean episode length: 985.13
       Episode_Reward/keep_balance: 0.9878
     Episode_Reward/rew_lin_vel_xy: 6.3494
      Episode_Reward/rew_ang_vel_z: 2.6194
    Episode_Reward/pen_base_height: -0.2744
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1431
   Episode_Reward/pen_joint_torque: -0.2319
    Episode_Reward/pen_joint_accel: -0.0990
    Episode_Reward/pen_action_rate: -0.1111
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0541
   Episode_Reward/pen_joint_powers: -0.0853
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2385
Episode_Reward/pen_flat_orientation: -0.0907
  Episode_Reward/pen_feet_distance: -0.0271
Episode_Reward/pen_feet_regulation: -0.4734
   Episode_Reward/foot_landing_vel: -0.1229
   Episode_Reward/test_gait_reward: -0.8831
Metrics/base_velocity/error_vel_xy: 0.9124
Metrics/base_velocity/error_vel_yaw: 1.2108
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 214106112
                    Iteration time: 1.09s
                        Total time: 2378.63s
                               ETA: 898.8s

################################################################################
                     [1m Learning iteration 2178/3000 [0m                     

                       Computation: 88957 steps/s (collection: 0.979s, learning 0.126s)
               Value function loss: 0.5989
                    Surrogate loss: -0.0041
             Mean action noise std: 0.8438
                     Learning rate: 0.0003
                       Mean reward: 139.21
               Mean episode length: 973.25
       Episode_Reward/keep_balance: 0.9842
     Episode_Reward/rew_lin_vel_xy: 6.3581
      Episode_Reward/rew_ang_vel_z: 2.6184
    Episode_Reward/pen_base_height: -0.2724
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1398
   Episode_Reward/pen_joint_torque: -0.2237
    Episode_Reward/pen_joint_accel: -0.1033
    Episode_Reward/pen_action_rate: -0.1101
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0534
   Episode_Reward/pen_joint_powers: -0.0826
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2390
Episode_Reward/pen_flat_orientation: -0.0855
  Episode_Reward/pen_feet_distance: -0.0261
Episode_Reward/pen_feet_regulation: -0.4583
   Episode_Reward/foot_landing_vel: -0.1191
   Episode_Reward/test_gait_reward: -0.8731
Metrics/base_velocity/error_vel_xy: 0.8931
Metrics/base_velocity/error_vel_yaw: 1.2051
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 214204416
                    Iteration time: 1.11s
                        Total time: 2379.73s
                               ETA: 897.7s

################################################################################
                     [1m Learning iteration 2179/3000 [0m                     

                       Computation: 88962 steps/s (collection: 0.981s, learning 0.124s)
               Value function loss: 0.5619
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8436
                     Learning rate: 0.0000
                       Mean reward: 136.94
               Mean episode length: 975.71
       Episode_Reward/keep_balance: 0.9608
     Episode_Reward/rew_lin_vel_xy: 6.0932
      Episode_Reward/rew_ang_vel_z: 2.4834
    Episode_Reward/pen_base_height: -0.2799
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1469
   Episode_Reward/pen_joint_torque: -0.2210
    Episode_Reward/pen_joint_accel: -0.1138
    Episode_Reward/pen_action_rate: -0.1106
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0558
   Episode_Reward/pen_joint_powers: -0.0857
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2397
Episode_Reward/pen_flat_orientation: -0.0953
  Episode_Reward/pen_feet_distance: -0.0266
Episode_Reward/pen_feet_regulation: -0.4674
   Episode_Reward/foot_landing_vel: -0.1174
   Episode_Reward/test_gait_reward: -0.8664
Metrics/base_velocity/error_vel_xy: 0.9325
Metrics/base_velocity/error_vel_yaw: 1.2524
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 214302720
                    Iteration time: 1.11s
                        Total time: 2380.84s
                               ETA: 896.6s

################################################################################
                     [1m Learning iteration 2180/3000 [0m                     

                       Computation: 88892 steps/s (collection: 0.980s, learning 0.125s)
               Value function loss: 0.4997
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8423
                     Learning rate: 0.0001
                       Mean reward: 138.71
               Mean episode length: 966.65
       Episode_Reward/keep_balance: 0.9616
     Episode_Reward/rew_lin_vel_xy: 6.2290
      Episode_Reward/rew_ang_vel_z: 2.5387
    Episode_Reward/pen_base_height: -0.2754
      Episode_Reward/pen_lin_vel_z: -0.0364
     Episode_Reward/pen_ang_vel_xy: -0.1352
   Episode_Reward/pen_joint_torque: -0.2401
    Episode_Reward/pen_joint_accel: -0.1000
    Episode_Reward/pen_action_rate: -0.1085
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0530
   Episode_Reward/pen_joint_powers: -0.0828
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.2355
Episode_Reward/pen_flat_orientation: -0.0917
  Episode_Reward/pen_feet_distance: -0.0286
Episode_Reward/pen_feet_regulation: -0.4391
   Episode_Reward/foot_landing_vel: -0.1214
   Episode_Reward/test_gait_reward: -0.8517
Metrics/base_velocity/error_vel_xy: 0.8588
Metrics/base_velocity/error_vel_yaw: 1.2000
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 214401024
                    Iteration time: 1.11s
                        Total time: 2381.94s
                               ETA: 895.5s

################################################################################
                     [1m Learning iteration 2181/3000 [0m                     

                       Computation: 88897 steps/s (collection: 0.980s, learning 0.126s)
               Value function loss: 0.5883
                    Surrogate loss: -0.0039
             Mean action noise std: 0.8412
                     Learning rate: 0.0004
                       Mean reward: 139.34
               Mean episode length: 979.21
       Episode_Reward/keep_balance: 0.9658
     Episode_Reward/rew_lin_vel_xy: 6.1832
      Episode_Reward/rew_ang_vel_z: 2.5325
    Episode_Reward/pen_base_height: -0.2836
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1474
   Episode_Reward/pen_joint_torque: -0.2357
    Episode_Reward/pen_joint_accel: -0.0980
    Episode_Reward/pen_action_rate: -0.1100
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0856
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2381
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0283
Episode_Reward/pen_feet_regulation: -0.4714
   Episode_Reward/foot_landing_vel: -0.1199
   Episode_Reward/test_gait_reward: -0.8643
Metrics/base_velocity/error_vel_xy: 0.9141
Metrics/base_velocity/error_vel_yaw: 1.2260
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 214499328
                    Iteration time: 1.11s
                        Total time: 2383.05s
                               ETA: 894.5s

################################################################################
                     [1m Learning iteration 2182/3000 [0m                     

                       Computation: 90032 steps/s (collection: 0.969s, learning 0.123s)
               Value function loss: 0.5529
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8400
                     Learning rate: 0.0006
                       Mean reward: 139.32
               Mean episode length: 979.99
       Episode_Reward/keep_balance: 0.9835
     Episode_Reward/rew_lin_vel_xy: 6.3568
      Episode_Reward/rew_ang_vel_z: 2.5385
    Episode_Reward/pen_base_height: -0.2692
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1443
   Episode_Reward/pen_joint_torque: -0.2246
    Episode_Reward/pen_joint_accel: -0.1050
    Episode_Reward/pen_action_rate: -0.1130
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0865
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2446
Episode_Reward/pen_flat_orientation: -0.0847
  Episode_Reward/pen_feet_distance: -0.0284
Episode_Reward/pen_feet_regulation: -0.4821
   Episode_Reward/foot_landing_vel: -0.1243
   Episode_Reward/test_gait_reward: -0.8831
Metrics/base_velocity/error_vel_xy: 0.8925
Metrics/base_velocity/error_vel_yaw: 1.2728
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 214597632
                    Iteration time: 1.09s
                        Total time: 2384.14s
                               ETA: 893.4s

################################################################################
                     [1m Learning iteration 2183/3000 [0m                     

                       Computation: 89854 steps/s (collection: 0.969s, learning 0.125s)
               Value function loss: 0.5341
                    Surrogate loss: -0.0029
             Mean action noise std: 0.8398
                     Learning rate: 0.0006
                       Mean reward: 138.19
               Mean episode length: 976.17
       Episode_Reward/keep_balance: 0.9577
     Episode_Reward/rew_lin_vel_xy: 6.1313
      Episode_Reward/rew_ang_vel_z: 2.5160
    Episode_Reward/pen_base_height: -0.2800
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1492
   Episode_Reward/pen_joint_torque: -0.2124
    Episode_Reward/pen_joint_accel: -0.1055
    Episode_Reward/pen_action_rate: -0.1100
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0540
   Episode_Reward/pen_joint_powers: -0.0826
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2383
Episode_Reward/pen_flat_orientation: -0.0868
  Episode_Reward/pen_feet_distance: -0.0294
Episode_Reward/pen_feet_regulation: -0.4663
   Episode_Reward/foot_landing_vel: -0.1211
   Episode_Reward/test_gait_reward: -0.8628
Metrics/base_velocity/error_vel_xy: 0.8962
Metrics/base_velocity/error_vel_yaw: 1.2064
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 214695936
                    Iteration time: 1.09s
                        Total time: 2385.24s
                               ETA: 892.3s

################################################################################
                     [1m Learning iteration 2184/3000 [0m                     

                       Computation: 89682 steps/s (collection: 0.973s, learning 0.123s)
               Value function loss: 0.5712
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8406
                     Learning rate: 0.0009
                       Mean reward: 138.88
               Mean episode length: 986.25
       Episode_Reward/keep_balance: 0.9932
     Episode_Reward/rew_lin_vel_xy: 6.3593
      Episode_Reward/rew_ang_vel_z: 2.5777
    Episode_Reward/pen_base_height: -0.2766
      Episode_Reward/pen_lin_vel_z: -0.0373
     Episode_Reward/pen_ang_vel_xy: -0.1473
   Episode_Reward/pen_joint_torque: -0.2339
    Episode_Reward/pen_joint_accel: -0.1050
    Episode_Reward/pen_action_rate: -0.1151
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0560
   Episode_Reward/pen_joint_powers: -0.0872
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2487
Episode_Reward/pen_flat_orientation: -0.0862
  Episode_Reward/pen_feet_distance: -0.0273
Episode_Reward/pen_feet_regulation: -0.4814
   Episode_Reward/foot_landing_vel: -0.1202
   Episode_Reward/test_gait_reward: -0.8944
Metrics/base_velocity/error_vel_xy: 0.9303
Metrics/base_velocity/error_vel_yaw: 1.2747
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 214794240
                    Iteration time: 1.10s
                        Total time: 2386.33s
                               ETA: 891.2s

################################################################################
                     [1m Learning iteration 2185/3000 [0m                     

                       Computation: 90562 steps/s (collection: 0.959s, learning 0.127s)
               Value function loss: 0.5439
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8412
                     Learning rate: 0.0006
                       Mean reward: 140.38
               Mean episode length: 990.06
       Episode_Reward/keep_balance: 0.9917
     Episode_Reward/rew_lin_vel_xy: 6.3169
      Episode_Reward/rew_ang_vel_z: 2.5816
    Episode_Reward/pen_base_height: -0.2876
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1486
   Episode_Reward/pen_joint_torque: -0.2287
    Episode_Reward/pen_joint_accel: -0.1208
    Episode_Reward/pen_action_rate: -0.1140
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0569
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2477
Episode_Reward/pen_flat_orientation: -0.0887
  Episode_Reward/pen_feet_distance: -0.0267
Episode_Reward/pen_feet_regulation: -0.4738
   Episode_Reward/foot_landing_vel: -0.1316
   Episode_Reward/test_gait_reward: -0.8919
Metrics/base_velocity/error_vel_xy: 0.9278
Metrics/base_velocity/error_vel_yaw: 1.2561
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 214892544
                    Iteration time: 1.09s
                        Total time: 2387.42s
                               ETA: 890.1s

################################################################################
                     [1m Learning iteration 2186/3000 [0m                     

                       Computation: 85206 steps/s (collection: 1.025s, learning 0.129s)
               Value function loss: 0.4983
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8415
                     Learning rate: 0.0004
                       Mean reward: 138.70
               Mean episode length: 974.62
       Episode_Reward/keep_balance: 0.9723
     Episode_Reward/rew_lin_vel_xy: 6.2746
      Episode_Reward/rew_ang_vel_z: 2.5293
    Episode_Reward/pen_base_height: -0.2782
      Episode_Reward/pen_lin_vel_z: -0.0361
     Episode_Reward/pen_ang_vel_xy: -0.1475
   Episode_Reward/pen_joint_torque: -0.2245
    Episode_Reward/pen_joint_accel: -0.1027
    Episode_Reward/pen_action_rate: -0.1115
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0847
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2426
Episode_Reward/pen_flat_orientation: -0.0860
  Episode_Reward/pen_feet_distance: -0.0275
Episode_Reward/pen_feet_regulation: -0.4723
   Episode_Reward/foot_landing_vel: -0.1263
   Episode_Reward/test_gait_reward: -0.8735
Metrics/base_velocity/error_vel_xy: 0.8810
Metrics/base_velocity/error_vel_yaw: 1.2420
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 214990848
                    Iteration time: 1.15s
                        Total time: 2388.57s
                               ETA: 889.0s

################################################################################
                     [1m Learning iteration 2187/3000 [0m                     

                       Computation: 88305 steps/s (collection: 0.988s, learning 0.125s)
               Value function loss: 0.4882
                    Surrogate loss: -0.0027
             Mean action noise std: 0.8417
                     Learning rate: 0.0001
                       Mean reward: 143.01
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4265
      Episode_Reward/rew_ang_vel_z: 2.6312
    Episode_Reward/pen_base_height: -0.2856
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1497
   Episode_Reward/pen_joint_torque: -0.2295
    Episode_Reward/pen_joint_accel: -0.1099
    Episode_Reward/pen_action_rate: -0.1131
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0558
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2449
Episode_Reward/pen_flat_orientation: -0.0865
  Episode_Reward/pen_feet_distance: -0.0317
Episode_Reward/pen_feet_regulation: -0.4816
   Episode_Reward/foot_landing_vel: -0.1310
   Episode_Reward/test_gait_reward: -0.8952
Metrics/base_velocity/error_vel_xy: 0.9176
Metrics/base_velocity/error_vel_yaw: 1.2484
      Episode_Termination/time_out: 4.3750
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 215089152
                    Iteration time: 1.11s
                        Total time: 2389.68s
                               ETA: 887.9s

################################################################################
                     [1m Learning iteration 2188/3000 [0m                     

                       Computation: 84070 steps/s (collection: 1.041s, learning 0.129s)
               Value function loss: 0.5256
                    Surrogate loss: -0.0049
             Mean action noise std: 0.8415
                     Learning rate: 0.0004
                       Mean reward: 141.40
               Mean episode length: 981.55
       Episode_Reward/keep_balance: 0.9707
     Episode_Reward/rew_lin_vel_xy: 6.2683
      Episode_Reward/rew_ang_vel_z: 2.5616
    Episode_Reward/pen_base_height: -0.2758
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1412
   Episode_Reward/pen_joint_torque: -0.2271
    Episode_Reward/pen_joint_accel: -0.1035
    Episode_Reward/pen_action_rate: -0.1104
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0539
   Episode_Reward/pen_joint_powers: -0.0845
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2390
Episode_Reward/pen_flat_orientation: -0.0891
  Episode_Reward/pen_feet_distance: -0.0270
Episode_Reward/pen_feet_regulation: -0.4619
   Episode_Reward/foot_landing_vel: -0.1213
   Episode_Reward/test_gait_reward: -0.8700
Metrics/base_velocity/error_vel_xy: 0.8860
Metrics/base_velocity/error_vel_yaw: 1.2084
      Episode_Termination/time_out: 4.0833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 215187456
                    Iteration time: 1.17s
                        Total time: 2390.85s
                               ETA: 886.9s

################################################################################
                     [1m Learning iteration 2189/3000 [0m                     

                       Computation: 87487 steps/s (collection: 0.997s, learning 0.126s)
               Value function loss: 0.4584
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8415
                     Learning rate: 0.0006
                       Mean reward: 143.86
               Mean episode length: 998.15
       Episode_Reward/keep_balance: 0.9987
     Episode_Reward/rew_lin_vel_xy: 6.4402
      Episode_Reward/rew_ang_vel_z: 2.6257
    Episode_Reward/pen_base_height: -0.2789
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1484
   Episode_Reward/pen_joint_torque: -0.2349
    Episode_Reward/pen_joint_accel: -0.0999
    Episode_Reward/pen_action_rate: -0.1154
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2487
Episode_Reward/pen_flat_orientation: -0.0900
  Episode_Reward/pen_feet_distance: -0.0284
Episode_Reward/pen_feet_regulation: -0.4842
   Episode_Reward/foot_landing_vel: -0.1226
   Episode_Reward/test_gait_reward: -0.8974
Metrics/base_velocity/error_vel_xy: 0.9150
Metrics/base_velocity/error_vel_yaw: 1.2505
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 215285760
                    Iteration time: 1.12s
                        Total time: 2391.98s
                               ETA: 885.8s

################################################################################
                     [1m Learning iteration 2190/3000 [0m                     

                       Computation: 89946 steps/s (collection: 0.969s, learning 0.124s)
               Value function loss: 0.4813
                    Surrogate loss: -0.0043
             Mean action noise std: 0.8406
                     Learning rate: 0.0009
                       Mean reward: 143.18
               Mean episode length: 1000.00
       Episode_Reward/keep_balance: 1.0000
     Episode_Reward/rew_lin_vel_xy: 6.4290
      Episode_Reward/rew_ang_vel_z: 2.5639
    Episode_Reward/pen_base_height: -0.2769
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1458
   Episode_Reward/pen_joint_torque: -0.2295
    Episode_Reward/pen_joint_accel: -0.1066
    Episode_Reward/pen_action_rate: -0.1155
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0874
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2494
Episode_Reward/pen_flat_orientation: -0.0893
  Episode_Reward/pen_feet_distance: -0.0251
Episode_Reward/pen_feet_regulation: -0.4948
   Episode_Reward/foot_landing_vel: -0.1229
   Episode_Reward/test_gait_reward: -0.9063
Metrics/base_velocity/error_vel_xy: 0.9223
Metrics/base_velocity/error_vel_yaw: 1.3177
      Episode_Termination/time_out: 4.2083
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 215384064
                    Iteration time: 1.09s
                        Total time: 2393.07s
                               ETA: 884.7s

################################################################################
                     [1m Learning iteration 2191/3000 [0m                     

                       Computation: 80855 steps/s (collection: 1.082s, learning 0.133s)
               Value function loss: 0.4596
                    Surrogate loss: -0.0010
             Mean action noise std: 0.8398
                     Learning rate: 0.0002
                       Mean reward: 141.97
               Mean episode length: 990.24
       Episode_Reward/keep_balance: 0.9865
     Episode_Reward/rew_lin_vel_xy: 6.3904
      Episode_Reward/rew_ang_vel_z: 2.6280
    Episode_Reward/pen_base_height: -0.2769
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.1393
   Episode_Reward/pen_joint_torque: -0.2371
    Episode_Reward/pen_joint_accel: -0.1068
    Episode_Reward/pen_action_rate: -0.1124
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0542
   Episode_Reward/pen_joint_powers: -0.0860
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2412
Episode_Reward/pen_flat_orientation: -0.0841
  Episode_Reward/pen_feet_distance: -0.0272
Episode_Reward/pen_feet_regulation: -0.4714
   Episode_Reward/foot_landing_vel: -0.1255
   Episode_Reward/test_gait_reward: -0.8821
Metrics/base_velocity/error_vel_xy: 0.8857
Metrics/base_velocity/error_vel_yaw: 1.1889
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 215482368
                    Iteration time: 1.22s
                        Total time: 2394.29s
                               ETA: 883.7s

################################################################################
                     [1m Learning iteration 2192/3000 [0m                     

                       Computation: 88035 steps/s (collection: 0.990s, learning 0.126s)
               Value function loss: 0.5243
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8384
                     Learning rate: 0.0006
                       Mean reward: 140.30
               Mean episode length: 990.35
       Episode_Reward/keep_balance: 0.9920
     Episode_Reward/rew_lin_vel_xy: 6.3637
      Episode_Reward/rew_ang_vel_z: 2.5612
    Episode_Reward/pen_base_height: -0.2784
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1492
   Episode_Reward/pen_joint_torque: -0.2337
    Episode_Reward/pen_joint_accel: -0.1156
    Episode_Reward/pen_action_rate: -0.1160
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0570
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2496
Episode_Reward/pen_flat_orientation: -0.0903
  Episode_Reward/pen_feet_distance: -0.0334
Episode_Reward/pen_feet_regulation: -0.4862
   Episode_Reward/foot_landing_vel: -0.1313
   Episode_Reward/test_gait_reward: -0.8940
Metrics/base_velocity/error_vel_xy: 0.9060
Metrics/base_velocity/error_vel_yaw: 1.2866
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 215580672
                    Iteration time: 1.12s
                        Total time: 2395.40s
                               ETA: 882.6s

################################################################################
                     [1m Learning iteration 2193/3000 [0m                     

                       Computation: 79618 steps/s (collection: 1.102s, learning 0.133s)
               Value function loss: 0.5440
                    Surrogate loss: -0.0034
             Mean action noise std: 0.8371
                     Learning rate: 0.0006
                       Mean reward: 140.71
               Mean episode length: 980.45
       Episode_Reward/keep_balance: 0.9800
     Episode_Reward/rew_lin_vel_xy: 6.3134
      Episode_Reward/rew_ang_vel_z: 2.5976
    Episode_Reward/pen_base_height: -0.2746
      Episode_Reward/pen_lin_vel_z: -0.0366
     Episode_Reward/pen_ang_vel_xy: -0.1435
   Episode_Reward/pen_joint_torque: -0.2196
    Episode_Reward/pen_joint_accel: -0.1061
    Episode_Reward/pen_action_rate: -0.1114
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0534
   Episode_Reward/pen_joint_powers: -0.0830
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2417
Episode_Reward/pen_flat_orientation: -0.0846
  Episode_Reward/pen_feet_distance: -0.0277
Episode_Reward/pen_feet_regulation: -0.4505
   Episode_Reward/foot_landing_vel: -0.1236
   Episode_Reward/test_gait_reward: -0.8792
Metrics/base_velocity/error_vel_xy: 0.8963
Metrics/base_velocity/error_vel_yaw: 1.2011
      Episode_Termination/time_out: 4.7083
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 215678976
                    Iteration time: 1.23s
                        Total time: 2396.64s
                               ETA: 881.5s

################################################################################
                     [1m Learning iteration 2194/3000 [0m                     

                       Computation: 81295 steps/s (collection: 1.078s, learning 0.132s)
               Value function loss: 0.4805
                    Surrogate loss: -0.0005
             Mean action noise std: 0.8367
                     Learning rate: 0.0000
                       Mean reward: 138.81
               Mean episode length: 967.84
       Episode_Reward/keep_balance: 0.9788
     Episode_Reward/rew_lin_vel_xy: 6.2705
      Episode_Reward/rew_ang_vel_z: 2.5742
    Episode_Reward/pen_base_height: -0.2778
      Episode_Reward/pen_lin_vel_z: -0.0379
     Episode_Reward/pen_ang_vel_xy: -0.1423
   Episode_Reward/pen_joint_torque: -0.2295
    Episode_Reward/pen_joint_accel: -0.1010
    Episode_Reward/pen_action_rate: -0.1125
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0553
   Episode_Reward/pen_joint_powers: -0.0849
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2402
Episode_Reward/pen_flat_orientation: -0.0905
  Episode_Reward/pen_feet_distance: -0.0239
Episode_Reward/pen_feet_regulation: -0.4891
   Episode_Reward/foot_landing_vel: -0.1260
   Episode_Reward/test_gait_reward: -0.8843
Metrics/base_velocity/error_vel_xy: 0.9077
Metrics/base_velocity/error_vel_yaw: 1.2303
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 215777280
                    Iteration time: 1.21s
                        Total time: 2397.85s
                               ETA: 880.5s

################################################################################
                     [1m Learning iteration 2195/3000 [0m                     

                       Computation: 85836 steps/s (collection: 1.013s, learning 0.132s)
               Value function loss: 0.5065
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8364
                     Learning rate: 0.0001
                       Mean reward: 145.72
               Mean episode length: 998.94
       Episode_Reward/keep_balance: 0.9985
     Episode_Reward/rew_lin_vel_xy: 6.5111
      Episode_Reward/rew_ang_vel_z: 2.6638
    Episode_Reward/pen_base_height: -0.2664
      Episode_Reward/pen_lin_vel_z: -0.0358
     Episode_Reward/pen_ang_vel_xy: -0.1444
   Episode_Reward/pen_joint_torque: -0.2281
    Episode_Reward/pen_joint_accel: -0.0992
    Episode_Reward/pen_action_rate: -0.1127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0526
   Episode_Reward/pen_joint_powers: -0.0839
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2419
Episode_Reward/pen_flat_orientation: -0.0837
  Episode_Reward/pen_feet_distance: -0.0287
Episode_Reward/pen_feet_regulation: -0.4392
   Episode_Reward/foot_landing_vel: -0.1124
   Episode_Reward/test_gait_reward: -0.8919
Metrics/base_velocity/error_vel_xy: 0.8633
Metrics/base_velocity/error_vel_yaw: 1.2218
      Episode_Termination/time_out: 4.1250
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 215875584
                    Iteration time: 1.15s
                        Total time: 2398.99s
                               ETA: 879.4s

################################################################################
                     [1m Learning iteration 2196/3000 [0m                     

                       Computation: 87930 steps/s (collection: 0.992s, learning 0.126s)
               Value function loss: 0.5211
                    Surrogate loss: -0.0042
             Mean action noise std: 0.8363
                     Learning rate: 0.0001
                       Mean reward: 142.10
               Mean episode length: 994.18
       Episode_Reward/keep_balance: 0.9940
     Episode_Reward/rew_lin_vel_xy: 6.4304
      Episode_Reward/rew_ang_vel_z: 2.6008
    Episode_Reward/pen_base_height: -0.2702
      Episode_Reward/pen_lin_vel_z: -0.0372
     Episode_Reward/pen_ang_vel_xy: -0.1460
   Episode_Reward/pen_joint_torque: -0.2430
    Episode_Reward/pen_joint_accel: -0.1038
    Episode_Reward/pen_action_rate: -0.1154
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0888
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2463
Episode_Reward/pen_flat_orientation: -0.0845
  Episode_Reward/pen_feet_distance: -0.0312
Episode_Reward/pen_feet_regulation: -0.4817
   Episode_Reward/foot_landing_vel: -0.1277
   Episode_Reward/test_gait_reward: -0.8885
Metrics/base_velocity/error_vel_xy: 0.8946
Metrics/base_velocity/error_vel_yaw: 1.2573
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 215973888
                    Iteration time: 1.12s
                        Total time: 2400.11s
                               ETA: 878.3s

################################################################################
                     [1m Learning iteration 2197/3000 [0m                     

                       Computation: 89312 steps/s (collection: 0.977s, learning 0.124s)
               Value function loss: 0.6140
                    Surrogate loss: -0.0003
             Mean action noise std: 0.8364
                     Learning rate: 0.0000
                       Mean reward: 141.14
               Mean episode length: 988.78
       Episode_Reward/keep_balance: 0.9908
     Episode_Reward/rew_lin_vel_xy: 6.3524
      Episode_Reward/rew_ang_vel_z: 2.6019
    Episode_Reward/pen_base_height: -0.2799
      Episode_Reward/pen_lin_vel_z: -0.0388
     Episode_Reward/pen_ang_vel_xy: -0.1528
   Episode_Reward/pen_joint_torque: -0.2304
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.1153
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0567
   Episode_Reward/pen_joint_powers: -0.0879
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2465
Episode_Reward/pen_flat_orientation: -0.0890
  Episode_Reward/pen_feet_distance: -0.0294
Episode_Reward/pen_feet_regulation: -0.4931
   Episode_Reward/foot_landing_vel: -0.1330
   Episode_Reward/test_gait_reward: -0.8896
Metrics/base_velocity/error_vel_xy: 0.9259
Metrics/base_velocity/error_vel_yaw: 1.2507
      Episode_Termination/time_out: 4.5833
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 216072192
                    Iteration time: 1.10s
                        Total time: 2401.21s
                               ETA: 877.2s

################################################################################
                     [1m Learning iteration 2198/3000 [0m                     

                       Computation: 92205 steps/s (collection: 0.941s, learning 0.125s)
               Value function loss: 0.5638
                    Surrogate loss: -0.0007
             Mean action noise std: 0.8362
                     Learning rate: 0.0000
                       Mean reward: 139.24
               Mean episode length: 981.82
       Episode_Reward/keep_balance: 0.9623
     Episode_Reward/rew_lin_vel_xy: 6.2001
      Episode_Reward/rew_ang_vel_z: 2.5101
    Episode_Reward/pen_base_height: -0.2810
      Episode_Reward/pen_lin_vel_z: -0.0381
     Episode_Reward/pen_ang_vel_xy: -0.1410
   Episode_Reward/pen_joint_torque: -0.2443
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.1122
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0878
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2375
Episode_Reward/pen_flat_orientation: -0.0939
  Episode_Reward/pen_feet_distance: -0.0292
Episode_Reward/pen_feet_regulation: -0.4762
   Episode_Reward/foot_landing_vel: -0.1283
   Episode_Reward/test_gait_reward: -0.8718
Metrics/base_velocity/error_vel_xy: 0.8963
Metrics/base_velocity/error_vel_yaw: 1.2226
      Episode_Termination/time_out: 4.1667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 216170496
                    Iteration time: 1.07s
                        Total time: 2402.28s
                               ETA: 876.1s

################################################################################
                     [1m Learning iteration 2199/3000 [0m                     

                       Computation: 89311 steps/s (collection: 0.976s, learning 0.125s)
               Value function loss: 0.4425
                    Surrogate loss: -0.0013
             Mean action noise std: 0.8360
                     Learning rate: 0.0000
                       Mean reward: 142.02
               Mean episode length: 990.52
       Episode_Reward/keep_balance: 0.9938
     Episode_Reward/rew_lin_vel_xy: 6.4415
      Episode_Reward/rew_ang_vel_z: 2.6313
    Episode_Reward/pen_base_height: -0.2760
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1423
   Episode_Reward/pen_joint_torque: -0.2460
    Episode_Reward/pen_joint_accel: -0.1047
    Episode_Reward/pen_action_rate: -0.1152
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0538
   Episode_Reward/pen_joint_powers: -0.0862
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2445
Episode_Reward/pen_flat_orientation: -0.0885
  Episode_Reward/pen_feet_distance: -0.0266
Episode_Reward/pen_feet_regulation: -0.4706
   Episode_Reward/foot_landing_vel: -0.1194
   Episode_Reward/test_gait_reward: -0.8928
Metrics/base_velocity/error_vel_xy: 0.8963
Metrics/base_velocity/error_vel_yaw: 1.2311
      Episode_Termination/time_out: 4.7500
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 216268800
                    Iteration time: 1.10s
                        Total time: 2403.38s
                               ETA: 875.0s

################################################################################
                     [1m Learning iteration 2200/3000 [0m                     

                       Computation: 91262 steps/s (collection: 0.953s, learning 0.124s)
               Value function loss: 0.5743
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8357
                     Learning rate: 0.0000
                       Mean reward: 141.32
               Mean episode length: 995.95
       Episode_Reward/keep_balance: 0.9966
     Episode_Reward/rew_lin_vel_xy: 6.4074
      Episode_Reward/rew_ang_vel_z: 2.6323
    Episode_Reward/pen_base_height: -0.2734
      Episode_Reward/pen_lin_vel_z: -0.0386
     Episode_Reward/pen_ang_vel_xy: -0.1461
   Episode_Reward/pen_joint_torque: -0.2450
    Episode_Reward/pen_joint_accel: -0.1045
    Episode_Reward/pen_action_rate: -0.1156
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0561
   Episode_Reward/pen_joint_powers: -0.0886
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2462
Episode_Reward/pen_flat_orientation: -0.0866
  Episode_Reward/pen_feet_distance: -0.0264
Episode_Reward/pen_feet_regulation: -0.4792
   Episode_Reward/foot_landing_vel: -0.1174
   Episode_Reward/test_gait_reward: -0.9041
Metrics/base_velocity/error_vel_xy: 0.9154
Metrics/base_velocity/error_vel_yaw: 1.2282
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 216367104
                    Iteration time: 1.08s
                        Total time: 2404.45s
                               ETA: 873.9s

################################################################################
                     [1m Learning iteration 2201/3000 [0m                     

                       Computation: 88910 steps/s (collection: 0.977s, learning 0.129s)
               Value function loss: 0.5046
                    Surrogate loss: -0.0019
             Mean action noise std: 0.8353
                     Learning rate: 0.0000
                       Mean reward: 137.56
               Mean episode length: 968.91
       Episode_Reward/keep_balance: 0.9757
     Episode_Reward/rew_lin_vel_xy: 6.2844
      Episode_Reward/rew_ang_vel_z: 2.5735
    Episode_Reward/pen_base_height: -0.2658
      Episode_Reward/pen_lin_vel_z: -0.0363
     Episode_Reward/pen_ang_vel_xy: -0.1416
   Episode_Reward/pen_joint_torque: -0.2354
    Episode_Reward/pen_joint_accel: -0.1118
    Episode_Reward/pen_action_rate: -0.1127
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2425
Episode_Reward/pen_flat_orientation: -0.0875
  Episode_Reward/pen_feet_distance: -0.0281
Episode_Reward/pen_feet_regulation: -0.4693
   Episode_Reward/foot_landing_vel: -0.1255
   Episode_Reward/test_gait_reward: -0.8718
Metrics/base_velocity/error_vel_xy: 0.8878
Metrics/base_velocity/error_vel_yaw: 1.2056
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 216465408
                    Iteration time: 1.11s
                        Total time: 2405.56s
                               ETA: 872.9s

################################################################################
                     [1m Learning iteration 2202/3000 [0m                     

                       Computation: 91275 steps/s (collection: 0.956s, learning 0.121s)
               Value function loss: 0.5265
                    Surrogate loss: -0.0036
             Mean action noise std: 0.8347
                     Learning rate: 0.0001
                       Mean reward: 138.94
               Mean episode length: 989.90
       Episode_Reward/keep_balance: 0.9916
     Episode_Reward/rew_lin_vel_xy: 6.3309
      Episode_Reward/rew_ang_vel_z: 2.6273
    Episode_Reward/pen_base_height: -0.2856
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1500
   Episode_Reward/pen_joint_torque: -0.2354
    Episode_Reward/pen_joint_accel: -0.1190
    Episode_Reward/pen_action_rate: -0.1165
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2494
Episode_Reward/pen_flat_orientation: -0.0936
  Episode_Reward/pen_feet_distance: -0.0252
Episode_Reward/pen_feet_regulation: -0.4976
   Episode_Reward/foot_landing_vel: -0.1293
   Episode_Reward/test_gait_reward: -0.9048
Metrics/base_velocity/error_vel_xy: 0.9522
Metrics/base_velocity/error_vel_yaw: 1.2275
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 216563712
                    Iteration time: 1.08s
                        Total time: 2406.64s
                               ETA: 871.8s

################################################################################
                     [1m Learning iteration 2203/3000 [0m                     

                       Computation: 88575 steps/s (collection: 0.979s, learning 0.131s)
               Value function loss: 0.7083
                    Surrogate loss: -0.0016
             Mean action noise std: 0.8347
                     Learning rate: 0.0000
                       Mean reward: 142.06
               Mean episode length: 984.24
       Episode_Reward/keep_balance: 0.9833
     Episode_Reward/rew_lin_vel_xy: 6.3996
      Episode_Reward/rew_ang_vel_z: 2.6256
    Episode_Reward/pen_base_height: -0.2695
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1386
   Episode_Reward/pen_joint_torque: -0.2290
    Episode_Reward/pen_joint_accel: -0.1064
    Episode_Reward/pen_action_rate: -0.1123
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0535
   Episode_Reward/pen_joint_powers: -0.0842
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2410
Episode_Reward/pen_flat_orientation: -0.0873
  Episode_Reward/pen_feet_distance: -0.0227
Episode_Reward/pen_feet_regulation: -0.4540
   Episode_Reward/foot_landing_vel: -0.1261
   Episode_Reward/test_gait_reward: -0.8855
Metrics/base_velocity/error_vel_xy: 0.8637
Metrics/base_velocity/error_vel_yaw: 1.1944
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 216662016
                    Iteration time: 1.11s
                        Total time: 2407.75s
                               ETA: 870.7s

################################################################################
                     [1m Learning iteration 2204/3000 [0m                     

                       Computation: 89717 steps/s (collection: 0.971s, learning 0.125s)
               Value function loss: 8.6414
                    Surrogate loss: -0.0028
             Mean action noise std: 0.8347
                     Learning rate: 0.0000
                       Mean reward: 138.87
               Mean episode length: 981.61
       Episode_Reward/keep_balance: 0.9859
     Episode_Reward/rew_lin_vel_xy: 6.3836
      Episode_Reward/rew_ang_vel_z: 2.5751
    Episode_Reward/pen_base_height: -0.2749
      Episode_Reward/pen_lin_vel_z: -0.0367
     Episode_Reward/pen_ang_vel_xy: -0.1446
   Episode_Reward/pen_joint_torque: -0.2367
    Episode_Reward/pen_joint_accel: -0.1041
    Episode_Reward/pen_action_rate: -0.1204
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0544
   Episode_Reward/pen_joint_powers: -0.0856
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2455
Episode_Reward/pen_flat_orientation: -0.0848
  Episode_Reward/pen_feet_distance: -0.0270
Episode_Reward/pen_feet_regulation: -0.4703
   Episode_Reward/foot_landing_vel: -0.1233
   Episode_Reward/test_gait_reward: -0.8902
Metrics/base_velocity/error_vel_xy: 0.8804
Metrics/base_velocity/error_vel_yaw: 1.2461
      Episode_Termination/time_out: 3.6667
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 216760320
                    Iteration time: 1.10s
                        Total time: 2408.84s
                               ETA: 869.6s

################################################################################
                     [1m Learning iteration 2205/3000 [0m                     

                       Computation: 90017 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 109.6206
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8348
                     Learning rate: 0.0000
                       Mean reward: 139.97
               Mean episode length: 978.46
       Episode_Reward/keep_balance: 0.9822
     Episode_Reward/rew_lin_vel_xy: 6.2884
      Episode_Reward/rew_ang_vel_z: 2.6032
    Episode_Reward/pen_base_height: -0.2724
      Episode_Reward/pen_lin_vel_z: -0.0376
     Episode_Reward/pen_ang_vel_xy: -0.1406
   Episode_Reward/pen_joint_torque: -0.2458
    Episode_Reward/pen_joint_accel: -0.1001
    Episode_Reward/pen_action_rate: -0.1468
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0538
   Episode_Reward/pen_joint_powers: -0.0851
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2431
Episode_Reward/pen_flat_orientation: -0.0878
  Episode_Reward/pen_feet_distance: -0.0262
Episode_Reward/pen_feet_regulation: -0.4796
   Episode_Reward/foot_landing_vel: -0.1211
   Episode_Reward/test_gait_reward: -0.8859
Metrics/base_velocity/error_vel_xy: 0.9185
Metrics/base_velocity/error_vel_yaw: 1.2113
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 216858624
                    Iteration time: 1.09s
                        Total time: 2409.93s
                               ETA: 868.5s

################################################################################
                     [1m Learning iteration 2206/3000 [0m                     

                       Computation: 89695 steps/s (collection: 0.970s, learning 0.126s)
               Value function loss: 308.0608
                    Surrogate loss: -0.0009
             Mean action noise std: 0.8348
                     Learning rate: 0.0000
                       Mean reward: 133.62
               Mean episode length: 975.75
       Episode_Reward/keep_balance: 0.9863
     Episode_Reward/rew_lin_vel_xy: 6.3273
      Episode_Reward/rew_ang_vel_z: 2.5936
    Episode_Reward/pen_base_height: -0.2759
      Episode_Reward/pen_lin_vel_z: -0.0369
     Episode_Reward/pen_ang_vel_xy: -0.1426
   Episode_Reward/pen_joint_torque: -0.2610
    Episode_Reward/pen_joint_accel: -0.1073
    Episode_Reward/pen_action_rate: -0.3903
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0558
   Episode_Reward/pen_joint_powers: -0.0864
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.2499
Episode_Reward/pen_flat_orientation: -0.0923
  Episode_Reward/pen_feet_distance: -0.0285
Episode_Reward/pen_feet_regulation: -0.4767
   Episode_Reward/foot_landing_vel: -0.1272
   Episode_Reward/test_gait_reward: -0.8924
Metrics/base_velocity/error_vel_xy: 0.9151
Metrics/base_velocity/error_vel_yaw: 1.2266
      Episode_Termination/time_out: 3.9167
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 216956928
                    Iteration time: 1.10s
                        Total time: 2411.03s
                               ETA: 867.4s

################################################################################
                     [1m Learning iteration 2207/3000 [0m                     

                       Computation: 88700 steps/s (collection: 0.985s, learning 0.124s)
               Value function loss: 41611.6073
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8348
                     Learning rate: 0.0000
                       Mean reward: 136.15
               Mean episode length: 977.88
       Episode_Reward/keep_balance: 0.9765
     Episode_Reward/rew_lin_vel_xy: 6.2531
      Episode_Reward/rew_ang_vel_z: 2.5437
    Episode_Reward/pen_base_height: -0.2903
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1429
   Episode_Reward/pen_joint_torque: -0.2894
    Episode_Reward/pen_joint_accel: -0.1062
    Episode_Reward/pen_action_rate: -0.2487
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0556
   Episode_Reward/pen_joint_powers: -0.0879
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.2450
Episode_Reward/pen_flat_orientation: -0.0961
  Episode_Reward/pen_feet_distance: -0.0261
Episode_Reward/pen_feet_regulation: -0.4760
   Episode_Reward/foot_landing_vel: -0.1227
   Episode_Reward/test_gait_reward: -0.8831
Metrics/base_velocity/error_vel_xy: 0.9189
Metrics/base_velocity/error_vel_yaw: 1.2532
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 217055232
                    Iteration time: 1.11s
                        Total time: 2412.14s
                               ETA: 866.3s

################################################################################
                     [1m Learning iteration 2208/3000 [0m                     

                       Computation: 88876 steps/s (collection: 0.980s, learning 0.126s)
               Value function loss: 1780533.7000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8349
                     Learning rate: 0.0000
                       Mean reward: 139.07
               Mean episode length: 984.71
       Episode_Reward/keep_balance: 0.9876
     Episode_Reward/rew_lin_vel_xy: 6.3723
      Episode_Reward/rew_ang_vel_z: 2.6321
    Episode_Reward/pen_base_height: -0.2762
      Episode_Reward/pen_lin_vel_z: -0.0374
     Episode_Reward/pen_ang_vel_xy: -0.1409
   Episode_Reward/pen_joint_torque: -0.2535
    Episode_Reward/pen_joint_accel: -0.1056
    Episode_Reward/pen_action_rate: -0.1453
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0546
   Episode_Reward/pen_joint_powers: -0.0850
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2438
Episode_Reward/pen_flat_orientation: -0.0849
  Episode_Reward/pen_feet_distance: -0.0336
Episode_Reward/pen_feet_regulation: -0.4831
   Episode_Reward/foot_landing_vel: -0.1238
   Episode_Reward/test_gait_reward: -0.8897
Metrics/base_velocity/error_vel_xy: 0.9003
Metrics/base_velocity/error_vel_yaw: 1.2112
      Episode_Termination/time_out: 4.3333
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 217153536
                    Iteration time: 1.11s
                        Total time: 2413.24s
                               ETA: 865.2s

################################################################################
                     [1m Learning iteration 2209/3000 [0m                     

                       Computation: 88793 steps/s (collection: 0.984s, learning 0.123s)
               Value function loss: 235215264.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8349
                     Learning rate: 0.0000
                       Mean reward: 136.86
               Mean episode length: 965.50
       Episode_Reward/keep_balance: 0.9548
     Episode_Reward/rew_lin_vel_xy: 6.1356
      Episode_Reward/rew_ang_vel_z: 2.5180
    Episode_Reward/pen_base_height: -0.2794
      Episode_Reward/pen_lin_vel_z: -0.0382
     Episode_Reward/pen_ang_vel_xy: -0.1450
   Episode_Reward/pen_joint_torque: -0.2493
    Episode_Reward/pen_joint_accel: -0.0995
    Episode_Reward/pen_action_rate: -0.1413
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0525
   Episode_Reward/pen_joint_powers: -0.0827
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.2355
Episode_Reward/pen_flat_orientation: -0.0966
  Episode_Reward/pen_feet_distance: -0.0253
Episode_Reward/pen_feet_regulation: -0.4435
   Episode_Reward/foot_landing_vel: -0.1198
   Episode_Reward/test_gait_reward: -0.8577
Metrics/base_velocity/error_vel_xy: 0.8876
Metrics/base_velocity/error_vel_yaw: 1.1909
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 217251840
                    Iteration time: 1.11s
                        Total time: 2414.35s
                               ETA: 864.1s

################################################################################
                     [1m Learning iteration 2210/3000 [0m                     

                       Computation: 89054 steps/s (collection: 0.983s, learning 0.121s)
               Value function loss: 8090711603.2000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8350
                     Learning rate: 0.0000
                       Mean reward: 139.65
               Mean episode length: 979.62
       Episode_Reward/keep_balance: 0.9740
     Episode_Reward/rew_lin_vel_xy: 6.2052
      Episode_Reward/rew_ang_vel_z: 2.5602
    Episode_Reward/pen_base_height: -0.2772
      Episode_Reward/pen_lin_vel_z: -0.0383
     Episode_Reward/pen_ang_vel_xy: -0.1418
   Episode_Reward/pen_joint_torque: -0.2260
    Episode_Reward/pen_joint_accel: -0.1071
    Episode_Reward/pen_action_rate: -0.1131
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0551
   Episode_Reward/pen_joint_powers: -0.0854
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2417
Episode_Reward/pen_flat_orientation: -0.0892
  Episode_Reward/pen_feet_distance: -0.0263
Episode_Reward/pen_feet_regulation: -0.4888
   Episode_Reward/foot_landing_vel: -0.1198
   Episode_Reward/test_gait_reward: -0.8871
Metrics/base_velocity/error_vel_xy: 0.9263
Metrics/base_velocity/error_vel_yaw: 1.2205
      Episode_Termination/time_out: 3.5000
  Episode_Termination/base_contact: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 217350144
                    Iteration time: 1.10s
                        Total time: 2415.46s
                               ETA: 863.1s

################################################################################
                     [1m Learning iteration 2211/3000 [0m                     

                       Computation: 89006 steps/s (collection: 0.983s, learning 0.121s)
               Value function loss: 5218397847552.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8350
                     Learning rate: 0.0000
                       Mean reward: 135.28
               Mean episode length: 963.58
       Episode_Reward/keep_balance: 0.9539
     Episode_Reward/rew_lin_vel_xy: 6.1050
      Episode_Reward/rew_ang_vel_z: 2.5017
    Episode_Reward/pen_base_height: -0.2853
      Episode_Reward/pen_lin_vel_z: -0.0371
     Episode_Reward/pen_ang_vel_xy: -0.1435
   Episode_Reward/pen_joint_torque: -0.2510
    Episode_Reward/pen_joint_accel: -0.1054
    Episode_Reward/pen_action_rate: -0.1416
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0550
   Episode_Reward/pen_joint_powers: -0.0861
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2405
Episode_Reward/pen_flat_orientation: -0.0970
  Episode_Reward/pen_feet_distance: -0.0304
Episode_Reward/pen_feet_regulation: -0.4658
   Episode_Reward/foot_landing_vel: -0.1181
   Episode_Reward/test_gait_reward: -0.8690
Metrics/base_velocity/error_vel_xy: 0.9000
Metrics/base_velocity/error_vel_yaw: 1.2189
      Episode_Termination/time_out: 4.5417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 217448448
                    Iteration time: 1.10s
                        Total time: 2416.56s
                               ETA: 862.0s

################################################################################
                     [1m Learning iteration 2212/3000 [0m                     

                       Computation: 87246 steps/s (collection: 1.005s, learning 0.122s)
               Value function loss: 306793866172825.6250
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8350
                     Learning rate: 0.0000
                       Mean reward: 91.73
               Mean episode length: 751.09
       Episode_Reward/keep_balance: 0.8136
     Episode_Reward/rew_lin_vel_xy: 5.0961
      Episode_Reward/rew_ang_vel_z: 2.1062
    Episode_Reward/pen_base_height: -0.2849
      Episode_Reward/pen_lin_vel_z: -0.0380
     Episode_Reward/pen_ang_vel_xy: -0.1382
   Episode_Reward/pen_joint_torque: -0.3235
    Episode_Reward/pen_joint_accel: -0.0882
    Episode_Reward/pen_action_rate: -0.2074
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0492
   Episode_Reward/pen_joint_powers: -0.0800
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.2084
Episode_Reward/pen_flat_orientation: -0.1174
  Episode_Reward/pen_feet_distance: -0.0224
Episode_Reward/pen_feet_regulation: -0.4103
   Episode_Reward/foot_landing_vel: -0.1078
   Episode_Reward/test_gait_reward: -0.7402
Metrics/base_velocity/error_vel_xy: 0.8313
Metrics/base_velocity/error_vel_yaw: 1.1130
      Episode_Termination/time_out: 3.6250
  Episode_Termination/base_contact: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 217546752
                    Iteration time: 1.13s
                        Total time: 2417.69s
                               ETA: 860.9s

################################################################################
                     [1m Learning iteration 2213/3000 [0m                     

                       Computation: 87870 steps/s (collection: 0.996s, learning 0.123s)
               Value function loss: 14425020627838566.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8350
                     Learning rate: 0.0000
                       Mean reward: 89.41
               Mean episode length: 773.78
       Episode_Reward/keep_balance: 0.7669
     Episode_Reward/rew_lin_vel_xy: 4.7162
      Episode_Reward/rew_ang_vel_z: 1.9459
    Episode_Reward/pen_base_height: -0.2952
      Episode_Reward/pen_lin_vel_z: -0.0407
     Episode_Reward/pen_ang_vel_xy: -0.1338
   Episode_Reward/pen_joint_torque: -0.3150
    Episode_Reward/pen_joint_accel: -0.0926
    Episode_Reward/pen_action_rate: -0.2616
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0502
   Episode_Reward/pen_joint_powers: -0.0795
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -0.2005
Episode_Reward/pen_flat_orientation: -0.1302
  Episode_Reward/pen_feet_distance: -0.0247
Episode_Reward/pen_feet_regulation: -0.4237
   Episode_Reward/foot_landing_vel: -0.1036
   Episode_Reward/test_gait_reward: -0.7045
Metrics/base_velocity/error_vel_xy: 0.8237
Metrics/base_velocity/error_vel_yaw: 1.1015
      Episode_Termination/time_out: 4.2500
  Episode_Termination/base_contact: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 217645056
                    Iteration time: 1.12s
                        Total time: 2418.81s
                               ETA: 859.8s

################################################################################
                     [1m Learning iteration 2214/3000 [0m                     

                       Computation: 88364 steps/s (collection: 0.988s, learning 0.124s)
               Value function loss: 417600619377852416.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8350
                     Learning rate: 0.0000
                       Mean reward: 116.06
               Mean episode length: 939.19
       Episode_Reward/keep_balance: 0.9321
     Episode_Reward/rew_lin_vel_xy: 5.8449
      Episode_Reward/rew_ang_vel_z: 2.4123
    Episode_Reward/pen_base_height: -0.2980
      Episode_Reward/pen_lin_vel_z: -0.0384
     Episode_Reward/pen_ang_vel_xy: -0.1439
   Episode_Reward/pen_joint_torque: -0.3103
    Episode_Reward/pen_joint_accel: -0.1105
    Episode_Reward/pen_action_rate: -0.6183
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0554
   Episode_Reward/pen_joint_powers: -0.0848
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.2390
Episode_Reward/pen_flat_orientation: -0.1096
  Episode_Reward/pen_feet_distance: -0.0266
Episode_Reward/pen_feet_regulation: -0.4791
   Episode_Reward/foot_landing_vel: -0.1255
   Episode_Reward/test_gait_reward: -0.8499
Metrics/base_velocity/error_vel_xy: 0.9162
Metrics/base_velocity/error_vel_yaw: 1.2275
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 217743360
                    Iteration time: 1.11s
                        Total time: 2419.92s
                               ETA: 858.7s

################################################################################
                     [1m Learning iteration 2215/3000 [0m                     

                       Computation: 89386 steps/s (collection: 0.976s, learning 0.124s)
               Value function loss: 40394046857430016000.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8350
                     Learning rate: 0.0000
                       Mean reward: 113.83
               Mean episode length: 920.23
       Episode_Reward/keep_balance: 0.8946
     Episode_Reward/rew_lin_vel_xy: 5.5115
      Episode_Reward/rew_ang_vel_z: 2.2496
    Episode_Reward/pen_base_height: -0.3238
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1460
   Episode_Reward/pen_joint_torque: -0.3910
    Episode_Reward/pen_joint_accel: -0.1013
    Episode_Reward/pen_action_rate: -0.8224
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0562
   Episode_Reward/pen_joint_powers: -0.0880
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.2424
Episode_Reward/pen_flat_orientation: -0.1316
  Episode_Reward/pen_feet_distance: -0.0259
Episode_Reward/pen_feet_regulation: -0.4798
   Episode_Reward/foot_landing_vel: -0.1253
   Episode_Reward/test_gait_reward: -0.8188
Metrics/base_velocity/error_vel_xy: 0.9440
Metrics/base_velocity/error_vel_yaw: 1.2670
      Episode_Termination/time_out: 3.7917
  Episode_Termination/base_contact: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 217841664
                    Iteration time: 1.10s
                        Total time: 2421.02s
                               ETA: 857.6s

################################################################################
                     [1m Learning iteration 2216/3000 [0m                     

                       Computation: 88773 steps/s (collection: 0.981s, learning 0.126s)
               Value function loss: 2065928393356505776128.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8351
                     Learning rate: 0.0000
                       Mean reward: 130.52
               Mean episode length: 969.98
       Episode_Reward/keep_balance: 0.9540
     Episode_Reward/rew_lin_vel_xy: 5.9383
      Episode_Reward/rew_ang_vel_z: 2.4864
    Episode_Reward/pen_base_height: -0.3038
      Episode_Reward/pen_lin_vel_z: -0.0412
     Episode_Reward/pen_ang_vel_xy: -0.1513
   Episode_Reward/pen_joint_torque: -0.2822
    Episode_Reward/pen_joint_accel: -0.1029
    Episode_Reward/pen_action_rate: -0.1793
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0564
   Episode_Reward/pen_joint_powers: -0.0868
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.2465
Episode_Reward/pen_flat_orientation: -0.1035
  Episode_Reward/pen_feet_distance: -0.0265
Episode_Reward/pen_feet_regulation: -0.4738
   Episode_Reward/foot_landing_vel: -0.1352
   Episode_Reward/test_gait_reward: -0.8662
Metrics/base_velocity/error_vel_xy: 0.9545
Metrics/base_velocity/error_vel_yaw: 1.2419
      Episode_Termination/time_out: 4.4583
  Episode_Termination/base_contact: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 217939968
                    Iteration time: 1.11s
                        Total time: 2422.13s
                               ETA: 856.5s

################################################################################
                     [1m Learning iteration 2217/3000 [0m                     

                       Computation: 87877 steps/s (collection: 0.995s, learning 0.123s)
               Value function loss: 126301793099042781134848.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8351
                     Learning rate: 0.0000
                       Mean reward: 122.10
               Mean episode length: 953.30
       Episode_Reward/keep_balance: 0.9497
     Episode_Reward/rew_lin_vel_xy: 5.8746
      Episode_Reward/rew_ang_vel_z: 2.4385
    Episode_Reward/pen_base_height: -0.3071
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1503
   Episode_Reward/pen_joint_torque: -0.2848
    Episode_Reward/pen_joint_accel: -0.1059
    Episode_Reward/pen_action_rate: -0.2951
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0578
   Episode_Reward/pen_joint_powers: -0.0890
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2485
Episode_Reward/pen_flat_orientation: -0.1063
  Episode_Reward/pen_feet_distance: -0.0328
Episode_Reward/pen_feet_regulation: -0.5008
   Episode_Reward/foot_landing_vel: -0.1276
   Episode_Reward/test_gait_reward: -0.8692
Metrics/base_velocity/error_vel_xy: 0.9891
Metrics/base_velocity/error_vel_yaw: 1.2816
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 218038272
                    Iteration time: 1.12s
                        Total time: 2423.24s
                               ETA: 855.5s

################################################################################
                     [1m Learning iteration 2218/3000 [0m                     

                       Computation: 87546 steps/s (collection: 0.998s, learning 0.125s)
               Value function loss: 16867963314238524489728.0000
                    Surrogate loss: -0.0013
             Mean action noise std: 0.8351
                     Learning rate: 0.0000
                       Mean reward: -889736784650.72
               Mean episode length: 937.69
       Episode_Reward/keep_balance: 0.9456
     Episode_Reward/rew_lin_vel_xy: 5.8678
      Episode_Reward/rew_ang_vel_z: 2.4216
    Episode_Reward/pen_base_height: -0.3075
      Episode_Reward/pen_lin_vel_z: -0.0393
     Episode_Reward/pen_ang_vel_xy: -0.1490
   Episode_Reward/pen_joint_torque: -0.3560
    Episode_Reward/pen_joint_accel: -0.1021
    Episode_Reward/pen_action_rate: -30837100544.0000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0565
   Episode_Reward/pen_joint_powers: -0.0882
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -56534608.0000
Episode_Reward/pen_flat_orientation: -0.1113
  Episode_Reward/pen_feet_distance: -0.0255
Episode_Reward/pen_feet_regulation: -0.4938
   Episode_Reward/foot_landing_vel: -0.1261
   Episode_Reward/test_gait_reward: -0.8790
Metrics/base_velocity/error_vel_xy: 0.9577
Metrics/base_velocity/error_vel_yaw: 1.2816
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 218136576
                    Iteration time: 1.12s
                        Total time: 2424.37s
                               ETA: 854.4s

################################################################################
                     [1m Learning iteration 2219/3000 [0m                     

                       Computation: 88243 steps/s (collection: 0.992s, learning 0.122s)
               Value function loss: 21760482355.2000
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8351
                     Learning rate: 0.0000
                       Mean reward: 123.77
               Mean episode length: 955.27
       Episode_Reward/keep_balance: 0.9668
     Episode_Reward/rew_lin_vel_xy: 6.0021
      Episode_Reward/rew_ang_vel_z: 2.4925
    Episode_Reward/pen_base_height: -0.2941
      Episode_Reward/pen_lin_vel_z: -0.0397
     Episode_Reward/pen_ang_vel_xy: -0.1473
   Episode_Reward/pen_joint_torque: -0.2765
    Episode_Reward/pen_joint_accel: -0.1066
    Episode_Reward/pen_action_rate: -0.2535
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0579
   Episode_Reward/pen_joint_powers: -0.0897
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2520
Episode_Reward/pen_flat_orientation: -0.1029
  Episode_Reward/pen_feet_distance: -0.0266
Episode_Reward/pen_feet_regulation: -0.5061
   Episode_Reward/foot_landing_vel: -0.1240
   Episode_Reward/test_gait_reward: -0.8866
Metrics/base_velocity/error_vel_xy: 0.9619
Metrics/base_velocity/error_vel_yaw: 1.2786
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 218234880
                    Iteration time: 1.11s
                        Total time: 2425.48s
                               ETA: 853.3s

################################################################################
                     [1m Learning iteration 2220/3000 [0m                     

                       Computation: 87830 steps/s (collection: 0.996s, learning 0.123s)
               Value function loss: 1228702089216.0000
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8351
                     Learning rate: 0.0000
                       Mean reward: 123.91
               Mean episode length: 955.18
       Episode_Reward/keep_balance: 0.9291
     Episode_Reward/rew_lin_vel_xy: 5.7308
      Episode_Reward/rew_ang_vel_z: 2.3701
    Episode_Reward/pen_base_height: -0.3050
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1492
   Episode_Reward/pen_joint_torque: -0.2663
    Episode_Reward/pen_joint_accel: -0.1124
    Episode_Reward/pen_action_rate: -0.1423
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0575
   Episode_Reward/pen_joint_powers: -0.0884
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.2481
Episode_Reward/pen_flat_orientation: -0.1088
  Episode_Reward/pen_feet_distance: -0.0264
Episode_Reward/pen_feet_regulation: -0.4980
   Episode_Reward/foot_landing_vel: -0.1233
   Episode_Reward/test_gait_reward: -0.8590
Metrics/base_velocity/error_vel_xy: 0.9468
Metrics/base_velocity/error_vel_yaw: 1.2536
      Episode_Termination/time_out: 3.7083
  Episode_Termination/base_contact: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 218333184
                    Iteration time: 1.12s
                        Total time: 2426.60s
                               ETA: 852.2s

################################################################################
                     [1m Learning iteration 2221/3000 [0m                     

                       Computation: 89550 steps/s (collection: 0.974s, learning 0.124s)
               Value function loss: 66484681939353.6016
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8351
                     Learning rate: 0.0000
                       Mean reward: 123.08
               Mean episode length: 954.27
       Episode_Reward/keep_balance: 0.9649
     Episode_Reward/rew_lin_vel_xy: 5.9782
      Episode_Reward/rew_ang_vel_z: 2.4256
    Episode_Reward/pen_base_height: -0.3014
      Episode_Reward/pen_lin_vel_z: -0.0406
     Episode_Reward/pen_ang_vel_xy: -0.1499
   Episode_Reward/pen_joint_torque: -0.2591
    Episode_Reward/pen_joint_accel: -0.1221
    Episode_Reward/pen_action_rate: -0.1591
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0599
   Episode_Reward/pen_joint_powers: -0.0899
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.2579
Episode_Reward/pen_flat_orientation: -0.1050
  Episode_Reward/pen_feet_distance: -0.0346
Episode_Reward/pen_feet_regulation: -0.4948
   Episode_Reward/foot_landing_vel: -0.1330
   Episode_Reward/test_gait_reward: -0.8941
Metrics/base_velocity/error_vel_xy: 0.9757
Metrics/base_velocity/error_vel_yaw: 1.3426
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 218431488
                    Iteration time: 1.10s
                        Total time: 2427.70s
                               ETA: 851.1s

################################################################################
                     [1m Learning iteration 2222/3000 [0m                     

                       Computation: 89608 steps/s (collection: 0.972s, learning 0.125s)
               Value function loss: 3553636868371251.0000
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8352
                     Learning rate: 0.0000
                       Mean reward: 127.12
               Mean episode length: 958.89
       Episode_Reward/keep_balance: 0.9575
     Episode_Reward/rew_lin_vel_xy: 5.9325
      Episode_Reward/rew_ang_vel_z: 2.4754
    Episode_Reward/pen_base_height: -0.3064
      Episode_Reward/pen_lin_vel_z: -0.0408
     Episode_Reward/pen_ang_vel_xy: -0.1515
   Episode_Reward/pen_joint_torque: -0.2747
    Episode_Reward/pen_joint_accel: -0.1091
    Episode_Reward/pen_action_rate: -0.1763
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0585
   Episode_Reward/pen_joint_powers: -0.0906
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.2510
Episode_Reward/pen_flat_orientation: -0.1053
  Episode_Reward/pen_feet_distance: -0.0310
Episode_Reward/pen_feet_regulation: -0.4917
   Episode_Reward/foot_landing_vel: -0.1273
   Episode_Reward/test_gait_reward: -0.8765
Metrics/base_velocity/error_vel_xy: 0.9664
Metrics/base_velocity/error_vel_yaw: 1.2673
      Episode_Termination/time_out: 3.9583
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 218529792
                    Iteration time: 1.10s
                        Total time: 2428.79s
                               ETA: 850.0s

################################################################################
                     [1m Learning iteration 2223/3000 [0m                     

                       Computation: 88428 steps/s (collection: 0.988s, learning 0.123s)
               Value function loss: 187748264957706240.0000
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8352
                     Learning rate: 0.0000
                       Mean reward: 130.99
               Mean episode length: 982.57
       Episode_Reward/keep_balance: 0.9785
     Episode_Reward/rew_lin_vel_xy: 5.9986
      Episode_Reward/rew_ang_vel_z: 2.4954
    Episode_Reward/pen_base_height: -0.2989
      Episode_Reward/pen_lin_vel_z: -0.0427
     Episode_Reward/pen_ang_vel_xy: -0.1501
   Episode_Reward/pen_joint_torque: -0.2408
    Episode_Reward/pen_joint_accel: -0.1020
    Episode_Reward/pen_action_rate: -0.1274
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0892
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2598
Episode_Reward/pen_flat_orientation: -0.1015
  Episode_Reward/pen_feet_distance: -0.0268
Episode_Reward/pen_feet_regulation: -0.4941
   Episode_Reward/foot_landing_vel: -0.1334
   Episode_Reward/test_gait_reward: -0.9040
Metrics/base_velocity/error_vel_xy: 1.0097
Metrics/base_velocity/error_vel_yaw: 1.3416
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 218628096
                    Iteration time: 1.11s
                        Total time: 2429.91s
                               ETA: 848.9s

################################################################################
                     [1m Learning iteration 2224/3000 [0m                     

                       Computation: 89374 steps/s (collection: 0.977s, learning 0.123s)
               Value function loss: 10005862356603424768.0000
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8353
                     Learning rate: 0.0000
                       Mean reward: 124.67
               Mean episode length: 971.99
       Episode_Reward/keep_balance: 0.9701
     Episode_Reward/rew_lin_vel_xy: 6.0302
      Episode_Reward/rew_ang_vel_z: 2.4509
    Episode_Reward/pen_base_height: -0.3059
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1582
   Episode_Reward/pen_joint_torque: -0.2618
    Episode_Reward/pen_joint_accel: -0.1108
    Episode_Reward/pen_action_rate: -0.2048
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0589
   Episode_Reward/pen_joint_powers: -0.0903
Episode_Reward/pen_undesired_contacts: -0.0003
Episode_Reward/pen_action_smoothness: -0.2624
Episode_Reward/pen_flat_orientation: -0.1073
  Episode_Reward/pen_feet_distance: -0.0300
Episode_Reward/pen_feet_regulation: -0.5133
   Episode_Reward/foot_landing_vel: -0.1263
   Episode_Reward/test_gait_reward: -0.9014
Metrics/base_velocity/error_vel_xy: 0.9597
Metrics/base_velocity/error_vel_yaw: 1.3348
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 218726400
                    Iteration time: 1.10s
                        Total time: 2431.01s
                               ETA: 847.8s

################################################################################
                     [1m Learning iteration 2225/3000 [0m                     

                       Computation: 89575 steps/s (collection: 0.974s, learning 0.123s)
               Value function loss: 528225106824146190336.0000
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8354
                     Learning rate: 0.0000
                       Mean reward: 129.06
               Mean episode length: 977.92
       Episode_Reward/keep_balance: 0.9797
     Episode_Reward/rew_lin_vel_xy: 6.0337
      Episode_Reward/rew_ang_vel_z: 2.4992
    Episode_Reward/pen_base_height: -0.3016
      Episode_Reward/pen_lin_vel_z: -0.0398
     Episode_Reward/pen_ang_vel_xy: -0.1566
   Episode_Reward/pen_joint_torque: -0.2307
    Episode_Reward/pen_joint_accel: -0.1130
    Episode_Reward/pen_action_rate: -0.1221
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0597
   Episode_Reward/pen_joint_powers: -0.0897
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2611
Episode_Reward/pen_flat_orientation: -0.0968
  Episode_Reward/pen_feet_distance: -0.0256
Episode_Reward/pen_feet_regulation: -0.5040
   Episode_Reward/foot_landing_vel: -0.1343
   Episode_Reward/test_gait_reward: -0.9073
Metrics/base_velocity/error_vel_xy: 0.9889
Metrics/base_velocity/error_vel_yaw: 1.3147
      Episode_Termination/time_out: 4.5000
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 218824704
                    Iteration time: 1.10s
                        Total time: 2432.10s
                               ETA: 846.8s

################################################################################
                     [1m Learning iteration 2226/3000 [0m                     

                       Computation: 88699 steps/s (collection: 0.986s, learning 0.122s)
               Value function loss: 27895642587629183041536.0000
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8355
                     Learning rate: 0.0000
                       Mean reward: 128.20
               Mean episode length: 968.12
       Episode_Reward/keep_balance: 0.9802
     Episode_Reward/rew_lin_vel_xy: 6.0882
      Episode_Reward/rew_ang_vel_z: 2.5030
    Episode_Reward/pen_base_height: -0.3085
      Episode_Reward/pen_lin_vel_z: -0.0395
     Episode_Reward/pen_ang_vel_xy: -0.1543
   Episode_Reward/pen_joint_torque: -0.2526
    Episode_Reward/pen_joint_accel: -0.1085
    Episode_Reward/pen_action_rate: -0.1320
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0908
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2629
Episode_Reward/pen_flat_orientation: -0.0985
  Episode_Reward/pen_feet_distance: -0.0275
Episode_Reward/pen_feet_regulation: -0.4881
   Episode_Reward/foot_landing_vel: -0.1324
   Episode_Reward/test_gait_reward: -0.9076
Metrics/base_velocity/error_vel_xy: 0.9587
Metrics/base_velocity/error_vel_yaw: 1.3116
      Episode_Termination/time_out: 4.0000
  Episode_Termination/base_contact: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 218923008
                    Iteration time: 1.11s
                        Total time: 2433.21s
                               ETA: 845.7s

################################################################################
                     [1m Learning iteration 2227/3000 [0m                     

                       Computation: 90663 steps/s (collection: 0.962s, learning 0.122s)
               Value function loss: 1468032029465685243461632.0000
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 128.18
               Mean episode length: 984.92
       Episode_Reward/keep_balance: 0.9874
     Episode_Reward/rew_lin_vel_xy: 6.0915
      Episode_Reward/rew_ang_vel_z: 2.5053
    Episode_Reward/pen_base_height: -0.3081
      Episode_Reward/pen_lin_vel_z: -0.0414
     Episode_Reward/pen_ang_vel_xy: -0.1536
   Episode_Reward/pen_joint_torque: -0.2525
    Episode_Reward/pen_joint_accel: -0.1261
    Episode_Reward/pen_action_rate: -0.1330
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0617
   Episode_Reward/pen_joint_powers: -0.0934
Episode_Reward/pen_undesired_contacts: -0.0000
Episode_Reward/pen_action_smoothness: -0.2666
Episode_Reward/pen_flat_orientation: -0.1006
  Episode_Reward/pen_feet_distance: -0.0320
Episode_Reward/pen_feet_regulation: -0.5253
   Episode_Reward/foot_landing_vel: -0.1397
   Episode_Reward/test_gait_reward: -0.9242
Metrics/base_velocity/error_vel_xy: 0.9919
Metrics/base_velocity/error_vel_yaw: 1.3293
      Episode_Termination/time_out: 4.2917
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 219021312
                    Iteration time: 1.08s
                        Total time: 2434.30s
                               ETA: 844.6s

################################################################################
                     [1m Learning iteration 2228/3000 [0m                     

                       Computation: 89774 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: 78733624056763535440478208.0000
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 119.87
               Mean episode length: 988.82
       Episode_Reward/keep_balance: 0.9788
     Episode_Reward/rew_lin_vel_xy: 6.0086
      Episode_Reward/rew_ang_vel_z: 2.4966
    Episode_Reward/pen_base_height: -0.3155
      Episode_Reward/pen_lin_vel_z: -0.0401
     Episode_Reward/pen_ang_vel_xy: -0.1568
   Episode_Reward/pen_joint_torque: -0.2630
    Episode_Reward/pen_joint_accel: -0.1120
    Episode_Reward/pen_action_rate: -0.5661
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0587
   Episode_Reward/pen_joint_powers: -0.0893
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.2635
Episode_Reward/pen_flat_orientation: -0.1066
  Episode_Reward/pen_feet_distance: -0.0341
Episode_Reward/pen_feet_regulation: -0.5067
   Episode_Reward/foot_landing_vel: -0.1376
   Episode_Reward/test_gait_reward: -0.9048
Metrics/base_velocity/error_vel_xy: 1.0121
Metrics/base_velocity/error_vel_yaw: 1.3154
      Episode_Termination/time_out: 3.4583
  Episode_Termination/base_contact: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 219119616
                    Iteration time: 1.10s
                        Total time: 2435.39s
                               ETA: 843.5s

################################################################################
                     [1m Learning iteration 2229/3000 [0m                     

                       Computation: 89358 steps/s (collection: 0.977s, learning 0.124s)
               Value function loss: 4154332756661414460160737280.0000
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 124.34
               Mean episode length: 959.58
       Episode_Reward/keep_balance: 0.9533
     Episode_Reward/rew_lin_vel_xy: 5.8788
      Episode_Reward/rew_ang_vel_z: 2.4346
    Episode_Reward/pen_base_height: -0.3103
      Episode_Reward/pen_lin_vel_z: -0.0404
     Episode_Reward/pen_ang_vel_xy: -0.1541
   Episode_Reward/pen_joint_torque: -0.2652
    Episode_Reward/pen_joint_accel: -0.1110
    Episode_Reward/pen_action_rate: -0.1369
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0592
   Episode_Reward/pen_joint_powers: -0.0908
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2573
Episode_Reward/pen_flat_orientation: -0.1059
  Episode_Reward/pen_feet_distance: -0.0290
Episode_Reward/pen_feet_regulation: -0.4972
   Episode_Reward/foot_landing_vel: -0.1295
   Episode_Reward/test_gait_reward: -0.8898
Metrics/base_velocity/error_vel_xy: 0.9562
Metrics/base_velocity/error_vel_yaw: 1.2875
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 219217920
                    Iteration time: 1.10s
                        Total time: 2436.49s
                               ETA: 842.4s

################################################################################
                     [1m Learning iteration 2230/3000 [0m                     

                       Computation: 89192 steps/s (collection: 0.978s, learning 0.124s)
               Value function loss: 221278259136865503382889037824.0000
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 126.98
               Mean episode length: 963.62
       Episode_Reward/keep_balance: 0.9568
     Episode_Reward/rew_lin_vel_xy: 5.8686
      Episode_Reward/rew_ang_vel_z: 2.4487
    Episode_Reward/pen_base_height: -0.3042
      Episode_Reward/pen_lin_vel_z: -0.0403
     Episode_Reward/pen_ang_vel_xy: -0.1521
   Episode_Reward/pen_joint_torque: -0.2466
    Episode_Reward/pen_joint_accel: -0.1067
    Episode_Reward/pen_action_rate: -0.1268
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0584
   Episode_Reward/pen_joint_powers: -0.0895
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2563
Episode_Reward/pen_flat_orientation: -0.1042
  Episode_Reward/pen_feet_distance: -0.0303
Episode_Reward/pen_feet_regulation: -0.5047
   Episode_Reward/foot_landing_vel: -0.1247
   Episode_Reward/test_gait_reward: -0.8896
Metrics/base_velocity/error_vel_xy: 0.9811
Metrics/base_velocity/error_vel_yaw: 1.2898
      Episode_Termination/time_out: 4.0417
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 219316224
                    Iteration time: 1.10s
                        Total time: 2437.59s
                               ETA: 841.3s

################################################################################
                     [1m Learning iteration 2231/3000 [0m                     

                       Computation: 90087 steps/s (collection: 0.968s, learning 0.124s)
               Value function loss: 11725593815677370005414700122112.0000
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 129.53
               Mean episode length: 988.56
       Episode_Reward/keep_balance: 0.9914
     Episode_Reward/rew_lin_vel_xy: 6.0571
      Episode_Reward/rew_ang_vel_z: 2.4997
    Episode_Reward/pen_base_height: -0.3114
      Episode_Reward/pen_lin_vel_z: -0.0418
     Episode_Reward/pen_ang_vel_xy: -0.1553
   Episode_Reward/pen_joint_torque: -0.2445
    Episode_Reward/pen_joint_accel: -0.1159
    Episode_Reward/pen_action_rate: -0.1292
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0604
   Episode_Reward/pen_joint_powers: -0.0924
Episode_Reward/pen_undesired_contacts: -0.0001
Episode_Reward/pen_action_smoothness: -0.2735
Episode_Reward/pen_flat_orientation: -0.1011
  Episode_Reward/pen_feet_distance: -0.0329
Episode_Reward/pen_feet_regulation: -0.5181
   Episode_Reward/foot_landing_vel: -0.1404
   Episode_Reward/test_gait_reward: -0.9242
Metrics/base_velocity/error_vel_xy: 1.0260
Metrics/base_velocity/error_vel_yaw: 1.3536
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 219414528
                    Iteration time: 1.09s
                        Total time: 2438.68s
                               ETA: 840.2s

################################################################################
                     [1m Learning iteration 2232/3000 [0m                     

                       Computation: 90199 steps/s (collection: 0.966s, learning 0.124s)
               Value function loss: 624008101939055421530749328687104.0000
                    Surrogate loss: -0.0037
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 124.51
               Mean episode length: 956.03
       Episode_Reward/keep_balance: 0.9592
     Episode_Reward/rew_lin_vel_xy: 5.9243
      Episode_Reward/rew_ang_vel_z: 2.4529
    Episode_Reward/pen_base_height: -0.3056
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1464
   Episode_Reward/pen_joint_torque: -0.2524
    Episode_Reward/pen_joint_accel: -0.1087
    Episode_Reward/pen_action_rate: -0.1359
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0577
   Episode_Reward/pen_joint_powers: -0.0894
Episode_Reward/pen_undesired_contacts: -0.0002
Episode_Reward/pen_action_smoothness: -0.2583
Episode_Reward/pen_flat_orientation: -0.0969
  Episode_Reward/pen_feet_distance: -0.0297
Episode_Reward/pen_feet_regulation: -0.4989
   Episode_Reward/foot_landing_vel: -0.1295
   Episode_Reward/test_gait_reward: -0.8968
Metrics/base_velocity/error_vel_xy: 0.9671
Metrics/base_velocity/error_vel_yaw: 1.2737
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 219512832
                    Iteration time: 1.09s
                        Total time: 2439.77s
                               ETA: 839.1s

################################################################################
                     [1m Learning iteration 2233/3000 [0m                     

                       Computation: 89914 steps/s (collection: 0.972s, learning 0.122s)
               Value function loss: inf
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 120.99
               Mean episode length: 941.08
       Episode_Reward/keep_balance: 0.9453
     Episode_Reward/rew_lin_vel_xy: 5.7095
      Episode_Reward/rew_ang_vel_z: 2.3986
    Episode_Reward/pen_base_height: -0.3134
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1504
   Episode_Reward/pen_joint_torque: -0.2697
    Episode_Reward/pen_joint_accel: -0.1193
    Episode_Reward/pen_action_rate: -0.1345
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0598
   Episode_Reward/pen_joint_powers: -0.0932
Episode_Reward/pen_undesired_contacts: -0.0004
Episode_Reward/pen_action_smoothness: -0.2616
Episode_Reward/pen_flat_orientation: -0.1080
  Episode_Reward/pen_feet_distance: -0.0349
Episode_Reward/pen_feet_regulation: -0.5156
   Episode_Reward/foot_landing_vel: -0.1333
   Episode_Reward/test_gait_reward: -0.8787
Metrics/base_velocity/error_vel_xy: 1.0202
Metrics/base_velocity/error_vel_yaw: 1.2820
      Episode_Termination/time_out: 3.5833
  Episode_Termination/base_contact: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 219611136
                    Iteration time: 1.09s
                        Total time: 2440.87s
                               ETA: 838.0s

################################################################################
                     [1m Learning iteration 2234/3000 [0m                     

                       Computation: 88485 steps/s (collection: 0.989s, learning 0.122s)
               Value function loss: inf
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 110.58
               Mean episode length: 888.62
       Episode_Reward/keep_balance: 0.9172
     Episode_Reward/rew_lin_vel_xy: 5.5478
      Episode_Reward/rew_ang_vel_z: 2.3415
    Episode_Reward/pen_base_height: -0.3113
      Episode_Reward/pen_lin_vel_z: -0.0424
     Episode_Reward/pen_ang_vel_xy: -0.1510
   Episode_Reward/pen_joint_torque: -0.2638
    Episode_Reward/pen_joint_accel: -0.1160
    Episode_Reward/pen_action_rate: -0.1944
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0582
   Episode_Reward/pen_joint_powers: -0.0875
Episode_Reward/pen_undesired_contacts: -0.0005
Episode_Reward/pen_action_smoothness: -0.2525
Episode_Reward/pen_flat_orientation: -0.1092
  Episode_Reward/pen_feet_distance: -0.0283
Episode_Reward/pen_feet_regulation: -0.4809
   Episode_Reward/foot_landing_vel: -0.1384
   Episode_Reward/test_gait_reward: -0.8504
Metrics/base_velocity/error_vel_xy: 0.9955
Metrics/base_velocity/error_vel_yaw: 1.2480
      Episode_Termination/time_out: 3.8750
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 219709440
                    Iteration time: 1.11s
                        Total time: 2441.98s
                               ETA: 836.9s

################################################################################
                     [1m Learning iteration 2235/3000 [0m                     

                       Computation: 87821 steps/s (collection: 0.997s, learning 0.123s)
               Value function loss: inf
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: -14642939089187786752.00
               Mean episode length: 750.47
       Episode_Reward/keep_balance: 0.7730
     Episode_Reward/rew_lin_vel_xy: 4.5675
      Episode_Reward/rew_ang_vel_z: 1.9409
    Episode_Reward/pen_base_height: -0.3502
      Episode_Reward/pen_lin_vel_z: -0.0409
     Episode_Reward/pen_ang_vel_xy: -0.1369
   Episode_Reward/pen_joint_torque: -0.4391
    Episode_Reward/pen_joint_accel: -0.0972
    Episode_Reward/pen_action_rate: -609093089184710656.0000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0513
   Episode_Reward/pen_joint_powers: -0.0804
Episode_Reward/pen_undesired_contacts: -0.0042
Episode_Reward/pen_action_smoothness: -1029459234783232.0000
Episode_Reward/pen_flat_orientation: -0.1401
  Episode_Reward/pen_feet_distance: -0.0266
Episode_Reward/pen_feet_regulation: -0.4298
   Episode_Reward/foot_landing_vel: -0.1158
   Episode_Reward/test_gait_reward: -0.7285
Metrics/base_velocity/error_vel_xy: 0.8959
Metrics/base_velocity/error_vel_yaw: 1.1223
      Episode_Termination/time_out: 4.4167
  Episode_Termination/base_contact: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 219807744
                    Iteration time: 1.12s
                        Total time: 2443.10s
                               ETA: 835.9s

################################################################################
                     [1m Learning iteration 2236/3000 [0m                     

                       Computation: 86800 steps/s (collection: 1.010s, learning 0.122s)
               Value function loss: inf
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 77.42
               Mean episode length: 729.84
       Episode_Reward/keep_balance: 0.7223
     Episode_Reward/rew_lin_vel_xy: 4.1854
      Episode_Reward/rew_ang_vel_z: 1.7782
    Episode_Reward/pen_base_height: -0.3370
      Episode_Reward/pen_lin_vel_z: -0.0445
     Episode_Reward/pen_ang_vel_xy: -0.1405
   Episode_Reward/pen_joint_torque: -0.2490
    Episode_Reward/pen_joint_accel: -0.0924
    Episode_Reward/pen_action_rate: -0.1280
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0519
   Episode_Reward/pen_joint_powers: -0.0790
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.2349
Episode_Reward/pen_flat_orientation: -0.1478
  Episode_Reward/pen_feet_distance: -0.0235
Episode_Reward/pen_feet_regulation: -0.4250
   Episode_Reward/foot_landing_vel: -0.1144
   Episode_Reward/test_gait_reward: -0.6807
Metrics/base_velocity/error_vel_xy: 0.8691
Metrics/base_velocity/error_vel_yaw: 1.1039
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 219906048
                    Iteration time: 1.13s
                        Total time: 2444.23s
                               ETA: 834.8s

################################################################################
                     [1m Learning iteration 2237/3000 [0m                     

                       Computation: 87174 steps/s (collection: 1.004s, learning 0.123s)
               Value function loss: inf
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 68.58
               Mean episode length: 693.24
       Episode_Reward/keep_balance: 0.6726
     Episode_Reward/rew_lin_vel_xy: 3.8034
      Episode_Reward/rew_ang_vel_z: 1.6244
    Episode_Reward/pen_base_height: -0.3341
      Episode_Reward/pen_lin_vel_z: -0.0449
     Episode_Reward/pen_ang_vel_xy: -0.1398
   Episode_Reward/pen_joint_torque: -0.2398
    Episode_Reward/pen_joint_accel: -0.0910
    Episode_Reward/pen_action_rate: -0.1355
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0510
   Episode_Reward/pen_joint_powers: -0.0784
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.2297
Episode_Reward/pen_flat_orientation: -0.1545
  Episode_Reward/pen_feet_distance: -0.0231
Episode_Reward/pen_feet_regulation: -0.4121
   Episode_Reward/foot_landing_vel: -0.1118
   Episode_Reward/test_gait_reward: -0.6345
Metrics/base_velocity/error_vel_xy: 0.8656
Metrics/base_velocity/error_vel_yaw: 1.0811
      Episode_Termination/time_out: 3.4167
  Episode_Termination/base_contact: 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 220004352
                    Iteration time: 1.13s
                        Total time: 2445.36s
                               ETA: 833.7s

################################################################################
                     [1m Learning iteration 2238/3000 [0m                     

                       Computation: 84799 steps/s (collection: 1.036s, learning 0.123s)
               Value function loss: inf
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 47.82
               Mean episode length: 556.56
       Episode_Reward/keep_balance: 0.6021
     Episode_Reward/rew_lin_vel_xy: 3.2791
      Episode_Reward/rew_ang_vel_z: 1.4278
    Episode_Reward/pen_base_height: -0.3324
      Episode_Reward/pen_lin_vel_z: -0.0450
     Episode_Reward/pen_ang_vel_xy: -0.1296
   Episode_Reward/pen_joint_torque: -0.2557
    Episode_Reward/pen_joint_accel: -0.0835
    Episode_Reward/pen_action_rate: -0.3438
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0484
   Episode_Reward/pen_joint_powers: -0.0750
Episode_Reward/pen_undesired_contacts: -0.0019
Episode_Reward/pen_action_smoothness: -0.2081
Episode_Reward/pen_flat_orientation: -0.1649
  Episode_Reward/pen_feet_distance: -0.0235
Episode_Reward/pen_feet_regulation: -0.3845
   Episode_Reward/foot_landing_vel: -0.1026
   Episode_Reward/test_gait_reward: -0.5725
Metrics/base_velocity/error_vel_xy: 0.8411
Metrics/base_velocity/error_vel_yaw: 1.0192
      Episode_Termination/time_out: 3.3750
  Episode_Termination/base_contact: 11.2083
--------------------------------------------------------------------------------
                   Total timesteps: 220102656
                    Iteration time: 1.16s
                        Total time: 2446.52s
                               ETA: 832.6s

################################################################################
                     [1m Learning iteration 2239/3000 [0m                     

                       Computation: 85690 steps/s (collection: 1.025s, learning 0.122s)
               Value function loss: inf
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: -12725343725212338749440.00
               Mean episode length: 520.14
       Episode_Reward/keep_balance: 0.5847
     Episode_Reward/rew_lin_vel_xy: 3.1165
      Episode_Reward/rew_ang_vel_z: 1.3814
    Episode_Reward/pen_base_height: -0.3396
      Episode_Reward/pen_lin_vel_z: -0.0458
     Episode_Reward/pen_ang_vel_xy: -0.1267
   Episode_Reward/pen_joint_torque: -0.2735
    Episode_Reward/pen_joint_accel: -0.0805
    Episode_Reward/pen_action_rate: -115066372344990662656.0000
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0475
   Episode_Reward/pen_joint_powers: -0.0740
Episode_Reward/pen_undesired_contacts: -0.0023
Episode_Reward/pen_action_smoothness: -199434435567812608.0000
Episode_Reward/pen_flat_orientation: -0.1682
  Episode_Reward/pen_feet_distance: -0.0226
Episode_Reward/pen_feet_regulation: -0.3829
   Episode_Reward/foot_landing_vel: -0.1022
   Episode_Reward/test_gait_reward: -0.5589
Metrics/base_velocity/error_vel_xy: 0.8491
Metrics/base_velocity/error_vel_yaw: 0.9738
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 220200960
                    Iteration time: 1.15s
                        Total time: 2447.67s
                               ETA: 831.6s

################################################################################
                     [1m Learning iteration 2240/3000 [0m                     

                       Computation: 85562 steps/s (collection: 1.026s, learning 0.123s)
               Value function loss: 67.8730
                    Surrogate loss: 0.0022
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 38.86
               Mean episode length: 515.99
       Episode_Reward/keep_balance: 0.5100
     Episode_Reward/rew_lin_vel_xy: 2.5821
      Episode_Reward/rew_ang_vel_z: 1.1726
    Episode_Reward/pen_base_height: -0.3250
      Episode_Reward/pen_lin_vel_z: -0.0446
     Episode_Reward/pen_ang_vel_xy: -0.1219
   Episode_Reward/pen_joint_torque: -0.1939
    Episode_Reward/pen_joint_accel: -0.0768
    Episode_Reward/pen_action_rate: -0.1220
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0445
   Episode_Reward/pen_joint_powers: -0.0685
Episode_Reward/pen_undesired_contacts: -0.0014
Episode_Reward/pen_action_smoothness: -0.1977
Episode_Reward/pen_flat_orientation: -0.1668
  Episode_Reward/pen_feet_distance: -0.0196
Episode_Reward/pen_feet_regulation: -0.3593
   Episode_Reward/foot_landing_vel: -0.0945
   Episode_Reward/test_gait_reward: -0.4961
Metrics/base_velocity/error_vel_xy: 0.8236
Metrics/base_velocity/error_vel_yaw: 0.9062
      Episode_Termination/time_out: 2.5833
  Episode_Termination/base_contact: 19.7083
--------------------------------------------------------------------------------
                   Total timesteps: 220299264
                    Iteration time: 1.15s
                        Total time: 2448.81s
                               ETA: 830.5s

################################################################################
                     [1m Learning iteration 2241/3000 [0m                     

                       Computation: 85510 steps/s (collection: 1.027s, learning 0.122s)
               Value function loss: 13930.5459
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 31.82
               Mean episode length: 511.74
       Episode_Reward/keep_balance: 0.5078
     Episode_Reward/rew_lin_vel_xy: 2.4961
      Episode_Reward/rew_ang_vel_z: 1.1472
    Episode_Reward/pen_base_height: -0.3474
      Episode_Reward/pen_lin_vel_z: -0.0492
     Episode_Reward/pen_ang_vel_xy: -0.1209
   Episode_Reward/pen_joint_torque: -0.2130
    Episode_Reward/pen_joint_accel: -0.0779
    Episode_Reward/pen_action_rate: -0.2120
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0458
   Episode_Reward/pen_joint_powers: -0.0698
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.1961
Episode_Reward/pen_flat_orientation: -0.1780
  Episode_Reward/pen_feet_distance: -0.0178
Episode_Reward/pen_feet_regulation: -0.3715
   Episode_Reward/foot_landing_vel: -0.0968
   Episode_Reward/test_gait_reward: -0.4948
Metrics/base_velocity/error_vel_xy: 0.8718
Metrics/base_velocity/error_vel_yaw: 0.9419
      Episode_Termination/time_out: 2.6250
  Episode_Termination/base_contact: 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 220397568
                    Iteration time: 1.15s
                        Total time: 2449.96s
                               ETA: 829.4s

################################################################################
                     [1m Learning iteration 2242/3000 [0m                     

                       Computation: 85213 steps/s (collection: 1.028s, learning 0.126s)
               Value function loss: 6325943.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 24.17
               Mean episode length: 518.81
       Episode_Reward/keep_balance: 0.5355
     Episode_Reward/rew_lin_vel_xy: 2.5311
      Episode_Reward/rew_ang_vel_z: 1.2043
    Episode_Reward/pen_base_height: -0.3747
      Episode_Reward/pen_lin_vel_z: -0.0517
     Episode_Reward/pen_ang_vel_xy: -0.1324
   Episode_Reward/pen_joint_torque: -0.2663
    Episode_Reward/pen_joint_accel: -0.0782
    Episode_Reward/pen_action_rate: -0.3193
Episode_Reward/pen_joint_pos_limits: -0.0001
   Episode_Reward/pen_joint_vel_l2: -0.0500
   Episode_Reward/pen_joint_powers: -0.0778
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.2147
Episode_Reward/pen_flat_orientation: -0.1897
  Episode_Reward/pen_feet_distance: -0.0167
Episode_Reward/pen_feet_regulation: -0.3971
   Episode_Reward/foot_landing_vel: -0.1055
   Episode_Reward/test_gait_reward: -0.5232
Metrics/base_velocity/error_vel_xy: 0.9606
Metrics/base_velocity/error_vel_yaw: 1.0367
      Episode_Termination/time_out: 2.5000
  Episode_Termination/base_contact: 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 220495872
                    Iteration time: 1.15s
                        Total time: 2451.12s
                               ETA: 828.3s

################################################################################
                     [1m Learning iteration 2243/3000 [0m                     

                       Computation: 86583 steps/s (collection: 1.010s, learning 0.125s)
               Value function loss: 448547282.8000
                    Surrogate loss: -0.0025
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: -34604.21
               Mean episode length: 460.51
       Episode_Reward/keep_balance: 0.4965
     Episode_Reward/rew_lin_vel_xy: 2.2953
      Episode_Reward/rew_ang_vel_z: 1.0945
    Episode_Reward/pen_base_height: -0.3755
      Episode_Reward/pen_lin_vel_z: -0.0510
     Episode_Reward/pen_ang_vel_xy: -0.1307
   Episode_Reward/pen_joint_torque: -0.3786
    Episode_Reward/pen_joint_accel: -0.0747
    Episode_Reward/pen_action_rate: -1026.1438
Episode_Reward/pen_joint_pos_limits: -0.0001
   Episode_Reward/pen_joint_vel_l2: -0.0481
   Episode_Reward/pen_joint_powers: -0.0751
Episode_Reward/pen_undesired_contacts: -0.0023
Episode_Reward/pen_action_smoothness: -4.6809
Episode_Reward/pen_flat_orientation: -0.2016
  Episode_Reward/pen_feet_distance: -0.0173
Episode_Reward/pen_feet_regulation: -0.3780
   Episode_Reward/foot_landing_vel: -0.1000
   Episode_Reward/test_gait_reward: -0.4847
Metrics/base_velocity/error_vel_xy: 0.9210
Metrics/base_velocity/error_vel_yaw: 1.0213
      Episode_Termination/time_out: 2.0000
  Episode_Termination/base_contact: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 220594176
                    Iteration time: 1.14s
                        Total time: 2452.25s
                               ETA: 827.3s

################################################################################
                     [1m Learning iteration 2244/3000 [0m                     

                       Computation: 85490 steps/s (collection: 1.026s, learning 0.124s)
               Value function loss: 231253.6492
                    Surrogate loss: -0.0020
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: -859.14
               Mean episode length: 481.59
       Episode_Reward/keep_balance: 0.5174
     Episode_Reward/rew_lin_vel_xy: 2.3346
      Episode_Reward/rew_ang_vel_z: 1.1270
    Episode_Reward/pen_base_height: -0.3805
      Episode_Reward/pen_lin_vel_z: -0.0534
     Episode_Reward/pen_ang_vel_xy: -0.1346
   Episode_Reward/pen_joint_torque: -0.3836
    Episode_Reward/pen_joint_accel: -0.0852
    Episode_Reward/pen_action_rate: -21.8393
Episode_Reward/pen_joint_pos_limits: -0.0001
   Episode_Reward/pen_joint_vel_l2: -0.0505
   Episode_Reward/pen_joint_powers: -0.0769
Episode_Reward/pen_undesired_contacts: -0.0026
Episode_Reward/pen_action_smoothness: -0.3095
Episode_Reward/pen_flat_orientation: -0.2103
  Episode_Reward/pen_feet_distance: -0.0194
Episode_Reward/pen_feet_regulation: -0.3979
   Episode_Reward/foot_landing_vel: -0.1066
   Episode_Reward/test_gait_reward: -0.5054
Metrics/base_velocity/error_vel_xy: 0.9824
Metrics/base_velocity/error_vel_yaw: 1.0712
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 220692480
                    Iteration time: 1.15s
                        Total time: 2453.40s
                               ETA: 826.2s

################################################################################
                     [1m Learning iteration 2245/3000 [0m                     

                       Computation: 86410 steps/s (collection: 1.014s, learning 0.123s)
               Value function loss: 7916.6072
                    Surrogate loss: -0.0002
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: -11.23
               Mean episode length: 495.05
       Episode_Reward/keep_balance: 0.4754
     Episode_Reward/rew_lin_vel_xy: 2.0488
      Episode_Reward/rew_ang_vel_z: 1.0429
    Episode_Reward/pen_base_height: -0.3389
      Episode_Reward/pen_lin_vel_z: -0.0492
     Episode_Reward/pen_ang_vel_xy: -0.1252
   Episode_Reward/pen_joint_torque: -0.2964
    Episode_Reward/pen_joint_accel: -0.0699
    Episode_Reward/pen_action_rate: -1.4348
Episode_Reward/pen_joint_pos_limits: -0.0001
   Episode_Reward/pen_joint_vel_l2: -0.0467
   Episode_Reward/pen_joint_powers: -0.0712
Episode_Reward/pen_undesired_contacts: -0.0022
Episode_Reward/pen_action_smoothness: -0.1956
Episode_Reward/pen_flat_orientation: -0.1759
  Episode_Reward/pen_feet_distance: -0.0153
Episode_Reward/pen_feet_regulation: -0.3731
   Episode_Reward/foot_landing_vel: -0.1033
   Episode_Reward/test_gait_reward: -0.4672
Metrics/base_velocity/error_vel_xy: 0.9659
Metrics/base_velocity/error_vel_yaw: 0.9561
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 220790784
                    Iteration time: 1.14s
                        Total time: 2454.54s
                               ETA: 825.1s

################################################################################
                     [1m Learning iteration 2246/3000 [0m                     

                       Computation: 85028 steps/s (collection: 1.032s, learning 0.124s)
               Value function loss: 59545.3158
                    Surrogate loss: 0.0001
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: -525.65
               Mean episode length: 497.20
       Episode_Reward/keep_balance: 0.5323
     Episode_Reward/rew_lin_vel_xy: 2.3708
      Episode_Reward/rew_ang_vel_z: 1.1773
    Episode_Reward/pen_base_height: -0.3567
      Episode_Reward/pen_lin_vel_z: -0.0517
     Episode_Reward/pen_ang_vel_xy: -0.1325
   Episode_Reward/pen_joint_torque: -0.2893
    Episode_Reward/pen_joint_accel: -0.0809
    Episode_Reward/pen_action_rate: -16.4618
Episode_Reward/pen_joint_pos_limits: -0.0001
   Episode_Reward/pen_joint_vel_l2: -0.0504
   Episode_Reward/pen_joint_powers: -0.0747
Episode_Reward/pen_undesired_contacts: -0.0022
Episode_Reward/pen_action_smoothness: -0.2742
Episode_Reward/pen_flat_orientation: -0.1795
  Episode_Reward/pen_feet_distance: -0.0209
Episode_Reward/pen_feet_regulation: -0.4179
   Episode_Reward/foot_landing_vel: -0.1078
   Episode_Reward/test_gait_reward: -0.5268
Metrics/base_velocity/error_vel_xy: 1.0225
Metrics/base_velocity/error_vel_yaw: 1.0237
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 220889088
                    Iteration time: 1.16s
                        Total time: 2455.70s
                               ETA: 824.0s

################################################################################
                     [1m Learning iteration 2247/3000 [0m                     

                       Computation: 86027 steps/s (collection: 1.020s, learning 0.123s)
               Value function loss: 4223.0592
                    Surrogate loss: -0.0013
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: -81.24
               Mean episode length: 560.93
       Episode_Reward/keep_balance: 0.5605
     Episode_Reward/rew_lin_vel_xy: 2.5324
      Episode_Reward/rew_ang_vel_z: 1.2326
    Episode_Reward/pen_base_height: -0.3570
      Episode_Reward/pen_lin_vel_z: -0.0517
     Episode_Reward/pen_ang_vel_xy: -0.1390
   Episode_Reward/pen_joint_torque: -0.2814
    Episode_Reward/pen_joint_accel: -0.0873
    Episode_Reward/pen_action_rate: -7.9054
Episode_Reward/pen_joint_pos_limits: -0.0001
   Episode_Reward/pen_joint_vel_l2: -0.0531
   Episode_Reward/pen_joint_powers: -0.0794
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.2489
Episode_Reward/pen_flat_orientation: -0.1777
  Episode_Reward/pen_feet_distance: -0.0188
Episode_Reward/pen_feet_regulation: -0.4195
   Episode_Reward/foot_landing_vel: -0.1148
   Episode_Reward/test_gait_reward: -0.5447
Metrics/base_velocity/error_vel_xy: 1.0241
Metrics/base_velocity/error_vel_yaw: 1.0946
      Episode_Termination/time_out: 1.3750
  Episode_Termination/base_contact: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 220987392
                    Iteration time: 1.14s
                        Total time: 2456.84s
                               ETA: 823.0s

################################################################################
                     [1m Learning iteration 2248/3000 [0m                     

                       Computation: 86328 steps/s (collection: 1.017s, learning 0.122s)
               Value function loss: 17219.2807
                    Surrogate loss: -0.0022
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 15.10
               Mean episode length: 592.20
       Episode_Reward/keep_balance: 0.5608
     Episode_Reward/rew_lin_vel_xy: 2.4124
      Episode_Reward/rew_ang_vel_z: 1.2387
    Episode_Reward/pen_base_height: -0.3718
      Episode_Reward/pen_lin_vel_z: -0.0552
     Episode_Reward/pen_ang_vel_xy: -0.1404
   Episode_Reward/pen_joint_torque: -0.3162
    Episode_Reward/pen_joint_accel: -0.0829
    Episode_Reward/pen_action_rate: -0.9116
Episode_Reward/pen_joint_pos_limits: -0.0001
   Episode_Reward/pen_joint_vel_l2: -0.0538
   Episode_Reward/pen_joint_powers: -0.0800
Episode_Reward/pen_undesired_contacts: -0.0020
Episode_Reward/pen_action_smoothness: -0.2255
Episode_Reward/pen_flat_orientation: -0.1913
  Episode_Reward/pen_feet_distance: -0.0217
Episode_Reward/pen_feet_regulation: -0.4388
   Episode_Reward/foot_landing_vel: -0.1212
   Episode_Reward/test_gait_reward: -0.5533
Metrics/base_velocity/error_vel_xy: 1.1130
Metrics/base_velocity/error_vel_yaw: 1.0859
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 221085696
                    Iteration time: 1.14s
                        Total time: 2457.98s
                               ETA: 821.9s

################################################################################
                     [1m Learning iteration 2249/3000 [0m                     

                       Computation: 87160 steps/s (collection: 1.005s, learning 0.123s)
               Value function loss: 8535377.8000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 21.04
               Mean episode length: 585.82
       Episode_Reward/keep_balance: 0.5879
     Episode_Reward/rew_lin_vel_xy: 2.6118
      Episode_Reward/rew_ang_vel_z: 1.2839
    Episode_Reward/pen_base_height: -0.3701
      Episode_Reward/pen_lin_vel_z: -0.0527
     Episode_Reward/pen_ang_vel_xy: -0.1418
   Episode_Reward/pen_joint_torque: -0.3639
    Episode_Reward/pen_joint_accel: -0.0899
    Episode_Reward/pen_action_rate: -0.9292
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0552
   Episode_Reward/pen_joint_powers: -0.0831
Episode_Reward/pen_undesired_contacts: -0.0022
Episode_Reward/pen_action_smoothness: -0.2314
Episode_Reward/pen_flat_orientation: -0.1794
  Episode_Reward/pen_feet_distance: -0.0225
Episode_Reward/pen_feet_regulation: -0.4502
   Episode_Reward/foot_landing_vel: -0.1194
   Episode_Reward/test_gait_reward: -0.5817
Metrics/base_velocity/error_vel_xy: 1.1011
Metrics/base_velocity/error_vel_yaw: 1.1495
      Episode_Termination/time_out: 2.0833
  Episode_Termination/base_contact: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 221184000
                    Iteration time: 1.13s
                        Total time: 2459.11s
                               ETA: 820.8s

################################################################################
                     [1m Learning iteration 2250/3000 [0m                     

                       Computation: 87783 steps/s (collection: 0.997s, learning 0.123s)
               Value function loss: 4994383948.8000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 35.90
               Mean episode length: 631.94
       Episode_Reward/keep_balance: 0.6489
     Episode_Reward/rew_lin_vel_xy: 2.8150
      Episode_Reward/rew_ang_vel_z: 1.4202
    Episode_Reward/pen_base_height: -0.3878
      Episode_Reward/pen_lin_vel_z: -0.0509
     Episode_Reward/pen_ang_vel_xy: -0.1533
   Episode_Reward/pen_joint_torque: -0.3168
    Episode_Reward/pen_joint_accel: -0.0902
    Episode_Reward/pen_action_rate: -0.3238
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0580
   Episode_Reward/pen_joint_powers: -0.0881
Episode_Reward/pen_undesired_contacts: -0.0013
Episode_Reward/pen_action_smoothness: -0.2506
Episode_Reward/pen_flat_orientation: -0.1674
  Episode_Reward/pen_feet_distance: -0.0237
Episode_Reward/pen_feet_regulation: -0.4972
   Episode_Reward/foot_landing_vel: -0.1229
   Episode_Reward/test_gait_reward: -0.6442
Metrics/base_velocity/error_vel_xy: 1.2158
Metrics/base_velocity/error_vel_yaw: 1.2327
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 221282304
                    Iteration time: 1.12s
                        Total time: 2460.23s
                               ETA: 819.7s

################################################################################
                     [1m Learning iteration 2251/3000 [0m                     

                       Computation: 83593 steps/s (collection: 1.046s, learning 0.130s)
               Value function loss: 442897719296.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 41.09
               Mean episode length: 672.40
       Episode_Reward/keep_balance: 0.6520
     Episode_Reward/rew_lin_vel_xy: 2.8643
      Episode_Reward/rew_ang_vel_z: 1.4280
    Episode_Reward/pen_base_height: -0.3776
      Episode_Reward/pen_lin_vel_z: -0.0551
     Episode_Reward/pen_ang_vel_xy: -0.1442
   Episode_Reward/pen_joint_torque: -0.2477
    Episode_Reward/pen_joint_accel: -0.0935
    Episode_Reward/pen_action_rate: -0.1587
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0583
   Episode_Reward/pen_joint_powers: -0.0871
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2469
Episode_Reward/pen_flat_orientation: -0.1674
  Episode_Reward/pen_feet_distance: -0.0199
Episode_Reward/pen_feet_regulation: -0.4937
   Episode_Reward/foot_landing_vel: -0.1309
   Episode_Reward/test_gait_reward: -0.6404
Metrics/base_velocity/error_vel_xy: 1.1957
Metrics/base_velocity/error_vel_yaw: 1.2373
      Episode_Termination/time_out: 1.8750
  Episode_Termination/base_contact: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 221380608
                    Iteration time: 1.18s
                        Total time: 2461.40s
                               ETA: 818.6s

################################################################################
                     [1m Learning iteration 2252/3000 [0m                     

                       Computation: 86804 steps/s (collection: 1.010s, learning 0.123s)
               Value function loss: 71634357164441.5938
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 22.40
               Mean episode length: 648.15
       Episode_Reward/keep_balance: 0.6122
     Episode_Reward/rew_lin_vel_xy: 2.4871
      Episode_Reward/rew_ang_vel_z: 1.3206
    Episode_Reward/pen_base_height: -0.3838
      Episode_Reward/pen_lin_vel_z: -0.0531
     Episode_Reward/pen_ang_vel_xy: -0.1529
   Episode_Reward/pen_joint_torque: -0.3786
    Episode_Reward/pen_joint_accel: -0.0881
    Episode_Reward/pen_action_rate: -0.9054
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0596
   Episode_Reward/pen_joint_powers: -0.0876
Episode_Reward/pen_undesired_contacts: -0.0023
Episode_Reward/pen_action_smoothness: -0.2472
Episode_Reward/pen_flat_orientation: -0.1897
  Episode_Reward/pen_feet_distance: -0.0197
Episode_Reward/pen_feet_regulation: -0.4679
   Episode_Reward/foot_landing_vel: -0.1215
   Episode_Reward/test_gait_reward: -0.5991
Metrics/base_velocity/error_vel_xy: 1.2208
Metrics/base_velocity/error_vel_yaw: 1.2248
      Episode_Termination/time_out: 1.1667
  Episode_Termination/base_contact: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 221478912
                    Iteration time: 1.13s
                        Total time: 2462.53s
                               ETA: 817.6s

################################################################################
                     [1m Learning iteration 2253/3000 [0m                     

                       Computation: 87726 steps/s (collection: 0.998s, learning 0.122s)
               Value function loss: 5480291833479168.0000
                    Surrogate loss: -0.0031
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: 42.73
               Mean episode length: 725.22
       Episode_Reward/keep_balance: 0.7463
     Episode_Reward/rew_lin_vel_xy: 3.2920
      Episode_Reward/rew_ang_vel_z: 1.6362
    Episode_Reward/pen_base_height: -0.3854
      Episode_Reward/pen_lin_vel_z: -0.0560
     Episode_Reward/pen_ang_vel_xy: -0.1704
   Episode_Reward/pen_joint_torque: -0.2884
    Episode_Reward/pen_joint_accel: -0.1191
    Episode_Reward/pen_action_rate: -0.1781
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0676
   Episode_Reward/pen_joint_powers: -0.0977
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.2809
Episode_Reward/pen_flat_orientation: -0.1769
  Episode_Reward/pen_feet_distance: -0.0216
Episode_Reward/pen_feet_regulation: -0.5442
   Episode_Reward/foot_landing_vel: -0.1454
   Episode_Reward/test_gait_reward: -0.7358
Metrics/base_velocity/error_vel_xy: 1.3274
Metrics/base_velocity/error_vel_yaw: 1.3955
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 221577216
                    Iteration time: 1.12s
                        Total time: 2463.65s
                               ETA: 816.5s

################################################################################
                     [1m Learning iteration 2254/3000 [0m                     

                       Computation: 88210 steps/s (collection: 0.991s, learning 0.123s)
               Value function loss: 552785080091672576.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8356
                     Learning rate: 0.0000
                       Mean reward: -7784472.00
               Mean episode length: 792.35
       Episode_Reward/keep_balance: 0.8158
     Episode_Reward/rew_lin_vel_xy: 3.6376
      Episode_Reward/rew_ang_vel_z: 1.8427
    Episode_Reward/pen_base_height: -0.4114
      Episode_Reward/pen_lin_vel_z: -0.0572
     Episode_Reward/pen_ang_vel_xy: -0.1756
   Episode_Reward/pen_joint_torque: -0.3379
    Episode_Reward/pen_joint_accel: -0.1227
    Episode_Reward/pen_action_rate: -179791.9688
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0695
   Episode_Reward/pen_joint_powers: -0.1049
Episode_Reward/pen_undesired_contacts: -0.0011
Episode_Reward/pen_action_smoothness: -405.8242
Episode_Reward/pen_flat_orientation: -0.1685
  Episode_Reward/pen_feet_distance: -0.0236
Episode_Reward/pen_feet_regulation: -0.5857
   Episode_Reward/foot_landing_vel: -0.1593
   Episode_Reward/test_gait_reward: -0.8022
Metrics/base_velocity/error_vel_xy: 1.4464
Metrics/base_velocity/error_vel_yaw: 1.4549
      Episode_Termination/time_out: 3.7500
  Episode_Termination/base_contact: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 221675520
                    Iteration time: 1.11s
                        Total time: 2464.77s
                               ETA: 815.4s

################################################################################
                     [1m Learning iteration 2255/3000 [0m                     

                       Computation: 85114 steps/s (collection: 1.029s, learning 0.126s)
               Value function loss: 58204763476694401024.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8357
                     Learning rate: 0.0000
                       Mean reward: -11.04
               Mean episode length: 808.16
       Episode_Reward/keep_balance: 0.7960
     Episode_Reward/rew_lin_vel_xy: 3.5211
      Episode_Reward/rew_ang_vel_z: 1.7700
    Episode_Reward/pen_base_height: -0.4115
      Episode_Reward/pen_lin_vel_z: -0.0586
     Episode_Reward/pen_ang_vel_xy: -0.1721
   Episode_Reward/pen_joint_torque: -0.3562
    Episode_Reward/pen_joint_accel: -0.1182
    Episode_Reward/pen_action_rate: -2.4429
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0701
   Episode_Reward/pen_joint_powers: -0.1026
Episode_Reward/pen_undesired_contacts: -0.0010
Episode_Reward/pen_action_smoothness: -0.3074
Episode_Reward/pen_flat_orientation: -0.1794
  Episode_Reward/pen_feet_distance: -0.0205
Episode_Reward/pen_feet_regulation: -0.5840
   Episode_Reward/foot_landing_vel: -0.1571
   Episode_Reward/test_gait_reward: -0.7762
Metrics/base_velocity/error_vel_xy: 1.4211
Metrics/base_velocity/error_vel_yaw: 1.4605
      Episode_Termination/time_out: 3.0417
  Episode_Termination/base_contact: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 221773824
                    Iteration time: 1.15s
                        Total time: 2465.92s
                               ETA: 814.3s

################################################################################
                     [1m Learning iteration 2256/3000 [0m                     

                       Computation: 88386 steps/s (collection: 0.990s, learning 0.122s)
               Value function loss: 5837815012720770023424.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8357
                     Learning rate: 0.0000
                       Mean reward: 37.14
               Mean episode length: 720.51
       Episode_Reward/keep_balance: 0.7122
     Episode_Reward/rew_lin_vel_xy: 2.9680
      Episode_Reward/rew_ang_vel_z: 1.5409
    Episode_Reward/pen_base_height: -0.4060
      Episode_Reward/pen_lin_vel_z: -0.0564
     Episode_Reward/pen_ang_vel_xy: -0.1649
   Episode_Reward/pen_joint_torque: -0.3854
    Episode_Reward/pen_joint_accel: -0.1219
    Episode_Reward/pen_action_rate: -0.3489
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0667
   Episode_Reward/pen_joint_powers: -0.0965
Episode_Reward/pen_undesired_contacts: -0.0017
Episode_Reward/pen_action_smoothness: -0.2709
Episode_Reward/pen_flat_orientation: -0.1790
  Episode_Reward/pen_feet_distance: -0.0209
Episode_Reward/pen_feet_regulation: -0.5529
   Episode_Reward/foot_landing_vel: -0.1548
   Episode_Reward/test_gait_reward: -0.7011
Metrics/base_velocity/error_vel_xy: 1.3810
Metrics/base_velocity/error_vel_yaw: 1.3916
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 221872128
                    Iteration time: 1.11s
                        Total time: 2467.04s
                               ETA: 813.2s

################################################################################
                     [1m Learning iteration 2257/3000 [0m                     

                       Computation: 91399 steps/s (collection: 0.954s, learning 0.122s)
               Value function loss: 588706093733439395069952.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8357
                     Learning rate: 0.0000
                       Mean reward: 46.77
               Mean episode length: 760.48
       Episode_Reward/keep_balance: 0.7574
     Episode_Reward/rew_lin_vel_xy: 3.2826
      Episode_Reward/rew_ang_vel_z: 1.6522
    Episode_Reward/pen_base_height: -0.4047
      Episode_Reward/pen_lin_vel_z: -0.0565
     Episode_Reward/pen_ang_vel_xy: -0.1696
   Episode_Reward/pen_joint_torque: -0.2910
    Episode_Reward/pen_joint_accel: -0.1095
    Episode_Reward/pen_action_rate: -0.1742
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0663
   Episode_Reward/pen_joint_powers: -0.0991
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.2862
Episode_Reward/pen_flat_orientation: -0.1713
  Episode_Reward/pen_feet_distance: -0.0201
Episode_Reward/pen_feet_regulation: -0.5458
   Episode_Reward/foot_landing_vel: -0.1514
   Episode_Reward/test_gait_reward: -0.7363
Metrics/base_velocity/error_vel_xy: 1.3753
Metrics/base_velocity/error_vel_yaw: 1.4270
      Episode_Termination/time_out: 2.3750
  Episode_Termination/base_contact: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 221970432
                    Iteration time: 1.08s
                        Total time: 2468.11s
                               ETA: 812.1s

################################################################################
                     [1m Learning iteration 2258/3000 [0m                     

                       Computation: 87793 steps/s (collection: 0.996s, learning 0.124s)
               Value function loss: 60876008575681427222298624.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8357
                     Learning rate: 0.0000
                       Mean reward: 54.42
               Mean episode length: 830.68
       Episode_Reward/keep_balance: 0.8576
     Episode_Reward/rew_lin_vel_xy: 3.7829
      Episode_Reward/rew_ang_vel_z: 1.9218
    Episode_Reward/pen_base_height: -0.4256
      Episode_Reward/pen_lin_vel_z: -0.0597
     Episode_Reward/pen_ang_vel_xy: -0.1844
   Episode_Reward/pen_joint_torque: -0.3337
    Episode_Reward/pen_joint_accel: -0.1225
    Episode_Reward/pen_action_rate: -0.2069
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0728
   Episode_Reward/pen_joint_powers: -0.1075
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3176
Episode_Reward/pen_flat_orientation: -0.1687
  Episode_Reward/pen_feet_distance: -0.0265
Episode_Reward/pen_feet_regulation: -0.6022
   Episode_Reward/foot_landing_vel: -0.1687
   Episode_Reward/test_gait_reward: -0.8403
Metrics/base_velocity/error_vel_xy: 1.5439
Metrics/base_velocity/error_vel_yaw: 1.5392
      Episode_Termination/time_out: 1.9167
  Episode_Termination/base_contact: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 222068736
                    Iteration time: 1.12s
                        Total time: 2469.23s
                               ETA: 811.1s

################################################################################
                     [1m Learning iteration 2259/3000 [0m                     

                       Computation: 88023 steps/s (collection: 0.993s, learning 0.124s)
               Value function loss: 6298486106465812418402451456.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8357
                     Learning rate: 0.0000
                       Mean reward: 52.06
               Mean episode length: 816.26
       Episode_Reward/keep_balance: 0.8285
     Episode_Reward/rew_lin_vel_xy: 3.5803
      Episode_Reward/rew_ang_vel_z: 1.8275
    Episode_Reward/pen_base_height: -0.4159
      Episode_Reward/pen_lin_vel_z: -0.0579
     Episode_Reward/pen_ang_vel_xy: -0.1770
   Episode_Reward/pen_joint_torque: -0.3052
    Episode_Reward/pen_joint_accel: -0.1351
    Episode_Reward/pen_action_rate: -0.1836
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0732
   Episode_Reward/pen_joint_powers: -0.1076
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.3185
Episode_Reward/pen_flat_orientation: -0.1731
  Episode_Reward/pen_feet_distance: -0.0246
Episode_Reward/pen_feet_regulation: -0.6246
   Episode_Reward/foot_landing_vel: -0.1650
   Episode_Reward/test_gait_reward: -0.8150
Metrics/base_velocity/error_vel_xy: 1.4870
Metrics/base_velocity/error_vel_yaw: 1.5219
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 222167040
                    Iteration time: 1.12s
                        Total time: 2470.35s
                               ETA: 810.0s

################################################################################
                     [1m Learning iteration 2260/3000 [0m                     

                       Computation: 88682 steps/s (collection: 0.986s, learning 0.122s)
               Value function loss: 659482644459983845119724879872.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8357
                     Learning rate: 0.0000
                       Mean reward: 54.18
               Mean episode length: 832.86
       Episode_Reward/keep_balance: 0.8519
     Episode_Reward/rew_lin_vel_xy: 3.9101
      Episode_Reward/rew_ang_vel_z: 1.9520
    Episode_Reward/pen_base_height: -0.4237
      Episode_Reward/pen_lin_vel_z: -0.0562
     Episode_Reward/pen_ang_vel_xy: -0.1748
   Episode_Reward/pen_joint_torque: -0.3477
    Episode_Reward/pen_joint_accel: -0.1223
    Episode_Reward/pen_action_rate: -0.2648
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0700
   Episode_Reward/pen_joint_powers: -0.1042
Episode_Reward/pen_undesired_contacts: -0.0012
Episode_Reward/pen_action_smoothness: -0.3136
Episode_Reward/pen_flat_orientation: -0.1607
  Episode_Reward/pen_feet_distance: -0.0213
Episode_Reward/pen_feet_regulation: -0.6012
   Episode_Reward/foot_landing_vel: -0.1686
   Episode_Reward/test_gait_reward: -0.8320
Metrics/base_velocity/error_vel_xy: 1.4258
Metrics/base_velocity/error_vel_yaw: 1.4581
      Episode_Termination/time_out: 1.7500
  Episode_Termination/base_contact: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 222265344
                    Iteration time: 1.11s
                        Total time: 2471.46s
                               ETA: 808.9s

################################################################################
                     [1m Learning iteration 2261/3000 [0m                     

                       Computation: 88352 steps/s (collection: 0.991s, learning 0.122s)
               Value function loss: 67886776657740055626999385817088.0000
                    Surrogate loss: -0.0030
             Mean action noise std: 0.8357
                     Learning rate: 0.0000
                       Mean reward: 4.17
               Mean episode length: 804.17
       Episode_Reward/keep_balance: 0.7911
     Episode_Reward/rew_lin_vel_xy: 3.2467
      Episode_Reward/rew_ang_vel_z: 1.6972
    Episode_Reward/pen_base_height: -0.4438
      Episode_Reward/pen_lin_vel_z: -0.0611
     Episode_Reward/pen_ang_vel_xy: -0.1831
   Episode_Reward/pen_joint_torque: -0.4592
    Episode_Reward/pen_joint_accel: -0.1269
    Episode_Reward/pen_action_rate: -2.3230
Episode_Reward/pen_joint_pos_limits: -0.0001
   Episode_Reward/pen_joint_vel_l2: -0.0721
   Episode_Reward/pen_joint_powers: -0.1057
Episode_Reward/pen_undesired_contacts: -0.0015
Episode_Reward/pen_action_smoothness: -0.3090
Episode_Reward/pen_flat_orientation: -0.1929
  Episode_Reward/pen_feet_distance: -0.0242
Episode_Reward/pen_feet_regulation: -0.6092
   Episode_Reward/foot_landing_vel: -0.1631
   Episode_Reward/test_gait_reward: -0.7773
Metrics/base_velocity/error_vel_xy: 1.5090
Metrics/base_velocity/error_vel_yaw: 1.5409
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 222363648
                    Iteration time: 1.11s
                        Total time: 2472.57s
                               ETA: 807.8s

################################################################################
                     [1m Learning iteration 2262/3000 [0m                     

                       Computation: 90748 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: 6403518128467301719611404030312448.0000
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8357
                     Learning rate: 0.0000
                       Mean reward: -5.30
               Mean episode length: 775.40
       Episode_Reward/keep_balance: 0.7972
     Episode_Reward/rew_lin_vel_xy: 3.3429
      Episode_Reward/rew_ang_vel_z: 1.7174
    Episode_Reward/pen_base_height: -0.4541
      Episode_Reward/pen_lin_vel_z: -0.0617
     Episode_Reward/pen_ang_vel_xy: -0.1831
   Episode_Reward/pen_joint_torque: -0.4739
    Episode_Reward/pen_joint_accel: -0.1253
    Episode_Reward/pen_action_rate: -0.6309
Episode_Reward/pen_joint_pos_limits: -0.0001
   Episode_Reward/pen_joint_vel_l2: -0.0710
   Episode_Reward/pen_joint_powers: -0.1041
Episode_Reward/pen_undesired_contacts: -0.0016
Episode_Reward/pen_action_smoothness: -0.3154
Episode_Reward/pen_flat_orientation: -0.2118
  Episode_Reward/pen_feet_distance: -0.0253
Episode_Reward/pen_feet_regulation: -0.5677
   Episode_Reward/foot_landing_vel: -0.1622
   Episode_Reward/test_gait_reward: -0.7771
Metrics/base_velocity/error_vel_xy: 1.5051
Metrics/base_velocity/error_vel_yaw: 1.5558
      Episode_Termination/time_out: 1.5417
  Episode_Termination/base_contact: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 222461952
                    Iteration time: 1.08s
                        Total time: 2473.65s
                               ETA: 806.7s

################################################################################
                     [1m Learning iteration 2263/3000 [0m                     

                       Computation: 89029 steps/s (collection: 0.981s, learning 0.123s)
               Value function loss: inf
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8357
                     Learning rate: 0.0000
                       Mean reward: 42.48
               Mean episode length: 809.55
       Episode_Reward/keep_balance: 0.8288
     Episode_Reward/rew_lin_vel_xy: 3.5662
      Episode_Reward/rew_ang_vel_z: 1.8115
    Episode_Reward/pen_base_height: -0.4065
      Episode_Reward/pen_lin_vel_z: -0.0593
     Episode_Reward/pen_ang_vel_xy: -0.1714
   Episode_Reward/pen_joint_torque: -0.3380
    Episode_Reward/pen_joint_accel: -0.1244
    Episode_Reward/pen_action_rate: -0.2882
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0743
   Episode_Reward/pen_joint_powers: -0.1089
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.3186
Episode_Reward/pen_flat_orientation: -0.1707
  Episode_Reward/pen_feet_distance: -0.0296
Episode_Reward/pen_feet_regulation: -0.6266
   Episode_Reward/foot_landing_vel: -0.1765
   Episode_Reward/test_gait_reward: -0.8179
Metrics/base_velocity/error_vel_xy: 1.5156
Metrics/base_velocity/error_vel_yaw: 1.5628
      Episode_Termination/time_out: 1.7917
  Episode_Termination/base_contact: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 222560256
                    Iteration time: 1.10s
                        Total time: 2474.76s
                               ETA: 805.6s

################################################################################
                     [1m Learning iteration 2264/3000 [0m                     

                       Computation: 90760 steps/s (collection: 0.961s, learning 0.122s)
               Value function loss: inf
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8357
                     Learning rate: 0.0000
                       Mean reward: 52.61
               Mean episode length: 841.23
       Episode_Reward/keep_balance: 0.8689
     Episode_Reward/rew_lin_vel_xy: 3.6069
      Episode_Reward/rew_ang_vel_z: 1.9157
    Episode_Reward/pen_base_height: -0.4295
      Episode_Reward/pen_lin_vel_z: -0.0622
     Episode_Reward/pen_ang_vel_xy: -0.1989
   Episode_Reward/pen_joint_torque: -0.3309
    Episode_Reward/pen_joint_accel: -0.1318
    Episode_Reward/pen_action_rate: -0.1835
Episode_Reward/pen_joint_pos_limits: -0.0001
   Episode_Reward/pen_joint_vel_l2: -0.0753
   Episode_Reward/pen_joint_powers: -0.1104
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.3305
Episode_Reward/pen_flat_orientation: -0.1724
  Episode_Reward/pen_feet_distance: -0.0226
Episode_Reward/pen_feet_regulation: -0.6213
   Episode_Reward/foot_landing_vel: -0.1688
   Episode_Reward/test_gait_reward: -0.8515
Metrics/base_velocity/error_vel_xy: 1.6288
Metrics/base_velocity/error_vel_yaw: 1.5908
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 222658560
                    Iteration time: 1.08s
                        Total time: 2475.84s
                               ETA: 804.5s

################################################################################
                     [1m Learning iteration 2265/3000 [0m                     

                       Computation: 88441 steps/s (collection: 0.988s, learning 0.124s)
               Value function loss: inf
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8357
                     Learning rate: 0.0000
                       Mean reward: 53.14
               Mean episode length: 827.25
       Episode_Reward/keep_balance: 0.8065
     Episode_Reward/rew_lin_vel_xy: 3.4468
      Episode_Reward/rew_ang_vel_z: 1.7994
    Episode_Reward/pen_base_height: -0.4137
      Episode_Reward/pen_lin_vel_z: -0.0550
     Episode_Reward/pen_ang_vel_xy: -0.1752
   Episode_Reward/pen_joint_torque: -0.2706
    Episode_Reward/pen_joint_accel: -0.1046
    Episode_Reward/pen_action_rate: -0.1601
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0692
   Episode_Reward/pen_joint_powers: -0.1033
Episode_Reward/pen_undesired_contacts: -0.0006
Episode_Reward/pen_action_smoothness: -0.3280
Episode_Reward/pen_flat_orientation: -0.1649
  Episode_Reward/pen_feet_distance: -0.0230
Episode_Reward/pen_feet_regulation: -0.5633
   Episode_Reward/foot_landing_vel: -0.1541
   Episode_Reward/test_gait_reward: -0.7824
Metrics/base_velocity/error_vel_xy: 1.4330
Metrics/base_velocity/error_vel_yaw: 1.4767
      Episode_Termination/time_out: 1.6667
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 222756864
                    Iteration time: 1.11s
                        Total time: 2476.95s
                               ETA: 803.4s

################################################################################
                     [1m Learning iteration 2266/3000 [0m                     

                       Computation: 90534 steps/s (collection: 0.962s, learning 0.124s)
               Value function loss: inf
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8357
                     Learning rate: 0.0000
                       Mean reward: 52.33
               Mean episode length: 811.62
       Episode_Reward/keep_balance: 0.8576
     Episode_Reward/rew_lin_vel_xy: 3.6888
      Episode_Reward/rew_ang_vel_z: 1.9149
    Episode_Reward/pen_base_height: -0.3945
      Episode_Reward/pen_lin_vel_z: -0.0568
     Episode_Reward/pen_ang_vel_xy: -0.1890
   Episode_Reward/pen_joint_torque: -0.3084
    Episode_Reward/pen_joint_accel: -0.1370
    Episode_Reward/pen_action_rate: -0.1712
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0728
   Episode_Reward/pen_joint_powers: -0.1072
Episode_Reward/pen_undesired_contacts: -0.0007
Episode_Reward/pen_action_smoothness: -0.3295
Episode_Reward/pen_flat_orientation: -0.1676
  Episode_Reward/pen_feet_distance: -0.0204
Episode_Reward/pen_feet_regulation: -0.6026
   Episode_Reward/foot_landing_vel: -0.1656
   Episode_Reward/test_gait_reward: -0.8366
Metrics/base_velocity/error_vel_xy: 1.5316
Metrics/base_velocity/error_vel_yaw: 1.5831
      Episode_Termination/time_out: 1.9583
  Episode_Termination/base_contact: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 222855168
                    Iteration time: 1.09s
                        Total time: 2478.04s
                               ETA: 802.3s

################################################################################
                     [1m Learning iteration 2267/3000 [0m                     

                       Computation: 89818 steps/s (collection: 0.972s, learning 0.123s)
               Value function loss: inf
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8357
                     Learning rate: 0.0000
                       Mean reward: 50.06
               Mean episode length: 837.30
       Episode_Reward/keep_balance: 0.8551
     Episode_Reward/rew_lin_vel_xy: 3.4595
      Episode_Reward/rew_ang_vel_z: 1.8642
    Episode_Reward/pen_base_height: -0.4258
      Episode_Reward/pen_lin_vel_z: -0.0608
     Episode_Reward/pen_ang_vel_xy: -0.1941
   Episode_Reward/pen_joint_torque: -0.3132
    Episode_Reward/pen_joint_accel: -0.1337
    Episode_Reward/pen_action_rate: -0.1844
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0770
   Episode_Reward/pen_joint_powers: -0.1121
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3396
Episode_Reward/pen_flat_orientation: -0.1850
  Episode_Reward/pen_feet_distance: -0.0214
Episode_Reward/pen_feet_regulation: -0.6417
   Episode_Reward/foot_landing_vel: -0.1695
   Episode_Reward/test_gait_reward: -0.8400
Metrics/base_velocity/error_vel_xy: 1.6278
Metrics/base_velocity/error_vel_yaw: 1.5913
      Episode_Termination/time_out: 2.1250
  Episode_Termination/base_contact: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 222953472
                    Iteration time: 1.09s
                        Total time: 2479.13s
                               ETA: 801.2s

################################################################################
                     [1m Learning iteration 2268/3000 [0m                     

                       Computation: 88539 steps/s (collection: 0.984s, learning 0.126s)
               Value function loss: inf
                    Surrogate loss: 0.0000
             Mean action noise std: 0.8357
                     Learning rate: 0.0000
                       Mean reward: 53.26
               Mean episode length: 869.00
       Episode_Reward/keep_balance: 0.8563
     Episode_Reward/rew_lin_vel_xy: 3.6961
      Episode_Reward/rew_ang_vel_z: 1.9246
    Episode_Reward/pen_base_height: -0.4164
      Episode_Reward/pen_lin_vel_z: -0.0552
     Episode_Reward/pen_ang_vel_xy: -0.1848
   Episode_Reward/pen_joint_torque: -0.3146
    Episode_Reward/pen_joint_accel: -0.1304
    Episode_Reward/pen_action_rate: -0.2110
Episode_Reward/pen_joint_pos_limits: -0.0000
   Episode_Reward/pen_joint_vel_l2: -0.0726
   Episode_Reward/pen_joint_powers: -0.1105
Episode_Reward/pen_undesired_contacts: -0.0008
Episode_Reward/pen_action_smoothness: -0.3411
Episode_Reward/pen_flat_orientation: -0.1673
  Episode_Reward/pen_feet_distance: -0.0219
Episode_Reward/pen_feet_regulation: -0.5897
   Episode_Reward/foot_landing_vel: -0.1578
   Episode_Reward/test_gait_reward: -0.8391
Metrics/base_velocity/error_vel_xy: 1.5160
Metrics/base_velocity/error_vel_yaw: 1.5608
      Episode_Termination/time_out: 2.0417
  Episode_Termination/base_contact: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 223051776
                    Iteration time: 1.11s
                        Total time: 2480.24s
                               ETA: 800.1s

Traceback (most recent call last):
  File "/personal/limxtron1lab-main/scripts/rsl_rl/train.py", line 154, in <module>
    main()
  File "/personal/limxtron1lab-main/scripts/rsl_rl/train.py", line 146, in main
    runner.learn(num_learning_iterations=agent_cfg.max_iterations, init_at_random_ep_len=True)
  File "/personal/limxtron1lab-main/rsl_rl/rsl_rl/runner/on_policy_runner.py", line 269, in learn
    ) = self.alg.update()
  File "/personal/limxtron1lab-main/rsl_rl/rsl_rl/algorithm/ppo.py", line 241, in update
    self.actor_critic.act(
  File "/personal/limxtron1lab-main/rsl_rl/rsl_rl/modules/actor_critic.py", line 180, in act
    self.update_distribution(observations)
  File "/personal/limxtron1lab-main/rsl_rl/rsl_rl/modules/actor_critic.py", line 169, in update_distribution
    self.distribution = Normal(mean, mean * 0.0 + torch.exp(self.logstd))
  File "/isaac-sim/extscache/omni.isaac.ml_archive-2.1.2+106.5.0.lx64.cp310/pip_prebundle/torch/distributions/normal.py", line 59, in __init__
    super().__init__(batch_shape, validate_args=validate_args)
  File "/isaac-sim/extscache/omni.isaac.ml_archive-2.1.2+106.5.0.lx64.cp310/pip_prebundle/torch/distributions/distribution.py", line 71, in __init__
    raise ValueError(
ValueError: Expected parameter loc (Tensor of shape (24576, 6)) of distribution Normal(loc: torch.Size([24576, 6]), scale: torch.Size([24576, 6])) to satisfy the constraint Real(), but found invalid values:
tensor([[nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan],
        ...,
        [nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan]], device='cuda:0',
       grad_fn=<AddmmBackward0>)
2026-01-05 04:30:40 [8,163,336ms] [Warning] [omni.fabric.plugin] gFabricState->gUsdStageToSimStageWithHistoryMap had 1 outstanding SimStageWithHistory(s) at shutdown
2026-01-05 04:30:40 [8,163,491ms] [Warning] [carb] Recursive unloadAllPlugins() detected!
